2024-06-29 15:07:24 root INFO     loading model + tokenizer
2024-06-29 15:07:41 root INFO     model + tokenizer loaded
2024-06-29 15:07:41 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-06-29 15:07:44 root INFO     building operator verb_inf - Ved
2024-06-29 15:07:44 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 15:07:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2207,  0.8438, -0.2192,  ...,  0.3623,  1.2656, -0.3030],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0458,  0.0251, -0.0615,  ...,  0.2156, -0.1685, -0.3887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2294,  0.8389, -0.4814,  ...,  0.7139,  0.6768, -0.1768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.0654e-01,  1.1841e-01,  6.6650e-02,  ...,  4.1528e-01,
        -3.6621e-04, -2.7783e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:07:44 root INFO     [order_1_approx] starting weight calculation for If the present form is hear, the past form is heard
If the present form is apply, the past form is applied
If the present form is replace, the past form is replaced
If the present form is perform, the past form is performed
If the present form is understand, the past form is understood
If the present form is appear, the past form is appeared
If the present form is follow, the past form is followed
If the present form is expect, the past form is
2024-06-29 15:07:44 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 15:07:51 root INFO     loading model + tokenizer
2024-06-29 15:08:07 root INFO     model + tokenizer loaded
2024-06-29 15:08:07 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-06-29 15:08:10 root INFO     building operator verb+able_reg
2024-06-29 15:08:10 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 15:08:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 6.0852e-02,  1.2720e-01,  5.5859e-01,  ..., -4.4586e-02,
         1.4563e-01, -4.1413e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2488, -0.3308,  0.0217,  ...,  0.4575, -0.3308, -0.5356],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2822,  0.4268,  0.0447,  ...,  0.0728, -0.1744, -0.2861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1394,  0.0677,  0.1562,  ...,  0.4409, -0.0406, -0.1825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:08:10 root INFO     [order_1_approx] starting weight calculation for If you can learn something, that thing is learnable
If you can predict something, that thing is predictable
If you can afford something, that thing is affordable
If you can enjoy something, that thing is enjoyable
If you can recognize something, that thing is recognizable
If you can identify something, that thing is identifiable
If you can vary something, that thing is variable
If you can replace something, that thing is
2024-06-29 15:08:10 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 15:08:33 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 15:08:44 root INFO     loading model + tokenizer
2024-06-29 15:09:01 root INFO     model + tokenizer loaded
2024-06-29 15:09:01 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-06-29 15:09:04 root INFO     building operator verb_3pSg - Ved
2024-06-29 15:09:04 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 15:09:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0702,  0.4912,  0.4126,  ...,  0.5562,  0.6592, -0.0330],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0356,  0.5059, -0.0503,  ..., -0.5439, -0.4768, -0.2373],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3589,  0.6318,  0.5938,  ...,  0.3691,  0.5073, -0.3293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0707,  0.8184,  0.5005,  ..., -0.3586, -0.0283, -0.4829],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:09:04 root INFO     [order_1_approx] starting weight calculation for When he introduces something, something has been introduced
When he allows something, something has been allowed
When he expects something, something has been expected
When he occurs something, something has been occurred
When he hears something, something has been heard
When he tells something, something has been told
When he agrees something, something has been agreed
When he happens something, something has been
2024-06-29 15:09:04 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 15:09:16 root INFO     loading model + tokenizer
2024-06-29 15:09:33 root INFO     model + tokenizer loaded
2024-06-29 15:09:33 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-06-29 15:09:36 root INFO     building operator hyponyms - misc
2024-06-29 15:09:36 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 15:09:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.5955e-01, -1.4688e+00, -1.3161e-03,  ...,  7.1875e-01,
        -1.5967e-01,  1.0273e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2241,  0.1066,  0.2312,  ...,  0.3667, -0.3977, -0.2067],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3118, -1.3018,  0.8760,  ...,  0.9492, -0.5986,  1.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1444,  0.4602, -0.0182,  ..., -0.0722, -0.5977,  0.3521],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:09:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:09:36 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 15:09:59 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 15:10:22 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 15:10:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.8348e-03,  7.8583e-04, -2.1667e-03,  ...,  4.3201e-04,
          2.6798e-03, -3.0537e-03],
        [-1.7824e-03, -9.6512e-03,  1.0290e-03,  ...,  3.8414e-03,
         -8.6021e-04,  1.4076e-03],
        [-3.5000e-03,  1.5421e-03, -1.1299e-02,  ..., -1.9875e-03,
         -5.7030e-04,  2.2392e-03],
        ...,
        [-7.7367e-05,  5.3930e-04, -9.1171e-04,  ..., -9.2163e-03,
         -1.6642e-03, -1.1168e-03],
        [ 1.2360e-03, -9.7561e-04, -5.7697e-05,  ..., -2.7447e-03,
         -8.5220e-03,  1.6479e-03],
        [-5.1260e-04, -1.4229e-03,  1.3304e-03,  ...,  3.0494e-04,
         -6.1321e-04, -7.4959e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0332, -0.0014,  0.0063,  ...,  0.0120, -0.0014, -0.0020],
        [-0.0048, -0.0386, -0.0034,  ...,  0.0070, -0.0011,  0.0047],
        [ 0.0017, -0.0032, -0.0381,  ..., -0.0028, -0.0073,  0.0092],
        ...,
        [-0.0015, -0.0013, -0.0038,  ..., -0.0437, -0.0002,  0.0001],
        [ 0.0040, -0.0011,  0.0055,  ..., -0.0010, -0.0338,  0.0053],
        [ 0.0015, -0.0005, -0.0056,  ..., -0.0001,  0.0011, -0.0319]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.5135e-02,  3.0060e-03,  3.9406e-03,  ..., -3.6449e-03,
          7.8201e-05, -5.4550e-03],
        [ 1.2712e-03, -4.4342e-02,  6.0368e-04,  ..., -1.3542e-03,
          9.9277e-04, -5.2452e-04],
        [-3.9177e-03,  1.9131e-03, -3.6133e-02,  ..., -7.2327e-03,
         -4.1962e-03, -3.2692e-03],
        ...,
        [-3.9673e-04,  2.8229e-04, -3.3569e-03,  ..., -4.6021e-02,
          1.3247e-03, -8.2922e-04],
        [-6.2466e-04, -1.2150e-03,  1.5202e-03,  ...,  1.4114e-03,
         -4.1748e-02,  9.9564e-04],
        [-1.2674e-03, -1.8988e-03, -5.3482e-03,  ...,  3.4943e-03,
          1.0920e-04, -4.1260e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:10:48 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-29 15:10:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1666, -1.2764,  0.3906,  ...,  0.5264, -0.2322,  0.8379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3186,  0.1194,  0.1998,  ...,  0.0145, -0.4351, -0.0242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0992, -0.9990,  1.0244,  ...,  0.5601, -0.6772,  1.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3296,  0.3140,  0.1763,  ..., -0.2480, -0.4941,  0.6636],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:10:48 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:10:48 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 15:11:12 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 15:11:36 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 15:12:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.4336e-02, -8.6927e-04, -9.7513e-04,  ...,  5.0735e-03,
         -2.2640e-03, -1.3685e-03],
        [ 1.5574e-03, -1.1284e-02,  1.0281e-03,  ...,  3.4580e-03,
         -7.2002e-04, -3.7718e-04],
        [-2.4867e-04, -8.1253e-04, -6.5804e-03,  ...,  6.7043e-04,
         -8.0299e-04, -1.1253e-03],
        ...,
        [ 1.4913e-04,  8.3160e-04,  8.8787e-04,  ..., -8.2703e-03,
         -2.7962e-03, -3.7308e-03],
        [ 6.6137e-04,  3.5610e-03,  4.2686e-03,  ..., -1.7223e-03,
         -1.1002e-02, -9.4056e-05],
        [ 2.5425e-03, -1.0319e-03,  9.0599e-05,  ..., -2.3899e-03,
          7.5436e-04, -1.0933e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0583,  0.0056, -0.0017,  ...,  0.0067,  0.0066,  0.0068],
        [ 0.0060, -0.0523,  0.0083,  ...,  0.0059,  0.0080, -0.0019],
        [-0.0026, -0.0086, -0.0493,  ...,  0.0046, -0.0028, -0.0024],
        ...,
        [ 0.0068,  0.0083, -0.0005,  ..., -0.0515, -0.0087, -0.0042],
        [-0.0060, -0.0052, -0.0060,  ...,  0.0027, -0.0413, -0.0031],
        [-0.0087, -0.0014,  0.0042,  ..., -0.0071,  0.0049, -0.0554]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.9092e-02,  7.0496e-03,  4.2076e-03,  ..., -6.4507e-03,
          1.0662e-03, -7.1487e-03],
        [-1.5974e-03, -7.8125e-02, -7.3013e-03,  ..., -4.2000e-03,
         -4.2114e-03, -2.7657e-03],
        [-1.7881e-05,  3.2616e-03, -6.7078e-02,  ..., -7.1945e-03,
          5.2872e-03, -1.3113e-03],
        ...,
        [ 1.5759e-04,  4.5700e-03, -4.3368e-04,  ..., -7.0312e-02,
         -4.3755e-03,  2.3232e-03],
        [-6.4430e-03, -9.0103e-03,  4.7913e-03,  ...,  4.0855e-03,
         -7.2449e-02,  2.7924e-03],
        [-4.8409e-03, -3.6240e-05,  4.3793e-03,  ..., -3.2253e-03,
          3.3741e-03, -7.2571e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:12:02 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-29 15:12:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3000, -1.4043,  0.8901,  ...,  0.9331, -0.6133,  1.3379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2358,  0.6924, -0.0281,  ..., -0.0999, -0.8833,  0.5278],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2345, -0.9443,  1.1143,  ...,  0.4983, -0.8545,  1.3545],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7051,  0.0493,  0.2512,  ..., -0.1577, -0.8857,  1.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:12:02 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:12:02 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 15:12:27 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 15:12:52 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 15:13:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0117,  0.0015, -0.0026,  ...,  0.0003, -0.0024, -0.0007],
        [ 0.0018, -0.0108,  0.0011,  ...,  0.0006,  0.0018,  0.0037],
        [ 0.0017, -0.0006, -0.0092,  ..., -0.0022,  0.0006,  0.0009],
        ...,
        [ 0.0020, -0.0001, -0.0008,  ..., -0.0096,  0.0030, -0.0002],
        [ 0.0009, -0.0011, -0.0007,  ...,  0.0020, -0.0084,  0.0016],
        [ 0.0007,  0.0004,  0.0018,  ...,  0.0022, -0.0002, -0.0088]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.9703e-02, -3.4637e-03, -2.4662e-03,  ...,  9.5444e-03,
         -4.7112e-04, -3.5248e-03],
        [-2.5902e-03, -3.8910e-02,  5.3177e-03,  ..., -5.9795e-04,
          2.4796e-05, -3.9444e-03],
        [ 1.1909e-02,  7.5073e-03, -3.2654e-02,  ..., -4.1847e-03,
          3.8567e-03, -4.6921e-03],
        ...,
        [-8.4305e-04,  4.8523e-03, -5.5408e-04,  ..., -2.4765e-02,
         -6.4392e-03,  5.1498e-04],
        [-3.2387e-03, -7.6523e-03, -4.1504e-03,  ..., -5.2109e-03,
         -3.3478e-02,  3.8223e-03],
        [-4.3869e-03,  2.7008e-03, -6.8512e-03,  ..., -1.2150e-03,
          3.9787e-03, -3.5431e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.2480e-02,  1.2617e-03, -2.9449e-03,  ...,  5.9624e-03,
         -1.2827e-03, -4.2801e-03],
        [-7.6637e-03, -4.0222e-02,  1.4603e-02,  ...,  1.5488e-02,
         -8.0338e-03, -5.3558e-03],
        [ 9.9106e-03,  1.6236e-04, -3.2074e-02,  ..., -3.2272e-03,
          7.5340e-04,  4.2992e-03],
        ...,
        [ 7.5531e-03,  6.1073e-03,  1.6975e-04,  ..., -3.6377e-02,
          4.4441e-04,  3.4771e-03],
        [-6.0425e-03,  2.2125e-03, -1.8539e-03,  ...,  3.4637e-03,
         -3.5034e-02,  6.2256e-03],
        [ 3.4714e-04,  7.8392e-04,  7.8201e-05,  ...,  1.3905e-03,
          7.5531e-03, -3.3478e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:13:19 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-29 15:13:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0765, -1.0869,  1.0391,  ...,  0.5571, -0.7109,  1.1191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5117,  0.4497,  0.2590,  ..., -0.3416, -0.7256,  0.9717],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3120, -1.2559,  1.0723,  ...,  0.8984, -0.5039,  1.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7969,  0.0545,  0.3247,  ..., -0.8838, -0.3496,  1.0068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:13:19 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:13:19 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 15:13:48 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 15:14:19 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 15:14:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.0321e-03,  5.8937e-04,  1.7881e-04,  ..., -2.2650e-05,
         -1.2493e-04, -1.4019e-03],
        [ 2.3499e-03, -6.5460e-03, -6.0081e-04,  ..., -1.1320e-03,
          3.8862e-04,  2.0373e-04],
        [-1.4029e-03, -1.8749e-03, -3.6011e-03,  ...,  1.9369e-03,
          1.4935e-03,  2.9469e-04],
        ...,
        [ 4.7851e-04, -2.1195e-04, -1.4076e-03,  ..., -3.9597e-03,
         -2.4509e-03, -2.4796e-04],
        [-1.6003e-03, -9.8038e-04, -7.7248e-05,  ..., -1.0014e-03,
         -4.7760e-03,  2.1687e-03],
        [ 1.6766e-03, -4.2000e-03,  4.0078e-04,  ..., -2.5482e-03,
          9.8944e-05, -5.1346e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.9011e-02,  4.2381e-03, -7.3357e-03,  ..., -7.7171e-03,
          1.0574e-02,  2.3613e-03],
        [-4.6120e-03, -4.3365e-02, -2.1338e-04,  ..., -2.0924e-03,
          1.6041e-03,  2.3880e-03],
        [-1.6689e-04, -1.3046e-02, -4.1534e-02,  ...,  1.2192e-02,
          4.0550e-03, -1.1482e-03],
        ...,
        [ 7.9269e-03,  4.1428e-03,  3.4409e-03,  ..., -4.7607e-02,
         -3.6163e-03, -1.7509e-03],
        [-4.9095e-03,  1.9407e-04,  3.8147e-05,  ..., -6.3019e-03,
         -4.2572e-02, -4.2000e-03],
        [ 5.6534e-03, -7.5035e-03, -6.0959e-03,  ..., -5.7755e-03,
         -3.6793e-03, -5.1605e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0589,  0.0054,  0.0032,  ..., -0.0040, -0.0014,  0.0014],
        [ 0.0049, -0.0542, -0.0090,  ..., -0.0031,  0.0064,  0.0008],
        [ 0.0064, -0.0075, -0.0607,  ..., -0.0021,  0.0004, -0.0001],
        ...,
        [ 0.0007,  0.0046,  0.0033,  ..., -0.0541, -0.0096, -0.0055],
        [ 0.0009,  0.0014,  0.0001,  ..., -0.0086, -0.0579, -0.0019],
        [-0.0017,  0.0017, -0.0023,  ...,  0.0019, -0.0016, -0.0599]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:14:52 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-29 15:14:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1952, -0.9492,  0.9790,  ...,  0.4153, -0.7578,  1.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7549,  0.0102,  0.2642,  ..., -0.1639, -0.9146,  1.0801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6729, -1.4805,  1.5664,  ...,  0.5977, -0.7661,  1.8184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9780, -0.1876,  0.3877,  ..., -0.7900, -0.4932,  1.1396],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:14:52 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:14:52 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 15:15:26 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 15:15:59 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 15:16:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0006,  0.0034, -0.0026,  ...,  0.0038,  0.0004,  0.0008],
        [ 0.0013,  0.0036,  0.0012,  ...,  0.0017, -0.0018,  0.0025],
        [-0.0007,  0.0031, -0.0032,  ...,  0.0025, -0.0005,  0.0002],
        ...,
        [-0.0002,  0.0035, -0.0009,  ..., -0.0020, -0.0015,  0.0001],
        [ 0.0017, -0.0021,  0.0005,  ...,  0.0004,  0.0011,  0.0014],
        [-0.0002, -0.0019, -0.0004,  ..., -0.0016, -0.0016,  0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.7393e-02,  6.0654e-03, -1.2505e-02,  ...,  1.5621e-03,
         -3.8548e-03, -5.0049e-03],
        [ 1.4870e-02, -6.9763e-02, -1.0017e-02,  ..., -9.5367e-05,
          1.1330e-03,  3.8986e-03],
        [ 2.4624e-03,  3.7994e-03, -8.3618e-02,  ..., -7.9498e-03,
          1.7300e-03,  1.8120e-03],
        ...,
        [-5.2795e-03,  7.3090e-03, -5.3749e-03,  ..., -6.8176e-02,
         -8.4076e-03, -4.7226e-03],
        [ 5.3329e-03,  9.2163e-03,  8.0824e-04,  ..., -5.3329e-03,
         -8.3435e-02,  2.3022e-03],
        [-1.8082e-02,  3.9673e-03,  7.6828e-03,  ...,  4.2419e-03,
          6.2065e-03, -8.2520e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1110, -0.0024,  0.0006,  ..., -0.0077, -0.0026, -0.0098],
        [ 0.0015, -0.1046,  0.0049,  ..., -0.0053, -0.0040, -0.0009],
        [-0.0014,  0.0003, -0.1013,  ...,  0.0016,  0.0052, -0.0001],
        ...,
        [-0.0047, -0.0003, -0.0043,  ..., -0.0953,  0.0080, -0.0025],
        [ 0.0032,  0.0040, -0.0059,  ..., -0.0022, -0.1095,  0.0108],
        [-0.0097,  0.0052,  0.0002,  ..., -0.0002, -0.0092, -0.1070]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:16:34 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-29 15:16:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2749, -1.1816,  0.9092,  ...,  0.7778, -0.4702,  1.3506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8579,  0.0465,  0.3250,  ..., -0.9028, -0.3855,  1.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2139, -0.7422,  1.8086,  ...,  0.6562, -1.0859,  1.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8389, -0.0181,  0.2954,  ..., -0.4834, -0.5430,  0.6011],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:16:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:16:34 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 15:17:03 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 15:17:38 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 15:18:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.0272e-03, -8.3008e-03,  5.8517e-03,  ..., -2.1000e-03,
          1.8435e-03, -9.8515e-04],
        [-1.3046e-03, -5.1155e-03,  7.8964e-03,  ..., -4.1161e-03,
          4.2653e-04,  2.5597e-03],
        [ 8.7833e-04,  4.4556e-03, -6.6719e-03,  ...,  3.2496e-04,
          3.6478e-05, -2.1629e-03],
        ...,
        [-1.8978e-04, -1.7643e-03, -4.7350e-04,  ..., -8.0948e-03,
         -8.5020e-04,  8.9073e-04],
        [ 2.9697e-03,  1.5268e-03,  8.2731e-04,  ..., -6.0806e-03,
         -2.5578e-03, -2.5940e-04],
        [ 3.7785e-03,  1.2207e-03, -3.1052e-03,  ..., -2.2602e-03,
         -3.6392e-03, -1.2331e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0696, -0.0124,  0.0070,  ...,  0.0046,  0.0074,  0.0004],
        [-0.0072, -0.0751,  0.0009,  ..., -0.0054,  0.0049,  0.0036],
        [ 0.0096,  0.0104, -0.0750,  ...,  0.0037,  0.0002, -0.0045],
        ...,
        [-0.0046, -0.0060,  0.0049,  ..., -0.0701,  0.0096,  0.0040],
        [-0.0050, -0.0084,  0.0014,  ...,  0.0070, -0.0703,  0.0017],
        [-0.0044,  0.0063,  0.0020,  ..., -0.0115,  0.0033, -0.0671]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1346e-01,  3.7956e-04, -1.5747e-02,  ...,  7.7324e-03,
          8.1177e-03, -6.1378e-03],
        [-3.3073e-03, -1.2250e-01, -1.0666e-02,  ...,  4.3030e-03,
          2.3651e-04,  1.4811e-03],
        [-2.3651e-04,  6.9656e-03, -1.1328e-01,  ..., -1.0872e-04,
          3.9749e-03,  2.8877e-03],
        ...,
        [ 7.6141e-03, -1.2951e-03,  1.5297e-02,  ..., -1.1517e-01,
         -2.6131e-03,  3.9291e-04],
        [ 3.9368e-03, -4.3869e-03,  1.6832e-03,  ...,  8.1024e-03,
         -1.1206e-01,  3.4409e-03],
        [-5.0659e-03,  8.9111e-03, -6.7482e-03,  ..., -1.2932e-02,
          6.6643e-03, -1.1743e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:18:16 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-29 15:18:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5640, -1.2871,  1.2295,  ...,  0.4460, -0.6523,  1.5430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9707, -0.1779,  0.3450,  ..., -0.7583, -0.4854,  1.1230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0596, -1.0283,  1.0342,  ...,  0.1575, -1.1641,  1.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4624, -0.3772, -0.3379,  ..., -0.6426, -0.5674,  0.4602],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:18:16 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:18:16 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 15:18:53 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 15:19:31 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 15:20:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0009,  0.0023, -0.0032,  ...,  0.0016, -0.0012,  0.0009],
        [ 0.0037,  0.0038, -0.0024,  ...,  0.0051,  0.0062, -0.0004],
        [ 0.0023, -0.0032,  0.0008,  ..., -0.0039, -0.0040,  0.0008],
        ...,
        [ 0.0005, -0.0021,  0.0015,  ..., -0.0053, -0.0011,  0.0046],
        [-0.0016,  0.0029, -0.0029,  ...,  0.0026,  0.0045, -0.0017],
        [ 0.0003, -0.0017,  0.0024,  ..., -0.0016,  0.0070,  0.0005]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0692, -0.0010, -0.0019,  ...,  0.0010, -0.0042, -0.0026],
        [-0.0036, -0.0803,  0.0046,  ..., -0.0020, -0.0002,  0.0077],
        [-0.0082, -0.0095, -0.0717,  ..., -0.0014, -0.0084, -0.0066],
        ...,
        [-0.0053,  0.0013,  0.0043,  ..., -0.0665, -0.0063,  0.0007],
        [ 0.0046, -0.0033, -0.0016,  ...,  0.0007, -0.0767,  0.0006],
        [-0.0031, -0.0083,  0.0012,  ...,  0.0023,  0.0061, -0.0743]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1160, -0.0064,  0.0080,  ..., -0.0105, -0.0011,  0.0036],
        [-0.0030, -0.0989, -0.0024,  ..., -0.0021, -0.0096,  0.0003],
        [ 0.0156,  0.0011, -0.0930,  ..., -0.0034,  0.0047, -0.0024],
        ...,
        [-0.0195,  0.0068, -0.0109,  ..., -0.1135,  0.0091,  0.0038],
        [ 0.0188,  0.0017, -0.0023,  ...,  0.0156, -0.1031, -0.0032],
        [ 0.0033, -0.0093,  0.0085,  ...,  0.0094,  0.0047, -0.1165]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:20:11 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-29 15:20:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9062, -0.5830,  1.2588,  ...,  0.4468, -0.7944,  0.9580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7524, -0.0243,  0.2418,  ..., -0.4048, -0.4792,  0.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4829, -1.1816,  0.5728,  ..., -0.2478, -1.5215,  2.0000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-8.1348e-01, -3.9893e-01, -3.9062e-02,  ..., -6.4062e-01,
        -4.8828e-04,  3.6450e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:20:11 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:20:11 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 15:20:54 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 15:21:35 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 15:22:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.7814e-03, -1.4906e-03, -2.0294e-03,  ...,  9.4461e-04,
         -6.5422e-04, -4.5815e-03],
        [-3.2597e-03, -1.1444e-02,  2.3479e-03,  ..., -4.3335e-03,
          8.8310e-04, -4.6921e-03],
        [-6.0177e-04,  4.2915e-04, -1.0468e-02,  ..., -2.5158e-03,
          2.1858e-03, -1.8940e-03],
        ...,
        [-5.4502e-04,  1.4019e-04, -1.6556e-03,  ..., -9.8724e-03,
          3.0518e-03, -1.6432e-03],
        [-1.3838e-03,  2.1858e-03, -1.8253e-03,  ..., -3.2845e-03,
         -1.3191e-02,  2.5558e-03],
        [ 2.9774e-03,  8.0032e-03, -3.6297e-03,  ..., -2.4438e-06,
         -1.3781e-03, -1.2489e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0939, -0.0062,  0.0034,  ..., -0.0075,  0.0046,  0.0094],
        [ 0.0015, -0.1032,  0.0054,  ...,  0.0086,  0.0020,  0.0122],
        [-0.0017,  0.0008, -0.0964,  ..., -0.0025, -0.0124, -0.0134],
        ...,
        [-0.0067,  0.0083, -0.0036,  ..., -0.0876,  0.0013, -0.0097],
        [-0.0076,  0.0015,  0.0020,  ...,  0.0077, -0.0928,  0.0155],
        [ 0.0210, -0.0020, -0.0074,  ...,  0.0061,  0.0030, -0.0967]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3403e-01,  8.1024e-03,  1.1398e-02,  ..., -1.8234e-02,
         -6.3782e-03,  6.1150e-03],
        [ 1.3351e-04, -1.3440e-01,  1.2817e-02,  ..., -1.1261e-02,
          5.1537e-03,  1.2306e-02],
        [ 3.4332e-04,  1.0429e-02, -1.3135e-01,  ..., -1.0862e-03,
         -4.3640e-03, -1.2112e-03],
        ...,
        [-9.2316e-03,  9.9869e-03,  1.8921e-03,  ..., -1.2646e-01,
          4.7913e-03, -7.9880e-03],
        [-5.0392e-03,  1.1490e-02, -1.1551e-02,  ..., -1.9360e-03,
         -1.2280e-01,  1.6966e-03],
        [-9.4604e-04, -1.1108e-02, -1.2436e-02,  ..., -8.7433e-03,
          2.7676e-03, -1.3171e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:22:18 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-29 15:22:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6724, -0.6914,  0.5908,  ...,  0.0734, -0.7559,  0.9932],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4041, -0.3225, -0.3184,  ..., -0.5190, -0.4724,  0.3748],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5156, -1.2920,  0.9619,  ..., -0.1018, -2.0117,  1.9756],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6450, -0.8486,  0.1433,  ..., -0.8960,  0.0792,  0.2556],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:22:18 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:22:18 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 15:23:07 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 15:23:54 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 15:24:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0044,  0.0005,  0.0010,  ..., -0.0028, -0.0041, -0.0009],
        [ 0.0029, -0.0042, -0.0036,  ..., -0.0039, -0.0052, -0.0009],
        [-0.0077,  0.0027,  0.0071,  ..., -0.0004, -0.0031,  0.0035],
        ...,
        [ 0.0001, -0.0085,  0.0004,  ...,  0.0033, -0.0061,  0.0014],
        [-0.0032,  0.0006,  0.0045,  ..., -0.0029, -0.0019,  0.0025],
        [-0.0025,  0.0005,  0.0010,  ..., -0.0095,  0.0068,  0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1027, -0.0098,  0.0015,  ...,  0.0032, -0.0023, -0.0113],
        [ 0.0068, -0.0961, -0.0055,  ...,  0.0060, -0.0023,  0.0039],
        [ 0.0107,  0.0032, -0.0905,  ...,  0.0075, -0.0006, -0.0023],
        ...,
        [ 0.0091,  0.0076,  0.0164,  ..., -0.0961, -0.0018, -0.0096],
        [ 0.0094, -0.0029,  0.0027,  ...,  0.0110, -0.0957, -0.0055],
        [-0.0079,  0.0041,  0.0166,  ..., -0.0077, -0.0023, -0.0933]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2010, -0.0021,  0.0115,  ...,  0.0109,  0.0018, -0.0023],
        [ 0.0028, -0.1991, -0.0106,  ...,  0.0033,  0.0003,  0.0072],
        [-0.0067, -0.0025, -0.1760,  ..., -0.0010, -0.0068, -0.0022],
        ...,
        [ 0.0002, -0.0010, -0.0039,  ..., -0.1956, -0.0041,  0.0146],
        [ 0.0138, -0.0004,  0.0059,  ..., -0.0025, -0.1936, -0.0184],
        [-0.0143,  0.0108,  0.0073,  ..., -0.0043, -0.0103, -0.1794]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:24:45 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-29 15:24:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2964, -0.7466,  0.2922,  ..., -0.1356, -0.9243,  1.1953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6519, -0.3401, -0.0674,  ..., -0.4763, -0.0154,  0.2561],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1592, -1.8135,  1.4941,  ..., -0.2590, -1.5098,  2.2461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7119, -0.9126,  0.5591,  ..., -0.6445, -0.1385,  1.7324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:24:45 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:24:45 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 15:25:34 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 15:26:24 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 15:27:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.2141e-03,  1.3304e-04, -4.6039e-04,  ...,  2.9469e-03,
          2.9964e-03, -7.1526e-05],
        [-4.6654e-03, -4.8637e-03,  1.9093e-03,  ...,  5.0049e-03,
          1.3838e-03,  3.2654e-03],
        [-1.6441e-03,  2.4071e-03, -6.9771e-03,  ...,  5.4474e-03,
         -6.1836e-03, -4.4250e-04],
        ...,
        [ 5.2567e-03, -4.0741e-03,  5.1727e-03,  ..., -4.0512e-03,
         -4.5815e-03,  5.7507e-04],
        [ 8.3447e-04, -9.4681e-03,  1.4935e-03,  ...,  1.8587e-03,
         -5.8022e-03,  4.8828e-03],
        [-1.6251e-03,  2.1725e-03, -4.9286e-03,  ...,  1.0557e-03,
          6.3038e-04, -7.0381e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0921,  0.0051, -0.0013,  ..., -0.0033,  0.0107,  0.0126],
        [ 0.0097, -0.0898, -0.0029,  ...,  0.0089,  0.0019, -0.0013],
        [ 0.0019, -0.0044, -0.1021,  ..., -0.0051,  0.0059,  0.0056],
        ...,
        [-0.0005,  0.0091,  0.0110,  ..., -0.0769, -0.0025, -0.0095],
        [ 0.0120,  0.0026,  0.0020,  ...,  0.0066, -0.0884,  0.0042],
        [ 0.0011,  0.0047, -0.0047,  ..., -0.0036, -0.0070, -0.0972]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1160,  0.0018, -0.0046,  ..., -0.0090,  0.0043, -0.0080],
        [ 0.0052, -0.1098,  0.0035,  ...,  0.0081, -0.0091, -0.0050],
        [ 0.0070,  0.0007, -0.1132,  ..., -0.0005, -0.0093,  0.0021],
        ...,
        [-0.0047,  0.0018,  0.0074,  ..., -0.1147,  0.0161, -0.0198],
        [ 0.0016, -0.0056, -0.0107,  ...,  0.0081, -0.1126,  0.0134],
        [ 0.0043,  0.0026, -0.0089,  ...,  0.0022, -0.0070, -0.1305]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:27:17 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-29 15:27:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2805, -0.7827,  0.4741,  ..., -0.0925, -1.1543,  1.1553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4604, -0.6162,  0.0479,  ..., -0.6196,  0.0328,  0.1818],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0834, -2.4141,  0.8213,  ..., -0.5664, -1.2949,  2.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2400, -0.4731,  0.5522,  ..., -0.3757,  0.8760,  1.2275],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:27:17 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:27:17 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 15:28:10 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 15:28:35 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 15:29:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0046, -0.0023,  0.0025,  ...,  0.0025,  0.0007,  0.0056],
        [ 0.0038,  0.0072, -0.0010,  ..., -0.0029,  0.0018, -0.0009],
        [-0.0057, -0.0079,  0.0065,  ..., -0.0108,  0.0063,  0.0014],
        ...,
        [ 0.0019,  0.0011,  0.0077,  ...,  0.0090, -0.0011,  0.0028],
        [ 0.0016, -0.0017,  0.0050,  ...,  0.0047,  0.0092,  0.0014],
        [ 0.0001,  0.0024,  0.0006,  ...,  0.0022, -0.0025,  0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1356, -0.0024,  0.0028,  ...,  0.0058, -0.0027, -0.0095],
        [ 0.0160, -0.1290, -0.0023,  ...,  0.0003, -0.0002,  0.0026],
        [-0.0085,  0.0067, -0.1378,  ..., -0.0006,  0.0017, -0.0027],
        ...,
        [-0.0082,  0.0025,  0.0087,  ..., -0.1295, -0.0032,  0.0082],
        [ 0.0040,  0.0097, -0.0104,  ..., -0.0008, -0.1426, -0.0025],
        [ 0.0005,  0.0022, -0.0064,  ..., -0.0028,  0.0078, -0.1377]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2793,  0.0198,  0.0099,  ..., -0.0033, -0.0037, -0.0009],
        [-0.0072, -0.2712, -0.0039,  ..., -0.0120,  0.0226,  0.0086],
        [-0.0036,  0.0157, -0.2656,  ...,  0.0110,  0.0098, -0.0056],
        ...,
        [-0.0045,  0.0011, -0.0036,  ..., -0.2666,  0.0196,  0.0066],
        [-0.0206,  0.0172,  0.0069,  ...,  0.0066, -0.2520, -0.0011],
        [ 0.0012, -0.0164, -0.0060,  ..., -0.0012,  0.0004, -0.2563]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:29:14 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-29 15:29:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0589, -1.0557,  0.7524,  ..., -0.1521, -0.8608,  1.2549],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5659, -0.7041,  0.3479,  ..., -0.4783, -0.1120,  1.2822],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0618, -2.6250,  0.5405,  ..., -0.2402, -1.4287,  2.7773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-7.3828e-01, -5.2734e-01, -3.8135e-01,  ..., -2.4414e-04,
         7.7734e-01,  8.2227e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:29:14 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:29:14 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 15:30:10 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 15:31:04 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 15:31:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0125,  0.0110, -0.0012,  ...,  0.0031, -0.0030, -0.0028],
        [-0.0040, -0.0150, -0.0008,  ..., -0.0088, -0.0047,  0.0012],
        [-0.0007,  0.0044, -0.0146,  ...,  0.0050, -0.0031,  0.0029],
        ...,
        [ 0.0052,  0.0014, -0.0046,  ..., -0.0093, -0.0034, -0.0023],
        [ 0.0031, -0.0062, -0.0022,  ..., -0.0060, -0.0163, -0.0021],
        [-0.0039,  0.0059, -0.0052,  ..., -0.0022,  0.0033, -0.0057]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1083, -0.0043,  0.0110,  ...,  0.0008,  0.0006, -0.0162],
        [ 0.0098, -0.1024, -0.0032,  ...,  0.0015, -0.0057,  0.0068],
        [-0.0068, -0.0194, -0.1024,  ..., -0.0030, -0.0022, -0.0011],
        ...,
        [ 0.0035, -0.0011,  0.0140,  ..., -0.0822, -0.0016,  0.0024],
        [ 0.0014, -0.0134,  0.0014,  ..., -0.0001, -0.0982,  0.0070],
        [-0.0076,  0.0099, -0.0014,  ..., -0.0103,  0.0121, -0.0901]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1044, -0.0029, -0.0097,  ...,  0.0010,  0.0031,  0.0065],
        [ 0.0179, -0.1218,  0.0039,  ..., -0.0015,  0.0124,  0.0032],
        [-0.0116, -0.0307, -0.1158,  ..., -0.0040, -0.0255,  0.0096],
        ...,
        [ 0.0048, -0.0002, -0.0004,  ..., -0.0892,  0.0024, -0.0072],
        [ 0.0049, -0.0014, -0.0037,  ...,  0.0042, -0.1119,  0.0082],
        [ 0.0003, -0.0094,  0.0014,  ..., -0.0120,  0.0025, -0.1089]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:32:00 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-29 15:32:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0409, -1.4180,  0.4263,  ..., -0.3320, -0.7280,  1.3984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1771, -0.3735,  0.3586,  ..., -0.2749,  0.6157,  0.8574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1151, -2.5820,  0.4294,  ..., -0.5229, -1.3086,  3.4980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0239, -1.1602, -0.2384,  ...,  0.2256,  0.9937, -0.0786],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:32:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:32:00 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 15:32:57 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 15:33:54 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 15:34:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0151, -0.0040, -0.0002,  ...,  0.0058, -0.0020, -0.0022],
        [-0.0123,  0.0217, -0.0023,  ...,  0.0020,  0.0043, -0.0041],
        [-0.0047, -0.0006,  0.0136,  ..., -0.0025, -0.0013, -0.0028],
        ...,
        [-0.0007,  0.0033,  0.0047,  ...,  0.0214, -0.0120,  0.0074],
        [ 0.0005, -0.0018,  0.0117,  ..., -0.0029,  0.0114, -0.0022],
        [ 0.0023,  0.0019, -0.0025,  ..., -0.0127, -0.0069,  0.0094]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1064, -0.0145, -0.0084,  ..., -0.0120,  0.0034,  0.0169],
        [ 0.0036, -0.1127,  0.0021,  ...,  0.0045,  0.0055,  0.0058],
        [ 0.0090,  0.0059, -0.1111,  ..., -0.0019, -0.0014, -0.0146],
        ...,
        [-0.0121,  0.0109, -0.0024,  ..., -0.1096, -0.0003, -0.0071],
        [ 0.0103,  0.0151, -0.0032,  ...,  0.0047, -0.1162, -0.0078],
        [ 0.0123,  0.0096, -0.0049,  ..., -0.0053,  0.0067, -0.0980]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1559,  0.0044, -0.0036,  ..., -0.0218,  0.0131, -0.0067],
        [-0.0228, -0.1824, -0.0035,  ...,  0.0043, -0.0018,  0.0143],
        [ 0.0164,  0.0043, -0.1614,  ..., -0.0048,  0.0065, -0.0109],
        ...,
        [-0.0006, -0.0054,  0.0024,  ..., -0.1439,  0.0026, -0.0026],
        [ 0.0013,  0.0127, -0.0032,  ..., -0.0003, -0.1744,  0.0007],
        [ 0.0104,  0.0161,  0.0058,  ..., -0.0092,  0.0133, -0.1580]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:34:53 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-29 15:34:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 3.1996e-04, -1.3730e+00,  2.3291e-01,  ..., -1.4221e-01,
        -7.1729e-01,  1.3994e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4717, -0.3308, -0.2399,  ..., -0.0167,  0.4937,  0.4421],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3450, -2.8281,  1.1045,  ..., -0.4238, -1.3301,  3.4648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0126, -1.5234, -0.4321,  ..., -0.4214,  1.0039,  0.0585],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:34:53 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:34:53 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 15:35:52 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 15:36:53 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 15:37:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.4992e-03, -5.4512e-03,  4.8876e-05,  ..., -3.3689e-04,
         -1.3878e-02, -2.7580e-03],
        [ 1.9426e-03,  5.1651e-03, -5.6152e-03,  ..., -3.8185e-03,
          4.6158e-03, -2.0161e-03],
        [-1.0117e-02, -1.6012e-03,  1.2817e-03,  ...,  2.6798e-03,
         -1.4887e-03,  3.5133e-03],
        ...,
        [ 7.7209e-03,  4.5776e-03, -4.5586e-03,  ...,  7.7629e-03,
         -5.1041e-03, -2.3613e-03],
        [ 4.7646e-03, -1.3123e-03,  1.6766e-03,  ...,  3.8109e-03,
          6.4392e-03,  2.5120e-03],
        [-1.4944e-03,  3.9406e-03,  5.6171e-04,  ..., -1.5631e-03,
          1.0700e-03,  7.8049e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0956,  0.0205,  0.0109,  ..., -0.0003, -0.0185, -0.0026],
        [-0.0006, -0.0880, -0.0035,  ..., -0.0064,  0.0038, -0.0084],
        [-0.0017, -0.0086, -0.0880,  ...,  0.0003,  0.0070, -0.0109],
        ...,
        [-0.0010,  0.0015, -0.0078,  ..., -0.0873,  0.0072, -0.0014],
        [-0.0077,  0.0022,  0.0017,  ..., -0.0018, -0.0850,  0.0074],
        [ 0.0005,  0.0005,  0.0010,  ...,  0.0087, -0.0014, -0.0946]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1241, -0.0038, -0.0035,  ..., -0.0077,  0.0026,  0.0014],
        [ 0.0140, -0.1172, -0.0015,  ...,  0.0223,  0.0093,  0.0025],
        [-0.0005, -0.0212, -0.1287,  ...,  0.0012,  0.0010,  0.0048],
        ...,
        [-0.0036, -0.0059, -0.0100,  ..., -0.1371,  0.0128, -0.0224],
        [-0.0125,  0.0121,  0.0158,  ...,  0.0075, -0.1288, -0.0056],
        [ 0.0030,  0.0072, -0.0137,  ..., -0.0026, -0.0054, -0.1250]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:37:51 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-29 15:37:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0692, -1.3232,  0.1991,  ..., -0.2693, -0.6392,  1.7158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0076, -0.7080, -0.1305,  ...,  0.1146,  0.5732, -0.0805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1611, -3.0879,  1.4629,  ..., -0.1040, -1.1914,  3.7578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7324, -2.3672, -0.4316,  ..., -1.1738,  0.6357, -0.5938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:37:51 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:37:51 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 15:38:45 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 15:39:40 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 15:40:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0103,  0.0017,  0.0003,  ...,  0.0010, -0.0027, -0.0012],
        [ 0.0017,  0.0039, -0.0023,  ...,  0.0019, -0.0047, -0.0009],
        [ 0.0049, -0.0040,  0.0080,  ..., -0.0015, -0.0047,  0.0004],
        ...,
        [-0.0015,  0.0002, -0.0010,  ...,  0.0107, -0.0059,  0.0042],
        [ 0.0019, -0.0044,  0.0029,  ...,  0.0009,  0.0092, -0.0025],
        [-0.0001, -0.0014,  0.0079,  ...,  0.0051,  0.0009,  0.0134]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.7463e-02, -3.2902e-05, -3.7727e-03,  ..., -1.1787e-02,
          8.8730e-03, -2.7122e-03],
        [-1.4580e-02, -8.4900e-02, -8.4229e-03,  ..., -1.2657e-02,
          8.3466e-03, -5.0964e-03],
        [-1.2764e-02,  2.7390e-03, -8.7463e-02,  ...,  1.1322e-02,
         -5.5008e-03,  6.2943e-03],
        ...,
        [ 1.6785e-03, -1.0521e-02,  1.2627e-03,  ..., -8.2214e-02,
         -2.3773e-02,  1.7414e-03],
        [ 6.0043e-03, -6.0310e-03, -1.4725e-03,  ...,  1.4008e-02,
         -9.7168e-02,  4.9553e-03],
        [ 6.5851e-04,  5.6953e-03, -4.5624e-03,  ..., -9.8572e-03,
          8.5754e-03, -7.3914e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1459,  0.0004,  0.0033,  ...,  0.0056, -0.0022,  0.0122],
        [-0.0027, -0.1681,  0.0028,  ..., -0.0103, -0.0015, -0.0020],
        [ 0.0030,  0.0072, -0.1576,  ...,  0.0101, -0.0021,  0.0090],
        ...,
        [ 0.0034, -0.0075,  0.0174,  ..., -0.1561,  0.0054,  0.0044],
        [-0.0059, -0.0166, -0.0048,  ...,  0.0084, -0.1708,  0.0003],
        [ 0.0042,  0.0027,  0.0059,  ...,  0.0007,  0.0085, -0.1604]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:40:41 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-29 15:40:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1214, -1.3740,  0.4778,  ..., -0.2054, -0.6309,  1.6406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0352, -0.8438, -0.2422,  ..., -0.2290,  0.5498,  0.0050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8672, -3.0273,  1.2031,  ..., -0.2048, -1.4062,  4.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0635, -1.8408, -0.3008,  ..., -1.3555,  0.6660, -0.3320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:40:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:40:41 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 15:41:41 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 15:42:41 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 15:43:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0029, -0.0112,  0.0023,  ...,  0.0084,  0.0019, -0.0062],
        [-0.0080,  0.0099,  0.0121,  ...,  0.0038,  0.0083,  0.0026],
        [-0.0066,  0.0009, -0.0010,  ...,  0.0066,  0.0017, -0.0030],
        ...,
        [ 0.0103, -0.0038, -0.0027,  ...,  0.0068, -0.0161, -0.0049],
        [-0.0030,  0.0050, -0.0070,  ...,  0.0089,  0.0057, -0.0056],
        [-0.0016,  0.0096,  0.0017,  ..., -0.0065,  0.0121, -0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.3171e-02,  3.0346e-03, -1.1940e-02,  ...,  1.9760e-02,
          4.1351e-03, -7.9918e-04],
        [-1.6541e-02, -4.7638e-02, -6.1722e-03,  ...,  2.3788e-02,
         -1.7853e-03, -6.8817e-03],
        [ 3.1586e-03,  5.5389e-03, -6.0242e-02,  ...,  7.1602e-03,
          2.6131e-03, -1.2764e-02],
        ...,
        [ 6.8741e-03, -2.0313e-03,  6.3858e-03,  ..., -5.9814e-02,
         -2.7657e-05, -1.2398e-02],
        [-3.8052e-04,  2.9221e-03, -2.0275e-03,  ...,  1.5244e-02,
         -4.6936e-02, -1.6983e-02],
        [ 6.5918e-03,  1.5121e-02,  1.5182e-02,  ..., -1.2932e-02,
          1.0056e-02, -8.0566e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0782,  0.0135, -0.0037,  ..., -0.0066, -0.0116,  0.0086],
        [ 0.0101, -0.0981, -0.0041,  ...,  0.0144, -0.0010,  0.0177],
        [ 0.0101,  0.0120, -0.0891,  ..., -0.0026, -0.0138, -0.0222],
        ...,
        [-0.0026, -0.0036, -0.0092,  ..., -0.0933,  0.0059, -0.0042],
        [ 0.0032,  0.0142, -0.0006,  ...,  0.0071, -0.0772,  0.0162],
        [-0.0061, -0.0016,  0.0126,  ..., -0.0068, -0.0159, -0.0999]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:43:41 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-29 15:43:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5356, -1.3770,  0.6118,  ..., -0.0534, -0.5122,  1.6035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3662, -1.1377, -0.1947,  ..., -0.5430,  0.3125, -0.3188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1855, -2.8555,  1.8691,  ..., -0.0127, -1.6797,  5.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5293, -1.4336, -0.9097,  ..., -0.7842,  0.6729, -0.7520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:43:42 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:43:42 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 15:44:45 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 15:45:47 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 15:46:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.4310e-03, -8.1329e-03, -6.9022e-05,  ..., -1.8768e-03,
          1.8892e-03,  4.6616e-03],
        [ 1.3065e-03,  1.8406e-03, -9.7632e-05,  ..., -3.5954e-04,
          1.9741e-03,  2.2793e-03],
        [-7.0190e-03,  3.2444e-03, -3.9711e-03,  ..., -4.1046e-03,
         -7.9250e-04, -4.4022e-03],
        ...,
        [ 8.7662e-03,  5.0879e-04,  3.5439e-03,  ...,  5.7755e-03,
         -4.4394e-04, -4.3335e-03],
        [ 1.5516e-03,  7.8125e-03, -1.4420e-03,  ...,  1.3189e-03,
         -5.7487e-03,  2.6875e-03],
        [ 2.4529e-03,  1.2159e-03,  5.6686e-03,  ..., -5.8441e-03,
          2.5463e-03, -7.3051e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0784,  0.0115, -0.0077,  ...,  0.0153,  0.0153,  0.0047],
        [ 0.0034, -0.0888,  0.0031,  ..., -0.0001, -0.0079,  0.0122],
        [-0.0002,  0.0030, -0.0920,  ..., -0.0093,  0.0043,  0.0105],
        ...,
        [ 0.0006,  0.0035,  0.0017,  ..., -0.0860,  0.0119, -0.0047],
        [ 0.0169,  0.0011,  0.0047,  ...,  0.0059, -0.0799,  0.0143],
        [ 0.0075,  0.0030,  0.0213,  ...,  0.0186,  0.0020, -0.0729]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2122e-01, -2.6970e-03, -8.1024e-03,  ..., -5.6381e-03,
          1.6357e-02,  8.5907e-03],
        [-1.2146e-02, -1.0925e-01, -7.0648e-03,  ...,  6.5193e-03,
         -1.1108e-02,  4.2801e-03],
        [ 7.4768e-03, -9.4223e-03, -1.2012e-01,  ..., -3.7079e-03,
          2.2173e-05, -6.7482e-03],
        ...,
        [ 1.3229e-02, -1.1322e-02,  1.6281e-02,  ..., -1.1346e-01,
          2.2354e-03,  5.9624e-03],
        [ 1.2550e-02,  1.3847e-02,  1.5007e-02,  ...,  5.7907e-03,
         -1.1523e-01, -3.5553e-03],
        [ 5.1422e-03, -1.6632e-03, -8.9874e-03,  ...,  1.7441e-02,
         -7.9536e-04, -1.0742e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:46:54 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-29 15:46:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3853, -1.2451,  0.4673,  ..., -0.0903, -0.5889,  1.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0110, -0.8135, -0.1427,  ..., -0.6016,  0.3069, -0.1969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.5400, -2.1602,  2.0332,  ..., -0.1997, -0.9824,  5.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4292, -0.8379,  0.4751,  ..., -1.0674,  1.6484, -1.3623],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:46:54 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:46:54 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 15:48:01 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 15:49:06 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 15:50:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0002, -0.0065, -0.0004,  ..., -0.0078, -0.0005, -0.0028],
        [ 0.0022, -0.0095,  0.0077,  ..., -0.0031,  0.0010, -0.0063],
        [-0.0018, -0.0055, -0.0013,  ...,  0.0039, -0.0027, -0.0001],
        ...,
        [ 0.0040, -0.0037,  0.0023,  ..., -0.0009,  0.0037,  0.0005],
        [ 0.0058, -0.0034,  0.0077,  ..., -0.0005, -0.0032, -0.0064],
        [-0.0042, -0.0035,  0.0016,  ..., -0.0016,  0.0002,  0.0025]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0934, -0.0107, -0.0021,  ..., -0.0005, -0.0012, -0.0016],
        [-0.0008, -0.0895,  0.0030,  ..., -0.0025,  0.0057, -0.0098],
        [ 0.0176, -0.0135, -0.0831,  ...,  0.0023,  0.0040, -0.0053],
        ...,
        [-0.0047, -0.0086, -0.0047,  ..., -0.0785, -0.0008,  0.0074],
        [ 0.0035,  0.0067,  0.0158,  ...,  0.0070, -0.0906, -0.0065],
        [-0.0087,  0.0006,  0.0032,  ..., -0.0032,  0.0024, -0.1025]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1017,  0.0138,  0.0048,  ..., -0.0018,  0.0069, -0.0200],
        [ 0.0151, -0.0998,  0.0118,  ..., -0.0041, -0.0048, -0.0066],
        [ 0.0060,  0.0061, -0.0854,  ...,  0.0087, -0.0011, -0.0075],
        ...,
        [-0.0022, -0.0015, -0.0207,  ..., -0.0927, -0.0020,  0.0036],
        [ 0.0051,  0.0105, -0.0011,  ...,  0.0088, -0.0858,  0.0033],
        [-0.0105,  0.0078, -0.0017,  ..., -0.0100, -0.0070, -0.0926]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:50:14 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-29 15:50:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4929, -1.1494,  0.6973,  ..., -0.0121, -0.6519,  2.0254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2281, -0.6216, -0.3987,  ..., -0.3362,  0.3120, -0.3740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.4375, -0.9629,  0.9893,  ..., -0.1667, -1.0068,  4.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9609, -1.1738, -0.5581,  ..., -1.0615,  0.8379, -2.3828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:50:14 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:50:14 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 15:51:23 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 15:52:29 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 15:53:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2980e-03,  6.1913e-03,  2.6627e-03,  ...,  7.4482e-04,
         -1.2693e-03, -5.6982e-05],
        [-2.7370e-03,  1.0384e-02, -3.5725e-03,  ...,  9.0561e-03,
          7.4883e-03, -5.9013e-03],
        [-1.1549e-03,  6.2370e-03,  5.2338e-03,  ...,  7.2174e-03,
          2.0027e-03, -1.4067e-03],
        ...,
        [-7.1478e-04, -3.6736e-03, -2.8477e-03,  ...,  1.9775e-02,
          1.8044e-03,  8.7643e-04],
        [-1.1950e-03, -1.1377e-03, -6.9122e-03,  ...,  1.5465e-02,
          1.2001e-02,  5.1498e-03],
        [ 4.7913e-03,  3.2196e-03,  1.7529e-03,  ..., -8.0795e-03,
         -5.0125e-03,  6.2103e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0471,  0.0027,  0.0107,  ..., -0.0089,  0.0225, -0.0148],
        [ 0.0019, -0.0324,  0.0025,  ...,  0.0060,  0.0103, -0.0063],
        [-0.0225,  0.0107, -0.0279,  ...,  0.0115,  0.0146,  0.0035],
        ...,
        [ 0.0146, -0.0193,  0.0184,  ..., -0.0137, -0.0008, -0.0016],
        [-0.0033,  0.0215,  0.0070,  ...,  0.0092, -0.0391,  0.0108],
        [ 0.0276,  0.0057,  0.0159,  ..., -0.0049,  0.0158, -0.0381]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0286, -0.0030,  0.0113,  ..., -0.0259,  0.0098,  0.0018],
        [ 0.0091, -0.0432, -0.0105,  ...,  0.0264, -0.0009,  0.0002],
        [-0.0073,  0.0115, -0.0470,  ...,  0.0009,  0.0107,  0.0195],
        ...,
        [ 0.0060, -0.0146,  0.0061,  ..., -0.0348, -0.0071, -0.0012],
        [-0.0078,  0.0043, -0.0005,  ..., -0.0008, -0.0535,  0.0081],
        [ 0.0018,  0.0092, -0.0029,  ...,  0.0085,  0.0066, -0.0626]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:53:40 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-29 15:53:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6021, -0.8428,  0.7197,  ..., -0.0761, -0.3762,  1.9424],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1769, -0.3513,  0.1639,  ..., -0.4224,  0.6479, -0.5879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.9990, -1.2852,  1.1914,  ..., -0.1143, -1.4199,  4.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7646, -1.8105, -0.2993,  ..., -1.1172, -0.0723, -1.6582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:53:40 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:53:40 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 15:54:52 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 15:56:03 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 15:57:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0251, -0.0067, -0.0070,  ...,  0.0083, -0.0067,  0.0034],
        [-0.0018,  0.0255, -0.0085,  ..., -0.0107, -0.0031,  0.0094],
        [-0.0070,  0.0003,  0.0176,  ..., -0.0008, -0.0044,  0.0057],
        ...,
        [ 0.0073, -0.0005, -0.0066,  ...,  0.0186,  0.0002,  0.0041],
        [ 0.0067,  0.0031, -0.0034,  ...,  0.0063,  0.0190, -0.0111],
        [-0.0056, -0.0003,  0.0037,  ..., -0.0017,  0.0034,  0.0155]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0158, -0.0045, -0.0022,  ..., -0.0006, -0.0049,  0.0023],
        [ 0.0130, -0.0278, -0.0020,  ..., -0.0102,  0.0123,  0.0025],
        [-0.0016, -0.0004, -0.0421,  ...,  0.0057, -0.0023,  0.0018],
        ...,
        [ 0.0070, -0.0083,  0.0070,  ..., -0.0156, -0.0174, -0.0130],
        [ 0.0216,  0.0014, -0.0239,  ..., -0.0033, -0.0313, -0.0094],
        [-0.0088,  0.0073, -0.0161,  ...,  0.0024,  0.0241, -0.0101]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0460,  0.0143,  0.0005,  ...,  0.0252, -0.0037,  0.0120],
        [-0.0007, -0.0533,  0.0083,  ...,  0.0103,  0.0020,  0.0207],
        [ 0.0002, -0.0014, -0.0474,  ...,  0.0129, -0.0009, -0.0042],
        ...,
        [-0.0134,  0.0001,  0.0198,  ..., -0.0343, -0.0041, -0.0084],
        [ 0.0073,  0.0185, -0.0039,  ..., -0.0135, -0.0464, -0.0209],
        [-0.0142,  0.0044, -0.0061,  ..., -0.0071,  0.0153, -0.0202]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 15:57:17 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-29 15:57:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5122, -0.3525,  0.3311,  ..., -0.0733, -0.3459,  1.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3630, -0.4512, -0.2166,  ..., -0.4072,  0.3191, -0.9229],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.5254, -1.1406,  1.2139,  ...,  0.1892, -1.1484,  3.9297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4778, -2.0762, -1.1660,  ..., -1.8574, -0.4001, -0.9482],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 15:57:17 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 15:57:17 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 15:58:37 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 15:59:56 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 16:01:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0075, -0.0064, -0.0016,  ...,  0.0037, -0.0005,  0.0028],
        [ 0.0003, -0.0184, -0.0047,  ...,  0.0018,  0.0028,  0.0025],
        [-0.0030,  0.0028, -0.0143,  ...,  0.0043, -0.0014,  0.0036],
        ...,
        [ 0.0064,  0.0005, -0.0061,  ..., -0.0087, -0.0013, -0.0006],
        [-0.0002,  0.0030,  0.0034,  ...,  0.0021, -0.0176, -0.0065],
        [ 0.0014, -0.0009,  0.0070,  ..., -0.0007,  0.0057, -0.0106]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0451, -0.0097, -0.0147,  ..., -0.0112, -0.0084,  0.0151],
        [-0.0210, -0.0415, -0.0175,  ...,  0.0043,  0.0147,  0.0067],
        [ 0.0002, -0.0104, -0.0463,  ..., -0.0029,  0.0023,  0.0136],
        ...,
        [ 0.0245, -0.0018, -0.0108,  ..., -0.0250,  0.0068,  0.0114],
        [-0.0005,  0.0008,  0.0016,  ...,  0.0009, -0.0590, -0.0029],
        [ 0.0078,  0.0013, -0.0095,  ..., -0.0176,  0.0158, -0.0404]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0833, -0.0090, -0.0179,  ..., -0.0147,  0.0013, -0.0222],
        [-0.0120, -0.0818, -0.0176,  ...,  0.0035,  0.0169,  0.0050],
        [-0.0094,  0.0005, -0.0630,  ..., -0.0036,  0.0124,  0.0147],
        ...,
        [ 0.0135, -0.0079,  0.0085,  ..., -0.0635, -0.0004,  0.0064],
        [-0.0154,  0.0122,  0.0132,  ..., -0.0137, -0.0775, -0.0185],
        [ 0.0168,  0.0052, -0.0217,  ..., -0.0050,  0.0047, -0.0736]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:01:17 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-29 16:01:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7090, -0.4395,  0.3889,  ..., -0.0358, -0.4863,  1.5068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2903, -0.6587, -0.1212,  ..., -0.4011, -0.0170, -0.6641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8677,  0.0430,  1.1621,  ..., -0.3513, -0.7500,  3.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6367, -1.0391, -1.2207,  ..., -2.7578, -0.6284, -0.0825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:01:17 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 16:01:17 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 16:02:39 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 16:04:00 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 16:05:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.0054e-03, -5.4455e-04,  6.5899e-04,  ..., -4.8971e-04,
          3.1900e-04,  1.2600e-04],
        [-3.2401e-04, -6.2981e-03, -3.8290e-04,  ...,  1.9531e-03,
         -1.4830e-03, -4.2748e-04],
        [-7.2622e-04, -1.3723e-03, -6.3477e-03,  ...,  2.3537e-03,
          3.9244e-04, -1.6108e-03],
        ...,
        [ 1.1902e-03,  3.4428e-04,  1.1212e-04,  ..., -4.1924e-03,
          1.7471e-03, -7.6103e-04],
        [-5.4932e-04,  2.1706e-03, -5.7697e-04,  ...,  1.9789e-05,
         -7.0572e-03,  3.3665e-04],
        [ 2.3961e-05,  7.7343e-04,  1.2674e-03,  ..., -1.5192e-03,
          8.2922e-04, -6.6071e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.6865e-02,  3.2104e-02,  2.6608e-04,  ...,  1.6785e-02,
         -7.4158e-03,  1.8673e-03],
        [-2.7599e-03, -4.0741e-02,  6.1913e-03,  ...,  2.5635e-03,
          1.8188e-02,  7.9498e-03],
        [-5.5504e-03, -1.7357e-04, -4.3030e-02,  ...,  2.2247e-02,
         -6.0654e-03, -3.4981e-03],
        ...,
        [ 1.4374e-02,  2.2476e-02, -1.3351e-02,  ..., -2.7481e-02,
          8.5907e-03,  6.3038e-04],
        [ 6.5346e-03,  2.4929e-03, -8.5526e-03,  ...,  1.6815e-02,
         -3.8422e-02,  8.2016e-05],
        [-1.1969e-03,  1.3336e-02,  2.4281e-03,  ..., -4.6349e-03,
         -5.6190e-03, -4.4189e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0657,  0.0201, -0.0123,  ...,  0.0220, -0.0059,  0.0155],
        [-0.0240, -0.0714, -0.0029,  ..., -0.0072, -0.0018,  0.0023],
        [ 0.0009, -0.0071, -0.0688,  ...,  0.0170,  0.0090, -0.0205],
        ...,
        [ 0.0027,  0.0261,  0.0070,  ..., -0.0389,  0.0066, -0.0027],
        [-0.0042,  0.0208,  0.0069,  ...,  0.0137, -0.0840,  0.0085],
        [ 0.0042,  0.0038,  0.0065,  ..., -0.0221, -0.0041, -0.0984]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:05:23 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-29 16:05:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5112, -0.3738,  0.3679,  ...,  0.0647, -0.3665,  1.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1624, -0.7148, -0.4250,  ..., -0.6362, -0.1221, -0.3704],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.3105,  0.4102,  2.0605,  ..., -0.4814, -0.3989,  2.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8057, -1.7930, -1.7295,  ..., -2.8770,  0.0659, -0.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:05:24 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 16:05:24 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 16:06:46 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 16:08:09 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 16:09:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.6030e-03,  1.6899e-03, -3.6669e-04,  ...,  8.6689e-04,
         -5.0354e-04,  8.9884e-05],
        [-3.7670e-04,  3.8948e-03,  1.0548e-03,  ...,  2.6627e-03,
          3.7050e-04,  2.8372e-04],
        [ 6.3944e-04,  3.7556e-03,  3.5343e-03,  ...,  8.1539e-04,
         -1.6356e-03,  3.7432e-04],
        ...,
        [ 2.0142e-03, -1.1978e-03, -2.2945e-03,  ...,  3.2425e-03,
         -1.3399e-03, -6.9761e-04],
        [-1.5230e-03, -5.8508e-04, -2.1896e-03,  ..., -4.6730e-05,
          1.8520e-03, -6.7759e-04],
        [ 1.2741e-03,  6.0320e-04,  2.3327e-03,  ..., -3.0184e-04,
         -1.9350e-03,  6.2799e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0214,  0.0057, -0.0124,  ..., -0.0139,  0.0144, -0.0035],
        [ 0.0073, -0.0326,  0.0222,  ...,  0.0260, -0.0152,  0.0026],
        [-0.0036, -0.0141, -0.0111,  ...,  0.0053, -0.0094, -0.0007],
        ...,
        [ 0.0077, -0.0059, -0.0069,  ..., -0.0075,  0.0056,  0.0064],
        [ 0.0059,  0.0015,  0.0046,  ..., -0.0239, -0.0081,  0.0110],
        [ 0.0169, -0.0133,  0.0099,  ...,  0.0037,  0.0138, -0.0569]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0545,  0.0016,  0.0016,  ..., -0.0047, -0.0003,  0.0084],
        [ 0.0161, -0.0437, -0.0053,  ..., -0.0002,  0.0186,  0.0047],
        [ 0.0060, -0.0125, -0.0774,  ..., -0.0017, -0.0202, -0.0159],
        ...,
        [ 0.0111, -0.0108, -0.0031,  ..., -0.0405, -0.0021, -0.0014],
        [ 0.0057, -0.0156, -0.0040,  ..., -0.0030, -0.0545,  0.0111],
        [ 0.0053, -0.0158,  0.0053,  ..., -0.0106, -0.0011, -0.0899]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:09:33 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-29 16:09:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2859,  0.0367,  0.3267,  ..., -0.1240, -0.2397,  1.0811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2230, -0.3142, -0.4585,  ..., -0.9253, -0.2050, -0.0592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1992,  0.6641,  2.2148,  ..., -0.4880,  0.0759,  2.6523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9155, -1.9072, -1.4727,  ..., -3.3398,  0.7539, -0.7603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:09:33 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 16:09:33 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 16:10:56 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 16:12:19 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 16:13:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0210,  0.0007,  0.0005,  ...,  0.0020,  0.0025,  0.0047],
        [-0.0020,  0.0103, -0.0003,  ..., -0.0022, -0.0037, -0.0036],
        [ 0.0002, -0.0001,  0.0197,  ...,  0.0003,  0.0007, -0.0003],
        ...,
        [-0.0027,  0.0007, -0.0003,  ...,  0.0202,  0.0020, -0.0002],
        [ 0.0044,  0.0040, -0.0002,  ...,  0.0103,  0.0243, -0.0079],
        [ 0.0048, -0.0059, -0.0031,  ...,  0.0030,  0.0006,  0.0249]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0252,  0.0078, -0.0034,  ...,  0.0249, -0.0027, -0.0021],
        [-0.0246,  0.0075, -0.0238,  ...,  0.0054,  0.0116,  0.0262],
        [-0.0078,  0.0112,  0.0397,  ...,  0.0134, -0.0027, -0.0169],
        ...,
        [-0.0314, -0.0090, -0.0156,  ...,  0.0482,  0.0060, -0.0130],
        [-0.0077, -0.0065, -0.0074,  ...,  0.0176,  0.0451, -0.0207],
        [-0.0190, -0.0007, -0.0145,  ...,  0.0025, -0.0039,  0.0471]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2154e-02, -1.4648e-02, -1.3840e-02,  ...,  3.1738e-03,
          7.5340e-05,  1.6663e-02],
        [-1.6880e-04, -2.6810e-02, -7.6218e-03,  ...,  7.4577e-04,
         -2.0737e-02,  1.8402e-02],
        [ 3.1395e-03,  2.6073e-03, -7.6599e-03,  ..., -7.9269e-03,
          5.6076e-03, -1.1734e-02],
        ...,
        [-2.5558e-02, -6.1264e-03,  6.7291e-03,  ...,  1.9913e-02,
          6.1493e-03, -1.4450e-02],
        [ 3.0685e-02,  1.9730e-02, -1.6880e-03,  ...,  1.2299e-02,
         -1.6006e-02,  6.9389e-03],
        [-9.0408e-03,  3.3703e-03,  5.8746e-03,  ...,  9.0218e-04,
         -9.0408e-04,  2.1744e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:13:44 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-29 16:13:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3933,  0.1439,  0.5898,  ..., -0.1896, -0.1305,  0.8984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2947, -0.5527, -0.6382,  ..., -0.9902,  0.0180, -0.2294],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.9912,  1.6426,  2.2676,  ..., -1.0967,  0.0701,  2.2129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1787, -1.8047, -1.6211,  ..., -2.3086,  0.7734, -0.6138],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:13:44 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 16:13:45 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 16:15:09 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 16:16:33 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 16:17:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.6790e-03, -4.1771e-04,  1.8625e-03,  ..., -9.2936e-04,
          2.1191e-03,  1.2703e-03],
        [-5.8413e-04,  3.2673e-03,  1.0118e-03,  ..., -7.7486e-05,
          4.2772e-04, -3.9935e-05],
        [-7.2670e-04, -3.5071e-04,  6.6986e-03,  ...,  4.5395e-04,
         -3.7050e-04,  3.5143e-04],
        ...,
        [ 9.3043e-05,  1.1749e-03, -9.5797e-04,  ...,  7.2784e-03,
          8.5258e-04,  7.0620e-04],
        [ 2.3937e-03,  2.3422e-03,  1.0939e-03,  ..., -4.1914e-04,
          5.4817e-03,  1.1247e-04],
        [ 9.6321e-04,  1.3561e-03,  2.3956e-03,  ...,  1.9252e-04,
          1.6856e-04,  5.6610e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0041, -0.0129,  0.0131,  ..., -0.0159,  0.0068,  0.0133],
        [ 0.0045, -0.0422, -0.0044,  ...,  0.0024,  0.0061, -0.0115],
        [-0.0112,  0.0163, -0.0025,  ...,  0.0087, -0.0137,  0.0095],
        ...,
        [-0.0186, -0.0108, -0.0081,  ..., -0.0144, -0.0066, -0.0060],
        [-0.0255,  0.0001,  0.0030,  ...,  0.0035, -0.0296,  0.0012],
        [ 0.0119,  0.0151,  0.0104,  ..., -0.0031, -0.0077,  0.0134]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0155,  0.0110,  0.0171,  ..., -0.0081,  0.0290,  0.0061],
        [ 0.0011, -0.0240,  0.0006,  ..., -0.0116,  0.0063,  0.0052],
        [-0.0143,  0.0189, -0.0193,  ...,  0.0067, -0.0094,  0.0059],
        ...,
        [-0.0111, -0.0195,  0.0005,  ..., -0.0320,  0.0088, -0.0172],
        [ 0.0073, -0.0002, -0.0033,  ...,  0.0093, -0.0517, -0.0188],
        [ 0.0069,  0.0079,  0.0235,  ...,  0.0228, -0.0046, -0.0336]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:17:59 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-29 16:17:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3088,  0.2125,  0.5479,  ..., -0.2413, -0.0079,  0.7256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3418, -0.5513, -0.5435,  ..., -1.1309,  0.2061, -0.3010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4004,  2.3281,  1.4131,  ..., -1.3398,  0.1292,  1.6152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.5791, -1.8496, -3.1660,  ..., -2.4922,  1.7090, -1.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:17:59 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 16:17:59 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 16:19:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 16:20:50 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 16:22:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.2643e-03, -2.2526e-03, -4.2725e-04,  ...,  7.1239e-04,
         -7.6151e-04, -1.5745e-03],
        [ 5.4207e-03,  6.7368e-03,  3.1033e-03,  ..., -4.5824e-04,
          3.6297e-03,  3.4924e-03],
        [ 6.0196e-03, -3.7556e-03,  5.4893e-03,  ..., -1.9217e-04,
         -3.9024e-03, -1.5087e-03],
        ...,
        [-1.8902e-03,  9.0790e-04, -8.2314e-05,  ...,  1.0193e-02,
         -6.2418e-04, -1.4915e-03],
        [ 1.0395e-03, -5.2109e-03,  1.8044e-03,  ..., -1.3514e-03,
          9.3994e-03, -1.9360e-04],
        [ 2.1534e-03,  3.1495e-04, -2.9221e-03,  ...,  1.1808e-04,
         -2.4681e-03,  1.2398e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0165,  0.0022, -0.0058,  ..., -0.0028,  0.0176, -0.0028],
        [ 0.0144,  0.0009, -0.0190,  ..., -0.0190,  0.0151,  0.0069],
        [-0.0086, -0.0097, -0.0170,  ..., -0.0020,  0.0015,  0.0132],
        ...,
        [-0.0184,  0.0089, -0.0121,  ..., -0.0188, -0.0134, -0.0016],
        [-0.0256,  0.0004,  0.0017,  ..., -0.0089, -0.0296,  0.0022],
        [ 0.0053,  0.0032, -0.0040,  ...,  0.0061,  0.0134, -0.0279]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0145, -0.0028,  0.0011,  ...,  0.0155,  0.0042,  0.0231],
        [ 0.0121, -0.0370,  0.0085,  ...,  0.0085,  0.0106,  0.0106],
        [-0.0085,  0.0020,  0.0088,  ..., -0.0120, -0.0107,  0.0223],
        ...,
        [-0.0049,  0.0301, -0.0261,  ..., -0.0117,  0.0089,  0.0182],
        [-0.0229,  0.0020,  0.0011,  ...,  0.0063,  0.0118,  0.0035],
        [-0.0035, -0.0240, -0.0010,  ...,  0.0204, -0.0025, -0.0109]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:22:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a brush is toothbrush
A more specific term for a citrus is
2024-06-29 16:22:18 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 16:22:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1621,  0.3806, -0.2252,  ..., -0.2395,  0.2125,  0.6152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0757,  0.1176,  0.1831,  ...,  0.2372, -0.2208, -0.1569],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3176,  0.6445, -0.1438,  ..., -0.2377,  0.6240,  0.4097],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2805,  0.2590, -0.0903,  ..., -0.0099, -0.3103,  0.2571],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:22:18 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:22:18 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 16:22:41 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 16:23:04 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 16:23:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.6654e-03,  6.7425e-04, -1.0109e-03,  ...,  2.8610e-05,
         -3.2520e-04, -1.8587e-03],
        [ 2.3603e-04, -6.3667e-03, -1.0204e-03,  ...,  2.2926e-03,
         -1.8835e-03, -1.4007e-04],
        [-1.2455e-03, -1.7667e-04, -8.5373e-03,  ..., -9.6083e-04,
         -2.0218e-03,  4.5562e-04],
        ...,
        [ 9.1124e-04,  1.2302e-04, -1.1330e-03,  ..., -6.9427e-03,
         -1.5259e-03, -6.4182e-04],
        [ 8.5831e-04,  1.4806e-04,  3.1471e-04,  ..., -1.7929e-03,
         -3.8166e-03,  1.5688e-04],
        [-4.9210e-04,  4.9114e-05, -1.4620e-03,  ...,  1.7285e-04,
          2.9063e-04, -4.0512e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.3325e-02, -1.0490e-02,  1.9817e-03,  ..., -3.0518e-05,
          7.0724e-03, -4.0245e-03],
        [-8.8882e-03, -3.9062e-02, -1.1387e-03,  ..., -1.7090e-03,
          3.0251e-03,  4.0197e-04],
        [ 9.2888e-04,  5.2910e-03, -3.4027e-02,  ..., -4.7264e-03,
         -2.6817e-03,  3.6774e-03],
        ...,
        [ 7.7133e-03,  2.5501e-03, -3.8300e-03,  ..., -4.2328e-02,
          4.5891e-03,  2.9564e-03],
        [ 1.0786e-03,  9.5844e-05,  4.4518e-03,  ...,  5.0068e-05,
         -3.6682e-02,  1.8997e-03],
        [ 2.3651e-04,  1.6193e-03, -2.2335e-03,  ...,  1.8311e-04,
          1.3218e-03, -3.8818e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.2755e-02,  2.2602e-03,  3.9520e-03,  ..., -3.1509e-03,
          2.1763e-03, -5.2490e-03],
        [ 2.3842e-04, -4.3823e-02,  9.9468e-04,  ...,  6.3133e-04,
          1.5030e-03,  1.7166e-04],
        [-4.6272e-03,  1.1272e-03, -3.5461e-02,  ..., -6.0883e-03,
         -3.3989e-03, -4.1351e-03],
        ...,
        [ 5.4550e-04, -2.7370e-04, -4.7798e-03,  ..., -4.4861e-02,
          7.7105e-04, -6.2132e-04],
        [-2.5158e-03, -5.3883e-05,  3.8624e-04,  ...,  2.2163e-03,
         -4.1626e-02,  1.5373e-03],
        [-1.6022e-03, -2.7809e-03, -4.0627e-03,  ...,  4.0092e-03,
         -3.0518e-05, -4.0649e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:23:30 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-29 16:23:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1556,  0.5039, -0.3062,  ..., -0.3562,  0.3652,  0.4194],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1185,  0.0473,  0.1321,  ...,  0.0210, -0.3511, -0.0580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3611,  0.3984,  0.1467,  ..., -0.3677,  0.3169,  0.3286],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4404, -0.0186, -0.0767,  ..., -0.1565, -0.2173,  0.3462],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:23:30 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:23:30 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 16:23:54 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 16:24:17 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 16:24:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.2316e-03, -2.4586e-03, -1.3037e-03,  ...,  2.7733e-03,
         -2.1458e-03,  6.8855e-04],
        [ 1.0881e-03, -8.9722e-03,  1.4105e-03,  ...,  3.0499e-03,
          1.2207e-04, -3.9518e-05],
        [-3.8671e-04, -1.1616e-03, -5.4855e-03,  ...,  9.1553e-04,
         -5.6171e-04, -4.6062e-04],
        ...,
        [-9.7990e-05,  5.7030e-04,  1.8525e-04,  ..., -7.1373e-03,
         -9.3079e-04, -1.1473e-03],
        [ 1.1749e-03,  4.5547e-03,  2.1381e-03,  ..., -8.2779e-04,
         -8.2397e-03, -4.2844e-04],
        [ 2.9640e-03, -5.2071e-04, -6.8188e-04,  ..., -2.0580e-03,
          2.4915e-04, -8.2855e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0533,  0.0032, -0.0084,  ..., -0.0017, -0.0061,  0.0046],
        [ 0.0103, -0.0527, -0.0022,  ...,  0.0088, -0.0035,  0.0053],
        [-0.0115, -0.0013, -0.0529,  ...,  0.0003,  0.0011,  0.0025],
        ...,
        [ 0.0039, -0.0015, -0.0016,  ..., -0.0552, -0.0007, -0.0021],
        [-0.0009, -0.0030,  0.0052,  ..., -0.0074, -0.0529, -0.0063],
        [-0.0005,  0.0056,  0.0019,  ..., -0.0060,  0.0002, -0.0598]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0667,  0.0015,  0.0009,  ..., -0.0046,  0.0008, -0.0085],
        [ 0.0013, -0.0722, -0.0035,  ..., -0.0009, -0.0025,  0.0010],
        [-0.0011,  0.0027, -0.0662,  ..., -0.0056,  0.0052, -0.0026],
        ...,
        [ 0.0013,  0.0053, -0.0034,  ..., -0.0679, -0.0038,  0.0003],
        [-0.0073, -0.0074,  0.0026,  ...,  0.0006, -0.0663,  0.0023],
        [-0.0068,  0.0011,  0.0049,  ..., -0.0041,  0.0010, -0.0706]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:24:43 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-29 16:24:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3711,  0.7905, -0.1847,  ..., -0.2834,  0.7505,  0.4951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4519,  0.3911, -0.1389,  ..., -0.0103, -0.4685,  0.3892],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2827,  0.5376,  0.1263,  ..., -0.2852,  0.4951,  1.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5840,  0.0874, -0.2466,  ..., -0.2993, -0.8418,  0.6650],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:24:43 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:24:43 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 16:25:09 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 16:25:35 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 16:26:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.5978e-03,  5.0449e-04, -2.2926e-03,  ..., -1.5345e-03,
         -2.2583e-03, -8.5878e-04],
        [-1.9014e-05, -7.8659e-03, -5.7268e-04,  ...,  3.8505e-04,
          1.7328e-03,  9.9564e-04],
        [ 2.2964e-03, -2.3532e-04, -7.6294e-03,  ..., -2.3441e-03,
          1.1034e-03,  4.2105e-04],
        ...,
        [ 1.5478e-03, -8.3864e-05, -1.9121e-03,  ..., -9.0179e-03,
          2.1992e-03, -6.9797e-05],
        [ 8.0466e-05,  1.7881e-06, -7.9679e-04,  ..., -3.4428e-04,
         -7.2060e-03, -2.5272e-04],
        [ 1.6232e-03,  1.4877e-04,  2.3537e-03,  ...,  1.4610e-03,
         -8.1301e-04, -8.3008e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.7058e-02,  2.9278e-04, -1.9407e-03,  ...,  7.9803e-03,
          8.5688e-04,  1.2045e-03],
        [-3.8700e-03, -4.3427e-02,  2.0885e-03,  ..., -6.4087e-03,
         -2.4376e-03, -4.4975e-03],
        [ 9.3460e-03,  1.5106e-03, -3.8116e-02,  ...,  2.6817e-03,
          5.7907e-03, -4.7531e-03],
        ...,
        [ 2.9144e-03, -4.2953e-03, -1.0735e-02,  ..., -3.8422e-02,
          6.8016e-03, -2.4033e-04],
        [-3.2616e-03, -5.8365e-03, -3.2177e-03,  ...,  1.5488e-03,
         -4.4891e-02,  3.0613e-03],
        [-2.6989e-04, -4.0531e-04, -5.3310e-04,  ...,  3.7346e-03,
         -3.3379e-05, -3.5309e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0404,  0.0044, -0.0020,  ...,  0.0065,  0.0007, -0.0017],
        [-0.0047, -0.0374,  0.0139,  ...,  0.0090, -0.0076, -0.0048],
        [ 0.0066,  0.0012, -0.0248,  ..., -0.0019,  0.0023,  0.0035],
        ...,
        [ 0.0046,  0.0058, -0.0007,  ..., -0.0376, -0.0010,  0.0037],
        [-0.0059,  0.0050, -0.0047,  ...,  0.0023, -0.0329,  0.0073],
        [-0.0006,  0.0052,  0.0005,  ...,  0.0012,  0.0050, -0.0322]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:26:03 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-29 16:26:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4148,  0.4624,  0.1715,  ..., -0.4253,  0.3525,  0.3679],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6851, -0.0481, -0.1056,  ..., -0.2152, -0.3308,  0.4988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2283,  0.0649,  0.2128,  ..., -0.3552,  0.9375,  1.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7617,  0.5342, -0.0634,  ..., -0.8848, -0.2231,  0.4866],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:26:03 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:26:03 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 16:26:32 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 16:27:02 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 16:27:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.8447e-03, -2.4915e-05, -1.5049e-03,  ..., -7.2622e-04,
          2.6722e-03, -1.3990e-03],
        [ 2.8648e-03, -8.2092e-03, -4.2677e-04,  ..., -1.9760e-03,
         -2.7537e-04, -9.6893e-04],
        [-6.8426e-04, -2.0428e-03, -5.1041e-03,  ..., -1.4343e-03,
         -6.1941e-04, -7.6866e-04],
        ...,
        [-3.3307e-04, -1.8568e-03, -8.4686e-04,  ..., -3.7746e-03,
          1.1015e-04, -4.3368e-04],
        [-9.6130e-04, -1.8930e-04,  3.6430e-04,  ..., -4.2114e-03,
         -8.6365e-03,  1.4162e-03],
        [ 1.3685e-04, -1.4973e-03, -1.2417e-03,  ..., -4.9973e-04,
         -2.6321e-03, -5.2338e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.1483e-02, -5.2023e-04, -7.1526e-03,  ..., -7.6904e-03,
          2.3441e-03,  3.8338e-03],
        [-6.6757e-05, -5.0262e-02, -2.9831e-03,  ..., -2.5034e-05,
         -2.3270e-04, -6.4611e-04],
        [ 2.2926e-03, -6.2256e-03, -4.8553e-02,  ...,  1.1330e-02,
          2.5635e-03, -1.6050e-03],
        ...,
        [ 1.0452e-03,  3.2845e-03, -2.3575e-03,  ..., -4.3274e-02,
         -7.2784e-03, -4.0436e-04],
        [-1.4496e-03,  2.3384e-03, -3.8528e-03,  ..., -1.3685e-04,
         -5.1056e-02, -8.7690e-04],
        [-2.5463e-03, -6.0806e-03,  1.8806e-03,  ..., -2.7885e-03,
          4.0817e-03, -5.1422e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0535, -0.0027, -0.0003,  ..., -0.0007, -0.0025,  0.0019],
        [ 0.0038, -0.0528, -0.0047,  ..., -0.0005,  0.0038, -0.0013],
        [ 0.0064, -0.0035, -0.0623,  ...,  0.0030, -0.0030,  0.0011],
        ...,
        [ 0.0017,  0.0019,  0.0059,  ..., -0.0612, -0.0047, -0.0020],
        [ 0.0040,  0.0009, -0.0081,  ..., -0.0028, -0.0573, -0.0065],
        [ 0.0020,  0.0040, -0.0025,  ...,  0.0077, -0.0017, -0.0566]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:27:34 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-29 16:27:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2756,  0.5322,  0.1272,  ..., -0.2925,  0.5503,  1.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6138,  0.0509, -0.2396,  ..., -0.2988, -0.8477,  0.6812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2141,  0.1478,  0.4883,  ..., -0.6616,  0.9541,  2.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8823,  0.4131, -0.0870,  ..., -1.0469, -0.3550,  0.5903],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:27:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:27:34 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 16:28:06 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 16:28:38 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 16:29:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1997e-03,  4.6921e-03, -3.3016e-03,  ...,  5.3749e-03,
          1.2989e-03,  8.4305e-04],
        [-1.3971e-03,  5.0278e-03,  3.7384e-03,  ...,  1.3857e-03,
         -2.3422e-03,  3.9215e-03],
        [ 6.7472e-04,  3.3607e-03, -2.4166e-03,  ...,  5.6601e-04,
         -1.5459e-03,  1.5202e-03],
        ...,
        [ 2.8682e-04,  4.4823e-03, -2.1725e-03,  ..., -1.9274e-03,
         -1.6994e-03,  1.4544e-03],
        [ 5.7411e-04,  3.2759e-04, -8.8310e-04,  ...,  1.8082e-03,
          4.6272e-03, -9.3699e-05],
        [-2.1935e-04, -2.5063e-03, -8.2397e-04,  ..., -2.3670e-03,
         -1.7939e-03,  5.0688e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0999,  0.0022, -0.0051,  ..., -0.0022,  0.0010, -0.0032],
        [ 0.0117, -0.0872, -0.0053,  ...,  0.0006,  0.0001,  0.0015],
        [-0.0073,  0.0077, -0.0875,  ..., -0.0088,  0.0016,  0.0054],
        ...,
        [-0.0100, -0.0034, -0.0123,  ..., -0.0867, -0.0048,  0.0073],
        [ 0.0075, -0.0017, -0.0081,  ..., -0.0123, -0.0908,  0.0132],
        [ 0.0005, -0.0044,  0.0028,  ...,  0.0051,  0.0060, -0.1127]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1214, -0.0044,  0.0119,  ..., -0.0056, -0.0055, -0.0008],
        [-0.0036, -0.1116,  0.0041,  ..., -0.0039, -0.0071,  0.0016],
        [-0.0019,  0.0018, -0.1086,  ..., -0.0029,  0.0111,  0.0018],
        ...,
        [-0.0046, -0.0031, -0.0056,  ..., -0.0986,  0.0070, -0.0083],
        [ 0.0032, -0.0005, -0.0065,  ..., -0.0049, -0.1152,  0.0061],
        [-0.0082,  0.0058,  0.0053,  ..., -0.0017, -0.0098, -0.1164]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:29:13 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-29 16:29:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2247,  0.0473,  0.1915,  ..., -0.3438,  0.9146,  1.2246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7959,  0.5586, -0.0704,  ..., -0.8774, -0.2440,  0.4990],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7549,  0.8140, -0.0840,  ..., -0.8682,  0.4351,  1.5234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7896,  0.6904, -0.2744,  ..., -0.6543, -0.2170, -0.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:29:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:29:13 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 16:29:49 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 16:30:25 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 16:30:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0079, -0.0022,  0.0065,  ...,  0.0016,  0.0027,  0.0017],
        [ 0.0006, -0.0068,  0.0060,  ..., -0.0002,  0.0010,  0.0030],
        [ 0.0020,  0.0040, -0.0044,  ..., -0.0003,  0.0001, -0.0047],
        ...,
        [ 0.0009, -0.0024, -0.0046,  ..., -0.0038, -0.0021,  0.0020],
        [ 0.0061,  0.0008, -0.0003,  ..., -0.0108, -0.0057, -0.0008],
        [ 0.0015, -0.0002,  0.0006,  ..., -0.0046,  0.0009, -0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0797, -0.0074,  0.0086,  ...,  0.0016,  0.0038,  0.0041],
        [-0.0019, -0.1012,  0.0110,  ..., -0.0015, -0.0022,  0.0036],
        [ 0.0061,  0.0137, -0.0817,  ...,  0.0065,  0.0067, -0.0060],
        ...,
        [ 0.0195,  0.0103, -0.0065,  ..., -0.0855, -0.0035, -0.0018],
        [-0.0074,  0.0034,  0.0064,  ...,  0.0008, -0.0818,  0.0121],
        [-0.0051,  0.0125,  0.0122,  ..., -0.0076,  0.0017, -0.0842]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1438e-01,  2.1362e-03, -1.0689e-02,  ...,  2.5921e-03,
          8.8348e-03, -4.5853e-03],
        [ 1.0204e-04, -1.1682e-01, -6.9885e-03,  ...,  5.8098e-03,
         -3.2921e-03,  3.2196e-03],
        [-3.4027e-03,  5.0812e-03, -1.1505e-01,  ...,  6.0616e-03,
          1.5726e-03,  2.1210e-03],
        ...,
        [ 5.2795e-03,  4.7226e-03,  7.2365e-03,  ..., -1.1609e-01,
          6.0272e-04,  1.0910e-03],
        [ 5.3787e-04,  3.2425e-05, -3.1281e-03,  ...,  1.0132e-02,
         -1.1554e-01,  3.9635e-03],
        [-8.9874e-03,  8.5678e-03, -5.0087e-03,  ..., -7.5188e-03,
          1.3008e-02, -1.1768e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:31:02 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-29 16:31:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2196,  0.1559,  0.4299,  ..., -0.6426,  0.9170,  2.0117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8652,  0.4294, -0.0960,  ..., -0.9854, -0.3457,  0.5591],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7627,  1.2949, -0.0054,  ..., -1.0322, -0.1616,  1.8936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6978,  0.2026, -0.5435,  ..., -0.9600, -0.3066,  0.2524],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:31:02 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:31:02 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 16:31:38 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 16:32:16 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 16:32:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1687e-03,  1.7538e-03, -1.3580e-03,  ...,  3.1147e-03,
         -2.9297e-03,  2.3918e-03],
        [ 2.8038e-03,  3.0460e-03, -3.0780e-04,  ...,  2.9049e-03,
          2.9430e-03,  4.7445e-05],
        [ 2.9907e-03, -2.2373e-03, -2.4471e-03,  ..., -2.1629e-03,
         -3.7537e-03,  1.4973e-03],
        ...,
        [ 1.4782e-05, -1.7586e-03,  3.2425e-03,  ..., -5.1117e-03,
         -2.3136e-03,  4.6883e-03],
        [-5.6725e-03,  2.4271e-04, -2.1992e-03,  ...,  1.8234e-03,
          1.0777e-03, -2.3842e-03],
        [ 2.0337e-04, -3.7537e-03,  2.2030e-03,  ..., -3.6278e-03,
          8.0185e-03, -3.5834e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.0515e-02, -2.6112e-03, -1.2726e-02,  ...,  8.0795e-03,
          5.6381e-03, -5.6076e-03],
        [-8.8215e-05, -9.4299e-02, -1.2207e-02,  ..., -6.9809e-03,
          1.2421e-02,  6.2675e-03],
        [-4.5319e-03, -3.3150e-03, -7.7759e-02,  ..., -4.1389e-03,
         -7.0190e-03,  6.5498e-03],
        ...,
        [-3.9902e-03,  1.3971e-03, -9.1019e-03,  ..., -7.0679e-02,
         -9.0332e-03,  1.3313e-02],
        [ 6.9580e-03, -2.5139e-03,  1.3550e-02,  ...,  1.0109e-02,
         -8.4595e-02, -2.2717e-03],
        [ 2.9640e-03,  1.0395e-04,  7.0496e-03,  ...,  9.4757e-03,
          2.3880e-03, -7.8491e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1112, -0.0082,  0.0107,  ..., -0.0085, -0.0009,  0.0041],
        [-0.0022, -0.1009, -0.0080,  ...,  0.0004, -0.0011,  0.0042],
        [ 0.0138, -0.0009, -0.0881,  ..., -0.0044,  0.0014, -0.0059],
        ...,
        [-0.0196,  0.0011, -0.0091,  ..., -0.1157,  0.0080,  0.0037],
        [ 0.0103,  0.0066,  0.0038,  ...,  0.0079, -0.1047, -0.0006],
        [ 0.0079, -0.0065,  0.0076,  ...,  0.0108,  0.0020, -0.1270]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:32:57 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-29 16:32:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6279,  0.6831, -0.0807,  ..., -0.6738,  0.3391,  1.2607],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7056,  0.6323, -0.2424,  ..., -0.5454, -0.1938, -0.3193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2217,  1.2031,  0.8511,  ..., -1.7246, -0.3794,  2.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4482, -0.2656,  0.0132,  ..., -1.0283, -0.0574,  0.3801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:32:57 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:32:57 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 16:33:35 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 16:34:16 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 16:34:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.4321e-03, -4.3106e-03, -8.1301e-04,  ..., -1.4639e-04,
         -1.5283e-04, -5.1041e-03],
        [-1.0576e-03, -4.7150e-03,  1.8940e-03,  ..., -4.9400e-03,
         -8.8024e-04, -7.4863e-04],
        [-9.2077e-04, -2.1172e-04, -5.5771e-03,  ..., -8.6498e-04,
          5.1003e-03,  6.7425e-04],
        ...,
        [-4.8370e-03, -1.4420e-03, -3.3169e-03,  ..., -6.0844e-03,
         -2.8667e-03, -1.9608e-03],
        [-1.1438e-04, -4.5128e-03,  1.3084e-03,  ..., -3.2883e-03,
         -1.1543e-02,  7.4863e-05],
        [ 2.8362e-03,  4.5013e-03,  3.9983e-04,  ...,  2.6608e-03,
         -5.0201e-03, -9.3918e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0970, -0.0031, -0.0073,  ..., -0.0026,  0.0024,  0.0189],
        [ 0.0081, -0.1130,  0.0007,  ..., -0.0056, -0.0014, -0.0021],
        [-0.0098,  0.0023, -0.0992,  ..., -0.0085, -0.0059, -0.0007],
        ...,
        [ 0.0005,  0.0155, -0.0104,  ..., -0.1076,  0.0065,  0.0037],
        [-0.0041, -0.0051, -0.0039,  ..., -0.0047, -0.1066,  0.0028],
        [ 0.0054,  0.0064, -0.0003,  ..., -0.0017, -0.0042, -0.1160]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1293,  0.0066, -0.0015,  ..., -0.0180,  0.0021, -0.0034],
        [ 0.0036, -0.1364,  0.0141,  ..., -0.0105, -0.0016,  0.0069],
        [-0.0017,  0.0086, -0.1259,  ...,  0.0010, -0.0036,  0.0150],
        ...,
        [-0.0090,  0.0055, -0.0090,  ..., -0.1226,  0.0048, -0.0183],
        [-0.0031,  0.0079, -0.0133,  ..., -0.0066, -0.1260,  0.0059],
        [-0.0123, -0.0130, -0.0073,  ..., -0.0168,  0.0061, -0.1234]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:35:00 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-29 16:35:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5205,  0.9292, -0.0574,  ..., -0.7070, -0.1298,  1.3486],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5962,  0.1691, -0.4783,  ..., -0.7603, -0.2598,  0.1973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1470,  1.7695,  1.1797,  ..., -1.7588, -0.9595,  1.6006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1968, -0.7549,  0.2661,  ..., -1.0791,  0.0867, -0.1541],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:35:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:35:00 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 16:35:50 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 16:36:37 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 16:37:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.6806e-03,  5.1270e-03,  1.2455e-03,  ..., -4.1695e-03,
         -2.5024e-03, -4.0321e-03],
        [ 4.3297e-03, -7.0648e-03, -4.8218e-03,  ..., -6.8932e-03,
         -2.7676e-03,  1.0967e-03],
        [-7.7400e-03,  2.0847e-03,  6.5498e-03,  ...,  9.5701e-04,
          2.5940e-03,  1.1873e-03],
        ...,
        [-1.7300e-03, -6.0654e-03,  2.5826e-03,  ...,  6.0806e-03,
         -7.4539e-03,  2.3060e-03],
        [-7.1564e-03,  1.6756e-03,  5.9967e-03,  ..., -2.5024e-03,
          4.6611e-05,  3.1910e-03],
        [ 1.5688e-03, -1.5697e-03,  3.8605e-03,  ..., -5.1193e-03,
          3.6392e-03,  6.8512e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1202, -0.0231,  0.0004,  ..., -0.0125,  0.0029, -0.0142],
        [ 0.0110, -0.1182, -0.0029,  ...,  0.0054, -0.0078,  0.0079],
        [-0.0048,  0.0124, -0.1072,  ..., -0.0083, -0.0038,  0.0052],
        ...,
        [ 0.0133, -0.0007,  0.0145,  ..., -0.1149,  0.0044,  0.0072],
        [ 0.0079,  0.0096,  0.0063,  ...,  0.0108, -0.1221, -0.0005],
        [ 0.0007, -0.0026,  0.0078,  ..., -0.0026,  0.0066, -0.1110]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.0337e-01, -1.1963e-02,  5.8327e-03,  ...,  1.8959e-03,
         -2.4376e-03, -8.3733e-04],
        [-3.8109e-03, -1.9946e-01, -1.1719e-02,  ...,  7.8964e-03,
          6.8207e-03,  1.2268e-02],
        [-6.3248e-03, -3.9597e-03, -1.8359e-01,  ..., -6.0081e-03,
         -6.7482e-03, -3.4332e-05],
        ...,
        [ 4.1695e-03,  9.9182e-04,  2.9755e-04,  ..., -1.9788e-01,
         -8.3084e-03,  1.2184e-02],
        [ 1.0880e-02, -1.5259e-04,  9.8419e-03,  ...,  1.4257e-03,
         -2.0447e-01, -1.8311e-02],
        [-1.0841e-02,  3.7422e-03,  1.4410e-03,  ...,  7.7438e-04,
         -1.3298e-02, -1.8665e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:37:27 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-29 16:37:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1477,  0.7793,  0.4937,  ..., -1.0645, -0.2620,  1.3027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3438, -0.2234, -0.0268,  ..., -0.7427, -0.0576,  0.2588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0280,  1.3457,  1.6152,  ..., -2.0664, -1.1836,  1.6465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3716, -1.1865,  0.4204,  ..., -1.0303,  0.1198,  1.0801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:37:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:37:27 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 16:38:16 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 16:39:04 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 16:39:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0038, -0.0003, -0.0022,  ...,  0.0028,  0.0040,  0.0048],
        [-0.0043,  0.0035,  0.0033,  ...,  0.0041,  0.0022,  0.0034],
        [ 0.0035,  0.0028, -0.0056,  ..., -0.0007, -0.0007, -0.0012],
        ...,
        [ 0.0035, -0.0005,  0.0053,  ..., -0.0034, -0.0044,  0.0037],
        [ 0.0006, -0.0022, -0.0006,  ...,  0.0039, -0.0058,  0.0008],
        [-0.0018, -0.0005, -0.0051,  ...,  0.0003,  0.0027, -0.0005]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1089,  0.0106, -0.0062,  ..., -0.0027,  0.0039,  0.0072],
        [-0.0002, -0.1047, -0.0021,  ..., -0.0072, -0.0002,  0.0019],
        [ 0.0060, -0.0069, -0.1157,  ..., -0.0056,  0.0077, -0.0006],
        ...,
        [-0.0015,  0.0045, -0.0005,  ..., -0.0928,  0.0016, -0.0090],
        [ 0.0010, -0.0026,  0.0041,  ...,  0.0143, -0.1023,  0.0096],
        [ 0.0033,  0.0062, -0.0012,  ..., -0.0023,  0.0092, -0.0970]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1215,  0.0051, -0.0017,  ..., -0.0066,  0.0013, -0.0070],
        [ 0.0072, -0.1103, -0.0011,  ..., -0.0031, -0.0097, -0.0094],
        [ 0.0060,  0.0008, -0.1217,  ...,  0.0088, -0.0116,  0.0027],
        ...,
        [-0.0018, -0.0030,  0.0033,  ..., -0.1096,  0.0081, -0.0174],
        [ 0.0033, -0.0011, -0.0064,  ...,  0.0079, -0.1119,  0.0165],
        [ 0.0049,  0.0043, -0.0089,  ...,  0.0050,  0.0046, -0.1290]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:39:57 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-29 16:39:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1102,  1.1064,  0.6489,  ..., -1.0830, -0.6104,  1.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1486, -0.5469,  0.1278,  ..., -0.7354,  0.0383, -0.1043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0834,  1.1074,  0.4971,  ..., -1.9004, -1.0078,  1.8721],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1698, -1.1270,  0.5420,  ..., -0.8667,  0.8115,  0.4146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:39:57 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:39:57 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 16:40:50 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 16:41:44 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 16:42:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0071e-02, -1.9073e-05,  4.7646e-03,  ..., -9.3746e-04,
         -8.2445e-04,  2.6360e-03],
        [ 1.0700e-03,  7.8659e-03,  3.0804e-03,  ..., -3.5286e-03,
         -1.7405e-04,  2.2106e-03],
        [-3.1395e-03, -6.0387e-03,  1.2329e-02,  ..., -4.1656e-03,
          3.6201e-03,  6.3610e-04],
        ...,
        [ 2.0275e-03,  4.3030e-03,  1.1650e-02,  ...,  1.7822e-02,
         -5.2528e-03,  1.0481e-03],
        [-1.5211e-03, -8.4543e-04, -1.0815e-03,  ..., -2.8400e-03,
          1.3359e-02,  1.6422e-03],
        [ 2.1482e-04,  3.6392e-03, -1.8513e-04,  ...,  1.5755e-03,
         -7.0477e-04,  8.0719e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.6089e-01, -8.7128e-03,  4.3774e-04,  ..., -6.8970e-03,
          2.7790e-03, -9.2850e-03],
        [ 1.0742e-02, -1.5295e-01,  1.1398e-02,  ...,  8.2397e-03,
          8.2397e-03, -9.9030e-03],
        [-8.2169e-03,  3.6831e-03, -1.6101e-01,  ...,  2.5978e-03,
          4.0150e-04, -6.0463e-03],
        ...,
        [-1.2749e-02, -9.9564e-04,  1.3443e-02,  ..., -1.6370e-01,
         -2.3861e-03,  5.0087e-03],
        [ 7.1945e-03,  1.1253e-04, -1.4603e-02,  ..., -5.7449e-03,
         -1.6150e-01, -6.4659e-03],
        [ 7.8440e-04, -7.5054e-04, -2.2339e-02,  ..., -1.4999e-02,
          1.2550e-02, -1.6626e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.7637e-01,  8.8196e-03,  3.1261e-03,  ...,  7.9346e-04,
         -6.3019e-03, -1.2817e-03],
        [-6.4201e-03, -2.7319e-01,  4.5891e-03,  ..., -1.3992e-02,
          3.1250e-02,  5.1498e-03],
        [-7.3471e-03,  8.9493e-03, -2.6074e-01,  ...,  5.9814e-03,
          1.0628e-02, -8.1635e-03],
        ...,
        [-7.7248e-03,  1.2484e-03, -6.7902e-03,  ..., -2.7734e-01,
          1.6998e-02,  7.2021e-03],
        [-1.4046e-02,  5.6915e-03,  1.0900e-03,  ...,  1.4679e-02,
         -2.6221e-01,  1.0193e-02],
        [-4.3793e-03, -4.2038e-03,  2.6894e-04,  ..., -3.8834e-03,
         -6.1493e-03, -2.6611e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:42:40 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-29 16:42:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0144,  0.8130,  0.8887,  ..., -1.2500, -0.7310,  0.9824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3127, -0.9233,  0.2537,  ..., -0.7720,  0.0812,  0.7910],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3862,  1.2344,  0.7305,  ..., -1.5186, -1.2246,  2.6211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4517, -1.4336,  0.4019,  ..., -1.0059,  0.1689,  1.3535],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:42:40 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:42:40 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 16:43:34 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 16:44:29 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 16:45:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0061,  0.0080, -0.0023,  ...,  0.0017,  0.0013, -0.0027],
        [ 0.0034, -0.0103, -0.0012,  ..., -0.0029, -0.0027,  0.0035],
        [-0.0021,  0.0062, -0.0130,  ..., -0.0027, -0.0028, -0.0057],
        ...,
        [ 0.0010,  0.0001, -0.0059,  ..., -0.0094,  0.0006,  0.0033],
        [-0.0002, -0.0013, -0.0014,  ..., -0.0039, -0.0072, -0.0002],
        [ 0.0021, -0.0003, -0.0003,  ..., -0.0022,  0.0029, -0.0078]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1049,  0.0097,  0.0098,  ...,  0.0014,  0.0030, -0.0082],
        [ 0.0113, -0.0966, -0.0061,  ..., -0.0070, -0.0025,  0.0228],
        [-0.0052, -0.0050, -0.0940,  ..., -0.0098,  0.0003, -0.0060],
        ...,
        [-0.0058,  0.0079,  0.0079,  ..., -0.0802,  0.0102, -0.0026],
        [-0.0047,  0.0053, -0.0019,  ..., -0.0051, -0.0960, -0.0009],
        [-0.0045, -0.0102,  0.0033,  ...,  0.0004,  0.0150, -0.0887]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1141,  0.0016, -0.0023,  ..., -0.0024,  0.0035,  0.0012],
        [ 0.0077, -0.1288, -0.0021,  ...,  0.0062,  0.0056,  0.0070],
        [-0.0009, -0.0182, -0.1217,  ..., -0.0129, -0.0194,  0.0028],
        ...,
        [ 0.0014,  0.0029,  0.0084,  ..., -0.1027,  0.0002, -0.0056],
        [ 0.0070,  0.0048, -0.0027,  ...,  0.0126, -0.1181,  0.0061],
        [ 0.0129, -0.0121,  0.0077,  ..., -0.0091,  0.0211, -0.1149]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:45:27 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-29 16:45:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0431,  0.6011,  0.2573,  ..., -1.0703, -0.5737,  1.0674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1284, -0.8545,  0.3594,  ..., -0.6191,  0.5825,  0.2800],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2086,  0.9307,  0.1348,  ..., -2.1504, -1.3174,  3.9629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4990, -1.3379,  0.8564,  ..., -0.7041,  0.1084,  1.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:45:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:45:27 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 16:46:25 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 16:47:23 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 16:48:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.5673e-03, -4.5204e-03, -4.9820e-03,  ...,  3.2806e-03,
          7.3433e-04,  9.3937e-04],
        [-6.6605e-03,  1.7334e-02, -2.3346e-03,  ...,  7.4863e-05,
         -2.3308e-03, -1.4931e-02],
        [-4.2572e-03,  1.0509e-03,  1.2146e-02,  ...,  2.5578e-03,
         -3.2663e-05,  1.3723e-03],
        ...,
        [ 2.3785e-03, -4.3893e-04,  1.2922e-03,  ...,  1.4336e-02,
         -1.6159e-02, -3.2597e-03],
        [-2.3975e-03, -9.0933e-04,  6.8207e-03,  ...,  5.1994e-03,
          2.0493e-02,  2.9907e-03],
        [-8.6164e-04,  1.5748e-04, -7.8812e-03,  ..., -6.2027e-03,
         -5.0125e-03,  1.4259e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.3428e-01, -2.1858e-03, -1.1337e-02,  ..., -1.9264e-03,
          1.7059e-02, -4.2572e-03],
        [ 1.7643e-03, -1.3354e-01, -6.4850e-05,  ...,  1.1063e-02,
          1.3588e-02,  7.1449e-03],
        [ 6.6261e-03, -4.6158e-03, -1.2683e-01,  ...,  3.0785e-03,
         -3.3379e-03, -1.0368e-02],
        ...,
        [-7.0953e-03,  9.3155e-03, -1.5697e-03,  ..., -1.2177e-01,
          3.9825e-03, -5.1498e-03],
        [ 3.7174e-03,  1.5350e-02, -3.9673e-03,  ...,  2.9240e-03,
         -1.2622e-01, -1.2512e-02],
        [ 6.3057e-03, -4.0131e-03, -1.3397e-02,  ..., -1.4168e-02,
         -6.0654e-04, -1.3171e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.5491e-01,  5.1117e-04, -8.4839e-03,  ..., -2.2621e-03,
          1.7395e-02, -1.0239e-02],
        [-1.8127e-02, -1.6113e-01, -1.0719e-02,  ...,  8.0795e-03,
         -6.5079e-03,  1.5076e-02],
        [ 1.1124e-02, -4.6921e-03, -1.5674e-01,  ..., -4.8447e-03,
         -2.7924e-03, -1.1421e-02],
        ...,
        [-2.0466e-03, -2.0847e-03, -4.1199e-03,  ..., -1.3635e-01,
          6.0959e-03, -2.1267e-03],
        [ 3.9024e-03,  1.8005e-02, -1.5707e-03,  ..., -1.1444e-04,
         -1.5649e-01,  3.1319e-03],
        [ 4.1084e-03,  1.3649e-02,  7.1716e-03,  ..., -7.6027e-03,
         -2.5082e-03, -1.5112e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:48:24 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-29 16:48:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1707,  0.6118,  0.3257,  ..., -0.7832, -0.6079,  1.3154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3018, -0.8770,  0.2021,  ..., -0.6074,  0.1310,  0.7729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7651,  0.9106,  0.1948,  ..., -2.4121, -0.6416,  3.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4568, -1.7617,  0.1592,  ..., -0.5820, -0.0986,  0.8311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:48:24 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:48:24 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 16:49:24 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 16:50:24 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 16:51:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0027, -0.0047,  0.0042,  ..., -0.0031, -0.0138, -0.0021],
        [ 0.0004,  0.0051, -0.0046,  ...,  0.0007,  0.0016,  0.0010],
        [-0.0084, -0.0025,  0.0045,  ..., -0.0001, -0.0028,  0.0005],
        ...,
        [ 0.0065,  0.0018, -0.0031,  ...,  0.0065, -0.0040,  0.0009],
        [ 0.0005, -0.0017, -0.0002,  ...,  0.0025,  0.0064,  0.0038],
        [-0.0006,  0.0060, -0.0024,  ..., -0.0007,  0.0009,  0.0066]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0908,  0.0150,  0.0069,  ..., -0.0056, -0.0056,  0.0078],
        [-0.0012, -0.0993,  0.0072,  ..., -0.0068,  0.0097, -0.0158],
        [ 0.0006,  0.0010, -0.0955,  ...,  0.0073,  0.0059, -0.0056],
        ...,
        [-0.0079, -0.0113, -0.0073,  ..., -0.0985,  0.0052,  0.0030],
        [ 0.0114, -0.0044,  0.0020,  ..., -0.0056, -0.0977, -0.0036],
        [ 0.0025, -0.0035,  0.0074,  ...,  0.0015,  0.0012, -0.0950]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1245,  0.0092,  0.0069,  ..., -0.0164, -0.0071,  0.0139],
        [ 0.0052, -0.1203, -0.0010,  ...,  0.0041, -0.0010, -0.0087],
        [ 0.0054, -0.0165, -0.1246,  ..., -0.0026,  0.0177, -0.0022],
        ...,
        [-0.0202, -0.0096, -0.0116,  ..., -0.1343,  0.0011, -0.0146],
        [-0.0116,  0.0074,  0.0055,  ...,  0.0113, -0.1251,  0.0036],
        [-0.0122, -0.0008, -0.0155,  ..., -0.0070, -0.0004, -0.1153]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:51:26 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-29 16:51:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0941,  0.4146,  0.0602,  ..., -1.0225, -0.6221,  1.8896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3066, -0.8218,  0.4783,  ..., -0.4155,  0.0682,  0.6123],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2935,  0.6582, -0.5684,  ..., -2.6230, -1.0566,  3.9648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4609, -2.6309, -0.8955,  ..., -0.6260, -0.7524,  0.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:51:26 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:51:26 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 16:52:28 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 16:53:27 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 16:54:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7624e-02,  7.4482e-04,  1.0128e-03,  ...,  3.1433e-03,
         -4.3869e-03,  1.7858e-04],
        [ 8.7204e-03,  9.3231e-03,  1.2083e-03,  ...,  1.6308e-03,
          1.2379e-03, -7.8821e-04],
        [ 1.4839e-03, -2.7962e-03,  1.2772e-02,  ..., -5.5008e-03,
          3.3545e-04, -2.5749e-03],
        ...,
        [-4.8027e-03, -8.4305e-04,  2.2430e-03,  ...,  1.9318e-02,
         -8.5907e-03,  2.2888e-05],
        [ 4.2267e-03, -1.6356e-03,  3.1490e-03,  ..., -6.2943e-03,
          1.8677e-02, -4.7565e-04],
        [-1.3704e-03, -1.4668e-03,  5.7373e-03,  ..., -4.7302e-03,
          4.5776e-03,  1.6907e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1049, -0.0052, -0.0100,  ...,  0.0035, -0.0071,  0.0042],
        [-0.0082, -0.1038, -0.0034,  ..., -0.0110,  0.0041, -0.0033],
        [ 0.0076,  0.0009, -0.1009,  ..., -0.0052, -0.0024,  0.0107],
        ...,
        [ 0.0085,  0.0069, -0.0003,  ..., -0.0884,  0.0013,  0.0008],
        [ 0.0073,  0.0068, -0.0104,  ..., -0.0047, -0.1014,  0.0160],
        [ 0.0039, -0.0046, -0.0080,  ..., -0.0106,  0.0063, -0.1130]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3123e-01, -5.2223e-03, -1.6632e-03,  ...,  3.0403e-03,
         -1.4931e-02,  1.4923e-02],
        [ 4.9438e-03, -1.5173e-01, -8.7585e-03,  ..., -2.4948e-03,
         -4.1847e-03, -3.1624e-03],
        [ 4.0283e-03,  1.5732e-02, -1.3074e-01,  ...,  4.9286e-03,
         -5.1422e-03,  1.6068e-02],
        ...,
        [ 2.4338e-02, -2.2984e-04,  1.8753e-02,  ..., -1.3452e-01,
         -7.5378e-03,  5.9395e-03],
        [-1.4252e-02, -8.9951e-03, -1.5030e-02,  ...,  8.9264e-03,
         -1.4587e-01,  1.0300e-04],
        [ 4.0474e-03,  1.1635e-03,  7.1564e-03,  ..., -3.0212e-03,
          2.1057e-02, -1.5552e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:54:27 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-29 16:54:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3184,  0.4316,  0.0655,  ..., -1.1104, -0.2949,  1.7607],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2937, -0.9658,  0.0638,  ..., -0.3120, -0.0485,  0.4277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5605,  1.0156, -0.6792,  ..., -2.6309, -0.8403,  5.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.5273, -3.3066, -1.4473,  ..., -0.8452, -0.4248,  1.3809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:54:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:54:27 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 16:55:28 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 16:56:30 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 16:57:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0070,  0.0038, -0.0008,  ...,  0.0047,  0.0005, -0.0002],
        [-0.0019,  0.0064, -0.0011,  ...,  0.0004,  0.0038, -0.0031],
        [-0.0015,  0.0051,  0.0006,  ...,  0.0035,  0.0048, -0.0003],
        ...,
        [-0.0013,  0.0044,  0.0002,  ...,  0.0019, -0.0085, -0.0003],
        [-0.0005,  0.0019,  0.0009,  ...,  0.0043,  0.0024, -0.0018],
        [ 0.0018, -0.0010, -0.0019,  ..., -0.0019,  0.0042, -0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0688,  0.0270, -0.0103,  ...,  0.0091,  0.0194, -0.0173],
        [-0.0026, -0.0609, -0.0062,  ...,  0.0135, -0.0074,  0.0049],
        [-0.0043, -0.0057, -0.0892,  ...,  0.0025, -0.0048, -0.0120],
        ...,
        [-0.0171,  0.0084,  0.0064,  ..., -0.0631, -0.0132,  0.0004],
        [-0.0104,  0.0152,  0.0130,  ...,  0.0072, -0.0691, -0.0141],
        [-0.0015,  0.0034,  0.0045,  ..., -0.0107,  0.0074, -0.0706]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0922,  0.0248,  0.0008,  ..., -0.0071, -0.0018, -0.0007],
        [ 0.0132, -0.0978, -0.0068,  ...,  0.0003, -0.0282,  0.0167],
        [ 0.0016,  0.0103, -0.1036,  ..., -0.0008, -0.0105, -0.0168],
        ...,
        [-0.0220,  0.0070, -0.0146,  ..., -0.1014, -0.0088,  0.0023],
        [ 0.0121,  0.0163, -0.0046,  ...,  0.0069, -0.0936,  0.0084],
        [-0.0062, -0.0053,  0.0038,  ..., -0.0005, -0.0088, -0.1131]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 16:57:36 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-29 16:57:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1392,  0.2700, -0.2269,  ..., -1.0615, -0.4272,  1.6074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7295, -1.2861, -0.4121,  ..., -0.2964, -0.3484,  0.3787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.0391,  1.2090, -0.0239,  ..., -2.6953, -0.7329,  4.9609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.7617, -2.9609, -2.0117,  ..., -1.2256, -0.7310,  0.8091],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 16:57:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 16:57:36 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 16:58:40 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 16:59:44 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 17:00:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0039, -0.0142, -0.0020,  ...,  0.0002,  0.0002,  0.0008],
        [-0.0087,  0.0173, -0.0003,  ...,  0.0033, -0.0020,  0.0019],
        [-0.0056, -0.0028,  0.0095,  ..., -0.0035,  0.0104, -0.0033],
        ...,
        [ 0.0014, -0.0059,  0.0032,  ...,  0.0111,  0.0091,  0.0008],
        [ 0.0114,  0.0028,  0.0001,  ..., -0.0016,  0.0003,  0.0004],
        [-0.0004,  0.0007,  0.0030,  ..., -0.0051,  0.0025, -0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0667, -0.0063,  0.0078,  ...,  0.0069,  0.0134, -0.0173],
        [-0.0109, -0.0707,  0.0087,  ...,  0.0097,  0.0149,  0.0082],
        [ 0.0090, -0.0012, -0.0668,  ..., -0.0069,  0.0096, -0.0051],
        ...,
        [ 0.0131, -0.0142,  0.0053,  ..., -0.0767,  0.0169,  0.0060],
        [ 0.0140, -0.0028, -0.0039,  ...,  0.0164, -0.0759,  0.0080],
        [-0.0163,  0.0031,  0.0168,  ..., -0.0011,  0.0144, -0.0624]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1035,  0.0126,  0.0051,  ...,  0.0003,  0.0066,  0.0168],
        [-0.0031, -0.0974,  0.0026,  ...,  0.0092,  0.0086,  0.0048],
        [ 0.0088,  0.0037, -0.1102,  ...,  0.0042,  0.0164, -0.0187],
        ...,
        [ 0.0272,  0.0041,  0.0108,  ..., -0.0910,  0.0073,  0.0118],
        [ 0.0189,  0.0116,  0.0017,  ...,  0.0010, -0.1111,  0.0011],
        [-0.0185,  0.0065, -0.0159,  ...,  0.0013,  0.0123, -0.0908]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:00:47 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-29 17:00:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2416,  0.3992, -0.2720,  ..., -1.0215, -0.3298,  1.9609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6841, -1.4131, -0.6177,  ..., -0.3618, -0.1796,  0.5649],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.9414,  2.0039,  0.0898,  ..., -3.2812,  0.0513,  6.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.5000, -3.4883, -2.4277,  ..., -1.3125, -0.0210,  2.3770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:00:47 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:00:47 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 17:01:52 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 17:02:56 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 17:03:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.5313e-03, -2.0447e-03, -3.8204e-03,  ..., -9.8038e-04,
         -3.9978e-03, -1.9109e-04],
        [ 6.6996e-05, -7.6904e-03,  1.4324e-03,  ...,  2.9039e-04,
          1.1187e-03, -9.9182e-04],
        [-2.4486e-04, -1.8253e-03, -9.9640e-03,  ...,  3.5248e-03,
          3.0499e-03,  4.0340e-04],
        ...,
        [ 1.2770e-03, -1.1387e-03,  1.5802e-03,  ..., -6.4354e-03,
          4.4250e-04, -1.9062e-04],
        [-7.2384e-04, -3.4833e-04,  3.7327e-03,  ..., -6.1321e-04,
         -6.7520e-03, -5.6982e-04],
        [-8.8930e-05, -4.0913e-04, -1.4782e-03,  ...,  6.3095e-03,
         -3.8166e-03, -8.7814e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1085, -0.0022, -0.0048,  ..., -0.0083, -0.0154, -0.0184],
        [ 0.0271, -0.1047,  0.0050,  ..., -0.0076, -0.0133, -0.0052],
        [ 0.0055,  0.0104, -0.0870,  ..., -0.0017,  0.0017,  0.0013],
        ...,
        [-0.0009, -0.0055, -0.0173,  ..., -0.0870,  0.0020, -0.0031],
        [-0.0008,  0.0142,  0.0073,  ...,  0.0116, -0.1174,  0.0012],
        [-0.0109, -0.0037,  0.0046,  ..., -0.0051, -0.0017, -0.1211]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1159,  0.0178, -0.0008,  ..., -0.0169, -0.0056, -0.0113],
        [ 0.0194, -0.1080, -0.0085,  ..., -0.0248, -0.0103,  0.0144],
        [ 0.0061, -0.0042, -0.0944,  ..., -0.0076,  0.0131, -0.0206],
        ...,
        [-0.0103, -0.0129, -0.0120,  ..., -0.0931, -0.0011,  0.0124],
        [ 0.0052, -0.0095,  0.0012,  ...,  0.0129, -0.0920,  0.0022],
        [-0.0168,  0.0037, -0.0075,  ..., -0.0114, -0.0131, -0.1117]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:04:01 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-29 17:04:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4280,  0.4709, -0.0320,  ..., -1.0586, -0.2695,  1.9551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8037, -1.3174, -0.8823,  ..., -0.5391, -0.3010,  0.3210],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5586,  2.6582, -0.5303,  ..., -3.1230,  0.9028,  6.6133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.2559, -2.9297, -2.9746,  ..., -1.8008,  0.8740,  1.6221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:04:01 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:04:01 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 17:05:07 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 17:06:18 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 17:07:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0015, -0.0006,  0.0032,  ...,  0.0002, -0.0007, -0.0043],
        [ 0.0039,  0.0015, -0.0048,  ..., -0.0014,  0.0001,  0.0033],
        [-0.0005, -0.0021, -0.0003,  ..., -0.0027,  0.0015,  0.0032],
        ...,
        [-0.0008, -0.0013, -0.0049,  ...,  0.0036,  0.0005, -0.0037],
        [ 0.0013, -0.0031,  0.0022,  ..., -0.0002, -0.0013,  0.0041],
        [-0.0002, -0.0010,  0.0040,  ..., -0.0027, -0.0015,  0.0038]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.8351e-02,  2.7390e-03, -2.6703e-03,  ..., -1.3344e-02,
          1.4137e-02, -2.9373e-04],
        [ 1.7410e-02, -3.9307e-02,  2.9755e-03,  ...,  1.5984e-03,
          1.4404e-02,  1.3687e-02],
        [-1.9436e-03, -3.6240e-05, -3.6896e-02,  ...,  5.9357e-03,
         -7.7515e-03,  8.6823e-03],
        ...,
        [-5.2214e-04, -9.8648e-03, -5.9700e-04,  ..., -3.8452e-02,
         -6.2332e-03, -1.7807e-02],
        [ 6.2656e-04,  5.8136e-03, -6.7902e-03,  ..., -2.4567e-02,
         -3.7750e-02,  3.4180e-03],
        [ 7.0190e-04,  8.5449e-03,  1.5991e-02,  ...,  9.4604e-03,
          1.5602e-02, -5.3558e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0447, -0.0002,  0.0168,  ..., -0.0282, -0.0037, -0.0098],
        [ 0.0205, -0.0612, -0.0099,  ...,  0.0142,  0.0066, -0.0131],
        [-0.0144, -0.0015, -0.0738,  ..., -0.0068,  0.0121,  0.0057],
        ...,
        [-0.0109, -0.0065,  0.0100,  ..., -0.0552, -0.0039,  0.0088],
        [ 0.0193, -0.0009, -0.0182,  ..., -0.0049, -0.0593,  0.0044],
        [-0.0058,  0.0112,  0.0037,  ...,  0.0139,  0.0094, -0.0655]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:07:30 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-29 17:07:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3665,  0.7520,  0.0121,  ..., -1.2285,  0.0127,  2.3691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0215, -1.4170, -0.9502,  ..., -0.5166, -0.0124,  0.9336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3682,  2.3516, -0.8555,  ..., -3.4629,  0.1851,  6.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.8125, -3.1777, -3.9062,  ..., -1.5254,  0.2290,  1.8887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:07:30 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:07:30 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 17:08:38 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 17:09:51 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 17:11:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0134,  0.0014, -0.0042,  ...,  0.0047, -0.0044,  0.0006],
        [-0.0048,  0.0083, -0.0024,  ..., -0.0059, -0.0046,  0.0027],
        [-0.0008, -0.0020,  0.0060,  ..., -0.0034,  0.0026,  0.0028],
        ...,
        [ 0.0015,  0.0009, -0.0040,  ...,  0.0040,  0.0042,  0.0017],
        [-0.0041, -0.0023,  0.0013,  ...,  0.0005,  0.0062, -0.0029],
        [-0.0017,  0.0026,  0.0005,  ..., -0.0004,  0.0003,  0.0078]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0288, -0.0056, -0.0015,  ..., -0.0041,  0.0036, -0.0036],
        [ 0.0040, -0.0231,  0.0040,  ..., -0.0126,  0.0201,  0.0025],
        [-0.0146, -0.0169, -0.0267,  ..., -0.0138, -0.0038, -0.0001],
        ...,
        [-0.0075,  0.0050,  0.0008,  ..., -0.0381,  0.0031,  0.0053],
        [-0.0033,  0.0067, -0.0048,  ..., -0.0214, -0.0171, -0.0116],
        [-0.0186,  0.0006, -0.0064,  ..., -0.0077,  0.0126, -0.0201]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.5217e-02, -5.3101e-03,  1.7410e-02,  ..., -8.0109e-05,
          1.5274e-02,  4.9019e-03],
        [ 7.1220e-03, -3.5736e-02, -1.8082e-02,  ..., -5.9357e-03,
          1.6815e-02, -2.2926e-03],
        [-1.6890e-03, -1.3100e-02, -3.0899e-02,  ...,  8.8348e-03,
          1.6312e-02, -1.9714e-02],
        ...,
        [-1.3294e-03, -5.9967e-03,  9.5215e-03,  ..., -5.0537e-02,
          1.1559e-03,  6.2523e-03],
        [-9.3536e-03,  6.4392e-03,  5.4359e-03,  ..., -5.4092e-03,
         -4.0405e-02, -4.2343e-03],
        [-7.0229e-03, -1.1917e-02, -8.9035e-03,  ..., -6.8893e-03,
         -8.7357e-03, -4.7180e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:11:06 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-29 17:11:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1962,  0.9316, -0.1968,  ..., -1.1123,  0.3245,  2.3262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8325, -1.0869, -1.0869,  ..., -0.6680,  0.3274,  0.5728],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3518,  2.4648, -1.0674,  ..., -3.7852,  0.7598,  6.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.1309, -3.3809, -3.7852,  ..., -1.9746,  0.3374,  3.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:11:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:11:06 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 17:12:27 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 17:13:46 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 17:15:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0239, -0.0039,  0.0056,  ..., -0.0053,  0.0005,  0.0004],
        [-0.0051,  0.0157,  0.0029,  ...,  0.0144, -0.0041, -0.0080],
        [ 0.0008, -0.0112,  0.0329,  ..., -0.0011,  0.0086, -0.0099],
        ...,
        [-0.0022,  0.0140,  0.0105,  ...,  0.0329, -0.0016,  0.0094],
        [-0.0034, -0.0061, -0.0003,  ..., -0.0065,  0.0261,  0.0100],
        [ 0.0024,  0.0005, -0.0029,  ..., -0.0100,  0.0071,  0.0367]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0267, -0.0163,  0.0031,  ..., -0.0061, -0.0161,  0.0004],
        [ 0.0025, -0.0125, -0.0100,  ...,  0.0145, -0.0176, -0.0004],
        [ 0.0090, -0.0066, -0.0157,  ..., -0.0087,  0.0055,  0.0060],
        ...,
        [-0.0154, -0.0069, -0.0117,  ..., -0.0191,  0.0147,  0.0087],
        [-0.0096, -0.0277,  0.0089,  ..., -0.0120, -0.0378, -0.0114],
        [ 0.0107,  0.0110, -0.0015,  ..., -0.0040, -0.0058, -0.0125]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0409, -0.0005,  0.0033,  ..., -0.0062, -0.0143, -0.0080],
        [ 0.0141, -0.0572, -0.0129,  ...,  0.0018, -0.0053,  0.0218],
        [ 0.0037, -0.0098, -0.0407,  ..., -0.0107,  0.0014, -0.0092],
        ...,
        [-0.0027,  0.0007, -0.0344,  ..., -0.0380,  0.0049,  0.0049],
        [ 0.0062, -0.0148,  0.0081,  ..., -0.0038, -0.0541, -0.0098],
        [ 0.0089,  0.0074, -0.0015,  ..., -0.0046, -0.0039, -0.0239]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:15:08 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-29 17:15:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1300,  0.8052, -0.3083,  ..., -1.1914,  0.0746,  2.1875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6323, -1.0645, -1.3184,  ..., -0.5054,  0.0901,  0.6323],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8237,  2.2383, -0.2271,  ..., -3.3418,  1.1279,  6.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.1797, -4.5000, -2.5664,  ..., -1.0762, -1.2402,  3.0664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:15:08 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:15:08 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 17:16:27 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 17:17:50 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 17:19:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.0817e-03,  1.0071e-03,  1.2941e-03,  ..., -6.0177e-04,
         -1.5574e-03, -1.4153e-03],
        [-8.0347e-05, -1.0834e-03, -2.5916e-04,  ...,  6.5279e-04,
         -4.5836e-05, -1.4734e-04],
        [ 7.8154e-04, -7.7057e-04, -4.0512e-03,  ...,  7.0930e-05,
          1.6081e-04, -1.3196e-04],
        ...,
        [ 5.9366e-04, -4.8876e-04,  9.6512e-04,  ..., -2.2907e-03,
          8.2397e-04, -4.3964e-04],
        [ 9.7656e-04,  1.3037e-03,  8.6069e-05,  ..., -6.9046e-04,
         -3.8357e-03, -1.5612e-03],
        [-8.7082e-05,  4.2224e-04,  1.3571e-03,  ..., -1.7433e-03,
         -8.2588e-04, -4.7226e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0411,  0.0072, -0.0014,  ...,  0.0102, -0.0260,  0.0048],
        [-0.0009, -0.0402,  0.0162,  ...,  0.0043,  0.0086,  0.0071],
        [ 0.0126,  0.0085, -0.0267,  ...,  0.0102, -0.0119, -0.0058],
        ...,
        [ 0.0106,  0.0277, -0.0027,  ..., -0.0475, -0.0068,  0.0059],
        [ 0.0058,  0.0055, -0.0211,  ...,  0.0069, -0.0285, -0.0082],
        [ 0.0091,  0.0025, -0.0004,  ...,  0.0090, -0.0016, -0.0336]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0574,  0.0218,  0.0020,  ...,  0.0080, -0.0198,  0.0090],
        [-0.0004, -0.0662,  0.0015,  ...,  0.0122,  0.0212, -0.0093],
        [ 0.0022,  0.0053, -0.0439,  ..., -0.0193,  0.0139,  0.0015],
        ...,
        [ 0.0198, -0.0074,  0.0235,  ..., -0.0536, -0.0065,  0.0140],
        [ 0.0071,  0.0263, -0.0044,  ..., -0.0031, -0.0598,  0.0038],
        [ 0.0078, -0.0166, -0.0167,  ..., -0.0093,  0.0015, -0.0667]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:19:14 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-29 17:19:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1299,  0.8159, -0.3787,  ..., -1.2549,  0.2764,  2.1914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6899, -1.0645, -1.2129,  ..., -0.6182,  0.1292,  0.9976],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4580,  2.8945, -0.3411,  ..., -3.4766,  1.0957,  7.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.1699, -4.7852, -1.8623,  ..., -0.5063, -1.2578,  2.4414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:19:14 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:19:14 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 17:20:37 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 17:22:00 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 17:23:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0052, -0.0029,  0.0010,  ...,  0.0012, -0.0066,  0.0013],
        [-0.0040, -0.0048,  0.0099,  ...,  0.0094, -0.0025, -0.0048],
        [-0.0019,  0.0080, -0.0039,  ...,  0.0023, -0.0015,  0.0066],
        ...,
        [ 0.0124,  0.0026, -0.0033,  ..., -0.0140, -0.0014, -0.0025],
        [-0.0077,  0.0005, -0.0007,  ...,  0.0006, -0.0054, -0.0061],
        [-0.0027, -0.0024,  0.0050,  ..., -0.0002, -0.0018, -0.0099]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0261, -0.0209, -0.0248,  ..., -0.0077, -0.0104, -0.0064],
        [ 0.0269, -0.0286,  0.0260,  ..., -0.0018, -0.0180, -0.0036],
        [ 0.0052,  0.0017, -0.0053,  ..., -0.0057, -0.0126,  0.0098],
        ...,
        [-0.0113,  0.0024, -0.0264,  ..., -0.0287,  0.0131, -0.0085],
        [-0.0227,  0.0097,  0.0163,  ..., -0.0068, -0.0213,  0.0101],
        [-0.0112, -0.0079, -0.0013,  ..., -0.0135,  0.0041, -0.0172]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0462, -0.0181,  0.0100,  ..., -0.0119, -0.0163, -0.0047],
        [ 0.0153, -0.0415,  0.0149,  ..., -0.0021,  0.0013, -0.0015],
        [ 0.0037, -0.0026, -0.0353,  ..., -0.0084, -0.0158, -0.0111],
        ...,
        [-0.0006, -0.0031, -0.0176,  ..., -0.0387,  0.0034, -0.0045],
        [-0.0002,  0.0084,  0.0273,  ...,  0.0043, -0.0450,  0.0010],
        [-0.0004, -0.0137, -0.0091,  ..., -0.0044, -0.0134, -0.0377]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:23:26 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-29 17:23:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2817,  0.7441, -0.1250,  ..., -1.1045,  0.3884,  2.1895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6812, -1.3203, -0.8374,  ..., -0.3359, -0.3777,  0.9414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0342,  3.0000,  0.1047,  ..., -2.6250,  0.7261,  7.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-3.0176, -4.9414, -1.2168,  ...,  0.0527, -1.2500,  3.3770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:23:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:23:27 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 17:24:50 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 17:26:14 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 17:27:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.2016e-03,  2.1496e-03,  2.6774e-04,  ...,  2.0943e-03,
          3.2558e-03,  4.4594e-03],
        [-4.3869e-04,  9.2239e-03, -6.1750e-04,  ..., -1.3571e-03,
         -1.7471e-03, -2.3384e-03],
        [-1.0691e-03,  1.1044e-03,  8.4305e-03,  ..., -2.1496e-03,
          1.3666e-03,  1.0605e-03],
        ...,
        [ 1.1683e-03, -2.3785e-03,  7.0000e-04,  ...,  1.1597e-02,
          4.4107e-04, -2.3708e-03],
        [ 1.7471e-03,  3.6106e-03, -5.0020e-04,  ...,  3.0651e-03,
          9.9258e-03, -2.5196e-03],
        [ 1.4842e-05, -1.8682e-03, -2.2144e-03,  ..., -2.4452e-03,
          6.5708e-04,  1.6052e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0177,  0.0258,  0.0087,  ...,  0.0017,  0.0224,  0.0028],
        [-0.0061, -0.0218,  0.0049,  ...,  0.0078,  0.0087,  0.0058],
        [-0.0046, -0.0005,  0.0206,  ...,  0.0164, -0.0039, -0.0066],
        ...,
        [-0.0126,  0.0030, -0.0087,  ...,  0.0137,  0.0001, -0.0086],
        [-0.0054, -0.0114, -0.0098,  ...,  0.0016,  0.0089, -0.0183],
        [ 0.0139,  0.0107,  0.0015,  ..., -0.0081,  0.0095,  0.0223]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 3.0041e-03,  5.6343e-03,  1.0357e-03,  ..., -1.9913e-02,
          2.1042e-02, -7.0667e-04],
        [ 6.6147e-03, -2.5452e-02, -1.5808e-02,  ..., -1.4336e-02,
          1.7166e-05,  2.7802e-02],
        [ 7.5226e-03, -1.4839e-03,  2.3621e-02,  ...,  2.7145e-02,
         -8.4610e-03, -4.1771e-03],
        ...,
        [-1.1459e-02,  1.0052e-03, -1.5373e-02,  ...,  1.3405e-02,
          5.9853e-03,  1.4366e-02],
        [ 5.0812e-03,  5.4283e-03, -7.4043e-03,  ..., -2.1591e-03,
          1.7639e-02,  1.3336e-02],
        [ 1.2390e-02,  4.3030e-03,  1.0643e-02,  ...,  4.2419e-03,
          1.7548e-02, -3.2139e-04]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:27:41 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-29 17:27:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1692,  0.9048, -0.1678,  ..., -1.1348,  0.3430,  2.3418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6348, -1.3584, -0.6196,  ..., -0.1881, -0.3809,  0.7134],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9126,  4.3164, -0.4519,  ..., -3.1641,  0.9209,  7.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-3.3398, -4.3242, -1.6807,  ...,  0.2271, -2.4219,  4.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:27:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:27:41 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 17:29:08 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 17:30:35 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 17:32:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.8862e-04,  4.2248e-04,  1.4095e-03,  ..., -5.4741e-04,
          7.2908e-04,  9.5272e-04],
        [ 5.4598e-05, -7.8201e-04,  3.9673e-04,  ...,  3.1734e-04,
         -5.9652e-04, -4.6074e-05],
        [ 1.0195e-03,  5.4240e-05, -4.9210e-04,  ...,  5.1737e-04,
          1.1711e-03, -1.2169e-03],
        ...,
        [-2.0003e-04,  1.9569e-03, -2.0370e-03,  ..., -2.0618e-03,
          1.0099e-03,  8.9216e-04],
        [ 1.4544e-03, -7.6962e-04,  6.9284e-04,  ..., -8.3447e-04,
         -1.5917e-03, -1.3866e-03],
        [ 2.4338e-03,  1.0929e-03,  1.3399e-04,  ...,  6.8283e-04,
          3.0422e-04, -1.9550e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0148,  0.0236,  0.0061,  ..., -0.0176,  0.0057,  0.0111],
        [-0.0138, -0.0290,  0.0036,  ...,  0.0098,  0.0027, -0.0151],
        [-0.0035,  0.0071, -0.0114,  ...,  0.0134,  0.0063, -0.0010],
        ...,
        [ 0.0004,  0.0098, -0.0147,  ..., -0.0270,  0.0076,  0.0013],
        [ 0.0074, -0.0121, -0.0033,  ...,  0.0100, -0.0182,  0.0215],
        [-0.0120,  0.0069, -0.0079,  ...,  0.0043, -0.0118, -0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0291,  0.0209,  0.0172,  ..., -0.0073,  0.0022,  0.0134],
        [-0.0118, -0.0140,  0.0079,  ...,  0.0233,  0.0149,  0.0014],
        [ 0.0062,  0.0077, -0.0031,  ...,  0.0039, -0.0115,  0.0042],
        ...,
        [-0.0074,  0.0024, -0.0281,  ..., -0.0384,  0.0239, -0.0038],
        [ 0.0122,  0.0094, -0.0222,  ...,  0.0083, -0.0210,  0.0032],
        [ 0.0086, -0.0020,  0.0102,  ...,  0.0002,  0.0047,  0.0213]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:32:03 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-29 17:32:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3523,  0.8623, -0.0591,  ..., -0.8452,  0.1785,  2.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8066, -1.3047, -0.4216,  ..., -0.0833, -0.3718,  0.8999],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3828,  4.3594, -1.6357,  ..., -3.5566,  0.6826,  6.4219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.2051, -3.5605, -3.6172,  ..., -0.1057, -2.0117,  3.3555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:32:03 root INFO     [order_1_approx] starting weight calculation for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:32:03 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 17:33:30 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 17:34:56 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 17:36:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.7351e-03, -1.3142e-03,  6.6996e-04,  ..., -1.0290e-03,
         -1.7405e-04, -1.5602e-03],
        [ 4.4370e-04,  8.5449e-03, -3.0160e-04,  ..., -7.8344e-04,
          1.1559e-03,  1.2817e-03],
        [ 3.6907e-03, -2.1038e-03,  1.0139e-02,  ...,  1.4038e-03,
         -2.9335e-03, -3.6049e-04],
        ...,
        [-4.9067e-04, -2.9302e-04,  1.1072e-03,  ...,  1.2939e-02,
         -1.3008e-03, -9.0551e-04],
        [-1.5793e-03, -1.7672e-03,  1.1368e-03,  ..., -1.1702e-03,
          1.2688e-02, -1.1215e-03],
        [ 1.6146e-03,  1.0033e-03, -6.5517e-04,  ...,  6.5982e-05,
          1.6308e-03,  1.5022e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0170,  0.0122, -0.0061,  ..., -0.0017,  0.0041,  0.0091],
        [ 0.0041, -0.0100, -0.0086,  ..., -0.0126,  0.0169,  0.0124],
        [-0.0092, -0.0003, -0.0206,  ...,  0.0136, -0.0138,  0.0012],
        ...,
        [-0.0099, -0.0108, -0.0064,  ..., -0.0065, -0.0318, -0.0217],
        [-0.0009,  0.0048, -0.0178,  ..., -0.0198,  0.0064, -0.0063],
        [-0.0141,  0.0158,  0.0133,  ...,  0.0061,  0.0033, -0.0107]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0048,  0.0083, -0.0092,  ...,  0.0008,  0.0031,  0.0093],
        [ 0.0355, -0.0210,  0.0025,  ...,  0.0050,  0.0148,  0.0281],
        [-0.0064, -0.0016,  0.0039,  ...,  0.0115,  0.0008,  0.0013],
        ...,
        [-0.0115,  0.0143, -0.0028,  ...,  0.0267, -0.0184, -0.0148],
        [ 0.0192,  0.0027, -0.0266,  ...,  0.0169,  0.0069, -0.0003],
        [-0.0289,  0.0186,  0.0261,  ..., -0.0045,  0.0172,  0.0182]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:36:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a bed is bunk
A more specific term for a weapon is gun
A more specific term for a painting is
2024-06-29 17:36:24 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 17:36:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0124,  0.1127,  0.5698,  ..., -0.1190, -0.8604,  0.1654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0764,  0.2744,  0.2100,  ...,  0.2028, -0.2883, -0.1796],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0460,  0.1548,  0.7510,  ..., -0.1523, -0.6069,  0.5259],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0496,  0.4583, -0.3279,  ...,  0.1243, -0.5635,  0.3589],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:36:24 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:36:24 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 17:36:48 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 17:37:11 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 17:37:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.9793e-03,  2.4509e-03, -6.0940e-04,  ..., -1.1921e-06,
         -2.1820e-03, -1.0672e-03],
        [ 6.2656e-04, -4.4060e-03, -7.8773e-04,  ...,  1.1177e-03,
         -1.1396e-03,  7.8106e-04],
        [-3.7003e-03, -1.1444e-03, -5.2528e-03,  ..., -5.1308e-04,
         -1.4801e-03,  6.0654e-04],
        ...,
        [-2.6083e-04,  9.6655e-04,  6.1131e-04,  ..., -3.4485e-03,
         -8.6308e-04,  6.1560e-04],
        [-6.9499e-05, -1.2712e-03, -1.5411e-03,  ..., -1.2074e-03,
         -3.9177e-03,  3.8147e-06],
        [-1.4582e-03,  7.5579e-04,  4.7851e-04,  ...,  4.5538e-04,
          7.5960e-04, -3.4962e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0301,  0.0020, -0.0021,  ...,  0.0064,  0.0035,  0.0017],
        [-0.0134, -0.0336,  0.0043,  ..., -0.0005,  0.0024, -0.0017],
        [-0.0015, -0.0021, -0.0285,  ..., -0.0024,  0.0077,  0.0125],
        ...,
        [ 0.0057,  0.0101, -0.0010,  ..., -0.0322,  0.0047,  0.0023],
        [ 0.0004,  0.0048,  0.0094,  ..., -0.0009, -0.0318,  0.0033],
        [-0.0011,  0.0003,  0.0030,  ..., -0.0038,  0.0003, -0.0349]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0446,  0.0045,  0.0034,  ..., -0.0051,  0.0022, -0.0050],
        [-0.0004, -0.0456,  0.0009,  ...,  0.0005,  0.0024, -0.0003],
        [-0.0056,  0.0016, -0.0392,  ..., -0.0048, -0.0041, -0.0038],
        ...,
        [ 0.0006,  0.0020, -0.0033,  ..., -0.0474,  0.0013,  0.0005],
        [-0.0025,  0.0010,  0.0001,  ...,  0.0012, -0.0429,  0.0017],
        [-0.0009, -0.0028, -0.0051,  ...,  0.0028,  0.0006, -0.0436]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:37:37 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-29 17:37:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0558, -0.1135,  0.6045,  ..., -0.4087, -0.9272,  0.5283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0463,  0.1602,  0.1151,  ...,  0.0442, -0.3916, -0.0579],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1387,  0.0441,  1.1846,  ..., -0.1082, -0.7368, -0.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0236,  0.1646, -0.0676,  ..., -0.0746, -0.5815,  0.4480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:37:37 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:37:37 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 17:38:01 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 17:38:25 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 17:38:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0148, -0.0021, -0.0005,  ...,  0.0051, -0.0012,  0.0008],
        [ 0.0038, -0.0072,  0.0008,  ...,  0.0046,  0.0022,  0.0003],
        [ 0.0002,  0.0016, -0.0070,  ..., -0.0003, -0.0011, -0.0012],
        ...,
        [-0.0011, -0.0023,  0.0008,  ..., -0.0073, -0.0010, -0.0008],
        [ 0.0019,  0.0049,  0.0019,  ..., -0.0021, -0.0079,  0.0008],
        [-0.0005, -0.0049,  0.0007,  ..., -0.0026,  0.0019, -0.0083]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0459,  0.0004,  0.0044,  ..., -0.0029, -0.0021,  0.0031],
        [ 0.0111, -0.0538,  0.0016,  ...,  0.0064, -0.0059,  0.0032],
        [-0.0152, -0.0027, -0.0420,  ..., -0.0014,  0.0032, -0.0084],
        ...,
        [ 0.0070,  0.0060, -0.0013,  ..., -0.0425, -0.0098,  0.0041],
        [ 0.0042, -0.0158,  0.0025,  ..., -0.0034, -0.0406,  0.0015],
        [ 0.0023,  0.0017, -0.0091,  ...,  0.0044, -0.0031, -0.0514]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.9641e-02,  6.5727e-03, -3.6621e-04,  ..., -7.5188e-03,
          4.3106e-04, -8.2397e-03],
        [ 5.8174e-05, -7.9163e-02, -5.9891e-03,  ..., -2.5082e-03,
         -6.8321e-03,  7.7820e-04],
        [-1.0567e-03,  1.0738e-03, -6.5674e-02,  ..., -7.3013e-03,
          3.7308e-03,  1.0939e-03],
        ...,
        [ 8.9931e-04,  3.0842e-03, -3.5286e-05,  ..., -7.0862e-02,
         -3.3073e-03,  7.6818e-04],
        [-7.8049e-03, -8.3694e-03,  3.9139e-03,  ...,  2.7542e-03,
         -6.8604e-02,  2.3327e-03],
        [-3.5343e-03, -9.2888e-04,  5.7182e-03,  ..., -1.6661e-03,
          1.2445e-03, -7.1411e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:38:52 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-29 17:38:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0340,  0.1694,  0.9043,  ..., -0.1791, -0.7319,  0.6372],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0594,  0.6982, -0.4978,  ...,  0.1852, -0.8433,  0.5454],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0044, -0.0376,  1.0654,  ...,  0.8447, -0.5684,  0.6587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2505, -0.0369, -0.1012,  ..., -0.0767, -0.9834,  0.8213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:38:52 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:38:52 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 17:39:17 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 17:39:42 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 17:40:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0087,  0.0004, -0.0016,  ..., -0.0008, -0.0023, -0.0003],
        [-0.0002, -0.0076, -0.0014,  ...,  0.0004,  0.0012,  0.0003],
        [ 0.0026, -0.0002, -0.0071,  ..., -0.0012,  0.0011,  0.0002],
        ...,
        [ 0.0012,  0.0005, -0.0016,  ..., -0.0090,  0.0006,  0.0005],
        [-0.0003, -0.0009,  0.0003,  ...,  0.0002, -0.0057,  0.0013],
        [ 0.0014, -0.0002,  0.0020,  ...,  0.0019, -0.0005, -0.0074]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0319, -0.0006, -0.0014,  ...,  0.0059,  0.0009,  0.0010],
        [-0.0083, -0.0421,  0.0031,  ..., -0.0063, -0.0047, -0.0008],
        [ 0.0081,  0.0016, -0.0331,  ...,  0.0047,  0.0001,  0.0047],
        ...,
        [-0.0049, -0.0010, -0.0008,  ..., -0.0363,  0.0011, -0.0059],
        [-0.0054, -0.0038,  0.0005,  ..., -0.0061, -0.0441, -0.0006],
        [-0.0021,  0.0012, -0.0031,  ...,  0.0010,  0.0079, -0.0311]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.8147e-02,  8.7023e-04, -4.7836e-03,  ...,  1.0338e-02,
          8.6164e-04, -1.9073e-06],
        [-8.5449e-03, -3.7659e-02,  1.3718e-02,  ...,  7.3929e-03,
         -6.0654e-03, -2.7542e-03],
        [ 1.0490e-02,  3.4885e-03, -3.0701e-02,  ..., -6.2103e-03,
          3.2196e-03,  4.2496e-03],
        ...,
        [ 3.1357e-03,  9.0714e-03, -6.3171e-03,  ..., -4.2450e-02,
         -1.8625e-03,  3.9864e-03],
        [-7.2136e-03,  6.4888e-03,  6.2561e-04,  ...,  6.5756e-04,
         -3.5583e-02,  1.3866e-03],
        [-1.8873e-03,  3.5057e-03,  1.1539e-03,  ..., -2.2602e-03,
          1.0086e-02, -3.6041e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:40:09 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-29 17:40:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1885,  0.0252,  1.3369,  ..., -0.1178, -0.8525, -0.1415],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0556,  0.2289, -0.0927,  ..., -0.0988, -0.8608,  0.6533],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1621, -0.2129,  0.9780,  ...,  1.3672, -0.7588,  0.7539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2554,  0.2878, -0.3052,  ..., -0.6621, -0.4878,  0.8550],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:40:09 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:40:09 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 17:40:39 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 17:41:09 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 17:41:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0064, -0.0011, -0.0004,  ...,  0.0003,  0.0031, -0.0036],
        [-0.0004, -0.0075, -0.0006,  ..., -0.0020, -0.0008, -0.0017],
        [-0.0030,  0.0003, -0.0033,  ..., -0.0007,  0.0008,  0.0005],
        ...,
        [-0.0006, -0.0008, -0.0015,  ..., -0.0038,  0.0004,  0.0024],
        [-0.0007, -0.0022, -0.0004,  ..., -0.0030, -0.0052,  0.0013],
        [ 0.0003, -0.0038,  0.0005,  ..., -0.0014, -0.0025, -0.0054]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0555,  0.0001, -0.0091,  ..., -0.0117,  0.0016,  0.0079],
        [ 0.0007, -0.0470, -0.0050,  ..., -0.0021, -0.0038,  0.0003],
        [ 0.0026, -0.0166, -0.0320,  ...,  0.0156,  0.0056, -0.0024],
        ...,
        [ 0.0001,  0.0056,  0.0025,  ..., -0.0427,  0.0011,  0.0016],
        [-0.0079, -0.0016,  0.0005,  ...,  0.0076, -0.0349,  0.0050],
        [-0.0024, -0.0081, -0.0004,  ...,  0.0064, -0.0093, -0.0455]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0540,  0.0025,  0.0043,  ..., -0.0039, -0.0013,  0.0009],
        [ 0.0068, -0.0530, -0.0051,  ...,  0.0009,  0.0057, -0.0048],
        [ 0.0022, -0.0067, -0.0622,  ..., -0.0001, -0.0031,  0.0034],
        ...,
        [ 0.0060, -0.0031,  0.0040,  ..., -0.0585, -0.0084, -0.0024],
        [ 0.0040,  0.0041, -0.0027,  ..., -0.0055, -0.0597, -0.0037],
        [-0.0012,  0.0038, -0.0036,  ...,  0.0026, -0.0025, -0.0609]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:41:41 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-29 17:41:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0109, -0.0872,  0.9971,  ...,  0.7607, -0.5249,  0.6201],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2764, -0.0851, -0.0970,  ..., -0.0831, -1.0254,  0.8740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0297, -0.0825,  1.2988,  ...,  0.7437, -1.0205,  1.0254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5317,  0.2715, -0.1320,  ..., -0.6533, -0.6968,  0.8555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:41:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:41:41 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 17:42:12 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 17:42:45 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 17:43:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.4343e-04,  3.1624e-03, -2.2755e-03,  ...,  4.2953e-03,
          1.0376e-03,  2.9826e-04],
        [ 1.2980e-03,  4.2992e-03,  7.3862e-04,  ...,  2.0618e-03,
         -2.2278e-03,  2.3537e-03],
        [ 4.2534e-04,  2.7866e-03,  1.9717e-04,  ...,  2.5501e-03,
         -7.8630e-04,  7.5340e-04],
        ...,
        [ 8.3745e-05,  1.0014e-03, -2.2259e-03,  ..., -3.8695e-04,
         -9.7847e-04,  5.4407e-04],
        [ 8.3351e-04, -1.9038e-04,  6.0654e-04,  ...,  3.2139e-04,
          3.7823e-03, -1.5125e-03],
        [ 1.1234e-03, -2.0046e-03, -1.0166e-03,  ..., -8.7166e-04,
         -2.3327e-03,  3.3855e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1089, -0.0053,  0.0015,  ...,  0.0086,  0.0018,  0.0012],
        [ 0.0023, -0.1024, -0.0118,  ...,  0.0013, -0.0040, -0.0005],
        [-0.0099, -0.0051, -0.0861,  ..., -0.0048,  0.0064, -0.0004],
        ...,
        [ 0.0037, -0.0008, -0.0108,  ..., -0.0924, -0.0103,  0.0047],
        [-0.0018, -0.0049, -0.0066,  ...,  0.0005, -0.1049,  0.0083],
        [-0.0108, -0.0095,  0.0023,  ...,  0.0037, -0.0015, -0.1085]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2109e-01, -3.8185e-03,  7.8201e-03,  ..., -9.2773e-03,
         -2.5063e-03,  1.5059e-03],
        [-2.0771e-03, -1.1340e-01,  4.1199e-03,  ..., -5.7945e-03,
         -5.4359e-05,  2.2926e-03],
        [ 3.1967e-03,  2.3022e-03, -1.0266e-01,  ..., -2.0618e-03,
          8.7357e-03,  1.5712e-04],
        ...,
        [-1.6308e-03, -2.6474e-03, -1.5888e-03,  ..., -9.3811e-02,
          9.2926e-03, -4.6768e-03],
        [-1.8024e-03,  1.5965e-03, -3.4447e-03,  ..., -4.4098e-03,
         -1.1676e-01,  1.0666e-02],
        [-8.3160e-03,  3.4504e-03,  3.6831e-03,  ..., -2.7180e-04,
         -6.1493e-03, -1.1371e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:43:20 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-29 17:43:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1432, -0.2163,  0.8374,  ...,  1.1953, -0.6997,  0.6758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2751,  0.3044, -0.3208,  ..., -0.6753, -0.5322,  0.9194],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7358,  0.1699,  0.8398,  ...,  0.9521, -1.6777,  0.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5942,  0.5054, -0.4429,  ..., -0.2617, -0.9307,  0.3972],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:43:20 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:43:20 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 17:43:56 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 17:44:26 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 17:44:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0020, -0.0021,  0.0049,  ...,  0.0026, -0.0007,  0.0021],
        [ 0.0006, -0.0086,  0.0037,  ..., -0.0016, -0.0024,  0.0040],
        [ 0.0017,  0.0027, -0.0050,  ..., -0.0003, -0.0007, -0.0031],
        ...,
        [ 0.0014, -0.0042, -0.0014,  ..., -0.0033, -0.0032,  0.0017],
        [ 0.0022,  0.0017, -0.0016,  ..., -0.0091, -0.0053, -0.0033],
        [ 0.0020, -0.0011, -0.0034,  ..., -0.0046, -0.0010, -0.0030]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.3853e-02, -1.1490e-02,  2.2602e-03,  ...,  5.9166e-03,
         -1.0872e-03,  7.6027e-03],
        [ 1.0162e-02, -9.0210e-02,  1.0941e-02,  ..., -2.2182e-03,
         -2.5826e-03,  1.0765e-02],
        [ 6.2943e-03,  4.5319e-03, -8.7830e-02,  ..., -1.1528e-02,
          1.3771e-03,  7.8964e-03],
        ...,
        [ 1.8860e-02,  7.9956e-03, -5.3787e-03,  ..., -7.8430e-02,
          3.5801e-03, -9.5367e-04],
        [ 3.7193e-05,  4.4861e-03, -1.0529e-03,  ...,  2.2717e-03,
         -6.9580e-02,  4.0588e-03],
        [ 2.3079e-03,  1.1604e-02,  3.3493e-03,  ..., -1.5388e-02,
          3.2043e-03, -8.3801e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1124,  0.0035, -0.0102,  ...,  0.0056,  0.0034, -0.0049],
        [-0.0007, -0.1129, -0.0084,  ...,  0.0051, -0.0073,  0.0082],
        [-0.0095,  0.0048, -0.1162,  ..., -0.0037,  0.0037,  0.0013],
        ...,
        [ 0.0092,  0.0066,  0.0032,  ..., -0.1142, -0.0045,  0.0029],
        [ 0.0015, -0.0054, -0.0034,  ...,  0.0046, -0.1088,  0.0002],
        [-0.0088,  0.0093, -0.0030,  ..., -0.0116,  0.0075, -0.1167]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:44:57 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-29 17:44:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0323, -0.0660,  1.0498,  ...,  0.5825, -0.8896,  0.8818],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5347,  0.2935, -0.1406,  ..., -0.6387, -0.6924,  0.8462],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4517, -0.5117,  0.5688,  ...,  0.7627, -2.5781,  0.7168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4609,  0.0352, -0.9385,  ..., -0.4626, -1.0254,  0.4414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:44:57 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:44:57 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 17:45:35 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 17:46:12 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 17:46:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.7403e-03,  2.4166e-03, -9.3937e-05,  ...,  2.5482e-03,
         -2.7447e-03,  1.6155e-03],
        [ 1.0376e-03,  4.2038e-03, -2.3174e-03,  ...,  5.9547e-03,
          1.5249e-03, -1.6308e-03],
        [ 5.1003e-03, -2.1439e-03, -1.7967e-03,  ..., -3.6812e-03,
         -3.0937e-03,  1.9102e-03],
        ...,
        [ 5.0640e-04,  7.8344e-04,  3.3131e-03,  ..., -9.8419e-04,
         -2.7046e-03,  5.5122e-03],
        [-3.5114e-03, -6.7472e-04, -3.8490e-03,  ...,  1.8063e-03,
          2.5253e-03, -9.7942e-04],
        [-2.4834e-03, -3.5133e-03,  3.6373e-03,  ..., -1.7185e-03,
          5.5656e-03, -1.0920e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.3547e-02,  1.1490e-02, -9.0408e-03,  ..., -5.0011e-03,
         -4.8828e-03, -9.9182e-05],
        [ 3.4142e-03, -7.6843e-02,  1.9894e-03,  ..., -1.5732e-02,
         -4.8981e-03,  1.1871e-02],
        [-8.5526e-03, -1.0742e-02, -6.1462e-02,  ...,  1.0777e-03,
         -8.2474e-03, -7.8506e-03],
        ...,
        [-6.1722e-03,  2.6703e-03, -2.1019e-03,  ..., -6.7566e-02,
          4.4227e-04,  9.6664e-03],
        [ 1.2711e-02,  3.2196e-03, -4.0436e-03,  ..., -1.3290e-02,
         -7.7087e-02, -5.1498e-03],
        [-4.3030e-03, -5.0583e-03,  1.6556e-02,  ...,  5.3978e-03,
         -3.9444e-03, -7.2021e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0681e-01, -5.0392e-03,  5.8975e-03,  ..., -6.1798e-03,
          1.1253e-04,  7.2594e-03],
        [-9.2125e-04, -1.0431e-01, -5.6534e-03,  ...,  2.2335e-03,
         -4.0855e-03,  2.1133e-03],
        [ 1.5137e-02, -1.6975e-04, -9.1553e-02,  ...,  3.7003e-04,
          7.0572e-03, -4.1809e-03],
        ...,
        [-1.7914e-02, -1.0614e-03, -1.0689e-02,  ..., -1.1401e-01,
          8.0185e-03,  8.7452e-04],
        [ 1.1253e-02,  8.3847e-03,  7.3719e-04,  ...,  1.2512e-02,
         -1.0559e-01,  9.0408e-04],
        [ 9.9258e-03, -7.1793e-03,  8.3160e-03,  ...,  5.7487e-03,
          2.6188e-03, -1.1792e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:46:54 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-29 17:46:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5806,  0.1257,  0.6099,  ...,  0.6885, -1.2861,  0.3271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5474,  0.4758, -0.3979,  ..., -0.2260, -0.8408,  0.3552],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0627,  0.0327,  0.5713,  ...,  0.9688, -2.7734,  0.6055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3237, -0.2014, -0.8892,  ..., -0.5674, -0.6973,  0.5435],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:46:54 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:46:54 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 17:47:34 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 17:48:17 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 17:48:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.6643e-03, -3.4924e-03, -3.2978e-03,  ...,  3.0499e-03,
         -2.8849e-04, -3.2883e-03],
        [-4.8981e-03, -7.0915e-03,  2.8725e-03,  ..., -3.8300e-03,
          2.5177e-04, -4.9591e-03],
        [ 3.6278e-03,  1.9779e-03, -3.9177e-03,  ...,  2.8992e-03,
          1.0252e-03,  3.2787e-03],
        ...,
        [-2.1591e-03, -1.1997e-03, -8.9169e-04,  ..., -4.7455e-03,
         -5.4855e-03, -2.8973e-03],
        [ 3.3712e-04,  2.5787e-03, -8.3542e-04,  ..., -5.5504e-03,
         -9.8267e-03,  2.4738e-03],
        [ 9.0942e-03,  4.9057e-03, -5.0783e-04,  ..., -7.6294e-05,
          3.9978e-03, -2.9831e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.8511e-02, -1.7731e-02,  1.4687e-04,  ..., -7.9498e-03,
         -1.3626e-02,  8.2474e-03],
        [-1.0498e-02, -1.0089e-01, -1.8272e-03,  ..., -5.7755e-03,
          8.7738e-03, -1.0063e-02],
        [-5.7259e-03,  3.4313e-03, -7.5317e-02,  ...,  8.3466e-03,
         -9.6817e-03,  1.4935e-03],
        ...,
        [ 5.4474e-03, -5.7755e-03, -6.2866e-03,  ..., -9.1553e-02,
         -1.3533e-03, -8.2397e-03],
        [ 1.7338e-03,  4.2915e-06, -1.2924e-02,  ...,  1.0773e-02,
         -8.3191e-02,  8.9417e-03],
        [ 5.2071e-03,  9.4757e-03, -1.7212e-02,  ..., -1.5259e-02,
         -1.1696e-02, -9.6191e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1969e-01,  6.6643e-03,  5.8746e-04,  ..., -1.2878e-02,
         -7.0572e-04, -7.7057e-04],
        [ 8.4460e-05, -1.1383e-01,  8.3771e-03,  ..., -8.8043e-03,
         -4.2191e-03,  7.7209e-03],
        [ 1.4648e-03,  5.3520e-03, -1.1011e-01,  ..., -8.6288e-03,
         -7.0419e-03,  8.2779e-03],
        ...,
        [-8.9798e-03,  2.8419e-03, -1.0391e-02,  ..., -1.0504e-01,
          4.4632e-03, -1.0178e-02],
        [-3.2215e-03,  3.5248e-03, -1.1566e-02,  ..., -3.0937e-03,
         -1.0657e-01,  9.6273e-04],
        [-1.8082e-03, -7.8278e-03, -1.3229e-02,  ..., -5.3558e-03,
         -4.0588e-03, -1.1090e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:49:00 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-29 17:49:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2754, -0.3455,  0.3022,  ...,  0.4443, -1.6475,  0.4585],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4153,  0.0288, -0.8203,  ..., -0.3906, -0.8691,  0.3713],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4382,  0.4448,  0.5400,  ...,  0.9028, -3.0508,  0.5371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0437, -0.4011, -0.6465,  ..., -0.5298, -0.9033, -0.0767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:49:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:49:00 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 17:49:46 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 17:50:22 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 17:51:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0021,  0.0061,  0.0032,  ..., -0.0030, -0.0024,  0.0010],
        [ 0.0036, -0.0093, -0.0039,  ..., -0.0048, -0.0060, -0.0020],
        [-0.0093,  0.0029,  0.0022,  ..., -0.0038,  0.0018,  0.0024],
        ...,
        [-0.0013, -0.0038,  0.0009,  ...,  0.0094, -0.0082,  0.0034],
        [-0.0053,  0.0023,  0.0091,  ..., -0.0017, -0.0048, -0.0025],
        [ 0.0019, -0.0027,  0.0050,  ..., -0.0050,  0.0055, -0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0986, -0.0038,  0.0013,  ..., -0.0065,  0.0081, -0.0037],
        [ 0.0064, -0.1075,  0.0012,  ...,  0.0058, -0.0160,  0.0027],
        [-0.0078,  0.0069, -0.1035,  ...,  0.0100, -0.0035, -0.0028],
        ...,
        [ 0.0011,  0.0020,  0.0226,  ..., -0.1050, -0.0052,  0.0072],
        [-0.0060,  0.0028,  0.0016,  ..., -0.0073, -0.1091,  0.0014],
        [ 0.0088,  0.0081, -0.0028,  ...,  0.0082,  0.0090, -0.0927]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1843, -0.0050,  0.0056,  ...,  0.0058,  0.0010, -0.0006],
        [-0.0085, -0.1986, -0.0087,  ...,  0.0094,  0.0055,  0.0120],
        [-0.0094, -0.0011, -0.1655,  ..., -0.0041, -0.0039, -0.0025],
        ...,
        [ 0.0060,  0.0085, -0.0022,  ..., -0.1848, -0.0014,  0.0072],
        [ 0.0092,  0.0035,  0.0074,  ..., -0.0039, -0.1860, -0.0083],
        [-0.0104,  0.0025, -0.0008,  ..., -0.0067, -0.0137, -0.1667]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:51:06 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-29 17:51:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0408,  0.0021,  0.2856,  ...,  0.5532, -1.6279,  0.3228],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2532, -0.1772, -0.7124,  ..., -0.4155, -0.5566,  0.3987],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2761,  0.0234,  0.6611,  ...,  0.7617, -3.1465,  0.7637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5566, -0.7988, -0.1516,  ..., -0.3633, -0.8496,  1.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:51:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:51:06 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 17:51:51 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 17:52:31 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 17:53:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.2139e-03, -6.5947e-04,  1.4057e-03,  ...,  2.6531e-03,
          6.6757e-05,  5.4016e-03],
        [-4.0207e-03, -1.4277e-03,  3.8986e-03,  ...,  5.8136e-03,
         -5.2929e-04,  1.4753e-03],
        [ 2.0943e-03,  2.3308e-03, -6.0883e-03,  ...,  3.2425e-03,
         -3.6144e-03,  2.9335e-03],
        ...,
        [ 1.1940e-03, -2.0180e-03,  4.8752e-03,  ..., -5.6572e-03,
         -2.2030e-03,  2.7199e-03],
        [ 2.2840e-04, -6.4011e-03,  2.0351e-03,  ...,  5.6343e-03,
         -8.7585e-03,  1.5926e-03],
        [-1.4424e-04,  3.7498e-03, -4.3030e-03,  ...,  1.6260e-03,
          2.6264e-03, -2.5520e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1267,  0.0019,  0.0047,  ...,  0.0031,  0.0075, -0.0048],
        [ 0.0015, -0.1149,  0.0046,  ...,  0.0039, -0.0047,  0.0097],
        [ 0.0032, -0.0137, -0.1296,  ...,  0.0008,  0.0086, -0.0082],
        ...,
        [-0.0027,  0.0116,  0.0041,  ..., -0.1125,  0.0021, -0.0153],
        [ 0.0071,  0.0003, -0.0010,  ...,  0.0127, -0.1207,  0.0234],
        [ 0.0032,  0.0193,  0.0024,  ..., -0.0015,  0.0108, -0.1183]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1263, -0.0006, -0.0054,  ..., -0.0031,  0.0049, -0.0150],
        [ 0.0084, -0.1150,  0.0066,  ...,  0.0049, -0.0106, -0.0073],
        [ 0.0061, -0.0077, -0.1163,  ...,  0.0031, -0.0121,  0.0012],
        ...,
        [-0.0086, -0.0076,  0.0064,  ..., -0.1151,  0.0071, -0.0236],
        [ 0.0050, -0.0030, -0.0125,  ...,  0.0141, -0.1188,  0.0129],
        [ 0.0012,  0.0079, -0.0071,  ...,  0.0077,  0.0068, -0.1307]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:53:23 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-29 17:53:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2695,  0.2399,  0.2466,  ...,  0.4590, -1.7363,  0.3149],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0439, -0.3059, -0.4741,  ..., -0.3855, -0.6382, -0.0518],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5762, -0.0377, -0.4756,  ...,  1.3018, -3.2012,  1.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5322, -0.4734, -0.2837,  ..., -0.2598, -0.1914,  0.7383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:53:23 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:53:23 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 17:54:16 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 17:55:10 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 17:56:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0032,  0.0022,  0.0036,  ..., -0.0020, -0.0004,  0.0023],
        [ 0.0010,  0.0027,  0.0037,  ...,  0.0035,  0.0039,  0.0026],
        [-0.0035, -0.0062,  0.0072,  ..., -0.0063,  0.0023, -0.0006],
        ...,
        [ 0.0015,  0.0056,  0.0088,  ...,  0.0110, -0.0040,  0.0034],
        [-0.0046, -0.0027, -0.0009,  ..., -0.0042,  0.0108,  0.0035],
        [-0.0013,  0.0016, -0.0017,  ..., -0.0025, -0.0010,  0.0030]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1431, -0.0100,  0.0074,  ..., -0.0016, -0.0028, -0.0075],
        [-0.0029, -0.1420,  0.0023,  ..., -0.0005, -0.0080, -0.0078],
        [-0.0007, -0.0003, -0.1295,  ...,  0.0004, -0.0032, -0.0070],
        ...,
        [-0.0096, -0.0119,  0.0122,  ..., -0.1420,  0.0013,  0.0042],
        [ 0.0093,  0.0028, -0.0132,  ..., -0.0015, -0.1533,  0.0005],
        [ 0.0056, -0.0213, -0.0158,  ..., -0.0059,  0.0139, -0.1379]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.6880e-01,  9.7580e-03,  5.6648e-03,  ...,  8.1253e-04,
         -8.8196e-03, -5.1918e-03],
        [-1.7061e-03, -2.8662e-01, -3.9625e-04,  ..., -1.8311e-02,
          3.5919e-02, -5.5466e-03],
        [-6.5460e-03,  1.4961e-02, -2.5879e-01,  ...,  5.3453e-04,
          4.2229e-03, -4.5929e-03],
        ...,
        [-1.4305e-04, -8.3237e-03, -8.0185e-03,  ..., -2.5439e-01,
          2.5253e-02,  1.4847e-02],
        [-1.8829e-02,  1.6418e-02,  1.4668e-03,  ...,  1.6953e-02,
         -2.5977e-01,  1.1940e-02],
        [ 3.1071e-03, -5.7259e-03,  4.9591e-03,  ...,  3.0270e-03,
          6.8130e-03, -2.5952e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:56:04 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-29 17:56:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1914, -0.0032,  0.3130,  ...,  0.4270, -1.8174,  0.4004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4729, -0.6533, -0.1643,  ..., -0.2869, -0.6758,  0.8384],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7349,  0.0385, -0.0825,  ...,  1.8535, -3.9863,  1.9521],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1787, -0.5967, -0.8838,  ...,  0.4258, -0.2717,  1.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:56:04 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:56:04 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 17:56:57 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 17:57:53 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 17:58:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0112,  0.0054, -0.0025,  ...,  0.0033,  0.0014, -0.0047],
        [-0.0015, -0.0119, -0.0051,  ..., -0.0040, -0.0015,  0.0006],
        [ 0.0085,  0.0048, -0.0128,  ..., -0.0017, -0.0022,  0.0026],
        ...,
        [ 0.0007,  0.0028, -0.0061,  ..., -0.0123, -0.0004,  0.0035],
        [-0.0005, -0.0024,  0.0003,  ..., -0.0048, -0.0069, -0.0018],
        [ 0.0015, -0.0023, -0.0006,  ..., -0.0030, -0.0012, -0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1006,  0.0014,  0.0071,  ...,  0.0028, -0.0104, -0.0110],
        [ 0.0047, -0.0993,  0.0039,  ...,  0.0034, -0.0011,  0.0156],
        [-0.0008, -0.0112, -0.0925,  ..., -0.0044, -0.0083,  0.0061],
        ...,
        [-0.0145,  0.0093,  0.0029,  ..., -0.0876,  0.0050, -0.0032],
        [-0.0105, -0.0061, -0.0081,  ...,  0.0080, -0.0853, -0.0017],
        [ 0.0004, -0.0080,  0.0020,  ..., -0.0154,  0.0078, -0.0795]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0315e-01,  7.3719e-04, -2.3746e-04,  ..., -4.4174e-03,
         -1.1444e-05, -1.9875e-03],
        [ 6.3210e-03, -1.1462e-01,  7.1411e-03,  ..., -4.6539e-04,
          7.9193e-03,  9.8114e-03],
        [-3.4790e-03, -2.3529e-02, -1.1151e-01,  ..., -1.2684e-03,
         -1.9043e-02,  9.0485e-03],
        ...,
        [ 7.9651e-03,  1.3580e-02,  8.3542e-03,  ..., -9.8511e-02,
         -3.7117e-03, -1.2901e-02],
        [ 7.2327e-03, -2.3975e-03, -3.4828e-03,  ...,  1.4992e-03,
         -1.0760e-01,  8.7357e-03],
        [ 3.9062e-03, -5.9624e-03,  2.1000e-03,  ..., -1.0178e-02,
          8.9417e-03, -1.0803e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 17:58:50 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-29 17:58:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3340, -0.0599, -0.2649,  ...,  0.6738, -1.7666,  0.7095],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4202, -0.4014, -0.2178,  ..., -0.2109, -0.1421,  0.5498],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7168, -0.1134, -0.1567,  ...,  1.8926, -3.6113,  2.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1943, -0.6865, -0.9150,  ..., -0.2759, -0.6377,  1.3770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 17:58:50 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 17:58:50 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 17:59:45 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 18:00:40 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 18:01:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.6785e-02, -4.5547e-03, -5.6610e-03,  ...,  1.0635e-02,
         -3.5591e-03,  3.3932e-03],
        [-5.0583e-03,  2.0645e-02, -6.6757e-04,  ...,  1.0862e-03,
         -1.7710e-03, -6.2447e-03],
        [-2.4834e-03, -2.0294e-03,  1.3367e-02,  ..., -1.1768e-03,
          2.0552e-04, -4.2610e-03],
        ...,
        [ 1.7071e-03, -3.6573e-04,  4.7798e-03,  ...,  2.0004e-02,
         -1.5747e-02,  3.0174e-03],
        [-1.7262e-03,  2.3460e-03,  5.0468e-03,  ...,  5.5313e-05,
          2.8763e-02,  1.1044e-03],
        [ 3.6392e-03, -2.9907e-03, -8.3313e-03,  ..., -8.8120e-03,
         -6.2943e-03,  1.5976e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0991, -0.0045, -0.0046,  ...,  0.0010,  0.0091,  0.0056],
        [ 0.0098, -0.1136,  0.0110,  ...,  0.0041, -0.0024,  0.0073],
        [ 0.0070, -0.0007, -0.1066,  ...,  0.0040,  0.0016, -0.0114],
        ...,
        [-0.0038,  0.0097,  0.0024,  ..., -0.1097, -0.0095,  0.0078],
        [ 0.0190,  0.0130, -0.0027,  ..., -0.0017, -0.0995, -0.0094],
        [ 0.0062, -0.0054, -0.0099,  ..., -0.0032, -0.0053, -0.1085]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3245e-01, -5.2376e-03,  2.5253e-03,  ..., -7.3662e-03,
          1.5221e-02, -5.0964e-03],
        [-2.1606e-02, -1.5076e-01, -1.2054e-02,  ..., -9.8228e-05,
         -8.9035e-03,  6.9847e-03],
        [ 6.8207e-03,  3.4142e-03, -1.4453e-01,  ..., -2.1400e-03,
          1.3428e-02, -4.0283e-03],
        ...,
        [-3.3932e-03,  3.7956e-03, -1.0033e-02,  ..., -1.2183e-01,
          8.5602e-03,  6.5689e-03],
        [ 1.5497e-03,  9.1782e-03, -5.1270e-03,  ...,  1.7914e-02,
         -1.3696e-01,  3.6888e-03],
        [-1.1311e-03,  9.3384e-03,  1.1215e-02,  ..., -2.1553e-03,
         -1.2684e-03, -1.3477e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:01:40 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-29 18:01:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-4.1187e-01, -1.1063e-03, -6.8420e-02,  ...,  9.1162e-01,
        -2.0332e+00,  9.6289e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1414, -0.3928, -0.5513,  ...,  0.2454, -0.1436,  0.9111],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0576, -0.5156, -0.2695,  ...,  1.1797, -3.7930,  2.4277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1307, -0.4080, -1.4658,  ..., -0.2725, -0.9536,  0.9888],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:01:40 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:01:40 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 18:02:38 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 18:03:37 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 18:04:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.3204e-03, -5.2338e-03,  2.6608e-03,  ..., -3.5019e-03,
         -1.2314e-02, -1.3371e-03],
        [ 5.2834e-03,  1.3779e-02, -2.5024e-03,  ..., -2.3136e-03,
          5.2299e-03,  2.8372e-05],
        [-7.5722e-03, -6.4964e-03,  1.1795e-02,  ...,  1.2512e-03,
         -1.0862e-03,  2.2202e-03],
        ...,
        [ 8.0566e-03,  1.4877e-03,  1.7576e-03,  ...,  9.9182e-03,
         -4.8351e-04,  7.0810e-05],
        [-3.0537e-03, -4.9591e-03, -1.0881e-03,  ...,  3.6869e-03,
          1.3168e-02,  8.0719e-03],
        [-7.3719e-04,  5.4207e-03, -4.6587e-04,  ..., -5.5923e-03,
          2.1324e-03,  1.3863e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0931,  0.0195,  0.0049,  ...,  0.0100, -0.0089,  0.0031],
        [ 0.0016, -0.0906, -0.0090,  ..., -0.0061, -0.0011, -0.0095],
        [ 0.0019, -0.0087, -0.0917,  ...,  0.0026,  0.0128, -0.0073],
        ...,
        [ 0.0059, -0.0001, -0.0047,  ..., -0.0923,  0.0094, -0.0058],
        [ 0.0076,  0.0063,  0.0061,  ..., -0.0018, -0.0873,  0.0054],
        [-0.0037,  0.0017, -0.0030,  ...,  0.0074, -0.0081, -0.0913]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1279,  0.0051, -0.0049,  ..., -0.0017, -0.0052,  0.0049],
        [ 0.0159, -0.1128, -0.0022,  ...,  0.0140,  0.0017,  0.0081],
        [ 0.0027, -0.0206, -0.1133,  ...,  0.0010,  0.0115, -0.0048],
        ...,
        [-0.0148, -0.0023, -0.0134,  ..., -0.1248,  0.0082, -0.0149],
        [-0.0092,  0.0064,  0.0186,  ...,  0.0094, -0.1284, -0.0023],
        [-0.0029, -0.0014, -0.0188,  ..., -0.0025, -0.0102, -0.1102]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:04:38 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-29 18:04:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3691, -0.0909, -0.0744,  ...,  0.8906, -1.7471,  1.2217],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1268, -0.4497, -0.5244,  ..., -0.1750, -0.3750,  0.8071],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5742,  0.1099, -0.3936,  ...,  1.8418, -3.7812,  2.9883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2988, -0.8945, -2.7461,  ...,  0.9209, -1.4004,  1.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:04:38 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:04:38 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 18:05:41 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 18:06:43 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 18:07:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0052,  0.0003,  0.0015,  ...,  0.0039, -0.0058, -0.0003],
        [ 0.0058,  0.0030, -0.0003,  ...,  0.0015,  0.0004, -0.0029],
        [ 0.0016, -0.0022, -0.0006,  ..., -0.0062,  0.0005,  0.0037],
        ...,
        [-0.0039,  0.0010,  0.0055,  ...,  0.0071, -0.0098, -0.0041],
        [ 0.0012, -0.0038,  0.0021,  ..., -0.0057,  0.0055, -0.0013],
        [ 0.0019, -0.0023,  0.0040,  ...,  0.0009,  0.0003,  0.0078]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.8135e-02, -7.8583e-04, -4.7798e-03,  ..., -1.1444e-05,
         -1.4162e-03,  1.1444e-04],
        [ 3.5591e-03, -7.5745e-02, -4.0221e-04,  ...,  3.2864e-03,
         -3.5381e-04, -6.2447e-03],
        [-5.7831e-03, -1.1162e-02, -9.2834e-02,  ..., -7.9575e-03,
         -1.1429e-02,  1.0773e-02],
        ...,
        [ 1.3351e-05,  1.3313e-02,  5.7068e-03,  ..., -7.6172e-02,
         -9.5901e-03, -1.2756e-02],
        [-1.0574e-02, -3.7136e-03, -8.0261e-03,  ..., -5.5428e-03,
         -8.8867e-02,  1.2962e-02],
        [ 6.5422e-03, -4.8218e-03, -1.4320e-02,  ..., -6.7406e-03,
          1.2909e-02, -8.8135e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2732e-01,  3.0460e-03, -1.0330e-02,  ...,  1.1467e-02,
         -8.3618e-03,  1.4549e-02],
        [-3.7193e-03, -1.3892e-01, -1.3702e-02,  ..., -1.1612e-02,
         -1.3618e-02,  4.1466e-03],
        [ 4.3869e-05,  4.1938e-04, -1.2939e-01,  ...,  8.3771e-03,
         -1.2085e-02,  1.7593e-02],
        ...,
        [ 1.2741e-02,  3.5801e-03,  8.0109e-03,  ..., -1.2988e-01,
         -1.2573e-02, -1.8906e-02],
        [-7.3891e-03, -2.4277e-02, -2.2369e-02,  ...,  3.8948e-03,
         -1.3208e-01, -6.8283e-04],
        [ 6.8169e-03, -2.9221e-03, -7.6485e-04,  ...,  7.2632e-03,
          1.8311e-02, -1.3293e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:07:45 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-29 18:07:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0164, -0.2549, -0.1451,  ...,  0.5601, -1.8320,  1.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1166, -0.2294, -0.7979,  ..., -0.1525, -0.5273,  0.5342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.9966,  0.4678, -0.3088,  ...,  2.0273, -4.5039,  3.1230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0535, -0.9922, -3.0469,  ...,  0.5981, -1.6201,  1.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:07:45 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:07:45 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 18:08:46 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 18:09:47 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 18:10:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.7656e-03,  4.7684e-07, -4.1237e-03,  ...,  8.1253e-03,
          2.9030e-03, -2.5520e-03],
        [-1.3943e-03,  8.1711e-03,  9.9659e-04,  ...,  1.0128e-03,
          1.4944e-03, -5.2738e-04],
        [-5.6038e-03,  6.8207e-03,  4.9515e-03,  ...,  6.3477e-03,
          5.9605e-04,  1.3952e-03],
        ...,
        [ 3.8700e-03,  1.3399e-03, -7.0810e-05,  ...,  8.5602e-03,
         -1.1604e-02, -7.5483e-04],
        [-4.7188e-03, -4.2439e-05, -2.1954e-03,  ...,  2.7523e-03,
          6.4774e-03, -7.3242e-04],
        [ 3.3226e-03, -1.0872e-03, -7.0047e-04,  ..., -2.5482e-03,
          9.0408e-03,  4.3678e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0573,  0.0190,  0.0011,  ...,  0.0121,  0.0003, -0.0042],
        [-0.0050, -0.0541, -0.0024,  ...,  0.0098, -0.0042,  0.0012],
        [-0.0068, -0.0019, -0.0781,  ..., -0.0034,  0.0169, -0.0059],
        ...,
        [-0.0117,  0.0041,  0.0050,  ..., -0.0697, -0.0159, -0.0036],
        [-0.0074,  0.0194,  0.0031,  ...,  0.0134, -0.0774, -0.0015],
        [ 0.0032, -0.0051,  0.0097,  ..., -0.0033,  0.0085, -0.0680]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1035,  0.0140, -0.0019,  ..., -0.0024, -0.0042,  0.0030],
        [ 0.0045, -0.1125, -0.0053,  ...,  0.0061, -0.0063,  0.0028],
        [-0.0025,  0.0295, -0.1168,  ...,  0.0009,  0.0019, -0.0113],
        ...,
        [-0.0302, -0.0099, -0.0136,  ..., -0.1169, -0.0027, -0.0039],
        [ 0.0109,  0.0212, -0.0033,  ...,  0.0108, -0.1070, -0.0014],
        [-0.0037, -0.0010,  0.0094,  ..., -0.0135, -0.0144, -0.1193]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:10:48 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-29 18:10:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2773,  0.0420, -0.1702,  ...,  0.7891, -1.6758,  1.2949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1438, -0.4719, -1.3584,  ...,  0.4551, -0.7085,  0.6104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7202,  0.3022, -0.0710,  ...,  2.1738, -5.1914,  3.3613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7734, -1.3496, -3.7559,  ...,  1.6523, -2.6113,  1.8711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:10:48 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:10:48 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 18:11:51 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 18:12:52 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 18:13:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0092, -0.0066, -0.0029,  ...,  0.0058, -0.0037,  0.0019],
        [-0.0058, -0.0026,  0.0036,  ...,  0.0007,  0.0018,  0.0046],
        [ 0.0012, -0.0037, -0.0025,  ..., -0.0032,  0.0083,  0.0037],
        ...,
        [ 0.0014, -0.0104,  0.0067,  ..., -0.0104,  0.0104, -0.0029],
        [ 0.0020,  0.0020,  0.0014,  ..., -0.0038, -0.0131,  0.0022],
        [ 0.0061, -0.0016,  0.0010,  ..., -0.0025,  0.0014, -0.0107]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0554, -0.0077,  0.0140,  ...,  0.0068,  0.0039, -0.0080],
        [-0.0043, -0.0812,  0.0110,  ...,  0.0095,  0.0207, -0.0009],
        [ 0.0063, -0.0101, -0.0572,  ..., -0.0134, -0.0028, -0.0076],
        ...,
        [ 0.0285, -0.0156, -0.0019,  ..., -0.0767,  0.0116, -0.0058],
        [-0.0036, -0.0084,  0.0012,  ...,  0.0012, -0.0753, -0.0160],
        [ 0.0083, -0.0024,  0.0144,  ..., -0.0117,  0.0086, -0.0574]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1028,  0.0084,  0.0012,  ..., -0.0014,  0.0073,  0.0082],
        [ 0.0026, -0.1115,  0.0047,  ..., -0.0092,  0.0007, -0.0046],
        [ 0.0294, -0.0063, -0.1095,  ...,  0.0003,  0.0155, -0.0107],
        ...,
        [ 0.0156, -0.0061,  0.0068,  ..., -0.0917,  0.0040,  0.0084],
        [ 0.0006,  0.0177,  0.0134,  ..., -0.0155, -0.1182, -0.0064],
        [ 0.0027, -0.0018, -0.0005,  ...,  0.0173, -0.0013, -0.0933]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:13:56 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-29 18:13:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4485,  0.2000, -0.1421,  ...,  0.8447, -1.9326,  1.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0439, -0.4722, -1.4443,  ...,  0.2842, -0.7896,  0.7642],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7266,  0.8906, -0.4739,  ...,  1.7871, -4.5391,  3.8652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2510, -0.5366, -4.7930,  ...,  1.5723, -1.7090,  2.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:13:57 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:13:57 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 18:15:03 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 18:16:09 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 18:17:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0160, -0.0101,  0.0010,  ..., -0.0022,  0.0006, -0.0077],
        [-0.0043,  0.0061,  0.0021,  ...,  0.0017,  0.0044,  0.0041],
        [-0.0008, -0.0080,  0.0107,  ..., -0.0030,  0.0045, -0.0050],
        ...,
        [ 0.0013, -0.0009,  0.0002,  ...,  0.0140, -0.0018, -0.0049],
        [ 0.0035, -0.0034,  0.0040,  ..., -0.0099,  0.0099,  0.0024],
        [-0.0024,  0.0019, -0.0045,  ...,  0.0037,  0.0040,  0.0098]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0737,  0.0056, -0.0016,  ..., -0.0168,  0.0047, -0.0073],
        [ 0.0128, -0.0728,  0.0094,  ..., -0.0030,  0.0024,  0.0025],
        [-0.0105, -0.0065, -0.0610,  ...,  0.0097,  0.0142, -0.0040],
        ...,
        [-0.0069, -0.0161, -0.0031,  ..., -0.0584, -0.0026, -0.0045],
        [-0.0103, -0.0010,  0.0018,  ...,  0.0113, -0.0718, -0.0015],
        [-0.0312, -0.0003, -0.0175,  ..., -0.0039, -0.0121, -0.0690]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.4097e-02,  2.6550e-02, -5.3024e-03,  ..., -1.1147e-02,
         -6.9046e-03, -5.3864e-03],
        [ 1.9547e-02, -8.1604e-02,  1.9012e-02,  ...,  2.9087e-05,
         -1.4099e-02,  5.5923e-03],
        [-5.4169e-03,  2.6894e-03, -7.5806e-02,  ..., -4.8180e-03,
          1.1719e-02, -1.2520e-02],
        ...,
        [-1.7181e-02, -7.6294e-04, -1.3557e-02,  ..., -4.2480e-02,
          1.3992e-02,  1.0345e-02],
        [ 1.1108e-02, -1.6678e-02,  4.5242e-03,  ...,  1.4305e-02,
         -6.3965e-02, -1.7471e-03],
        [-2.0325e-02,  1.2878e-02, -1.1703e-02,  ..., -1.5823e-02,
         -4.0359e-03, -6.3293e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:17:18 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-29 18:17:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3140,  0.1172, -0.0520,  ...,  0.8857, -2.1406,  1.3770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3657, -0.6372, -1.7197,  ...,  0.7593, -1.2002,  0.8472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1318,  1.3926, -1.1045,  ...,  2.0391, -3.9336,  3.4434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8306,  0.2788, -5.2891,  ...,  1.0859, -1.1152,  2.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:17:18 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:17:19 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 18:18:26 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 18:19:35 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 18:20:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3046e-03,  1.0672e-03,  1.6842e-03,  ..., -5.7364e-04,
         -3.8242e-03, -1.6375e-03],
        [ 2.5654e-03,  3.2578e-03, -3.0270e-03,  ..., -6.4015e-05,
         -8.5115e-04,  4.4775e-04],
        [-1.6804e-03,  5.8222e-04,  2.1744e-03,  ..., -1.7166e-03,
         -1.0195e-03,  4.9877e-04],
        ...,
        [ 6.4802e-04, -9.4891e-04, -4.3869e-03,  ...,  6.7806e-04,
         -1.3866e-03, -1.3695e-03],
        [ 1.9894e-03, -9.7609e-04, -4.2439e-05,  ...,  1.5926e-03,
          3.5801e-03,  1.2512e-03],
        [ 1.4610e-03, -3.1643e-03,  3.0136e-03,  ..., -8.0347e-04,
          7.0143e-04,  1.2617e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0379, -0.0001, -0.0020,  ..., -0.0187,  0.0128, -0.0122],
        [ 0.0077, -0.0385,  0.0115,  ...,  0.0087, -0.0096,  0.0091],
        [-0.0120,  0.0105, -0.0495,  ...,  0.0130, -0.0023, -0.0002],
        ...,
        [ 0.0034, -0.0136,  0.0066,  ..., -0.0336,  0.0041, -0.0260],
        [ 0.0120, -0.0094, -0.0044,  ..., -0.0103, -0.0442, -0.0064],
        [-0.0092,  0.0037,  0.0158,  ..., -0.0036,  0.0134, -0.0509]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0745, -0.0049, -0.0015,  ..., -0.0228,  0.0095,  0.0038],
        [ 0.0102, -0.0797, -0.0134,  ...,  0.0121, -0.0006, -0.0030],
        [-0.0163,  0.0024, -0.0831,  ...,  0.0008,  0.0086,  0.0019],
        ...,
        [-0.0051, -0.0215, -0.0090,  ..., -0.0715, -0.0014, -0.0042],
        [ 0.0228, -0.0178, -0.0075,  ...,  0.0075, -0.0828,  0.0050],
        [-0.0047,  0.0140, -0.0009,  ...,  0.0044,  0.0029, -0.0806]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:20:47 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-29 18:20:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2932,  0.3379, -0.1990,  ...,  0.6919, -1.7598,  1.5020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1079, -0.2397, -1.9600,  ...,  0.6582, -0.7158,  1.0684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0513,  0.5254, -1.5879,  ...,  1.6895, -4.4844,  3.8906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1270, -0.3154, -5.8281,  ...,  1.9688, -2.0586,  2.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:20:47 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:20:47 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 18:21:57 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 18:23:08 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 18:24:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.0688e-04, -4.1809e-03, -3.6850e-03,  ...,  4.8027e-03,
         -5.5046e-03,  2.1229e-03],
        [-5.9853e-03,  6.5374e-04, -5.5046e-03,  ..., -7.7553e-03,
         -6.2141e-03,  8.6899e-03],
        [ 3.1490e-03, -4.5128e-03, -1.3981e-03,  ..., -4.5280e-03,
          2.1992e-03,  4.1819e-04],
        ...,
        [-2.4700e-03, -4.5204e-03, -5.0020e-04,  ...,  9.6035e-04,
          2.2182e-03,  2.5702e-04],
        [-4.8523e-03, -1.0433e-03, -3.7975e-03,  ...,  2.8667e-03,
          1.5678e-03,  8.8310e-04],
        [-4.5891e-03, -8.6927e-04,  1.4973e-03,  ...,  2.5177e-04,
          4.0412e-05,  1.6127e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0394, -0.0058, -0.0033,  ..., -0.0056, -0.0039, -0.0060],
        [-0.0024, -0.0569, -0.0132,  ..., -0.0082,  0.0191, -0.0004],
        [-0.0224, -0.0109, -0.0432,  ..., -0.0032, -0.0030, -0.0149],
        ...,
        [ 0.0108, -0.0119, -0.0036,  ..., -0.0405,  0.0076,  0.0042],
        [-0.0053,  0.0097,  0.0087,  ..., -0.0022, -0.0378,  0.0025],
        [-0.0132, -0.0044, -0.0005,  ...,  0.0045,  0.0097, -0.0368]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0443, -0.0028,  0.0014,  ..., -0.0023, -0.0002, -0.0004],
        [-0.0118, -0.0617,  0.0014,  ..., -0.0046,  0.0181, -0.0020],
        [ 0.0058, -0.0104, -0.0540,  ...,  0.0098,  0.0047, -0.0260],
        ...,
        [-0.0122, -0.0027, -0.0001,  ..., -0.0460,  0.0009, -0.0006],
        [-0.0039,  0.0098,  0.0048,  ..., -0.0073, -0.0559,  0.0012],
        [-0.0110, -0.0091,  0.0084,  ..., -0.0079,  0.0119, -0.0454]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:24:22 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-29 18:24:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0459,  0.4985, -0.4099,  ...,  0.7266, -1.4209,  1.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3303,  0.1005, -2.0859,  ...,  0.4160, -0.4321,  0.8042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5000,  1.1094, -1.4404,  ...,  1.2490, -4.2695,  3.6660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.5469, -0.5059, -5.8789,  ...,  1.9473, -1.4648,  2.5879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:24:22 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:24:22 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 18:25:42 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 18:27:02 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 18:28:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.5106e-02, -7.5455e-03,  3.2673e-03,  ..., -2.4204e-03,
          3.0193e-03,  4.0092e-03],
        [-3.4370e-03,  3.8967e-03, -1.4486e-03,  ...,  1.1078e-02,
          4.2191e-03,  5.9175e-04],
        [ 1.3800e-03, -5.7602e-03,  1.4412e-02,  ...,  1.3943e-03,
          4.3983e-03, -1.6460e-03],
        ...,
        [ 3.9673e-03,  7.6752e-03, -2.6398e-03,  ...,  2.0645e-02,
          2.0409e-03,  6.7329e-03],
        [-5.6505e-05, -5.6267e-03,  4.9553e-03,  ...,  1.4687e-03,
          1.2177e-02, -3.8266e-04],
        [-3.1204e-03,  3.2234e-03,  1.3609e-03,  ..., -1.5039e-03,
          8.2550e-03,  1.9897e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0522,  0.0014, -0.0122,  ...,  0.0157, -0.0039,  0.0130],
        [ 0.0077, -0.0517, -0.0188,  ..., -0.0027, -0.0137,  0.0003],
        [-0.0075, -0.0014, -0.0384,  ...,  0.0190, -0.0164, -0.0020],
        ...,
        [-0.0001, -0.0059, -0.0214,  ..., -0.0315,  0.0014,  0.0086],
        [-0.0026, -0.0235,  0.0161,  ...,  0.0116, -0.0411, -0.0023],
        [ 0.0097,  0.0061, -0.0151,  ..., -0.0097, -0.0011, -0.0432]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0595, -0.0134,  0.0128,  ...,  0.0061, -0.0078, -0.0114],
        [ 0.0033, -0.0718, -0.0246,  ..., -0.0014, -0.0003,  0.0187],
        [ 0.0074,  0.0036, -0.0519,  ..., -0.0027,  0.0019,  0.0064],
        ...,
        [ 0.0053,  0.0078, -0.0338,  ..., -0.0486, -0.0129,  0.0169],
        [ 0.0123, -0.0230, -0.0068,  ..., -0.0083, -0.0643, -0.0121],
        [ 0.0026,  0.0093, -0.0188,  ..., -0.0068, -0.0016, -0.0365]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:28:26 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-29 18:28:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0170,  0.1821, -0.5762,  ...,  0.6040, -1.6260,  1.4150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4319, -0.1189, -2.1582,  ...,  0.7314, -0.7695,  1.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5112,  1.1201, -0.6460,  ...,  1.1660, -3.1445,  3.7930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.5156, -1.3564, -3.9219,  ...,  0.6748, -1.7637,  3.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:28:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:28:27 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 18:29:49 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 18:31:11 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 18:32:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.0804e-03, -1.5926e-04,  1.6260e-04,  ...,  8.8549e-04,
         -3.4380e-04, -1.3471e-04],
        [ 3.8528e-04, -2.3136e-03, -1.8263e-04,  ...,  5.5599e-04,
         -7.4863e-04,  1.8191e-04],
        [ 3.1233e-05,  6.5708e-04, -4.0398e-03,  ..., -1.1349e-03,
          2.8419e-04, -8.6546e-04],
        ...,
        [-4.7374e-04,  1.1379e-04,  2.4772e-04,  ..., -3.0060e-03,
          1.0557e-03,  4.2844e-04],
        [ 1.2817e-03,  7.9107e-04,  3.4094e-04,  ..., -7.8106e-04,
         -3.6640e-03, -1.6241e-03],
        [ 1.6499e-04,  4.8113e-04,  9.2268e-04,  ..., -1.6427e-04,
         -5.1928e-04, -3.1128e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0441,  0.0165, -0.0115,  ...,  0.0028, -0.0042,  0.0260],
        [ 0.0026, -0.0477,  0.0075,  ..., -0.0039,  0.0032, -0.0059],
        [ 0.0060, -0.0017, -0.0282,  ..., -0.0039,  0.0062,  0.0074],
        ...,
        [-0.0107,  0.0140, -0.0070,  ..., -0.0416,  0.0036,  0.0051],
        [-0.0071,  0.0067, -0.0105,  ...,  0.0020, -0.0300,  0.0127],
        [ 0.0043, -0.0071, -0.0053,  ...,  0.0120,  0.0111, -0.0343]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0715,  0.0014,  0.0060,  ...,  0.0188, -0.0285,  0.0094],
        [-0.0068, -0.0569, -0.0084,  ..., -0.0030,  0.0041, -0.0110],
        [ 0.0094,  0.0047, -0.0536,  ..., -0.0193,  0.0211, -0.0013],
        ...,
        [-0.0044,  0.0025,  0.0002,  ..., -0.0556,  0.0013,  0.0129],
        [ 0.0132,  0.0151, -0.0083,  ..., -0.0144, -0.0460,  0.0056],
        [ 0.0124, -0.0131, -0.0178,  ...,  0.0141,  0.0096, -0.0593]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:32:34 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-29 18:32:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1857,  0.3757, -0.5127,  ...,  0.4292, -1.4668,  1.2598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9448, -0.1783, -2.0898,  ...,  0.6924, -0.5098,  0.9150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0569,  1.6113, -1.0439,  ...,  1.1934, -3.3965,  4.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.0703, -1.9268, -3.5684,  ...,  0.9580, -1.4365,  4.1914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:32:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:32:34 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 18:33:57 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 18:35:21 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 18:36:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0824e-03, -6.8903e-04,  9.8228e-04,  ...,  8.1968e-04,
         -8.6260e-04, -1.2999e-03],
        [ 2.1756e-04,  5.1832e-04,  2.6627e-03,  ...,  2.8648e-03,
          1.9779e-03,  1.8382e-04],
        [-2.2545e-03,  1.7500e-03, -2.9182e-03,  ..., -1.0657e-04,
         -7.6056e-04,  2.5406e-03],
        ...,
        [ 3.0994e-03, -2.1887e-04,  8.7595e-04,  ..., -1.2016e-03,
          4.5836e-05, -7.7152e-04],
        [ 2.8229e-04, -5.0688e-04, -2.0294e-03,  ..., -1.4172e-03,
          6.1750e-04, -8.4925e-04],
        [-2.0466e-03, -1.2579e-03,  2.4700e-03,  ..., -4.0960e-04,
         -1.5697e-03, -3.6469e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0134,  0.0018, -0.0283,  ..., -0.0166, -0.0039,  0.0029],
        [ 0.0283, -0.0227,  0.0093,  ...,  0.0068, -0.0125, -0.0245],
        [-0.0161, -0.0123, -0.0118,  ...,  0.0094,  0.0049,  0.0034],
        ...,
        [-0.0128, -0.0050, -0.0006,  ..., -0.0206,  0.0223, -0.0057],
        [-0.0209,  0.0190,  0.0104,  ..., -0.0065, -0.0006,  0.0103],
        [ 0.0079,  0.0075,  0.0096,  ..., -0.0098,  0.0052, -0.0324]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0699, -0.0017, -0.0101,  ...,  0.0017, -0.0202,  0.0152],
        [ 0.0148, -0.0835,  0.0300,  ..., -0.0012, -0.0015, -0.0168],
        [-0.0089,  0.0023, -0.0995,  ..., -0.0256, -0.0216,  0.0222],
        ...,
        [-0.0021,  0.0018, -0.0076,  ..., -0.0733, -0.0061, -0.0091],
        [-0.0080, -0.0158,  0.0187,  ..., -0.0089, -0.0633,  0.0019],
        [-0.0091,  0.0175, -0.0076,  ..., -0.0076, -0.0114, -0.1135]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:36:46 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-29 18:36:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1793,  0.3904, -0.2661,  ...,  0.3774, -1.0664,  1.2812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9004, -0.4343, -1.4150,  ...,  0.2228, -0.6152,  1.1299],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7930,  1.6338, -0.9180,  ...,  1.0859, -3.3242,  5.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4277, -2.5547, -3.6523,  ...,  0.1113, -1.4902,  5.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:36:47 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:36:47 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 18:38:10 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 18:39:36 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 18:41:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0147, -0.0022, -0.0001,  ...,  0.0065,  0.0026,  0.0024],
        [-0.0006,  0.0117, -0.0004,  ..., -0.0035, -0.0031, -0.0039],
        [-0.0007,  0.0020,  0.0107,  ..., -0.0016,  0.0024, -0.0003],
        ...,
        [ 0.0012, -0.0040,  0.0019,  ...,  0.0177, -0.0003, -0.0012],
        [ 0.0047, -0.0007,  0.0017,  ...,  0.0088,  0.0123, -0.0061],
        [ 0.0034, -0.0047, -0.0037,  ...,  0.0012,  0.0004,  0.0188]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 4.7058e-02, -3.7918e-03,  1.8677e-02,  ...,  5.9700e-03,
         -1.0780e-02,  1.4145e-02],
        [ 5.3406e-05,  1.7776e-03,  1.3039e-02,  ...,  3.4485e-03,
          7.6904e-03,  3.7956e-03],
        [-9.1324e-03,  2.2926e-03,  3.9062e-02,  ...,  1.0185e-02,
         -1.0651e-02, -1.7151e-02],
        ...,
        [-6.1111e-03,  2.4605e-04, -7.8735e-03,  ...,  2.9175e-02,
         -3.5133e-03,  2.8687e-03],
        [ 3.7479e-03, -2.4841e-02, -4.7188e-03,  ...,  2.5253e-02,
          1.9958e-02, -2.6016e-02],
        [ 1.5686e-02,  3.8071e-03, -1.9974e-02,  ..., -9.7809e-03,
          5.1270e-03,  5.6915e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0110, -0.0214,  0.0273,  ..., -0.0109, -0.0009,  0.0054],
        [ 0.0004, -0.0246, -0.0092,  ..., -0.0045,  0.0038,  0.0123],
        [ 0.0181,  0.0059,  0.0121,  ...,  0.0215,  0.0079, -0.0179],
        ...,
        [-0.0026,  0.0080, -0.0030,  ...,  0.0024,  0.0092,  0.0075],
        [ 0.0006, -0.0206, -0.0069,  ...,  0.0137,  0.0032,  0.0034],
        [-0.0056,  0.0172,  0.0081,  ..., -0.0195,  0.0091,  0.0093]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:41:03 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-29 18:41:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0414,  0.5225, -0.3979,  ...,  0.3442, -1.1025,  1.5908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7358, -0.6089, -1.2812,  ...,  0.2854, -0.4932,  1.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5146,  3.3379, -0.6973,  ...,  0.6357, -3.0215,  6.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9336, -2.0469, -3.1152,  ..., -0.2832, -1.7822,  6.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:41:03 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:41:04 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 18:42:26 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 18:43:47 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 18:45:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.9932e-03, -1.5581e-04,  7.6628e-04,  ..., -3.2544e-04,
          9.4938e-04,  2.5558e-04],
        [ 9.8288e-05,  3.1257e-04,  2.2078e-04,  ..., -2.0361e-04,
         -1.5903e-04,  1.7548e-04],
        [-1.2436e-03, -2.6345e-04,  1.6489e-03,  ..., -4.5204e-04,
          4.8089e-04, -8.6880e-04],
        ...,
        [-7.9775e-04,  6.4707e-04, -1.3037e-03,  ...,  1.2856e-03,
          3.0899e-04,  2.8670e-05],
        [ 1.7633e-03,  8.7357e-04, -2.7156e-04,  ..., -3.0732e-04,
          1.0033e-03, -1.1053e-03],
        [ 1.4114e-03, -2.4629e-04,  3.1757e-04,  ...,  4.9973e-04,
          5.1498e-04,  1.1654e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 5.7144e-03,  1.4618e-02, -2.2926e-03,  ..., -5.5428e-03,
          2.9354e-03,  1.3885e-02],
        [-8.4152e-03, -3.0746e-02,  8.6288e-03,  ...,  5.1651e-03,
          3.7746e-03, -1.1826e-02],
        [-4.0770e-05, -8.9874e-03, -5.4207e-03,  ...,  1.2573e-02,
          1.5549e-02,  1.4038e-02],
        ...,
        [-1.9855e-03,  1.0384e-02, -1.2207e-02,  ..., -2.1622e-02,
          7.9422e-03,  1.1024e-02],
        [ 3.1815e-03, -2.0737e-02, -1.4587e-02,  ...,  3.8490e-03,
         -4.4594e-03,  1.9012e-02],
        [-8.7509e-03,  2.8286e-03,  3.8204e-03,  ...,  5.4207e-03,
         -1.7258e-02, -2.3193e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0048,  0.0276, -0.0023,  ..., -0.0045,  0.0144,  0.0108],
        [-0.0054, -0.0209,  0.0157,  ..., -0.0145,  0.0279, -0.0098],
        [ 0.0031,  0.0049, -0.0200,  ...,  0.0227, -0.0059, -0.0046],
        ...,
        [-0.0099, -0.0010, -0.0017,  ..., -0.0426,  0.0014,  0.0154],
        [-0.0129,  0.0158, -0.0343,  ..., -0.0126, -0.0197,  0.0119],
        [-0.0206, -0.0297,  0.0037,  ..., -0.0027,  0.0012, -0.0146]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:45:15 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-29 18:45:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2908,  0.4998, -0.3604,  ...,  0.2208, -1.0146,  1.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5132, -0.7593, -1.2354,  ..., -0.0638, -0.4976,  1.6348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6582,  2.9922, -1.7803,  ..., -0.1938, -3.4414,  4.9883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8027, -1.5723, -5.1172,  ..., -0.5225, -1.5371,  6.0273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:45:16 root INFO     [order_1_approx] starting weight calculation for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:45:16 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 18:46:43 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 18:48:11 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 18:49:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.1640e-03, -1.1415e-03,  3.7503e-04,  ...,  5.4359e-05,
         -7.3147e-04, -9.7847e-04],
        [ 1.3590e-03,  4.0436e-03,  1.4567e-04,  ..., -1.6046e-04,
          2.4643e-03,  1.5545e-03],
        [ 1.9932e-03, -1.6212e-03,  8.0490e-03,  ...,  2.2292e-05,
         -1.8539e-03,  4.8780e-04],
        ...,
        [-5.0783e-04, -9.0003e-05,  1.2789e-03,  ...,  1.1772e-02,
          1.1063e-04, -1.2407e-03],
        [-2.8658e-04, -1.2197e-03, -6.2466e-04,  ..., -9.5367e-04,
          8.1482e-03,  3.1376e-04],
        [ 3.5882e-04,  1.2436e-03, -4.6253e-04,  ...,  1.6665e-04,
          4.9877e-04,  1.1406e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0144, -0.0057, -0.0006,  ...,  0.0091,  0.0054, -0.0015],
        [ 0.0044, -0.0165, -0.0110,  ..., -0.0077,  0.0044,  0.0109],
        [-0.0051,  0.0114, -0.0102,  ..., -0.0239, -0.0117,  0.0117],
        ...,
        [-0.0068,  0.0080, -0.0066,  ...,  0.0020, -0.0169,  0.0011],
        [-0.0085, -0.0063, -0.0053,  ...,  0.0052, -0.0017, -0.0068],
        [-0.0103,  0.0338, -0.0035,  ..., -0.0119,  0.0037, -0.0046]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0437, -0.0070,  0.0140,  ..., -0.0111, -0.0027, -0.0048],
        [ 0.0128, -0.0760, -0.0128,  ..., -0.0076,  0.0076,  0.0112],
        [ 0.0017,  0.0048, -0.0432,  ..., -0.0012, -0.0095,  0.0101],
        ...,
        [-0.0049,  0.0054, -0.0287,  ..., -0.0582,  0.0111,  0.0015],
        [ 0.0143, -0.0167, -0.0205,  ..., -0.0054, -0.0594, -0.0041],
        [-0.0261,  0.0335,  0.0016,  ..., -0.0069, -0.0039, -0.0105]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:49:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a collar is choker
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a brush is
2024-06-29 18:49:40 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 18:49:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2761, -0.1462,  0.9053,  ...,  0.0919,  0.1980,  0.0617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0441,  0.1425,  0.2280,  ...,  0.2251, -0.2776, -0.2390],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1351, -0.0251,  0.6562,  ..., -0.0220, -0.1299,  0.2400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1473,  0.4490,  0.0164,  ...,  0.1283, -0.3279, -0.0482],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:49:40 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 18:49:40 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 18:50:01 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 18:50:24 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 18:50:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.2937e-03,  1.6165e-04, -1.5402e-03,  ..., -1.6127e-03,
          2.3117e-03, -3.2463e-03],
        [-9.1791e-06, -8.8959e-03,  2.3544e-05,  ...,  2.6512e-03,
          5.0068e-05,  6.9618e-04],
        [-2.8839e-03,  2.8419e-03, -1.0963e-02,  ..., -1.9848e-04,
         -2.4490e-03,  6.9332e-04],
        ...,
        [ 1.4877e-04,  1.8454e-03,  1.0252e-03,  ..., -9.2468e-03,
         -1.4343e-03, -8.0013e-04],
        [ 9.0790e-04, -6.8569e-04, -1.9431e-04,  ..., -2.9583e-03,
         -6.4507e-03,  2.0809e-03],
        [-1.2112e-03, -9.2983e-04,  1.5507e-03,  ...,  1.4009e-03,
         -2.5225e-04, -6.4621e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.1555e-02, -3.8662e-03,  1.0620e-02,  ...,  1.9855e-03,
          4.8752e-03, -3.4857e-04],
        [-6.7482e-03, -4.2633e-02,  8.0490e-04,  ...,  1.4133e-03,
          6.7825e-03,  3.2539e-03],
        [ 2.0084e-03, -1.4935e-03, -4.1382e-02,  ..., -6.1035e-03,
          6.4545e-03,  9.8267e-03],
        ...,
        [ 7.4673e-04,  7.2937e-03,  2.6512e-04,  ..., -3.5156e-02,
         -2.0905e-03, -2.3689e-03],
        [ 4.8103e-03, -2.4853e-03,  2.6207e-03,  ..., -5.5504e-04,
         -3.1708e-02,  4.5395e-03],
        [ 4.2648e-03,  1.4381e-03,  9.6798e-05,  ..., -1.7824e-03,
         -7.2765e-04, -2.9617e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0435,  0.0043,  0.0028,  ..., -0.0043,  0.0030, -0.0045],
        [-0.0001, -0.0446,  0.0006,  ..., -0.0006,  0.0015, -0.0008],
        [-0.0079,  0.0012, -0.0377,  ..., -0.0049, -0.0027, -0.0032],
        ...,
        [ 0.0011,  0.0016, -0.0041,  ..., -0.0466,  0.0005, -0.0011],
        [-0.0015,  0.0014, -0.0004,  ...,  0.0012, -0.0426,  0.0020],
        [-0.0015, -0.0035, -0.0052,  ...,  0.0020,  0.0009, -0.0417]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:50:50 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-29 18:50:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0202, -0.1940,  0.6772,  ..., -0.1581, -0.0708, -0.0275],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2139,  0.1372,  0.2278,  ..., -0.0112, -0.3557, -0.2175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1282, -0.0674,  0.8779,  ...,  0.1387, -0.4438,  0.0836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2683,  0.2310,  0.2407,  ..., -0.0688, -0.3538,  0.0074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:50:50 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 18:50:50 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 18:51:14 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 18:51:38 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 18:52:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3443e-02, -2.1629e-03, -1.5593e-03,  ...,  3.7098e-03,
         -1.4324e-03,  8.6832e-04],
        [ 4.2114e-03, -1.0437e-02,  1.1778e-03,  ...,  6.0883e-03,
         -1.9157e-04, -4.6968e-04],
        [ 7.5579e-04,  1.4668e-03, -6.3515e-03,  ...,  6.4278e-04,
         -1.3304e-03,  1.1711e-03],
        ...,
        [ 6.9332e-04, -5.2547e-04,  5.4169e-04,  ..., -6.2904e-03,
          1.4305e-06, -1.2388e-03],
        [-3.8204e-03,  5.7507e-04,  2.8286e-03,  ..., -1.9531e-03,
         -8.9111e-03,  1.3418e-03],
        [ 3.8872e-03, -1.1864e-03, -2.3079e-04,  ..., -1.7300e-03,
          2.3842e-04, -9.1858e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.9622e-02,  7.0648e-03,  6.0005e-03,  ...,  5.1842e-03,
         -1.2579e-03,  1.0361e-02],
        [ 7.3891e-03, -5.5511e-02,  6.1226e-04,  ...,  3.8757e-03,
         -3.8795e-03,  5.2757e-03],
        [-4.3488e-03, -1.9646e-04, -4.4250e-02,  ..., -6.7558e-03,
          2.2125e-03,  4.9629e-03],
        ...,
        [ 8.0795e-03, -2.3670e-03,  1.9102e-03,  ..., -4.7821e-02,
         -9.0027e-03, -5.7144e-03],
        [ 1.2455e-03, -8.5831e-05,  6.5689e-03,  ...,  1.3590e-03,
         -3.9795e-02,  8.4381e-03],
        [-3.0556e-03,  1.3437e-03,  2.2659e-03,  ...,  4.9171e-03,
          4.1809e-03, -4.4556e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.2205e-02,  5.9967e-03, -3.1528e-03,  ..., -7.7858e-03,
          1.7586e-03, -9.3079e-03],
        [-8.3351e-04, -7.8491e-02, -3.4065e-03,  ..., -1.3523e-03,
         -3.0937e-03,  8.0919e-04],
        [ 1.2951e-03,  1.2379e-03, -6.7200e-02,  ..., -5.8517e-03,
          4.8180e-03, -1.2722e-03],
        ...,
        [-1.5678e-03,  3.7632e-03, -1.1234e-03,  ..., -7.2388e-02,
         -3.2883e-03,  2.3603e-05],
        [-7.7782e-03, -4.0817e-03,  2.8229e-04,  ..., -6.0463e-04,
         -7.1350e-02,  2.6264e-03],
        [-6.4316e-03,  1.9512e-03,  4.3297e-03,  ..., -1.2188e-03,
          1.5459e-03, -6.9275e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:52:04 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-29 18:52:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1945, -0.0546,  0.8325,  ..., -0.0260, -0.1659,  0.2942],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2384,  0.6704,  0.0239,  ...,  0.1877, -0.4805, -0.0955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3474, -0.1323,  0.8726,  ...,  0.6567, -0.4763,  0.2123],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3301,  0.3181,  0.1886,  ..., -0.0062, -0.7070,  0.5728],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:52:04 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 18:52:04 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 18:52:28 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 18:52:50 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 18:53:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.7509e-03,  3.2043e-04, -1.5240e-03,  ..., -1.2445e-03,
         -2.0962e-03, -1.0357e-03],
        [ 1.0395e-03, -8.0490e-03,  2.8038e-04,  ...,  1.2512e-03,
          1.7881e-03,  9.6798e-04],
        [ 2.9278e-03, -1.1644e-03, -5.3291e-03,  ..., -1.2980e-03,
          1.1978e-03,  2.0146e-04],
        ...,
        [ 6.5470e-04,  6.4659e-04, -7.5674e-04,  ..., -8.2474e-03,
          1.5640e-03,  3.0279e-04],
        [ 5.9903e-05,  1.0662e-03,  2.8157e-04,  ...,  4.7207e-04,
         -5.6229e-03,  3.6168e-04],
        [ 1.4353e-03,  4.7994e-04,  2.7218e-03,  ...,  1.5869e-03,
         -1.6279e-03, -6.6299e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0438,  0.0054, -0.0034,  ...,  0.0004, -0.0027,  0.0073],
        [-0.0127, -0.0402,  0.0043,  ...,  0.0052, -0.0065, -0.0035],
        [ 0.0058,  0.0046, -0.0363,  ...,  0.0098, -0.0018, -0.0005],
        ...,
        [ 0.0022,  0.0002, -0.0017,  ..., -0.0329,  0.0008,  0.0001],
        [-0.0025, -0.0037,  0.0001,  ...,  0.0002, -0.0421, -0.0034],
        [-0.0013, -0.0009, -0.0019,  ...,  0.0006, -0.0098, -0.0343]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0437,  0.0025,  0.0017,  ...,  0.0077, -0.0006,  0.0056],
        [-0.0038, -0.0363,  0.0114,  ...,  0.0061, -0.0057, -0.0035],
        [ 0.0064,  0.0010, -0.0316,  ..., -0.0025,  0.0018,  0.0019],
        ...,
        [-0.0005,  0.0058,  0.0001,  ..., -0.0424, -0.0034,  0.0008],
        [-0.0082,  0.0035,  0.0006,  ...,  0.0020, -0.0358, -0.0015],
        [-0.0030,  0.0023, -0.0023,  ..., -0.0009,  0.0072, -0.0349]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:53:18 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-29 18:53:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1846, -0.1091,  1.0654,  ...,  0.1686, -0.5562,  0.0699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4160,  0.3225,  0.3486,  ..., -0.0883, -0.5186, -0.0218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4780, -0.3428,  0.8647,  ...,  0.9238, -0.3931,  0.2281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3721,  0.5249,  0.1306,  ..., -0.4622, -0.1260,  0.5400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:53:18 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 18:53:18 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 18:53:48 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 18:54:18 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 18:54:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.6512e-03,  8.2350e-04,  3.1447e-04,  ...,  7.6151e-04,
          1.4353e-03,  7.1526e-06],
        [ 1.0881e-03, -4.5471e-03,  5.7268e-04,  ..., -1.1272e-03,
          1.3626e-04, -1.6618e-04],
        [-9.3508e-04, -1.9741e-04, -2.1019e-03,  ..., -4.3750e-04,
          7.8154e-04, -7.3814e-04],
        ...,
        [ 2.0084e-03, -2.5959e-03, -5.5790e-04,  ..., -2.9659e-03,
         -9.6703e-04,  2.0480e-04],
        [-8.5831e-06, -2.3289e-03,  1.8511e-03,  ..., -1.2922e-03,
         -4.6234e-03, -1.0099e-03],
        [ 0.0000e+00, -2.5368e-03, -5.5027e-04,  ..., -2.0838e-04,
         -2.0905e-03, -5.7220e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.6509e-02, -2.2850e-03, -8.9340e-03,  ...,  1.1168e-03,
          8.5144e-03, -5.9853e-03],
        [-2.1019e-03, -4.8676e-02,  1.8768e-03,  ..., -5.4932e-03,
         -2.3499e-03, -4.7035e-03],
        [-7.9441e-04, -8.7433e-03, -3.8269e-02,  ...,  4.5280e-03,
          9.2850e-03,  3.9902e-03],
        ...,
        [ 4.5776e-05,  9.3384e-03,  2.9449e-03,  ..., -4.4800e-02,
         -3.3073e-03, -4.4899e-03],
        [-3.7384e-03,  2.2316e-04,  6.6853e-04,  ..., -1.3800e-03,
         -4.9561e-02,  1.0208e-02],
        [-4.3082e-04, -1.9569e-03,  1.3390e-03,  ...,  5.3711e-03,
         -1.6823e-03, -5.2277e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.0049e-02,  1.3704e-03,  4.2725e-03,  ..., -2.3384e-03,
         -3.1614e-04,  2.8915e-03],
        [ 5.6686e-03, -5.3314e-02, -6.4240e-03,  ..., -2.5139e-03,
          6.4850e-03, -2.5730e-03],
        [ 8.7585e-03, -6.9199e-03, -6.0425e-02,  ..., -1.8959e-03,
         -2.4300e-03,  2.3174e-03],
        ...,
        [ 5.3978e-03,  3.6955e-05,  4.6616e-03,  ..., -5.3558e-02,
         -5.1956e-03, -2.7046e-03],
        [ 7.0953e-04,  2.7199e-03, -5.6877e-03,  ..., -1.0117e-02,
         -5.5878e-02, -2.9945e-03],
        [ 5.5170e-04,  4.5776e-03, -9.6607e-04,  ...,  2.2011e-03,
         -5.8060e-03, -5.5389e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:54:51 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-29 18:54:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3416, -0.1893,  0.8682,  ...,  0.6270, -0.4614,  0.1863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3591,  0.3086,  0.2006,  ..., -0.0120, -0.7231,  0.5952],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3118, -0.2050,  1.2441,  ...,  0.7729, -0.8931,  0.7109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4363,  0.0835,  0.1416,  ..., -0.6104, -0.2998,  0.7217],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:54:51 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 18:54:51 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 18:55:24 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 18:55:55 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 18:56:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.3212e-04,  1.0090e-03, -1.3752e-03,  ...,  3.3169e-03,
         -1.8525e-04,  8.6689e-04],
        [ 1.0281e-03,  3.0270e-03,  1.2875e-03,  ...,  2.2602e-03,
         -1.0023e-03,  1.9178e-03],
        [-5.6791e-04,  9.5129e-04, -3.7766e-04,  ...,  1.3542e-03,
         -3.4380e-04,  1.0080e-03],
        ...,
        [ 5.8556e-04,  1.7910e-03, -2.1725e-03,  ...,  5.9700e-04,
         -1.4865e-04,  1.0490e-04],
        [ 1.0461e-04,  1.9789e-05, -4.7731e-04,  ...,  1.1339e-03,
          4.5052e-03, -3.0589e-04],
        [ 4.3106e-04, -1.1911e-03, -2.9254e-04,  ..., -1.7614e-03,
         -2.0180e-03,  3.3169e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0763,  0.0034, -0.0099,  ..., -0.0082,  0.0028,  0.0068],
        [ 0.0001, -0.0858,  0.0052,  ...,  0.0055,  0.0022,  0.0083],
        [-0.0107,  0.0097, -0.0897,  ..., -0.0087,  0.0061,  0.0069],
        ...,
        [ 0.0064, -0.0010, -0.0038,  ..., -0.0760,  0.0039,  0.0002],
        [ 0.0099, -0.0033, -0.0068,  ...,  0.0029, -0.0871,  0.0075],
        [-0.0066, -0.0069, -0.0071,  ...,  0.0025, -0.0009, -0.0834]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1890e-01, -3.0098e-03,  3.4904e-03,  ..., -6.7902e-03,
          3.1519e-04,  4.3964e-04],
        [ 5.7364e-04, -1.1194e-01,  3.9673e-03,  ..., -3.6087e-03,
         -2.0199e-03,  4.0474e-03],
        [ 1.0719e-03,  3.4103e-03, -1.0468e-01,  ..., -3.8414e-03,
          5.6419e-03,  7.1526e-05],
        ...,
        [-3.1395e-03,  1.3390e-03, -4.6015e-04,  ..., -9.5154e-02,
          6.2408e-03, -2.8400e-03],
        [-2.6846e-04,  6.5136e-04, -5.1689e-03,  ..., -1.6766e-03,
         -1.1566e-01,  9.6588e-03],
        [-9.4833e-03,  2.4605e-03,  4.4479e-03,  ...,  1.2417e-03,
         -6.3553e-03, -1.1743e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:56:25 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-29 18:56:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4482, -0.3467,  0.7671,  ...,  0.8389, -0.3821,  0.1969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4055,  0.5723,  0.1281,  ..., -0.4744, -0.1499,  0.5801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8447,  0.2607,  0.9946,  ...,  0.6079, -1.3535,  0.6152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4048,  0.5029, -0.1777,  ..., -0.4695, -0.3938,  0.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:56:25 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 18:56:25 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 18:56:57 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 18:57:33 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 18:58:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.6528e-03, -3.5629e-03,  6.4926e-03,  ...,  5.9128e-04,
          2.8667e-03, -9.7179e-04],
        [ 3.0708e-03, -5.6572e-03,  3.2063e-03,  ...,  7.4911e-04,
         -1.7519e-03,  2.1839e-04],
        [-1.4696e-03,  2.9984e-03, -8.1406e-03,  ..., -5.0354e-04,
          2.1572e-03,  2.2197e-04],
        ...,
        [ 6.9380e-05, -2.7103e-03, -1.0757e-03,  ..., -5.0392e-03,
         -2.8648e-03,  1.2703e-03],
        [ 4.6806e-03, -5.2023e-04, -1.5631e-03,  ..., -5.1346e-03,
         -9.9716e-03, -2.6178e-04],
        [ 2.5215e-03, -3.4771e-03,  1.1797e-03,  ..., -3.6192e-04,
         -5.9204e-03, -3.7174e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0842,  0.0011,  0.0130,  ...,  0.0074,  0.0113,  0.0027],
        [ 0.0027, -0.0850,  0.0175,  ...,  0.0079, -0.0115,  0.0061],
        [ 0.0121,  0.0060, -0.0989,  ..., -0.0099, -0.0102,  0.0113],
        ...,
        [-0.0035,  0.0044,  0.0101,  ..., -0.0895,  0.0042,  0.0085],
        [ 0.0025,  0.0104,  0.0090,  ...,  0.0043, -0.0934,  0.0062],
        [ 0.0050,  0.0008,  0.0080,  ..., -0.0025,  0.0118, -0.0897]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1255e-01,  2.9907e-03, -1.5114e-02,  ..., -2.8908e-05,
          6.0539e-03, -1.5287e-03],
        [-3.8795e-03, -1.1395e-01, -6.1131e-04,  ...,  8.0261e-03,
         -2.1248e-03,  5.8060e-03],
        [-8.3771e-03,  1.6994e-03, -1.1469e-01,  ..., -8.8406e-04,
          2.6360e-03,  4.2419e-03],
        ...,
        [ 6.7177e-03,  1.1978e-03,  8.8959e-03,  ..., -1.1224e-01,
         -2.5520e-03,  3.8414e-03],
        [-1.5411e-03, -1.7099e-03, -6.1989e-04,  ...,  5.3139e-03,
         -1.1438e-01,  2.9850e-04],
        [-2.1801e-03,  7.7934e-03, -4.8409e-03,  ..., -1.1505e-02,
          9.6054e-03, -1.1353e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 18:58:11 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-29 18:58:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2820, -0.1830,  1.0557,  ...,  0.6387, -0.8145,  0.6323],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4370,  0.0991,  0.1169,  ..., -0.5957, -0.2986,  0.7051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6396, -0.0918,  0.9780,  ...,  0.8486, -1.4375,  0.8428],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1423,  0.0918, -0.5303,  ..., -0.7930, -0.4536,  0.3970],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 18:58:11 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 18:58:11 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 18:58:49 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 18:59:27 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 19:00:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.9049e-03,  4.1318e-04,  2.8172e-03,  ...,  1.4935e-03,
         -2.3155e-03,  7.2002e-05],
        [ 3.1357e-03,  2.5444e-03, -1.3008e-03,  ...,  5.7983e-03,
          3.4599e-03, -3.0632e-03],
        [ 2.1210e-03, -5.4970e-03, -1.8387e-03,  ..., -3.6736e-03,
         -5.0354e-03,  3.3264e-03],
        ...,
        [-5.5408e-04,  7.8344e-04,  2.8648e-03,  ..., -3.6411e-03,
         -2.5482e-03,  2.1286e-03],
        [-3.7498e-03,  2.2399e-04, -4.7722e-03,  ...,  1.5297e-03,
          4.5090e-03, -8.2636e-04],
        [ 9.6369e-04, -4.3716e-03,  2.2755e-03,  ..., -5.0545e-03,
          8.6288e-03,  6.0678e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0577e-01, -5.4312e-04, -1.4862e-02,  ...,  7.5226e-03,
          1.7872e-03,  5.6877e-03],
        [-1.8311e-02, -1.0254e-01, -7.4654e-03,  ..., -1.4297e-02,
         -3.5439e-03, -2.2221e-04],
        [ 5.8289e-03,  1.6241e-03, -7.4951e-02,  ...,  1.7614e-03,
         -3.5820e-03,  9.6283e-03],
        ...,
        [-1.6868e-05,  5.1575e-03,  6.4850e-05,  ..., -8.4412e-02,
          4.9362e-03,  2.5539e-03],
        [ 7.6866e-03, -1.1490e-02, -8.9188e-03,  ...,  7.9041e-03,
         -9.5764e-02, -1.0185e-03],
        [ 9.3384e-03, -2.4605e-04,  1.0086e-02,  ..., -5.3291e-03,
          5.8517e-03, -9.2041e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1090, -0.0065,  0.0025,  ..., -0.0046, -0.0029,  0.0048],
        [ 0.0010, -0.1016, -0.0037,  ..., -0.0041, -0.0077,  0.0034],
        [ 0.0136,  0.0029, -0.0801,  ...,  0.0001,  0.0084, -0.0066],
        ...,
        [-0.0228, -0.0002, -0.0133,  ..., -0.1147,  0.0049, -0.0004],
        [ 0.0123,  0.0057,  0.0008,  ...,  0.0146, -0.1029,  0.0013],
        [ 0.0050, -0.0075,  0.0089,  ...,  0.0029,  0.0003, -0.1198]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:00:07 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-29 19:00:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7271,  0.2197,  0.7925,  ...,  0.4785, -1.1299,  0.5132],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3660,  0.4668, -0.1633,  ..., -0.3992, -0.3542,  0.1113],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3938, -0.2207,  1.5449,  ...,  0.3613, -1.7598,  1.1738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1453, -0.0374, -0.5215,  ..., -0.9932, -0.1650,  0.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:00:07 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:00:07 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 19:00:49 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 19:01:31 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 19:02:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3489e-02, -3.1815e-03, -5.1994e-03,  ...,  1.1063e-03,
         -1.1692e-03, -5.4626e-03],
        [-2.2888e-03, -1.5419e-02,  8.3256e-04,  ..., -5.8784e-03,
          6.8951e-04, -1.3771e-03],
        [ 5.9605e-06,  6.5470e-04, -6.5536e-03,  ...,  1.4553e-03,
          3.2215e-03,  1.6327e-03],
        ...,
        [ 3.5167e-05, -3.8338e-03, -3.5362e-03,  ..., -8.1253e-03,
         -1.3285e-03, -3.2406e-03],
        [ 8.5258e-04, -9.1553e-05,  2.8839e-03,  ..., -3.1185e-03,
         -1.2871e-02,  3.0918e-03],
        [ 1.0948e-02,  4.5547e-03, -2.0580e-03,  ...,  1.1501e-03,
         -1.8501e-03, -1.1467e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0969,  0.0020,  0.0087,  ..., -0.0111, -0.0060,  0.0100],
        [ 0.0007, -0.0888, -0.0077,  ...,  0.0066,  0.0076,  0.0011],
        [-0.0009,  0.0050, -0.0715,  ..., -0.0065, -0.0019, -0.0076],
        ...,
        [ 0.0014,  0.0015,  0.0023,  ..., -0.0889,  0.0023, -0.0112],
        [-0.0033, -0.0063, -0.0059,  ..., -0.0016, -0.0874,  0.0025],
        [ 0.0045,  0.0027, -0.0158,  ..., -0.0035,  0.0067, -0.0836]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1310, -0.0009,  0.0017,  ..., -0.0164, -0.0018,  0.0002],
        [ 0.0024, -0.1235,  0.0128,  ..., -0.0142, -0.0020,  0.0063],
        [-0.0010,  0.0051, -0.1206,  ..., -0.0034, -0.0075,  0.0101],
        ...,
        [-0.0139,  0.0087, -0.0077,  ..., -0.1234,  0.0045, -0.0081],
        [-0.0047,  0.0078, -0.0167,  ..., -0.0048, -0.1136,  0.0050],
        [-0.0053, -0.0080, -0.0098,  ..., -0.0105,  0.0054, -0.1194]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:02:15 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-29 19:02:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4331, -0.0699,  0.6069,  ...,  0.5396, -0.9985,  0.5884],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1381,  0.0769, -0.4771,  ..., -0.6445, -0.3855,  0.3259],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0920,  0.0916,  1.9521,  ...,  0.3398, -1.7666,  0.5903],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4141, -0.4688, -0.2290,  ..., -1.2559, -0.1840, -0.2529],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:02:15 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:02:15 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 19:03:04 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 19:03:52 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 19:04:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0020,  0.0111,  0.0036,  ..., -0.0060, -0.0011,  0.0004],
        [ 0.0065, -0.0020, -0.0019,  ..., -0.0004, -0.0113,  0.0014],
        [-0.0058,  0.0052,  0.0121,  ...,  0.0008,  0.0015,  0.0013],
        ...,
        [-0.0035, -0.0120,  0.0055,  ...,  0.0039, -0.0021,  0.0030],
        [-0.0066, -0.0017,  0.0094,  ..., -0.0009,  0.0013, -0.0028],
        [-0.0007, -0.0021,  0.0008,  ..., -0.0046,  0.0050,  0.0108]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0997, -0.0053,  0.0018,  ..., -0.0111,  0.0081, -0.0120],
        [ 0.0051, -0.1215, -0.0087,  ...,  0.0144, -0.0062,  0.0074],
        [ 0.0025, -0.0013, -0.1051,  ...,  0.0011, -0.0059, -0.0083],
        ...,
        [ 0.0002,  0.0014,  0.0162,  ..., -0.1097, -0.0058,  0.0082],
        [-0.0008,  0.0146,  0.0055,  ...,  0.0036, -0.1108,  0.0080],
        [-0.0060,  0.0021, -0.0006,  ..., -0.0162,  0.0085, -0.0985]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.0337e-01, -7.0076e-03, -8.7547e-04,  ...,  3.7842e-03,
          8.2397e-03, -1.5640e-04],
        [-2.7542e-03, -1.9604e-01, -1.5106e-02,  ...,  5.5809e-03,
          1.9741e-03,  1.1993e-02],
        [ 1.9684e-03, -8.3084e-03, -1.8018e-01,  ..., -2.5921e-03,
         -8.4305e-03, -1.2917e-02],
        ...,
        [ 6.9656e-03,  1.2512e-03, -6.9733e-03,  ..., -1.9299e-01,
         -6.6757e-03,  3.5725e-03],
        [ 1.1787e-02, -1.0414e-03,  1.0529e-02,  ..., -1.5278e-03,
         -2.0496e-01, -1.6251e-02],
        [-1.0330e-02,  6.2141e-03, -4.4608e-04,  ..., -8.8654e-03,
         -2.1500e-02, -1.7773e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:04:41 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-29 19:04:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2561, -0.1584,  0.9014,  ...,  0.2273, -1.1104,  0.7183],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1088, -0.0450, -0.4268,  ..., -0.7241, -0.1406,  0.4509],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2155, -0.2039,  2.0742,  ..., -0.0410, -1.9697,  0.6587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2583, -0.9746,  0.2925,  ..., -1.1621,  0.0905,  0.8076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:04:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:04:41 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 19:05:32 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 19:06:20 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 19:06:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0005, -0.0030,  0.0009,  ...,  0.0037,  0.0023,  0.0049],
        [-0.0052,  0.0003,  0.0019,  ...,  0.0064,  0.0037,  0.0024],
        [ 0.0039,  0.0018, -0.0029,  ..., -0.0005, -0.0061,  0.0031],
        ...,
        [ 0.0024, -0.0010,  0.0027,  ..., -0.0028, -0.0023,  0.0017],
        [-0.0042, -0.0019,  0.0010,  ...,  0.0018, -0.0075,  0.0019],
        [-0.0007,  0.0034, -0.0055,  ...,  0.0049,  0.0017, -0.0033]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1066e-01,  8.5754e-03,  1.0271e-03,  ...,  2.5234e-03,
          6.7558e-03,  6.3744e-03],
        [ 1.3161e-03, -1.1670e-01, -8.0109e-05,  ..., -2.3575e-03,
          4.2992e-03,  1.5707e-03],
        [ 2.6321e-04,  5.9052e-03, -1.2115e-01,  ...,  6.8512e-03,
          1.7929e-03,  3.9101e-04],
        ...,
        [ 5.8708e-03,  9.5749e-03,  3.1242e-03,  ..., -1.1108e-01,
          1.5244e-02, -1.5213e-02],
        [ 5.6076e-04,  3.8147e-05, -3.4351e-03,  ...,  8.5068e-03,
         -1.1621e-01, -2.3117e-03],
        [ 3.2234e-03, -2.9793e-03, -1.0300e-02,  ...,  2.8992e-03,
          3.0632e-03, -1.1603e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1194,  0.0018, -0.0016,  ..., -0.0081,  0.0026, -0.0165],
        [ 0.0075, -0.1123,  0.0037,  ...,  0.0105, -0.0076, -0.0043],
        [ 0.0027, -0.0072, -0.1201,  ..., -0.0033, -0.0100,  0.0050],
        ...,
        [-0.0005, -0.0028,  0.0090,  ..., -0.1094,  0.0071, -0.0119],
        [-0.0004, -0.0037, -0.0113,  ...,  0.0136, -0.1165,  0.0110],
        [ 0.0042,  0.0029, -0.0077,  ...,  0.0018, -0.0023, -0.1318]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:06:52 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-29 19:06:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0414,  0.0363,  1.0684,  ...,  0.1614, -1.0625,  0.3643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2957, -0.3433, -0.1920,  ..., -0.8423, -0.1416, -0.1716],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4084, -0.2603,  1.2148,  ...,  0.4917, -1.9385,  0.8569],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1143, -0.6079,  0.7129,  ..., -1.0117,  0.6240, -0.1260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:06:52 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:06:52 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 19:07:46 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 19:08:40 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 19:09:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.7858e-03,  1.1778e-03,  4.6730e-03,  ..., -8.9169e-04,
         -3.2024e-03,  2.2240e-03],
        [ 2.0542e-03,  1.6212e-03,  3.1338e-03,  ...,  1.5259e-05,
         -7.4863e-04,  5.4741e-03],
        [-9.6798e-05, -3.8414e-03,  4.5929e-03,  ..., -1.9245e-03,
          6.6833e-03, -1.7405e-03],
        ...,
        [ 1.8845e-03,  1.6689e-03,  5.6686e-03,  ...,  7.3776e-03,
         -3.8128e-03,  5.8060e-03],
        [-1.8787e-03, -4.7913e-03, -3.7169e-04,  ..., -1.8144e-04,
          9.9792e-03,  2.8968e-04],
        [-1.5879e-03, -4.7898e-04, -8.9455e-04,  ..., -6.1035e-04,
         -3.2043e-03,  5.4741e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1765, -0.0013,  0.0032,  ..., -0.0023, -0.0064, -0.0058],
        [-0.0022, -0.1779,  0.0145,  ...,  0.0064,  0.0136, -0.0031],
        [-0.0017,  0.0079, -0.1543,  ..., -0.0039, -0.0076, -0.0029],
        ...,
        [-0.0144,  0.0021,  0.0139,  ..., -0.1688, -0.0077, -0.0038],
        [-0.0033,  0.0056, -0.0116,  ...,  0.0133, -0.1813, -0.0101],
        [-0.0080,  0.0022, -0.0066,  ..., -0.0041,  0.0202, -0.1707]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.7905e-01,  1.2650e-02, -4.9667e-03,  ..., -2.0370e-03,
         -9.7809e-03, -1.3676e-03],
        [-5.5656e-03, -2.6880e-01,  5.6152e-03,  ..., -2.4872e-02,
          2.2827e-02, -1.8883e-03],
        [ 1.1063e-04,  1.0841e-02, -2.5073e-01,  ...,  1.1360e-02,
          9.0942e-03, -5.8899e-03],
        ...,
        [-1.4687e-02, -1.6985e-03, -1.4868e-03,  ..., -2.7026e-01,
          1.9318e-02,  8.0490e-04],
        [-2.7809e-03,  9.0408e-03,  9.8877e-03,  ...,  2.0966e-02,
         -2.6343e-01,  7.0343e-03],
        [-1.9188e-03, -1.0719e-02, -2.2907e-03,  ..., -5.2948e-03,
          4.5166e-03, -2.5415e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:09:36 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-29 19:09:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1065, -0.1443,  1.1816,  ..., -0.0303, -1.2285,  0.3694],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2256, -0.7598,  0.1610,  ..., -0.8682,  0.0592,  0.5767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1628, -0.3127,  1.4111,  ...,  0.2891, -1.9854,  0.8481],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4526, -0.3501,  0.6230,  ..., -1.2109,  0.0679, -0.2151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:09:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:09:36 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 19:10:31 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 19:11:27 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 19:12:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.8348e-03,  4.4212e-03, -1.9684e-03,  ...,  2.1172e-03,
          9.0408e-04, -1.2627e-03],
        [-3.0289e-03, -1.0086e-02, -1.0462e-03,  ..., -3.8147e-03,
          2.0313e-04,  1.7047e-04],
        [ 4.1809e-03,  3.6564e-03, -9.3536e-03,  ..., -1.0176e-03,
         -1.2093e-03, -2.0142e-03],
        ...,
        [ 1.9360e-03,  2.6512e-03, -6.1302e-03,  ..., -7.8812e-03,
          1.2875e-03,  2.7390e-03],
        [ 3.6945e-03, -2.0075e-04,  1.3027e-03,  ..., -4.4556e-03,
         -6.6147e-03,  1.3113e-03],
        [-1.1027e-05,  4.0531e-05, -2.4929e-03,  ..., -1.6756e-03,
          2.3041e-03, -4.5128e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1082, -0.0053,  0.0140,  ...,  0.0049,  0.0030, -0.0057],
        [ 0.0028, -0.0965, -0.0059,  ...,  0.0010, -0.0001,  0.0091],
        [ 0.0091, -0.0155, -0.1038,  ..., -0.0021, -0.0127,  0.0076],
        ...,
        [-0.0115,  0.0134,  0.0093,  ..., -0.0842,  0.0114,  0.0067],
        [ 0.0093, -0.0106, -0.0016,  ...,  0.0058, -0.0872,  0.0047],
        [-0.0062, -0.0003,  0.0035,  ...,  0.0040,  0.0109, -0.0883]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1019,  0.0043, -0.0037,  ..., -0.0005,  0.0034,  0.0007],
        [ 0.0119, -0.1161, -0.0067,  ..., -0.0040,  0.0171,  0.0068],
        [-0.0048, -0.0184, -0.1086,  ..., -0.0051, -0.0144,  0.0067],
        ...,
        [ 0.0110,  0.0085,  0.0065,  ..., -0.0876, -0.0011, -0.0075],
        [ 0.0112, -0.0024, -0.0058,  ...,  0.0084, -0.0999,  0.0096],
        [-0.0003, -0.0083,  0.0034,  ..., -0.0079,  0.0090, -0.1052]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:12:20 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-29 19:12:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2440, -0.1924,  0.6709,  ...,  0.2585, -1.1338,  0.4915],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0884, -0.4819,  0.4805,  ..., -0.7256,  0.4526, -0.1168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2556,  0.0632,  1.2998,  ...,  0.9375, -1.8789,  1.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7578, -0.6167,  0.7710,  ..., -0.7515, -0.3267, -0.6465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:12:20 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:12:20 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 19:13:18 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 19:14:12 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 19:15:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.1422e-03,  8.3542e-04, -5.5027e-04,  ...,  8.4457e-03,
          3.7670e-03,  3.0499e-03],
        [-9.7351e-03,  1.4648e-02, -2.6531e-03,  ..., -4.9210e-04,
         -4.8218e-03, -1.2222e-02],
        [-4.9744e-03,  2.5311e-03,  4.8027e-03,  ..., -3.4561e-03,
         -8.3923e-05, -9.1028e-04],
        ...,
        [ 2.7657e-03,  3.7670e-04,  3.8319e-03,  ...,  9.4070e-03,
         -1.6235e-02,  2.7585e-04],
        [-1.3676e-03,  1.9493e-03,  7.6256e-03,  ...,  2.9984e-03,
          1.2413e-02,  1.1921e-03],
        [ 2.3518e-03,  4.2820e-04, -9.2316e-03,  ..., -6.8436e-03,
         -5.6763e-03,  5.0812e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1884e-01, -7.4005e-03, -6.0806e-03,  ...,  3.0823e-03,
          6.1264e-03,  9.6893e-03],
        [ 5.3978e-03, -1.1896e-01,  5.7220e-06,  ...,  5.9128e-03,
          5.1918e-03,  6.1607e-03],
        [-4.8923e-04,  8.0261e-03, -1.2219e-01,  ...,  1.4305e-05,
          6.4888e-03, -4.5166e-03],
        ...,
        [-7.1945e-03,  1.0431e-05,  1.9665e-03,  ..., -1.2030e-01,
          1.9485e-02, -1.1581e-02],
        [ 1.0490e-02,  2.2446e-02,  4.1542e-03,  ...,  2.5482e-03,
         -1.2061e-01, -1.4297e-02],
        [ 1.4809e-02, -1.3191e-02, -1.9455e-03,  ..., -7.1793e-03,
          6.6233e-04, -1.1975e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.4294e-01, -8.2550e-03,  4.6082e-03,  ..., -9.7351e-03,
          1.3153e-02, -2.0599e-03],
        [-2.2766e-02, -1.4819e-01, -1.1421e-02,  ..., -8.4400e-04,
         -1.0536e-02,  1.1414e-02],
        [-1.8997e-03, -1.8845e-03, -1.4490e-01,  ..., -4.0741e-03,
          6.6681e-03, -7.3318e-03],
        ...,
        [ 5.6915e-03,  1.7166e-05,  1.8988e-03,  ..., -1.1676e-01,
          9.1782e-03,  8.7891e-03],
        [ 3.1490e-03,  1.1353e-02, -4.3907e-03,  ...,  1.6556e-02,
         -1.4270e-01,  1.2951e-03],
        [ 3.5496e-03,  1.1887e-02, -9.8038e-04,  ..., -6.7940e-03,
          9.1553e-03, -1.3501e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:15:11 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-29 19:15:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1155, -0.1843,  0.6797,  ...,  0.1326, -1.0312,  0.4014],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2461, -0.2263,  0.3250,  ..., -0.7227,  0.0695, -0.1874],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5254,  0.2231,  1.8457,  ...,  0.6084, -1.4863,  1.3389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.3630, -1.2764,  0.0742,  ..., -1.1846,  0.3618, -0.8486],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:15:11 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:15:11 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 19:16:09 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 19:17:10 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 19:18:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0076, -0.0079,  0.0028,  ..., -0.0060, -0.0123, -0.0030],
        [-0.0006,  0.0067, -0.0053,  ..., -0.0030,  0.0031,  0.0024],
        [-0.0070, -0.0025,  0.0108,  ..., -0.0028,  0.0003,  0.0052],
        ...,
        [ 0.0053, -0.0012, -0.0034,  ...,  0.0107, -0.0018,  0.0020],
        [ 0.0063, -0.0028, -0.0024,  ..., -0.0019,  0.0092,  0.0055],
        [ 0.0023,  0.0092, -0.0035,  ..., -0.0042,  0.0049,  0.0127]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0964,  0.0033,  0.0125,  ...,  0.0005,  0.0010,  0.0007],
        [ 0.0015, -0.1065,  0.0134,  ...,  0.0008,  0.0025, -0.0076],
        [ 0.0026,  0.0034, -0.0883,  ...,  0.0048, -0.0046,  0.0005],
        ...,
        [ 0.0041, -0.0083, -0.0070,  ..., -0.0986,  0.0079, -0.0045],
        [ 0.0079,  0.0035,  0.0114,  ...,  0.0125, -0.0789, -0.0020],
        [-0.0099, -0.0006, -0.0029,  ..., -0.0011, -0.0091, -0.1128]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2408e-01,  6.5155e-03,  2.1515e-03,  ..., -2.8801e-03,
          8.3923e-03,  1.0300e-04],
        [ 1.1047e-02, -1.2769e-01,  3.2215e-03,  ...,  2.8210e-03,
          3.8986e-03,  1.0712e-02],
        [ 5.4855e-03, -1.0109e-02, -1.2915e-01,  ..., -1.1406e-02,
          1.2531e-03,  3.2473e-04],
        ...,
        [-9.5978e-03, -1.0117e-02, -8.8654e-03,  ..., -1.3147e-01,
          5.7220e-03, -1.1116e-02],
        [-3.9253e-03,  1.3748e-02,  2.5558e-03,  ...,  1.9714e-02,
         -1.3159e-01,  1.4324e-03],
        [-1.6647e-02,  5.2147e-03, -1.0185e-02,  ..., -6.0158e-03,
         -3.8757e-03, -1.2878e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:18:13 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-29 19:18:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1245, -0.0013,  0.6191,  ...,  0.4451, -0.9248,  0.5918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4373, -0.3872,  0.4192,  ..., -0.4314, -0.1790, -0.4080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3618,  0.4600,  1.5537,  ...,  0.3042, -1.1436,  2.0723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2363, -1.5410, -0.9434,  ..., -0.8940, -0.9077, -0.1909],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:18:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:18:13 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 19:19:14 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 19:20:16 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 19:21:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0043,  0.0012,  0.0019,  ..., -0.0002, -0.0047,  0.0018],
        [ 0.0061,  0.0027,  0.0013,  ...,  0.0014,  0.0014, -0.0027],
        [ 0.0033, -0.0019,  0.0067,  ...,  0.0011, -0.0037, -0.0010],
        ...,
        [-0.0052, -0.0035,  0.0005,  ...,  0.0015, -0.0059,  0.0001],
        [ 0.0010, -0.0034,  0.0069,  ..., -0.0014,  0.0062, -0.0057],
        [-0.0023, -0.0008,  0.0062,  ...,  0.0013, -0.0028,  0.0068]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0992,  0.0174, -0.0054,  ...,  0.0034,  0.0014,  0.0005],
        [-0.0105, -0.1060, -0.0017,  ..., -0.0102, -0.0095,  0.0096],
        [-0.0008, -0.0180, -0.1144,  ..., -0.0025, -0.0051,  0.0038],
        ...,
        [ 0.0027,  0.0201,  0.0015,  ..., -0.1168, -0.0111,  0.0014],
        [ 0.0146, -0.0262, -0.0160,  ...,  0.0083, -0.1162,  0.0028],
        [ 0.0097, -0.0037, -0.0036,  ...,  0.0009,  0.0174, -0.1121]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.4807e-01, -6.9666e-04, -1.3641e-02,  ...,  8.5926e-04,
         -1.1009e-02,  1.7273e-02],
        [ 8.6365e-03, -1.6870e-01, -4.4556e-03,  ..., -2.1858e-03,
         -8.8196e-03, -3.4866e-03],
        [-4.7379e-03,  9.9182e-03, -1.4539e-01,  ...,  7.5150e-03,
          4.0016e-03,  2.4853e-03],
        ...,
        [ 1.0551e-02,  5.5466e-03,  1.8005e-02,  ..., -1.5820e-01,
         -2.6703e-05, -5.4817e-03],
        [ 2.9182e-04, -1.7120e-02, -1.1726e-02,  ...,  8.9951e-03,
         -1.6650e-01,  7.6408e-03],
        [ 2.1362e-03,  1.4248e-03, -1.3866e-03,  ..., -4.1676e-04,
          1.1948e-02, -1.6382e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:21:19 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-29 19:21:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2188,  0.1130,  0.8369,  ...,  0.2898, -0.7192,  0.6338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1562, -0.6919,  0.0197,  ..., -0.6270,  0.1970, -0.4868],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8027,  0.9580,  1.6914,  ...,  0.3691, -1.5928,  2.6016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1704, -1.7344, -0.0308,  ..., -1.3906, -0.7622, -0.7632],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:21:20 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:21:20 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 19:22:19 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 19:23:17 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 19:24:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.5912e-03,  3.5286e-03, -2.1782e-03,  ...,  6.6643e-03,
          2.4529e-03, -1.0910e-03],
        [-4.3259e-03,  4.5319e-03, -4.3774e-04,  ...,  8.4257e-04,
         -5.5265e-04, -4.8676e-03],
        [ 8.1682e-04,  1.2083e-03,  4.2343e-03,  ...,  6.0005e-03,
         -5.2786e-04,  1.5771e-04],
        ...,
        [-1.6680e-03, -1.8854e-03, -1.6749e-05,  ...,  6.4812e-03,
         -1.0368e-02,  6.3038e-04],
        [-1.8520e-03,  3.5076e-03,  2.8801e-03,  ...,  5.8784e-03,
          9.7351e-03,  6.8235e-04],
        [-2.4509e-04,  1.2913e-03,  3.6716e-04,  ..., -4.6310e-03,
          7.9269e-03,  4.3640e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0731,  0.0153, -0.0058,  ...,  0.0068,  0.0093, -0.0053],
        [ 0.0020, -0.0690, -0.0076,  ...,  0.0161, -0.0036, -0.0062],
        [-0.0008, -0.0100, -0.0696,  ...,  0.0016,  0.0063, -0.0061],
        ...,
        [-0.0099, -0.0049,  0.0048,  ..., -0.0690, -0.0057,  0.0041],
        [ 0.0044,  0.0127,  0.0054,  ...,  0.0108, -0.0526, -0.0111],
        [-0.0057,  0.0120,  0.0086,  ..., -0.0070,  0.0082, -0.0669]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1106,  0.0103, -0.0038,  ..., -0.0174,  0.0068,  0.0082],
        [ 0.0070, -0.1082, -0.0060,  ...,  0.0083, -0.0189,  0.0068],
        [ 0.0190,  0.0093, -0.1114,  ...,  0.0116, -0.0153, -0.0166],
        ...,
        [-0.0300, -0.0091, -0.0119,  ..., -0.1151, -0.0005,  0.0093],
        [ 0.0128,  0.0089, -0.0044,  ...,  0.0210, -0.1024, -0.0003],
        [-0.0052, -0.0012,  0.0208,  ..., -0.0068, -0.0119, -0.1256]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:24:20 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-29 19:24:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1791,  0.2026,  0.6680,  ...,  0.1260, -0.4993,  0.8892],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1044, -0.7671, -0.4414,  ..., -0.4285, -0.4302, -0.1313],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.2539,  0.7051,  1.7822,  ...,  0.5122, -1.5811,  2.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2473, -1.2031, -0.5176,  ..., -1.1406, -0.8857, -1.3623],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:24:20 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:24:20 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 19:25:21 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 19:26:25 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 19:27:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0073, -0.0002, -0.0008,  ...,  0.0010, -0.0013,  0.0053],
        [-0.0002, -0.0026, -0.0014,  ...,  0.0030,  0.0028,  0.0007],
        [-0.0008, -0.0035, -0.0047,  ..., -0.0034,  0.0023, -0.0053],
        ...,
        [ 0.0025, -0.0006, -0.0003,  ..., -0.0004,  0.0025, -0.0016],
        [ 0.0025,  0.0054, -0.0011,  ...,  0.0020, -0.0079, -0.0002],
        [-0.0006, -0.0022,  0.0051,  ..., -0.0020,  0.0017, -0.0072]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.0007e-02,  7.1373e-03,  2.0813e-02,  ...,  2.3132e-02,
          1.7075e-02,  9.0027e-03],
        [ 3.3455e-03, -9.7412e-02,  9.0866e-03,  ..., -8.4000e-03,
          2.2919e-02,  3.3379e-05],
        [-1.9302e-02, -3.2883e-03, -7.4768e-02,  ..., -1.2558e-02,
         -4.5128e-03, -6.8703e-03],
        ...,
        [ 9.0332e-03, -6.7291e-03,  1.2253e-02,  ..., -8.4290e-02,
          1.8250e-02,  6.0806e-03],
        [ 2.1179e-02, -1.5457e-02,  4.0016e-03,  ..., -4.3564e-03,
         -7.7393e-02,  7.7286e-03],
        [-5.0888e-03, -3.2463e-03,  7.1602e-03,  ...,  5.9395e-03,
          3.6716e-03, -4.9103e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1151,  0.0150,  0.0078,  ...,  0.0194,  0.0165,  0.0109],
        [-0.0008, -0.1274,  0.0119,  ..., -0.0144, -0.0146,  0.0045],
        [ 0.0002, -0.0193, -0.1338,  ..., -0.0087,  0.0140, -0.0009],
        ...,
        [ 0.0139,  0.0029,  0.0031,  ..., -0.1068,  0.0069,  0.0050],
        [ 0.0152,  0.0039,  0.0150,  ..., -0.0026, -0.1331,  0.0062],
        [ 0.0053,  0.0102, -0.0136,  ...,  0.0059,  0.0008, -0.1047]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:27:31 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-29 19:27:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3560,  0.4011,  0.6704,  ...,  0.1489, -0.6660,  1.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0981, -0.7983, -0.0260,  ..., -0.6431, -0.3547, -0.4084],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7285,  1.3125,  1.8828,  ...,  0.6562, -1.6973,  3.5938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4238, -1.5020, -0.6436,  ..., -0.9658, -0.7256, -0.1631],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:27:31 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:27:31 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 19:28:36 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 19:29:41 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 19:30:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.4283e-03, -1.8616e-03, -8.1491e-04,  ..., -3.6573e-04,
         -2.0981e-03, -3.6087e-03],
        [-2.5425e-03,  2.2526e-03,  4.7708e-04,  ..., -1.0757e-03,
          1.4334e-03, -1.5640e-03],
        [-2.8348e-04, -2.6703e-03,  4.1428e-03,  ...,  1.0657e-04,
          8.5354e-04, -1.0939e-03],
        ...,
        [ 1.7328e-03,  4.6182e-04,  3.2616e-04,  ...,  4.8981e-03,
         -1.5774e-03, -2.5826e-03],
        [ 2.6107e-05, -7.7343e-04,  2.6608e-03,  ..., -2.3613e-03,
          1.2674e-03,  7.9775e-04],
        [-3.3140e-04,  1.9894e-03, -1.8454e-03,  ...,  8.7929e-04,
          4.6992e-04,  4.9744e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0233,  0.0176, -0.0098,  ..., -0.0095, -0.0059, -0.0081],
        [ 0.0265, -0.0704, -0.0035,  ...,  0.0003, -0.0093,  0.0005],
        [ 0.0132,  0.0110, -0.0381,  ...,  0.0084,  0.0056, -0.0063],
        ...,
        [ 0.0053, -0.0067,  0.0063,  ..., -0.0360, -0.0017,  0.0009],
        [-0.0037,  0.0056,  0.0015,  ..., -0.0063, -0.0405,  0.0032],
        [-0.0206,  0.0029, -0.0027,  ..., -0.0027,  0.0005, -0.0529]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0726,  0.0199,  0.0060,  ..., -0.0074, -0.0225, -0.0023],
        [ 0.0298, -0.0585, -0.0012,  ..., -0.0036, -0.0218,  0.0054],
        [ 0.0054,  0.0075, -0.0818,  ...,  0.0040,  0.0044, -0.0099],
        ...,
        [-0.0031,  0.0094, -0.0100,  ..., -0.0673,  0.0054,  0.0049],
        [-0.0040, -0.0083, -0.0219,  ..., -0.0026, -0.0579, -0.0099],
        [-0.0055,  0.0067, -0.0036,  ..., -0.0166, -0.0109, -0.0645]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:30:50 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-29 19:30:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5151,  0.2747,  0.6641,  ...,  0.1974, -0.6064,  1.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1204, -0.5547, -0.2493,  ..., -0.5171, -0.3816, -0.6777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1191,  1.8145,  1.6963,  ...,  0.8027, -1.3389,  3.7539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2389, -2.1680, -0.0361,  ..., -1.0967, -0.6045,  0.2637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:30:50 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:30:50 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 19:31:57 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 19:33:04 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 19:34:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2831e-03, -5.8556e-04,  2.9545e-03,  ...,  2.3994e-03,
         -3.8967e-03, -1.3857e-03],
        [ 2.8362e-03,  3.3069e-04,  8.8453e-04,  ...,  2.0428e-03,
          6.2418e-04,  1.9989e-03],
        [-2.0542e-03, -2.4490e-03,  5.7793e-03,  ...,  6.2561e-04,
          7.9870e-04,  1.9741e-03],
        ...,
        [-2.7332e-03, -1.6432e-03, -1.3266e-03,  ...,  4.5433e-03,
         -1.2183e-04, -1.2808e-03],
        [-2.2745e-04, -1.7567e-03, -5.7340e-05,  ...,  3.7174e-03,
          2.2259e-03,  4.8470e-04],
        [ 7.4482e-04,  1.4048e-03,  2.9774e-03,  ..., -3.1509e-03,
          1.0717e-04,  5.3711e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0327,  0.0045, -0.0019,  ...,  0.0008, -0.0024, -0.0057],
        [ 0.0082, -0.0453,  0.0167,  ...,  0.0172,  0.0109,  0.0057],
        [ 0.0183,  0.0068, -0.0414,  ...,  0.0153,  0.0074, -0.0036],
        ...,
        [-0.0048, -0.0119,  0.0012,  ..., -0.0426, -0.0128, -0.0109],
        [ 0.0174, -0.0032, -0.0031,  ..., -0.0327, -0.0533, -0.0015],
        [-0.0063,  0.0045,  0.0111,  ...,  0.0104,  0.0120, -0.0396]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0565, -0.0070, -0.0097,  ..., -0.0136, -0.0191, -0.0075],
        [ 0.0204, -0.0680, -0.0020,  ...,  0.0147,  0.0120,  0.0057],
        [-0.0059, -0.0028, -0.0717,  ..., -0.0042,  0.0136, -0.0053],
        ...,
        [ 0.0061,  0.0004, -0.0157,  ..., -0.0768, -0.0159, -0.0114],
        [ 0.0095,  0.0032,  0.0076,  ..., -0.0051, -0.0751,  0.0036],
        [ 0.0046,  0.0103,  0.0013,  ...,  0.0159,  0.0043, -0.0715]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:34:16 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-29 19:34:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2781,  0.4829,  0.6562,  ...,  0.2449, -0.6294,  1.3311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1829, -0.6499, -0.2793,  ..., -0.4006, -0.3064, -0.1018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1466,  0.7354,  1.2061,  ...,  0.5176, -1.8340,  3.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.3794, -3.2715, -0.7734,  ..., -1.8066, -1.4209,  1.3457],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:34:16 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:34:16 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 19:35:29 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 19:36:40 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 19:37:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2522e-02, -5.8594e-03,  7.2289e-04,  ...,  4.0207e-03,
         -2.9182e-03, -1.3466e-03],
        [-7.7581e-04,  1.8692e-02,  8.7261e-04,  ..., -3.9673e-03,
         -1.8463e-03,  3.7956e-03],
        [-1.2369e-03,  2.8896e-03,  1.2947e-02,  ..., -2.4929e-03,
          4.0970e-03,  1.2865e-03],
        ...,
        [ 6.9313e-03, -6.0844e-03, -2.8629e-03,  ...,  1.9913e-02,
         -2.3041e-03,  4.4632e-03],
        [-3.3951e-03, -4.5929e-03, -1.9722e-03,  ...,  1.5697e-03,
          1.3733e-02, -7.2002e-05],
        [-4.8018e-04, -1.2817e-03,  4.5853e-03,  ..., -1.2665e-03,
         -6.8855e-04,  1.7120e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0267,  0.0018,  0.0072,  ..., -0.0047, -0.0056, -0.0068],
        [ 0.0082, -0.0468,  0.0012,  ...,  0.0043,  0.0131,  0.0076],
        [-0.0062, -0.0122, -0.0527,  ...,  0.0102,  0.0154, -0.0004],
        ...,
        [ 0.0145, -0.0009, -0.0008,  ..., -0.0295, -0.0010,  0.0109],
        [-0.0039, -0.0060, -0.0009,  ...,  0.0027, -0.0323, -0.0064],
        [-0.0039,  0.0140, -0.0061,  ...,  0.0064,  0.0019, -0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0222,  0.0074,  0.0028,  ...,  0.0181,  0.0098,  0.0081],
        [ 0.0214, -0.0262, -0.0190,  ...,  0.0129,  0.0072,  0.0013],
        [-0.0054, -0.0023, -0.0315,  ...,  0.0124,  0.0081, -0.0078],
        ...,
        [ 0.0066,  0.0063,  0.0078,  ..., -0.0378, -0.0025,  0.0219],
        [ 0.0123, -0.0090, -0.0152,  ...,  0.0009, -0.0134,  0.0017],
        [-0.0104, -0.0022,  0.0052,  ...,  0.0050, -0.0024, -0.0448]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:37:54 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-29 19:37:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0417,  0.6187,  0.5693,  ...,  0.2637, -0.4500,  1.2783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0952, -0.8623, -0.0237,  ..., -0.4392, -0.2268,  0.0782],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4077,  1.0938,  1.4551,  ...,  0.5361, -1.7783,  3.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4448, -3.4961, -1.2676,  ..., -1.6885, -1.4375,  0.5698],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:37:54 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:37:54 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 19:39:14 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 19:40:36 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 19:41:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0245,  0.0001,  0.0046,  ..., -0.0057, -0.0004, -0.0031],
        [-0.0039,  0.0132,  0.0036,  ...,  0.0125, -0.0042, -0.0059],
        [-0.0006, -0.0112,  0.0274,  ...,  0.0037,  0.0045, -0.0015],
        ...,
        [-0.0015,  0.0166,  0.0083,  ...,  0.0265,  0.0018, -0.0028],
        [-0.0039, -0.0055, -0.0069,  ..., -0.0008,  0.0265,  0.0040],
        [ 0.0042,  0.0032, -0.0030,  ..., -0.0062,  0.0051,  0.0305]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0539, -0.0100, -0.0064,  ..., -0.0073, -0.0090,  0.0163],
        [ 0.0090, -0.0350, -0.0230,  ...,  0.0241, -0.0031,  0.0028],
        [ 0.0015, -0.0018, -0.0312,  ...,  0.0115, -0.0201, -0.0007],
        ...,
        [ 0.0033,  0.0092, -0.0014,  ..., -0.0304,  0.0030,  0.0138],
        [ 0.0158, -0.0253,  0.0059,  ..., -0.0040, -0.0557, -0.0002],
        [ 0.0058,  0.0126, -0.0127,  ..., -0.0036, -0.0036, -0.0425]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0677, -0.0127,  0.0098,  ..., -0.0176, -0.0041, -0.0045],
        [ 0.0039, -0.0704, -0.0106,  ...,  0.0171,  0.0031,  0.0236],
        [-0.0114,  0.0108, -0.0649,  ...,  0.0010,  0.0078,  0.0029],
        ...,
        [-0.0140,  0.0105, -0.0240,  ..., -0.0534,  0.0055, -0.0040],
        [ 0.0121, -0.0083, -0.0047,  ...,  0.0066, -0.0549, -0.0157],
        [-0.0003,  0.0007, -0.0001,  ..., -0.0110, -0.0046, -0.0416]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:41:57 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-29 19:41:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0506,  0.2435,  0.3914,  ...,  0.1793, -0.6182,  1.2295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1423, -1.1816, -0.2908,  ..., -0.6475, -0.5166,  0.4780],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4561,  1.3311,  2.4453,  ..., -0.0698, -0.9365,  3.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0977, -2.9316, -0.5288,  ..., -1.8477, -1.5420,  1.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:41:57 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:41:57 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 19:43:16 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 19:44:35 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 19:45:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.7752e-04,  1.2994e-05, -1.0198e-04,  ..., -3.0935e-05,
         -1.2088e-04, -1.5640e-04],
        [ 1.2732e-04, -1.1845e-03, -4.6372e-04,  ...,  1.9944e-04,
         -2.0337e-04, -1.0574e-04],
        [ 1.5676e-05, -2.9325e-04, -1.3075e-03,  ..., -1.5593e-04,
         -2.5797e-04, -1.9813e-04],
        ...,
        [ 6.5088e-05, -4.1425e-05, -4.4405e-05,  ..., -1.2417e-03,
         -1.6594e-04, -2.0862e-04],
        [-1.7357e-04,  1.5366e-04, -1.6689e-04,  ..., -1.3351e-04,
         -8.7976e-04,  1.2422e-04],
        [ 1.3781e-04, -2.8253e-05, -3.3808e-04,  ..., -5.2881e-04,
          1.5569e-04, -1.9207e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.4399e-02,  1.4748e-02, -5.0735e-03,  ...,  1.8936e-02,
         -2.4052e-03,  2.0782e-02],
        [ 4.6692e-03, -4.2328e-02,  1.9363e-02,  ...,  7.1526e-05,
          1.1435e-03,  1.4595e-02],
        [-5.4436e-03, -5.5580e-03, -5.4230e-02,  ..., -3.8338e-03,
         -1.1787e-02, -1.4877e-03],
        ...,
        [ 4.3259e-03,  4.5204e-03, -1.6890e-03,  ..., -3.6804e-02,
         -1.9135e-02,  1.3023e-02],
        [ 1.2932e-02, -1.1932e-02, -2.0313e-03,  ...,  2.9240e-03,
         -2.4673e-02,  2.4853e-03],
        [-8.4114e-04, -8.2779e-04, -9.4070e-03,  ..., -1.1902e-02,
         -1.3817e-02, -4.7150e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0675,  0.0106,  0.0011,  ...,  0.0147,  0.0022,  0.0126],
        [-0.0045, -0.0665,  0.0169,  ..., -0.0022,  0.0061,  0.0105],
        [ 0.0092,  0.0037, -0.0745,  ..., -0.0165, -0.0199,  0.0010],
        ...,
        [ 0.0006, -0.0012,  0.0218,  ..., -0.0637, -0.0019,  0.0115],
        [ 0.0094,  0.0149, -0.0009,  ..., -0.0116, -0.0679,  0.0002],
        [ 0.0044, -0.0009, -0.0123,  ..., -0.0135, -0.0091, -0.0726]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:45:58 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-29 19:45:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1260,  0.3530,  0.4431,  ...,  0.1790, -0.5654,  1.1455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1677, -1.1904, -0.4551,  ..., -0.5718, -0.4827,  0.1705],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6514,  2.1934,  2.9746,  ..., -0.8389, -1.2930,  3.6387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.7891, -4.1836,  0.5493,  ..., -2.0117, -1.1562,  0.9399],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:45:58 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:45:58 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 19:47:19 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 19:48:40 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 19:50:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.2234e-03,  7.1049e-04,  5.3930e-04,  ...,  3.5882e-04,
         -7.9918e-04, -2.2650e-05],
        [-2.8062e-04,  3.3436e-03,  2.7847e-04,  ...,  1.9875e-03,
          7.0667e-04,  1.1711e-03],
        [ 8.1205e-04, -3.6049e-04,  3.5267e-03,  ...,  1.0204e-04,
         -4.2677e-04,  1.6057e-04],
        ...,
        [ 1.0490e-04, -1.4372e-03, -3.9744e-04,  ...,  3.0060e-03,
          5.3644e-04, -5.5552e-04],
        [-6.4182e-04,  7.4816e-04, -1.5533e-04,  ...,  9.4891e-04,
          3.3360e-03,  5.6219e-04],
        [ 3.5882e-04, -2.9731e-04,  7.0810e-04,  ..., -8.3506e-05,
         -3.9577e-04,  3.1414e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0307, -0.0003, -0.0109,  ..., -0.0126, -0.0111, -0.0141],
        [ 0.0315, -0.0429, -0.0004,  ..., -0.0054, -0.0022, -0.0060],
        [ 0.0028, -0.0176, -0.0175,  ..., -0.0029,  0.0053,  0.0221],
        ...,
        [-0.0061,  0.0076, -0.0198,  ..., -0.0340,  0.0047, -0.0276],
        [-0.0150, -0.0061, -0.0107,  ...,  0.0080, -0.0227,  0.0039],
        [-0.0046, -0.0217,  0.0096,  ...,  0.0126, -0.0062, -0.0545]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.4504e-02,  1.6689e-03, -7.8812e-03,  ...,  1.9131e-03,
         -1.4244e-02, -4.7569e-03],
        [ 5.8098e-03, -6.1462e-02,  6.0654e-03,  ...,  2.4433e-03,
         -1.5888e-03, -6.8359e-03],
        [ 4.3144e-03, -2.0325e-02, -4.9042e-02,  ..., -1.0204e-03,
         -4.8523e-03,  1.9760e-03],
        ...,
        [ 2.0813e-02,  2.4277e-02, -2.2827e-02,  ..., -2.4277e-02,
         -5.6725e-03, -7.6294e-06],
        [ 4.9057e-03, -7.0724e-03, -7.1487e-03,  ..., -2.2087e-03,
         -5.1208e-02, -5.5008e-03],
        [-3.7781e-02,  5.1651e-03,  2.0126e-02,  ...,  4.0359e-03,
          3.1776e-03, -4.5227e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:50:05 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-29 19:50:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1450,  0.4431,  0.7412,  ..., -0.0305, -0.2959,  1.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3660, -0.9150, -0.2224,  ..., -0.6118, -0.5078,  0.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5757,  1.9766,  3.6270,  ..., -0.0249, -1.3408,  3.9492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.8281, -4.3945,  0.9873,  ..., -1.1719, -1.5918,  0.4507],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:50:05 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:50:05 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 19:51:29 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 19:52:54 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 19:54:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.0844e-03,  1.7273e-04, -2.7895e-04,  ...,  4.5624e-03,
          1.9093e-03,  3.8223e-03],
        [-2.6474e-03,  5.5885e-03, -5.3711e-03,  ..., -5.3167e-04,
          8.3387e-05, -1.1511e-03],
        [ 4.5466e-04, -8.5545e-04,  8.6899e-03,  ..., -5.3978e-04,
         -5.6386e-05, -1.3762e-03],
        ...,
        [-3.8028e-05, -1.9131e-03,  1.0490e-03,  ...,  6.2141e-03,
          1.8702e-03,  1.6427e-04],
        [ 5.4932e-04,  3.2864e-03, -1.2188e-03,  ...,  2.8324e-03,
          5.5847e-03, -2.2964e-03],
        [ 8.2159e-04, -3.0575e-03, -1.8158e-03,  ..., -3.3903e-04,
          5.0354e-04,  7.7324e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0274,  0.0181,  0.0020,  ...,  0.0037, -0.0206,  0.0096],
        [ 0.0042, -0.0077,  0.0158,  ..., -0.0043, -0.0081,  0.0084],
        [ 0.0061,  0.0023,  0.0214,  ..., -0.0040, -0.0101,  0.0048],
        ...,
        [-0.0132,  0.0018,  0.0057,  ...,  0.0251, -0.0007,  0.0012],
        [-0.0033, -0.0059, -0.0070,  ...,  0.0221,  0.0324, -0.0198],
        [ 0.0079, -0.0086, -0.0156,  ..., -0.0149,  0.0052,  0.0250]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0245, -0.0069,  0.0095,  ..., -0.0037, -0.0006,  0.0170],
        [ 0.0095, -0.0689, -0.0135,  ..., -0.0209, -0.0192,  0.0157],
        [-0.0037, -0.0047, -0.0314,  ...,  0.0073,  0.0140,  0.0052],
        ...,
        [-0.0023, -0.0074,  0.0071,  ..., -0.0466, -0.0001,  0.0042],
        [-0.0162, -0.0055, -0.0305,  ...,  0.0149, -0.0385, -0.0146],
        [ 0.0089,  0.0129,  0.0085,  ..., -0.0022,  0.0196, -0.0397]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:54:21 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-29 19:54:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1805,  0.6802,  0.8765,  ..., -0.2964, -0.4055,  1.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5659, -1.2891,  0.1232,  ..., -0.6885, -0.3804,  0.2739],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4731,  3.5352,  3.5566,  ..., -0.4395, -0.7734,  4.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.4141, -3.6680,  1.3535,  ..., -0.6748, -0.7354,  0.0696],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:54:21 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:54:21 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 19:55:47 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 19:57:11 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 19:58:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.3746e-03, -1.0529e-03,  6.2037e-04,  ...,  2.9421e-04,
          3.8004e-04,  2.8038e-04],
        [-5.3024e-04,  1.5345e-03,  2.7657e-04,  ..., -7.0620e-04,
          2.9802e-07, -1.6403e-04],
        [ 6.4659e-04, -6.0606e-04,  2.6703e-03,  ...,  1.7130e-04,
          6.4468e-04, -4.6682e-04],
        ...,
        [ 4.7350e-04,  6.2561e-04, -1.2007e-03,  ...,  1.5955e-03,
          6.0701e-04,  5.5075e-05],
        [ 1.4677e-03, -6.5756e-04,  7.9584e-04,  ...,  6.5088e-04,
          2.1534e-03, -4.7946e-04],
        [ 7.0238e-04, -4.0960e-04, -1.1325e-05,  ...,  4.0054e-04,
          5.5969e-05,  2.1019e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0175, -0.0110,  0.0094,  ..., -0.0062, -0.0123,  0.0117],
        [-0.0148, -0.0358,  0.0176,  ..., -0.0026,  0.0022, -0.0253],
        [-0.0103, -0.0038, -0.0187,  ...,  0.0179,  0.0062,  0.0203],
        ...,
        [ 0.0019,  0.0172, -0.0066,  ..., -0.0254,  0.0130,  0.0082],
        [-0.0061, -0.0104,  0.0035,  ...,  0.0091, -0.0251,  0.0092],
        [ 0.0141,  0.0065,  0.0060,  ...,  0.0048, -0.0198,  0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0104, -0.0029,  0.0047,  ...,  0.0010,  0.0213, -0.0096],
        [-0.0010, -0.0266,  0.0061,  ...,  0.0082,  0.0156, -0.0150],
        [ 0.0145,  0.0033, -0.0195,  ...,  0.0226, -0.0117,  0.0004],
        ...,
        [-0.0130,  0.0125, -0.0030,  ..., -0.0430,  0.0089, -0.0077],
        [ 0.0065, -0.0042, -0.0017,  ...,  0.0177, -0.0549, -0.0137],
        [ 0.0227, -0.0039, -0.0083,  ...,  0.0144, -0.0020, -0.0140]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 19:58:35 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-29 19:58:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1182,  0.5776,  0.9419,  ..., -0.1053, -0.4089,  1.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8418, -1.2891,  0.2146,  ..., -0.4561, -0.5151,  0.0839],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0645,  3.3418,  2.1992,  ..., -1.1533, -0.8037,  3.9961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0840, -3.6211, -0.3584,  ..., -1.9580, -1.2461, -1.5625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 19:58:35 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 19:58:35 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 20:00:04 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 20:01:32 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 20:02:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1093e-02, -1.8740e-04, -3.1590e-06,  ..., -7.1192e-04,
         -5.3501e-04, -8.6260e-04],
        [ 3.0003e-03,  9.0866e-03,  1.5230e-03,  ...,  5.1832e-04,
          1.9970e-03,  2.2054e-04],
        [ 2.4223e-03, -2.5253e-03,  1.1360e-02,  ...,  6.5267e-05,
         -1.9131e-03, -1.0414e-03],
        ...,
        [-8.8978e-04, -9.5749e-04,  6.2323e-04,  ...,  1.4854e-02,
         -1.0319e-03, -1.2388e-03],
        [-2.0485e-03, -2.5821e-04, -4.6825e-04,  ...,  1.4019e-04,
          1.2070e-02, -1.4400e-04],
        [ 1.9007e-03,  1.5230e-03, -5.5838e-04,  ...,  9.3889e-04,
         -1.0910e-03,  1.3924e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0010, -0.0125, -0.0005,  ...,  0.0104,  0.0087,  0.0054],
        [ 0.0018, -0.0155, -0.0193,  ..., -0.0017,  0.0198,  0.0010],
        [-0.0173,  0.0063, -0.0237,  ..., -0.0141,  0.0023,  0.0083],
        ...,
        [-0.0113, -0.0074, -0.0031,  ..., -0.0082, -0.0141, -0.0045],
        [-0.0087, -0.0054, -0.0087,  ...,  0.0335, -0.0091,  0.0033],
        [-0.0089,  0.0271, -0.0010,  ...,  0.0024, -0.0060, -0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0178, -0.0073, -0.0018,  ...,  0.0090,  0.0042,  0.0131],
        [ 0.0014, -0.0284, -0.0070,  ...,  0.0236,  0.0140,  0.0037],
        [-0.0046, -0.0102,  0.0050,  ..., -0.0242,  0.0258,  0.0188],
        ...,
        [-0.0145,  0.0057, -0.0074,  ...,  0.0056,  0.0290,  0.0125],
        [-0.0022, -0.0182, -0.0107,  ...,  0.0217, -0.0054, -0.0105],
        [ 0.0004,  0.0066,  0.0084,  ...,  0.0138,  0.0047, -0.0042]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:03:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a painting is watercolor
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a weapon is gun
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a weekday is monday
A more specific term for a bed is
2024-06-29 20:03:01 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 20:03:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9990, -0.8115, -0.3359,  ...,  0.2886, -1.0098,  0.7056],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0319,  0.1340,  0.1918,  ...,  0.2371, -0.1478, -0.1470],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7153, -0.8125, -0.3420,  ...,  0.5669, -1.1006,  0.8379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0746,  0.4597, -0.0696,  ...,  0.0615, -0.2450,  0.3662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:03:01 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:03:01 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 20:03:24 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 20:03:47 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 20:04:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.9547e-03,  1.6661e-03, -3.2120e-03,  ..., -1.6851e-03,
          1.0691e-03, -2.7103e-03],
        [-6.7806e-04, -9.5291e-03,  2.5511e-04,  ...,  2.1057e-03,
         -1.3571e-03,  1.4997e-04],
        [-1.4935e-03, -6.4468e-04, -1.0735e-02,  ..., -1.4381e-03,
         -1.7185e-03,  6.6566e-04],
        ...,
        [ 1.3533e-03, -6.5923e-05,  8.5115e-05,  ..., -9.7351e-03,
          9.0933e-04, -8.3065e-04],
        [ 3.9124e-04,  1.6289e-03,  1.0309e-03,  ..., -1.7567e-03,
         -7.9956e-03,  1.9350e-03],
        [ 9.1124e-04, -5.9080e-04,  3.3236e-04,  ...,  8.0168e-05,
          2.2292e-05, -6.4430e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.8025e-02,  6.9618e-05,  3.2463e-03,  ...,  2.3880e-03,
         -5.5885e-03, -9.9411e-03],
        [-8.8425e-03, -4.2175e-02,  5.1804e-03,  ..., -2.3022e-03,
          6.5041e-04,  8.5602e-03],
        [-3.2234e-04, -4.8904e-03, -3.8727e-02,  ..., -5.4836e-04,
          3.9368e-03,  1.5831e-03],
        ...,
        [-3.8643e-03,  4.3182e-03, -4.1847e-03,  ..., -4.0527e-02,
          1.0109e-03, -2.6054e-03],
        [-1.4992e-03, -1.4400e-04,  5.1994e-03,  ..., -2.7046e-03,
         -4.0771e-02, -4.4022e-03],
        [ 5.2376e-03,  1.8177e-03,  2.6817e-03,  ...,  6.3171e-03,
          1.1063e-04, -3.4912e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0447,  0.0043,  0.0017,  ..., -0.0035,  0.0016, -0.0061],
        [ 0.0016, -0.0462,  0.0013,  ...,  0.0014,  0.0022, -0.0004],
        [-0.0055,  0.0007, -0.0381,  ..., -0.0053, -0.0047, -0.0032],
        ...,
        [ 0.0013,  0.0002, -0.0044,  ..., -0.0467,  0.0027, -0.0014],
        [-0.0033, -0.0006,  0.0006,  ...,  0.0010, -0.0435,  0.0005],
        [-0.0005, -0.0015, -0.0054,  ...,  0.0047, -0.0004, -0.0421]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:04:13 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-29 20:04:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6758, -0.6499, -0.6499,  ...,  0.2313, -1.0107,  0.8086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1682,  0.1105,  0.1049,  ..., -0.0588, -0.2015, -0.0810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7759, -0.7202, -0.2952,  ...,  0.4565, -1.0771,  0.6323],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2056,  0.3020,  0.1479,  ..., -0.1311, -0.2351,  0.4685],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:04:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:04:13 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 20:04:37 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 20:05:00 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 20:05:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3130e-02, -5.8098e-03, -2.5539e-03,  ...,  5.1231e-03,
         -2.7695e-03,  9.5987e-04],
        [ 2.8496e-03, -1.1139e-02,  2.0008e-03,  ...,  4.9744e-03,
         -5.4550e-04,  1.0109e-04],
        [-1.7586e-03,  5.8746e-04, -6.2485e-03,  ...,  2.6560e-04,
         -9.9850e-04, -1.3275e-03],
        ...,
        [ 1.7643e-05, -5.6028e-04, -2.4376e-03,  ..., -7.3395e-03,
         -1.9341e-03, -2.7428e-03],
        [ 6.9523e-04,  4.2686e-03,  2.1706e-03,  ..., -4.9496e-04,
         -9.5901e-03,  2.0542e-03],
        [ 2.6760e-03, -2.8305e-03,  1.9836e-04,  ..., -2.3689e-03,
          5.4598e-04, -1.0040e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0458,  0.0082,  0.0020,  ...,  0.0061, -0.0069,  0.0087],
        [ 0.0081, -0.0519,  0.0029,  ...,  0.0086,  0.0012,  0.0139],
        [-0.0052,  0.0012, -0.0438,  ..., -0.0020, -0.0007,  0.0066],
        ...,
        [-0.0055, -0.0024, -0.0058,  ..., -0.0466, -0.0111,  0.0054],
        [-0.0018,  0.0051,  0.0066,  ..., -0.0108, -0.0412,  0.0006],
        [ 0.0017, -0.0021,  0.0059,  ...,  0.0059, -0.0066, -0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.6711e-02,  5.5237e-03, -1.5068e-03,  ..., -4.6349e-03,
          2.4261e-03, -1.0391e-02],
        [-1.2407e-03, -7.3975e-02, -4.1771e-03,  ..., -2.7466e-03,
         -4.8485e-03, -3.3903e-04],
        [-1.1063e-03,  2.8992e-03, -6.5979e-02,  ..., -7.2479e-03,
          6.4545e-03, -2.1744e-03],
        ...,
        [-9.5367e-06,  5.0964e-03, -1.6794e-03,  ..., -6.8665e-02,
         -3.1166e-03,  1.9836e-03],
        [-7.1335e-03, -1.0162e-02,  3.5229e-03,  ...,  4.3221e-03,
         -7.0068e-02,  3.0804e-03],
        [-4.1924e-03,  6.5327e-04,  6.0806e-03,  ...,  2.2650e-05,
          1.2627e-03, -6.6772e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:05:26 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-29 20:05:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8145, -1.0020, -0.4077,  ...,  0.6265, -1.2715,  0.9810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1305,  0.6948, -0.1055,  ...,  0.0928, -0.3633,  0.5522],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7236, -0.8027, -0.7783,  ...,  0.8340, -1.2314,  1.1895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5557,  0.2329, -0.0981,  ..., -0.1465, -0.6289,  0.8818],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:05:26 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:05:26 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 20:05:52 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 20:06:17 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 20:06:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0170e-02,  1.4286e-03, -1.5297e-03,  ..., -1.0910e-03,
         -2.0485e-03, -7.2575e-04],
        [ 1.6317e-03, -8.4457e-03,  2.0719e-04,  ...,  6.3753e-04,
          1.5936e-03,  3.8028e-04],
        [ 2.3155e-03, -1.8568e-03, -6.4087e-03,  ..., -1.1635e-03,
          1.1330e-03, -2.6035e-04],
        ...,
        [ 1.4086e-03,  6.2609e-04, -5.4646e-04,  ..., -8.8425e-03,
          2.5177e-03,  4.9496e-04],
        [-3.9577e-05,  2.6178e-04, -6.3896e-04,  ...,  4.8828e-04,
         -6.9618e-03,  5.2452e-05],
        [ 1.7185e-03,  6.7055e-05,  1.4095e-03,  ...,  1.3123e-03,
         -6.1989e-04, -9.1858e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0436,  0.0032, -0.0011,  ...,  0.0097, -0.0036,  0.0008],
        [-0.0048, -0.0418,  0.0007,  ..., -0.0026,  0.0046, -0.0058],
        [ 0.0057,  0.0011, -0.0428,  ..., -0.0013,  0.0095,  0.0046],
        ...,
        [ 0.0051,  0.0034, -0.0123,  ..., -0.0313, -0.0001,  0.0023],
        [ 0.0002, -0.0062, -0.0063,  ...,  0.0012, -0.0393, -0.0022],
        [-0.0040,  0.0080, -0.0036,  ..., -0.0026,  0.0004, -0.0366]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0384,  0.0034,  0.0005,  ...,  0.0067,  0.0020, -0.0022],
        [-0.0058, -0.0385,  0.0122,  ...,  0.0066, -0.0082, -0.0048],
        [ 0.0101,  0.0038, -0.0274,  ..., -0.0047,  0.0023,  0.0044],
        ...,
        [ 0.0038,  0.0051, -0.0034,  ..., -0.0378, -0.0018,  0.0033],
        [-0.0097,  0.0050, -0.0019,  ...,  0.0025, -0.0333,  0.0013],
        [-0.0018,  0.0021,  0.0026,  ..., -0.0020,  0.0105, -0.0357]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:06:44 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-29 20:06:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8833, -0.8838, -0.3401,  ...,  0.5049, -1.2490,  0.7124],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3298,  0.4365,  0.2206,  ..., -0.1791, -0.3564,  0.6836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4602, -1.2959, -0.6279,  ...,  1.1895, -0.8174,  1.1553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7236,  0.5234, -0.1689,  ..., -0.7310,  0.1167,  0.8525],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:06:44 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:06:44 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 20:07:14 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 20:07:44 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 20:08:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.5204e-03,  5.6076e-04, -1.0071e-03,  ...,  6.2466e-04,
         -3.4475e-04,  1.0386e-03],
        [ 1.0834e-03, -5.3711e-03, -2.7752e-04,  ..., -1.9054e-03,
          1.7643e-05,  1.6570e-05],
        [-1.9569e-03, -1.7393e-04, -3.6926e-03,  ...,  6.8712e-04,
          1.7500e-03,  1.0228e-04],
        ...,
        [ 5.1975e-05, -1.8559e-03,  2.0742e-04,  ..., -3.9444e-03,
          5.0831e-04, -3.8147e-04],
        [-1.0834e-03, -1.2035e-03,  1.2646e-03,  ..., -1.4334e-03,
         -5.5161e-03,  6.7663e-04],
        [ 1.3437e-03, -2.6989e-03, -1.8263e-04,  ...,  1.7524e-04,
         -7.0572e-04, -7.9041e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0579,  0.0023, -0.0089,  ...,  0.0016,  0.0018,  0.0037],
        [-0.0031, -0.0600,  0.0014,  ...,  0.0045,  0.0002,  0.0021],
        [-0.0049, -0.0058, -0.0392,  ...,  0.0066, -0.0001,  0.0071],
        ...,
        [ 0.0031,  0.0014, -0.0015,  ..., -0.0426, -0.0032, -0.0033],
        [-0.0053,  0.0030, -0.0022,  ..., -0.0033, -0.0450,  0.0052],
        [-0.0039, -0.0043, -0.0049,  ...,  0.0047, -0.0008, -0.0546]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0567,  0.0022,  0.0025,  ..., -0.0038, -0.0028,  0.0042],
        [ 0.0079, -0.0578, -0.0074,  ..., -0.0033,  0.0064, -0.0048],
        [ 0.0068, -0.0100, -0.0649,  ...,  0.0019,  0.0002,  0.0073],
        ...,
        [ 0.0028,  0.0018,  0.0019,  ..., -0.0584, -0.0060, -0.0062],
        [ 0.0039,  0.0006, -0.0072,  ..., -0.0065, -0.0606, -0.0051],
        [ 0.0014,  0.0023, -0.0028,  ...,  0.0040, -0.0032, -0.0569]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:08:16 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-29 20:08:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6802, -0.8677, -0.7314,  ...,  0.7495, -1.1826,  1.1533],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5874,  0.2095, -0.0916,  ..., -0.1501, -0.6274,  0.9189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6157, -1.2188, -0.2070,  ...,  1.3047, -1.0234,  1.6377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9424,  0.2166, -0.0344,  ..., -0.7646, -0.1133,  0.9199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:08:16 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:08:16 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 20:08:50 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 20:09:23 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 20:09:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2283e-03,  2.9945e-03, -2.1291e-04,  ...,  6.0921e-03,
         -4.1628e-04,  1.8559e-03],
        [ 9.8288e-05,  3.2482e-03,  5.3120e-04,  ...,  2.7256e-03,
         -7.5197e-04,  2.5749e-03],
        [ 2.6774e-04,  2.7065e-03, -2.0638e-03,  ...,  2.5678e-04,
         -8.2588e-04,  5.3596e-04],
        ...,
        [-8.4877e-04,  2.1858e-03, -1.1511e-03,  ..., -2.6817e-03,
         -1.5984e-03,  6.6710e-04],
        [ 1.2159e-03,  9.2268e-04, -8.7357e-04,  ...,  8.2302e-04,
          2.8000e-03, -6.7949e-06],
        [-7.9012e-04, -1.7195e-03, -1.8775e-04,  ..., -1.3304e-03,
         -1.9703e-03,  1.8177e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0762,  0.0043,  0.0004,  ...,  0.0010,  0.0068, -0.0004],
        [ 0.0097, -0.0757, -0.0093,  ...,  0.0100,  0.0005,  0.0117],
        [-0.0075,  0.0050, -0.0844,  ..., -0.0024,  0.0113, -0.0007],
        ...,
        [-0.0007, -0.0034, -0.0110,  ..., -0.0704, -0.0038,  0.0071],
        [ 0.0187, -0.0033, -0.0029,  ...,  0.0127, -0.0825,  0.0143],
        [-0.0154,  0.0065,  0.0027,  ..., -0.0020,  0.0013, -0.0894]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1194, -0.0063,  0.0044,  ..., -0.0075, -0.0020, -0.0015],
        [-0.0022, -0.1095,  0.0040,  ..., -0.0058, -0.0072,  0.0004],
        [ 0.0015,  0.0029, -0.1029,  ..., -0.0018,  0.0096,  0.0004],
        ...,
        [-0.0049, -0.0032, -0.0022,  ..., -0.0968,  0.0067, -0.0032],
        [ 0.0014,  0.0012, -0.0071,  ..., -0.0053, -0.1160,  0.0105],
        [-0.0124,  0.0035,  0.0018,  ...,  0.0006, -0.0085, -0.1126]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:09:57 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-29 20:09:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4062, -1.2178, -0.5552,  ...,  1.0254, -0.7485,  1.0332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7720,  0.5581, -0.1793,  ..., -0.7388,  0.1077,  0.9067],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8071, -1.6875, -0.6270,  ...,  1.4551, -1.3945,  1.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9209,  0.3364, -0.1246,  ..., -0.4202,  0.0029,  0.2549],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:09:57 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:09:57 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 20:10:32 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 20:11:08 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 20:11:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.4398e-03, -3.4122e-03,  5.2071e-03,  ..., -1.7996e-03,
          1.1930e-03, -6.1893e-04],
        [ 2.3994e-03, -6.0997e-03,  5.8098e-03,  ...,  1.8921e-03,
          9.5367e-06,  3.0994e-05],
        [-1.1444e-04,  2.7370e-03, -2.9812e-03,  ...,  3.3736e-04,
         -8.5163e-04, -1.7061e-03],
        ...,
        [ 1.1520e-03, -1.9989e-03, -3.3188e-03,  ..., -9.3699e-05,
         -2.3193e-03, -1.1692e-03],
        [ 3.5114e-03,  9.1696e-04,  4.2295e-04,  ..., -6.2599e-03,
         -5.3520e-03, -1.4629e-03],
        [ 3.1319e-03, -3.4409e-03,  3.1776e-03,  ..., -5.1575e-03,
         -4.2915e-03, -3.3588e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0742, -0.0018,  0.0136,  ..., -0.0051, -0.0018, -0.0067],
        [ 0.0084, -0.0729, -0.0035,  ...,  0.0035,  0.0083, -0.0050],
        [ 0.0119,  0.0025, -0.0787,  ...,  0.0052, -0.0021,  0.0100],
        ...,
        [ 0.0078,  0.0079,  0.0102,  ..., -0.0840,  0.0010,  0.0051],
        [-0.0119,  0.0061,  0.0181,  ...,  0.0022, -0.0818, -0.0028],
        [-0.0086,  0.0090,  0.0094,  ..., -0.0136, -0.0041, -0.0867]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2122e-01,  5.7793e-03, -1.4366e-02,  ...,  4.4861e-03,
          4.9858e-03, -3.8376e-03],
        [-1.2312e-03, -1.2585e-01, -8.5297e-03,  ...,  4.5700e-03,
         -8.0872e-04,  7.3166e-03],
        [-2.8419e-03,  4.8485e-03, -1.1859e-01,  ...,  2.3861e-03,
          2.6512e-03,  3.2005e-03],
        ...,
        [ 5.3215e-03,  6.8092e-04,  9.8190e-03,  ..., -1.2177e-01,
         -7.6294e-05,  2.0027e-04],
        [ 2.8057e-03,  4.3201e-04, -2.6398e-03,  ...,  7.8812e-03,
         -1.1597e-01, -5.8556e-04],
        [-7.2517e-03,  6.5193e-03, -2.9278e-03,  ..., -1.5884e-02,
          5.5923e-03, -1.1865e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:11:46 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-29 20:11:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4985, -1.0273, -0.1842,  ...,  0.9775, -0.8433,  1.3418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9224,  0.2310, -0.0477,  ..., -0.7251, -0.1124,  0.8877],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0703, -1.0781, -1.2012,  ...,  0.9810, -1.3467,  1.7803],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5293,  0.0305, -0.5601,  ..., -0.5938, -0.1357,  0.3794],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:11:46 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:11:46 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 20:12:25 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 20:12:51 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 20:13:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1885e-03,  1.5211e-03, -1.8997e-03,  ...,  2.1133e-03,
         -1.6136e-03,  2.1324e-03],
        [ 3.0975e-03,  1.6165e-03, -2.2583e-03,  ...,  3.4885e-03,
          4.0245e-03, -1.2579e-03],
        [ 2.4414e-03, -3.0193e-03, -3.1147e-03,  ..., -3.1586e-03,
         -4.8943e-03,  1.7796e-03],
        ...,
        [ 1.0777e-03, -2.4986e-03,  2.3403e-03,  ..., -6.8855e-03,
         -2.8210e-03,  2.9545e-03],
        [-4.7264e-03,  8.1205e-04, -2.3727e-03,  ...,  4.8943e-03,
          2.4014e-03,  7.5626e-04],
        [ 3.7527e-04, -1.7939e-03,  1.5259e-05,  ..., -3.0327e-03,
          9.2926e-03, -1.4925e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0984, -0.0004, -0.0090,  ...,  0.0059,  0.0078,  0.0091],
        [ 0.0049, -0.0807,  0.0002,  ..., -0.0046,  0.0043,  0.0102],
        [-0.0015, -0.0026, -0.0740,  ..., -0.0041, -0.0081, -0.0117],
        ...,
        [ 0.0025, -0.0009,  0.0032,  ..., -0.0770, -0.0037,  0.0097],
        [ 0.0139, -0.0040, -0.0067,  ...,  0.0042, -0.0851, -0.0095],
        [ 0.0011, -0.0026,  0.0204,  ..., -0.0027,  0.0015, -0.0924]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1517e-01, -4.2191e-03,  5.5847e-03,  ..., -1.0063e-02,
         -5.3692e-04,  5.0316e-03],
        [-1.0014e-04, -1.0309e-01, -7.9803e-03,  ...,  2.3670e-03,
         -7.8125e-03,  4.4098e-03],
        [ 1.1101e-02,  2.9411e-03, -9.4116e-02,  ..., -9.1934e-04,
          5.6152e-03, -7.7629e-03],
        ...,
        [-1.8372e-02, -1.9121e-04, -6.5308e-03,  ..., -1.1908e-01,
          6.8474e-03,  2.2507e-03],
        [ 1.2451e-02,  4.8676e-03, -3.8757e-03,  ...,  1.1971e-02,
         -1.0730e-01, -1.6804e-03],
        [ 9.1019e-03, -7.7515e-03,  6.1722e-03,  ...,  7.2975e-03,
          2.4757e-03, -1.2433e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:13:27 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-29 20:13:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5938, -1.2939, -0.4521,  ...,  0.9849, -1.0049,  0.8276],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8296,  0.3062, -0.1161,  ..., -0.3530, -0.0026,  0.2150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4351, -1.1270, -0.9600,  ...,  0.7295, -1.6641,  2.0762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5034, -0.2520, -0.5952,  ..., -0.9702, -0.1580,  0.3818],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:13:27 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:13:27 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 20:14:08 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 20:14:49 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 20:15:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.7406e-03, -1.7738e-03, -4.0054e-03,  ...,  1.1578e-03,
          1.1864e-03, -6.1836e-03],
        [-1.0061e-03, -6.3095e-03,  2.8591e-03,  ..., -1.8082e-03,
          2.3212e-03, -4.2572e-03],
        [ 2.4891e-03,  3.1967e-03, -7.7400e-03,  ..., -2.7428e-03,
          2.2163e-03, -3.5691e-04],
        ...,
        [-3.0613e-03, -8.5354e-04, -2.3079e-03,  ..., -5.0659e-03,
         -7.6294e-04,  1.6413e-03],
        [ 2.3861e-03,  6.0201e-05,  1.8549e-04,  ..., -2.1858e-03,
         -8.2016e-03,  3.5858e-03],
        [ 5.3940e-03,  4.5433e-03, -1.0242e-03,  ..., -2.9850e-04,
         -5.9605e-06, -5.3787e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0917, -0.0016, -0.0024,  ..., -0.0142, -0.0188,  0.0069],
        [-0.0048, -0.1086, -0.0106,  ..., -0.0100,  0.0075,  0.0036],
        [ 0.0070,  0.0039, -0.0845,  ...,  0.0062, -0.0081, -0.0007],
        ...,
        [-0.0157, -0.0042,  0.0024,  ..., -0.0869,  0.0031, -0.0026],
        [-0.0061, -0.0015, -0.0033,  ...,  0.0099, -0.1034, -0.0018],
        [ 0.0183,  0.0090, -0.0073,  ...,  0.0057, -0.0062, -0.1037]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1372,  0.0063,  0.0030,  ..., -0.0191, -0.0063,  0.0031],
        [ 0.0046, -0.1389,  0.0089,  ..., -0.0125, -0.0022,  0.0058],
        [-0.0025,  0.0032, -0.1260,  ..., -0.0004, -0.0116,  0.0124],
        ...,
        [-0.0098,  0.0075, -0.0082,  ..., -0.1250,  0.0071, -0.0097],
        [-0.0088,  0.0114, -0.0128,  ..., -0.0082, -0.1260,  0.0103],
        [-0.0121, -0.0108, -0.0088,  ..., -0.0042,  0.0053, -0.1332]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:15:30 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-29 20:15:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6440, -0.6899, -0.7666,  ...,  0.5464, -0.8301,  1.1064],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4563,  0.0238, -0.4915,  ..., -0.4773, -0.1230,  0.3042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5527, -0.7505, -0.4819,  ...,  0.6504, -1.8594,  1.2119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2524, -0.7905, -0.2563,  ..., -1.1572, -0.0694,  0.1733],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:15:30 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:15:30 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 20:16:19 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 20:17:06 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 20:17:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.4899e-03,  1.0271e-03,  1.3638e-03,  ..., -6.6261e-03,
         -1.5998e-04,  1.5707e-03],
        [ 4.5280e-03, -6.8359e-03, -4.6616e-03,  ..., -4.8523e-03,
         -5.6076e-03, -1.4553e-03],
        [-6.6147e-03,  4.3068e-03,  4.4785e-03,  ..., -7.8976e-05,
         -2.7618e-03,  3.2024e-03],
        ...,
        [ 3.1834e-03, -8.1635e-03,  2.1152e-03,  ...,  3.7975e-03,
         -5.0507e-03,  1.9197e-03],
        [-4.3716e-03, -2.9683e-04,  8.3923e-03,  ...,  3.8509e-03,
         -2.9354e-03, -6.7520e-04],
        [-1.7166e-04, -3.0899e-03,  3.1242e-03,  ..., -6.0692e-03,
          4.9820e-03,  6.1340e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1203, -0.0161, -0.0073,  ..., -0.0077,  0.0199, -0.0044],
        [ 0.0135, -0.1267, -0.0079,  ...,  0.0066, -0.0093,  0.0058],
        [ 0.0027, -0.0109, -0.1060,  ...,  0.0107, -0.0037, -0.0161],
        ...,
        [ 0.0120,  0.0163,  0.0173,  ..., -0.1237,  0.0073,  0.0071],
        [ 0.0079,  0.0037,  0.0029,  ..., -0.0027, -0.1283,  0.0113],
        [ 0.0002,  0.0043,  0.0027,  ..., -0.0087,  0.0148, -0.0948]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.9751e-01, -6.7291e-03,  1.9073e-05,  ...,  8.3542e-04,
          3.7193e-03, -2.0523e-03],
        [-4.1199e-03, -2.0251e-01, -9.1705e-03,  ...,  5.8746e-03,
          8.9569e-03,  1.3710e-02],
        [-8.6670e-03, -3.7308e-03, -1.6760e-01,  ..., -3.8986e-03,
         -9.9564e-04, -1.0941e-02],
        ...,
        [ 5.7716e-03, -1.4725e-03, -2.9068e-03,  ..., -1.9275e-01,
         -8.8806e-03,  9.8877e-03],
        [ 1.7700e-02, -3.6087e-03,  9.0256e-03,  ...,  3.2043e-04,
         -1.9312e-01, -1.7395e-02],
        [-1.5602e-03,  8.6670e-03,  1.5230e-03,  ..., -5.0926e-03,
         -9.2239e-03, -1.7700e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:17:57 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-29 20:17:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2477, -0.6631, -0.5591,  ...,  0.3962, -0.9375,  1.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3899, -0.2144, -0.4814,  ..., -0.7061, -0.1350,  0.2627],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9805, -0.8994,  0.2183,  ...,  0.0088, -2.1406,  1.5664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3276, -0.9810,  0.1655,  ..., -1.0098,  0.1738,  1.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:17:57 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:17:57 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 20:18:46 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 20:19:36 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 20:20:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.5820e-03,  5.5790e-05, -4.9782e-04,  ...,  2.0695e-03,
          3.1223e-03,  3.3092e-03],
        [-3.9101e-03, -3.2330e-03,  2.3899e-03,  ...,  6.5155e-03,
          2.6016e-03,  1.0319e-03],
        [ 1.3943e-03,  2.2221e-03, -6.2256e-03,  ...,  6.8665e-05,
         -6.3286e-03,  1.2302e-04],
        ...,
        [ 3.3455e-03, -1.4305e-03,  5.6534e-03,  ..., -5.2986e-03,
         -3.1948e-03,  1.0386e-03],
        [ 7.1383e-04, -6.6376e-03,  2.6245e-03,  ...,  1.1740e-03,
         -9.2163e-03,  5.4550e-03],
        [-1.9188e-03,  4.2458e-03, -3.4904e-03,  ...,  3.1204e-03,
          2.2755e-03, -7.6218e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1163e-01,  9.2010e-03,  2.5215e-03,  ..., -5.8174e-03,
         -3.4275e-03,  1.8635e-03],
        [ 5.6076e-04, -1.0889e-01,  2.0981e-04,  ...,  7.1049e-04,
         -3.7937e-03, -1.0269e-02],
        [ 6.8855e-04, -1.9121e-03, -1.1737e-01,  ...,  8.2779e-03,
          9.9335e-03,  3.8671e-04],
        ...,
        [ 3.5706e-03,  4.3488e-04,  1.5388e-02,  ..., -9.2529e-02,
          1.0109e-04, -8.0490e-03],
        [ 9.8419e-03,  9.0942e-03,  2.6703e-03,  ...,  1.9989e-02,
         -1.0895e-01,  3.6278e-03],
        [ 7.2174e-03,  2.8000e-03,  1.6479e-03,  ...,  4.6730e-03,
         -3.6850e-03, -1.1749e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1256,  0.0043, -0.0026,  ..., -0.0003,  0.0044, -0.0107],
        [ 0.0073, -0.1142,  0.0064,  ...,  0.0038, -0.0088, -0.0036],
        [ 0.0013, -0.0037, -0.1199,  ...,  0.0064, -0.0074, -0.0039],
        ...,
        [-0.0011, -0.0035,  0.0109,  ..., -0.1158,  0.0068, -0.0143],
        [-0.0040,  0.0035, -0.0171,  ...,  0.0102, -0.1165,  0.0121],
        [ 0.0036,  0.0030, -0.0054,  ...,  0.0008,  0.0018, -0.1315]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:20:24 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-29 20:20:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2771, -0.4299, -0.2915,  ...,  0.2913, -0.9873,  0.6528],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1899, -0.5811, -0.2141,  ..., -0.7993, -0.0671,  0.1261],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7246, -1.0615, -0.6108,  ...,  0.4351, -1.9688,  2.1992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4604, -0.5376,  0.2549,  ..., -0.9019,  0.6196,  0.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:20:24 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:20:24 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 20:21:18 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 20:22:10 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 20:23:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.3302e-03, -3.6025e-04,  4.2648e-03,  ...,  2.1744e-03,
         -5.6763e-03,  4.2267e-03],
        [ 4.1199e-03,  3.4332e-04,  1.6117e-03,  ...,  1.1082e-03,
          1.5354e-03,  3.0174e-03],
        [-2.5291e-03, -4.4937e-03,  4.3869e-03,  ..., -6.7673e-03,
          4.1809e-03,  9.0122e-04],
        ...,
        [ 1.6603e-03,  7.5674e-04,  6.1340e-03,  ...,  6.0120e-03,
         -5.5008e-03,  6.9160e-03],
        [-4.9591e-03, -5.7640e-03,  1.3113e-04,  ..., -1.7843e-03,
          1.1879e-02,  2.6207e-03],
        [-1.2951e-03,  2.0180e-03, -3.3069e-04,  ...,  5.9962e-05,
         -1.6747e-03,  5.1651e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.8799e-01, -1.1063e-04,  6.8245e-03,  ..., -4.1199e-03,
          2.5406e-03,  9.6893e-04],
        [ 3.6659e-03, -1.7053e-01,  6.7139e-03,  ..., -3.6621e-03,
         -4.3259e-03, -4.8370e-03],
        [ 4.9553e-03,  4.7989e-03, -1.7871e-01,  ...,  4.6692e-03,
         -1.7700e-02,  6.2141e-03],
        ...,
        [-2.9888e-03, -6.1302e-03,  7.8278e-03,  ..., -1.7065e-01,
          3.1710e-04, -7.9575e-03],
        [-9.9182e-04,  1.2802e-02, -3.9749e-03,  ...,  3.9062e-03,
         -1.7334e-01, -4.7989e-03],
        [ 2.6131e-03, -5.9433e-03, -1.9211e-02,  ..., -1.2207e-02,
          1.1063e-02, -1.8396e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2729,  0.0091,  0.0108,  ...,  0.0049, -0.0130,  0.0010],
        [-0.0030, -0.2703, -0.0010,  ..., -0.0151,  0.0247, -0.0051],
        [ 0.0012,  0.0145, -0.2598,  ...,  0.0104, -0.0029, -0.0138],
        ...,
        [-0.0077,  0.0027, -0.0055,  ..., -0.2646,  0.0229,  0.0090],
        [-0.0114,  0.0097,  0.0007,  ...,  0.0167, -0.2593,  0.0092],
        [ 0.0006, -0.0166, -0.0032,  ..., -0.0033,  0.0014, -0.2668]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:23:06 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-29 20:23:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4985, -0.5068,  0.0579,  ..., -0.0038, -1.1533,  0.8096],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2832, -0.7788,  0.0717,  ..., -0.7690,  0.1242,  0.9854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6030, -0.9561, -0.5815,  ...,  0.3298, -2.5742,  2.7227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3684, -0.9062, -0.2559,  ..., -1.6152,  0.2002,  0.9927],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:23:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:23:06 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 20:24:01 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 20:24:51 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 20:25:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0696e-02,  1.6756e-03, -2.4929e-03,  ...,  2.1267e-03,
          2.8591e-03, -2.0409e-03],
        [-3.4008e-03, -1.3634e-02, -2.6360e-03,  ..., -2.9373e-03,
          7.1287e-05,  1.4610e-03],
        [ 4.3449e-03,  1.7462e-03, -1.0056e-02,  ..., -3.2845e-03,
         -7.4005e-04,  5.5313e-04],
        ...,
        [ 1.2951e-03,  1.0443e-03, -7.6904e-03,  ..., -7.9422e-03,
          1.5898e-03,  1.4782e-03],
        [ 2.9678e-03,  7.3004e-04, -1.6041e-03,  ..., -5.2185e-03,
         -1.0971e-02,  1.6508e-03],
        [-1.2426e-03,  5.3253e-03,  1.5783e-04,  ...,  3.8357e-03,
          1.8940e-03, -9.3689e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1042, -0.0071,  0.0023,  ...,  0.0069, -0.0044, -0.0173],
        [ 0.0109, -0.1059, -0.0089,  ..., -0.0020, -0.0048,  0.0137],
        [-0.0011, -0.0183, -0.0880,  ...,  0.0064, -0.0042,  0.0072],
        ...,
        [-0.0078,  0.0092,  0.0152,  ..., -0.0815,  0.0053, -0.0148],
        [-0.0025, -0.0089, -0.0109,  ..., -0.0028, -0.0836,  0.0201],
        [ 0.0034, -0.0014,  0.0012,  ..., -0.0096,  0.0069, -0.0868]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0966, -0.0003, -0.0051,  ...,  0.0032,  0.0035,  0.0008],
        [ 0.0109, -0.1177, -0.0030,  ..., -0.0064,  0.0082,  0.0019],
        [-0.0051, -0.0227, -0.1127,  ..., -0.0026, -0.0132,  0.0012],
        ...,
        [-0.0014,  0.0015,  0.0077,  ..., -0.0953, -0.0028, -0.0070],
        [ 0.0078,  0.0018, -0.0037,  ...,  0.0117, -0.1087,  0.0125],
        [ 0.0075, -0.0088, -0.0011,  ..., -0.0158,  0.0123, -0.1046]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:25:43 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-29 20:25:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3865, -0.6089, -0.3240,  ...,  0.1971, -1.0371,  1.1592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3513, -0.4363,  0.1672,  ..., -0.6582,  0.4563,  0.4541],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2354, -0.8882, -0.9087,  ...,  0.1694, -2.4277,  3.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3787, -1.0527, -0.1299,  ..., -0.9253, -0.0215,  0.5107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:25:43 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:25:43 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 20:26:40 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 20:27:36 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 20:28:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2657e-02,  4.6873e-04, -5.2490e-03,  ...,  7.5226e-03,
          3.4180e-03,  2.3861e-03],
        [-1.2848e-02,  1.5839e-02,  3.4285e-04,  ..., -3.5048e-05,
         -3.1357e-03, -8.9340e-03],
        [-3.2139e-03, -4.5738e-03,  7.7667e-03,  ..., -2.4395e-03,
         -3.1910e-03,  1.8764e-04],
        ...,
        [ 1.0872e-03, -2.7981e-03,  1.0368e-02,  ...,  1.5160e-02,
         -1.9943e-02,  7.6180e-03],
        [-5.1928e-04,  3.8123e-04,  9.6741e-03,  ...,  7.4100e-04,
          1.5083e-02,  3.6354e-03],
        [ 4.3068e-03,  2.1935e-03, -5.2376e-03,  ..., -9.0790e-03,
         -8.0414e-03,  5.3139e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1108, -0.0113, -0.0045,  ..., -0.0050,  0.0196, -0.0041],
        [ 0.0046, -0.1251, -0.0055,  ..., -0.0073,  0.0036, -0.0021],
        [ 0.0148,  0.0014, -0.1080,  ..., -0.0037, -0.0009, -0.0073],
        ...,
        [-0.0070,  0.0014,  0.0097,  ..., -0.1142,  0.0112, -0.0054],
        [ 0.0069,  0.0135, -0.0039,  ...,  0.0088, -0.1066, -0.0073],
        [ 0.0156,  0.0017, -0.0060,  ..., -0.0051,  0.0127, -0.1204]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1525, -0.0051, -0.0058,  ..., -0.0149,  0.0148, -0.0019],
        [-0.0181, -0.1671, -0.0089,  ..., -0.0005, -0.0067,  0.0092],
        [ 0.0120,  0.0009, -0.1492,  ..., -0.0074,  0.0043, -0.0038],
        ...,
        [ 0.0057, -0.0048,  0.0024,  ..., -0.1351,  0.0065, -0.0007],
        [-0.0039,  0.0109,  0.0012,  ...,  0.0074, -0.1494,  0.0009],
        [ 0.0059,  0.0090,  0.0035,  ..., -0.0019,  0.0089, -0.1444]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:28:34 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-29 20:28:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2639, -0.4856, -0.2969,  ...,  0.1351, -1.2324,  1.2861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2515, -0.5625, -0.1709,  ..., -0.9683,  0.1506,  0.5542],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6592, -1.2275, -0.8774,  ..., -0.1003, -1.7148,  3.1133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1788, -1.1113, -0.6377,  ..., -1.2334,  0.1541, -0.0059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:28:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:28:34 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 20:29:35 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 20:30:37 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 20:31:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0062, -0.0075,  0.0012,  ..., -0.0040, -0.0145, -0.0062],
        [-0.0004,  0.0078, -0.0043,  ..., -0.0010,  0.0044,  0.0042],
        [-0.0104, -0.0033,  0.0108,  ..., -0.0032, -0.0047,  0.0019],
        ...,
        [ 0.0054, -0.0013, -0.0006,  ...,  0.0121, -0.0026,  0.0021],
        [ 0.0020, -0.0023,  0.0012,  ...,  0.0039,  0.0155,  0.0069],
        [-0.0008,  0.0066, -0.0038,  ..., -0.0025,  0.0019,  0.0079]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.8745e-02,  1.0681e-02,  3.9749e-03,  ...,  7.3547e-03,
          6.6605e-03, -4.7913e-03],
        [-1.5686e-02, -1.1517e-01,  1.5320e-02,  ..., -5.1117e-03,
          5.7106e-03, -1.8549e-03],
        [-6.6032e-03,  1.9045e-03, -9.2346e-02,  ...,  3.3188e-03,
          5.7068e-03, -1.2520e-02],
        ...,
        [ 1.8044e-03, -8.9951e-03, -1.2848e-02,  ..., -1.1456e-01,
          7.3738e-03, -4.2114e-03],
        [ 2.3766e-03,  4.0932e-03, -8.2493e-04,  ...,  9.0256e-03,
         -9.5459e-02,  6.1035e-05],
        [ 1.4343e-03, -8.6517e-03,  3.0518e-03,  ..., -8.2779e-03,
          6.5327e-04, -1.0669e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1405,  0.0112,  0.0092,  ..., -0.0140,  0.0115,  0.0066],
        [ 0.0044, -0.1497, -0.0018,  ...,  0.0011,  0.0034,  0.0081],
        [-0.0037, -0.0160, -0.1409,  ..., -0.0056,  0.0056, -0.0038],
        ...,
        [-0.0212, -0.0062, -0.0144,  ..., -0.1564,  0.0102, -0.0227],
        [ 0.0036,  0.0054,  0.0057,  ...,  0.0224, -0.1495, -0.0026],
        [-0.0015, -0.0059, -0.0051,  ..., -0.0177, -0.0125, -0.1455]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:31:39 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-29 20:31:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1009, -0.4502, -0.4028,  ...,  0.0598, -1.1084,  1.4492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2317, -0.6475, -0.0707,  ..., -0.5366, -0.0065,  0.2664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3779, -1.4521, -1.0645,  ...,  0.3525, -1.6104,  3.5527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3562, -1.9502, -1.1182,  ..., -0.9009, -0.3538, -0.1036],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:31:39 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:31:39 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 20:32:42 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 20:33:44 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 20:34:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0070,  0.0014,  0.0022,  ..., -0.0014, -0.0056,  0.0006],
        [ 0.0067,  0.0019,  0.0006,  ..., -0.0004, -0.0002, -0.0062],
        [ 0.0006, -0.0030,  0.0067,  ...,  0.0014, -0.0028,  0.0029],
        ...,
        [-0.0032, -0.0036, -0.0002,  ...,  0.0017, -0.0077,  0.0006],
        [-0.0006, -0.0026,  0.0046,  ..., -0.0013,  0.0079, -0.0047],
        [-0.0027, -0.0027,  0.0048,  ...,  0.0012, -0.0025,  0.0103]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1798e-01,  9.5367e-05,  8.6899e-03,  ..., -6.0616e-03,
         -6.0368e-04,  6.5308e-03],
        [ 2.8725e-03, -1.2256e-01, -4.8981e-03,  ..., -6.6528e-03,
         -6.5079e-03,  1.0748e-03],
        [-5.6992e-03,  7.4615e-03, -1.2140e-01,  ...,  7.8430e-03,
          2.2964e-03, -8.0109e-03],
        ...,
        [ 1.0468e-02,  1.0757e-02,  1.4648e-03,  ..., -1.1584e-01,
         -1.0399e-02, -7.8430e-03],
        [-2.3956e-03, -1.4095e-03, -4.2076e-03,  ...,  1.0902e-02,
         -1.2445e-01, -6.2637e-03],
        [ 3.3245e-03,  5.9891e-03, -1.4305e-02,  ..., -6.6185e-03,
          1.1063e-02, -1.2683e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1323,  0.0029, -0.0092,  ..., -0.0022, -0.0072,  0.0068],
        [ 0.0022, -0.1461, -0.0078,  ..., -0.0054, -0.0090,  0.0051],
        [-0.0078,  0.0128, -0.1343,  ...,  0.0086,  0.0075, -0.0008],
        ...,
        [ 0.0140, -0.0017,  0.0068,  ..., -0.1411,  0.0003,  0.0000],
        [ 0.0004, -0.0095, -0.0178,  ...,  0.0068, -0.1450,  0.0049],
        [ 0.0007,  0.0032,  0.0029,  ...,  0.0055,  0.0182, -0.1544]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:34:46 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-29 20:34:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7358, -0.5801, -0.4082,  ..., -0.0529, -0.7900,  1.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1412, -0.6143, -0.3481,  ..., -0.6655,  0.0884, -0.0300],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2778, -1.5137, -0.6069,  ...,  0.6172, -1.8467,  4.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3442, -2.2910, -0.8755,  ..., -1.1416, -1.2012, -0.4233],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:34:47 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:34:47 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 20:35:52 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 20:36:54 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 20:37:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0113, -0.0011, -0.0059,  ...,  0.0101, -0.0011, -0.0044],
        [-0.0031,  0.0150,  0.0060,  ...,  0.0036,  0.0006, -0.0032],
        [-0.0025, -0.0006,  0.0023,  ...,  0.0061, -0.0013, -0.0009],
        ...,
        [ 0.0021,  0.0008,  0.0028,  ...,  0.0092, -0.0175,  0.0004],
        [-0.0031, -0.0014, -0.0027,  ...,  0.0048,  0.0064, -0.0006],
        [-0.0002,  0.0016,  0.0036,  ..., -0.0026,  0.0117,  0.0044]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0489, -0.0090, -0.0142,  ...,  0.0041, -0.0077, -0.0171],
        [-0.0145, -0.0504, -0.0119,  ...,  0.0182,  0.0036, -0.0058],
        [ 0.0074, -0.0081, -0.0627,  ..., -0.0119, -0.0034, -0.0045],
        ...,
        [-0.0126, -0.0038,  0.0149,  ..., -0.0698, -0.0263,  0.0013],
        [-0.0076,  0.0132,  0.0029,  ...,  0.0125, -0.0606, -0.0090],
        [-0.0061, -0.0067,  0.0093,  ..., -0.0027,  0.0051, -0.0635]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0455e-01,  7.5912e-03, -1.8063e-03,  ..., -1.1871e-02,
         -2.7866e-03,  1.0513e-02],
        [ 9.5825e-03, -9.9670e-02, -1.0414e-02,  ...,  5.5389e-03,
         -5.1384e-03,  2.5063e-03],
        [ 1.7252e-03,  1.8044e-03, -1.0828e-01,  ..., -1.1044e-03,
         -6.9847e-03, -2.1683e-02],
        ...,
        [-3.5187e-02, -4.6883e-03,  2.8896e-03,  ..., -9.7168e-02,
         -6.7902e-03,  8.1177e-03],
        [ 2.0981e-05,  1.3031e-02, -5.8899e-03,  ...,  8.5297e-03,
         -1.0437e-01,  1.4641e-02],
        [ 3.0003e-03, -8.8043e-03,  1.0429e-02,  ...,  1.9569e-03,
         -1.7258e-02, -1.1304e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:37:58 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-29 20:37:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1479, -0.6450, -0.4453,  ...,  0.1376, -0.6870,  1.4932],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1912, -0.9741, -0.5259,  ..., -0.4336, -0.1606, -0.0886],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4182, -0.6318,  0.1392,  ...,  1.1182, -2.1191,  4.8477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4819, -1.9971, -0.9624,  ..., -1.3633, -1.0840, -0.3591],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:37:58 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:37:58 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 20:39:00 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 20:40:02 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 20:41:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.4054e-03, -9.1400e-03,  3.0565e-04,  ...,  6.9141e-04,
         -2.5177e-03,  8.0795e-03],
        [-4.4632e-03,  2.1439e-03, -2.9736e-03,  ...,  2.7428e-03,
          8.9407e-07, -1.0777e-03],
        [-3.7498e-03, -1.4067e-04, -3.1281e-03,  ..., -3.4370e-03,
          4.0550e-03, -5.3864e-03],
        ...,
        [ 2.2736e-03,  3.9601e-04,  5.1575e-03,  ...,  1.6985e-03,
          1.0460e-02, -2.9354e-03],
        [ 7.7248e-03,  7.3624e-03,  2.5463e-04,  ...,  6.0797e-04,
         -8.3084e-03, -1.8990e-04],
        [-1.0490e-03,  1.1139e-03,  3.9406e-03,  ..., -5.4779e-03,
          4.0970e-03, -1.0132e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0521, -0.0041,  0.0118,  ...,  0.0077, -0.0023,  0.0003],
        [ 0.0090, -0.0712, -0.0020,  ...,  0.0105,  0.0114, -0.0072],
        [-0.0136,  0.0007, -0.0648,  ..., -0.0067, -0.0043,  0.0011],
        ...,
        [ 0.0006, -0.0083,  0.0009,  ..., -0.0704,  0.0080, -0.0098],
        [ 0.0147, -0.0099,  0.0141,  ..., -0.0009, -0.0669,  0.0174],
        [-0.0026,  0.0158,  0.0056,  ...,  0.0004,  0.0036, -0.0570]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.6252e-02,  5.6152e-03,  7.8659e-03,  ...,  2.3651e-02,
          1.2985e-02,  1.0002e-02],
        [ 3.9577e-05, -9.4177e-02, -1.4732e-02,  ...,  9.1400e-03,
          4.9133e-03,  4.6730e-03],
        [-6.5575e-03,  2.5043e-03, -1.0950e-01,  ..., -1.0551e-02,
          9.6054e-03, -1.2314e-02],
        ...,
        [ 9.9945e-03,  8.1558e-03,  1.2077e-02,  ..., -9.7656e-02,
          7.1259e-03,  2.4471e-03],
        [ 1.9287e-02,  2.0477e-02,  7.4310e-03,  ..., -3.5133e-03,
         -1.0687e-01,  1.6220e-02],
        [ 9.3079e-03,  1.5396e-02, -5.9204e-03,  ...,  1.7029e-02,
         -1.8024e-03, -1.0162e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:41:08 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-29 20:41:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0973, -0.6484, -0.2715,  ...,  0.2546, -0.8057,  1.7959],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1736, -1.0186, -0.3936,  ..., -0.5088, -0.5410, -0.2388],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0371, -0.2959, -0.0846,  ...,  1.4551, -1.6914,  5.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3101, -3.1719, -1.0791,  ..., -0.9780, -0.4336,  0.4177],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:41:08 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:41:08 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 20:42:12 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 20:43:17 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 20:44:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8063e-03, -4.5509e-03,  5.9843e-05,  ..., -2.6665e-03,
         -2.1095e-03, -2.4548e-03],
        [ 3.6860e-04, -2.0370e-03,  2.8229e-04,  ...,  9.3365e-04,
          2.5120e-03,  2.6932e-03],
        [-1.3046e-03, -2.3193e-03, -6.2418e-04,  ...,  1.6689e-04,
          2.9049e-03,  1.9083e-03],
        ...,
        [ 1.7576e-03,  8.2922e-04,  1.0815e-03,  ...,  1.8263e-03,
         -4.1084e-03, -5.0049e-03],
        [-3.8457e-04, -8.5306e-04,  2.8725e-03,  ..., -3.0670e-03,
         -2.1439e-03, -1.6680e-03],
        [ 1.5717e-03, -1.6441e-03, -1.8430e-04,  ...,  8.3971e-04,
          6.0511e-04, -4.0359e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0696, -0.0087, -0.0072,  ..., -0.0026, -0.0027, -0.0121],
        [ 0.0159, -0.0593,  0.0038,  ..., -0.0123,  0.0048,  0.0047],
        [-0.0082, -0.0106, -0.0591,  ..., -0.0002,  0.0079,  0.0138],
        ...,
        [-0.0162,  0.0007,  0.0071,  ..., -0.0504, -0.0054,  0.0031],
        [-0.0123,  0.0109, -0.0012,  ...,  0.0074, -0.0469, -0.0040],
        [ 0.0049,  0.0098, -0.0056,  ..., -0.0098, -0.0046, -0.0577]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1284,  0.0156, -0.0066,  ..., -0.0200, -0.0032, -0.0076],
        [ 0.0240, -0.1242,  0.0217,  ..., -0.0113,  0.0040,  0.0065],
        [-0.0159, -0.0081, -0.1098,  ..., -0.0066,  0.0301, -0.0070],
        ...,
        [-0.0233,  0.0215, -0.0043,  ..., -0.0946, -0.0190,  0.0092],
        [-0.0028, -0.0067, -0.0012,  ...,  0.0051, -0.0998, -0.0086],
        [ 0.0003,  0.0166,  0.0018,  ..., -0.0089, -0.0091, -0.1067]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:44:25 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-29 20:44:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1718, -0.2798,  0.0309,  ...,  0.4600, -0.8838,  2.0488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2218, -0.9214, -0.4475,  ..., -0.6206, -0.4746, -0.2125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6626,  0.1565, -0.4453,  ...,  1.8633, -1.2773,  5.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5039, -2.5156, -1.3018,  ..., -1.4600, -0.7305, -0.3547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:44:26 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:44:26 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 20:45:34 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 20:46:44 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 20:47:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.5136e-04,  4.7636e-04,  1.3638e-04,  ...,  9.4223e-04,
          1.9920e-04, -8.7357e-04],
        [-3.2520e-04,  4.4556e-03, -2.4433e-03,  ...,  5.2738e-04,
          1.9646e-03,  3.2020e-04],
        [ 3.2473e-04,  1.1044e-03,  7.3242e-04,  ...,  1.0471e-03,
         -4.2152e-04, -7.4100e-04],
        ...,
        [ 1.4954e-03,  3.5381e-04, -2.7618e-03,  ...,  2.0599e-03,
          1.3485e-03, -1.5783e-04],
        [ 1.4086e-03, -8.2111e-04, -2.5635e-03,  ...,  1.7509e-03,
          2.0618e-03,  1.0405e-03],
        [-5.5504e-04,  2.7633e-04,  2.8000e-03,  ...,  8.1837e-05,
          9.5701e-04,  2.7008e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0277, -0.0055, -0.0011,  ..., -0.0173,  0.0037, -0.0075],
        [ 0.0009, -0.0320,  0.0157,  ...,  0.0174,  0.0063,  0.0059],
        [-0.0071, -0.0005, -0.0328,  ...,  0.0093,  0.0032,  0.0023],
        ...,
        [ 0.0097, -0.0009,  0.0090,  ..., -0.0280, -0.0193, -0.0146],
        [ 0.0160, -0.0169, -0.0118,  ..., -0.0170, -0.0524,  0.0057],
        [-0.0012,  0.0016,  0.0228,  ...,  0.0103,  0.0048, -0.0139]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0552, -0.0042,  0.0155,  ..., -0.0173, -0.0124, -0.0019],
        [ 0.0026, -0.0555, -0.0015,  ...,  0.0087,  0.0144,  0.0066],
        [-0.0096, -0.0002, -0.0733,  ...,  0.0019,  0.0151,  0.0010],
        ...,
        [ 0.0087,  0.0072, -0.0213,  ..., -0.0555,  0.0047, -0.0118],
        [ 0.0037, -0.0118, -0.0202,  ..., -0.0133, -0.0609,  0.0041],
        [-0.0125,  0.0020,  0.0138,  ..., -0.0084,  0.0284, -0.0505]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:47:55 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-29 20:47:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0098, -0.1377, -0.0567,  ...,  0.5811, -0.6865,  2.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1340, -1.3633, -0.4565,  ..., -0.4067, -0.1853,  0.1475],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6875, -0.5078, -0.9229,  ...,  1.9551, -1.8672,  4.5938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5762, -4.0938, -2.0039,  ..., -1.1348, -1.1680, -1.0645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:47:55 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:47:55 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 20:49:07 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 20:50:19 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 20:51:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.9421e-04, -3.7155e-03,  2.9373e-03,  ...,  7.6180e-03,
         -6.7215e-03, -4.7874e-03],
        [-3.1242e-03,  8.4996e-05, -2.3232e-03,  ..., -3.3455e-03,
         -7.2594e-03,  6.2523e-03],
        [-1.2970e-03, -4.3907e-03,  4.7326e-04,  ..., -1.8415e-03,
         -1.7109e-03,  6.7568e-04],
        ...,
        [ 5.2376e-03,  2.0456e-04, -4.6959e-03,  ..., -5.2986e-03,
          2.3098e-03,  4.3945e-03],
        [-7.3853e-03,  1.4992e-03,  1.3030e-04,  ..., -1.4400e-03,
          1.4496e-03, -2.4605e-03],
        [-7.3624e-03, -1.8263e-03, -3.2959e-03,  ..., -6.2332e-03,
         -1.0710e-03,  1.0748e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0104, -0.0016, -0.0064,  ...,  0.0086,  0.0067, -0.0003],
        [ 0.0142, -0.0244, -0.0173,  ...,  0.0130,  0.0146,  0.0010],
        [-0.0086,  0.0075, -0.0461,  ..., -0.0128, -0.0043,  0.0018],
        ...,
        [ 0.0016,  0.0016, -0.0009,  ..., -0.0212,  0.0092, -0.0017],
        [ 0.0041, -0.0039, -0.0240,  ..., -0.0017, -0.0162, -0.0028],
        [-0.0042, -0.0134,  0.0006,  ..., -0.0080,  0.0023, -0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.5009e-02, -2.7580e-03,  5.3406e-05,  ..., -1.1101e-03,
          1.8158e-03, -3.3264e-03],
        [ 2.4757e-03, -4.8584e-02, -1.3992e-02,  ...,  1.4900e-02,
          5.4016e-03,  6.6948e-04],
        [-1.0483e-02,  1.0223e-02, -2.1332e-02,  ..., -1.1826e-04,
         -1.0086e-02, -8.0719e-03],
        ...,
        [ 6.5269e-03,  9.3384e-03,  1.9485e-02,  ..., -2.4567e-02,
         -7.6294e-04, -1.0643e-03],
        [-3.1815e-03, -7.3967e-03, -1.2657e-02,  ...,  1.2573e-02,
         -3.4241e-02,  5.5847e-03],
        [-4.0321e-03, -1.5747e-02,  5.7526e-03,  ...,  1.0586e-03,
         -8.8120e-03, -2.4506e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:51:33 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-29 20:51:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2510,  0.0453, -0.1844,  ...,  0.6968, -0.4861,  1.9209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2051, -1.0254, -0.5273,  ..., -0.5962, -0.2837, -0.1694],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7173, -0.8638, -0.2129,  ...,  2.0410, -1.3184,  4.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1145, -4.9141, -1.6270,  ..., -3.2617, -0.5596, -1.6729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:51:33 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:51:33 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 20:52:55 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 20:54:16 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 20:55:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.0779e-03, -2.8610e-03, -1.8663e-03,  ...,  1.2159e-05,
         -1.8988e-03,  8.3237e-03],
        [ 2.4052e-03, -1.5230e-03, -8.2474e-03,  ...,  6.8512e-03,
          3.7899e-03, -2.5482e-03],
        [-3.1452e-03, -2.3899e-03,  1.1917e-02,  ...,  4.3030e-03,
          3.6316e-03, -1.9779e-03],
        ...,
        [ 3.3703e-03,  4.9591e-03, -7.6523e-03,  ...,  1.0254e-02,
         -2.3956e-03,  1.0290e-03],
        [-1.1759e-03,  4.2748e-04,  6.9427e-03,  ...,  7.2861e-03,
          7.9575e-03, -3.5362e-03],
        [-5.2299e-03, -3.6478e-04,  2.8877e-03,  ..., -2.2144e-03,
          8.7967e-03,  8.0719e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.6957e-02,  9.5367e-07, -8.8043e-03,  ...,  1.5640e-04,
         -1.1215e-02,  9.1934e-03],
        [ 4.9133e-03, -2.6093e-02, -9.9087e-04,  ..., -1.4816e-02,
         -4.4136e-03,  9.6130e-03],
        [ 1.0658e-02,  3.9825e-03, -1.9516e-02,  ...,  7.7019e-03,
          2.1782e-03,  5.4455e-04],
        ...,
        [-1.2856e-03, -9.4528e-03, -2.1858e-03,  ..., -2.8656e-02,
          1.4267e-02,  2.3136e-03],
        [-1.1444e-03, -5.6534e-03,  4.9706e-03,  ...,  1.0193e-02,
         -4.9744e-02, -7.8087e-03],
        [ 1.7593e-02, -1.3933e-03,  1.0586e-04,  ...,  7.7019e-03,
         -1.3016e-02, -6.6757e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0485, -0.0004,  0.0077,  ..., -0.0181,  0.0207,  0.0073],
        [-0.0067, -0.0421, -0.0109,  ..., -0.0055,  0.0146,  0.0125],
        [ 0.0040,  0.0101, -0.0329,  ..., -0.0061,  0.0179,  0.0089],
        ...,
        [-0.0024, -0.0154, -0.0193,  ..., -0.0432, -0.0053, -0.0179],
        [ 0.0412, -0.0159, -0.0065,  ...,  0.0174, -0.0472, -0.0080],
        [-0.0013, -0.0051, -0.0022,  ..., -0.0084,  0.0086, -0.0282]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:55:36 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-29 20:55:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2617, -0.1963, -0.3606,  ...,  0.7305, -0.7100,  1.7617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2252, -1.5391, -0.7646,  ..., -0.4219, -0.4409, -0.4521],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4434, -0.6885,  1.0723,  ...,  2.0215, -0.1582,  4.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6973, -4.9531, -1.1465,  ..., -3.5605, -0.8857, -2.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:55:36 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:55:36 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 20:56:56 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 20:58:20 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 20:59:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5993e-03,  5.8365e-04,  9.4533e-05,  ...,  9.2506e-05,
         -2.8968e-05,  3.9637e-05],
        [ 1.5306e-04, -1.5373e-03, -2.4700e-04,  ...,  4.3368e-04,
          4.4060e-04,  5.0402e-04],
        [ 1.7285e-05, -4.6790e-05, -1.6727e-03,  ...,  1.9336e-04,
         -7.4339e-04, -1.0985e-04],
        ...,
        [ 1.0997e-04,  1.9848e-05, -5.2452e-06,  ..., -1.6117e-03,
          9.7692e-05, -3.1757e-04],
        [ 1.3411e-04, -2.0480e-04, -6.1095e-05,  ..., -4.2057e-04,
         -1.2722e-03,  2.0623e-04],
        [ 9.1195e-06,  8.7070e-04,  7.4244e-04,  ..., -4.3440e-04,
         -4.0674e-04, -1.6441e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0307,  0.0075,  0.0056,  ...,  0.0090, -0.0168,  0.0047],
        [ 0.0063, -0.0308,  0.0040,  ...,  0.0096,  0.0076,  0.0029],
        [ 0.0064,  0.0089, -0.0281,  ...,  0.0163, -0.0172, -0.0024],
        ...,
        [-0.0038,  0.0117,  0.0022,  ..., -0.0394, -0.0154,  0.0018],
        [ 0.0065,  0.0033, -0.0166,  ...,  0.0035, -0.0280, -0.0053],
        [-0.0004,  0.0067, -0.0116,  ..., -0.0130, -0.0202, -0.0149]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0646,  0.0118, -0.0043,  ...,  0.0124, -0.0260, -0.0118],
        [-0.0046, -0.0753, -0.0076,  ...,  0.0083, -0.0051,  0.0061],
        [-0.0039,  0.0027, -0.0969,  ...,  0.0019,  0.0023, -0.0160],
        ...,
        [ 0.0070,  0.0260,  0.0080,  ..., -0.0661, -0.0020, -0.0124],
        [ 0.0166,  0.0092, -0.0250,  ..., -0.0088, -0.0892, -0.0192],
        [-0.0032,  0.0130, -0.0079,  ..., -0.0148, -0.0190, -0.1033]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 20:59:47 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-29 20:59:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2717, -0.3115, -0.1042,  ...,  0.7295, -0.4661,  1.5566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0519, -1.7432, -0.6001,  ..., -1.1553, -0.1841, -0.6475],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.8076, 0.7773, 1.2090,  ..., 1.3242, 0.0372, 4.2578], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8984, -4.4766, -0.6489,  ..., -4.1484, -0.5850, -2.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 20:59:47 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 20:59:47 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 21:01:08 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 21:02:30 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 21:03:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.3542e-03, -4.0579e-04, -6.3705e-04,  ...,  6.1607e-04,
         -1.8024e-04, -2.4605e-04],
        [-1.3285e-03,  6.7940e-03, -1.7700e-03,  ...,  2.9926e-03,
          8.0633e-04,  3.3379e-05],
        [ 5.5742e-04,  1.8721e-03,  9.1476e-03,  ...,  1.1320e-03,
         -8.5306e-04,  1.1355e-04],
        ...,
        [-2.1374e-04, -2.0905e-03, -5.4181e-05,  ...,  8.3694e-03,
          1.4277e-03, -1.1358e-03],
        [-1.0719e-03, -7.3719e-04, -2.1973e-03,  ...,  1.3399e-03,
          7.0877e-03, -9.4509e-04],
        [ 5.6887e-04, -7.9489e-04,  7.8011e-04,  ..., -5.9843e-05,
         -3.4285e-04,  7.8087e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0259,  0.0014, -0.0208,  ...,  0.0070,  0.0020,  0.0012],
        [ 0.0174, -0.0316,  0.0141,  ..., -0.0003, -0.0151,  0.0002],
        [-0.0097, -0.0144,  0.0085,  ..., -0.0179, -0.0006, -0.0026],
        ...,
        [-0.0254,  0.0126, -0.0269,  ..., -0.0164,  0.0247, -0.0152],
        [-0.0079,  0.0006, -0.0051,  ...,  0.0098, -0.0069,  0.0060],
        [ 0.0136, -0.0071,  0.0130,  ...,  0.0013,  0.0026, -0.0333]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0436, -0.0116, -0.0050,  ...,  0.0145,  0.0245,  0.0067],
        [-0.0086, -0.0236, -0.0065,  ..., -0.0041,  0.0009, -0.0166],
        [-0.0048, -0.0124, -0.0327,  ...,  0.0123, -0.0179,  0.0088],
        ...,
        [-0.0096,  0.0102, -0.0111,  ..., -0.0204, -0.0052, -0.0151],
        [-0.0005,  0.0047, -0.0081,  ...,  0.0059, -0.0546,  0.0031],
        [ 0.0052,  0.0083,  0.0191,  ..., -0.0034, -0.0008, -0.0545]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:03:55 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-29 21:03:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5200, -0.2141,  0.3252,  ...,  0.6899, -0.0507,  1.5293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2394, -1.6211, -0.4402,  ..., -1.2119, -0.2979, -0.7681],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2383,  0.8657,  0.8604,  ...,  1.0674, -0.0212,  4.8906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6406, -2.9258, -1.3008,  ..., -4.9219, -1.4141, -3.6680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:03:55 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 21:03:55 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 21:05:18 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 21:06:44 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 21:08:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.6953e-02,  4.5300e-04, -6.7520e-04,  ...,  2.7428e-03,
          1.9760e-03,  2.4433e-03],
        [-9.0003e-05,  1.0033e-02, -6.1607e-04,  ..., -1.0133e-05,
         -9.3937e-04,  9.7847e-04],
        [ 1.9836e-04, -1.5104e-04,  1.6647e-02,  ..., -9.7942e-04,
          2.3365e-04,  7.7915e-04],
        ...,
        [-1.9586e-04,  1.1168e-03, -1.7395e-03,  ...,  1.7914e-02,
          1.5202e-03, -3.8528e-04],
        [ 1.0519e-03,  1.4467e-03, -2.1076e-03,  ...,  3.5934e-03,
          1.9089e-02, -2.1286e-03],
        [ 1.6813e-03, -7.5579e-04, -1.9855e-03,  ..., -8.5878e-04,
          3.8719e-04,  1.9806e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0597, -0.0041, -0.0109,  ...,  0.0047,  0.0131,  0.0031],
        [-0.0140,  0.0010,  0.0063,  ...,  0.0027,  0.0016,  0.0019],
        [-0.0138, -0.0091,  0.0465,  ...,  0.0090, -0.0170, -0.0104],
        ...,
        [-0.0147,  0.0098, -0.0016,  ...,  0.0653, -0.0099, -0.0153],
        [ 0.0005, -0.0208, -0.0039,  ...,  0.0183,  0.0624, -0.0046],
        [ 0.0068,  0.0050,  0.0280,  ..., -0.0099, -0.0018,  0.0504]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0293, -0.0255,  0.0044,  ..., -0.0020,  0.0126, -0.0124],
        [ 0.0193, -0.0166, -0.0220,  ..., -0.0018, -0.0137,  0.0083],
        [-0.0110, -0.0226, -0.0063,  ...,  0.0164,  0.0070,  0.0012],
        ...,
        [-0.0139, -0.0070, -0.0068,  ...,  0.0014, -0.0121, -0.0021],
        [ 0.0027, -0.0186, -0.0149,  ..., -0.0048,  0.0151,  0.0020],
        [ 0.0121,  0.0265,  0.0198,  ...,  0.0130, -0.0090, -0.0105]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:08:12 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-29 21:08:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.6245, 0.2664, 0.3416,  ..., 0.3933, 0.0053, 1.4023], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2808, -1.4189, -0.2761,  ..., -1.4170, -0.1995, -0.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.4219,  1.4434, -0.0122,  ...,  0.5117, -0.0172,  4.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7139, -2.7148, -1.3564,  ..., -5.2969, -1.7705, -3.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:08:12 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 21:08:12 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 21:09:37 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 21:11:04 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 21:12:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.6245e-03, -8.7643e-04,  3.4630e-05,  ..., -3.1412e-05,
          4.7421e-04, -3.4428e-04],
        [-9.3412e-04,  2.0294e-03,  1.1444e-03,  ...,  7.8249e-04,
          3.5548e-04, -2.6083e-04],
        [ 7.7438e-04, -6.8903e-05,  3.2082e-03,  ...,  4.7374e-04,
          8.4066e-04, -1.1625e-03],
        ...,
        [ 5.3120e-04, -1.6212e-04, -7.2193e-04,  ...,  3.0861e-03,
          5.0449e-04,  5.3930e-04],
        [ 2.1019e-03, -5.7077e-04, -2.7847e-04,  ..., -3.9196e-04,
          2.2469e-03, -4.9305e-04],
        [ 1.6356e-03, -8.9359e-04,  8.9073e-04,  ...,  3.6097e-04,
         -2.7728e-04,  3.4447e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.5961e-02, -3.9902e-03,  9.9106e-03,  ..., -7.7534e-04,
          1.4282e-02, -4.2725e-03],
        [-1.1841e-02, -4.0100e-02,  8.1863e-03,  ...,  8.4763e-03,
         -1.2579e-03, -1.7639e-02],
        [-1.0368e-02,  1.8997e-02, -3.1471e-04,  ...,  1.0086e-02,
         -5.6610e-03,  9.1324e-03],
        ...,
        [ 1.4496e-02,  4.0283e-03, -1.0208e-02,  ...,  9.7351e-03,
         -1.9054e-03,  3.6354e-03],
        [-6.3591e-03, -1.1282e-03,  1.3268e-02,  ...,  2.7866e-03,
         -1.7151e-02,  6.5155e-03],
        [-1.6785e-04,  1.7242e-02,  5.9068e-05,  ...,  1.2482e-02,
         -1.9363e-02,  8.2016e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 1.6541e-02, -2.4185e-03,  1.0666e-02,  ...,  8.7128e-03,
          1.7197e-02,  3.0994e-04],
        [ 9.0790e-04, -9.6893e-03,  1.1726e-02,  ...,  9.6130e-03,
          4.2648e-03, -1.7990e-02],
        [-1.6830e-02, -1.1520e-03,  3.0319e-02,  ...,  1.3535e-02,
         -8.6441e-03, -8.3618e-03],
        ...,
        [ 2.1133e-02,  1.3298e-02,  3.2158e-03,  ...,  2.6825e-02,
          1.3916e-02, -8.6670e-03],
        [-8.8272e-03,  6.3248e-03, -8.5373e-03,  ..., -2.6951e-03,
          5.2109e-03, -8.7128e-03],
        [-5.8174e-05,  4.5013e-03,  1.2665e-03,  ...,  1.1559e-02,
          2.1667e-03,  2.3544e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:12:32 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-29 21:12:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7227,  0.2727,  0.1609,  ...,  0.2102, -0.0365,  1.4102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1526, -0.8511, -0.4861,  ..., -1.6055, -0.4622, -1.2158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 4.1602,  1.4648, -0.9482,  ..., -0.4121,  0.1750,  3.6621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6963, -1.9395, -2.6055,  ..., -6.7383, -1.5723, -4.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:12:32 root INFO     [order_1_approx] starting weight calculation for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 21:12:32 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 21:13:59 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 21:15:26 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 21:16:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.8896e-03, -1.3313e-03,  1.4420e-03,  ..., -2.4021e-05,
         -3.7098e-04, -1.0424e-03],
        [ 9.0361e-05,  3.8986e-03, -1.3876e-04,  ..., -1.5926e-03,
          1.2708e-04,  1.4057e-03],
        [ 1.3256e-03, -1.4591e-03,  4.2992e-03,  ..., -9.9540e-05,
         -2.5043e-03, -4.1652e-04],
        ...,
        [ 4.0174e-04,  7.2527e-04, -2.7490e-04,  ...,  4.0741e-03,
         -3.9291e-04,  9.7692e-05],
        [-5.1737e-05,  7.1645e-05,  3.6597e-04,  ..., -5.5218e-04,
          4.3221e-03, -6.8092e-04],
        [ 5.4932e-04,  2.7027e-03,  9.6321e-04,  ..., -5.6744e-04,
          1.3769e-04,  6.8474e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0173, -0.0011, -0.0036,  ...,  0.0059, -0.0021, -0.0010],
        [ 0.0116, -0.0228,  0.0027,  ...,  0.0009,  0.0094,  0.0059],
        [-0.0120, -0.0112,  0.0055,  ..., -0.0012, -0.0014,  0.0051],
        ...,
        [-0.0136, -0.0073, -0.0080,  ...,  0.0063, -0.0170,  0.0092],
        [-0.0139, -0.0008, -0.0089,  ...,  0.0075,  0.0149, -0.0006],
        [-0.0138,  0.0081, -0.0019,  ..., -0.0152, -0.0060, -0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0048, -0.0191, -0.0238,  ...,  0.0017, -0.0125, -0.0197],
        [ 0.0151, -0.0427,  0.0022,  ...,  0.0320,  0.0114,  0.0293],
        [-0.0106, -0.0157,  0.0169,  ..., -0.0088,  0.0136,  0.0120],
        ...,
        [-0.0276, -0.0057, -0.0116,  ..., -0.0006,  0.0112,  0.0032],
        [-0.0073, -0.0056, -0.0062,  ...,  0.0395,  0.0071,  0.0202],
        [-0.0045, -0.0066,  0.0228,  ..., -0.0041, -0.0133,  0.0051]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:16:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a painting is watercolor
A more specific term for a weapon is gun
A more specific term for a weekday is monday
A more specific term for a citrus is lemon
A more specific term for a collar is choker
A more specific term for a bed is bunk
A more specific term for a brush is toothbrush
A more specific term for a trousers is
2024-06-29 21:16:53 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 21:16:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1942,  0.4187,  1.0781,  ..., -0.6675, -0.0191,  0.2717],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0721,  0.0951,  0.2676,  ...,  0.2362, -0.2219, -0.2046],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5127,  0.2910,  0.4316,  ..., -0.4556, -0.1943,  0.4128],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2622,  0.1476, -0.0758,  ...,  0.1593, -0.3079,  0.2869],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:16:53 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:16:53 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 21:17:17 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 21:17:40 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 21:18:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.5656e-03,  7.4959e-04, -2.2030e-03,  ..., -4.2200e-04,
          9.3842e-04, -3.8090e-03],
        [ 7.0763e-04, -9.6436e-03, -1.0121e-04,  ...,  1.9646e-03,
         -3.5882e-04,  9.6035e-04],
        [-1.1168e-03,  8.2970e-04, -9.8190e-03,  ..., -2.1725e-03,
         -2.7637e-03,  9.1839e-04],
        ...,
        [-8.8632e-05,  3.0346e-03, -6.5947e-04,  ..., -8.0566e-03,
         -5.1069e-04,  1.4849e-03],
        [-7.4863e-05, -1.2839e-04,  6.2227e-04,  ..., -2.2221e-03,
         -7.9193e-03,  1.6212e-03],
        [ 3.9577e-04,  1.0071e-03, -9.8419e-04,  ...,  2.8491e-04,
          3.3379e-05, -5.1308e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0391, -0.0049, -0.0058,  ..., -0.0038, -0.0059,  0.0100],
        [-0.0040, -0.0412, -0.0011,  ...,  0.0043,  0.0065,  0.0018],
        [-0.0027,  0.0061, -0.0381,  ...,  0.0007,  0.0054, -0.0007],
        ...,
        [-0.0033,  0.0078, -0.0007,  ..., -0.0416, -0.0017,  0.0021],
        [-0.0071,  0.0027, -0.0005,  ...,  0.0019, -0.0425,  0.0020],
        [-0.0004,  0.0004, -0.0029,  ...,  0.0017, -0.0026, -0.0370]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.3854e-02,  3.7003e-03,  3.3760e-03,  ..., -4.6616e-03,
          1.4887e-03, -4.5624e-03],
        [ 1.2999e-03, -4.5135e-02,  5.2404e-04,  ...,  7.9727e-04,
          2.1095e-03, -7.6199e-04],
        [-5.9128e-03, -1.0967e-05, -3.5248e-02,  ..., -5.1498e-03,
         -4.0665e-03, -2.9526e-03],
        ...,
        [ 6.8712e-04,  1.0643e-03, -3.3684e-03,  ..., -4.6722e-02,
          6.9523e-04, -1.5087e-03],
        [-2.5787e-03,  6.9475e-04, -9.5987e-04,  ...,  1.5516e-03,
         -4.3396e-02,  1.4429e-03],
        [-3.3402e-04, -2.0142e-03, -4.7455e-03,  ...,  3.3722e-03,
          5.3072e-04, -4.1504e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:18:06 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-29 21:18:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2308,  0.2971,  0.5107,  ..., -0.4641, -0.0435,  0.2378],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1903,  0.0125,  0.1581,  ...,  0.0360, -0.3691, -0.1192],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6255,  0.3799,  0.6323,  ..., -0.5527, -0.1239,  0.4082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5078, -0.0781,  0.3032,  ..., -0.0032, -0.1567,  0.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:18:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:18:06 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 21:18:30 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 21:18:53 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 21:19:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.4986e-03, -1.4133e-03, -1.0881e-03,  ...,  2.8667e-03,
         -5.9938e-04,  4.2534e-04],
        [ 2.7161e-03, -8.5983e-03,  1.7643e-03,  ...,  2.8973e-03,
          7.7200e-04,  1.4086e-03],
        [-9.4318e-04, -1.4296e-03, -4.5204e-03,  ...,  1.0014e-03,
         -6.9046e-04, -9.8467e-05],
        ...,
        [ 2.7490e-04, -1.1120e-03,  2.0754e-04,  ..., -4.2953e-03,
         -7.5436e-04, -1.1063e-03],
        [ 4.5300e-04,  3.4199e-03,  2.3689e-03,  ..., -1.2417e-03,
         -8.2474e-03,  2.2399e-04],
        [ 2.9659e-03, -1.3504e-03, -2.0485e-03,  ..., -6.1417e-04,
          1.3456e-03, -8.2245e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0615,  0.0140, -0.0116,  ...,  0.0102, -0.0029, -0.0068],
        [ 0.0047, -0.0574,  0.0051,  ...,  0.0106, -0.0010,  0.0078],
        [-0.0103, -0.0015, -0.0523,  ..., -0.0016, -0.0012,  0.0050],
        ...,
        [ 0.0031,  0.0079, -0.0078,  ..., -0.0508, -0.0067,  0.0026],
        [ 0.0022, -0.0007,  0.0023,  ...,  0.0046, -0.0457,  0.0011],
        [-0.0031,  0.0070,  0.0021,  ..., -0.0017,  0.0071, -0.0498]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0696,  0.0041, -0.0007,  ..., -0.0050,  0.0010, -0.0109],
        [ 0.0004, -0.0764, -0.0057,  ..., -0.0012, -0.0044,  0.0007],
        [ 0.0008,  0.0004, -0.0674,  ..., -0.0063,  0.0037, -0.0027],
        ...,
        [ 0.0008,  0.0064, -0.0015,  ..., -0.0682, -0.0040, -0.0006],
        [-0.0063, -0.0080,  0.0041,  ...,  0.0037, -0.0684,  0.0020],
        [-0.0062,  0.0011,  0.0051,  ..., -0.0030,  0.0033, -0.0697]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:19:20 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-29 21:19:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6143,  0.3438,  0.5225,  ..., -0.5381, -0.2401,  0.4998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4241,  0.2153, -0.1168,  ...,  0.2391, -0.4656,  0.4373],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6372,  0.4663,  0.1624,  ..., -0.0879, -0.1830,  0.8345],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8218, -0.0579,  0.2534,  ..., -0.0747, -0.6475,  0.7012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:19:20 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:19:20 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 21:19:45 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 21:20:10 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 21:20:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0536e-02,  1.1997e-03, -2.4738e-03,  ..., -8.6069e-04,
         -2.0256e-03, -4.9305e-04],
        [ 1.5955e-03, -1.0590e-02, -3.2783e-05,  ...,  1.2474e-03,
          1.0872e-03,  1.2436e-03],
        [ 2.5959e-03, -1.7157e-03, -6.9275e-03,  ..., -8.4305e-04,
          1.6375e-03, -5.6863e-05],
        ...,
        [ 3.6478e-04,  3.6192e-04, -2.9049e-03,  ..., -1.0269e-02,
          2.8229e-03, -1.8539e-03],
        [ 2.4486e-04, -3.7098e-04, -1.1806e-03,  ...,  6.1274e-04,
         -8.1253e-03, -2.0361e-04],
        [ 1.9503e-03, -7.5388e-04,  3.4161e-03,  ...,  8.7833e-04,
         -9.3174e-04, -8.3313e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.4769e-02,  1.8787e-04, -5.2490e-03,  ...,  9.1171e-03,
          4.6196e-03, -2.3308e-03],
        [-5.5466e-03, -5.0171e-02, -1.0681e-04,  ..., -8.2169e-03,
         -3.4027e-03,  6.9976e-05],
        [ 7.1869e-03,  7.9422e-03, -4.4037e-02,  ..., -2.5826e-03,
          1.5783e-03,  4.2686e-03],
        ...,
        [-9.5463e-04,  6.4774e-03, -6.3667e-03,  ..., -4.1931e-02,
         -1.7529e-03, -1.6975e-04],
        [ 2.6093e-03, -4.2191e-03,  2.2469e-03,  ..., -2.9202e-03,
         -4.1046e-02,  2.0943e-03],
        [ 1.8482e-03, -1.4629e-03, -8.2779e-03,  ...,  9.9411e-03,
          1.9836e-03, -3.5889e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.1931e-02,  6.3362e-03, -6.2466e-05,  ...,  2.3575e-03,
         -1.5087e-03, -7.8964e-04],
        [-3.5439e-03, -3.5187e-02,  1.6602e-02,  ...,  8.0490e-03,
         -6.6605e-03, -8.1253e-04],
        [ 6.2180e-03,  3.5572e-03, -2.5146e-02,  ..., -1.4639e-03,
          4.1504e-03,  3.5934e-03],
        ...,
        [ 3.4199e-03,  4.9820e-03, -3.0327e-04,  ..., -3.8910e-02,
         -1.6346e-03,  6.3171e-03],
        [-9.2926e-03,  5.8365e-03, -1.8711e-03,  ...,  2.1381e-03,
         -3.0411e-02,  2.9011e-03],
        [-9.5367e-06,  6.5918e-03,  3.0155e-03,  ...,  1.2112e-03,
          7.6523e-03, -3.2898e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:20:37 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-29 21:20:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7183,  0.4275,  0.7251,  ..., -0.6182, -0.1622,  0.4539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7959, -0.1401,  0.4531,  ...,  0.0033, -0.2454,  0.6768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9360,  0.2073,  0.2194,  ...,  0.3516, -0.1377,  1.0811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0664,  0.2668,  0.2754,  ..., -0.6182,  0.0532,  0.7578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:20:37 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:20:37 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 21:21:07 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 21:21:37 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 21:22:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0026, -0.0005,  0.0017,  ...,  0.0018,  0.0014,  0.0011],
        [ 0.0028, -0.0051, -0.0002,  ..., -0.0021,  0.0005, -0.0001],
        [-0.0010,  0.0015, -0.0036,  ..., -0.0004,  0.0004,  0.0004],
        ...,
        [ 0.0002, -0.0023,  0.0002,  ..., -0.0016, -0.0003,  0.0001],
        [-0.0029,  0.0004,  0.0013,  ..., -0.0028, -0.0052,  0.0010],
        [ 0.0013, -0.0015,  0.0011,  ..., -0.0014, -0.0008, -0.0056]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0474,  0.0015, -0.0017,  ..., -0.0026, -0.0007,  0.0105],
        [-0.0079, -0.0567, -0.0013,  ..., -0.0021,  0.0020,  0.0006],
        [ 0.0007, -0.0148, -0.0428,  ...,  0.0112,  0.0077, -0.0005],
        ...,
        [-0.0029, -0.0028,  0.0004,  ..., -0.0425, -0.0025, -0.0018],
        [-0.0054,  0.0055, -0.0083,  ..., -0.0089, -0.0518,  0.0070],
        [ 0.0048,  0.0018,  0.0028,  ...,  0.0040, -0.0050, -0.0508]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.1575e-02, -4.8923e-04,  2.8477e-03,  ...,  9.1553e-05,
         -2.5673e-03,  1.9932e-03],
        [ 4.4136e-03, -5.2368e-02, -6.7749e-03,  ..., -3.1204e-03,
          2.8553e-03, -1.1072e-03],
        [ 4.9515e-03, -1.0704e-02, -6.2073e-02,  ...,  3.3264e-03,
         -3.2663e-04,  1.2217e-03],
        ...,
        [ 2.3594e-03, -8.0013e-04,  5.5847e-03,  ..., -5.7068e-02,
         -5.2452e-03, -4.2114e-03],
        [ 6.7749e-03, -1.0767e-03, -7.9422e-03,  ..., -6.9885e-03,
         -5.6152e-02, -1.8730e-03],
        [ 1.6079e-03,  4.8218e-03, -2.3708e-03,  ...,  5.8899e-03,
         -3.1071e-03, -5.0781e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:22:10 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-29 21:22:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5918,  0.4165,  0.1523,  ..., -0.0898, -0.1455,  0.7876],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8750, -0.1077,  0.2661,  ..., -0.0802, -0.6558,  0.7339],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6978, -0.0476,  0.9683,  ...,  0.0918, -0.1479,  1.4248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0605,  0.1892,  0.3784,  ..., -0.6621, -0.0238,  0.7085],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:22:10 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:22:10 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 21:22:40 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 21:23:12 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 21:23:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7328e-03,  8.3828e-04, -1.8597e-03,  ...,  4.0436e-03,
          2.4242e-03,  1.0862e-03],
        [ 1.3170e-03,  5.9662e-03,  2.4033e-03,  ...,  2.0390e-03,
         -2.7752e-03,  3.7689e-03],
        [-1.0529e-03, -3.8981e-04,  3.7766e-04,  ...,  1.5860e-03,
         -2.4068e-04,  7.1049e-04],
        ...,
        [-8.8406e-04,  1.4791e-03, -3.0537e-03,  ...,  1.0395e-03,
         -6.3515e-04,  2.0695e-04],
        [ 1.0653e-03, -1.6284e-04, -1.2894e-03,  ...,  1.3561e-03,
          5.5771e-03, -7.7188e-05],
        [ 3.1757e-04, -1.3494e-03, -1.5850e-03,  ...,  2.4438e-04,
         -1.3075e-03,  2.7580e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.9670e-02,  2.4395e-03, -8.2779e-03,  ..., -3.7117e-03,
         -7.6447e-03, -2.6245e-03],
        [ 1.2922e-03, -1.0535e-01,  2.1420e-03,  ...,  2.6703e-03,
         -1.5364e-03,  3.4714e-03],
        [-6.1035e-05,  3.0155e-03, -1.0162e-01,  ..., -1.0101e-02,
          9.9030e-03,  5.1880e-03],
        ...,
        [ 5.4474e-03, -1.6899e-03, -8.5678e-03,  ..., -9.6558e-02,
          1.1215e-03,  6.0577e-03],
        [ 1.1040e-02, -1.1276e-02, -1.1383e-02,  ..., -8.6899e-03,
         -1.0651e-01, -1.0881e-03],
        [-3.9101e-03, -1.6489e-03,  2.1706e-03,  ..., -5.8937e-03,
         -1.8950e-03, -1.1096e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1247, -0.0043,  0.0087,  ..., -0.0074, -0.0050, -0.0038],
        [-0.0025, -0.1154,  0.0033,  ..., -0.0081, -0.0035,  0.0027],
        [ 0.0002,  0.0078, -0.1112,  ..., -0.0021,  0.0045,  0.0015],
        ...,
        [-0.0047, -0.0004, -0.0022,  ..., -0.1009,  0.0070, -0.0022],
        [-0.0012,  0.0043, -0.0061,  ..., -0.0041, -0.1224,  0.0081],
        [-0.0116,  0.0043,  0.0015,  ..., -0.0011, -0.0070, -0.1215]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:23:51 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-29 21:23:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8447,  0.1749,  0.1780,  ...,  0.3088, -0.1418,  0.9751],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.1240,  0.2751,  0.2695,  ..., -0.6162,  0.0407,  0.7949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3809,  0.6963,  0.5059,  ...,  0.3032, -0.5449,  0.6260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0742,  0.2666,  0.2102,  ..., -0.3896,  0.2847, -0.1440],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:23:51 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:23:51 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 21:24:23 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 21:24:57 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 21:25:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.8501e-03, -2.7637e-03,  5.1765e-03,  ...,  7.7248e-05,
          2.1000e-03, -2.0790e-03],
        [ 2.8534e-03, -6.1493e-03,  4.7264e-03,  ...,  1.6022e-03,
          1.5526e-03, -3.7694e-04],
        [ 2.8539e-04,  4.3221e-03, -7.7705e-03,  ..., -1.0834e-03,
         -3.0613e-04, -1.7424e-03],
        ...,
        [ 1.2505e-04, -2.7008e-03,  7.1716e-04,  ..., -6.3553e-03,
         -1.4439e-03,  1.8749e-03],
        [ 6.2904e-03, -9.8515e-04, -1.2913e-03,  ..., -5.5389e-03,
         -4.6997e-03, -1.6832e-03],
        [ 4.4289e-03, -1.0309e-03,  2.5940e-03,  ..., -2.3956e-03,
         -3.8815e-03, -4.5586e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1000,  0.0037,  0.0017,  ..., -0.0033,  0.0077,  0.0007],
        [ 0.0029, -0.1004,  0.0089,  ...,  0.0003, -0.0026, -0.0037],
        [ 0.0122,  0.0008, -0.1018,  ...,  0.0016,  0.0033,  0.0099],
        ...,
        [-0.0006,  0.0071,  0.0019,  ..., -0.1057,  0.0083,  0.0074],
        [-0.0038,  0.0012,  0.0117,  ..., -0.0091, -0.0981,  0.0030],
        [-0.0104,  0.0017,  0.0089,  ..., -0.0059,  0.0038, -0.0991]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1200,  0.0011, -0.0114,  ...,  0.0029,  0.0052,  0.0002],
        [-0.0002, -0.1190, -0.0058,  ...,  0.0012, -0.0033,  0.0036],
        [-0.0083,  0.0037, -0.1152,  ...,  0.0052,  0.0017, -0.0002],
        ...,
        [ 0.0064, -0.0021,  0.0095,  ..., -0.1215, -0.0019, -0.0012],
        [ 0.0010,  0.0010, -0.0015,  ...,  0.0100, -0.1138, -0.0026],
        [-0.0055,  0.0045, -0.0026,  ..., -0.0111,  0.0070, -0.1202]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:25:34 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-29 21:25:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6064, -0.0342,  0.7793,  ...,  0.0473, -0.1359,  1.2432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0439,  0.2048,  0.3340,  ..., -0.6343, -0.0262,  0.6807],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6904,  0.3999,  0.1592,  ...,  0.3000, -0.7051,  0.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9141, -0.0957, -0.1948,  ..., -0.6875,  0.3643,  0.1147],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:25:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:25:34 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 21:26:13 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 21:26:51 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 21:27:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0481e-03,  2.1191e-03, -1.1711e-03,  ...,  2.1324e-03,
         -1.9102e-03,  1.4925e-03],
        [ 1.5764e-03,  2.9106e-03, -2.4776e-03,  ...,  3.0632e-03,
          3.8280e-03, -2.3556e-03],
        [ 3.3188e-03, -3.8471e-03,  1.6630e-05,  ..., -3.9024e-03,
         -2.8629e-03,  7.6103e-04],
        ...,
        [ 1.5297e-03, -2.5501e-03,  4.0588e-03,  ...,  1.6284e-04,
         -9.6989e-04,  3.8414e-03],
        [-4.9973e-03,  8.5473e-05, -7.0858e-04,  ...,  4.6234e-03,
         -8.1825e-04,  2.2831e-03],
        [ 3.7551e-04, -3.2768e-03,  2.7657e-03,  ..., -3.0231e-03,
          6.0692e-03, -7.8487e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0815e-01,  2.0695e-03,  3.1328e-04,  ..., -1.9360e-03,
          1.4410e-03, -2.6970e-03],
        [ 3.4180e-03, -1.1523e-01, -1.5594e-02,  ..., -1.2085e-02,
          1.4229e-03,  9.8419e-03],
        [ 4.2038e-03, -2.2697e-03, -8.6975e-02,  ..., -4.1199e-03,
         -4.6234e-03, -5.7220e-05],
        ...,
        [-9.9640e-03, -4.7951e-03,  8.3847e-03,  ..., -9.6008e-02,
         -3.8147e-04, -1.9054e-03],
        [ 1.0719e-02, -5.9166e-03,  2.7294e-03,  ..., -1.3485e-03,
         -9.4604e-02, -9.8586e-05],
        [ 8.8501e-03, -2.4223e-03,  1.8005e-02,  ...,  4.6635e-04,
         -5.6839e-03, -1.0101e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1273e-01, -4.1618e-03,  6.3858e-03,  ..., -4.4174e-03,
         -3.3379e-05,  5.5771e-03],
        [-5.2605e-03, -1.0223e-01, -2.3937e-03,  ..., -1.5259e-04,
         -8.1711e-03,  5.2872e-03],
        [ 1.5221e-02,  4.4823e-04, -8.8867e-02,  ..., -2.8992e-04,
          5.5771e-03, -4.2419e-03],
        ...,
        [-1.8417e-02,  2.8419e-03, -5.9929e-03,  ..., -1.1853e-01,
          5.3787e-03,  3.7479e-03],
        [ 1.3107e-02,  2.7065e-03,  6.8665e-04,  ...,  7.9041e-03,
         -1.0803e-01, -1.0109e-04],
        [ 2.2335e-03, -7.0801e-03,  6.5804e-03,  ...,  9.7504e-03,
          6.9199e-03, -1.2122e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:27:33 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-29 21:27:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0879,  0.5518,  0.3621,  ...,  0.2161, -0.4231,  0.4763],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9902,  0.2468,  0.1742,  ..., -0.3347,  0.2496, -0.1550],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5449,  0.0620,  0.8770,  ..., -0.2356, -1.2021,  0.6519],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7866, -0.5845, -0.1310,  ..., -0.8975,  0.6396,  0.2445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:27:33 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:27:33 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 21:28:10 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 21:28:51 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 21:29:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.4915e-03, -3.3913e-03, -1.6775e-03,  ...,  6.2084e-04,
         -8.0872e-04, -2.6588e-03],
        [-1.1406e-03, -6.0921e-03, -4.3392e-04,  ..., -5.3406e-03,
          1.9503e-04, -3.8815e-03],
        [ 3.3140e-04, -6.0320e-04, -4.0932e-03,  ...,  1.3113e-03,
          2.6741e-03, -5.1546e-04],
        ...,
        [-2.4185e-03, -1.2856e-03, -1.1940e-03,  ..., -6.1073e-03,
         -1.2360e-03, -2.6531e-03],
        [-7.3862e-04, -3.3150e-03,  2.7657e-04,  ...,  1.7548e-04,
         -8.5297e-03,  1.3828e-05],
        [ 2.2984e-03,  5.7678e-03, -1.5984e-03,  ...,  2.1152e-03,
          2.1553e-04, -7.1335e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0952,  0.0010,  0.0064,  ..., -0.0138, -0.0056,  0.0131],
        [-0.0011, -0.1003,  0.0036,  ..., -0.0069, -0.0058,  0.0014],
        [-0.0090, -0.0050, -0.0928,  ...,  0.0073, -0.0037, -0.0003],
        ...,
        [-0.0034,  0.0020, -0.0056,  ..., -0.1107,  0.0003,  0.0015],
        [-0.0040, -0.0024, -0.0042,  ..., -0.0006, -0.0941,  0.0052],
        [ 0.0127,  0.0075, -0.0149,  ..., -0.0045, -0.0021, -0.1078]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1327,  0.0080,  0.0035,  ..., -0.0214, -0.0012, -0.0053],
        [-0.0019, -0.1350,  0.0110,  ..., -0.0160, -0.0021,  0.0085],
        [-0.0037,  0.0081, -0.1199,  ..., -0.0025, -0.0048,  0.0136],
        ...,
        [-0.0042,  0.0041, -0.0090,  ..., -0.1257,  0.0021, -0.0112],
        [-0.0044,  0.0065, -0.0106,  ..., -0.0082, -0.1229,  0.0043],
        [-0.0034, -0.0066, -0.0092,  ..., -0.0072,  0.0060, -0.1216]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:29:35 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-29 21:29:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1045,  0.2656,  0.0487,  ...,  0.1650, -0.4700,  0.4727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7891, -0.0840, -0.2059,  ..., -0.5596,  0.2830,  0.0828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9795,  0.3008,  1.5312,  ..., -0.4705, -1.3506,  0.4487],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5186, -1.1172,  0.1320,  ..., -1.0488,  0.7246, -0.0455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:29:35 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:29:35 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 21:30:23 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 21:31:10 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 21:31:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1744e-03,  5.2032e-03,  9.8038e-04,  ..., -2.9964e-03,
          3.7270e-03, -1.1234e-03],
        [ 5.2376e-03,  7.3910e-05, -2.1915e-03,  ..., -6.4430e-03,
         -2.5330e-03, -4.6577e-03],
        [-5.1537e-03, -1.0242e-03,  8.4152e-03,  ...,  1.4567e-04,
         -6.3658e-04, -8.1158e-04],
        ...,
        [ 4.2057e-04, -1.9684e-03,  3.0975e-03,  ...,  7.2441e-03,
         -5.7831e-03,  1.1539e-03],
        [-4.9286e-03,  1.3800e-03,  7.5989e-03,  ..., -3.7327e-03,
          7.2718e-04,  3.4199e-03],
        [ 1.1415e-03, -4.4174e-03, -9.7466e-04,  ..., -1.4515e-03,
          2.0332e-03,  5.0430e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1096e-01, -1.6068e-02,  4.7188e-03,  ..., -1.1688e-02,
          3.0785e-03, -5.2261e-03],
        [-7.3776e-03, -1.2927e-01,  9.6130e-04,  ...,  7.7057e-03,
          2.4796e-05, -6.1493e-03],
        [ 8.7662e-03, -6.8207e-03, -1.1743e-01,  ..., -2.2945e-03,
         -6.7444e-03, -1.3123e-02],
        ...,
        [ 8.4763e-03, -4.5471e-03,  1.7670e-02,  ..., -1.2201e-01,
         -7.6752e-03,  3.6850e-03],
        [ 4.5242e-03,  4.7531e-03,  8.2092e-03,  ..., -6.5956e-03,
         -1.3599e-01, -9.5797e-04],
        [ 6.0349e-03, -1.5354e-03,  1.2917e-02,  ..., -4.3182e-03,
          1.2718e-02, -1.0852e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.9519e-01, -9.5978e-03, -3.1071e-03,  ...,  9.2545e-03,
          5.5313e-03, -8.2397e-03],
        [-5.3787e-04, -1.9287e-01, -1.6876e-02,  ...,  9.3079e-03,
          8.1635e-03,  1.4450e-02],
        [ 5.1498e-05, -8.4152e-03, -1.7346e-01,  ..., -7.6447e-03,
         -2.5311e-03, -7.7133e-03],
        ...,
        [ 6.1302e-03, -2.5444e-03, -3.9139e-03,  ..., -1.9519e-01,
         -4.9095e-03,  1.1436e-02],
        [ 1.5930e-02,  1.3008e-03,  1.3351e-02,  ...,  4.6234e-03,
         -1.9409e-01, -1.7090e-02],
        [-9.2392e-03,  3.7079e-03,  3.1281e-03,  ..., -9.9335e-03,
         -1.5007e-02, -1.7529e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:31:59 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-29 21:31:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9453,  0.0207,  0.4697,  ..., -0.1260, -0.7295,  0.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6362, -0.4951, -0.1384,  ..., -0.6777,  0.4934,  0.1604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8750,  0.0826,  1.7266,  ..., -0.7744, -0.9023,  0.8086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6562, -1.2773,  0.6211,  ..., -0.8506,  0.5811,  1.1816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:31:59 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:31:59 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 21:32:50 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 21:33:39 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 21:34:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.4218e-03, -1.1921e-03,  1.6718e-03,  ...,  2.1610e-03,
          2.8038e-03,  4.6539e-03],
        [-3.7231e-03,  3.8767e-04,  8.3637e-04,  ...,  5.3139e-03,
          3.2654e-03,  4.3755e-03],
        [ 1.2302e-03,  1.8005e-03, -3.9062e-03,  ..., -1.1311e-03,
         -2.9736e-03, -2.4259e-05],
        ...,
        [ 2.4033e-03, -1.0958e-03,  3.2253e-03,  ..., -3.5172e-03,
         -4.4861e-03,  3.0537e-03],
        [ 2.7323e-04, -4.4670e-03,  1.4935e-03,  ..., -3.3379e-05,
         -4.0054e-03,  2.4567e-03],
        [-2.3174e-03,  2.1324e-03, -4.0364e-04,  ...,  4.0703e-03,
          4.5433e-03, -1.3723e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1318,  0.0134, -0.0020,  ..., -0.0052, -0.0031, -0.0029],
        [ 0.0030, -0.1282,  0.0048,  ...,  0.0090, -0.0039, -0.0082],
        [-0.0086, -0.0015, -0.1283,  ...,  0.0014,  0.0143,  0.0026],
        ...,
        [ 0.0055,  0.0044,  0.0086,  ..., -0.1031,  0.0028, -0.0113],
        [ 0.0017,  0.0060,  0.0150,  ...,  0.0182, -0.1093,  0.0167],
        [ 0.0097,  0.0086,  0.0020,  ..., -0.0013, -0.0008, -0.1202]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1284,  0.0095, -0.0099,  ..., -0.0091,  0.0007, -0.0076],
        [ 0.0051, -0.1132,  0.0051,  ...,  0.0009, -0.0137, -0.0048],
        [ 0.0048, -0.0032, -0.1189,  ...,  0.0060, -0.0075, -0.0049],
        ...,
        [-0.0040, -0.0017,  0.0106,  ..., -0.1135,  0.0056, -0.0172],
        [-0.0027, -0.0057, -0.0088,  ...,  0.0014, -0.1113,  0.0197],
        [ 0.0040,  0.0021, -0.0074,  ...,  0.0044, -0.0018, -0.1342]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:34:30 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-29 21:34:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5464,  0.1539,  0.7788,  ..., -0.2896, -0.7734,  0.2610],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3813, -0.8242,  0.0432,  ..., -0.7363,  0.4795, -0.0297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2910,  0.2993,  1.1074,  ..., -0.5576, -0.6523,  0.6104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5391, -0.9253,  0.6533,  ..., -0.7007,  1.0820,  0.5786],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:34:30 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:34:30 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 21:35:20 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 21:36:13 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 21:37:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0086, -0.0011,  0.0039,  ..., -0.0002,  0.0015,  0.0050],
        [ 0.0027,  0.0030,  0.0006,  ..., -0.0014,  0.0034,  0.0023],
        [ 0.0005, -0.0036,  0.0076,  ...,  0.0002,  0.0035,  0.0007],
        ...,
        [ 0.0021,  0.0010,  0.0014,  ...,  0.0095, -0.0003,  0.0035],
        [ 0.0002, -0.0017,  0.0019,  ...,  0.0029,  0.0092, -0.0005],
        [-0.0005,  0.0030, -0.0021,  ..., -0.0027, -0.0003,  0.0046]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.2002,  0.0054, -0.0014,  ...,  0.0003, -0.0040, -0.0091],
        [ 0.0012, -0.1958,  0.0054,  ..., -0.0075,  0.0066, -0.0063],
        [-0.0019,  0.0021, -0.1832,  ..., -0.0027,  0.0006, -0.0100],
        ...,
        [-0.0068,  0.0011,  0.0071,  ..., -0.1824, -0.0072,  0.0016],
        [ 0.0016, -0.0038, -0.0066,  ..., -0.0092, -0.2106, -0.0074],
        [-0.0118, -0.0096, -0.0188,  ..., -0.0018,  0.0082, -0.1807]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2664,  0.0042,  0.0060,  ..., -0.0012, -0.0060, -0.0055],
        [-0.0127, -0.2712,  0.0039,  ..., -0.0164,  0.0276,  0.0009],
        [-0.0089,  0.0097, -0.2454,  ...,  0.0108,  0.0083, -0.0109],
        ...,
        [-0.0093, -0.0112, -0.0058,  ..., -0.2559,  0.0194,  0.0091],
        [-0.0115,  0.0123, -0.0015,  ...,  0.0176, -0.2578,  0.0033],
        [ 0.0047, -0.0162, -0.0063,  ...,  0.0003,  0.0065, -0.2539]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:37:08 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-29 21:37:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5044,  0.0333,  0.9443,  ..., -0.4670, -0.5532,  0.4492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5483, -1.0283,  0.4146,  ..., -0.6606,  0.4438,  0.9038],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7500,  0.3501,  1.4092,  ..., -0.7856, -0.7910,  0.5283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0234, -0.7993,  0.1890,  ..., -1.0596,  1.2402,  0.5845],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:37:08 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:37:08 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 21:38:03 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 21:38:59 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 21:39:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0044,  0.0042,  0.0013,  ..., -0.0011,  0.0028, -0.0025],
        [-0.0016, -0.0095, -0.0008,  ..., -0.0038, -0.0013,  0.0003],
        [ 0.0024,  0.0036, -0.0095,  ..., -0.0009, -0.0012, -0.0020],
        ...,
        [-0.0001,  0.0011, -0.0043,  ..., -0.0112,  0.0012,  0.0021],
        [ 0.0024, -0.0019,  0.0008,  ..., -0.0076, -0.0094, -0.0002],
        [-0.0019,  0.0015, -0.0015,  ...,  0.0044,  0.0009, -0.0093]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1114,  0.0139,  0.0137,  ..., -0.0050,  0.0012, -0.0059],
        [ 0.0117, -0.0937, -0.0148,  ..., -0.0082, -0.0040,  0.0186],
        [ 0.0063, -0.0212, -0.0905,  ...,  0.0029,  0.0001,  0.0062],
        ...,
        [-0.0131,  0.0093,  0.0086,  ..., -0.0923, -0.0037, -0.0022],
        [ 0.0017, -0.0017, -0.0061,  ..., -0.0066, -0.0948,  0.0142],
        [-0.0041, -0.0037, -0.0018,  ..., -0.0066,  0.0145, -0.1011]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1030,  0.0006, -0.0014,  ..., -0.0072,  0.0027, -0.0025],
        [ 0.0105, -0.1207,  0.0008,  ..., -0.0020,  0.0085,  0.0046],
        [-0.0037, -0.0235, -0.1164,  ..., -0.0048, -0.0140,  0.0102],
        ...,
        [ 0.0011,  0.0142,  0.0065,  ..., -0.0947, -0.0058, -0.0083],
        [ 0.0066, -0.0037,  0.0044,  ...,  0.0051, -0.1107,  0.0125],
        [ 0.0043, -0.0094,  0.0011,  ..., -0.0107,  0.0094, -0.1097]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:39:58 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-29 21:39:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7544,  0.1343,  0.5908,  ..., -0.3289, -0.3696,  0.3308],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4172, -0.7354,  0.4536,  ..., -0.5239,  0.8066,  0.4172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6924,  0.1263,  1.6445,  ..., -0.6270, -0.9727,  1.0459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1200, -0.9497,  1.0215,  ..., -0.4512,  1.0576,  0.5732],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:39:58 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:39:58 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 21:40:54 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 21:41:52 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 21:42:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.9411e-03, -2.9716e-03, -5.4131e-03,  ...,  7.0114e-03,
          2.8305e-03,  8.9741e-04],
        [-7.6218e-03,  2.1072e-02, -4.3774e-04,  ...,  1.5736e-03,
         -2.2984e-03, -3.9940e-03],
        [-1.4791e-03,  6.0272e-04,  9.7809e-03,  ...,  3.2482e-03,
         -2.7790e-03,  2.1744e-03],
        ...,
        [ 1.1854e-03,  2.3746e-03,  7.0610e-03,  ...,  1.3878e-02,
         -1.4854e-02,  4.5319e-03],
        [ 8.8167e-04,  3.0518e-03,  7.7667e-03,  ...,  3.3722e-03,
          1.3908e-02,  7.7772e-04],
        [ 3.6716e-03, -3.8624e-05, -8.4686e-03,  ..., -8.9798e-03,
         -8.1940e-03,  1.2070e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1180, -0.0175, -0.0196,  ..., -0.0025,  0.0149,  0.0115],
        [ 0.0006, -0.1346, -0.0048,  ...,  0.0088,  0.0083,  0.0036],
        [ 0.0099,  0.0037, -0.1194,  ...,  0.0095,  0.0050,  0.0024],
        ...,
        [-0.0069, -0.0004,  0.0112,  ..., -0.1268,  0.0170, -0.0005],
        [ 0.0070,  0.0182,  0.0053,  ...,  0.0098, -0.1215, -0.0070],
        [ 0.0143, -0.0002, -0.0142,  ..., -0.0065,  0.0076, -0.1368]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1246, -0.0078, -0.0010,  ..., -0.0083,  0.0115, -0.0005],
        [-0.0211, -0.1442, -0.0155,  ..., -0.0010, -0.0062,  0.0151],
        [ 0.0120,  0.0037, -0.1348,  ..., -0.0100,  0.0033, -0.0048],
        ...,
        [ 0.0012, -0.0093,  0.0021,  ..., -0.1191,  0.0050,  0.0042],
        [ 0.0082,  0.0070,  0.0033,  ...,  0.0108, -0.1383,  0.0046],
        [ 0.0044,  0.0134,  0.0095,  ..., -0.0013,  0.0019, -0.1283]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:42:53 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-29 21:42:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8677,  0.1569,  0.6460,  ..., -0.4072, -0.3757,  0.2144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0417, -0.5127,  0.0851,  ..., -0.6597,  0.8037,  0.3137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2891,  0.2428,  1.7373,  ..., -1.1475, -0.4199,  1.1240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.3848, -1.3906, -0.3906,  ..., -1.2148,  1.1680,  0.0186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:42:53 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:42:53 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 21:43:54 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 21:44:54 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 21:45:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.9182e-03, -1.0506e-02,  3.4809e-03,  ..., -1.9007e-03,
         -1.2581e-02, -5.5656e-03],
        [ 3.3970e-03,  1.1673e-02, -5.7678e-03,  ..., -2.7809e-03,
          2.4529e-03,  1.8415e-03],
        [-7.3242e-03, -2.2717e-03,  1.0010e-02,  ..., -9.3651e-04,
         -4.3297e-03,  1.5869e-03],
        ...,
        [ 6.7787e-03,  4.6349e-03, -6.6528e-03,  ...,  1.2077e-02,
         -1.0958e-03,  2.5368e-03],
        [ 2.1515e-03, -1.4191e-03,  1.8816e-03,  ...,  2.0065e-03,
          1.0460e-02,  4.2038e-03],
        [ 2.2449e-03,  1.0323e-02, -3.4752e-03,  ..., -3.0270e-03,
          6.3181e-06,  1.1620e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.9539e-02,  1.1604e-02,  2.3901e-05,  ...,  4.8485e-03,
          5.6305e-03,  3.6049e-04],
        [ 1.2150e-03, -1.0590e-01, -2.7962e-03,  ..., -1.1978e-02,
          1.5022e-02, -3.9825e-03],
        [ 7.3910e-04,  2.3670e-03, -7.6416e-02,  ..., -1.4830e-03,
          1.1971e-02, -9.9487e-03],
        ...,
        [ 2.7943e-04, -1.0727e-02, -1.3771e-02,  ..., -1.0040e-01,
          1.0269e-02,  1.9016e-03],
        [ 1.5327e-02,  7.9498e-03,  1.2047e-02,  ...,  6.3181e-04,
         -9.6252e-02, -6.5498e-03],
        [ 4.2343e-04, -1.0681e-02, -1.2169e-03,  ...,  3.9330e-03,
          3.3379e-04, -1.0199e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3501e-01,  2.1133e-03, -2.5406e-03,  ..., -1.9348e-02,
          1.1978e-02,  1.1692e-03],
        [ 1.1368e-02, -1.2067e-01,  6.4583e-03,  ...,  1.4366e-02,
          2.7943e-04,  1.0201e-02],
        [-3.2425e-05, -1.1353e-02, -1.1749e-01,  ..., -7.3700e-03,
          1.4877e-02,  1.0328e-03],
        ...,
        [-1.3016e-02, -1.0544e-02, -1.2817e-02,  ..., -1.3232e-01,
          3.8528e-04, -9.6130e-03],
        [ 4.7951e-03,  1.6129e-02,  1.9577e-02,  ...,  2.0340e-02,
         -1.2988e-01, -1.1589e-02],
        [-5.0125e-03, -1.1322e-02, -1.3596e-02,  ..., -7.9918e-04,
         -9.3155e-03, -1.2659e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:45:59 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-29 21:45:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8096,  0.0261,  0.7354,  ..., -0.3013, -0.4478,  0.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0661, -0.5913,  0.5698,  ..., -0.2698,  0.6177,  0.3059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4004,  1.0898,  2.0352,  ..., -1.3662,  0.2905,  1.4072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2510, -1.2559, -0.7837,  ..., -1.3857,  1.0000,  0.6201],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:45:59 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:45:59 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 21:47:00 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 21:48:02 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 21:49:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0108,  0.0036, -0.0009,  ...,  0.0027, -0.0068,  0.0004],
        [ 0.0043,  0.0045,  0.0028,  ...,  0.0002,  0.0038, -0.0028],
        [ 0.0051, -0.0033,  0.0084,  ..., -0.0001, -0.0044, -0.0038],
        ...,
        [-0.0103, -0.0037,  0.0016,  ...,  0.0005, -0.0086,  0.0040],
        [-0.0010,  0.0007,  0.0056,  ..., -0.0037,  0.0081, -0.0029],
        [-0.0005,  0.0001,  0.0067,  ..., -0.0010, -0.0027,  0.0084]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0303e-01, -2.3117e-03, -1.3031e-02,  ...,  2.7390e-03,
         -5.8174e-03,  1.3466e-02],
        [-7.0000e-03, -1.0986e-01, -3.0918e-03,  ..., -1.1261e-02,
         -7.2861e-04, -2.3651e-04],
        [ 8.4534e-03, -1.1742e-02, -1.1279e-01,  ...,  2.3575e-03,
         -1.0918e-02, -3.5133e-03],
        ...,
        [ 1.6870e-03,  1.1948e-02, -5.1575e-03,  ..., -1.0046e-01,
         -5.6305e-03, -2.3155e-03],
        [ 7.6866e-03, -1.0315e-02, -4.3983e-03,  ...,  8.2703e-03,
         -9.1675e-02,  2.4719e-03],
        [ 9.5367e-07,  1.5430e-03, -9.9487e-03,  ..., -2.8610e-04,
          1.4969e-02, -1.0419e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1277, -0.0020, -0.0149,  ...,  0.0099,  0.0046,  0.0247],
        [ 0.0069, -0.1703, -0.0116,  ..., -0.0062, -0.0111,  0.0071],
        [ 0.0092,  0.0013, -0.1525,  ...,  0.0116,  0.0018,  0.0005],
        ...,
        [ 0.0108, -0.0126, -0.0008,  ..., -0.1522,  0.0052, -0.0050],
        [ 0.0037, -0.0087, -0.0184,  ...,  0.0090, -0.1542,  0.0010],
        [ 0.0142, -0.0010, -0.0019,  ...,  0.0004,  0.0193, -0.1503]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:49:06 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-29 21:49:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0371,  0.1160,  0.7441,  ..., -0.5273, -0.1906,  0.4980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1680, -0.7500, -0.2148,  ..., -0.6392,  0.6240, -0.0163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4912,  1.3799,  2.1621,  ..., -1.2344,  0.1160,  1.7148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9531, -1.4502, -0.5239,  ..., -1.5625,  0.5293,  1.2930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:49:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:49:07 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 21:49:56 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 21:51:02 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 21:52:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.6496e-03,  2.4796e-03,  3.8362e-04,  ...,  6.2904e-03,
          1.6136e-03, -2.8782e-03],
        [-8.1348e-04,  6.4774e-03, -3.3545e-04,  ...,  1.7490e-03,
          5.8126e-04, -2.8553e-03],
        [-4.0650e-05, -1.1292e-03,  6.5207e-05,  ...,  3.8319e-03,
         -1.5030e-03, -2.4986e-04],
        ...,
        [ 5.6419e-03,  2.0943e-03,  1.0681e-03,  ...,  2.8706e-03,
         -9.5673e-03, -1.5583e-03],
        [-2.9278e-03, -6.1846e-04, -2.1095e-03,  ...,  4.8943e-03,
          4.4861e-03,  7.1049e-04],
        [ 1.3876e-03, -1.2541e-03, -5.3358e-04,  ..., -1.0300e-03,
          4.8447e-03,  5.9032e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0638,  0.0034,  0.0018,  ...,  0.0020,  0.0018, -0.0149],
        [-0.0051, -0.0545,  0.0013,  ..., -0.0065, -0.0067, -0.0054],
        [ 0.0034,  0.0018, -0.0754,  ..., -0.0143,  0.0069,  0.0023],
        ...,
        [-0.0013, -0.0052,  0.0005,  ..., -0.0637, -0.0027,  0.0024],
        [-0.0104,  0.0109,  0.0125,  ...,  0.0038, -0.0771, -0.0045],
        [-0.0079,  0.0211,  0.0043,  ...,  0.0010,  0.0003, -0.0757]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0958,  0.0125,  0.0005,  ..., -0.0083, -0.0102,  0.0088],
        [ 0.0078, -0.0952, -0.0132,  ...,  0.0006, -0.0102, -0.0027],
        [ 0.0069,  0.0111, -0.0872,  ...,  0.0008, -0.0027, -0.0219],
        ...,
        [-0.0163,  0.0071, -0.0137,  ..., -0.0903,  0.0011,  0.0048],
        [ 0.0011,  0.0020, -0.0045,  ...,  0.0105, -0.0955,  0.0050],
        [-0.0023,  0.0041,  0.0100,  ..., -0.0049, -0.0183, -0.0984]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:52:06 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-29 21:52:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5908,  0.4619,  0.8291,  ..., -0.5679,  0.1343,  0.5581],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1091, -0.6055, -0.3538,  ..., -0.6396,  0.4863,  0.2571],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5400,  1.8955,  2.8359,  ..., -1.0732, -0.5078,  2.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.3730, -1.3945, -0.8418,  ..., -1.1016,  0.3730,  1.4033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:52:06 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:52:06 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 21:53:08 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 21:54:10 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 21:55:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.2714e-03, -1.3638e-04,  6.0558e-05,  ...,  1.5869e-03,
         -7.9870e-04,  3.2425e-03],
        [-2.5616e-03, -6.8932e-03,  6.3210e-03,  ..., -2.8210e-03,
          4.4746e-03, -1.5812e-03],
        [ 7.9203e-04, -1.0509e-03, -9.7733e-03,  ..., -4.1676e-04,
          2.7180e-04, -2.1210e-03],
        ...,
        [ 1.9350e-03, -2.1114e-03,  1.6623e-03,  ..., -7.1793e-03,
          6.3057e-03,  5.4216e-04],
        [ 9.8343e-03,  3.0708e-03,  7.0000e-04,  ...,  2.0428e-03,
         -1.0780e-02, -5.4550e-03],
        [ 2.4529e-03, -1.2655e-03,  1.9894e-03,  ..., -1.9016e-03,
         -7.8773e-04, -1.2711e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0418,  0.0186,  0.0044,  ...,  0.0185,  0.0111, -0.0048],
        [ 0.0160, -0.0726,  0.0137,  ..., -0.0089, -0.0063, -0.0054],
        [-0.0063, -0.0128, -0.0509,  ..., -0.0041, -0.0037, -0.0031],
        ...,
        [ 0.0002, -0.0122,  0.0020,  ..., -0.0621,  0.0078, -0.0074],
        [ 0.0265,  0.0032,  0.0085,  ..., -0.0033, -0.0580,  0.0058],
        [ 0.0092, -0.0019,  0.0104,  ...,  0.0005,  0.0056, -0.0632]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1069,  0.0130,  0.0051,  ...,  0.0070,  0.0089,  0.0126],
        [ 0.0142, -0.1144,  0.0054,  ..., -0.0200,  0.0062, -0.0101],
        [ 0.0049, -0.0064, -0.1290,  ..., -0.0110,  0.0032, -0.0157],
        ...,
        [ 0.0163, -0.0036,  0.0058,  ..., -0.1111,  0.0126,  0.0039],
        [ 0.0244,  0.0101,  0.0179,  ..., -0.0002, -0.1176, -0.0042],
        [ 0.0047, -0.0157, -0.0075,  ..., -0.0058,  0.0098, -0.1180]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:55:12 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-29 21:55:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5981,  0.5654,  0.8452,  ..., -0.5024,  0.0519,  0.6694],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4104, -0.6313, -0.2360,  ..., -0.6846,  0.2439,  0.5405],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1719,  2.9062,  2.8145,  ..., -1.3027,  0.2578,  2.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6362, -0.9243, -1.0381,  ..., -1.7129,  1.8125,  2.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:55:12 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:55:12 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 21:56:16 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 21:57:21 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 21:58:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2962e-02, -2.4929e-03, -3.2091e-04,  ..., -1.4343e-03,
         -1.9970e-03, -1.1311e-03],
        [-3.6469e-03,  5.4970e-03,  7.3814e-04,  ..., -1.5488e-03,
          2.2564e-03,  6.1154e-05],
        [ 3.5524e-04, -3.8204e-03,  1.0277e-02,  ..., -1.9112e-03,
          2.5043e-03, -2.0790e-03],
        ...,
        [-3.5262e-04,  8.2970e-04, -5.4264e-04,  ...,  1.1696e-02,
         -2.2774e-03, -2.5120e-03],
        [ 6.5660e-04,  3.9577e-05,  5.8098e-03,  ..., -6.7215e-03,
          7.7248e-03,  2.7199e-03],
        [-1.0252e-03,  3.4885e-03, -4.6158e-03,  ...,  4.4060e-03,
          2.1877e-03,  1.2505e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0387,  0.0074,  0.0086,  ..., -0.0191,  0.0020, -0.0103],
        [ 0.0150, -0.0627,  0.0037,  ..., -0.0011, -0.0017, -0.0109],
        [ 0.0005, -0.0030, -0.0389,  ..., -0.0026,  0.0088, -0.0150],
        ...,
        [ 0.0046, -0.0052, -0.0007,  ..., -0.0400,  0.0064, -0.0019],
        [ 0.0090,  0.0047, -0.0102,  ...,  0.0069, -0.0545, -0.0042],
        [-0.0064,  0.0008, -0.0130,  ..., -0.0206, -0.0012, -0.0512]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.9548e-02,  7.8201e-03,  1.0483e-02,  ..., -1.2955e-02,
         -1.2779e-02, -7.1220e-03],
        [ 2.7420e-02, -1.0925e-01,  4.7798e-03,  ..., -8.9798e-03,
         -8.0414e-03, -7.9155e-05],
        [-1.2459e-02, -4.9477e-03, -1.0602e-01,  ..., -9.5749e-03,
          7.9956e-03, -6.6910e-03],
        ...,
        [-2.3994e-03, -1.4992e-02, -1.4656e-02,  ..., -1.0291e-01,
          1.2604e-02,  1.2703e-02],
        [ 4.3640e-03, -1.1902e-02, -1.3535e-02,  ...,  8.6288e-03,
         -9.9609e-02,  2.8038e-04],
        [ 2.7466e-04, -3.8261e-03, -4.0512e-03,  ..., -1.9058e-02,
         -8.4457e-03, -9.4055e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 21:58:29 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-29 21:58:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6221,  0.7476,  1.0693,  ..., -0.4263, -0.1804,  1.0049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6162, -0.6196, -0.3787,  ..., -0.4819,  0.1884,  0.5869],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6465,  3.9102,  2.3867,  ..., -0.6426,  0.8755,  2.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0293, -1.1592, -0.7612,  ..., -1.6953,  2.4141,  2.7246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 21:58:29 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 21:58:29 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 21:59:35 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 22:00:40 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 22:01:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1971e-02, -8.0395e-04,  2.4354e-04,  ..., -2.3918e-03,
         -8.5783e-04, -4.1656e-03],
        [ 2.7542e-03,  1.2520e-02, -4.0474e-03,  ..., -1.2808e-03,
          3.6831e-03, -7.5161e-05],
        [-9.3079e-04, -3.7575e-03,  1.1093e-02,  ..., -1.2469e-04,
         -3.6657e-05, -1.0052e-03],
        ...,
        [-2.2392e-03, -2.5101e-03, -2.4834e-03,  ...,  1.1795e-02,
          2.3746e-04, -8.7023e-04],
        [-2.0409e-03,  3.9253e-03, -4.5509e-03,  ...,  2.0618e-03,
          8.5373e-03,  2.3651e-03],
        [-4.8637e-04, -1.7941e-05,  3.6621e-03,  ..., -2.1381e-03,
          2.4319e-03,  1.2306e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0312,  0.0040,  0.0080,  ..., -0.0106,  0.0159, -0.0120],
        [ 0.0098, -0.0377,  0.0181,  ...,  0.0054,  0.0130, -0.0002],
        [-0.0151, -0.0036, -0.0355,  ...,  0.0013, -0.0065, -0.0156],
        ...,
        [-0.0078, -0.0112,  0.0009,  ..., -0.0256, -0.0013, -0.0152],
        [-0.0033,  0.0040, -0.0176,  ..., -0.0395, -0.0300,  0.0098],
        [-0.0052,  0.0026,  0.0083,  ...,  0.0037,  0.0104, -0.0342]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0439, -0.0025, -0.0121,  ..., -0.0147,  0.0029, -0.0036],
        [ 0.0070, -0.0481,  0.0150,  ..., -0.0068,  0.0086, -0.0023],
        [-0.0248, -0.0030, -0.0523,  ...,  0.0031,  0.0078, -0.0009],
        ...,
        [ 0.0076, -0.0065, -0.0110,  ..., -0.0400, -0.0102, -0.0164],
        [ 0.0115,  0.0060, -0.0075,  ..., -0.0194, -0.0446,  0.0055],
        [-0.0019,  0.0060,  0.0042,  ...,  0.0066,  0.0015, -0.0464]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:01:49 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-29 22:01:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4526,  1.0977,  1.0039,  ..., -0.4871,  0.0908,  1.0684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2500, -0.3669, -0.3989,  ..., -0.6450,  0.6812,  0.8584],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2900,  3.8457,  2.2070,  ..., -0.7510,  1.0781,  2.0645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1172, -1.2559, -0.4888,  ..., -1.8066,  3.5977,  2.9902],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:01:50 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 22:01:50 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 22:02:56 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 22:04:08 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 22:05:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.2572e-03, -2.9240e-03,  2.0170e-04,  ...,  1.8167e-03,
         -1.4055e-04, -2.0199e-03],
        [ 1.0669e-05,  1.7385e-03, -2.5330e-03,  ..., -1.3046e-03,
         -1.4186e-05,  1.0443e-03],
        [-2.7847e-04, -1.1292e-03,  6.1750e-04,  ...,  9.6607e-04,
          5.9962e-05,  1.4758e-04],
        ...,
        [ 6.6400e-05,  3.9387e-04, -2.3270e-03,  ...,  9.7275e-04,
          2.0123e-03,  2.3899e-03],
        [ 1.2960e-03,  1.1864e-03, -2.0504e-03,  ..., -5.8889e-05,
          3.8280e-03, -2.6550e-03],
        [ 1.6203e-03, -2.1648e-03,  1.5106e-03,  ...,  9.4235e-05,
         -1.5450e-03,  9.3937e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0305, -0.0130, -0.0003,  ...,  0.0105, -0.0116,  0.0028],
        [ 0.0067, -0.0254,  0.0038,  ...,  0.0093,  0.0091, -0.0059],
        [-0.0081,  0.0089, -0.0298,  ..., -0.0082, -0.0070, -0.0009],
        ...,
        [ 0.0092,  0.0115, -0.0008,  ..., -0.0193,  0.0032, -0.0056],
        [ 0.0002,  0.0062,  0.0032,  ...,  0.0015, -0.0190,  0.0005],
        [-0.0047, -0.0053, -0.0099,  ...,  0.0003,  0.0068, -0.0205]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0276, -0.0009,  0.0098,  ...,  0.0157,  0.0030,  0.0015],
        [ 0.0075, -0.0402, -0.0070,  ...,  0.0245,  0.0048, -0.0002],
        [-0.0078,  0.0079, -0.0225,  ...,  0.0085,  0.0160, -0.0253],
        ...,
        [-0.0024,  0.0165,  0.0103,  ..., -0.0324, -0.0047, -0.0168],
        [-0.0026,  0.0206,  0.0025,  ...,  0.0097, -0.0291,  0.0108],
        [-0.0141, -0.0049,  0.0005,  ...,  0.0124, -0.0061, -0.0217]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:05:21 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-29 22:05:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5815,  1.3711,  0.8203,  ..., -0.2378,  0.3142,  0.9077],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3684, -0.4226, -0.2761,  ..., -0.6104,  0.8633,  0.9507],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3193,  4.1250,  2.4512,  ..., -0.4211,  1.0938,  1.8105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6475, -1.4814, -1.3516,  ..., -1.4678,  3.7695,  2.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:05:21 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 22:05:21 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 22:06:39 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 22:08:00 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 22:09:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0811e-02, -2.4586e-03,  2.7466e-03,  ..., -5.8365e-03,
          1.1148e-03,  1.6375e-03],
        [-3.1013e-03,  8.1482e-03,  2.9755e-04,  ...,  7.1602e-03,
         -2.7370e-03, -4.6425e-03],
        [-8.1062e-06, -4.4556e-03,  1.3702e-02,  ..., -1.2016e-03,
          2.6207e-03, -4.2191e-03],
        ...,
        [-7.2145e-04,  4.7112e-03,  5.6190e-03,  ...,  1.2115e-02,
          2.2030e-03, -2.1291e-04],
        [-6.5756e-04, -5.4741e-04, -1.0281e-03,  ...,  2.8152e-03,
          1.1482e-02,  5.8060e-03],
        [-1.1129e-03, -5.1165e-04, -1.5173e-03,  ..., -3.6488e-03,
          2.2087e-03,  1.7654e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.0975e-02, -8.2016e-03, -1.3672e-02,  ...,  9.1400e-03,
         -1.8326e-02,  1.9287e-02],
        [ 3.5629e-03, -2.8534e-02, -1.3344e-02,  ..., -3.5782e-03,
          5.4131e-03, -5.4131e-03],
        [-2.5368e-03, -1.8723e-02, -1.9547e-02,  ..., -1.5358e-02,
         -2.5215e-03, -1.7548e-02],
        ...,
        [ 1.2192e-02, -6.6490e-03,  8.4877e-04,  ..., -3.5431e-02,
          1.3245e-02,  3.2310e-03],
        [-1.4511e-02, -1.5587e-02,  2.9716e-03,  ..., -7.3013e-03,
         -3.9062e-02, -6.6280e-05],
        [ 5.5351e-03,  1.8883e-03,  4.9019e-03,  ...,  3.5152e-03,
         -4.6539e-03, -6.6109e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0328, -0.0080, -0.0012,  ...,  0.0133, -0.0074, -0.0033],
        [ 0.0184, -0.0441, -0.0063,  ...,  0.0105,  0.0146,  0.0140],
        [-0.0006,  0.0011, -0.0278,  ...,  0.0014,  0.0204, -0.0018],
        ...,
        [ 0.0185,  0.0082, -0.0251,  ..., -0.0312,  0.0076,  0.0196],
        [ 0.0048, -0.0275, -0.0093,  ..., -0.0091, -0.0584, -0.0058],
        [-0.0017, -0.0082, -0.0039,  ..., -0.0003,  0.0061, -0.0201]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:09:23 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-29 22:09:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4543,  1.2979,  0.7349,  ..., -0.2496,  0.3857,  0.7017],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3777, -0.4070, -0.1686,  ..., -0.5786,  1.2100,  0.9854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2871,  3.8809,  3.4219,  ..., -0.7266,  1.5703,  1.6699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7251, -1.3916, -0.8574,  ..., -1.3750,  3.3203,  1.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:09:23 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 22:09:23 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 22:10:44 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 22:12:04 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 22:13:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.5536e-03,  1.8663e-03, -6.3002e-05,  ..., -9.8610e-04,
         -1.9512e-03, -5.9128e-04],
        [-5.2071e-04, -7.3700e-03,  9.7370e-04,  ...,  4.4394e-04,
          9.7322e-04, -8.7619e-06],
        [ 1.3704e-03,  8.8215e-04, -7.7362e-03,  ..., -1.5917e-03,
         -1.6975e-04,  5.9938e-04],
        ...,
        [ 4.0007e-04,  5.3072e-04,  8.6784e-04,  ..., -6.3858e-03,
          8.5449e-04, -7.5960e-04],
        [ 2.5711e-03,  4.5776e-04, -6.5851e-04,  ...,  8.5354e-04,
         -7.9346e-03,  8.5831e-04],
        [-3.8958e-04,  1.4365e-05,  1.5163e-03,  ..., -1.2283e-03,
         -3.0708e-04, -7.4005e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.0405e-02,  2.1057e-02,  7.8583e-03,  ..., -5.1117e-03,
         -9.4528e-03,  1.0948e-02],
        [ 3.9330e-03, -4.2175e-02,  9.3689e-03,  ..., -2.1458e-04,
          1.7071e-04,  7.0152e-03],
        [ 9.7198e-03, -1.1574e-02, -3.5278e-02,  ..., -1.5984e-03,
         -1.2794e-02,  1.4465e-02],
        ...,
        [-8.6441e-03,  1.0468e-02, -1.4946e-02,  ..., -3.5706e-02,
         -2.6360e-03,  1.9646e-04],
        [-1.2465e-03, -2.0050e-02, -2.0813e-02,  ...,  1.5182e-02,
         -3.0685e-02, -5.3167e-04],
        [-5.2376e-03, -6.2828e-03,  1.6212e-05,  ..., -8.6441e-03,
         -1.3222e-02, -2.2964e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0651, -0.0021,  0.0076,  ...,  0.0079, -0.0242,  0.0026],
        [ 0.0177, -0.0645,  0.0171,  ...,  0.0060, -0.0200, -0.0028],
        [ 0.0074, -0.0247, -0.0754,  ..., -0.0143,  0.0035,  0.0205],
        ...,
        [ 0.0096, -0.0069,  0.0038,  ..., -0.0842, -0.0087, -0.0013],
        [ 0.0028, -0.0125, -0.0225,  ..., -0.0099, -0.0561,  0.0036],
        [-0.0113,  0.0051,  0.0071,  ..., -0.0121,  0.0109, -0.0661]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:13:29 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-29 22:13:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4609,  1.3535,  0.7773,  ..., -0.1339,  0.3872,  0.5854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2173, -0.4517, -0.4355,  ..., -0.4441,  1.2021,  0.8091],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.8838,  4.1797,  3.2559,  ..., -0.1562,  1.1934,  1.8271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1074, -1.0957, -0.9844,  ..., -0.0176,  3.5527,  1.5332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:13:29 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 22:13:29 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 22:14:53 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 22:16:17 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 22:17:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.8509e-03,  9.2697e-04,  1.2803e-04,  ...,  6.6662e-04,
         -3.9983e-04, -2.9802e-04],
        [-1.0710e-03,  2.9430e-03,  5.4073e-04,  ...,  1.9798e-03,
          5.3406e-04,  5.3549e-04],
        [ 2.3842e-04,  1.9970e-03,  4.7913e-03,  ...,  2.4281e-03,
          2.4939e-04,  3.8457e-04],
        ...,
        [ 6.0844e-04, -1.9093e-03, -3.9029e-04,  ...,  3.6583e-03,
         -5.2166e-04,  1.1462e-04],
        [-4.8876e-04, -3.0613e-04, -1.1492e-03,  ...,  4.6206e-04,
          3.2520e-03, -5.6458e-04],
        [-5.9319e-04, -3.1829e-05,  1.6489e-03,  ...,  4.7851e-04,
          1.5712e-04,  2.4109e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0010,  0.0101, -0.0039,  ..., -0.0035, -0.0080, -0.0074],
        [ 0.0304, -0.0193, -0.0008,  ...,  0.0071, -0.0166, -0.0085],
        [-0.0027,  0.0037,  0.0055,  ...,  0.0004,  0.0166,  0.0060],
        ...,
        [-0.0118, -0.0009, -0.0064,  ...,  0.0090,  0.0066, -0.0163],
        [-0.0282,  0.0032,  0.0194,  ..., -0.0083, -0.0043,  0.0163],
        [ 0.0139, -0.0017,  0.0097,  ..., -0.0030,  0.0115, -0.0299]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0168, -0.0127,  0.0013,  ...,  0.0117, -0.0086,  0.0019],
        [ 0.0081, -0.0515,  0.0047,  ...,  0.0008,  0.0052,  0.0011],
        [ 0.0033,  0.0021, -0.0528,  ..., -0.0133, -0.0029, -0.0032],
        ...,
        [-0.0115,  0.0048, -0.0218,  ..., -0.0320, -0.0062,  0.0023],
        [-0.0131,  0.0078,  0.0112,  ..., -0.0019, -0.0353,  0.0185],
        [ 0.0060, -0.0182,  0.0045,  ..., -0.0015, -0.0124, -0.0725]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:17:42 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-29 22:17:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7744,  1.2666,  1.0781,  ..., -0.2462,  0.5356,  0.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2291, -0.3828, -0.3066,  ..., -0.4192,  1.0312,  0.3225],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2949,  4.7500,  3.9395,  ..., -0.4707,  0.6558,  1.4863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1023,  0.5469, -0.4082,  ..., -1.1846,  2.7578,  1.6738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:17:42 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 22:17:42 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 22:19:04 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 22:20:26 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 22:21:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.2392e-03, -1.0328e-03,  3.6573e-04,  ...,  3.2253e-03,
          1.7986e-03,  2.4354e-04],
        [-1.3351e-03,  7.0953e-03, -3.3498e-04,  ..., -1.6413e-03,
         -3.5343e-03, -1.3409e-03],
        [-6.2943e-04,  2.1210e-03,  5.7220e-03,  ..., -1.4057e-03,
          1.2617e-03,  4.0855e-03],
        ...,
        [-1.5793e-03,  3.9444e-03,  7.4005e-04,  ...,  8.1024e-03,
          1.5907e-03,  3.6392e-03],
        [ 4.1389e-03,  1.1005e-03, -6.8665e-05,  ...,  3.8261e-03,
          8.9798e-03, -6.6109e-03],
        [ 3.1509e-03, -4.5891e-03, -2.7351e-03,  ..., -2.4986e-04,
          7.1526e-04,  1.1238e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0407,  0.0108,  0.0025,  ...,  0.0181,  0.0130, -0.0107],
        [-0.0220,  0.0018,  0.0223,  ...,  0.0020, -0.0056,  0.0044],
        [-0.0135,  0.0027,  0.0439,  ..., -0.0062, -0.0069, -0.0204],
        ...,
        [-0.0150,  0.0026, -0.0127,  ...,  0.0261, -0.0094, -0.0109],
        [-0.0009, -0.0061, -0.0206,  ...,  0.0124,  0.0365, -0.0150],
        [ 0.0118,  0.0013, -0.0130,  ..., -0.0241,  0.0017,  0.0493]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0222, -0.0132,  0.0095,  ..., -0.0027, -0.0006, -0.0036],
        [ 0.0139, -0.0549,  0.0033,  ..., -0.0155, -0.0211,  0.0113],
        [-0.0015, -0.0165, -0.0220,  ..., -0.0013, -0.0032, -0.0137],
        ...,
        [-0.0103, -0.0168, -0.0120,  ..., -0.0398,  0.0264,  0.0006],
        [-0.0032, -0.0128,  0.0020,  ...,  0.0046, -0.0206, -0.0044],
        [-0.0041, -0.0162,  0.0157,  ...,  0.0040,  0.0111, -0.0325]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:21:53 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-29 22:21:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6216,  1.2852,  0.9722,  ..., -0.0871,  0.3713,  0.5483],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0564, -0.2898, -0.3511,  ..., -0.0425,  1.0527,  0.4272],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0098,  5.6562,  3.7695,  ..., -0.8076,  0.9834,  1.5771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1055,  0.4795,  0.2974,  ..., -0.5293,  2.3516,  0.9297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:21:53 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 22:21:53 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 22:23:19 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 22:24:44 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 22:26:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.5034e-04, -5.1689e-04,  4.8375e-04,  ...,  2.1517e-05,
          2.3174e-04, -2.3758e-04],
        [ 3.1996e-04, -3.3903e-04,  7.6628e-04,  ...,  5.2643e-04,
          2.6798e-04,  4.2200e-04],
        [ 2.5725e-04, -5.6219e-04,  1.2102e-03,  ...,  5.0211e-04,
          1.9765e-04, -6.5994e-04],
        ...,
        [-7.5960e-04,  8.7833e-04, -1.0138e-03,  ...,  2.6560e-04,
         -3.8028e-04,  5.1856e-06],
        [ 4.8828e-04, -5.2357e-04,  1.1110e-04,  ...,  1.2124e-04,
          6.4325e-04,  1.6165e-04],
        [ 1.1387e-03, -2.8706e-04,  6.1703e-04,  ...,  6.1321e-04,
          1.0252e-04,  8.2111e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0114,  0.0118,  0.0042,  ..., -0.0002,  0.0184,  0.0076],
        [-0.0056, -0.0269,  0.0255,  ...,  0.0217, -0.0003, -0.0125],
        [-0.0117,  0.0205,  0.0057,  ..., -0.0013,  0.0007,  0.0159],
        ...,
        [-0.0076,  0.0075, -0.0095,  ...,  0.0250,  0.0148,  0.0144],
        [-0.0032,  0.0021,  0.0039,  ...,  0.0163,  0.0096,  0.0157],
        [-0.0012,  0.0169, -0.0065,  ...,  0.0227,  0.0053,  0.0149]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.6365e-03,  2.0538e-02,  1.5747e-02,  ..., -3.0785e-03,
         -6.8474e-03, -1.0147e-03],
        [-7.4310e-03, -9.3765e-03,  1.3268e-02,  ..., -9.3079e-03,
          1.8295e-02,  5.2643e-03],
        [-8.7357e-03, -1.5593e-03, -7.6942e-03,  ...,  6.3667e-03,
         -1.8784e-02,  8.0032e-03],
        ...,
        [-1.1024e-03,  1.1612e-02, -4.7531e-03,  ..., -1.1185e-02,
         -5.7518e-05,  3.7918e-03],
        [ 1.5869e-03, -7.8583e-03, -3.7231e-02,  ..., -2.0615e-02,
         -4.3335e-02,  1.1215e-02],
        [ 1.4656e-02,  5.5466e-03,  3.8624e-04,  ...,  2.2141e-02,
          8.5678e-03, -3.5309e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:26:12 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-29 22:26:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7139,  1.3330,  1.0166,  ..., -0.2312,  0.1565,  0.3701],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0205,  0.1764, -0.2014,  ..., -0.4282,  0.7427,  0.4211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.2500,  5.4219,  2.6016,  ..., -1.7100,  0.5474,  0.1953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8496,  0.8037, -1.4375,  ..., -1.2559,  2.9668, -0.8936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:26:12 root INFO     [order_1_approx] starting weight calculation for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 22:26:12 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 22:27:39 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 22:29:04 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 22:30:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.2746e-03,  1.6117e-04,  2.4283e-04,  ..., -1.0061e-04,
         -3.5191e-04, -5.2023e-04],
        [ 9.1648e-04,  1.0010e-02,  7.1883e-05,  ..., -2.0123e-03,
          3.4542e-03,  1.3771e-03],
        [ 1.7042e-03, -1.3075e-03,  6.0577e-03,  ..., -6.6566e-04,
         -7.0000e-04, -4.3678e-04],
        ...,
        [-9.8991e-04, -1.4801e-03, -2.2888e-05,  ...,  1.0536e-02,
         -2.5311e-03, -8.0061e-04],
        [-1.4544e-03,  8.6260e-04,  5.6553e-04,  ..., -5.8460e-04,
          9.1705e-03, -1.1454e-03],
        [ 7.7057e-04,  1.6575e-03, -8.2350e-04,  ..., -7.3195e-04,
         -8.3160e-04,  8.9264e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0201, -0.0095, -0.0022,  ..., -0.0022, -0.0009,  0.0047],
        [ 0.0065,  0.0012,  0.0017,  ..., -0.0015,  0.0155, -0.0036],
        [-0.0111,  0.0044, -0.0040,  ...,  0.0043, -0.0109,  0.0080],
        ...,
        [ 0.0029,  0.0037, -0.0046,  ...,  0.0106, -0.0178, -0.0167],
        [-0.0100,  0.0006, -0.0125,  ..., -0.0057,  0.0120,  0.0064],
        [-0.0070,  0.0193,  0.0057,  ...,  0.0119, -0.0016,  0.0065]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0336, -0.0114, -0.0142,  ..., -0.0067,  0.0150,  0.0197],
        [ 0.0147, -0.0436,  0.0026,  ..., -0.0040,  0.0132,  0.0065],
        [ 0.0070,  0.0016, -0.0444,  ..., -0.0102,  0.0089,  0.0134],
        ...,
        [-0.0074,  0.0106, -0.0140,  ..., -0.0400,  0.0003, -0.0010],
        [-0.0071,  0.0247, -0.0264,  ...,  0.0046, -0.0240, -0.0097],
        [-0.0236,  0.0189,  0.0226,  ...,  0.0027,  0.0063, -0.0216]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:30:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a citrus is lemon
A more specific term for a painting is watercolor
A more specific term for a bed is bunk
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is choker
A more specific term for a weapon is
2024-06-29 22:30:32 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 22:30:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2260, -0.2788,  0.4312,  ...,  0.0100,  0.7275,  0.1780],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0411,  0.2056,  0.1742,  ...,  0.3093, -0.2661, -0.1580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1237, -0.5776,  0.6523,  ...,  0.1272,  0.3716,  0.6499],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1160,  0.4277,  0.0511,  ...,  0.2013, -0.5303,  0.2837],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:30:33 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:30:33 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 22:30:56 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 22:31:19 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 22:31:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0033,  0.0003, -0.0030,  ...,  0.0012,  0.0005, -0.0021],
        [ 0.0003, -0.0047,  0.0003,  ...,  0.0033,  0.0011,  0.0015],
        [-0.0010, -0.0002, -0.0063,  ..., -0.0013, -0.0022,  0.0009],
        ...,
        [ 0.0009,  0.0007, -0.0005,  ..., -0.0043, -0.0010,  0.0010],
        [ 0.0011,  0.0003, -0.0004,  ..., -0.0022, -0.0038, -0.0002],
        [ 0.0008, -0.0001,  0.0004,  ..., -0.0008, -0.0007, -0.0036]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0294, -0.0066, -0.0008,  ...,  0.0066, -0.0012,  0.0019],
        [-0.0042, -0.0276, -0.0071,  ..., -0.0061,  0.0045,  0.0002],
        [-0.0035, -0.0052, -0.0324,  ..., -0.0125,  0.0063,  0.0070],
        ...,
        [ 0.0015,  0.0026, -0.0053,  ..., -0.0360, -0.0009, -0.0030],
        [-0.0009,  0.0031,  0.0031,  ...,  0.0043, -0.0299,  0.0045],
        [ 0.0002, -0.0075, -0.0055,  ...,  0.0017,  0.0029, -0.0312]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.3762e-02,  3.7804e-03,  4.0894e-03,  ..., -4.3106e-03,
          1.4381e-03, -5.1270e-03],
        [ 1.0376e-03, -4.6204e-02,  1.3561e-03,  ...,  1.2684e-03,
          2.2755e-03,  7.1526e-05],
        [-5.2452e-03,  1.1578e-03, -3.6346e-02,  ..., -5.5199e-03,
         -5.6763e-03, -2.6684e-03],
        ...,
        [ 7.0333e-04,  7.9060e-04, -3.3722e-03,  ..., -4.6204e-02,
          1.1301e-03,  3.4189e-04],
        [-1.5020e-03, -4.8637e-04,  6.9809e-04,  ...,  1.9970e-03,
         -4.1199e-02,  3.5787e-04],
        [-1.8101e-03, -7.9346e-04, -5.5809e-03,  ...,  2.7847e-03,
         -8.2350e-04, -4.0527e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:31:44 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-29 22:31:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3203, -0.4351,  0.4358,  ..., -0.1104,  0.6089,  0.2134],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0239,  0.1296,  0.1880,  ...,  0.0881, -0.3665, -0.0855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3760, -0.5537,  0.7085,  ..., -0.0410,  0.1719,  0.3914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2255,  0.2158,  0.2932,  ...,  0.0750, -0.3892,  0.3643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:31:45 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:31:45 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 22:32:09 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 22:32:33 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 22:32:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1444e-02, -2.0485e-03, -1.4143e-03,  ...,  3.0174e-03,
         -1.5879e-03, -8.8215e-04],
        [ 3.2902e-03, -7.9803e-03,  8.9645e-04,  ...,  3.5553e-03,
         -6.0081e-04, -6.3848e-04],
        [-1.8787e-03, -1.0900e-03, -5.0735e-03,  ..., -4.2200e-05,
          7.6532e-04, -4.0555e-04],
        ...,
        [-3.2735e-04, -1.4830e-03, -9.5558e-04,  ..., -5.6839e-03,
         -1.4639e-04, -3.0117e-03],
        [-1.4949e-04,  3.1738e-03,  2.6340e-03,  ..., -1.2722e-03,
         -8.5220e-03,  3.2735e-04],
        [ 1.7900e-03, -3.2463e-03,  7.6389e-04,  ..., -2.5215e-03,
         -7.9751e-05, -7.7744e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0523,  0.0025, -0.0081,  ...,  0.0014,  0.0026, -0.0026],
        [ 0.0035, -0.0535,  0.0068,  ...,  0.0086, -0.0065,  0.0096],
        [-0.0091,  0.0017, -0.0410,  ..., -0.0031, -0.0079, -0.0036],
        ...,
        [-0.0049,  0.0096, -0.0049,  ..., -0.0429, -0.0129,  0.0023],
        [-0.0061, -0.0094,  0.0082,  ...,  0.0004, -0.0316, -0.0004],
        [-0.0012,  0.0051,  0.0011,  ...,  0.0076, -0.0024, -0.0456]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0714,  0.0065, -0.0002,  ..., -0.0054,  0.0022, -0.0108],
        [-0.0001, -0.0763, -0.0043,  ..., -0.0033, -0.0041, -0.0004],
        [-0.0014,  0.0024, -0.0682,  ..., -0.0079,  0.0041, -0.0022],
        ...,
        [ 0.0030,  0.0057, -0.0016,  ..., -0.0705, -0.0041,  0.0014],
        [-0.0067, -0.0084,  0.0033,  ...,  0.0027, -0.0701,  0.0035],
        [-0.0043,  0.0017,  0.0051,  ..., -0.0005,  0.0022, -0.0696]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:32:59 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-29 22:32:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1267, -0.7388,  0.7734,  ...,  0.1440,  0.4341,  0.7827],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1934,  0.6450,  0.0760,  ...,  0.2949, -0.7871,  0.4231],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3120, -0.3550,  0.7520,  ...,  0.4573,  0.3386,  1.2490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6045,  0.1819,  0.1553,  ..., -0.0566, -0.9072,  0.7271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:32:59 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:32:59 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 22:33:23 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 22:33:48 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 22:34:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.6365e-03,  1.0233e-03, -1.2121e-03,  ..., -5.0306e-04,
         -2.0046e-03, -9.8324e-04],
        [ 1.2999e-03, -8.2932e-03,  2.3508e-04,  ...,  8.9455e-04,
          1.2026e-03,  9.6655e-04],
        [ 2.1114e-03, -1.1721e-03, -5.6190e-03,  ..., -1.1902e-03,
          1.1139e-03,  6.4993e-04],
        ...,
        [ 9.5224e-04,  5.9175e-04, -9.1696e-04,  ..., -7.4463e-03,
          1.4400e-03, -5.7077e-04],
        [ 5.6553e-04, -4.8542e-04, -1.3614e-04,  ...,  5.8270e-04,
         -5.6152e-03,  9.3746e-04],
        [ 1.5936e-03, -2.7299e-05,  2.2106e-03,  ...,  1.1444e-03,
         -1.0509e-03, -6.5765e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0385,  0.0029,  0.0056,  ...,  0.0099, -0.0003, -0.0017],
        [-0.0014, -0.0338, -0.0005,  ..., -0.0043,  0.0003, -0.0021],
        [ 0.0055,  0.0099, -0.0399,  ..., -0.0003,  0.0052,  0.0005],
        ...,
        [-0.0003,  0.0019, -0.0106,  ..., -0.0399, -0.0004,  0.0004],
        [ 0.0034,  0.0008, -0.0027,  ...,  0.0081, -0.0409, -0.0002],
        [-0.0004,  0.0072, -0.0107,  ...,  0.0035, -0.0011, -0.0368]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.9886e-02,  2.1095e-03,  2.8896e-04,  ...,  8.7814e-03,
         -6.7234e-05, -8.3160e-04],
        [-6.6528e-03, -3.9948e-02,  1.5381e-02,  ...,  7.7286e-03,
         -7.8354e-03, -2.9545e-03],
        [ 8.1711e-03,  1.2989e-03, -2.7985e-02,  ..., -3.3684e-03,
          2.9793e-03,  3.5992e-03],
        ...,
        [ 3.0231e-03,  6.5346e-03, -2.1935e-03,  ..., -3.9154e-02,
         -1.1253e-03,  4.7531e-03],
        [-5.6305e-03,  3.3398e-03, -1.2550e-03,  ...,  8.9741e-04,
         -3.4607e-02,  2.5826e-03],
        [-3.1223e-03,  3.8872e-03, -1.4114e-04,  ..., -3.8552e-04,
          7.9880e-03, -3.3936e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:34:15 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-29 22:34:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4651, -0.6758,  0.7954,  ..., -0.0442,  0.1721,  0.4231],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3618,  0.3083,  0.4346,  ...,  0.1149, -0.5840,  0.5278],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0845, -0.7598,  0.9922,  ...,  0.6318,  0.3589,  1.4854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7026,  0.3838,  0.1102,  ..., -0.6094, -0.1631,  1.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:34:15 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:34:15 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 22:34:42 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 22:35:09 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 22:35:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0026, -0.0003,  0.0008,  ...,  0.0027,  0.0020, -0.0019],
        [ 0.0008, -0.0039,  0.0005,  ..., -0.0013, -0.0004, -0.0016],
        [-0.0029, -0.0001, -0.0041,  ..., -0.0014,  0.0012,  0.0007],
        ...,
        [-0.0010, -0.0015, -0.0008,  ..., -0.0017, -0.0004, -0.0008],
        [-0.0015, -0.0005,  0.0032,  ..., -0.0017, -0.0031,  0.0038],
        [ 0.0007, -0.0043,  0.0006,  ..., -0.0006, -0.0006, -0.0056]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.2938e-02,  4.2343e-04, -1.2985e-02,  ..., -2.9964e-03,
          3.6736e-03,  3.4046e-03],
        [-1.6508e-03, -5.0934e-02,  4.4289e-03,  ...,  2.3155e-03,
          3.1013e-03,  9.6130e-04],
        [-2.5120e-03, -9.0599e-06, -3.9185e-02,  ...,  7.3853e-03,
         -3.7746e-03,  1.1501e-03],
        ...,
        [ 1.2283e-02,  5.0497e-04, -2.2240e-03,  ..., -3.5339e-02,
         -4.3640e-03, -5.1498e-03],
        [-1.0223e-02,  2.5902e-03, -7.4310e-03,  ..., -1.6165e-03,
         -4.3030e-02, -4.0131e-03],
        [-5.7144e-03, -7.3395e-03, -7.5760e-03,  ...,  2.4929e-03,
          2.9373e-04, -4.6906e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.6183e-02, -4.0293e-04,  3.9825e-03,  ..., -3.1052e-03,
         -1.3094e-03,  3.6163e-03],
        [ 6.5041e-03, -5.1483e-02, -4.0359e-03,  ..., -3.4962e-03,
          4.8256e-03, -1.5869e-03],
        [ 5.2605e-03, -7.5760e-03, -6.2744e-02,  ...,  9.3555e-04,
         -2.8667e-03,  3.1395e-03],
        ...,
        [ 4.8027e-03, -3.7050e-04,  2.7142e-03,  ..., -5.6000e-02,
         -9.8190e-03, -5.6076e-03],
        [ 4.2038e-03, -8.1730e-04, -5.4626e-03,  ..., -8.3847e-03,
         -5.7068e-02, -4.5395e-03],
        [ 2.4567e-03,  4.0054e-05, -3.0098e-03,  ...,  4.1580e-03,
         -3.5620e-04, -6.0364e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:35:41 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-29 22:35:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3171, -0.4097,  0.7051,  ...,  0.4070,  0.3628,  1.2158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6484,  0.1573,  0.1661,  ..., -0.0626, -0.9370,  0.7642],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1406, -0.7573,  1.5732,  ...,  0.6855,  0.3967,  1.4141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7021,  0.4602,  0.1501,  ..., -0.5732, -0.5850,  1.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:35:41 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:35:41 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 22:36:13 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 22:36:46 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 22:37:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.5444e-03,  2.8629e-03, -2.2793e-03,  ...,  4.1771e-03,
          1.7319e-03,  1.8349e-03],
        [ 2.4939e-04,  6.0844e-03,  1.5068e-04,  ...,  2.7204e-04,
         -5.6505e-04,  4.5319e-03],
        [-3.5763e-05,  9.5034e-04, -6.1369e-04,  ...,  5.8222e-04,
         -8.9312e-04,  1.0185e-03],
        ...,
        [-1.0118e-03,  2.0065e-03, -3.0708e-03,  ..., -4.2224e-04,
         -2.9583e-03, -3.1948e-04],
        [ 2.1706e-03, -1.6451e-04,  9.5654e-04,  ...,  2.4357e-03,
          3.9444e-03, -6.6137e-04],
        [ 1.6518e-03, -1.4496e-03, -1.5039e-03,  ..., -1.2627e-03,
         -2.6054e-03,  3.9520e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0823, -0.0027, -0.0073,  ..., -0.0026,  0.0016, -0.0064],
        [ 0.0023, -0.0813, -0.0047,  ...,  0.0017,  0.0002,  0.0009],
        [ 0.0016, -0.0019, -0.0701,  ..., -0.0095,  0.0042,  0.0027],
        ...,
        [ 0.0059,  0.0058, -0.0058,  ..., -0.0789, -0.0018,  0.0026],
        [ 0.0161, -0.0059, -0.0024,  ...,  0.0115, -0.0821,  0.0186],
        [-0.0072, -0.0095,  0.0019,  ...,  0.0075,  0.0120, -0.0925]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1171, -0.0065,  0.0041,  ..., -0.0084, -0.0047, -0.0022],
        [-0.0002, -0.1100,  0.0023,  ..., -0.0030, -0.0008, -0.0004],
        [ 0.0003,  0.0026, -0.1024,  ..., -0.0014,  0.0087, -0.0004],
        ...,
        [-0.0052,  0.0002,  0.0015,  ..., -0.0968,  0.0105, -0.0019],
        [-0.0002,  0.0029, -0.0039,  ..., -0.0044, -0.1129,  0.0105],
        [-0.0134,  0.0043,  0.0029,  ..., -0.0019, -0.0076, -0.1119]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:37:22 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-29 22:37:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0826, -0.7300,  0.8521,  ...,  0.5557,  0.3030,  1.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7324,  0.3962,  0.1019,  ..., -0.6001, -0.1820,  1.1377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3040, -0.7329,  1.5020,  ...,  0.6792,  0.0447,  1.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7324,  0.4600, -0.0370,  ..., -0.3132, -0.7646,  0.6289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:37:23 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:37:23 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 22:37:58 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 22:38:34 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 22:39:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.8289e-03, -1.4372e-03,  8.2245e-03,  ..., -1.4496e-03,
          1.8892e-03,  2.7370e-04],
        [ 3.4313e-03, -2.6569e-03,  6.4545e-03,  ...,  1.2932e-03,
         -3.5572e-04,  1.6775e-03],
        [-3.8481e-04,  3.2005e-03, -5.1155e-03,  ...,  1.2836e-03,
         -3.5343e-03, -3.5515e-03],
        ...,
        [ 1.4067e-03, -3.0308e-03, -4.8161e-04,  ..., -4.8828e-03,
         -1.4515e-03,  5.2333e-05],
        [ 7.2441e-03,  2.7237e-03, -5.8746e-03,  ..., -2.5387e-03,
         -4.7493e-03, -6.0558e-04],
        [ 3.7937e-03, -2.0828e-03,  1.2217e-03,  ..., -1.0926e-04,
         -4.7073e-03, -6.4182e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0733,  0.0054,  0.0143,  ...,  0.0002, -0.0075, -0.0088],
        [ 0.0076, -0.0742,  0.0101,  ...,  0.0095,  0.0098, -0.0019],
        [ 0.0018,  0.0069, -0.0723,  ..., -0.0038, -0.0017,  0.0090],
        ...,
        [ 0.0108, -0.0038,  0.0006,  ..., -0.0686, -0.0048,  0.0044],
        [ 0.0031,  0.0059,  0.0051,  ...,  0.0041, -0.0718,  0.0034],
        [-0.0132,  0.0210,  0.0059,  ..., -0.0121,  0.0091, -0.0824]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1481e-01,  6.2752e-03, -9.3536e-03,  ...,  4.4365e-03,
          3.8013e-03, -5.0774e-03],
        [-3.9482e-03, -1.2268e-01, -3.8185e-03,  ...,  4.7913e-03,
         -4.0550e-03,  5.9242e-03],
        [-8.4763e-03,  2.1324e-03, -1.1993e-01,  ...,  1.6403e-03,
          3.2883e-03, -3.7193e-05],
        ...,
        [ 8.0566e-03, -3.4237e-03,  9.8190e-03,  ..., -1.1621e-01,
         -5.8594e-03, -9.6703e-04],
        [ 5.3749e-03, -2.8114e-03, -2.6894e-03,  ...,  1.1673e-02,
         -1.1743e-01, -1.0414e-03],
        [-3.8242e-03,  8.3923e-03, -4.3640e-03,  ..., -1.3031e-02,
          3.9368e-03, -1.2097e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:39:11 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-29 22:39:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1172, -0.6802,  1.2861,  ...,  0.5391,  0.3367,  1.2412],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6812,  0.4714,  0.1207,  ..., -0.5444, -0.5615,  1.0830],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2489, -0.7256,  1.0889,  ...,  0.5146, -0.4739,  1.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6099, -0.1436, -0.1917,  ..., -0.4277, -0.5684,  0.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:39:11 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:39:11 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 22:39:47 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 22:40:24 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 22:41:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.1526e-05,  2.3651e-03, -2.2049e-03,  ...,  2.3975e-03,
         -1.8044e-03,  6.6948e-04],
        [ 3.3112e-03,  3.9520e-03, -7.5340e-04,  ...,  7.0992e-03,
          4.8561e-03, -1.5230e-03],
        [ 2.9755e-03, -2.1954e-03, -7.6056e-05,  ..., -5.2795e-03,
         -4.1199e-03,  2.1591e-03],
        ...,
        [-1.4675e-04, -1.2550e-03,  2.0714e-03,  ..., -1.6985e-03,
         -3.4275e-03,  3.9482e-03],
        [-4.3449e-03,  1.1683e-05, -3.8986e-03,  ...,  2.1915e-03,
          3.6087e-03,  2.8610e-05],
        [ 4.7874e-04, -2.7275e-03,  1.6813e-03,  ..., -4.2686e-03,
          6.5727e-03,  1.9932e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0798, -0.0011, -0.0065,  ..., -0.0171,  0.0059,  0.0022],
        [-0.0017, -0.0729, -0.0065,  ..., -0.0088, -0.0058,  0.0105],
        [ 0.0064, -0.0049, -0.0551,  ...,  0.0056,  0.0003, -0.0098],
        ...,
        [ 0.0040,  0.0005,  0.0013,  ..., -0.0710, -0.0005, -0.0036],
        [ 0.0081, -0.0010, -0.0001,  ..., -0.0026, -0.0822,  0.0013],
        [-0.0003, -0.0099,  0.0072,  ..., -0.0133, -0.0020, -0.0617]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1178, -0.0035,  0.0064,  ..., -0.0056, -0.0002,  0.0106],
        [-0.0037, -0.1068, -0.0076,  ..., -0.0004, -0.0062,  0.0037],
        [ 0.0122,  0.0011, -0.0968,  ...,  0.0051,  0.0040, -0.0028],
        ...,
        [-0.0144, -0.0011, -0.0099,  ..., -0.1165,  0.0039,  0.0008],
        [ 0.0109,  0.0061, -0.0027,  ...,  0.0135, -0.1083, -0.0011],
        [ 0.0116, -0.0076,  0.0071,  ...,  0.0050,  0.0009, -0.1278]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:41:05 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-29 22:41:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2496, -0.6309,  1.1484,  ...,  0.5098,  0.0252,  1.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6680,  0.4272, -0.0417,  ..., -0.2673, -0.6841,  0.5669],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3184, -0.2710,  1.1543,  ...,  0.4578, -0.6587,  1.5498],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5391, -0.5107, -0.2209,  ..., -0.5923, -0.5840,  0.9155],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:41:05 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:41:05 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 22:41:47 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 22:42:27 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 22:43:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.3864e-03, -4.0550e-03, -1.6308e-03,  ...,  1.7786e-03,
         -3.2158e-03, -6.3782e-03],
        [-2.1172e-03, -1.0284e-02, -3.4404e-04,  ..., -2.0142e-03,
         -3.7098e-03, -4.5013e-03],
        [-1.2503e-03,  8.3065e-04, -4.2725e-03,  ...,  2.2459e-04,
          6.6853e-04,  3.2139e-03],
        ...,
        [-2.3861e-03, -3.4504e-03,  2.9325e-04,  ..., -2.4815e-03,
         -8.3542e-04,  3.8204e-03],
        [-2.0087e-05, -1.3180e-03,  3.5515e-03,  ..., -3.1042e-04,
         -7.3013e-03, -1.3103e-03],
        [ 3.8300e-03,  5.4436e-03,  2.6283e-03,  ...,  1.3437e-03,
         -1.8082e-03, -1.1528e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.9956e-02, -6.4621e-03,  7.4863e-04,  ..., -1.3222e-02,
         -4.3373e-03,  5.4932e-03],
        [-1.2474e-03, -7.9834e-02, -7.9575e-03,  ..., -4.6997e-03,
          9.9258e-03,  6.0806e-03],
        [-5.0259e-04,  7.3547e-03, -6.9641e-02,  ...,  4.5624e-03,
         -1.0139e-02, -3.3379e-05],
        ...,
        [-1.9394e-02,  2.9812e-03, -3.7117e-03,  ..., -6.8726e-02,
          7.1220e-03,  9.5367e-03],
        [-1.8950e-03,  2.3651e-03,  1.8139e-03,  ..., -8.3237e-03,
         -7.4768e-02,  7.4005e-03],
        [ 1.4015e-02,  9.4299e-03, -1.1925e-02,  ...,  3.0079e-03,
          2.7752e-04, -8.6548e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1213,  0.0024, -0.0003,  ..., -0.0172, -0.0044,  0.0005],
        [ 0.0040, -0.1207,  0.0115,  ..., -0.0078, -0.0015,  0.0090],
        [ 0.0056,  0.0036, -0.1099,  ..., -0.0084, -0.0097,  0.0090],
        ...,
        [-0.0077,  0.0090, -0.0073,  ..., -0.1111,  0.0061, -0.0063],
        [-0.0056,  0.0074, -0.0126,  ..., -0.0136, -0.1136,  0.0123],
        [-0.0060, -0.0109, -0.0102,  ..., -0.0068,  0.0047, -0.1158]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:43:11 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-29 22:43:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1516, -0.5186,  0.6670,  ...,  0.3113, -0.3362,  1.1035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5356, -0.1261, -0.2046,  ..., -0.3574, -0.4810,  0.6660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0994, -0.1292,  1.1934,  ...,  0.4790, -1.1836,  2.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9561, -0.5449, -0.0573,  ..., -0.8774, -0.4666,  0.3384],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:43:12 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:43:12 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 22:43:59 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 22:44:46 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 22:45:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.9397e-04,  3.7327e-03, -3.4428e-03,  ..., -6.5765e-03,
         -3.9101e-03, -6.2370e-04],
        [ 4.7913e-03, -6.4697e-03, -3.4313e-03,  ..., -4.0207e-03,
         -8.6899e-03, -1.5774e-03],
        [-7.9880e-03,  7.4539e-03,  6.2637e-03,  ..., -1.8053e-03,
          2.0504e-03,  1.7166e-05],
        ...,
        [ 1.0681e-03, -9.5291e-03,  1.6708e-03,  ...,  5.5771e-03,
         -4.3640e-03,  6.5155e-03],
        [-5.2757e-03,  2.0752e-03,  7.7667e-03,  ...,  1.2708e-04,
         -9.3365e-04,  3.6860e-04],
        [ 2.4471e-03, -3.2043e-03,  2.3422e-03,  ..., -4.8409e-03,
          2.0485e-03,  7.7133e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.0627e-02, -1.8372e-02, -1.4648e-03,  ..., -1.3718e-02,
          3.3512e-03, -3.0231e-03],
        [ 5.2071e-03, -8.8623e-02,  7.3967e-03,  ...,  8.6899e-03,
         -2.7332e-03,  7.7820e-03],
        [-8.5373e-03,  6.1493e-03, -7.4402e-02,  ...,  1.2405e-02,
         -1.5167e-02, -2.3632e-03],
        ...,
        [ 7.0572e-05, -4.2877e-03,  2.5406e-02,  ..., -8.0688e-02,
          6.6223e-03,  3.9139e-03],
        [-1.2207e-03,  2.6131e-03, -2.9259e-03,  ..., -3.2368e-03,
         -9.6436e-02,  5.3062e-03],
        [-6.4087e-03, -8.4305e-03,  1.9348e-02,  ...,  2.7790e-03,
          8.8120e-03, -7.1045e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1970, -0.0049,  0.0063,  ...,  0.0051,  0.0042,  0.0063],
        [-0.0004, -0.1942, -0.0113,  ...,  0.0071,  0.0033,  0.0077],
        [-0.0060, -0.0068, -0.1674,  ..., -0.0025, -0.0020, -0.0090],
        ...,
        [ 0.0051,  0.0035,  0.0052,  ..., -0.1909, -0.0080,  0.0153],
        [ 0.0126,  0.0012,  0.0123,  ..., -0.0013, -0.1893, -0.0202],
        [-0.0016,  0.0030,  0.0033,  ..., -0.0027, -0.0133, -0.1713]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:45:20 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-29 22:45:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2021, -0.1898,  0.6494,  ...,  0.2786, -0.4202,  0.9424],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4192, -0.4199, -0.2021,  ..., -0.4280, -0.4622,  0.6899],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2864, -0.7363,  1.6816,  ...,  0.2791, -1.4229,  2.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8433, -0.4148,  0.3516,  ..., -0.9424, -0.1638,  1.4551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:45:20 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:45:20 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 22:46:05 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 22:46:41 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 22:47:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0037, -0.0015,  0.0017,  ...,  0.0029,  0.0027,  0.0022],
        [-0.0033,  0.0027,  0.0014,  ...,  0.0016,  0.0028,  0.0013],
        [ 0.0023, -0.0002, -0.0025,  ...,  0.0018, -0.0050, -0.0004],
        ...,
        [ 0.0032, -0.0018,  0.0030,  ..., -0.0004, -0.0011,  0.0009],
        [ 0.0008, -0.0027,  0.0011,  ...,  0.0028, -0.0040,  0.0027],
        [-0.0033,  0.0036, -0.0029,  ...,  0.0016,  0.0034, -0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0906,  0.0009, -0.0021,  ..., -0.0019,  0.0102,  0.0045],
        [ 0.0029, -0.0836,  0.0103,  ..., -0.0062, -0.0142, -0.0068],
        [-0.0055, -0.0045, -0.0861,  ...,  0.0018,  0.0036, -0.0090],
        ...,
        [ 0.0044, -0.0021,  0.0035,  ..., -0.0818,  0.0131, -0.0072],
        [ 0.0092, -0.0008, -0.0040,  ...,  0.0105, -0.0798,  0.0129],
        [ 0.0022,  0.0078, -0.0194,  ...,  0.0096,  0.0095, -0.0807]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1326,  0.0010,  0.0012,  ..., -0.0029,  0.0092, -0.0125],
        [ 0.0097, -0.1201,  0.0063,  ...,  0.0107, -0.0105, -0.0039],
        [ 0.0012, -0.0010, -0.1234,  ...,  0.0004, -0.0106,  0.0025],
        ...,
        [-0.0053, -0.0045,  0.0087,  ..., -0.1234,  0.0144, -0.0180],
        [-0.0019, -0.0022, -0.0127,  ...,  0.0119, -0.1231,  0.0153],
        [ 0.0028,  0.0038, -0.0093,  ...,  0.0037, -0.0009, -0.1375]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:47:35 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-29 22:47:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0421, -0.1006,  0.6191,  ...,  0.2333, -0.7070,  1.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6694, -0.3982, -0.0819,  ..., -0.6016, -0.3306,  0.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4131, -0.7104,  0.8687,  ...,  0.6572, -1.3906,  2.3027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6611,  0.1838,  0.3494,  ..., -0.6011, -0.0538,  0.8677],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:47:35 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:47:35 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 22:48:28 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 22:49:21 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-29 22:50:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0050, -0.0015,  0.0046,  ..., -0.0019, -0.0025,  0.0050],
        [ 0.0031,  0.0022, -0.0001,  ...,  0.0025,  0.0016,  0.0051],
        [-0.0022, -0.0048,  0.0099,  ..., -0.0064,  0.0053, -0.0019],
        ...,
        [ 0.0030,  0.0027,  0.0082,  ...,  0.0103, -0.0032,  0.0028],
        [-0.0011, -0.0050, -0.0005,  ..., -0.0001,  0.0105,  0.0019],
        [ 0.0017,  0.0041, -0.0018,  ...,  0.0007, -0.0015,  0.0069]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1348, -0.0038, -0.0002,  ...,  0.0025,  0.0117, -0.0061],
        [ 0.0024, -0.1355,  0.0075,  ..., -0.0090,  0.0029,  0.0051],
        [-0.0035, -0.0008, -0.1288,  ...,  0.0021, -0.0063,  0.0097],
        ...,
        [-0.0146, -0.0072,  0.0117,  ..., -0.1228,  0.0024,  0.0065],
        [ 0.0104,  0.0059, -0.0040,  ...,  0.0057, -0.1292,  0.0050],
        [ 0.0013, -0.0074, -0.0027,  ..., -0.0089,  0.0203, -0.1411]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2700,  0.0100, -0.0005,  ...,  0.0014, -0.0078, -0.0066],
        [-0.0030, -0.2734,  0.0016,  ..., -0.0063,  0.0338, -0.0004],
        [-0.0007,  0.0086, -0.2566,  ...,  0.0076,  0.0054, -0.0106],
        ...,
        [-0.0131, -0.0007, -0.0042,  ..., -0.2671,  0.0281,  0.0081],
        [-0.0076,  0.0081, -0.0025,  ...,  0.0122, -0.2627,  0.0096],
        [-0.0049, -0.0149,  0.0036,  ..., -0.0083,  0.0016, -0.2681]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:50:17 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-29 22:50:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1403, -0.4604,  0.8994,  ...,  0.1555, -0.8516,  1.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6792, -0.3354,  0.2062,  ..., -0.7124, -0.1332,  1.0947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2961, -0.6509,  0.8511,  ...,  0.3892, -2.1172,  2.8125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8032, -0.6777,  0.1333,  ..., -0.7007, -0.2299,  1.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:50:17 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:50:17 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 22:51:13 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 22:52:08 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-29 22:53:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0131,  0.0077, -0.0012,  ...,  0.0031, -0.0005, -0.0004],
        [-0.0041, -0.0079, -0.0036,  ..., -0.0033, -0.0007,  0.0059],
        [ 0.0041,  0.0003, -0.0085,  ..., -0.0024, -0.0007,  0.0002],
        ...,
        [-0.0025, -0.0013, -0.0058,  ..., -0.0068,  0.0031, -0.0010],
        [ 0.0049, -0.0045, -0.0014,  ..., -0.0024, -0.0089, -0.0027],
        [ 0.0047,  0.0012, -0.0031,  ..., -0.0003,  0.0009, -0.0118]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0834,  0.0002,  0.0089,  ...,  0.0095, -0.0080, -0.0074],
        [ 0.0129, -0.0937, -0.0007,  ...,  0.0075,  0.0003,  0.0055],
        [-0.0051, -0.0102, -0.0750,  ..., -0.0014,  0.0003,  0.0085],
        ...,
        [-0.0098,  0.0078,  0.0108,  ..., -0.0703, -0.0063,  0.0060],
        [-0.0072, -0.0081, -0.0049,  ..., -0.0015, -0.0748,  0.0081],
        [ 0.0004,  0.0058, -0.0031,  ..., -0.0106, -0.0025, -0.0745]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0960, -0.0010, -0.0065,  ..., -0.0035, -0.0043,  0.0013],
        [ 0.0053, -0.1094, -0.0014,  ..., -0.0106,  0.0070,  0.0036],
        [-0.0038, -0.0201, -0.1121,  ..., -0.0044, -0.0088,  0.0044],
        ...,
        [ 0.0033,  0.0020,  0.0062,  ..., -0.0898, -0.0060, -0.0126],
        [ 0.0105,  0.0046, -0.0071,  ...,  0.0139, -0.1032,  0.0117],
        [ 0.0068, -0.0025, -0.0005,  ..., -0.0080,  0.0128, -0.0939]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:53:07 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-29 22:53:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2388, -0.4551,  0.4636,  ...,  0.3420, -0.7993,  1.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4968,  0.0980,  0.2303,  ..., -0.4402, -0.0356,  0.6191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0239, -0.3357,  0.6294,  ...,  0.3894, -1.8008,  3.7305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1953, -1.0947,  0.5439,  ..., -0.6860, -0.3667,  1.3799],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:53:07 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:53:07 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 22:54:06 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 22:55:02 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-29 22:56:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1993e-02, -2.5883e-03, -4.2191e-03,  ...,  9.9792e-03,
         -4.7708e-04,  3.7842e-03],
        [-1.0689e-02,  1.1284e-02, -2.3918e-03,  ..., -2.5463e-03,
         -1.9350e-03, -5.0430e-03],
        [-3.0785e-03,  7.2956e-04,  8.0109e-03,  ..., -4.2381e-03,
         -4.6844e-03, -4.0674e-04],
        ...,
        [ 8.1491e-04, -3.4180e-03,  8.0338e-03,  ...,  9.2392e-03,
         -1.5884e-02,  5.1956e-03],
        [ 6.6161e-05,  2.8229e-03,  1.0017e-02,  ..., -7.0035e-05,
          1.4183e-02,  1.6708e-03],
        [ 2.0180e-03, -1.9064e-03, -6.9046e-03,  ..., -9.1400e-03,
         -7.5912e-03,  6.0234e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0967,  0.0045, -0.0061,  ..., -0.0061,  0.0150,  0.0107],
        [ 0.0141, -0.1256, -0.0017,  ..., -0.0129,  0.0062,  0.0054],
        [ 0.0088,  0.0088, -0.1165,  ...,  0.0008, -0.0023, -0.0051],
        ...,
        [-0.0191, -0.0074,  0.0061,  ..., -0.1065,  0.0035, -0.0090],
        [ 0.0095,  0.0046, -0.0065,  ...,  0.0118, -0.1050, -0.0089],
        [ 0.0196,  0.0044,  0.0027,  ...,  0.0006,  0.0032, -0.1161]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.4392e-01, -2.1820e-03, -9.8228e-05,  ..., -1.6312e-02,
          9.5596e-03, -7.3700e-03],
        [-2.0432e-02, -1.6052e-01, -1.6220e-02,  ...,  4.8256e-03,
         -5.0659e-03,  8.2092e-03],
        [ 4.9858e-03,  1.4572e-03, -1.4941e-01,  ..., -5.5275e-03,
         -1.3609e-03, -6.1493e-03],
        ...,
        [ 2.6798e-03, -1.1005e-03, -8.8692e-04,  ..., -1.3416e-01,
          3.9902e-03,  3.1013e-03],
        [ 4.0588e-03,  5.6419e-03, -5.4932e-04,  ...,  1.4557e-02,
         -1.4233e-01, -7.0114e-03],
        [ 6.2256e-03,  7.3433e-03,  7.4692e-03,  ..., -1.3561e-03,
          4.7379e-03, -1.4612e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:56:04 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-29 22:56:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1272, -0.3657,  0.3953,  ...,  0.1808, -1.1025,  1.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5107, -0.4199,  0.0495,  ..., -0.4238, -0.1083,  0.7251],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0547, -0.3315,  1.1064,  ..., -0.0496, -1.5928,  3.7949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1785, -1.3291,  0.2715,  ..., -0.9043, -0.1006,  0.8491],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:56:04 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:56:04 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 22:57:04 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 22:57:58 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-29 22:58:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0056, -0.0075,  0.0038,  ..., -0.0041, -0.0165,  0.0016],
        [-0.0038,  0.0118, -0.0061,  ..., -0.0025,  0.0025,  0.0034],
        [-0.0081, -0.0053,  0.0155,  ..., -0.0030, -0.0008,  0.0031],
        ...,
        [ 0.0060,  0.0024, -0.0025,  ...,  0.0121, -0.0034,  0.0023],
        [ 0.0053, -0.0063,  0.0030,  ...,  0.0033,  0.0161,  0.0038],
        [-0.0009,  0.0088, -0.0048,  ..., -0.0028,  0.0005,  0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0848,  0.0110,  0.0037,  ...,  0.0128,  0.0043,  0.0017],
        [-0.0028, -0.1030, -0.0004,  ...,  0.0005,  0.0067,  0.0015],
        [ 0.0043, -0.0045, -0.0724,  ...,  0.0065, -0.0079, -0.0132],
        ...,
        [ 0.0064, -0.0095, -0.0119,  ..., -0.0904,  0.0061, -0.0003],
        [ 0.0027,  0.0082,  0.0014,  ...,  0.0060, -0.0865, -0.0025],
        [ 0.0006,  0.0005, -0.0036,  ..., -0.0012, -0.0081, -0.1008]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1334, -0.0021,  0.0045,  ..., -0.0033,  0.0114,  0.0109],
        [ 0.0003, -0.1327,  0.0028,  ...,  0.0041,  0.0077,  0.0052],
        [ 0.0026, -0.0177, -0.1142,  ..., -0.0003,  0.0048, -0.0032],
        ...,
        [-0.0168, -0.0095, -0.0097,  ..., -0.1426,  0.0125, -0.0149],
        [ 0.0003,  0.0125,  0.0088,  ...,  0.0152, -0.1364,  0.0021],
        [ 0.0019,  0.0032, -0.0157,  ..., -0.0095, -0.0083, -0.1290]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 22:58:56 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-29 22:58:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0023, -0.2074,  0.3003,  ...,  0.1763, -0.8994,  1.8740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1199, -0.6582,  0.2952,  ..., -0.3926, -0.2001,  0.7598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0547, -0.7793,  1.4453,  ...,  0.3557, -0.7979,  4.3711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1230, -1.9219, -0.7109,  ..., -1.1279,  0.4019,  1.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 22:58:56 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 22:58:56 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 22:59:58 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 23:01:01 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-29 23:01:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.0260e-05, -1.1504e-05,  2.1935e-03,  ..., -1.6241e-03,
         -4.8561e-03,  3.7575e-03],
        [ 5.1041e-03, -2.2526e-03,  2.7657e-03,  ...,  3.6716e-04,
          2.4319e-03, -2.2850e-03],
        [ 1.4668e-03, -4.2820e-04,  1.2589e-03,  ...,  2.8076e-03,
         -3.7518e-03,  3.3875e-03],
        ...,
        [-8.5678e-03, -4.6082e-03, -2.8133e-04,  ..., -1.4858e-03,
         -6.4583e-03,  2.5291e-03],
        [-8.0967e-04, -8.3637e-04,  3.3607e-03,  ..., -7.6675e-04,
         -6.4087e-04, -5.1155e-03],
        [ 2.1305e-03, -2.1420e-03,  3.5915e-03,  ...,  1.0347e-03,
         -3.0732e-04,  1.2875e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0939, -0.0099,  0.0008,  ..., -0.0072,  0.0086,  0.0013],
        [-0.0004, -0.0943, -0.0123,  ..., -0.0047, -0.0031, -0.0015],
        [-0.0083, -0.0089, -0.0858,  ...,  0.0028, -0.0111, -0.0042],
        ...,
        [-0.0057,  0.0178,  0.0104,  ..., -0.0928, -0.0113, -0.0039],
        [ 0.0013, -0.0019, -0.0082,  ...,  0.0026, -0.0933,  0.0066],
        [-0.0031, -0.0097, -0.0089,  ..., -0.0009,  0.0079, -0.1003]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1298, -0.0020, -0.0147,  ...,  0.0003, -0.0039,  0.0086],
        [-0.0021, -0.1454, -0.0038,  ..., -0.0082, -0.0055,  0.0014],
        [-0.0106,  0.0017, -0.1306,  ...,  0.0008,  0.0096,  0.0004],
        ...,
        [ 0.0165,  0.0076,  0.0146,  ..., -0.1355, -0.0040,  0.0039],
        [-0.0085, -0.0103, -0.0204,  ...,  0.0031, -0.1471,  0.0003],
        [ 0.0066,  0.0009, -0.0002,  ..., -0.0016,  0.0115, -0.1472]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:02:03 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-29 23:02:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4951, -0.1713,  0.5063,  ..., -0.0311, -0.7979,  1.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1389, -0.7197,  0.1202,  ..., -0.4783, -0.0487,  0.4329],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1542, -1.1113,  1.4531,  ...,  0.7671, -0.6294,  4.7930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0732, -1.8750, -0.3601,  ..., -1.6221, -0.5244,  1.2051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:02:03 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:02:03 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 23:03:09 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 23:04:09 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-29 23:05:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2321e-02,  3.2463e-03, -4.7188e-03,  ...,  7.4081e-03,
         -1.7166e-05, -4.7836e-03],
        [-7.5951e-03,  1.4771e-02,  6.5079e-03,  ...,  3.3493e-03,
         -1.8759e-03, -6.3992e-04],
        [ 2.7227e-04,  1.0166e-03,  4.5471e-03,  ...,  5.7983e-03,
         -9.0218e-04, -1.8301e-03],
        ...,
        [ 5.0783e-04,  1.5154e-03,  3.8509e-03,  ...,  9.8038e-03,
         -1.8021e-02,  2.0676e-03],
        [-3.5324e-03, -1.5383e-03, -6.7787e-03,  ...,  9.7122e-03,
          6.9160e-03,  9.4748e-04],
        [ 1.8864e-03, -2.3212e-03,  9.5797e-04,  ..., -3.2425e-03,
          1.1787e-02,  5.8098e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0439,  0.0077, -0.0131,  ...,  0.0159, -0.0064, -0.0097],
        [-0.0158, -0.0584, -0.0083,  ...,  0.0077, -0.0084, -0.0031],
        [ 0.0033, -0.0047, -0.0609,  ..., -0.0061,  0.0104,  0.0049],
        ...,
        [-0.0101, -0.0053,  0.0094,  ..., -0.0480, -0.0112, -0.0062],
        [-0.0144,  0.0114,  0.0094,  ...,  0.0177, -0.0490, -0.0023],
        [ 0.0127,  0.0028,  0.0167,  ..., -0.0066,  0.0115, -0.0530]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0916,  0.0098,  0.0007,  ..., -0.0057, -0.0031,  0.0017],
        [ 0.0046, -0.1031, -0.0123,  ...,  0.0003, -0.0062,  0.0004],
        [ 0.0092,  0.0038, -0.1023,  ...,  0.0031, -0.0069, -0.0170],
        ...,
        [-0.0310, -0.0049, -0.0049,  ..., -0.0998,  0.0025,  0.0041],
        [ 0.0008,  0.0136, -0.0042,  ...,  0.0070, -0.0929,  0.0172],
        [ 0.0013, -0.0062,  0.0149,  ...,  0.0026, -0.0181, -0.1014]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:05:14 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-29 23:05:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0438, -0.3767,  0.6431,  ...,  0.1510, -0.3628,  1.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5742, -0.9585, -0.3335,  ..., -0.5410,  0.2091,  0.5425],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5405, -0.8223,  1.7705,  ...,  1.2744, -0.7324,  6.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0938, -2.0781, -0.1895,  ..., -1.5781, -0.1233,  1.6738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:05:14 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:05:14 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 23:06:18 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 23:07:21 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-29 23:08:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.0441e-03, -4.0321e-03, -2.0638e-03,  ...,  9.0599e-04,
         -3.9864e-03,  9.8343e-03],
        [-9.8953e-03,  7.8087e-03, -2.3994e-03,  ..., -2.0390e-03,
          2.6093e-03,  4.7607e-03],
        [-3.0289e-03, -1.9236e-03,  3.7403e-03,  ..., -3.4943e-03,
          3.2711e-03, -9.2850e-03],
        ...,
        [ 3.6068e-03, -3.0060e-03,  2.7409e-03,  ...,  8.8501e-03,
          5.3482e-03, -7.0953e-03],
        [ 9.6970e-03,  1.2970e-03,  2.2240e-03,  ..., -3.5496e-03,
          1.4305e-06, -2.7237e-03],
        [ 2.7599e-03, -2.1877e-03,  1.0090e-03,  ..., -4.4632e-03,
          1.1349e-03, -4.3755e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.1472e-02,  6.0196e-03,  9.5062e-03,  ...,  3.0460e-03,
          1.2634e-02, -8.0566e-03],
        [-6.6528e-03, -8.0383e-02,  7.2784e-03,  ...,  1.5106e-02,
          1.3237e-02,  7.7782e-03],
        [-1.4679e-02, -3.7251e-03, -5.8960e-02,  ..., -1.6342e-02,
         -6.4201e-03,  8.0109e-03],
        ...,
        [ 6.4430e-03,  7.7534e-04,  6.3667e-03,  ..., -6.2744e-02,
          3.7460e-03, -1.2817e-02],
        [ 7.0038e-03, -2.8610e-03,  3.6926e-03,  ...,  4.2953e-03,
         -6.7505e-02,  7.4844e-03],
        [-1.0757e-02,  1.9135e-02,  1.4290e-02,  ..., -4.0054e-05,
          8.4610e-03, -6.1707e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0974,  0.0108,  0.0117,  ...,  0.0065,  0.0217,  0.0149],
        [-0.0082, -0.0974, -0.0116,  ..., -0.0090,  0.0040,  0.0137],
        [ 0.0074, -0.0047, -0.1017,  ..., -0.0146,  0.0036,  0.0015],
        ...,
        [ 0.0142,  0.0006,  0.0027,  ..., -0.0842,  0.0074, -0.0089],
        [ 0.0251,  0.0110,  0.0011,  ..., -0.0071, -0.1006,  0.0098],
        [ 0.0081,  0.0166, -0.0109,  ...,  0.0107,  0.0063, -0.0983]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:08:24 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-29 23:08:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0922, -0.4939,  0.6152,  ...,  0.3328, -0.2849,  2.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5195, -0.8560, -0.1735,  ..., -0.7427, -0.2400,  0.5239],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1865, -0.1934,  2.0117,  ...,  1.6836, -0.3125,  6.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2734, -2.7168,  0.4170,  ..., -1.8730,  0.7109,  3.2129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:08:25 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:08:25 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 23:09:29 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 23:10:29 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-29 23:11:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0080, -0.0067, -0.0010,  ..., -0.0056, -0.0018,  0.0025],
        [-0.0039,  0.0091, -0.0001,  ..., -0.0004,  0.0043,  0.0053],
        [-0.0005, -0.0085,  0.0081,  ...,  0.0018,  0.0022, -0.0034],
        ...,
        [ 0.0024,  0.0015,  0.0012,  ...,  0.0101, -0.0019, -0.0021],
        [ 0.0012, -0.0004,  0.0045,  ..., -0.0007,  0.0064, -0.0013],
        [-0.0009,  0.0012,  0.0011,  ...,  0.0011,  0.0003,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0446,  0.0011, -0.0042,  ..., -0.0165,  0.0057,  0.0032],
        [ 0.0239, -0.0764,  0.0077,  ..., -0.0087,  0.0041, -0.0035],
        [ 0.0036, -0.0262, -0.0695,  ...,  0.0087, -0.0056, -0.0044],
        ...,
        [ 0.0088, -0.0109,  0.0072,  ..., -0.0511, -0.0118, -0.0013],
        [-0.0108,  0.0172, -0.0126,  ...,  0.0137, -0.0737,  0.0007],
        [-0.0067,  0.0122, -0.0074,  ...,  0.0009,  0.0051, -0.0726]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.0557e-02,  1.5213e-02, -3.2234e-03,  ..., -1.7731e-02,
         -2.4796e-05, -5.1498e-03],
        [ 1.8097e-02, -5.7953e-02, -1.3151e-03,  ..., -5.8784e-03,
         -8.1635e-03, -3.7842e-03],
        [-1.0063e-02, -6.2294e-03, -6.5247e-02,  ...,  6.5651e-03,
          9.3842e-04, -3.0956e-03],
        ...,
        [-1.2512e-02, -3.0136e-04,  8.8730e-03,  ..., -4.8340e-02,
         -1.4641e-02,  1.7990e-02],
        [-9.4223e-04, -1.1978e-02, -2.9297e-03,  ..., -9.3460e-03,
         -5.0415e-02, -4.2725e-03],
        [-1.6403e-02,  7.8583e-03, -5.8708e-03,  ..., -1.2810e-02,
         -1.8433e-02, -4.5593e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:11:38 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-29 23:11:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2345, -0.3718,  0.7280,  ...,  0.5454, -0.3040,  2.6543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5015, -0.9272, -0.1019,  ..., -0.6943, -0.0317,  0.7124],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3047,  0.2529,  1.4111,  ...,  1.8652, -0.7119,  6.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4424, -2.2695,  0.8301,  ..., -2.9707,  1.1387,  3.4121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:11:38 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:11:38 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 23:12:45 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 23:13:51 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-29 23:15:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.3610e-04, -2.5215e-03, -3.5596e-04,  ...,  7.7343e-04,
         -6.1264e-03, -5.0240e-03],
        [ 9.5546e-05,  6.4735e-03, -3.0632e-03,  ...,  1.5187e-04,
         -1.3876e-03, -1.4687e-04],
        [-1.8082e-03,  3.0117e-03,  3.1967e-03,  ..., -2.3575e-03,
          1.7252e-03,  5.1165e-04],
        ...,
        [-1.3828e-03, -9.6798e-04, -7.6103e-03,  ...,  4.1046e-03,
          4.3654e-04, -1.2131e-03],
        [ 2.0647e-04, -4.3564e-03, -7.2021e-03,  ...,  2.9469e-03,
         -3.3340e-03,  2.8515e-03],
        [-2.7866e-03,  2.1420e-03,  2.9621e-03,  ..., -3.7556e-03,
         -3.0575e-03,  5.6953e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0204,  0.0062, -0.0130,  ..., -0.0171,  0.0123, -0.0243],
        [ 0.0056, -0.0291,  0.0058,  ...,  0.0218,  0.0075,  0.0047],
        [-0.0112, -0.0091, -0.0395,  ...,  0.0105,  0.0172,  0.0062],
        ...,
        [-0.0005, -0.0117,  0.0066,  ..., -0.0295, -0.0006, -0.0152],
        [ 0.0041, -0.0129, -0.0014,  ..., -0.0155, -0.0444,  0.0032],
        [-0.0149,  0.0111,  0.0226,  ..., -0.0036,  0.0011, -0.0245]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0393, -0.0047,  0.0118,  ..., -0.0148, -0.0052, -0.0057],
        [ 0.0049, -0.0477, -0.0108,  ...,  0.0200, -0.0048, -0.0164],
        [-0.0118, -0.0037, -0.0527,  ..., -0.0052,  0.0018,  0.0050],
        ...,
        [ 0.0083, -0.0119, -0.0088,  ..., -0.0468, -0.0115, -0.0158],
        [ 0.0109, -0.0188, -0.0182,  ..., -0.0086, -0.0733, -0.0047],
        [-0.0136,  0.0030,  0.0075,  ..., -0.0117,  0.0096, -0.0599]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:15:03 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-29 23:15:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5024, -0.0966,  0.7842,  ...,  0.6943, -0.1371,  2.7168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5259, -1.1182,  0.1436,  ..., -0.7466,  0.2793,  1.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.9336, -0.1094,  1.2715,  ...,  1.6953, -0.7539,  6.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2549, -3.1641, -0.4150,  ..., -2.0156,  1.2080,  3.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:15:03 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:15:03 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 23:16:13 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 23:17:23 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-29 23:18:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.5618e-03, -5.2795e-03, -2.7609e-04,  ...,  8.6136e-03,
         -6.6833e-03,  6.0997e-03],
        [-2.6846e-04,  7.8964e-03, -2.0390e-03,  ..., -6.4926e-03,
         -4.6844e-03, -1.7624e-03],
        [-1.3199e-03, -4.1437e-04,  6.0310e-03,  ..., -4.6120e-03,
         -8.9025e-04,  1.3268e-02],
        ...,
        [ 9.8419e-03, -7.9498e-03, -2.9316e-03,  ...,  2.1496e-03,
         -3.1013e-03, -7.2098e-03],
        [-6.1989e-04,  4.0150e-04, -1.5011e-03,  ...,  1.3542e-03,
          6.2981e-03, -7.1907e-03],
        [-5.3558e-03, -7.2479e-05, -1.8539e-03,  ..., -5.4092e-03,
         -7.3099e-04,  1.4305e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.0243e-02, -6.3324e-04,  4.1275e-03,  ..., -2.1896e-03,
         -1.4534e-03, -1.1551e-02],
        [ 8.1635e-03, -4.6509e-02,  2.8229e-03,  ...,  8.1329e-03,
          9.3002e-03, -1.6413e-03],
        [-8.3084e-03, -1.3824e-02, -5.7831e-02,  ..., -6.8474e-03,
         -3.9330e-03, -9.1553e-03],
        ...,
        [-2.8210e-03,  2.6207e-03, -6.0081e-03,  ..., -4.5258e-02,
         -1.1627e-02, -8.8215e-05],
        [ 7.1259e-03, -2.4796e-04, -8.9798e-03,  ..., -8.2245e-03,
         -4.2969e-02, -1.5001e-03],
        [-8.4305e-03, -1.0536e-02, -4.3564e-03,  ...,  9.9640e-03,
          3.6583e-03, -3.8605e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0389, -0.0055, -0.0075,  ...,  0.0147,  0.0019,  0.0008],
        [ 0.0193, -0.0635, -0.0075,  ...,  0.0057,  0.0066,  0.0152],
        [-0.0036, -0.0163, -0.0277,  ...,  0.0058,  0.0046, -0.0027],
        ...,
        [-0.0020,  0.0138,  0.0154,  ..., -0.0200, -0.0079, -0.0226],
        [ 0.0063,  0.0067, -0.0069,  ...,  0.0078, -0.0414,  0.0058],
        [-0.0174, -0.0061,  0.0060,  ...,  0.0108, -0.0164, -0.0215]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:18:34 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-29 23:18:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5024,  0.0848,  0.5254,  ...,  0.6997, -0.2673,  2.4414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5488, -0.8701,  0.3005,  ..., -1.1270,  0.4363,  1.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.1738, -0.6431,  1.8398,  ...,  1.9248, -0.0747,  5.8164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4062, -3.7656, -0.9053,  ..., -2.2871,  3.3125,  3.3691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:18:35 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:18:35 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 23:19:50 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 23:21:08 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-29 23:22:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0082, -0.0034, -0.0020,  ..., -0.0013,  0.0011,  0.0049],
        [-0.0017, -0.0006,  0.0020,  ...,  0.0052,  0.0020, -0.0041],
        [-0.0020,  0.0018,  0.0080,  ..., -0.0012,  0.0018,  0.0021],
        ...,
        [-0.0029,  0.0080, -0.0015,  ...,  0.0106, -0.0012,  0.0080],
        [-0.0021,  0.0002,  0.0022,  ..., -0.0004,  0.0046, -0.0034],
        [-0.0045,  0.0048,  0.0014,  ..., -0.0051,  0.0056,  0.0176]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0403, -0.0092, -0.0172,  ...,  0.0031, -0.0108,  0.0024],
        [ 0.0138, -0.0146, -0.0119,  ...,  0.0059, -0.0052, -0.0129],
        [-0.0019,  0.0041, -0.0227,  ...,  0.0019, -0.0078, -0.0053],
        ...,
        [-0.0008,  0.0072, -0.0096,  ..., -0.0286,  0.0097,  0.0105],
        [-0.0035, -0.0138,  0.0087,  ...,  0.0002, -0.0404,  0.0025],
        [ 0.0133,  0.0004, -0.0096,  ..., -0.0090, -0.0103, -0.0165]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.4656e-02,  4.3793e-03,  8.3084e-03,  ..., -1.2901e-02,
          1.3649e-02,  8.7738e-05],
        [ 5.4855e-03, -6.9092e-02, -7.3662e-03,  ...,  1.2924e-02,
         -3.9024e-03, -1.2703e-02],
        [-2.1229e-03,  1.7502e-02, -7.6965e-02,  ..., -1.1612e-02,
          1.7227e-02, -6.6719e-03],
        ...,
        [ 1.5556e-02,  6.3133e-04, -2.8854e-02,  ..., -9.9609e-02,
         -2.1210e-03,  6.4392e-03],
        [ 2.6108e-02, -3.0396e-02,  2.5940e-04,  ...,  7.1182e-03,
         -9.6252e-02, -9.7580e-03],
        [ 2.2034e-02, -8.5373e-03, -3.7041e-03,  ..., -2.0813e-02,
         -1.8692e-02, -9.3079e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:22:31 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-29 23:22:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7461, -0.0457,  0.4580,  ...,  0.6338, -0.2800,  2.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4729, -1.1436, -0.1616,  ..., -0.7236,  0.4600,  1.3555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2422, -0.6343,  2.4648,  ...,  2.5117,  0.4507,  5.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2998, -4.1484, -1.1914,  ..., -1.8730,  3.7617,  3.3945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:22:31 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:22:31 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 23:23:49 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 23:25:10 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-29 23:26:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7042e-03,  5.0306e-04, -1.6756e-03,  ..., -1.1438e-04,
         -9.5177e-04,  2.7037e-04],
        [ 1.3924e-04, -1.7643e-03, -3.5048e-04,  ...,  3.3140e-04,
         -3.5858e-04,  1.0004e-03],
        [-1.1289e-04,  2.8658e-04, -2.1629e-03,  ...,  7.9250e-04,
         -1.1320e-03, -2.8944e-04],
        ...,
        [-5.2989e-05, -6.5041e-04, -3.9983e-04,  ..., -1.6518e-03,
         -2.3079e-04, -6.1083e-04],
        [ 2.3437e-04,  4.0054e-04, -2.4962e-04,  ..., -2.6155e-04,
         -1.9197e-03,  5.4693e-04],
        [ 2.3055e-04, -5.4407e-04,  2.9898e-04,  ...,  5.5969e-05,
         -4.8637e-04, -3.0174e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0305,  0.0202, -0.0019,  ...,  0.0091, -0.0196,  0.0035],
        [ 0.0051, -0.0307,  0.0222,  ...,  0.0016, -0.0031,  0.0015],
        [-0.0173,  0.0012, -0.0211,  ...,  0.0205, -0.0117, -0.0049],
        ...,
        [-0.0004,  0.0182, -0.0057,  ..., -0.0084,  0.0008, -0.0022],
        [ 0.0205, -0.0059, -0.0203,  ...,  0.0059, -0.0185,  0.0012],
        [-0.0024,  0.0109, -0.0004,  ...,  0.0029, -0.0087, -0.0290]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0577, -0.0049,  0.0117,  ...,  0.0012, -0.0244,  0.0018],
        [ 0.0048, -0.0592,  0.0063,  ...,  0.0168,  0.0108,  0.0088],
        [ 0.0056, -0.0030, -0.0499,  ...,  0.0033, -0.0158,  0.0074],
        ...,
        [ 0.0002,  0.0223,  0.0024,  ..., -0.0376, -0.0111, -0.0050],
        [ 0.0107,  0.0143, -0.0016,  ..., -0.0129, -0.0532, -0.0062],
        [-0.0037,  0.0150, -0.0065,  ...,  0.0021, -0.0245, -0.0829]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:26:34 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-29 23:26:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8125, -0.2301,  0.6250,  ...,  0.6880, -0.0096,  2.1113],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5000, -1.3086, -0.3381,  ..., -0.7925,  1.2012,  1.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3047, -0.0825,  2.4785,  ...,  2.2734,  1.2197,  4.8594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1816, -3.5957, -0.7090,  ..., -2.1250,  4.0469,  2.5000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:26:34 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:26:34 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 23:27:58 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 23:29:22 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-29 23:30:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.9117e-03,  1.9064e-03, -1.0633e-03,  ...,  3.2616e-04,
         -3.6850e-03,  1.8425e-03],
        [ 7.3385e-04,  8.4457e-03,  2.6665e-03,  ...,  5.5428e-03,
          5.6171e-04, -2.3708e-03],
        [ 1.8206e-03,  5.0888e-03,  7.2479e-03,  ...,  9.6703e-04,
          2.5868e-04,  1.3676e-03],
        ...,
        [ 1.4791e-03, -3.5000e-03, -2.2011e-03,  ...,  6.3362e-03,
         -3.7169e-04,  6.1464e-04],
        [-9.6798e-04, -1.6508e-03, -3.9749e-03,  ...,  1.4400e-03,
          6.1111e-03, -1.3371e-03],
        [-4.7207e-05, -1.7500e-03,  4.4861e-03,  ..., -7.9393e-04,
          1.2894e-03,  6.3400e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.4094e-02, -5.6114e-03, -1.8738e-02,  ...,  1.2390e-02,
          4.8752e-03,  1.6846e-02],
        [ 2.0462e-02, -1.0574e-02,  1.0399e-02,  ..., -3.0823e-03,
         -2.9266e-02, -1.1169e-02],
        [-8.5473e-05, -5.5771e-03, -1.7273e-02,  ..., -4.8866e-03,
          3.0212e-03, -1.4122e-02],
        ...,
        [-5.2147e-03, -2.6588e-03, -5.8517e-03,  ..., -2.5101e-02,
         -1.5686e-02,  3.1185e-03],
        [-2.3758e-02, -7.6523e-03, -1.7227e-02,  ...,  6.3095e-03,
         -1.7532e-02,  8.1177e-03],
        [ 4.0894e-03, -1.1383e-02,  9.7885e-03,  ..., -2.0279e-02,
          1.0376e-02, -4.6234e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0334, -0.0002, -0.0127,  ...,  0.0091, -0.0042,  0.0066],
        [ 0.0049, -0.0492,  0.0149,  ..., -0.0080, -0.0262, -0.0027],
        [-0.0084, -0.0132, -0.0508,  ..., -0.0052, -0.0080,  0.0095],
        ...,
        [-0.0218,  0.0112, -0.0114,  ..., -0.0607, -0.0074, -0.0238],
        [-0.0175, -0.0240, -0.0312,  ..., -0.0071, -0.0693,  0.0100],
        [-0.0276, -0.0059,  0.0072,  ...,  0.0060, -0.0080, -0.0567]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:30:46 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-29 23:30:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8091, -0.1932,  0.8169,  ...,  0.8618,  0.1696,  1.9688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4509, -1.3555, -0.4561,  ..., -0.6431,  1.3213,  1.1670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.7305, -0.0471,  2.9766,  ...,  2.9512,  1.7930,  5.4336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4624, -2.5879, -0.7817,  ..., -1.7422,  4.1250,  1.8105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:30:46 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:30:46 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 23:32:05 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 23:33:26 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-29 23:34:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.6337e-02,  4.5538e-04, -5.4216e-04,  ...,  4.5624e-03,
          2.0580e-03,  2.4948e-03],
        [-3.0541e-04,  1.9196e-02, -2.1515e-03,  ..., -2.3150e-04,
         -1.4961e-05,  1.4038e-03],
        [-8.2207e-04,  3.3140e-04,  2.9434e-02,  ..., -3.0251e-03,
          3.8552e-04, -5.2023e-04],
        ...,
        [-3.1853e-04,  4.2000e-03, -1.4353e-04,  ...,  3.1586e-02,
          3.6755e-03,  2.5153e-05],
        [ 3.2768e-03,  1.6718e-03, -3.1395e-03,  ...,  6.3972e-03,
          3.1036e-02, -8.4839e-03],
        [ 3.1796e-03, -5.4474e-03, -5.5199e-03,  ..., -3.0270e-03,
          2.3532e-04,  3.5431e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0276,  0.0005,  0.0093,  ..., -0.0017, -0.0112, -0.0040],
        [-0.0115, -0.0075,  0.0049,  ...,  0.0113, -0.0054,  0.0075],
        [-0.0082, -0.0077,  0.0397,  ...,  0.0086, -0.0164, -0.0108],
        ...,
        [-0.0128,  0.0138, -0.0115,  ...,  0.0168, -0.0125, -0.0051],
        [ 0.0043,  0.0048, -0.0005,  ..., -0.0054,  0.0343, -0.0156],
        [ 0.0168, -0.0041, -0.0019,  ..., -0.0201, -0.0205,  0.0353]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0315, -0.0224, -0.0116,  ..., -0.0098,  0.0002, -0.0131],
        [ 0.0137, -0.0432, -0.0271,  ...,  0.0101, -0.0139,  0.0189],
        [-0.0083, -0.0051, -0.0078,  ...,  0.0099, -0.0078, -0.0105],
        ...,
        [ 0.0094, -0.0059, -0.0057,  ..., -0.0018, -0.0158, -0.0033],
        [ 0.0002,  0.0014, -0.0056,  ...,  0.0161, -0.0218,  0.0205],
        [ 0.0084,  0.0123,  0.0129,  ...,  0.0036, -0.0170, -0.0387]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:34:47 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-29 23:34:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8057, -0.0058,  0.7803,  ...,  0.7192,  0.4053,  1.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3767, -1.1357, -0.2966,  ..., -0.7446,  1.3535,  0.8198],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([3.1113, 0.8447, 2.9648,  ..., 2.7793, 2.1758, 5.6641], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6680, -1.3447, -0.3367,  ..., -1.7559,  4.6797,  1.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:34:47 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:34:47 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 23:36:08 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 23:37:30 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-29 23:38:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.2763e-03, -1.7805e-03,  9.4604e-04,  ..., -1.0357e-03,
          2.0256e-03,  4.0150e-04],
        [-3.3703e-03,  3.9177e-03,  2.7027e-03,  ..., -6.6948e-04,
         -5.5027e-04, -5.5408e-04],
        [ 1.4133e-03, -1.0338e-03,  7.0190e-03,  ...,  1.0338e-03,
          5.9891e-04,  7.7438e-04],
        ...,
        [ 8.4543e-04,  1.2045e-03, -5.1422e-03,  ...,  7.8430e-03,
         -2.8276e-04, -7.8678e-06],
        [ 8.2016e-04,  1.0328e-03, -1.3371e-03,  ..., -1.8635e-03,
          6.3553e-03, -1.0033e-03],
        [ 9.1791e-05, -3.6430e-04,  4.8590e-04,  ..., -6.6710e-04,
          7.9012e-04,  7.9651e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0093,  0.0126,  0.0226,  ..., -0.0126,  0.0284,  0.0056],
        [-0.0134, -0.0303, -0.0043,  ...,  0.0203, -0.0022, -0.0255],
        [-0.0250,  0.0195,  0.0074,  ...,  0.0014, -0.0097,  0.0290],
        ...,
        [-0.0041, -0.0007, -0.0096,  ...,  0.0274, -0.0002, -0.0166],
        [-0.0018,  0.0040, -0.0025,  ...,  0.0111, -0.0101,  0.0296],
        [-0.0127,  0.0174, -0.0164,  ..., -0.0051, -0.0054,  0.0343]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0247,  0.0237,  0.0135,  ..., -0.0100,  0.0323,  0.0159],
        [-0.0175, -0.0054,  0.0004,  ..., -0.0022,  0.0003, -0.0379],
        [ 0.0005,  0.0120, -0.0024,  ...,  0.0313, -0.0016, -0.0047],
        ...,
        [-0.0043,  0.0133,  0.0109,  ..., -0.0034,  0.0263, -0.0236],
        [-0.0189,  0.0075, -0.0079,  ..., -0.0009, -0.0076, -0.0181],
        [-0.0296, -0.0012, -0.0020,  ...,  0.0118, -0.0014,  0.0116]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:38:58 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-29 23:38:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.8989, 0.0118, 0.8091,  ..., 0.7896, 0.5142, 1.6289], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0973, -0.7539, -0.3286,  ..., -0.6348,  1.2471,  0.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([4.2734, 0.5210, 2.6445,  ..., 2.2129, 2.1309, 4.4609], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0996, -1.7061, -1.2773,  ..., -3.1523,  5.6602,  1.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:38:58 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:38:58 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 23:40:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 23:41:41 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-29 23:43:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.3870e-02, -1.6689e-03, -3.7670e-04,  ..., -9.1219e-04,
          2.1422e-04, -1.6556e-03],
        [ 1.7233e-03,  1.2978e-02, -1.5602e-03,  ..., -4.5967e-04,
          1.6327e-03,  2.3613e-03],
        [ 4.5776e-03, -5.0240e-03,  1.4587e-02,  ..., -3.3617e-05,
         -1.4954e-03,  2.9449e-03],
        ...,
        [-2.0199e-03, -5.9986e-04,  4.1437e-04,  ...,  1.6800e-02,
         -2.5654e-03, -1.3914e-03],
        [-3.4404e-04, -3.0565e-04,  1.0834e-03,  ..., -3.3360e-03,
          1.7441e-02, -1.3914e-03],
        [ 1.2360e-03,  3.3817e-03, -3.5267e-03,  ...,  2.3198e-04,
          3.5572e-04,  2.0523e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 3.0670e-03, -1.0223e-02, -9.4147e-03,  ...,  3.0518e-05,
         -1.4086e-03,  7.7744e-03],
        [-5.7831e-03, -7.0343e-03,  1.1986e-02,  ..., -7.0801e-03,
          5.2109e-03,  1.1162e-02],
        [-1.1948e-02, -5.5542e-03,  1.2611e-02,  ...,  8.6594e-03,
         -1.0017e-02,  1.8036e-02],
        ...,
        [-4.8208e-04,  1.0750e-02, -3.8815e-03,  ...,  8.8043e-03,
         -5.4092e-03, -6.0425e-03],
        [-6.2485e-03, -7.5302e-03, -2.8496e-03,  ...,  2.6760e-03,
          9.6970e-03, -1.2007e-03],
        [-1.3443e-02,  1.0040e-02, -6.2370e-03,  ..., -1.0010e-02,
         -1.0635e-02,  2.4994e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0107, -0.0263, -0.0085,  ...,  0.0213, -0.0006,  0.0054],
        [ 0.0113, -0.0563,  0.0156,  ...,  0.0127,  0.0184,  0.0201],
        [-0.0183, -0.0060, -0.0020,  ..., -0.0030,  0.0055,  0.0136],
        ...,
        [-0.0076,  0.0324, -0.0007,  ..., -0.0074,  0.0177, -0.0193],
        [-0.0021, -0.0028,  0.0016,  ...,  0.0207,  0.0162,  0.0045],
        [ 0.0129, -0.0095,  0.0146,  ..., -0.0164, -0.0068,  0.0229]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:43:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bed is bunk
A more specific term for a citrus is lemon
A more specific term for a weapon is gun
A more specific term for a painting is watercolor
A more specific term for a weekday is monday
A more specific term for a brush is toothbrush
A more specific term for a trousers is jeans
A more specific term for a collar is
2024-06-29 23:43:10 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-29 23:43:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2324,  1.1299,  0.3767,  ..., -0.0766,  0.2366, -0.7065],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0200,  0.1257,  0.2111,  ...,  0.4939, -0.2959, -0.1143],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.8394e-01,  8.3496e-01,  6.1035e-04,  ..., -2.4561e-01,
        -4.5654e-02, -7.1924e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1021,  0.2986, -0.2059,  ...,  0.0338, -0.4722,  0.2406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:43:10 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:43:10 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 23:43:33 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 23:43:56 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-29 23:44:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.7940e-03, -1.7095e-04, -1.4753e-03,  ..., -5.8937e-04,
          2.3901e-04, -1.8196e-03],
        [-2.5487e-04, -8.9035e-03, -1.4296e-03,  ...,  2.8229e-03,
         -6.1131e-04,  1.4038e-03],
        [-1.6298e-03,  1.8501e-04, -9.7885e-03,  ..., -1.5659e-03,
         -1.6546e-03,  1.5962e-04],
        ...,
        [ 1.3285e-03,  1.8673e-03, -1.2100e-05,  ..., -8.4534e-03,
         -1.3762e-03, -1.2970e-03],
        [ 3.0470e-04, -3.6597e-04,  2.3472e-04,  ..., -8.1348e-04,
         -6.1073e-03,  4.9019e-04],
        [-2.8038e-04,  1.2312e-03, -5.7220e-04,  ..., -1.9894e-03,
          1.9801e-04, -6.2485e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0284,  0.0042, -0.0030,  ...,  0.0071,  0.0013,  0.0007],
        [-0.0058, -0.0355, -0.0062,  ...,  0.0031, -0.0007,  0.0060],
        [ 0.0015,  0.0062, -0.0309,  ...,  0.0026,  0.0029,  0.0012],
        ...,
        [ 0.0011,  0.0033, -0.0045,  ..., -0.0372,  0.0026, -0.0025],
        [-0.0036, -0.0031,  0.0073,  ...,  0.0002, -0.0328,  0.0051],
        [-0.0019,  0.0042, -0.0023,  ...,  0.0026,  0.0012, -0.0363]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0469,  0.0055,  0.0039,  ..., -0.0038,  0.0020, -0.0060],
        [ 0.0012, -0.0481, -0.0008,  ..., -0.0012,  0.0033, -0.0019],
        [-0.0072,  0.0011, -0.0365,  ..., -0.0073, -0.0054, -0.0012],
        ...,
        [ 0.0011,  0.0022, -0.0028,  ..., -0.0461,  0.0017, -0.0025],
        [-0.0022,  0.0015,  0.0013,  ...,  0.0016, -0.0442,  0.0024],
        [-0.0011, -0.0038, -0.0056,  ...,  0.0017, -0.0009, -0.0446]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:44:21 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-29 23:44:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2108,  1.2275, -0.1299,  ..., -0.2634,  0.0648, -0.9556],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0227,  0.0671,  0.1650,  ...,  0.0511, -0.4502, -0.0660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1060,  0.8984,  0.1951,  ..., -0.0219, -0.1565, -0.9106],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2937, -0.0449, -0.1642,  ..., -0.0597, -0.3904,  0.2115],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:44:21 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:44:21 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 23:44:43 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 23:45:06 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-29 23:45:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0094, -0.0019, -0.0012,  ...,  0.0020, -0.0008,  0.0013],
        [ 0.0019, -0.0079,  0.0018,  ...,  0.0007, -0.0013, -0.0004],
        [-0.0012, -0.0012, -0.0064,  ...,  0.0016,  0.0007, -0.0012],
        ...,
        [ 0.0012,  0.0003, -0.0007,  ..., -0.0081, -0.0012, -0.0024],
        [ 0.0007,  0.0016,  0.0015,  ..., -0.0005, -0.0098, -0.0002],
        [ 0.0034, -0.0008, -0.0016,  ..., -0.0023, -0.0008, -0.0105]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0549, -0.0003, -0.0004,  ..., -0.0058,  0.0013,  0.0074],
        [ 0.0029, -0.0607, -0.0069,  ...,  0.0086, -0.0065, -0.0039],
        [-0.0069, -0.0058, -0.0528,  ..., -0.0022, -0.0025,  0.0049],
        ...,
        [-0.0048, -0.0034,  0.0098,  ..., -0.0559, -0.0046, -0.0004],
        [ 0.0085, -0.0018, -0.0095,  ..., -0.0013, -0.0486, -0.0009],
        [ 0.0060, -0.0165, -0.0053,  ..., -0.0009, -0.0069, -0.0565]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.4951e-02,  4.5471e-03, -1.0471e-03,  ..., -4.8561e-03,
          5.8460e-04, -1.0033e-02],
        [-3.6049e-04, -7.5928e-02, -6.0616e-03,  ..., -1.0643e-03,
         -1.0147e-03,  6.1798e-04],
        [ 9.5701e-04,  1.3027e-03, -6.9458e-02,  ..., -8.8882e-03,
          9.6321e-04, -1.2169e-03],
        ...,
        [-6.0511e-04,  4.7646e-03, -3.6488e-03,  ..., -7.1411e-02,
         -5.6343e-03,  5.9547e-03],
        [-5.7220e-03, -6.0616e-03,  1.9970e-03,  ..., -6.2227e-04,
         -7.3425e-02,  2.2125e-03],
        [-5.3596e-03,  7.1144e-04,  4.6806e-03,  ..., -2.7752e-03,
         -4.4227e-05, -7.2937e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:45:32 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-29 23:45:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3398,  0.9131, -0.0088,  ..., -0.2622, -0.0569, -0.8481],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1746,  0.4521, -0.3152,  ...,  0.0538, -0.7114,  0.3618],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1736,  1.0303, -0.1753,  ...,  0.3057, -0.2142, -0.6489],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6318,  0.0613, -0.1310,  ..., -0.1025, -1.0049,  0.4893],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:45:32 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:45:32 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 23:45:57 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 23:46:22 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-29 23:46:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1482e-02, -1.3113e-04, -1.6565e-03,  ...,  7.1764e-04,
         -1.8291e-03, -5.2881e-04],
        [ 2.9993e-04, -1.1230e-02, -8.3780e-04,  ...,  1.8382e-04,
          2.9278e-04,  1.1187e-03],
        [ 2.8839e-03, -3.5501e-04, -9.2010e-03,  ..., -1.5173e-03,
          2.1439e-03,  1.8387e-03],
        ...,
        [ 2.9831e-03,  1.0691e-03, -1.9255e-03,  ..., -1.1719e-02,
          2.3289e-03, -8.2791e-05],
        [ 2.4962e-04, -1.1215e-03, -2.2697e-03,  ...,  1.2064e-03,
         -9.4299e-03, -4.6706e-04],
        [-1.0262e-03,  1.3733e-03,  3.8552e-04,  ...,  4.6086e-04,
         -8.4925e-04, -1.1490e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0371,  0.0039,  0.0074,  ...,  0.0096, -0.0066, -0.0040],
        [-0.0145, -0.0331,  0.0049,  ..., -0.0013, -0.0057, -0.0069],
        [ 0.0096,  0.0035, -0.0424,  ...,  0.0019, -0.0064, -0.0049],
        ...,
        [ 0.0107, -0.0024, -0.0012,  ..., -0.0409,  0.0020,  0.0042],
        [-0.0022, -0.0023, -0.0026,  ...,  0.0016, -0.0384,  0.0080],
        [-0.0004,  0.0041, -0.0090,  ...,  0.0021, -0.0049, -0.0444]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0373,  0.0039,  0.0038,  ...,  0.0058, -0.0010,  0.0014],
        [-0.0034, -0.0373,  0.0166,  ...,  0.0116, -0.0073, -0.0070],
        [ 0.0025, -0.0002, -0.0271,  ..., -0.0027,  0.0017,  0.0013],
        ...,
        [ 0.0021,  0.0069,  0.0021,  ..., -0.0409, -0.0030, -0.0003],
        [-0.0084,  0.0052, -0.0032,  ...,  0.0029, -0.0341,  0.0054],
        [-0.0022,  0.0004, -0.0021,  ...,  0.0010,  0.0043, -0.0314]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:46:51 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-29 23:46:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1508,  1.0029,  0.2118,  ..., -0.0251, -0.1965, -1.1006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4658, -0.0887, -0.2345,  ..., -0.0778, -0.5864,  0.2937],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2722,  0.5195, -0.1552,  ...,  0.7124,  0.1940, -0.4219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8857,  0.0460, -0.1349,  ..., -0.6597, -0.0493,  0.6094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:46:51 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:46:51 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 23:47:21 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 23:47:52 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-29 23:48:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0043, -0.0004, -0.0015,  ..., -0.0005,  0.0019,  0.0022],
        [ 0.0055, -0.0038, -0.0026,  ..., -0.0022,  0.0006, -0.0015],
        [-0.0012,  0.0001, -0.0043,  ..., -0.0009,  0.0024, -0.0013],
        ...,
        [-0.0018, -0.0014, -0.0022,  ..., -0.0040, -0.0012,  0.0023],
        [ 0.0010,  0.0011,  0.0005,  ..., -0.0012, -0.0056, -0.0023],
        [ 0.0051,  0.0011, -0.0001,  ..., -0.0003, -0.0018, -0.0051]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0335, -0.0039, -0.0126,  ..., -0.0002,  0.0064,  0.0013],
        [ 0.0032, -0.0558,  0.0040,  ..., -0.0052,  0.0040,  0.0082],
        [-0.0089, -0.0083, -0.0469,  ...,  0.0061,  0.0041, -0.0001],
        ...,
        [-0.0025,  0.0092,  0.0033,  ..., -0.0360,  0.0069,  0.0002],
        [-0.0024, -0.0006, -0.0079,  ...,  0.0026, -0.0417, -0.0072],
        [-0.0080,  0.0030,  0.0032,  ...,  0.0035, -0.0087, -0.0361]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0574, -0.0029,  0.0019,  ..., -0.0022, -0.0014,  0.0029],
        [ 0.0070, -0.0448, -0.0033,  ...,  0.0005,  0.0056, -0.0008],
        [ 0.0054, -0.0075, -0.0602,  ...,  0.0009, -0.0024, -0.0026],
        ...,
        [ 0.0015,  0.0004,  0.0065,  ..., -0.0574, -0.0007, -0.0018],
        [ 0.0033,  0.0013, -0.0048,  ..., -0.0044, -0.0532, -0.0022],
        [ 0.0017,  0.0011, -0.0004,  ...,  0.0091, -0.0025, -0.0571]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:48:26 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-29 23:48:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1467,  0.9751, -0.1624,  ...,  0.2620, -0.1790, -0.6890],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6797,  0.0243, -0.1271,  ..., -0.1086, -1.0459,  0.5049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4763,  0.9707, -0.2460,  ...,  0.3752,  0.1825, -0.2876],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-8.5205e-01, -1.9897e-01, -2.4414e-04,  ..., -7.7930e-01,
        -1.0730e-01,  7.7588e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:48:26 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:48:26 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 23:49:00 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 23:49:25 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-29 23:49:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.2506e-04,  2.0046e-03, -4.6921e-03,  ...,  5.9853e-03,
          6.2513e-04, -1.3094e-03],
        [ 6.2656e-04,  1.9150e-03,  4.2992e-03,  ...,  2.7962e-03,
         -3.0003e-03,  3.0594e-03],
        [ 1.5411e-03,  1.6146e-03, -4.2343e-03,  ...,  9.7942e-04,
         -7.5340e-04,  1.8816e-03],
        ...,
        [ 9.6130e-04,  3.2692e-03, -3.1834e-03,  ..., -2.9869e-03,
         -1.9369e-03, -1.3561e-03],
        [ 1.4381e-03,  8.2922e-04, -3.3092e-03,  ...,  1.8044e-03,
          2.0695e-03, -6.2275e-04],
        [-3.2043e-04, -3.9101e-03, -1.7333e-04,  ..., -5.4836e-06,
         -1.7176e-03,  7.9966e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0788,  0.0008, -0.0005,  ..., -0.0088, -0.0006,  0.0122],
        [ 0.0017, -0.0773, -0.0107,  ..., -0.0073, -0.0026, -0.0090],
        [-0.0029, -0.0016, -0.0892,  ..., -0.0092,  0.0053, -0.0050],
        ...,
        [-0.0025, -0.0042,  0.0004,  ..., -0.0676,  0.0038,  0.0048],
        [ 0.0024,  0.0010, -0.0061,  ...,  0.0028, -0.0937,  0.0073],
        [-0.0070, -0.0020,  0.0070,  ..., -0.0002,  0.0020, -0.0845]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2537e-01, -8.2321e-03,  6.4850e-03,  ..., -9.9106e-03,
         -6.3477e-03, -1.6403e-04],
        [-5.7411e-03, -1.1517e-01,  1.8005e-03,  ..., -5.8136e-03,
         -5.7068e-03, -2.3975e-03],
        [ 8.2350e-04,  6.9427e-03, -1.1395e-01,  ..., -4.6425e-03,
          5.5008e-03, -2.7122e-03],
        ...,
        [-6.5880e-03, -6.6185e-04, -6.4545e-03,  ..., -1.0455e-01,
          4.0817e-03, -4.2496e-03],
        [ 6.2332e-03, -4.1962e-05,  6.6757e-04,  ..., -1.4391e-03,
         -1.2085e-01,  9.4070e-03],
        [-1.0223e-02,  3.8414e-03,  2.0885e-03,  ...,  2.1763e-03,
         -9.1248e-03, -1.2433e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:50:00 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-29 23:50:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2502,  0.4526, -0.1466,  ...,  0.6079,  0.1477, -0.4104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9268,  0.0365, -0.1417,  ..., -0.6528, -0.0652,  0.6309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2346,  1.2715, -0.7715,  ...,  0.1172, -0.0804, -0.4722],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7148,  0.1528, -0.2142,  ..., -0.3784, -0.0153,  0.2991],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:50:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:50:00 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 23:50:35 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 23:51:10 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-29 23:51:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.0942e-03, -3.6392e-03,  2.2697e-03,  ...,  1.8072e-03,
         -2.4242e-03,  9.3460e-05],
        [-3.2463e-03, -6.9046e-03,  8.0261e-03,  ..., -1.8282e-03,
         -6.5708e-04,  2.9907e-03],
        [-2.2519e-04,  2.9926e-03, -5.2376e-03,  ..., -3.3379e-04,
          3.0117e-03, -2.5101e-03],
        ...,
        [-1.6794e-03, -2.9583e-03, -2.2335e-03,  ..., -3.9444e-03,
         -3.8757e-03,  1.6289e-03],
        [ 3.4790e-03,  3.5000e-04,  2.9392e-03,  ..., -5.1765e-03,
         -3.5992e-03,  5.3930e-04],
        [ 4.6539e-03, -3.6030e-03, -1.1768e-03,  ...,  4.6062e-04,
         -1.1387e-03, -3.7441e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0831, -0.0023, -0.0125,  ...,  0.0029,  0.0045, -0.0017],
        [ 0.0071, -0.0803,  0.0132,  ...,  0.0011, -0.0006,  0.0061],
        [ 0.0014,  0.0072, -0.0801,  ...,  0.0021,  0.0023,  0.0064],
        ...,
        [-0.0014, -0.0166,  0.0078,  ..., -0.0724,  0.0080, -0.0045],
        [-0.0009,  0.0068,  0.0097,  ...,  0.0031, -0.0781,  0.0054],
        [ 0.0002, -0.0005,  0.0018,  ..., -0.0060,  0.0114, -0.0801]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3318e-01,  7.6294e-03, -2.0905e-02,  ...,  1.0086e-02,
          7.7744e-03, -9.3689e-03],
        [ 5.0449e-04, -1.3342e-01, -3.1776e-03,  ...,  8.8348e-03,
         -8.9836e-04,  6.3133e-03],
        [-5.9814e-03,  5.6572e-03, -1.2500e-01,  ...,  5.8823e-03,
          2.4490e-03,  2.4204e-03],
        ...,
        [-1.0204e-04,  3.5114e-03,  1.1978e-02,  ..., -1.2585e-01,
          1.2798e-03, -1.2817e-03],
        [ 8.6641e-04, -4.0016e-03, -5.7220e-05,  ...,  8.3771e-03,
         -1.2360e-01, -4.8370e-03],
        [-8.3237e-03,  4.8599e-03, -6.9885e-03,  ..., -1.0368e-02,
          3.8109e-03, -1.3635e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:51:48 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-29 23:51:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4182,  0.8623, -0.2222,  ...,  0.2710,  0.1437, -0.2944],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8447, -0.1887, -0.0160,  ..., -0.7476, -0.1077,  0.7539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3350,  0.7749, -1.0898,  ..., -0.1750, -0.4336, -0.1643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3442, -0.3813, -0.7827,  ..., -0.3960,  0.0848,  0.6724],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:51:48 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:51:48 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 23:52:27 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 23:53:06 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-29 23:53:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0008,  0.0039, -0.0025,  ...,  0.0007, -0.0025,  0.0024],
        [ 0.0036, -0.0018, -0.0023,  ...,  0.0036,  0.0049, -0.0002],
        [ 0.0011, -0.0056, -0.0048,  ..., -0.0047, -0.0043,  0.0010],
        ...,
        [ 0.0015, -0.0021,  0.0039,  ..., -0.0026, -0.0047,  0.0048],
        [-0.0046,  0.0002, -0.0057,  ...,  0.0026,  0.0015, -0.0007],
        [ 0.0005, -0.0037,  0.0021,  ..., -0.0024,  0.0052,  0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.5144e-02, -5.9843e-05,  1.0242e-03,  ...,  1.2827e-03,
         -6.7101e-03, -3.4618e-03],
        [-1.8173e-02, -9.1431e-02, -9.8801e-03,  ..., -4.0627e-03,
         -2.0447e-03,  1.4820e-03],
        [-9.1248e-03,  1.6651e-03, -7.2266e-02,  ...,  2.2488e-03,
          4.2725e-03, -1.4091e-02],
        ...,
        [-4.3869e-03, -8.8806e-03, -9.4223e-03,  ..., -7.4463e-02,
         -6.4125e-03,  8.9550e-04],
        [ 4.1618e-03, -5.6076e-03,  2.1687e-03,  ...,  3.5667e-03,
         -8.0933e-02,  1.9245e-03],
        [-2.2690e-02, -1.2527e-02, -1.6613e-03,  ..., -2.1057e-03,
         -5.0468e-03, -8.5327e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1129, -0.0059,  0.0107,  ..., -0.0076, -0.0055,  0.0038],
        [-0.0040, -0.0992, -0.0013,  ..., -0.0030, -0.0064,  0.0040],
        [ 0.0152, -0.0005, -0.0837,  ...,  0.0015,  0.0043, -0.0064],
        ...,
        [-0.0108, -0.0029, -0.0132,  ..., -0.1187,  0.0037, -0.0004],
        [ 0.0117,  0.0054,  0.0015,  ...,  0.0080, -0.1054,  0.0016],
        [ 0.0070, -0.0056,  0.0133,  ...,  0.0115,  0.0033, -0.1115]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:53:32 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-29 23:53:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1801,  0.9976, -0.5796,  ...,  0.0765, -0.0721, -0.3977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6479,  0.1365, -0.1941,  ..., -0.3206, -0.0186,  0.2581],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0574,  0.8271, -0.4839,  ..., -0.8975, -0.7061, -0.3535],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0554, -0.8643, -1.0918,  ..., -0.5234,  0.7627,  0.6758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:53:32 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:53:32 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 23:54:14 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 23:54:57 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-29 23:55:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3420e-02, -3.6979e-04, -2.2507e-03,  ..., -1.9951e-03,
          2.1420e-03, -5.3673e-03],
        [ 2.1706e-03, -1.5114e-02,  3.1147e-03,  ..., -1.6270e-03,
         -4.1809e-03,  2.9945e-03],
        [ 5.7793e-04,  3.7689e-03, -7.0724e-03,  ...,  6.4087e-04,
          2.2011e-03,  1.1749e-03],
        ...,
        [-1.5125e-03, -3.6755e-03,  3.5048e-04,  ..., -1.0971e-02,
         -2.8610e-03, -4.2801e-03],
        [-1.6766e-03,  4.9639e-04,  1.0967e-05,  ..., -3.8338e-03,
         -8.2779e-03, -2.1172e-03],
        [ 8.9722e-03,  2.9716e-03, -2.0103e-03,  ..., -4.8828e-04,
         -1.4648e-03, -7.4196e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0939,  0.0012,  0.0102,  ..., -0.0151, -0.0013,  0.0141],
        [-0.0005, -0.0913, -0.0008,  ..., -0.0016,  0.0044,  0.0063],
        [-0.0009,  0.0039, -0.0854,  ...,  0.0070, -0.0081,  0.0036],
        ...,
        [-0.0057, -0.0006, -0.0063,  ..., -0.0842,  0.0083, -0.0022],
        [-0.0153,  0.0097, -0.0019,  ...,  0.0025, -0.0827,  0.0124],
        [ 0.0190,  0.0019, -0.0121,  ..., -0.0096,  0.0051, -0.0999]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1299,  0.0081,  0.0008,  ..., -0.0182,  0.0027,  0.0069],
        [-0.0045, -0.1344,  0.0139,  ..., -0.0093,  0.0028,  0.0021],
        [-0.0081,  0.0072, -0.1299,  ..., -0.0041, -0.0050,  0.0157],
        ...,
        [-0.0105,  0.0080, -0.0016,  ..., -0.1195,  0.0080, -0.0090],
        [-0.0048,  0.0115, -0.0220,  ..., -0.0079, -0.1210,  0.0033],
        [ 0.0024, -0.0089, -0.0151,  ..., -0.0072,  0.0031, -0.1266]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:55:29 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-29 23:55:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2052,  0.5293, -0.7627,  ..., -0.1353, -0.3059, -0.1359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3057, -0.3264, -0.6733,  ..., -0.3274,  0.0546,  0.5571],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2346,  1.1191, -0.3887,  ..., -1.1523, -0.8477, -0.6411],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1882, -1.5098, -0.5781,  ..., -1.4414,  0.7285,  0.3381],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:55:29 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:55:30 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 23:56:17 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 23:57:05 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-29 23:57:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0011, -0.0005,  0.0046,  ..., -0.0119, -0.0054, -0.0050],
        [ 0.0052,  0.0027,  0.0006,  ..., -0.0009, -0.0118,  0.0025],
        [-0.0063,  0.0040,  0.0095,  ..., -0.0019,  0.0007, -0.0023],
        ...,
        [ 0.0028, -0.0045,  0.0043,  ...,  0.0044, -0.0048, -0.0018],
        [-0.0066, -0.0034,  0.0024,  ..., -0.0026,  0.0038,  0.0015],
        [-0.0008, -0.0033,  0.0012,  ..., -0.0056,  0.0082,  0.0073]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.8562e-02, -1.7746e-02,  4.2801e-03,  ..., -2.9659e-03,
          1.2230e-02, -2.0859e-02],
        [ 3.6564e-03, -1.2213e-01,  6.7444e-03,  ...,  9.7198e-03,
         -8.3313e-03,  5.6953e-03],
        [-3.3436e-03,  5.8174e-04, -1.0004e-01,  ..., -5.1270e-03,
         -5.3787e-03, -1.8616e-02],
        ...,
        [ 1.4557e-02,  1.0014e-04,  1.6266e-02,  ..., -1.0364e-01,
          1.3107e-02,  1.1765e-02],
        [-1.2283e-03, -1.2634e-02,  1.0582e-02,  ...,  3.2711e-03,
         -1.1139e-01,  9.7733e-03],
        [ 2.6779e-03,  2.8400e-03,  8.5144e-03,  ..., -2.3689e-03,
          9.8343e-03, -9.2407e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.0105e-01, -7.3776e-03,  2.6379e-03,  ...,  7.8735e-03,
          8.1406e-03, -6.8932e-03],
        [-1.1005e-03, -1.9287e-01, -9.3079e-03,  ...,  6.9656e-03,
         -7.0114e-03,  1.4069e-02],
        [-4.2572e-03, -3.7098e-03, -1.6882e-01,  ..., -7.4387e-04,
         -7.8201e-03, -1.0872e-02],
        ...,
        [ 1.1063e-04, -2.0218e-03, -9.4986e-03,  ..., -1.8970e-01,
         -1.6336e-03,  7.6790e-03],
        [ 1.1406e-02,  4.4632e-04,  1.2711e-02,  ...,  1.5173e-03,
         -1.9568e-01, -1.5030e-02],
        [-9.9411e-03,  8.4839e-03,  9.1782e-03,  ..., -8.0261e-03,
         -7.4425e-03, -1.7883e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-29 23:57:55 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-29 23:57:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0357,  0.4844, -0.3201,  ..., -0.5054, -0.4355, -0.2639],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0492, -0.7036, -0.8584,  ..., -0.3789,  0.5732,  0.5010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1028,  0.5938, -0.0471,  ..., -0.6616, -0.9438, -0.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3970, -1.8438, -0.1514,  ..., -0.7246,  0.6553,  1.2305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-29 23:57:55 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-29 23:57:55 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 23:58:40 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-29 23:59:29 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 00:00:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0099, -0.0042,  0.0005,  ...,  0.0006,  0.0032,  0.0026],
        [-0.0041,  0.0009,  0.0009,  ...,  0.0012,  0.0008, -0.0007],
        [-0.0005,  0.0024, -0.0053,  ...,  0.0007, -0.0041,  0.0032],
        ...,
        [-0.0008, -0.0051,  0.0048,  ..., -0.0059, -0.0022,  0.0010],
        [-0.0002, -0.0023,  0.0007,  ..., -0.0009, -0.0073,  0.0004],
        [ 0.0004,  0.0026, -0.0022,  ...,  0.0011,  0.0045, -0.0069]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1426e-01, -3.6240e-05,  8.6594e-04,  ...,  8.3618e-03,
         -2.2793e-03,  4.4518e-03],
        [ 7.7019e-03, -1.0559e-01, -6.5498e-03,  ..., -1.8797e-03,
          2.0218e-03, -1.5930e-02],
        [-6.4201e-03, -1.0284e-02, -1.2067e-01,  ...,  6.6452e-03,
         -9.6054e-03, -2.3499e-03],
        ...,
        [ 1.7410e-02, -8.6670e-03,  6.5384e-03,  ..., -1.0315e-01,
         -2.3251e-03, -7.8888e-03],
        [ 1.4381e-02,  2.0981e-03, -3.1471e-04,  ...,  9.4070e-03,
         -1.0651e-01,  6.3477e-03],
        [-3.8261e-03, -8.0719e-03, -9.3536e-03,  ..., -1.1024e-03,
          6.0730e-03, -1.1206e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1239, -0.0002, -0.0025,  ..., -0.0020,  0.0078, -0.0072],
        [ 0.0090, -0.1079, -0.0024,  ...,  0.0028,  0.0031, -0.0076],
        [ 0.0096, -0.0115, -0.1263,  ...,  0.0033, -0.0080, -0.0033],
        ...,
        [ 0.0002, -0.0065,  0.0065,  ..., -0.1119,  0.0065, -0.0170],
        [-0.0005, -0.0132, -0.0074,  ...,  0.0152, -0.1180,  0.0269],
        [ 0.0022, -0.0006, -0.0125,  ...,  0.0064,  0.0032, -0.1299]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:00:22 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 00:00:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1494,  0.6138, -0.2546,  ..., -0.6479, -0.4858, -0.3660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1403, -1.0547, -0.4126,  ..., -0.9531,  0.4580,  0.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1056,  0.6963, -0.5801,  ..., -0.8203, -0.6934, -0.2993],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2019, -2.0137, -0.0209,  ..., -0.7578,  1.3955,  0.6074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:00:22 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:00:22 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 00:01:11 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 00:02:04 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 00:02:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0081, -0.0003,  0.0032,  ...,  0.0037, -0.0025,  0.0032],
        [ 0.0102,  0.0107,  0.0066,  ..., -0.0073,  0.0029, -0.0017],
        [-0.0033, -0.0022,  0.0141,  ..., -0.0057,  0.0017, -0.0045],
        ...,
        [ 0.0075,  0.0045,  0.0169,  ...,  0.0130, -0.0137,  0.0048],
        [-0.0046, -0.0053,  0.0019,  ...,  0.0050,  0.0158,  0.0024],
        [ 0.0018,  0.0004, -0.0031,  ..., -0.0078, -0.0031,  0.0038]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1482, -0.0033,  0.0054,  ...,  0.0054, -0.0179, -0.0037],
        [-0.0104, -0.1605,  0.0005,  ..., -0.0033,  0.0002,  0.0004],
        [-0.0107,  0.0035, -0.1338,  ...,  0.0151, -0.0069,  0.0127],
        ...,
        [-0.0091, -0.0150,  0.0159,  ..., -0.1385, -0.0046,  0.0046],
        [ 0.0070,  0.0049, -0.0002,  ..., -0.0063, -0.1577, -0.0017],
        [ 0.0141, -0.0018, -0.0077,  ..., -0.0165,  0.0053, -0.1399]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.8125e-01,  3.9825e-03,  8.7891e-03,  ...,  6.7520e-03,
         -4.4098e-03, -2.2755e-03],
        [-1.0834e-03, -2.9028e-01, -3.4599e-03,  ..., -1.0429e-02,
          2.4963e-02,  1.5793e-03],
        [-7.6675e-03,  1.9409e-02, -2.6636e-01,  ...,  1.7761e-02,
          3.1548e-03,  2.0409e-03],
        ...,
        [-8.6899e-03, -5.2872e-03,  3.4485e-03,  ..., -2.7490e-01,
          1.0498e-02,  8.9035e-03],
        [-1.8585e-02,  1.5427e-02,  6.6223e-03,  ...,  1.5327e-02,
         -2.7661e-01,  3.3340e-03],
        [-5.4016e-03, -3.3264e-03, -1.2497e-02,  ...,  1.1253e-03,
         -1.0300e-04, -2.6514e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:03:00 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 00:03:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0271,  0.3252, -0.0796,  ..., -0.3823, -0.5513, -0.3794],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3291, -1.4111, -0.1582,  ..., -0.5386,  0.4785,  0.8979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1195,  0.6084, -0.4485,  ..., -0.5864, -0.9570,  0.6597],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.3792, -2.1582, -0.3071,  ..., -0.3149,  1.0801,  0.8359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:03:00 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:03:00 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 00:03:57 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 00:04:55 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 00:05:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6846e-02,  5.8556e-03, -4.8904e-03,  ...,  8.3733e-04,
         -1.6022e-03, -1.4706e-03],
        [-1.6117e-03, -1.8005e-02, -3.2082e-03,  ...,  1.4448e-03,
          2.9640e-03, -1.9627e-03],
        [ 7.1220e-03,  5.9433e-03, -1.3252e-02,  ...,  3.8552e-04,
         -1.1444e-05,  9.1136e-05],
        ...,
        [ 9.5367e-04, -1.9014e-04, -7.5798e-03,  ..., -1.2177e-02,
          5.7259e-03,  2.7485e-03],
        [ 4.1389e-03, -2.0561e-03, -2.5539e-03,  ..., -7.1640e-03,
         -1.2550e-02,  4.7684e-06],
        [ 5.2795e-03,  4.3030e-03, -3.1414e-03,  ...,  3.4409e-03,
          1.6518e-03, -9.0714e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0675e-01,  1.2062e-02,  5.1727e-03,  ...,  4.2152e-03,
          8.6899e-03, -9.1400e-03],
        [ 1.5137e-02, -1.0535e-01,  1.2236e-03,  ..., -5.8823e-03,
          8.4915e-03,  7.6447e-03],
        [ 8.2474e-03, -1.3313e-02, -9.7046e-02,  ..., -1.4029e-03,
          4.5776e-05, -1.2074e-03],
        ...,
        [-5.7678e-03,  6.6833e-03,  8.9417e-03,  ..., -8.2947e-02,
         -9.6989e-04, -5.8365e-03],
        [ 8.3008e-03, -2.4757e-03,  6.0043e-03,  ...,  1.1444e-02,
         -8.4839e-02,  1.7960e-02],
        [-3.7670e-03,  2.3861e-03, -4.7760e-03,  ...,  4.2419e-03,
          2.3155e-03, -9.9365e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1161,  0.0046, -0.0084,  ..., -0.0079,  0.0057,  0.0037],
        [ 0.0089, -0.1152,  0.0030,  ...,  0.0089,  0.0072,  0.0055],
        [-0.0067, -0.0154, -0.1139,  ..., -0.0041, -0.0148,  0.0017],
        ...,
        [ 0.0074,  0.0152,  0.0076,  ..., -0.0965,  0.0066, -0.0113],
        [ 0.0043, -0.0024, -0.0052,  ...,  0.0107, -0.1122,  0.0113],
        [ 0.0104, -0.0068,  0.0049,  ..., -0.0096,  0.0059, -0.1192]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:05:53 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 00:05:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0527,  0.3481, -0.3213,  ..., -0.4607, -0.3821, -0.1965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1495, -1.4717, -0.0255,  ..., -0.5347,  0.9819,  0.4136],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3311,  0.5000, -0.6377,  ..., -0.4629, -1.0430,  0.8052],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2839, -3.2383, -0.5176,  ...,  0.1235,  0.9131, -0.1689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:05:53 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:05:53 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 00:06:50 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 00:07:43 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 00:08:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.2310e-03, -7.3128e-03,  9.7179e-04,  ...,  5.0049e-03,
          3.4313e-03,  1.6403e-04],
        [-6.0539e-03,  9.0637e-03,  4.3983e-03,  ..., -3.6545e-03,
          6.6948e-03, -4.7302e-03],
        [-6.1989e-04, -9.4223e-04, -1.3027e-03,  ..., -4.8103e-03,
         -1.4944e-03,  5.1594e-04],
        ...,
        [-6.6757e-03, -3.2845e-03,  1.2764e-02,  ...,  1.5316e-03,
         -7.9117e-03,  6.3324e-03],
        [ 6.8092e-04, -1.3981e-03,  4.0932e-03,  ...,  7.4863e-05,
          6.6643e-03, -1.2779e-03],
        [ 3.6716e-03,  3.4332e-03, -3.2272e-03,  ..., -1.2642e-02,
         -2.8515e-03,  6.4945e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1139, -0.0109, -0.0031,  ..., -0.0126,  0.0075,  0.0084],
        [ 0.0015, -0.1354,  0.0025,  ...,  0.0007, -0.0018,  0.0057],
        [ 0.0114, -0.0166, -0.1198,  ..., -0.0089,  0.0036, -0.0173],
        ...,
        [-0.0092,  0.0085,  0.0114,  ..., -0.1225,  0.0102, -0.0036],
        [ 0.0121,  0.0098, -0.0012,  ...,  0.0022, -0.1279, -0.0033],
        [ 0.0024,  0.0048, -0.0106,  ..., -0.0126, -0.0032, -0.1296]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1360, -0.0064,  0.0020,  ..., -0.0170,  0.0035,  0.0053],
        [-0.0161, -0.1473, -0.0087,  ..., -0.0139, -0.0030,  0.0051],
        [ 0.0132, -0.0073, -0.1416,  ..., -0.0075,  0.0216, -0.0189],
        ...,
        [-0.0060, -0.0015, -0.0016,  ..., -0.1213,  0.0057,  0.0091],
        [ 0.0049,  0.0141,  0.0011,  ...,  0.0104, -0.1423,  0.0120],
        [ 0.0023,  0.0149, -0.0036,  ...,  0.0005,  0.0006, -0.1382]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:08:38 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 00:08:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0925,  0.2837, -0.2433,  ..., -0.3098, -0.4607,  0.2783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2087, -1.3428, -0.2042,  ..., -0.2061,  0.6968,  0.4678],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3564,  0.2417, -0.1936,  ..., -0.5669, -0.6367,  1.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4658, -3.5430, -0.9072,  ...,  0.0375,  1.5996, -0.5005],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:08:38 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:08:38 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 00:09:38 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 00:10:36 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 00:11:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.0027e-03, -3.4294e-03, -2.0752e-03,  ..., -4.9286e-03,
         -1.3535e-02, -9.4986e-03],
        [ 1.2875e-04,  7.7133e-03, -5.5809e-03,  ..., -2.7790e-03,
          7.2050e-04, -1.3809e-03],
        [-1.5900e-02, -9.7122e-03,  1.2466e-02,  ..., -4.1695e-03,
         -2.1362e-03,  6.8245e-03],
        ...,
        [ 1.5616e-05, -3.1128e-03, -1.7776e-03,  ...,  1.8341e-02,
         -4.5090e-03,  4.4060e-03],
        [ 5.7068e-03, -1.4076e-03,  3.6125e-03,  ...,  1.9226e-03,
          1.2589e-02,  2.7313e-03],
        [-4.6802e-04,  8.7814e-03, -2.4700e-03,  ..., -1.8387e-03,
         -2.3098e-03,  8.2474e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.9905e-02,  7.5188e-03,  4.3755e-03,  ...,  3.5820e-03,
         -1.0319e-03,  5.0507e-03],
        [ 5.9204e-03, -1.0352e-01,  4.7302e-03,  ..., -1.0300e-04,
          2.7895e-04, -9.2850e-03],
        [-1.3863e-02,  2.5902e-03, -7.6111e-02,  ...,  4.0436e-04,
          9.6664e-03, -1.3161e-02],
        ...,
        [ 1.0818e-02, -1.5549e-02, -6.9084e-03,  ..., -7.8125e-02,
          1.0651e-02,  3.1166e-03],
        [ 7.5340e-03, -2.7428e-03,  1.0506e-02,  ...,  4.9400e-04,
         -7.4280e-02,  5.3215e-03],
        [ 1.8864e-03, -1.8940e-03,  2.4300e-03,  ..., -1.1368e-02,
          4.3793e-03, -8.1360e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1140,  0.0015, -0.0022,  ..., -0.0012,  0.0154,  0.0043],
        [ 0.0145, -0.0995, -0.0018,  ...,  0.0163, -0.0020,  0.0029],
        [-0.0041, -0.0091, -0.1023,  ..., -0.0067,  0.0086,  0.0168],
        ...,
        [-0.0095, -0.0098, -0.0103,  ..., -0.1035,  0.0005, -0.0293],
        [-0.0070,  0.0075,  0.0057,  ...,  0.0010, -0.1057,  0.0006],
        [-0.0110,  0.0050,  0.0031,  ..., -0.0098,  0.0060, -0.0947]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:11:38 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 00:11:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1726,  0.2043, -0.2927,  ..., -0.2322, -0.4915,  0.3523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1626, -1.9219, -0.2844,  ...,  0.0575,  0.5288, -0.1333],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2588,  0.2791, -0.3569,  ..., -0.5078, -0.5708,  2.0879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5605, -4.1406, -1.4561,  ...,  0.4277,  1.4805, -0.2637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:11:38 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:11:38 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 00:12:40 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 00:13:41 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 00:14:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.3771e-03,  2.8610e-03, -7.3051e-04,  ...,  1.4114e-03,
         -3.1042e-04,  1.5278e-03],
        [ 4.9667e-03,  3.0327e-03,  5.6314e-04,  ..., -1.9445e-03,
         -8.0013e-04, -2.3174e-03],
        [ 3.0661e-04, -1.2503e-03,  4.6997e-03,  ..., -1.8148e-03,
         -2.6627e-03, -9.0313e-04],
        ...,
        [-3.4828e-03, -1.2951e-03,  3.3379e-04,  ...,  5.2643e-03,
         -5.3864e-03,  3.9387e-04],
        [ 1.3199e-03, -1.5163e-03,  1.5926e-03,  ...,  3.9062e-03,
          4.1847e-03, -1.5020e-03],
        [ 1.4000e-03, -2.8191e-03,  4.2267e-03,  ..., -3.3426e-04,
         -9.2983e-05,  7.9422e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0912,  0.0101, -0.0079,  ..., -0.0078,  0.0003, -0.0009],
        [ 0.0100, -0.0891, -0.0208,  ..., -0.0074,  0.0011,  0.0062],
        [-0.0093, -0.0116, -0.1105,  ..., -0.0010, -0.0169,  0.0018],
        ...,
        [-0.0087,  0.0105, -0.0002,  ..., -0.0982, -0.0070, -0.0026],
        [-0.0016, -0.0048, -0.0008,  ...,  0.0038, -0.1070, -0.0011],
        [ 0.0052, -0.0056, -0.0111,  ..., -0.0050,  0.0058, -0.1141]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1376, -0.0109,  0.0055,  ...,  0.0083, -0.0053,  0.0212],
        [-0.0038, -0.1560, -0.0078,  ..., -0.0068, -0.0159,  0.0111],
        [-0.0023,  0.0054, -0.1571,  ...,  0.0168, -0.0056, -0.0059],
        ...,
        [ 0.0164,  0.0034,  0.0027,  ..., -0.1515,  0.0033,  0.0119],
        [-0.0046,  0.0018, -0.0132,  ...,  0.0046, -0.1591,  0.0128],
        [ 0.0141, -0.0092, -0.0039,  ...,  0.0063,  0.0122, -0.1614]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:14:43 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 00:14:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1235,  0.1138, -0.1075,  ..., -0.2666, -0.2952,  0.6660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2180, -1.9678, -0.4885,  ...,  0.0184,  0.8745, -0.3037],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2861,  0.2485, -0.0991,  ...,  0.0181,  0.1460,  2.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6729, -4.8125, -1.0156,  ...,  0.8213,  2.2539, -0.6152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:14:43 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:14:43 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 00:15:45 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 00:16:48 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 00:17:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0006, -0.0026, -0.0032,  ...,  0.0088,  0.0014, -0.0044],
        [-0.0101,  0.0024,  0.0010,  ..., -0.0053,  0.0089,  0.0029],
        [ 0.0037,  0.0009, -0.0098,  ...,  0.0007, -0.0017,  0.0007],
        ...,
        [ 0.0080, -0.0033, -0.0005,  ..., -0.0011, -0.0047,  0.0056],
        [ 0.0038,  0.0004,  0.0005,  ...,  0.0026, -0.0018,  0.0038],
        [ 0.0006,  0.0004, -0.0059,  ...,  0.0004,  0.0048, -0.0070]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0643,  0.0010, -0.0026,  ..., -0.0103,  0.0048, -0.0055],
        [-0.0096, -0.0679, -0.0146,  ...,  0.0053, -0.0073, -0.0027],
        [ 0.0013, -0.0074, -0.0726,  ..., -0.0015,  0.0054, -0.0010],
        ...,
        [-0.0066, -0.0041,  0.0034,  ..., -0.0673, -0.0053, -0.0054],
        [ 0.0045,  0.0209,  0.0027,  ...,  0.0123, -0.0737,  0.0029],
        [-0.0096,  0.0004,  0.0128,  ..., -0.0121, -0.0098, -0.0649]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0627,  0.0078,  0.0137,  ..., -0.0226, -0.0107,  0.0098],
        [-0.0072, -0.0787, -0.0058,  ...,  0.0070, -0.0143,  0.0044],
        [ 0.0193,  0.0085, -0.0853,  ..., -0.0132, -0.0017, -0.0124],
        ...,
        [-0.0183, -0.0113, -0.0147,  ..., -0.0641, -0.0054, -0.0102],
        [ 0.0166,  0.0131, -0.0006,  ...,  0.0101, -0.0901,  0.0107],
        [ 0.0051, -0.0101,  0.0155,  ..., -0.0146, -0.0233, -0.0996]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:17:56 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 00:17:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0974,  0.1140, -0.1510,  ..., -0.2222, -0.2385,  0.8652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2729, -2.1016, -0.6978,  ...,  0.2026,  0.7520, -0.1696],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1901,  0.2959, -0.1284,  ..., -0.2212,  0.4768,  3.4590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.5000, -4.8594, -1.2988,  ...,  0.6133,  2.0605, -1.7939],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:17:56 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:17:56 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 00:19:02 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 00:20:10 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 00:21:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0002, -0.0099,  0.0055,  ..., -0.0044,  0.0063,  0.0011],
        [-0.0053,  0.0042,  0.0120,  ..., -0.0052,  0.0106, -0.0093],
        [-0.0096, -0.0043, -0.0119,  ...,  0.0049, -0.0007, -0.0050],
        ...,
        [-0.0032, -0.0080,  0.0022,  ...,  0.0072,  0.0073,  0.0013],
        [ 0.0043,  0.0026, -0.0074,  ..., -0.0034, -0.0054,  0.0041],
        [ 0.0014,  0.0019,  0.0013,  ..., -0.0012,  0.0015, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.0944e-02, -4.3583e-04,  2.3209e-02,  ...,  1.3824e-02,
          4.0169e-03, -5.7220e-04],
        [ 2.1954e-03, -7.7515e-02,  1.2604e-02,  ...,  1.5373e-03,
          1.3733e-03,  1.0729e-04],
        [-9.8114e-03,  7.5340e-05, -7.4402e-02,  ..., -1.3214e-02,
         -4.6082e-03, -3.8376e-03],
        ...,
        [ 2.5120e-03, -2.0416e-02,  1.9043e-02,  ..., -5.8258e-02,
         -2.3956e-03, -7.9727e-03],
        [ 1.2436e-02, -1.1040e-02,  7.3013e-03,  ...,  3.9825e-03,
         -7.9163e-02,  8.4457e-03],
        [ 2.3079e-03, -1.8749e-03, -3.4046e-04,  ...,  9.2087e-03,
          2.4433e-03, -6.5735e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.2712e-02, -7.6866e-03,  1.1955e-02,  ..., -2.4948e-03,
          1.4259e-02,  2.0905e-02],
        [-9.7656e-04, -1.0114e-01, -1.7033e-03,  ..., -1.5991e-02,
         -7.1983e-03, -7.2861e-04],
        [-6.0654e-03, -4.5128e-03, -9.3994e-02,  ..., -3.7460e-03,
          1.2573e-02, -1.0490e-05],
        ...,
        [ 5.5580e-03, -1.4069e-02,  2.2003e-02,  ..., -9.3079e-02,
          1.7181e-02,  8.5907e-03],
        [-7.2784e-03,  5.5618e-03,  1.0048e-02,  ..., -2.6550e-03,
         -1.1401e-01,  7.0114e-03],
        [ 2.3823e-03, -3.7079e-03,  8.0776e-04,  ...,  1.8005e-03,
          9.2545e-03, -9.5825e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:21:16 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 00:21:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1014,  0.1068, -0.0570,  ...,  0.0014,  0.0641,  0.9639],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7681, -2.2148, -0.4692,  ...,  0.3748,  1.0645, -0.3362],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0709,  0.7710, -0.5400,  ..., -0.2537,  1.0010,  4.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1074, -5.6367, -1.3105,  ...,  0.3481,  2.3652, -2.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:21:16 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:21:16 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 00:22:17 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 00:23:22 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 00:24:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0031, -0.0064, -0.0034,  ...,  0.0017, -0.0020, -0.0090],
        [-0.0006, -0.0052,  0.0037,  ..., -0.0044,  0.0062, -0.0086],
        [-0.0059, -0.0008, -0.0012,  ...,  0.0018,  0.0002, -0.0045],
        ...,
        [ 0.0041, -0.0019,  0.0007,  ...,  0.0042,  0.0046, -0.0033],
        [ 0.0053,  0.0002,  0.0041,  ..., -0.0019,  0.0014, -0.0023],
        [-0.0008, -0.0012, -0.0009,  ...,  0.0017,  0.0039,  0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0495,  0.0108, -0.0065,  ...,  0.0010,  0.0015, -0.0152],
        [ 0.0258, -0.0722,  0.0148,  ..., -0.0081, -0.0039, -0.0055],
        [-0.0061, -0.0178, -0.0565,  ...,  0.0117,  0.0117,  0.0083],
        ...,
        [ 0.0094, -0.0103,  0.0088,  ..., -0.0616, -0.0063, -0.0031],
        [ 0.0166,  0.0105,  0.0084,  ...,  0.0011, -0.0418, -0.0061],
        [-0.0208, -0.0017, -0.0034,  ...,  0.0029,  0.0098, -0.0445]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0983,  0.0244,  0.0003,  ...,  0.0050, -0.0233, -0.0092],
        [ 0.0172, -0.0817, -0.0011,  ..., -0.0034, -0.0021,  0.0076],
        [ 0.0009, -0.0190, -0.1024,  ...,  0.0054,  0.0166,  0.0054],
        ...,
        [-0.0030, -0.0037, -0.0123,  ..., -0.0959, -0.0026,  0.0091],
        [ 0.0026, -0.0102, -0.0011,  ..., -0.0008, -0.0930,  0.0041],
        [-0.0093,  0.0025, -0.0023,  ..., -0.0246, -0.0071, -0.0891]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:24:29 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 00:24:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0743,  0.1165, -0.0779,  ..., -0.1010,  0.2225,  1.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6938, -2.2168, -0.5923,  ...,  0.2717,  0.9609, -0.8765],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9058,  1.8164, -0.7671,  ..., -0.2588,  1.4414,  4.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8379, -4.7148, -1.8770,  ...,  1.4492,  2.9531, -2.0645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:24:29 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:24:29 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 00:25:35 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 00:26:42 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 00:27:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.2377e-04, -2.5463e-03,  1.1358e-03,  ..., -9.7513e-05,
          1.4286e-03, -1.3361e-03],
        [ 1.0910e-03,  2.7618e-03, -1.0118e-03,  ...,  3.1400e-04,
         -3.5453e-04, -1.0166e-03],
        [ 3.6049e-03, -4.8566e-04, -7.3719e-04,  ...,  1.6975e-03,
         -1.1879e-04,  6.3610e-04],
        ...,
        [-1.5616e-04,  1.1177e-03, -1.6899e-03,  ...,  5.9166e-03,
          1.5283e-04,  4.0207e-03],
        [-7.4339e-04, -1.2550e-03,  1.8330e-03,  ..., -7.2527e-04,
          1.7023e-03,  1.6356e-03],
        [-3.2687e-04, -3.3903e-04,  1.7014e-03,  ..., -1.5421e-03,
         -6.0177e-04, -2.8014e-06]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0028, -0.0061,  0.0096,  ..., -0.0025,  0.0057, -0.0110],
        [ 0.0010, -0.0258,  0.0078,  ...,  0.0133,  0.0046,  0.0026],
        [ 0.0029,  0.0018, -0.0286,  ..., -0.0025,  0.0046, -0.0181],
        ...,
        [ 0.0045, -0.0114, -0.0029,  ..., -0.0052, -0.0033, -0.0060],
        [ 0.0105, -0.0043, -0.0162,  ..., -0.0092, -0.0323,  0.0050],
        [ 0.0125, -0.0076,  0.0118,  ..., -0.0187,  0.0153, -0.0270]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0280,  0.0030,  0.0002,  ..., -0.0003, -0.0091, -0.0044],
        [ 0.0011, -0.0516,  0.0114,  ...,  0.0093,  0.0009,  0.0042],
        [-0.0078,  0.0051, -0.0517,  ..., -0.0026,  0.0114,  0.0005],
        ...,
        [ 0.0101, -0.0040, -0.0038,  ..., -0.0446, -0.0186,  0.0013],
        [-0.0014, -0.0069, -0.0070,  ...,  0.0071, -0.0591,  0.0172],
        [ 0.0184, -0.0057,  0.0012,  ..., -0.0020,  0.0111, -0.0407]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:27:49 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 00:27:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0254,  0.2998, -0.2322,  ..., -0.1029,  0.3916,  1.7158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4758, -2.4004, -0.5474,  ...,  0.1472,  0.9761, -0.9092],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8892,  1.9150, -1.4668,  ..., -0.3655,  1.6758,  5.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.9492, -4.8828, -1.8369,  ...,  1.0234,  3.4961, -2.8184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:27:49 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:27:49 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 00:28:58 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 00:30:08 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 00:31:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0009, -0.0012, -0.0021,  ...,  0.0062, -0.0078,  0.0029],
        [-0.0066,  0.0021, -0.0018,  ..., -0.0003, -0.0081,  0.0040],
        [ 0.0024, -0.0022, -0.0022,  ..., -0.0041,  0.0053,  0.0059],
        ...,
        [-0.0006, -0.0062, -0.0060,  ..., -0.0017, -0.0033,  0.0022],
        [-0.0013,  0.0033,  0.0079,  ..., -0.0042,  0.0070, -0.0090],
        [-0.0074, -0.0049, -0.0098,  ..., -0.0028, -0.0024,  0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0054,  0.0031, -0.0107,  ...,  0.0035, -0.0071, -0.0052],
        [ 0.0207, -0.0019, -0.0038,  ..., -0.0003,  0.0212,  0.0029],
        [-0.0138, -0.0007, -0.0139,  ..., -0.0054, -0.0110,  0.0085],
        ...,
        [ 0.0109, -0.0071, -0.0089,  ..., -0.0055, -0.0018,  0.0041],
        [-0.0021, -0.0052, -0.0110,  ..., -0.0099, -0.0067, -0.0271],
        [ 0.0001,  0.0041, -0.0117,  ..., -0.0006, -0.0030, -0.0238]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0226,  0.0069, -0.0095,  ...,  0.0198,  0.0090, -0.0146],
        [ 0.0029, -0.0161,  0.0068,  ...,  0.0031,  0.0071, -0.0070],
        [-0.0041, -0.0082, -0.0344,  ...,  0.0122,  0.0067, -0.0058],
        ...,
        [ 0.0026, -0.0030,  0.0033,  ..., -0.0209, -0.0151,  0.0043],
        [-0.0035,  0.0128,  0.0138,  ...,  0.0041, -0.0247, -0.0370],
        [-0.0049, -0.0043, -0.0019,  ...,  0.0016,  0.0020, -0.0519]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:31:20 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 00:31:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3418,  0.6787, -0.3008,  ..., -0.1131,  0.5493,  1.8291],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7109, -1.8301, -0.7236,  ...,  0.5425,  1.1387, -0.8247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8237,  2.4590, -1.5332,  ..., -0.4827,  2.1406,  5.0469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.8848, -4.4531, -1.7949,  ...,  0.3906,  3.7148, -3.2461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:31:20 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:31:20 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 00:32:37 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 00:33:52 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 00:35:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.4145e-02, -5.9776e-03,  2.5215e-03,  ..., -2.9202e-03,
          1.7147e-03, -1.7643e-05],
        [-4.6997e-03,  9.6283e-03,  1.4658e-03,  ...,  7.0229e-03,
         -3.7861e-03,  7.1526e-05],
        [ 2.0754e-04, -3.3379e-03,  1.4542e-02,  ...,  3.7174e-03,
          1.6479e-03, -8.7357e-04],
        ...,
        [-1.7891e-03,  4.2419e-03,  5.0812e-03,  ...,  1.2428e-02,
         -1.3762e-03,  2.7120e-05],
        [ 4.7493e-04, -5.8174e-03, -1.9760e-03,  ..., -5.7745e-04,
          1.4503e-02,  9.9373e-04],
        [-7.6294e-04,  2.3823e-03, -2.0003e-04,  ..., -7.6628e-04,
          3.7937e-03,  1.7670e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0158, -0.0040, -0.0092,  ..., -0.0035, -0.0053,  0.0070],
        [ 0.0119, -0.0070, -0.0063,  ...,  0.0258,  0.0032, -0.0124],
        [ 0.0014, -0.0120, -0.0064,  ..., -0.0069,  0.0083,  0.0006],
        ...,
        [ 0.0015,  0.0142, -0.0024,  ..., -0.0131,  0.0072,  0.0194],
        [ 0.0033, -0.0085,  0.0269,  ..., -0.0062, -0.0088,  0.0106],
        [ 0.0006,  0.0104,  0.0188,  ...,  0.0166, -0.0023,  0.0118]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0312, -0.0036,  0.0107,  ..., -0.0030, -0.0125, -0.0086],
        [ 0.0139, -0.0587,  0.0115,  ...,  0.0159,  0.0081,  0.0195],
        [-0.0111, -0.0090, -0.0537,  ..., -0.0106,  0.0158, -0.0088],
        ...,
        [ 0.0012,  0.0141, -0.0080,  ..., -0.0283,  0.0145,  0.0013],
        [ 0.0151, -0.0031, -0.0036,  ...,  0.0123, -0.0437, -0.0148],
        [ 0.0021, -0.0065, -0.0022,  ..., -0.0021, -0.0063, -0.0268]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:35:09 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 00:35:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3296,  0.6816, -0.5405,  ..., -0.1284,  0.6270,  1.8711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7393, -1.7754, -0.6792,  ...,  0.3789,  1.3193, -1.1074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5234,  2.7031, -1.3828,  ..., -0.9175,  3.2852,  4.8711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.8477, -3.4941, -1.6709,  ...,  0.1494,  4.1445, -3.2441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:35:09 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:35:09 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 00:36:28 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 00:37:50 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 00:39:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.0346e-03,  7.7724e-05, -4.1223e-04,  ...,  5.0879e-04,
          7.5221e-05,  1.8609e-04],
        [-2.8276e-04, -2.2011e-03, -2.0778e-04,  ...,  3.3236e-04,
         -1.0910e-03,  7.2300e-05],
        [-6.3992e-04,  3.9768e-04, -2.7351e-03,  ..., -9.8228e-04,
         -7.1585e-05, -1.3018e-04],
        ...,
        [ 2.7871e-04,  7.3433e-04, -2.3580e-04,  ..., -2.9354e-03,
         -1.4246e-05,  1.9360e-04],
        [-3.3474e-04,  7.0190e-04,  1.3816e-04,  ..., -4.6563e-04,
         -1.8435e-03, -2.9683e-04],
        [ 5.9843e-05,  4.9591e-04,  4.4870e-04,  ..., -6.6638e-05,
          3.2306e-04, -3.0518e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0465,  0.0192, -0.0034,  ...,  0.0178, -0.0071,  0.0063],
        [-0.0194, -0.0326,  0.0068,  ..., -0.0106, -0.0018,  0.0105],
        [-0.0100, -0.0071, -0.0460,  ..., -0.0084,  0.0013, -0.0112],
        ...,
        [ 0.0065,  0.0077, -0.0179,  ..., -0.0228, -0.0037,  0.0068],
        [ 0.0118, -0.0081,  0.0087,  ..., -0.0048, -0.0412,  0.0107],
        [-0.0060,  0.0008, -0.0036,  ..., -0.0173, -0.0045, -0.0390]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0608,  0.0284,  0.0026,  ...,  0.0114, -0.0115, -0.0237],
        [-0.0302, -0.0568,  0.0132,  ...,  0.0255, -0.0083,  0.0077],
        [-0.0073,  0.0042, -0.0811,  ..., -0.0011,  0.0026,  0.0064],
        ...,
        [ 0.0234,  0.0118,  0.0014,  ..., -0.0509, -0.0238,  0.0101],
        [-0.0016,  0.0116,  0.0194,  ..., -0.0066, -0.0671, -0.0093],
        [-0.0091, -0.0067,  0.0033,  ..., -0.0262,  0.0007, -0.0695]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:39:13 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 00:39:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3069,  0.8555, -0.5596,  ..., -0.1660,  0.7827,  1.7939],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.0645, -1.5596, -0.6509,  ...,  0.1431,  1.3555, -1.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3357,  2.7832, -2.3262,  ..., -0.7451,  2.4062,  4.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.3242, -3.4062, -2.0898,  ...,  0.3525,  4.1875, -3.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:39:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:39:13 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 00:40:32 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 00:41:53 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 00:43:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1566e-02, -4.1962e-04,  1.9970e-03,  ...,  1.8764e-04,
         -1.5354e-04,  1.2553e-04],
        [ 9.4652e-04,  1.3474e-02,  1.2589e-03,  ...,  5.4207e-03,
         -6.1750e-05,  1.4248e-03],
        [ 2.3098e-03,  2.7866e-03,  1.8433e-02,  ...,  5.6386e-05,
          1.4868e-03,  3.3784e-04],
        ...,
        [-2.5234e-03, -2.5597e-03,  9.1314e-04,  ...,  1.1627e-02,
          7.6866e-04, -1.9493e-03],
        [ 1.3752e-03,  1.9302e-03,  1.0405e-03,  ...,  2.7847e-03,
          1.0994e-02, -6.3121e-05],
        [-2.4681e-03, -5.3167e-05,  1.6031e-03,  ...,  2.2678e-03,
          1.6651e-03,  1.2177e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.3842e-03, -5.7220e-05,  2.4147e-03,  ...,  3.7460e-03,
         -8.1406e-03, -1.2062e-02],
        [ 1.7120e-02,  6.2256e-03, -4.1199e-03,  ...,  4.9782e-03,
         -3.0441e-03, -1.6846e-02],
        [ 1.1269e-02, -2.3056e-02,  1.3771e-02,  ..., -1.2634e-02,
          1.2543e-02, -1.1301e-03],
        ...,
        [-5.0354e-03,  3.6316e-03, -4.1656e-03,  ..., -2.8336e-02,
         -6.0654e-04, -2.1027e-02],
        [-1.2245e-02, -1.7090e-02, -1.2789e-03,  ..., -7.4387e-03,
          9.0027e-03,  8.9493e-03],
        [ 5.8212e-03,  1.3161e-03,  1.0996e-03,  ..., -1.3275e-02,
         -4.0894e-03, -4.5227e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0531,  0.0041,  0.0066,  ..., -0.0091,  0.0033,  0.0163],
        [ 0.0153, -0.0191, -0.0023,  ...,  0.0035,  0.0087, -0.0389],
        [ 0.0168,  0.0059, -0.0294,  ..., -0.0146,  0.0021, -0.0121],
        ...,
        [-0.0205,  0.0075, -0.0103,  ..., -0.0225, -0.0010, -0.0013],
        [-0.0175, -0.0135,  0.0165,  ...,  0.0017, -0.0350, -0.0109],
        [-0.0220,  0.0063, -0.0004,  ..., -0.0005,  0.0054, -0.0543]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:43:16 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 00:43:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1879,  0.9355, -0.5308,  ..., -0.3264,  1.1689,  1.7080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9907, -1.1221, -0.6123,  ...,  0.0416,  1.4375, -1.1592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5254,  3.4609, -2.0547,  ..., -0.5796,  2.1602,  4.6719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.0020, -3.9023, -2.1133,  ...,  0.6509,  4.0820, -3.0273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:43:16 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:43:16 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 00:44:40 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 00:46:04 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 00:47:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0094, -0.0010, -0.0003,  ...,  0.0012,  0.0008, -0.0005],
        [-0.0005,  0.0100, -0.0007,  ..., -0.0013, -0.0004, -0.0013],
        [ 0.0008,  0.0009,  0.0119,  ...,  0.0009, -0.0006,  0.0003],
        ...,
        [-0.0034,  0.0009,  0.0040,  ...,  0.0119,  0.0020,  0.0011],
        [ 0.0017,  0.0021, -0.0027,  ...,  0.0024,  0.0119, -0.0024],
        [-0.0015, -0.0018, -0.0006,  ..., -0.0025, -0.0004,  0.0133]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0148,  0.0101,  0.0075,  ..., -0.0162,  0.0004,  0.0060],
        [-0.0057,  0.0059,  0.0104,  ..., -0.0020,  0.0072,  0.0163],
        [-0.0103, -0.0065,  0.0206,  ...,  0.0018, -0.0281, -0.0052],
        ...,
        [-0.0199, -0.0080,  0.0109,  ...,  0.0072, -0.0030, -0.0076],
        [-0.0026, -0.0228,  0.0053,  ...,  0.0376,  0.0005, -0.0074],
        [ 0.0037,  0.0110,  0.0026,  ...,  0.0002, -0.0068,  0.0299]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0023, -0.0110,  0.0008,  ..., -0.0331,  0.0126, -0.0094],
        [ 0.0195, -0.0046,  0.0152,  ...,  0.0035, -0.0135,  0.0267],
        [ 0.0037, -0.0105,  0.0145,  ...,  0.0089, -0.0138, -0.0098],
        ...,
        [-0.0120, -0.0104,  0.0132,  ...,  0.0083, -0.0120, -0.0082],
        [ 0.0242, -0.0111,  0.0031,  ...,  0.0323,  0.0055, -0.0020],
        [-0.0071,  0.0068, -0.0183,  ...,  0.0134, -0.0190,  0.0081]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:47:33 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 00:47:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1343,  0.9111, -0.8394,  ..., -0.2864,  0.7954,  1.5605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1191, -1.0430, -0.7417,  ...,  0.0771,  1.3623, -1.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3579,  4.9414, -2.3535,  ..., -0.7451,  2.8867,  5.0820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4766, -3.2969, -1.6436,  ...,  0.0171,  4.1328, -3.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:47:33 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:47:33 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 00:48:59 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 00:50:26 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 00:51:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3762e-03, -4.8757e-04,  4.6158e-03,  ...,  1.5271e-04,
          8.9788e-04,  2.5201e-04],
        [ 6.6805e-04, -7.1526e-04, -7.5054e-04,  ...,  4.1842e-04,
         -9.0170e-04, -4.9543e-04],
        [-1.4429e-03,  1.0675e-04,  1.6050e-03,  ...,  3.5501e-04,
          2.4486e-04, -1.0548e-03],
        ...,
        [-1.9512e-03,  4.9543e-04,  2.2736e-03,  ...,  9.0408e-04,
          1.9531e-03,  1.4410e-03],
        [ 1.4992e-03, -4.8041e-05, -2.6703e-05,  ..., -1.4229e-03,
         -6.0844e-04, -4.2367e-04],
        [-8.8120e-04,  8.1360e-05,  5.1804e-03,  ...,  1.5583e-03,
          2.0142e-03,  1.8749e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0093,  0.0101,  0.0120,  ..., -0.0060,  0.0029,  0.0121],
        [ 0.0025, -0.0258,  0.0165,  ...,  0.0099,  0.0288, -0.0043],
        [-0.0139, -0.0074, -0.0200,  ...,  0.0181,  0.0057,  0.0105],
        ...,
        [-0.0015, -0.0033,  0.0082,  ..., -0.0085, -0.0037,  0.0062],
        [ 0.0041, -0.0003,  0.0120,  ...,  0.0142,  0.0029,  0.0230],
        [-0.0098,  0.0133, -0.0049,  ...,  0.0169, -0.0026, -0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.7248e-03,  1.3458e-02,  7.3242e-03,  ...,  8.4076e-03,
          1.6113e-02,  1.2293e-03],
        [ 6.0806e-03, -5.4016e-03, -5.5313e-05,  ...,  1.8112e-02,
          4.1962e-03, -5.4321e-03],
        [ 1.8814e-02, -6.9008e-03, -6.3324e-03,  ...,  2.0859e-02,
          3.2349e-03,  1.3031e-02],
        ...,
        [-9.6588e-03,  1.2100e-02, -9.1705e-03,  ..., -4.6173e-02,
          5.0430e-03, -1.6279e-03],
        [-5.3692e-04,  1.2695e-02, -1.5305e-02,  ..., -1.6665e-04,
         -2.5009e-02,  9.9411e-03],
        [-3.8223e-03,  3.6812e-03, -1.1208e-02,  ...,  1.4374e-02,
         -1.4908e-02, -8.4991e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:51:56 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 00:51:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2094,  1.0352, -0.7017,  ..., -0.2732,  0.6162,  1.3721],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9824, -1.1211, -0.7217,  ...,  0.0978,  1.2051, -0.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8140,  5.1953, -3.5312,  ..., -1.0088,  2.6152,  4.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.3047, -2.6035, -3.5605,  ..., -0.9946,  4.2422, -5.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:51:56 root INFO     [order_1_approx] starting weight calculation for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:51:56 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 00:53:20 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 00:54:48 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 00:56:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.6975e-03,  1.7395e-03,  1.0881e-03,  ..., -5.3101e-03,
         -2.1923e-04, -1.6680e-03],
        [ 1.1177e-03,  9.2392e-03,  9.6560e-04,  ...,  5.0974e-04,
          2.3785e-03,  3.8280e-03],
        [ 3.8643e-03,  2.4056e-04,  7.5836e-03,  ..., -2.3899e-03,
         -4.4518e-03, -2.5787e-03],
        ...,
        [ 2.7597e-05, -1.6356e-03, -5.8174e-04,  ...,  1.1269e-02,
         -5.7364e-04,  1.4114e-04],
        [-1.2665e-03, -2.0771e-03,  6.7177e-03,  ...,  2.0428e-03,
          1.2627e-02, -5.6934e-04],
        [ 3.8109e-03,  6.7406e-03, -1.9312e-03,  ..., -3.5152e-03,
          1.0223e-03,  1.4725e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 2.3041e-03, -5.0354e-03, -6.2943e-05,  ...,  8.6441e-03,
          1.0384e-02, -8.5831e-03],
        [ 7.0190e-03, -7.0858e-04, -1.2436e-02,  ..., -1.3634e-02,
         -5.8823e-03,  9.8190e-03],
        [-1.0384e-02, -1.6678e-02, -3.6278e-03,  ..., -1.1658e-02,
         -2.6054e-03,  3.9444e-03],
        ...,
        [-1.5823e-02, -6.5346e-03,  1.3065e-03,  ...,  8.6517e-03,
         -4.1275e-03, -7.4463e-03],
        [ 7.1144e-03,  8.8196e-03,  2.8725e-03,  ..., -1.2756e-02,
          1.8826e-03, -8.8348e-03],
        [ 6.2466e-05,  2.0050e-02,  3.0918e-03,  ..., -8.9111e-03,
         -5.6000e-03,  1.8707e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0058, -0.0222, -0.0088,  ..., -0.0120,  0.0092, -0.0189],
        [ 0.0109, -0.0079,  0.0156,  ...,  0.0099,  0.0320, -0.0038],
        [ 0.0045,  0.0030,  0.0156,  ...,  0.0127, -0.0052,  0.0161],
        ...,
        [-0.0364,  0.0220, -0.0019,  ...,  0.0352,  0.0049,  0.0016],
        [ 0.0325,  0.0072, -0.0030,  ..., -0.0227,  0.0279,  0.0072],
        [-0.0176,  0.0033,  0.0339,  ...,  0.0021,  0.0051,  0.0383]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:56:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a bed is bunk
A more specific term for a painting is watercolor
A more specific term for a trousers is jeans
A more specific term for a weapon is gun
A more specific term for a collar is choker
A more specific term for a brush is toothbrush
A more specific term for a citrus is lemon
A more specific term for a weekday is
2024-06-30 00:56:13 root INFO     total operator prediction time: 35196.907620191574 seconds
2024-06-30 00:56:13 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-06-30 00:56:15 root INFO     building operator over+adj_reg
2024-06-30 00:56:15 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 00:56:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0842,  0.3928, -0.3394,  ...,  0.4448, -0.0179, -0.2937],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1935, -0.1431,  0.1320,  ...,  0.2112, -0.3462, -0.5879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.0356, 0.4966, 0.3552,  ..., 0.6753, 0.1202, 0.0420], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5986,  0.1439,  0.2334,  ...,  0.2068, -0.3828, -0.0842],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:56:15 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 00:56:15 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 00:56:39 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 00:57:02 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 00:57:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.4109e-03, -5.9652e-04, -2.2840e-04,  ...,  4.1056e-04,
          1.2398e-05, -3.1209e-04],
        [ 1.9860e-04, -2.3308e-03,  2.4855e-05,  ..., -5.8174e-04,
         -7.1430e-04,  6.0606e-04],
        [-1.6630e-05,  7.1347e-05, -2.7580e-03,  ..., -3.8099e-04,
         -1.8263e-04,  2.1458e-05],
        ...,
        [-9.6035e-04, -3.0923e-04,  2.2697e-04,  ..., -2.4910e-03,
         -2.6298e-04, -7.4565e-05],
        [ 3.7670e-04,  1.0431e-05, -2.9159e-04,  ..., -3.0351e-04,
         -2.2755e-03,  1.8346e-04],
        [-4.7517e-04,  3.2783e-05, -9.4533e-05,  ..., -4.5896e-05,
         -5.6314e-04, -2.3766e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0341, -0.0072, -0.0046,  ...,  0.0016,  0.0029,  0.0052],
        [-0.0026, -0.0357, -0.0039,  ..., -0.0048,  0.0022,  0.0017],
        [ 0.0058, -0.0075, -0.0427,  ...,  0.0020, -0.0028,  0.0108],
        ...,
        [ 0.0005,  0.0087, -0.0043,  ..., -0.0466,  0.0035, -0.0010],
        [-0.0022,  0.0005,  0.0009,  ...,  0.0087, -0.0407,  0.0074],
        [-0.0018, -0.0009, -0.0042,  ...,  0.0060,  0.0093, -0.0246]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0349, -0.0010,  0.0024,  ...,  0.0003,  0.0007, -0.0003],
        [ 0.0025, -0.0352, -0.0041,  ...,  0.0007,  0.0056, -0.0010],
        [-0.0064, -0.0023, -0.0313,  ..., -0.0014, -0.0035,  0.0014],
        ...,
        [-0.0013,  0.0008,  0.0018,  ..., -0.0330, -0.0009, -0.0017],
        [-0.0010,  0.0011,  0.0020,  ..., -0.0022, -0.0309,  0.0060],
        [-0.0009, -0.0024, -0.0025,  ...,  0.0050,  0.0016, -0.0302]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:57:27 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 00:57:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6104,  0.5903,  0.0265,  ...,  0.6621,  0.0043, -0.2494],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7329, -0.0889,  0.3772,  ..., -0.1025, -0.4924, -0.3618],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0400,  0.7051,  0.2803,  ...,  0.4470,  0.0387, -0.0283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5625,  0.0680,  0.2058,  ..., -0.6631, -0.3594,  0.1333],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:57:27 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 00:57:27 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 00:57:51 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 00:58:15 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 00:58:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3651e-03,  6.3086e-04,  2.8133e-04,  ..., -1.1511e-03,
         -1.3647e-03,  1.6403e-04],
        [ 8.7833e-04, -4.8370e-03, -4.9782e-04,  ...,  1.0509e-03,
         -1.5736e-04, -1.2407e-03],
        [ 7.1943e-05,  1.0080e-03, -4.4479e-03,  ...,  8.7547e-04,
         -1.7500e-04,  6.5470e-04],
        ...,
        [ 4.3678e-04, -6.4659e-04, -9.3174e-04,  ..., -3.2997e-03,
         -1.2732e-03, -4.9877e-04],
        [ 5.0020e-04,  3.6454e-04,  3.9649e-04,  ..., -7.1824e-05,
         -3.8071e-03,  4.1795e-04],
        [ 1.8573e-04, -1.8895e-04, -3.9101e-05,  ...,  4.3213e-05,
          2.8372e-04, -3.6888e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0682,  0.0128,  0.0060,  ...,  0.0007, -0.0003, -0.0033],
        [ 0.0102, -0.0629, -0.0092,  ...,  0.0048,  0.0009,  0.0011],
        [-0.0079, -0.0135, -0.0588,  ..., -0.0014,  0.0038,  0.0008],
        ...,
        [ 0.0041,  0.0104,  0.0002,  ..., -0.0671, -0.0033, -0.0041],
        [ 0.0015, -0.0153,  0.0077,  ...,  0.0022, -0.0597,  0.0026],
        [-0.0051, -0.0025,  0.0008,  ...,  0.0016, -0.0007, -0.0685]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0690,  0.0015, -0.0059,  ...,  0.0005,  0.0065,  0.0008],
        [-0.0006, -0.0798, -0.0084,  ...,  0.0064,  0.0027,  0.0037],
        [ 0.0059,  0.0024, -0.0592,  ...,  0.0018, -0.0054, -0.0068],
        ...,
        [ 0.0019,  0.0108,  0.0037,  ..., -0.0758, -0.0071, -0.0042],
        [-0.0059,  0.0003,  0.0026,  ...,  0.0050, -0.0727,  0.0016],
        [ 0.0016,  0.0005,  0.0012,  ..., -0.0036,  0.0073, -0.0768]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:58:42 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 00:58:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.0207, 0.6284, 0.4451,  ..., 0.8267, 0.1443, 0.0257], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9463,  0.2107,  0.3584,  ...,  0.3103, -0.5781, -0.1544],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3557,  0.8096,  0.3467,  ...,  0.7573,  0.3008, -0.0614],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8018,  0.3118,  0.0493,  ..., -0.6431, -0.4517,  0.9644],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:58:42 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 00:58:42 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 00:59:07 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 00:59:32 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 00:59:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.5161e-03, -2.4486e-04, -2.0504e-03,  ...,  5.3120e-04,
          4.4513e-04, -1.4896e-03],
        [ 5.0783e-04, -6.7177e-03,  9.7466e-04,  ...,  8.9407e-04,
         -1.3771e-03,  6.0034e-04],
        [-9.0504e-04, -6.7759e-04, -4.3144e-03,  ...,  9.3555e-04,
         -5.3930e-04, -5.5313e-04],
        ...,
        [-7.5340e-04,  3.3021e-05, -7.0477e-04,  ..., -6.0120e-03,
          5.7459e-04, -1.3065e-03],
        [-1.1057e-04, -8.6546e-05, -1.1454e-03,  ..., -3.9935e-04,
         -5.6343e-03, -1.5583e-03],
        [ 1.4563e-03, -1.3390e-03,  1.3790e-03,  ..., -4.2748e-04,
          5.5313e-04, -6.1836e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0328, -0.0009, -0.0017,  ...,  0.0045,  0.0066, -0.0010],
        [-0.0089, -0.0436, -0.0025,  ..., -0.0125, -0.0037, -0.0012],
        [ 0.0076, -0.0060, -0.0322,  ...,  0.0019, -0.0081,  0.0026],
        ...,
        [-0.0002, -0.0084, -0.0076,  ..., -0.0393,  0.0008,  0.0061],
        [ 0.0006, -0.0084, -0.0006,  ...,  0.0012, -0.0382, -0.0029],
        [-0.0125, -0.0052, -0.0044,  ...,  0.0034,  0.0005, -0.0354]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0388,  0.0028, -0.0009,  ...,  0.0013,  0.0009, -0.0029],
        [ 0.0037, -0.0302,  0.0043,  ..., -0.0031, -0.0003,  0.0057],
        [ 0.0041,  0.0014, -0.0334,  ..., -0.0075,  0.0015,  0.0042],
        ...,
        [-0.0010, -0.0015, -0.0081,  ..., -0.0309,  0.0002, -0.0022],
        [-0.0049,  0.0055,  0.0083,  ...,  0.0020, -0.0232,  0.0010],
        [-0.0042,  0.0045,  0.0061,  ..., -0.0002,  0.0068, -0.0286]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 00:59:57 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 00:59:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0821,  0.9004,  0.3516,  ...,  0.5527,  0.0253, -0.0806],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8823,  0.0862,  0.3123,  ..., -0.9521, -0.5454,  0.1766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4617,  0.8682,  0.7056,  ...,  0.8325,  0.7793, -0.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6499,  0.9590,  0.4265,  ..., -1.0635, -0.0603,  0.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 00:59:57 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 00:59:57 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 01:00:22 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 01:00:49 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 01:01:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1282e-03,  2.3670e-03,  1.1473e-03,  ...,  2.0337e-04,
          2.0180e-03,  4.4823e-04],
        [ 1.2674e-03, -3.4485e-03,  8.8215e-05,  ..., -1.5831e-03,
          2.7180e-04,  1.2684e-03],
        [ 4.0197e-04, -4.4775e-04, -2.5387e-03,  ...,  1.3275e-03,
          8.7321e-05,  1.5488e-03],
        ...,
        [ 6.8855e-04, -2.7218e-03, -3.8600e-04,  ..., -2.6703e-03,
          8.4114e-04, -5.6124e-04],
        [ 7.1812e-04,  7.8082e-05, -4.1938e-04,  ..., -7.6818e-04,
         -1.6451e-03,  1.1921e-03],
        [ 5.5170e-04, -1.5364e-03,  1.4186e-04,  ...,  4.5276e-04,
         -7.1049e-04, -3.7251e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.5868e-02,  1.1549e-03,  5.3406e-05,  ..., -1.3256e-03,
          2.8458e-03, -8.0681e-04],
        [ 1.7357e-03, -4.9072e-02, -2.1534e-03,  ..., -7.8583e-03,
          2.0599e-04, -3.3779e-03],
        [-2.3537e-03,  8.1635e-03, -4.7119e-02,  ...,  5.7259e-03,
         -1.8501e-03,  2.4204e-03],
        ...,
        [-4.1733e-03,  1.5593e-03, -9.7351e-03,  ..., -5.0507e-02,
          2.9621e-03, -1.0971e-02],
        [-4.6806e-03, -9.1171e-03,  4.5166e-03,  ..., -4.9162e-04,
         -4.2511e-02, -2.1210e-03],
        [ 1.2138e-02, -1.5121e-02, -5.3711e-03,  ...,  5.5962e-03,
         -6.3133e-04, -4.9194e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0533, -0.0012,  0.0048,  ..., -0.0030,  0.0013,  0.0011],
        [ 0.0043, -0.0333, -0.0027,  ...,  0.0045,  0.0107, -0.0062],
        [-0.0009, -0.0026, -0.0443,  ..., -0.0009, -0.0029,  0.0038],
        ...,
        [-0.0091, -0.0018,  0.0002,  ..., -0.0392,  0.0046, -0.0009],
        [ 0.0005,  0.0009, -0.0034,  ..., -0.0074, -0.0358,  0.0044],
        [-0.0007, -0.0016, -0.0026,  ..., -0.0060, -0.0010, -0.0446]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:01:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 01:01:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3767,  0.8906,  0.3726,  ...,  0.7842,  0.3677, -0.1168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9014,  0.3210,  0.0615,  ..., -0.6831, -0.4731,  1.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5171,  0.8867,  0.8960,  ...,  0.3911,  1.3750, -0.1205],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5957,  0.6260,  0.4941,  ..., -0.6836,  0.1820,  0.5708],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:01:21 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:01:21 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 01:01:54 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 01:02:26 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 01:02:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0006, -0.0006, -0.0017,  ..., -0.0006,  0.0013,  0.0023],
        [-0.0019,  0.0019,  0.0007,  ...,  0.0011, -0.0010,  0.0018],
        [ 0.0012,  0.0005, -0.0002,  ..., -0.0007, -0.0004, -0.0008],
        ...,
        [-0.0006,  0.0013, -0.0010,  ...,  0.0002, -0.0036,  0.0005],
        [-0.0007,  0.0026,  0.0009,  ...,  0.0016,  0.0028, -0.0010],
        [-0.0011, -0.0023, -0.0010,  ...,  0.0006, -0.0011,  0.0020]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.3730e-02,  4.3106e-03, -1.2226e-03,  ..., -4.3511e-05,
          6.2256e-03,  1.8749e-03],
        [ 2.3479e-03, -6.4392e-02,  1.2421e-02,  ..., -6.8092e-03,
          9.2087e-03,  9.8877e-03],
        [-4.2343e-03, -3.6564e-03, -5.5084e-02,  ..., -2.7390e-03,
          2.1210e-03,  9.5215e-03],
        ...,
        [-9.0561e-03, -1.1566e-02, -1.1734e-02,  ..., -6.0944e-02,
         -3.8528e-04, -3.5915e-03],
        [ 6.8550e-03, -1.4439e-03, -3.7842e-03,  ...,  3.5439e-03,
         -5.3223e-02,  8.7690e-04],
        [-2.5692e-03,  7.0305e-03,  6.6032e-03,  ..., -6.9904e-04,
          1.5202e-03, -6.6895e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0920, -0.0076,  0.0059,  ..., -0.0008, -0.0055, -0.0015],
        [-0.0086, -0.0995,  0.0043,  ..., -0.0054, -0.0030,  0.0013],
        [-0.0023,  0.0019, -0.0916,  ...,  0.0008,  0.0082,  0.0061],
        ...,
        [-0.0045,  0.0021, -0.0015,  ..., -0.0847,  0.0081,  0.0035],
        [-0.0008, -0.0056, -0.0009,  ...,  0.0053, -0.0945,  0.0077],
        [ 0.0054,  0.0042,  0.0093,  ..., -0.0076, -0.0062, -0.0995]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:03:02 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 01:03:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4570,  0.8735,  0.6616,  ...,  0.8022,  0.7495, -0.0598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7090,  1.0605,  0.4377,  ..., -1.1035, -0.0785,  0.8145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5205,  0.8438,  0.8184,  ...,  0.7510,  1.1426, -0.5044],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1553,  0.3865,  0.4246,  ..., -0.1240,  0.1927,  0.0332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:03:02 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:03:02 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 01:03:37 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 01:04:12 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 01:04:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1885e-03, -1.2436e-03,  2.3651e-03,  ..., -2.7204e-04,
          2.6417e-03, -3.0270e-03],
        [ 3.3627e-03, -7.5874e-03,  2.7084e-03,  ...,  5.6887e-04,
          2.5902e-03, -1.0691e-03],
        [-1.0109e-03,  1.3647e-03, -3.9520e-03,  ..., -5.5790e-04,
          1.1864e-03, -1.6508e-03],
        ...,
        [ 5.2643e-04,  1.3649e-04,  2.0576e-04,  ..., -2.8782e-03,
         -2.0390e-03,  4.4746e-03],
        [ 3.6716e-03, -1.8330e-03,  9.1457e-04,  ..., -9.8038e-04,
         -1.7223e-03,  5.9795e-04],
        [ 1.1349e-03, -9.6512e-04,  2.5635e-03,  ..., -9.2149e-05,
         -1.6117e-03,  8.7738e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0825,  0.0151,  0.0005,  ..., -0.0004, -0.0048, -0.0089],
        [ 0.0137, -0.1052,  0.0104,  ...,  0.0231, -0.0078,  0.0027],
        [ 0.0116,  0.0160, -0.0804,  ...,  0.0052,  0.0020, -0.0049],
        ...,
        [ 0.0027,  0.0032,  0.0050,  ..., -0.0946,  0.0030,  0.0032],
        [-0.0086,  0.0056,  0.0155,  ..., -0.0004, -0.1008,  0.0053],
        [-0.0019,  0.0068,  0.0109,  ..., -0.0080,  0.0026, -0.0999]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0964,  0.0008, -0.0017,  ...,  0.0016,  0.0038,  0.0024],
        [ 0.0008, -0.1001, -0.0060,  ...,  0.0022, -0.0058,  0.0016],
        [ 0.0019, -0.0050, -0.0998,  ...,  0.0048,  0.0058, -0.0062],
        ...,
        [ 0.0062, -0.0016,  0.0034,  ..., -0.1000, -0.0001, -0.0039],
        [-0.0039, -0.0029, -0.0019,  ...,  0.0048, -0.1008, -0.0033],
        [-0.0021,  0.0004, -0.0084,  ..., -0.0116,  0.0066, -0.1115]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:04:50 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 01:04:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4866,  0.8789,  0.7847,  ...,  0.3203,  1.2891, -0.1597],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5942,  0.6562,  0.4485,  ..., -0.6626,  0.1768,  0.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6543,  0.4556,  0.7158,  ...,  1.3330,  1.8555, -0.2964],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1133,  0.4487,  0.7998,  ..., -0.0562,  0.3374, -0.3245],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:04:50 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:04:50 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 01:05:28 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 01:06:07 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 01:06:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.9210e-03,  9.3603e-04, -4.9114e-04,  ...,  3.8719e-04,
         -1.4830e-03, -1.1802e-04],
        [ 1.8635e-03, -2.2202e-03,  9.4509e-04,  ...,  1.5545e-03,
          1.8978e-03, -7.3624e-04],
        [ 1.2865e-03,  5.5075e-04, -2.5730e-03,  ..., -1.0328e-03,
         -5.7650e-04, -1.1206e-04],
        ...,
        [ 7.2289e-04,  1.6899e-03,  1.2140e-03,  ..., -2.7065e-03,
          1.0157e-03,  1.9293e-03],
        [ 7.8154e-04,  9.6142e-05, -1.9245e-03,  ..., -1.4949e-04,
         -1.8864e-03, -1.3375e-04],
        [ 3.9053e-04, -1.2951e-03,  7.7963e-04,  ..., -7.2670e-04,
          3.0499e-03, -5.1117e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0909, -0.0050, -0.0009,  ..., -0.0097,  0.0108, -0.0085],
        [-0.0062, -0.0739, -0.0013,  ..., -0.0048, -0.0127,  0.0020],
        [ 0.0160, -0.0063, -0.0630,  ..., -0.0059, -0.0112,  0.0009],
        ...,
        [-0.0066,  0.0035,  0.0077,  ..., -0.0774, -0.0045, -0.0018],
        [ 0.0101, -0.0019, -0.0038,  ..., -0.0058, -0.0790,  0.0066],
        [-0.0086,  0.0098,  0.0092,  ...,  0.0144,  0.0109, -0.0706]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0955,  0.0021,  0.0098,  ..., -0.0080, -0.0063, -0.0043],
        [ 0.0036, -0.0837, -0.0081,  ...,  0.0031,  0.0065, -0.0121],
        [ 0.0066,  0.0067, -0.0828,  ...,  0.0042,  0.0006,  0.0063],
        ...,
        [-0.0037, -0.0024,  0.0033,  ..., -0.0891,  0.0089,  0.0031],
        [ 0.0018,  0.0063,  0.0007,  ...,  0.0100, -0.0818, -0.0028],
        [-0.0009, -0.0088,  0.0027,  ..., -0.0011,  0.0007, -0.0778]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:06:48 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 01:06:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4753,  0.7808,  0.6914,  ...,  0.6294,  1.0000, -0.4978],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.1143,  0.3792,  0.3796,  ..., -0.1111,  0.1764,  0.0142],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7432,  0.8716,  1.1387,  ...,  0.7573,  1.6367, -0.7109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0098,  0.2489,  0.4302,  ..., -0.3413,  0.1628,  0.0378],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:06:49 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:06:49 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 01:07:30 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 01:08:13 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 01:08:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8210e-03, -2.1191e-03,  3.3798e-03,  ...,  1.0252e-03,
         -2.0008e-03, -2.6608e-03],
        [ 2.2011e-03, -1.2293e-03, -3.2854e-04,  ..., -3.6449e-03,
          2.5630e-05, -1.1082e-03],
        [-1.4544e-03, -2.3961e-04, -6.2227e-04,  ...,  1.4305e-06,
         -1.6766e-03, -2.8725e-03],
        ...,
        [-1.7691e-03, -1.0490e-03,  7.7724e-04,  ...,  6.8760e-04,
          1.5602e-03,  1.0328e-03],
        [ 1.5268e-03,  7.3624e-04, -1.5507e-03,  ...,  1.1806e-03,
         -3.9978e-03,  3.1509e-03],
        [ 3.7632e-03, -6.6185e-04,  2.0313e-03,  ...,  1.3590e-05,
          1.0490e-04, -6.4087e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0746,  0.0008, -0.0081,  ...,  0.0013, -0.0142, -0.0010],
        [-0.0034, -0.0961,  0.0159,  ...,  0.0026,  0.0148,  0.0175],
        [-0.0067,  0.0065, -0.0634,  ..., -0.0050,  0.0005, -0.0107],
        ...,
        [-0.0009,  0.0073, -0.0029,  ..., -0.0765,  0.0009,  0.0130],
        [ 0.0114,  0.0047,  0.0074,  ..., -0.0046, -0.0643,  0.0066],
        [ 0.0137, -0.0150, -0.0003,  ..., -0.0072,  0.0153, -0.0898]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1031,  0.0065, -0.0057,  ..., -0.0007,  0.0053, -0.0101],
        [ 0.0011, -0.1229,  0.0055,  ..., -0.0083, -0.0058,  0.0115],
        [-0.0047, -0.0004, -0.1180,  ..., -0.0088, -0.0104,  0.0064],
        ...,
        [ 0.0054,  0.0100, -0.0048,  ..., -0.1032, -0.0031,  0.0026],
        [-0.0068,  0.0090, -0.0105,  ..., -0.0017, -0.0949,  0.0036],
        [-0.0114, -0.0021, -0.0099,  ...,  0.0031,  0.0030, -0.1179]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:08:57 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 01:08:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4766,  0.3457,  0.4656,  ...,  0.9258,  1.3506, -0.2527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0029,  0.4026,  0.6255,  ..., -0.0643,  0.2749, -0.3076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0811,  1.0430,  2.1133,  ...,  0.7139,  1.5771, -0.8711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1689,  0.5581,  0.9565,  ...,  0.1958, -0.0256,  0.0243],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:08:57 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:08:57 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 01:09:45 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 01:10:33 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 01:11:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1648e-03,  1.7357e-03, -6.0797e-04,  ...,  4.3488e-04,
         -2.7199e-03, -2.5539e-03],
        [ 9.9945e-04, -4.9114e-04, -3.6240e-03,  ..., -4.0388e-04,
         -2.2411e-03,  3.5286e-03],
        [-9.8991e-04,  2.5806e-03,  2.5425e-03,  ..., -1.9445e-03,
          1.9760e-03,  4.0054e-03],
        ...,
        [-7.6008e-04, -3.6583e-03, -8.7833e-04,  ...,  2.9469e-03,
         -2.2259e-03, -7.8201e-05],
        [-1.9016e-03,  2.5501e-03,  1.0052e-03,  ...,  2.4185e-03,
         -3.4866e-03, -3.2692e-03],
        [ 1.5049e-03,  3.6120e-05,  6.9466e-03,  ..., -1.3781e-03,
          5.0201e-03,  3.7346e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.1248e-02, -7.2289e-04, -2.1553e-03,  ...,  3.7098e-03,
          3.4714e-04,  1.0773e-02],
        [-3.5133e-03, -1.1694e-01, -7.8888e-03,  ...,  8.7662e-03,
         -1.7538e-03, -7.2365e-03],
        [ 8.7738e-05,  7.1983e-03, -1.0333e-01,  ...,  9.9335e-03,
         -7.1945e-03,  3.0708e-03],
        ...,
        [-9.8648e-03,  2.8706e-04,  1.2032e-02,  ..., -1.1145e-01,
         -5.8784e-03,  5.0087e-03],
        [-9.9335e-03,  6.8817e-03,  1.5778e-02,  ...,  1.6584e-03,
         -1.2085e-01, -3.4733e-03],
        [ 4.6082e-03, -7.7858e-03,  3.6106e-03,  ..., -6.5613e-03,
         -1.3931e-02, -9.9731e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6577e-01,  1.3933e-03,  4.1466e-03,  ...,  4.1504e-03,
         -2.2602e-03,  7.6447e-03],
        [-9.1248e-03, -1.5271e-01, -7.7477e-03,  ...,  7.8888e-03,
          6.4659e-03,  5.8250e-03],
        [-2.9564e-03, -3.3684e-03, -1.3953e-01,  ...,  6.7215e-03,
         -2.0351e-03, -9.2545e-03],
        ...,
        [-7.3471e-03,  2.5909e-02,  9.2468e-03,  ..., -1.5942e-01,
          1.0300e-04,  7.3471e-03],
        [-3.3302e-03,  3.1319e-03,  8.3084e-03,  ..., -9.0103e-03,
         -1.5991e-01, -1.3504e-03],
        [-2.7695e-03,  3.3302e-03,  6.8512e-03,  ..., -1.9196e-02,
         -2.1553e-03, -1.4758e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:11:24 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 01:11:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5132,  0.5845,  0.7056,  ...,  0.4980,  1.0811, -0.5459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8291,  0.1919,  0.3018,  ..., -0.2544,  0.1171, -0.0098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6548,  1.5029,  2.1094,  ...,  1.1113,  1.5020, -0.6631],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6113, -0.0117,  0.9360,  ..., -0.0964, -0.0550,  0.3511],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:11:24 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:11:24 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 01:12:08 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 01:12:34 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 01:13:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0080,  0.0017,  0.0005,  ...,  0.0011,  0.0017,  0.0022],
        [ 0.0007,  0.0025,  0.0032,  ...,  0.0006,  0.0020, -0.0003],
        [-0.0001, -0.0009, -0.0065,  ...,  0.0023,  0.0004,  0.0015],
        ...,
        [ 0.0055, -0.0022,  0.0018,  ..., -0.0079, -0.0016, -0.0021],
        [-0.0012, -0.0022,  0.0013,  ...,  0.0022, -0.0039,  0.0028],
        [-0.0014, -0.0014, -0.0023,  ...,  0.0027,  0.0002, -0.0079]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0468e-01,  1.1108e-02,  8.8043e-03,  ...,  9.4070e-03,
         -1.7691e-03, -9.1553e-03],
        [-1.0414e-03, -1.0791e-01, -2.8419e-03,  ...,  7.7705e-03,
         -1.7166e-05,  2.9373e-04],
        [ 7.9956e-03,  7.8278e-03, -9.7412e-02,  ...,  9.7656e-03,
         -1.7731e-02,  9.1076e-04],
        ...,
        [ 7.3662e-03, -6.3782e-03, -5.1003e-03,  ..., -1.0748e-01,
          6.9351e-03, -1.4587e-02],
        [ 7.6332e-03,  7.6675e-03, -1.0536e-02,  ...,  3.2578e-03,
         -9.9121e-02,  6.9008e-03],
        [ 1.7731e-02,  1.3512e-02,  3.6049e-03,  ...,  6.7806e-04,
          1.4915e-02, -1.1334e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1022,  0.0020,  0.0052,  ...,  0.0045, -0.0041, -0.0076],
        [ 0.0130, -0.1027, -0.0043,  ..., -0.0074, -0.0154,  0.0030],
        [-0.0034,  0.0053, -0.1105,  ...,  0.0093, -0.0021,  0.0126],
        ...,
        [ 0.0029, -0.0036,  0.0054,  ..., -0.0962,  0.0029, -0.0056],
        [ 0.0041, -0.0136, -0.0102,  ...,  0.0122, -0.1008, -0.0032],
        [ 0.0050,  0.0005,  0.0036,  ...,  0.0087, -0.0039, -0.1082]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:13:17 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 01:13:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0331,  0.6479,  1.2119,  ...,  0.3909,  0.9463, -0.5620],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9062,  0.4141,  0.6426,  ...,  0.1090, -0.0390,  0.0217],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5098,  1.6748,  1.1738,  ...,  0.9189,  1.4844, -0.0820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9810,  0.1377,  0.6582,  ...,  0.4480,  0.0441,  0.4592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:13:17 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:13:17 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 01:14:09 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 01:14:58 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 01:15:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.1684e-03, -1.5092e-04,  6.6280e-04,  ..., -5.0211e-04,
          1.3933e-03, -1.3685e-03],
        [-2.1763e-03,  3.8548e-03, -1.3232e-05,  ...,  2.9202e-03,
          2.4452e-03,  2.9755e-03],
        [-2.6417e-03,  4.5729e-04,  7.4768e-03,  ..., -2.2602e-03,
          2.1801e-03, -1.5278e-03],
        ...,
        [-1.5173e-03, -8.3447e-05,  4.6120e-03,  ...,  7.8735e-03,
         -3.7079e-03,  4.0550e-03],
        [-2.1172e-03, -3.5310e-04, -2.1195e-04,  ..., -3.6144e-03,
          1.2047e-02,  5.1880e-04],
        [ 1.0681e-03,  2.8572e-03,  6.9714e-04,  ..., -3.7956e-04,
          7.1669e-04,  4.9324e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1705, -0.0040, -0.0079,  ..., -0.0087,  0.0066,  0.0074],
        [ 0.0066, -0.1670, -0.0083,  ...,  0.0019, -0.0118, -0.0082],
        [-0.0061,  0.0005, -0.1677,  ..., -0.0113,  0.0049, -0.0254],
        ...,
        [-0.0218, -0.0151,  0.0016,  ..., -0.1760,  0.0008,  0.0007],
        [-0.0069,  0.0044, -0.0032,  ...,  0.0047, -0.1735,  0.0044],
        [-0.0147,  0.0038, -0.0179,  ..., -0.0036, -0.0038, -0.1672]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.9812e-01,  1.3390e-02,  1.5015e-02,  ..., -1.5732e-02,
         -6.1340e-03, -4.0207e-03],
        [ 8.7404e-04, -2.1838e-01, -1.5686e-02,  ..., -1.5182e-03,
          1.2238e-02,  8.5831e-05],
        [-3.9864e-03,  3.8033e-03, -2.0166e-01,  ...,  4.0817e-03,
          2.5749e-03, -1.3756e-02],
        ...,
        [-2.9945e-03, -2.2736e-03,  8.5831e-05,  ..., -2.2681e-01,
          4.2725e-03, -3.5896e-03],
        [ 2.6016e-03,  2.6989e-03, -1.0193e-02,  ...,  1.3077e-02,
         -2.0886e-01,  1.3695e-03],
        [-3.2616e-04, -1.1017e-02, -2.5768e-03,  ..., -5.5733e-03,
          2.5959e-03, -2.0667e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:15:54 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 01:15:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3826,  0.9346,  1.2100,  ...,  0.6777,  0.9238, -0.4893],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5264, -0.0246,  0.6699,  ..., -0.0808, -0.0527,  0.2385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.3979, 1.2891, 1.3760,  ..., 0.5664, 1.4990, 0.7710], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7803,  0.6699,  1.6152,  ...,  0.0044,  0.8896,  0.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:15:54 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:15:54 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 01:16:41 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 01:17:36 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 01:18:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.8512e-03,  4.1733e-03,  1.4629e-03,  ...,  2.9707e-04,
          2.8133e-05, -4.9515e-03],
        [-5.9271e-04, -8.0338e-03,  3.3712e-04,  ..., -2.5597e-03,
         -4.9667e-03,  2.3556e-03],
        [ 1.3218e-03, -1.9312e-04, -4.3678e-03,  ..., -2.3785e-03,
         -3.2692e-03, -1.5621e-03],
        ...,
        [ 8.5831e-04, -6.6185e-04, -2.0809e-03,  ..., -6.6795e-03,
          3.4666e-04, -3.4618e-04],
        [-8.9645e-04,  2.0008e-03, -2.7943e-03,  ..., -3.6507e-03,
         -6.8893e-03,  1.8930e-03],
        [-7.1526e-05,  3.5992e-03,  2.9240e-03,  ...,  5.9938e-04,
          2.2278e-03, -7.8659e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0831,  0.0074,  0.0135,  ...,  0.0070,  0.0062, -0.0073],
        [-0.0115, -0.0843, -0.0007,  ..., -0.0117, -0.0027,  0.0100],
        [-0.0023, -0.0091, -0.0806,  ...,  0.0032, -0.0039,  0.0090],
        ...,
        [-0.0041,  0.0019,  0.0117,  ..., -0.0721, -0.0042, -0.0095],
        [-0.0062, -0.0008,  0.0048,  ...,  0.0043, -0.0785,  0.0065],
        [-0.0090, -0.0069,  0.0146,  ..., -0.0002,  0.0025, -0.0739]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0820, -0.0041,  0.0115,  ..., -0.0054,  0.0008,  0.0058],
        [ 0.0055, -0.0775, -0.0059,  ...,  0.0011,  0.0113,  0.0025],
        [-0.0023, -0.0003, -0.0933,  ...,  0.0014, -0.0129,  0.0072],
        ...,
        [-0.0030, -0.0109, -0.0078,  ..., -0.0729,  0.0068,  0.0010],
        [-0.0040,  0.0039,  0.0022,  ...,  0.0050, -0.0862,  0.0092],
        [ 0.0045,  0.0011,  0.0037,  ...,  0.0054,  0.0059, -0.0797]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:18:35 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 01:18:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3083,  0.9800,  0.6597,  ...,  0.5093,  0.8896, -0.0789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7354,  0.0654,  0.4456,  ...,  0.2944,  0.0363,  0.3181],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.3665, 1.0039, 0.4727,  ..., 0.9229, 1.3467, 1.1133], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2070,  0.3145,  1.0215,  ...,  0.3008,  1.8672,  1.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:18:36 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:18:36 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 01:19:33 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 01:20:31 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 01:21:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0098,  0.0041, -0.0002,  ...,  0.0013,  0.0020, -0.0028],
        [-0.0103,  0.0096, -0.0060,  ...,  0.0013, -0.0033, -0.0067],
        [-0.0014, -0.0028, -0.0071,  ..., -0.0012, -0.0010, -0.0030],
        ...,
        [-0.0019, -0.0035,  0.0034,  ...,  0.0043, -0.0007,  0.0058],
        [ 0.0070, -0.0033,  0.0055,  ...,  0.0005, -0.0127, -0.0029],
        [ 0.0022,  0.0072,  0.0020,  ..., -0.0029, -0.0057, -0.0078]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1023, -0.0040,  0.0055,  ..., -0.0148,  0.0007,  0.0089],
        [-0.0035, -0.1191, -0.0197,  ...,  0.0153,  0.0004,  0.0174],
        [ 0.0046, -0.0012, -0.0948,  ...,  0.0126, -0.0108, -0.0064],
        ...,
        [-0.0090, -0.0080, -0.0012,  ..., -0.1042, -0.0152,  0.0054],
        [ 0.0124,  0.0035,  0.0062,  ..., -0.0066, -0.1220,  0.0013],
        [ 0.0048,  0.0113, -0.0110,  ..., -0.0138, -0.0025, -0.1043]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1306,  0.0031,  0.0044,  ...,  0.0018,  0.0078,  0.0086],
        [-0.0172, -0.1500, -0.0063,  ...,  0.0045, -0.0012,  0.0198],
        [ 0.0025,  0.0071, -0.1346,  ..., -0.0031, -0.0022, -0.0053],
        ...,
        [-0.0090,  0.0018, -0.0023,  ..., -0.1382, -0.0013,  0.0069],
        [ 0.0162,  0.0187, -0.0017,  ...,  0.0131, -0.1464,  0.0069],
        [-0.0005, -0.0039,  0.0052,  ..., -0.0076,  0.0146, -0.1388]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:21:25 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 01:21:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.1873, 0.6777, 0.6772,  ..., 0.2805, 0.8452, 0.3669], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4912,  0.3782,  0.8755,  ..., -0.0121,  0.5586,  0.3826],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.4482, 0.9326, 0.7549,  ..., 0.3926, 1.4180, 1.6152], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3633, -0.0933,  1.1094,  ..., -0.3823,  0.6973,  0.5918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:21:25 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:21:25 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 01:22:24 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 01:23:22 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 01:24:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0088, -0.0026,  0.0005,  ..., -0.0021, -0.0142, -0.0026],
        [-0.0060,  0.0094, -0.0026,  ..., -0.0041, -0.0019,  0.0029],
        [-0.0035, -0.0016,  0.0113,  ..., -0.0024, -0.0014,  0.0011],
        ...,
        [ 0.0086, -0.0020, -0.0055,  ...,  0.0162, -0.0024,  0.0003],
        [-0.0001, -0.0027,  0.0040,  ...,  0.0008,  0.0121,  0.0041],
        [ 0.0026,  0.0049, -0.0052,  ...,  0.0003,  0.0022,  0.0085]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0254e-01,  1.5686e-02, -2.1696e-05,  ..., -8.2245e-03,
          3.8834e-03, -2.6703e-03],
        [ 6.7472e-04, -9.8083e-02, -7.2174e-03,  ..., -5.4502e-04,
          7.6408e-03, -8.0566e-03],
        [-2.8534e-03,  8.8501e-03, -9.7107e-02,  ...,  5.5161e-03,
          4.1122e-03, -1.6556e-03],
        ...,
        [ 2.8172e-03, -5.8746e-03, -7.2403e-03,  ..., -7.6782e-02,
          7.9498e-03,  5.3787e-04],
        [-1.9188e-03,  1.2520e-02, -6.6833e-03,  ...,  1.0658e-02,
         -8.3740e-02, -3.1414e-03],
        [-8.5831e-04,  1.0513e-02,  5.8212e-03,  ...,  1.0948e-02,
         -1.2650e-02, -9.1858e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1172,  0.0018, -0.0041,  ..., -0.0185,  0.0064,  0.0020],
        [ 0.0065, -0.1055, -0.0077,  ...,  0.0099, -0.0023,  0.0087],
        [ 0.0037, -0.0081, -0.0979,  ...,  0.0044,  0.0008, -0.0096],
        ...,
        [-0.0065, -0.0148, -0.0002,  ..., -0.1117,  0.0130, -0.0046],
        [-0.0045,  0.0076, -0.0108,  ...,  0.0072, -0.1029,  0.0032],
        [-0.0124,  0.0008,  0.0013,  ..., -0.0090,  0.0025, -0.1036]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:24:23 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 01:24:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.1774, 0.4668, 0.2213,  ..., 0.4326, 0.6650, 0.5239], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7134,  0.1497,  0.5576,  ...,  0.1569,  1.0625,  0.5952],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.9409, 1.5889, 0.5464,  ..., 0.8799, 1.1807, 2.3047], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6465, -0.1611,  0.6523,  ...,  0.3252,  0.5098,  0.7334],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:24:23 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:24:23 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 01:25:25 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 01:26:26 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 01:27:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8721e-03,  2.6679e-04,  1.0319e-03,  ...,  1.6651e-03,
         -1.6947e-03, -6.6948e-04],
        [ 1.8692e-03,  9.9850e-04,  2.8629e-03,  ...,  3.1209e-04,
          2.2850e-03,  3.9816e-04],
        [ 2.4605e-03, -3.0756e-05,  6.0844e-04,  ...,  4.2439e-04,
         -1.2894e-03,  1.2932e-03],
        ...,
        [-1.4219e-03, -2.6093e-03, -1.3554e-04,  ...,  3.5954e-04,
         -1.5812e-03, -1.3247e-03],
        [ 1.9150e-03, -1.9312e-04,  4.1313e-03,  ..., -1.2290e-04,
         -1.4105e-03,  1.5945e-03],
        [ 6.1178e-04,  1.4133e-03,  1.2646e-03,  ...,  1.9083e-03,
         -6.9714e-04,  2.3212e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0959, -0.0149, -0.0066,  ..., -0.0043,  0.0048,  0.0016],
        [-0.0060, -0.0923,  0.0068,  ...,  0.0083, -0.0196, -0.0066],
        [ 0.0092,  0.0023, -0.0861,  ..., -0.0046, -0.0114,  0.0014],
        ...,
        [ 0.0029,  0.0067, -0.0125,  ..., -0.0972, -0.0033,  0.0002],
        [ 0.0079,  0.0039, -0.0030,  ...,  0.0091, -0.1072,  0.0060],
        [-0.0002,  0.0056, -0.0065,  ..., -0.0020,  0.0164, -0.0834]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1031,  0.0049, -0.0134,  ..., -0.0002, -0.0119,  0.0062],
        [ 0.0033, -0.1153,  0.0018,  ...,  0.0078, -0.0045,  0.0010],
        [ 0.0047, -0.0087, -0.1103,  ..., -0.0128,  0.0044,  0.0060],
        ...,
        [ 0.0022,  0.0083, -0.0090,  ..., -0.0957, -0.0011, -0.0079],
        [ 0.0059,  0.0004, -0.0106,  ...,  0.0188, -0.1104, -0.0002],
        [ 0.0202,  0.0049,  0.0033,  ..., -0.0102,  0.0173, -0.1074]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:27:27 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 01:27:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.6660, 0.4568, 0.3237,  ..., 0.1808, 0.6802, 0.7568], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2417, -0.0470,  0.5547,  ..., -0.2052,  0.3821,  0.2993],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.8506, 1.4062, 0.5112,  ..., 1.3535, 0.9121, 2.6875], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4797, -0.2622,  0.8008,  ...,  0.5918,  0.2310,  0.0527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:27:27 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:27:27 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 01:28:32 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 01:29:32 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 01:30:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.6201e-03, -5.4741e-03, -4.6463e-03,  ..., -8.4763e-03,
          1.2932e-03,  5.7220e-06],
        [-3.3722e-03, -2.0850e-04,  3.0670e-03,  ...,  4.3678e-03,
          8.6832e-04, -2.8419e-03],
        [-2.6073e-03, -1.2159e-03, -5.4054e-03,  ..., -1.7500e-03,
         -3.2139e-04, -2.8400e-03],
        ...,
        [ 6.9771e-03, -1.5926e-03, -7.2136e-03,  ..., -7.2594e-03,
         -3.3302e-03, -2.1381e-03],
        [-2.2106e-03, -5.2989e-05, -3.5534e-03,  ...,  3.7594e-03,
         -5.1270e-03, -1.1892e-03],
        [-1.0366e-03,  4.9133e-03, -4.0588e-03,  ..., -8.1635e-03,
         -4.0102e-04, -1.2566e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0632,  0.0089,  0.0029,  ..., -0.0134, -0.0182, -0.0188],
        [-0.0067, -0.0731, -0.0162,  ...,  0.0038,  0.0045,  0.0070],
        [ 0.0077, -0.0038, -0.0531,  ..., -0.0110, -0.0053,  0.0035],
        ...,
        [-0.0059, -0.0034, -0.0022,  ..., -0.0602, -0.0023, -0.0088],
        [-0.0011,  0.0124, -0.0079,  ...,  0.0039, -0.0662,  0.0108],
        [-0.0011,  0.0062,  0.0181,  ..., -0.0043,  0.0025, -0.0580]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0800,  0.0113, -0.0029,  ..., -0.0120,  0.0086,  0.0002],
        [ 0.0028, -0.0827, -0.0044,  ..., -0.0038,  0.0039,  0.0054],
        [ 0.0084,  0.0098, -0.0765,  ..., -0.0017, -0.0144, -0.0119],
        ...,
        [-0.0190, -0.0054, -0.0054,  ..., -0.0847, -0.0024,  0.0063],
        [ 0.0023,  0.0180, -0.0072,  ..., -0.0015, -0.0809,  0.0032],
        [-0.0085,  0.0010,  0.0099,  ..., -0.0012, -0.0067, -0.0786]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:30:39 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 01:30:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.4146, 0.7153, 0.2340,  ..., 0.3750, 0.5391, 0.9961], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3289, -0.0817,  0.3044,  ...,  0.1483,  0.2590,  0.3171],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.2295, 0.5527, 0.3818,  ..., 1.5557, 0.2446, 3.6387], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2998, -0.3071,  0.9814,  ...,  0.7461,  0.1084,  0.5566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:30:39 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:30:39 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 01:31:45 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 01:32:51 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 01:33:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0153, -0.0053,  0.0021,  ...,  0.0039, -0.0006, -0.0019],
        [ 0.0005, -0.0062, -0.0070,  ...,  0.0003,  0.0031,  0.0038],
        [-0.0016,  0.0014, -0.0143,  ..., -0.0030,  0.0012,  0.0005],
        ...,
        [-0.0025, -0.0047, -0.0027,  ..., -0.0129,  0.0019, -0.0078],
        [ 0.0058,  0.0084, -0.0040,  ...,  0.0025, -0.0210,  0.0006],
        [ 0.0044,  0.0023, -0.0031,  ..., -0.0032,  0.0047, -0.0169]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0417,  0.0007,  0.0073,  ...,  0.0091, -0.0009,  0.0172],
        [ 0.0057, -0.0419,  0.0097,  ..., -0.0041,  0.0110, -0.0062],
        [ 0.0150, -0.0018, -0.0621,  ..., -0.0044,  0.0250,  0.0049],
        ...,
        [ 0.0199, -0.0122,  0.0165,  ..., -0.0608,  0.0079, -0.0005],
        [ 0.0027, -0.0107, -0.0071,  ...,  0.0069, -0.0627, -0.0031],
        [-0.0028,  0.0121, -0.0025,  ...,  0.0027,  0.0021, -0.0519]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.1707e-02, -1.6754e-02,  4.1199e-03,  ...,  1.9855e-03,
         -7.9422e-03, -4.1389e-03],
        [-1.1742e-02, -7.7026e-02, -1.4130e-02,  ..., -1.6983e-02,
          5.6610e-03,  4.3068e-03],
        [ 2.9640e-03, -1.0666e-02, -8.5693e-02,  ...,  1.3412e-02,
          8.0948e-03, -1.0586e-03],
        ...,
        [-2.9984e-03, -4.5090e-03,  2.2522e-02,  ..., -6.4453e-02,
          7.3929e-03, -2.3308e-03],
        [-1.7166e-05,  1.3256e-04, -7.0686e-03,  ...,  8.0643e-03,
         -8.5022e-02, -1.9360e-03],
        [-1.6098e-02,  6.8398e-03, -7.2212e-03,  ..., -7.6141e-03,
          7.5607e-03, -8.0444e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:34:01 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 01:34:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.3489, 0.6035, 0.1981,  ..., 0.5698, 0.3992, 1.1309], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2491, -0.1183,  0.3608,  ...,  0.2786,  0.1180, -0.0186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.9482, 0.6279, 0.6646,  ..., 1.7949, 0.0675, 3.8926], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1304, -0.7769,  0.0967,  ..., -0.2354, -0.0648,  0.7866],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:34:01 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:34:01 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 01:35:10 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 01:36:16 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 01:37:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.3945e-03, -3.4695e-03,  1.8559e-03,  ..., -1.5507e-03,
          3.3016e-03,  3.0861e-03],
        [-3.9597e-03, -5.4693e-04, -1.4410e-03,  ..., -1.2732e-03,
          2.4676e-04, -5.2757e-03],
        [-4.0703e-03, -7.6866e-03,  1.2910e-04,  ...,  1.9798e-03,
          1.2617e-03,  2.4357e-03],
        ...,
        [ 1.2884e-03,  7.3767e-04, -1.5736e-05,  ..., -2.6035e-03,
         -3.6087e-03, -3.9215e-03],
        [ 2.0943e-03,  3.8481e-04,  6.8665e-03,  ..., -4.2915e-04,
         -6.1417e-04,  3.5934e-03],
        [-1.3123e-03, -2.3723e-04, -2.4147e-03,  ...,  2.4033e-03,
         -2.7466e-04, -1.1261e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0648,  0.0041, -0.0082,  ..., -0.0089, -0.0080, -0.0099],
        [-0.0027, -0.0667,  0.0004,  ...,  0.0015, -0.0016,  0.0043],
        [-0.0209, -0.0009, -0.0710,  ...,  0.0148,  0.0021, -0.0126],
        ...,
        [-0.0088,  0.0002,  0.0065,  ..., -0.0598, -0.0012, -0.0012],
        [ 0.0066,  0.0015, -0.0029,  ...,  0.0057, -0.0759,  0.0205],
        [-0.0044,  0.0077,  0.0024,  ..., -0.0080,  0.0232, -0.0645]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.9468e-02,  3.4142e-03, -1.1063e-03,  ...,  4.4823e-03,
          5.0049e-03,  2.8992e-03],
        [ 1.1887e-02, -1.0742e-01,  1.5038e-02,  ..., -2.7657e-03,
          1.3313e-03,  2.3758e-02],
        [-4.5700e-03, -3.5210e-03, -8.4900e-02,  ..., -1.8585e-02,
          2.8362e-03, -1.4694e-02],
        ...,
        [-2.4605e-03,  4.1428e-03, -1.0864e-02,  ..., -9.2346e-02,
          7.1411e-03,  3.1815e-03],
        [ 1.0401e-04, -4.5776e-04,  3.2654e-03,  ..., -2.1088e-02,
         -7.6782e-02, -5.6534e-03],
        [-7.9498e-03,  8.0261e-03,  6.6528e-03,  ..., -8.8806e-03,
         -7.2594e-03, -7.8979e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:37:22 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 01:37:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.5137, 0.2202, 0.1292,  ..., 0.6294, 0.1214, 1.4873], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1388, -0.1400,  0.3994,  ...,  0.3230,  0.0721,  0.2073],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5322, -0.6768,  0.6143,  ...,  1.7891,  0.0297,  3.9258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0538, -1.5732, -0.9873,  ..., -0.2810,  0.0776,  0.6763],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:37:22 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:37:22 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 01:38:28 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 01:39:31 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 01:40:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.2468e-03, -9.5427e-05, -9.4910e-03,  ..., -4.3755e-03,
          3.1986e-03, -1.1703e-02],
        [ 5.3825e-03,  2.4586e-03,  3.1414e-03,  ...,  1.4648e-03,
          6.3062e-05,  7.0343e-03],
        [ 4.2648e-03, -3.4981e-03, -2.5940e-04,  ...,  7.6199e-04,
         -3.5305e-03,  3.6983e-03],
        ...,
        [ 1.2121e-03, -3.2406e-03, -1.1902e-02,  ...,  1.1124e-02,
         -2.1973e-03,  4.1656e-03],
        [-4.0169e-03, -1.2383e-02, -2.0180e-03,  ...,  6.0940e-04,
          4.3030e-03,  5.7030e-04],
        [ 5.7297e-03,  3.8910e-03,  7.7820e-03,  ..., -4.9210e-03,
         -7.0267e-03,  3.8795e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.0960e-02,  3.8490e-03, -1.3885e-02,  ..., -1.2299e-02,
         -9.0885e-04, -6.0196e-03],
        [ 4.9286e-03, -8.0643e-03, -1.3399e-03,  ...,  7.1220e-03,
         -6.5517e-04, -2.7828e-03],
        [-9.9564e-03,  1.0056e-02, -2.8549e-02,  ...,  1.6174e-02,
          4.7874e-03,  8.2550e-03],
        ...,
        [-1.3741e-02, -5.1308e-03, -5.0545e-03,  ..., -3.2349e-02,
          1.0468e-02,  1.4786e-02],
        [ 9.7046e-03,  7.9870e-05, -1.7715e-02,  ..., -1.2589e-02,
         -3.2837e-02, -7.2327e-03],
        [-4.3106e-03,  1.3191e-02, -4.8981e-03,  ..., -1.4107e-02,
          1.0048e-02, -1.1505e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0632, -0.0025,  0.0218,  ..., -0.0053,  0.0006,  0.0136],
        [-0.0032, -0.0420, -0.0166,  ..., -0.0032,  0.0033, -0.0078],
        [ 0.0060, -0.0166, -0.0625,  ..., -0.0132,  0.0125,  0.0134],
        ...,
        [-0.0042,  0.0098, -0.0133,  ..., -0.0674, -0.0129, -0.0095],
        [-0.0036,  0.0056, -0.0044,  ..., -0.0129, -0.0364,  0.0132],
        [ 0.0026,  0.0095,  0.0088,  ...,  0.0056,  0.0097, -0.0474]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:40:40 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 01:40:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.3843, 0.2390, 0.2336,  ..., 0.7090, 0.0194, 1.5439], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0526, -0.3098,  0.0184,  ..., -0.0853, -0.0274,  0.2756],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2344, -0.8979,  0.6929,  ...,  2.1387, -0.0276,  3.6582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5220, -1.7012, -0.5708,  ...,  0.0896,  0.4917,  0.8750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:40:40 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:40:41 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 01:41:52 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 01:43:07 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 01:44:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.5305e-02, -3.6983e-03, -2.0733e-03,  ...,  3.5362e-03,
         -8.7440e-05, -9.5701e-04],
        [-2.6493e-03,  1.4656e-02, -8.7738e-04,  ..., -4.5090e-03,
         -1.0145e-04,  3.6240e-03],
        [ 8.7023e-04, -3.7742e-04,  1.0841e-02,  ..., -4.9114e-04,
         -3.8743e-05,  1.1263e-03],
        ...,
        [ 9.6750e-04, -2.8443e-04, -2.6131e-03,  ...,  1.1658e-02,
          3.0041e-04,  1.8311e-03],
        [-3.4866e-03, -2.1038e-03, -1.1272e-03,  ...,  2.7771e-03,
          1.0338e-02, -3.5954e-04],
        [-2.2926e-03,  2.0409e-03, -1.6136e-03,  ...,  2.1887e-04,
         -7.8022e-05,  1.1726e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0385, -0.0131, -0.0178,  ...,  0.0008, -0.0097, -0.0050],
        [ 0.0086, -0.0259, -0.0072,  ...,  0.0014,  0.0055,  0.0065],
        [-0.0107, -0.0039, -0.0218,  ..., -0.0155, -0.0006, -0.0004],
        ...,
        [ 0.0228, -0.0064, -0.0146,  ..., -0.0206,  0.0100, -0.0089],
        [ 0.0060, -0.0046,  0.0077,  ...,  0.0038, -0.0265, -0.0050],
        [-0.0177,  0.0007,  0.0012,  ..., -0.0083,  0.0034, -0.0308]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0455,  0.0111,  0.0099,  ...,  0.0129,  0.0044, -0.0013],
        [ 0.0180, -0.0643, -0.0138,  ..., -0.0087, -0.0140,  0.0199],
        [-0.0043, -0.0028, -0.0530,  ...,  0.0102, -0.0029,  0.0102],
        ...,
        [ 0.0023, -0.0023, -0.0212,  ..., -0.0500,  0.0029,  0.0002],
        [ 0.0052,  0.0073,  0.0051,  ..., -0.0168, -0.0512, -0.0041],
        [-0.0207,  0.0002,  0.0007,  ..., -0.0153, -0.0019, -0.0655]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:44:20 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 01:44:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5615, -0.2605,  0.2108,  ...,  0.6372,  0.0176,  1.4189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0204, -0.6035, -0.3762,  ..., -0.1164,  0.0386,  0.2316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5723, -1.1445,  0.6538,  ...,  1.0479,  0.1947,  3.5820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8032, -1.9111,  0.0645,  ...,  0.0927,  0.6758,  1.1748],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:44:20 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:44:20 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 01:45:35 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 01:46:53 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 01:48:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2007e-03, -5.3558e-03, -2.3842e-03,  ...,  3.7727e-03,
         -3.5648e-03,  1.8148e-03],
        [ 8.8787e-04, -7.2746e-03, -3.7861e-03,  ...,  7.5293e-04,
          3.0632e-03, -3.2473e-04],
        [-1.9484e-03,  5.2547e-04, -5.0774e-03,  ...,  8.9169e-05,
         -1.2627e-03, -9.2125e-04],
        ...,
        [ 2.2850e-03,  3.0842e-03, -3.4008e-03,  ..., -3.0651e-03,
          4.2105e-04,  2.8934e-03],
        [ 3.1586e-03,  3.1395e-03,  3.4237e-03,  ...,  3.5324e-03,
         -8.1558e-03, -3.3760e-03],
        [-5.8212e-03,  1.4162e-03,  5.7755e-03,  ..., -6.4659e-04,
          3.8338e-03, -2.2411e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0042,  0.0164, -0.0070,  ..., -0.0071,  0.0082, -0.0012],
        [-0.0150, -0.0410, -0.0085,  ...,  0.0097,  0.0115,  0.0056],
        [ 0.0016,  0.0141, -0.0069,  ...,  0.0025,  0.0025, -0.0213],
        ...,
        [ 0.0056,  0.0004, -0.0088,  ..., -0.0333,  0.0070,  0.0020],
        [-0.0031,  0.0006,  0.0077,  ..., -0.0088, -0.0034, -0.0140],
        [-0.0053, -0.0022, -0.0070,  ..., -0.0014,  0.0113, -0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.5359e-02,  1.6541e-02, -1.2703e-02,  ...,  9.3613e-03,
         -1.1147e-02,  3.4714e-03],
        [ 1.1086e-02, -7.4707e-02, -1.1536e-02,  ..., -1.3336e-02,
          1.0674e-02,  7.9498e-03],
        [ 1.4244e-02,  1.6357e-02, -3.3722e-02,  ...,  1.2646e-03,
          4.2439e-05, -1.1414e-02],
        ...,
        [ 8.5602e-03, -6.1722e-03, -8.2016e-03,  ..., -5.2002e-02,
          5.3787e-03, -1.4221e-02],
        [-8.5602e-03, -1.5884e-02, -9.2468e-03,  ..., -5.5428e-03,
         -6.3171e-02, -3.2158e-03],
        [-4.4327e-03,  2.5520e-03, -9.6130e-03,  ...,  1.1017e-02,
         -7.6141e-03, -5.1147e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:48:14 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 01:48:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 4.4824e-01, -3.1738e-01,  2.2913e-01,  ...,  7.5342e-01,
        -4.4560e-04,  1.3096e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2018, -0.6294, -0.2217,  ...,  0.0398,  0.1989,  0.3088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6523, -1.9863,  0.6484,  ...,  1.0264,  1.0488,  4.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1895, -2.2070,  0.4402,  ...,  0.4756,  0.6289,  1.5977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:48:14 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:48:14 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 01:49:36 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 01:50:57 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 01:52:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.6458e-04, -2.5272e-04, -5.1975e-05,  ..., -9.4771e-06,
         -9.7871e-05,  3.6478e-04],
        [-5.7602e-04,  1.2980e-03,  5.1212e-04,  ...,  1.7071e-04,
         -2.3770e-04, -2.1827e-04],
        [-1.4925e-04,  7.9870e-04,  1.6868e-04,  ...,  2.4033e-04,
          7.6246e-04, -3.7432e-04],
        ...,
        [-1.1091e-03, -8.0776e-04,  7.8487e-04,  ..., -1.6212e-03,
         -1.1921e-03,  1.0240e-04],
        [-2.8610e-04, -7.7438e-04, -7.6199e-04,  ..., -4.0388e-04,
          7.6628e-04,  3.8600e-04],
        [-4.7350e-04,  1.9968e-04,  7.1192e-04,  ..., -3.9935e-04,
          9.1124e-04, -3.5167e-06]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0106,  0.0252, -0.0052,  ..., -0.0036,  0.0004,  0.0095],
        [-0.0049, -0.0268, -0.0032,  ...,  0.0043,  0.0035, -0.0013],
        [ 0.0017, -0.0044, -0.0052,  ..., -0.0050, -0.0015, -0.0002],
        ...,
        [-0.0051,  0.0101, -0.0127,  ..., -0.0022, -0.0086,  0.0096],
        [ 0.0046,  0.0107,  0.0117,  ...,  0.0056, -0.0360, -0.0049],
        [-0.0011, -0.0086, -0.0172,  ...,  0.0018, -0.0049, -0.0131]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0547, -0.0031,  0.0022,  ..., -0.0289, -0.0307,  0.0002],
        [-0.0149, -0.0368, -0.0032,  ...,  0.0111,  0.0098, -0.0025],
        [-0.0043, -0.0129, -0.0584,  ..., -0.0179,  0.0050,  0.0029],
        ...,
        [-0.0087,  0.0104, -0.0015,  ..., -0.0532,  0.0154,  0.0154],
        [-0.0050, -0.0121, -0.0064,  ..., -0.0234, -0.0551, -0.0089],
        [-0.0012,  0.0250, -0.0161,  ..., -0.0063,  0.0127, -0.0728]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:52:21 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 01:52:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5625, -0.3870,  0.1947,  ...,  0.3586,  0.0861,  1.2236],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 3.1128e-01, -6.8359e-01, -3.1781e-04,  ...,  3.9398e-02,
         2.6904e-01,  4.0747e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3076, -1.0137,  0.2427,  ...,  0.8691,  0.9985,  4.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.3359, -2.0117,  1.0986,  ...,  0.5815,  0.0786,  2.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:52:21 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:52:21 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 01:53:44 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 01:55:08 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 01:56:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.4806e-03,  4.4155e-04, -7.5006e-04,  ..., -5.3406e-05,
         -5.7316e-04,  9.0897e-05],
        [-5.7173e-04,  7.7019e-03, -7.7057e-04,  ...,  7.7915e-04,
         -2.8477e-03,  9.5844e-04],
        [ 8.9788e-04,  3.1033e-03,  1.2482e-02,  ..., -5.1260e-05,
          1.3857e-03,  4.0293e-04],
        ...,
        [-1.9588e-03, -1.0414e-03,  2.3937e-03,  ...,  7.1106e-03,
          2.3289e-03,  4.3917e-04],
        [ 1.4753e-03,  5.2977e-04, -3.4523e-03,  ..., -7.9870e-06,
          3.5667e-03,  6.0201e-05],
        [-9.5844e-04,  1.1339e-03, -2.8253e-04,  ...,  2.9469e-03,
          1.6575e-03,  7.3700e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0198,  0.0011, -0.0121,  ..., -0.0071,  0.0135, -0.0007],
        [-0.0003, -0.0182,  0.0145,  ...,  0.0046, -0.0079,  0.0100],
        [ 0.0031, -0.0028, -0.0052,  ...,  0.0016,  0.0068,  0.0073],
        ...,
        [ 0.0016,  0.0026, -0.0109,  ..., -0.0141, -0.0118, -0.0007],
        [-0.0025, -0.0032, -0.0108,  ..., -0.0060, -0.0051,  0.0008],
        [-0.0248,  0.0060,  0.0068,  ...,  0.0046,  0.0174, -0.0296]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0493,  0.0065, -0.0096,  ...,  0.0177,  0.0081,  0.0118],
        [ 0.0040, -0.0737,  0.0160,  ..., -0.0114, -0.0277,  0.0051],
        [ 0.0014, -0.0177, -0.0783,  ..., -0.0128,  0.0047,  0.0035],
        ...,
        [ 0.0235, -0.0027, -0.0183,  ..., -0.0859, -0.0068, -0.0131],
        [-0.0079, -0.0064,  0.0044,  ..., -0.0043, -0.0952,  0.0243],
        [ 0.0089,  0.0027, -0.0005,  ..., -0.0009,  0.0041, -0.0827]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 01:56:32 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 01:56:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5723, -0.6255,  0.1693,  ...,  0.3313,  0.3684,  1.4785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4329, -0.7261,  0.1078,  ...,  0.1572,  0.2362,  0.5483],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0449, -0.6270,  1.0898,  ...,  1.2891,  1.6484,  4.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0420, -2.0059,  1.6230,  ...,  0.8716,  0.3816,  2.9473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 01:56:32 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 01:56:32 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 01:57:54 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 01:59:19 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 02:00:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.0926e-04,  2.4354e-04,  5.6553e-04,  ..., -8.4400e-04,
          1.5211e-03,  3.6716e-03],
        [-1.8561e-04,  2.0742e-05,  4.0913e-04,  ..., -3.2854e-04,
         -1.2560e-03, -4.6396e-04],
        [ 6.4707e-04, -3.7551e-05, -6.2466e-05,  ..., -2.9373e-04,
          1.0757e-03,  2.6774e-04],
        ...,
        [-4.6062e-04,  7.3242e-04,  1.8501e-03,  ...,  3.1471e-04,
         -4.7898e-04,  1.8415e-03],
        [ 8.3971e-04,  8.2302e-04,  3.8242e-04,  ...,  9.0313e-04,
          1.6642e-03, -4.8685e-04],
        [ 3.4404e-04, -8.3733e-04, -7.5579e-05,  ..., -5.3072e-04,
         -5.6124e-04,  3.3817e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0118,  0.0044,  0.0024,  ..., -0.0063,  0.0019, -0.0104],
        [ 0.0051,  0.0151,  0.0010,  ...,  0.0095, -0.0015,  0.0065],
        [ 0.0085,  0.0102,  0.0057,  ...,  0.0070,  0.0163, -0.0147],
        ...,
        [-0.0124, -0.0043, -0.0042,  ...,  0.0569, -0.0099,  0.0152],
        [ 0.0038,  0.0003,  0.0037,  ..., -0.0147,  0.0114, -0.0024],
        [ 0.0094,  0.0079, -0.0186,  ..., -0.0133,  0.0037,  0.0232]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0161,  0.0008,  0.0108,  ...,  0.0045,  0.0035,  0.0074],
        [-0.0045, -0.0359, -0.0055,  ..., -0.0043, -0.0154,  0.0290],
        [ 0.0019,  0.0025,  0.0294,  ...,  0.0034, -0.0068, -0.0241],
        ...,
        [ 0.0012, -0.0170, -0.0158,  ...,  0.0090,  0.0055, -0.0166],
        [-0.0002,  0.0081, -0.0129,  ...,  0.0131,  0.0203, -0.0205],
        [-0.0073,  0.0227, -0.0055,  ...,  0.0103,  0.0045,  0.0039]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:00:47 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 02:00:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4512, -0.2939,  0.0210,  ...,  0.2408,  0.3193,  1.3496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8247, -0.6304,  0.3186,  ...,  0.1591,  0.0247,  0.6621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0059, -0.0293,  1.5430,  ...,  0.6006,  2.6426,  4.3477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4717, -2.3398,  1.2314,  ...,  0.7959, -0.3967,  3.8164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:00:47 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 02:00:47 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 02:02:13 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 02:03:38 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 02:05:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.0225e-04,  1.5440e-03, -5.5909e-05,  ...,  2.3041e-03,
         -1.8301e-03, -6.7294e-05],
        [-2.3403e-03, -2.7332e-03,  1.6813e-03,  ..., -2.4986e-03,
          8.7452e-04, -5.8270e-04],
        [ 6.8045e-04,  4.1103e-04, -4.0169e-03,  ...,  8.9550e-04,
         -2.1152e-03, -1.3857e-03],
        ...,
        [-2.3823e-03, -4.1389e-03,  3.7479e-03,  ..., -4.2458e-03,
          3.6697e-03,  5.4359e-04],
        [ 3.4356e-04,  1.6556e-03,  3.2783e-04,  ...,  1.2088e-04,
         -3.3798e-03,  3.7861e-04],
        [-8.9169e-04, -1.6766e-03,  3.8223e-03,  ..., -7.1192e-04,
         -4.2617e-05, -1.8225e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0214,  0.0254,  0.0210,  ...,  0.0049, -0.0003, -0.0053],
        [-0.0010, -0.0290,  0.0054,  ...,  0.0093, -0.0003,  0.0047],
        [ 0.0052,  0.0063, -0.0114,  ..., -0.0139, -0.0132,  0.0065],
        ...,
        [-0.0151,  0.0074, -0.0033,  ..., -0.0047,  0.0085,  0.0099],
        [ 0.0052,  0.0094, -0.0038,  ..., -0.0107, -0.0106,  0.0006],
        [-0.0101,  0.0013, -0.0008,  ...,  0.0132,  0.0048, -0.0063]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0371,  0.0023,  0.0141,  ...,  0.0097,  0.0092,  0.0027],
        [-0.0111, -0.0349,  0.0002,  ...,  0.0122,  0.0015, -0.0067],
        [ 0.0045,  0.0081, -0.0248,  ...,  0.0101, -0.0067, -0.0155],
        ...,
        [-0.0300, -0.0139,  0.0156,  ..., -0.0212,  0.0038,  0.0087],
        [ 0.0071, -0.0091, -0.0004,  ..., -0.0080, -0.0260,  0.0104],
        [ 0.0163,  0.0101, -0.0173,  ...,  0.0078,  0.0172, -0.0421]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:05:05 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 02:05:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3611, -0.1510,  0.2266,  ...,  0.2727,  0.4500,  1.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3928, -0.5938,  0.4285,  ...,  0.1791,  0.0957,  0.9053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.4824,  0.3884,  0.0713,  ..., -0.7256,  2.6328,  3.5879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.8789, -2.1387, -0.1240,  ..., -0.5928, -0.3604,  3.3633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:05:05 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 02:05:05 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 02:06:33 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 02:08:01 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 02:09:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.2152e-04, -8.7881e-04,  4.9543e-04,  ..., -1.5426e-04,
         -6.8963e-05, -6.0081e-05],
        [-5.5432e-06,  1.5364e-03, -3.8433e-04,  ..., -3.3784e-04,
         -1.3137e-04,  5.6458e-04],
        [ 9.6130e-04, -1.0741e-04,  1.0567e-03,  ...,  1.3709e-04,
         -4.8470e-04, -1.0765e-04],
        ...,
        [ 3.3164e-04,  2.8658e-04, -3.1662e-04,  ...,  9.1171e-04,
         -1.5974e-04, -2.2221e-04],
        [-3.8052e-04,  8.6212e-04,  9.9850e-04,  ..., -4.8923e-04,
          7.8392e-04, -1.1533e-04],
        [ 3.7193e-04, -4.9734e-04,  9.4271e-04,  ...,  5.0724e-05,
          7.6675e-04,  2.2373e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0083,  0.0157,  0.0011,  ...,  0.0006,  0.0004,  0.0046],
        [ 0.0046, -0.0041, -0.0012,  ..., -0.0007,  0.0090, -0.0086],
        [-0.0164,  0.0055,  0.0090,  ...,  0.0025, -0.0030,  0.0036],
        ...,
        [-0.0142,  0.0092, -0.0107,  ...,  0.0266, -0.0071,  0.0029],
        [ 0.0132, -0.0024, -0.0093,  ..., -0.0035,  0.0247,  0.0110],
        [-0.0109,  0.0102,  0.0115,  ..., -0.0005,  0.0043,  0.0145]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0128,  0.0086,  0.0033,  ..., -0.0037, -0.0052, -0.0054],
        [ 0.0163, -0.0405, -0.0078,  ..., -0.0115,  0.0037, -0.0036],
        [ 0.0002,  0.0097, -0.0079,  ..., -0.0213,  0.0074, -0.0060],
        ...,
        [-0.0015, -0.0061,  0.0241,  ..., -0.0068,  0.0015, -0.0151],
        [-0.0169, -0.0188,  0.0079,  ..., -0.0083, -0.0357,  0.0161],
        [-0.0082,  0.0062,  0.0281,  ...,  0.0137,  0.0186, -0.0212]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:09:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too spent, it is overspent
If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too powered, it is
2024-06-30 02:09:31 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 02:09:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4302,  0.2861,  0.3313,  ...,  0.5396, -0.3242, -0.3179],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1978, -0.1086,  0.1226,  ...,  0.2009, -0.3789, -0.4961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8203,  0.7402,  1.0801,  ...,  0.3433, -0.2886, -0.3191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6196,  0.1748,  0.2057,  ...,  0.1989, -0.4214, -0.0428],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:09:31 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:09:31 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 02:09:54 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 02:10:17 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 02:10:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.4719e-03,  5.1355e-04,  1.8191e-04,  ...,  1.1122e-04,
         -1.3900e-04,  9.1076e-05],
        [ 3.1686e-04, -2.6321e-03,  3.5584e-05,  ...,  1.7464e-04,
         -1.0931e-04,  5.0449e-04],
        [ 2.6822e-06, -8.5473e-05, -2.3003e-03,  ..., -2.1851e-04,
         -9.4295e-05,  1.0878e-04],
        ...,
        [-7.9012e-04,  9.0659e-05, -2.7132e-04,  ..., -2.2583e-03,
         -5.9843e-04,  4.6086e-04],
        [-3.2711e-04,  1.8883e-04, -2.6822e-06,  ..., -1.7738e-04,
         -2.6665e-03, -3.4988e-05],
        [-2.3973e-04,  9.5963e-06, -8.2731e-05,  ...,  1.9169e-04,
          4.8161e-04, -2.6112e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0312, -0.0007,  0.0045,  ...,  0.0090, -0.0032,  0.0031],
        [-0.0065, -0.0323,  0.0071,  ...,  0.0066,  0.0064,  0.0017],
        [ 0.0005, -0.0074, -0.0441,  ...,  0.0025, -0.0019,  0.0084],
        ...,
        [ 0.0015, -0.0024, -0.0016,  ..., -0.0341,  0.0133, -0.0076],
        [-0.0032, -0.0003, -0.0002,  ...,  0.0053, -0.0259,  0.0019],
        [ 0.0012,  0.0002, -0.0001,  ...,  0.0059,  0.0019, -0.0337]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.5583e-02, -1.3943e-03,  1.7357e-03,  ...,  4.8637e-05,
          4.9543e-04,  2.3770e-04],
        [ 2.1000e-03, -3.5431e-02, -4.2076e-03,  ...,  1.1911e-03,
          5.8517e-03, -5.7316e-04],
        [-6.2332e-03, -2.1267e-03, -3.1250e-02,  ..., -9.7179e-04,
         -4.1008e-03,  8.3351e-04],
        ...,
        [-7.7152e-04,  2.0504e-04,  3.0518e-03,  ..., -3.2043e-02,
         -1.0128e-03, -1.5879e-03],
        [-1.2589e-03,  1.5526e-03,  1.8215e-03,  ..., -2.6512e-03,
         -3.0640e-02,  5.4436e-03],
        [-1.2455e-03, -2.3193e-03, -2.6226e-03,  ...,  5.2452e-03,
          1.7052e-03, -3.1143e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:10:43 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 02:10:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8770,  0.6221,  0.7314,  ...,  0.5366, -0.4155, -0.8271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7373, -0.0271,  0.3647,  ..., -0.1140, -0.5132, -0.2795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8125,  0.9185,  1.0156,  ..., -0.2759, -0.8413, -0.2439],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6763,  0.1328,  0.2032,  ..., -0.6777, -0.4084,  0.1708],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:10:43 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:10:43 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 02:11:07 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 02:11:31 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 02:11:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8076e-03,  2.1970e-04,  9.0742e-04,  ..., -1.9627e-03,
         -7.7915e-04,  2.5797e-04],
        [ 1.6880e-04, -4.4365e-03,  1.3351e-04,  ...,  1.3590e-03,
         -7.2145e-04, -3.1757e-04],
        [ 1.9300e-04,  1.5259e-05, -5.4932e-03,  ...,  6.9141e-04,
         -2.8014e-04, -4.1986e-04],
        ...,
        [ 5.7459e-05,  6.7830e-05, -2.2411e-05,  ..., -4.7874e-03,
         -2.2430e-03,  7.5293e-04],
        [ 3.7360e-04,  2.3842e-04,  9.3746e-04,  ...,  6.6090e-04,
         -3.7689e-03,  5.2500e-04],
        [ 1.1122e-04,  2.9612e-04, -1.0862e-03,  ..., -7.4387e-04,
         -1.4603e-04, -4.5204e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0709,  0.0047, -0.0080,  ...,  0.0050,  0.0008, -0.0036],
        [ 0.0046, -0.0796, -0.0013,  ...,  0.0154, -0.0049,  0.0075],
        [-0.0108,  0.0026, -0.0582,  ...,  0.0050, -0.0089, -0.0070],
        ...,
        [ 0.0146,  0.0070,  0.0036,  ..., -0.0765, -0.0064,  0.0021],
        [ 0.0078, -0.0064,  0.0068,  ..., -0.0095, -0.0815, -0.0050],
        [-0.0011,  0.0038, -0.0013,  ...,  0.0041,  0.0006, -0.0711]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.9214e-02,  1.7633e-03, -6.9199e-03,  ...,  1.9312e-04,
          6.9160e-03,  3.1471e-05],
        [-3.0255e-04, -8.0078e-02, -7.6942e-03,  ...,  6.0616e-03,
          3.6469e-03,  3.9902e-03],
        [ 5.4588e-03,  3.1090e-03, -5.9692e-02,  ...,  1.2035e-03,
         -5.2109e-03, -6.7406e-03],
        ...,
        [ 1.0834e-03,  9.6436e-03,  2.8172e-03,  ..., -7.6111e-02,
         -6.5918e-03, -5.0774e-03],
        [-5.1231e-03,  4.3106e-04,  2.4605e-03,  ...,  4.9820e-03,
         -7.3303e-02,  2.6817e-03],
        [ 1.1072e-03,  1.1024e-03,  3.2921e-03,  ..., -3.3703e-03,
          6.6986e-03, -7.7026e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:11:55 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 02:11:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.9907,  0.8604,  1.2451,  ...,  0.3794, -0.3384, -0.4158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9839,  0.2612,  0.3179,  ...,  0.3003, -0.6396, -0.0884],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6729,  0.8916,  1.2314,  ...,  0.1572, -0.8135, -0.2439],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9478,  0.3247, -0.0897,  ..., -0.6421, -0.5576,  0.9409],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:11:55 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:11:55 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 02:12:21 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 02:12:45 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 02:13:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.0430e-03,  4.3917e-04, -2.7847e-03,  ..., -3.6669e-04,
          3.2663e-04, -2.3518e-03],
        [ 6.3896e-05, -6.6490e-03,  2.1667e-03,  ...,  1.3952e-03,
         -1.1539e-03,  7.6008e-04],
        [-4.1628e-04, -5.7983e-04, -4.2038e-03,  ...,  6.6376e-04,
         -8.6975e-04, -4.1795e-04],
        ...,
        [-2.0957e-04,  1.0586e-03, -1.4963e-03,  ..., -5.7640e-03,
          1.0853e-03, -1.8501e-03],
        [-1.2035e-03, -1.3459e-04, -1.3294e-03,  ..., -2.7490e-04,
         -4.3106e-03, -6.0797e-04],
        [ 6.5184e-04, -1.5049e-03,  1.6966e-03,  ...,  7.6485e-04,
          3.9339e-04, -5.0468e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0464, -0.0054, -0.0097,  ...,  0.0057,  0.0010, -0.0011],
        [-0.0033, -0.0402,  0.0005,  ..., -0.0035,  0.0026, -0.0012],
        [ 0.0065, -0.0037, -0.0422,  ...,  0.0013,  0.0076,  0.0029],
        ...,
        [ 0.0034,  0.0005, -0.0075,  ..., -0.0424,  0.0059, -0.0013],
        [-0.0109, -0.0069,  0.0070,  ...,  0.0052, -0.0402,  0.0007],
        [-0.0016, -0.0044,  0.0017,  ..., -0.0026,  0.0009, -0.0366]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0396,  0.0033, -0.0019,  ...,  0.0018,  0.0009, -0.0022],
        [ 0.0078, -0.0316,  0.0036,  ..., -0.0010, -0.0004,  0.0047],
        [ 0.0034,  0.0015, -0.0319,  ..., -0.0068,  0.0024,  0.0032],
        ...,
        [-0.0004, -0.0020, -0.0086,  ..., -0.0303,  0.0004, -0.0010],
        [-0.0045,  0.0041,  0.0067,  ...,  0.0006, -0.0222, -0.0004],
        [-0.0038,  0.0049,  0.0058,  ...,  0.0001,  0.0063, -0.0288]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:13:14 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 02:13:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.9873,  1.0596,  1.1523,  ..., -0.3079, -0.9805, -0.3340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0557,  0.1862,  0.3081,  ..., -0.9722, -0.6172,  0.2349],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6699,  0.9375,  1.9131,  ...,  0.6406, -0.1895, -0.2162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6870,  0.9922,  0.1891,  ..., -0.9673,  0.1162,  0.8154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:13:14 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:13:14 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 02:13:44 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 02:14:14 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 02:14:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.6001e-04, -7.1049e-04,  1.2722e-03,  ...,  1.1444e-03,
          1.5297e-03, -3.4332e-04],
        [ 2.1887e-04, -4.0169e-03, -2.8610e-06,  ..., -4.2510e-04,
          9.0027e-04,  8.2254e-05],
        [ 2.3162e-04,  8.1253e-04, -7.9632e-04,  ..., -1.3626e-04,
          1.3518e-04, -4.4227e-05],
        ...,
        [-9.4938e-04, -2.6150e-03, -1.6069e-04,  ..., -1.3161e-03,
          3.0518e-04,  9.4795e-04],
        [ 1.4296e-03,  4.4775e-04, -8.9586e-05,  ..., -2.0504e-03,
         -1.2369e-03,  9.5844e-05],
        [ 5.9128e-04, -1.3943e-03,  6.2370e-04,  ..., -3.4952e-04,
         -4.8447e-04, -1.8711e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.1056e-02,  7.1640e-03,  3.7766e-03,  ...,  1.8387e-03,
          1.4145e-02,  1.3380e-03],
        [ 2.7580e-03, -4.5441e-02,  4.1695e-03,  ..., -3.8033e-03,
          6.8130e-03, -9.2545e-03],
        [-2.2984e-04,  4.3869e-05, -5.9753e-02,  ..., -1.2569e-03,
         -7.1030e-03,  7.6485e-04],
        ...,
        [-8.7738e-05,  2.8458e-03, -2.6054e-03,  ..., -4.2267e-02,
         -2.5291e-03, -5.8460e-04],
        [-2.0828e-03, -3.6373e-03,  6.7139e-03,  ...,  1.2007e-03,
         -4.4495e-02,  2.3479e-03],
        [ 4.1294e-04, -4.8752e-03, -1.1002e-02,  ...,  1.2650e-02,
          5.0278e-03, -4.6448e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0540, -0.0005,  0.0035,  ..., -0.0022,  0.0015,  0.0036],
        [ 0.0048, -0.0345, -0.0033,  ...,  0.0068,  0.0112, -0.0074],
        [ 0.0004, -0.0024, -0.0470,  ..., -0.0004, -0.0028,  0.0046],
        ...,
        [-0.0091, -0.0008,  0.0012,  ..., -0.0405,  0.0051, -0.0018],
        [ 0.0007,  0.0008, -0.0036,  ..., -0.0068, -0.0340,  0.0036],
        [-0.0011, -0.0011, -0.0022,  ..., -0.0076, -0.0014, -0.0457]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:14:42 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 02:14:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6650,  0.8477,  1.1484,  ...,  0.1305, -0.7661, -0.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0596,  0.3347, -0.0880,  ..., -0.6792, -0.5903,  1.0527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3257,  1.1064,  1.9141,  ...,  0.2109,  0.7861, -0.2183],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6328,  0.7305,  0.2496,  ..., -0.5117,  0.1453,  0.6470],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:14:42 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:14:42 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 02:15:13 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 02:15:46 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 02:16:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7405e-03,  2.0523e-03, -1.4763e-03,  ...,  4.2772e-04,
         -2.5711e-03,  1.8578e-03],
        [-2.8839e-03,  1.3695e-03, -8.3733e-04,  ...,  1.4858e-03,
         -3.0708e-04,  1.7595e-04],
        [ 1.5240e-03, -2.9612e-04, -6.2895e-04,  ..., -2.1572e-03,
         -2.6655e-04, -8.7595e-04],
        ...,
        [ 1.0812e-04,  6.6519e-04, -7.4673e-04,  ..., -7.9536e-04,
         -2.9716e-03,  7.3814e-04],
        [-6.6757e-04,  1.6489e-03, -8.2397e-04,  ...,  1.5564e-03,
          1.6880e-03, -1.2827e-03],
        [ 3.7313e-05, -1.3657e-03,  9.2554e-04,  ...,  4.3702e-04,
         -1.7786e-03, -2.2781e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0175e-01,  4.8065e-04,  9.4299e-03,  ..., -4.4861e-03,
          2.3479e-03, -4.6768e-03],
        [ 6.6757e-03, -8.6670e-02,  2.1172e-03,  ..., -6.9466e-03,
          8.6899e-03,  1.2527e-02],
        [-3.7746e-03, -3.3913e-03, -8.6609e-02,  ..., -2.8172e-03,
          7.7095e-03,  4.3411e-03],
        ...,
        [ 1.6108e-03,  1.7395e-03,  6.8893e-03,  ..., -8.2825e-02,
         -9.9945e-03,  2.6398e-03],
        [-3.2425e-05, -4.4212e-03, -4.8637e-05,  ...,  5.8632e-03,
         -9.1736e-02, -1.4229e-03],
        [ 2.7332e-03,  9.3536e-03, -2.3613e-03,  ..., -6.5956e-03,
         -3.8223e-03, -9.3018e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0915, -0.0072,  0.0081,  ..., -0.0016, -0.0040, -0.0011],
        [-0.0092, -0.1005,  0.0032,  ..., -0.0066, -0.0013,  0.0006],
        [-0.0041,  0.0013, -0.0927,  ..., -0.0003,  0.0071,  0.0073],
        ...,
        [-0.0037, -0.0020,  0.0023,  ..., -0.0836,  0.0067,  0.0057],
        [-0.0013, -0.0026,  0.0032,  ...,  0.0006, -0.0991,  0.0064],
        [ 0.0049,  0.0039,  0.0063,  ..., -0.0094, -0.0072, -0.1018]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:16:21 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 02:16:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6499,  0.8999,  1.7344,  ...,  0.5889, -0.2009, -0.2385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7466,  1.0938,  0.1899,  ..., -0.9990,  0.1112,  0.8867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4607,  0.6870,  1.7705,  ...,  0.5059,  0.9702, -0.3784],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2139,  0.4573,  0.0721,  ..., -0.0154,  0.0874,  0.2471],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:16:21 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:16:21 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 02:16:56 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 02:17:33 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 02:18:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.3970e-03,  2.2769e-04,  4.4098e-03,  ...,  9.5654e-04,
          1.8768e-03,  1.0329e-04],
        [ 5.0011e-03, -8.0109e-03,  3.6430e-03,  ..., -1.5478e-03,
          2.2392e-03, -1.2660e-04],
        [-1.7776e-03,  1.5087e-03, -4.6539e-03,  ..., -1.9836e-03,
         -1.7214e-04,  9.8133e-04],
        ...,
        [ 2.3365e-03, -1.3161e-03,  1.4794e-04,  ..., -3.9291e-03,
         -2.2545e-03,  5.4131e-03],
        [ 2.6016e-03, -3.6831e-03,  1.0881e-03,  ..., -2.2221e-03,
         -2.2087e-03, -1.3313e-03],
        [ 1.3475e-03,  3.2902e-05,  2.5005e-03,  ...,  1.4334e-03,
         -2.4796e-03, -3.2163e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.9956e-02,  9.2239e-03, -5.8517e-03,  ...,  3.4637e-03,
          2.3689e-03,  1.2684e-03],
        [ 6.9199e-03, -8.4290e-02,  4.5776e-04,  ...,  1.1429e-02,
         -7.3586e-03,  4.5776e-04],
        [ 9.8190e-03,  1.1108e-02, -7.6294e-02,  ...,  1.5915e-02,
         -2.9144e-03,  8.5220e-03],
        ...,
        [ 1.4297e-02, -6.5880e-03, -1.6384e-03,  ..., -7.7332e-02,
         -2.2583e-03,  6.0916e-05],
        [-8.2397e-03,  1.3687e-02,  7.2250e-03,  ..., -7.2250e-03,
         -7.8186e-02, -6.0654e-03],
        [-2.5139e-03,  8.8043e-03,  4.8542e-04,  ..., -8.1329e-03,
         -5.8289e-03, -9.1003e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0952, -0.0002, -0.0044,  ...,  0.0015,  0.0039,  0.0020],
        [ 0.0010, -0.1007, -0.0041,  ...,  0.0033, -0.0060,  0.0017],
        [ 0.0041, -0.0062, -0.1030,  ...,  0.0055,  0.0016, -0.0065],
        ...,
        [ 0.0075,  0.0002,  0.0047,  ..., -0.0987,  0.0040, -0.0107],
        [-0.0010, -0.0031, -0.0057,  ...,  0.0074, -0.0993, -0.0019],
        [-0.0025,  0.0024, -0.0104,  ..., -0.0093,  0.0051, -0.1110]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:18:10 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 02:18:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2981,  1.0176,  1.5791,  ...,  0.1455,  0.6792, -0.2394],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6279,  0.7593,  0.2180,  ..., -0.4990,  0.1400,  0.6255],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0986,  0.9600,  2.2168,  ...,  0.8560,  1.6631, -0.0171],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8906,  0.4790,  0.4023,  ...,  0.3315,  0.3594, -0.0466],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:18:11 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:18:11 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 02:18:49 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 02:19:24 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 02:20:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.3678e-03, -5.6505e-04, -1.8501e-03,  ..., -4.9925e-04,
         -2.4776e-03,  5.8842e-04],
        [ 2.3117e-03, -1.5926e-03, -4.1771e-04,  ...,  2.4281e-03,
          9.6226e-04, -3.7098e-04],
        [ 3.5667e-04, -1.2121e-03, -2.6627e-03,  ..., -1.0490e-03,
         -2.6226e-04,  2.8038e-04],
        ...,
        [ 2.9964e-03,  4.0970e-03,  2.0027e-03,  ..., -3.4676e-03,
          1.8597e-03,  3.4447e-03],
        [-2.8396e-04,  4.8256e-04, -3.2539e-03,  ...,  9.8705e-04,
         -6.4087e-04, -6.8247e-05],
        [ 4.8208e-04, -1.3809e-03,  1.6994e-03,  ..., -3.9577e-04,
          4.0131e-03, -3.7079e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0965,  0.0031,  0.0036,  ..., -0.0095,  0.0088,  0.0097],
        [ 0.0036, -0.0790, -0.0132,  ..., -0.0020, -0.0056,  0.0028],
        [-0.0097, -0.0073, -0.0707,  ...,  0.0118,  0.0057, -0.0097],
        ...,
        [-0.0117, -0.0003,  0.0091,  ..., -0.0679,  0.0015, -0.0018],
        [ 0.0162, -0.0089, -0.0115,  ...,  0.0022, -0.0771, -0.0046],
        [ 0.0021, -0.0056,  0.0007,  ...,  0.0013, -0.0047, -0.0742]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0945,  0.0028,  0.0066,  ..., -0.0064, -0.0082, -0.0055],
        [ 0.0012, -0.0851, -0.0093,  ...,  0.0023,  0.0046, -0.0116],
        [ 0.0081,  0.0033, -0.0883,  ...,  0.0074,  0.0002,  0.0076],
        ...,
        [-0.0032, -0.0057,  0.0020,  ..., -0.0916,  0.0066,  0.0014],
        [ 0.0026,  0.0036, -0.0008,  ...,  0.0112, -0.0828, -0.0057],
        [-0.0006, -0.0089,  0.0052,  ..., -0.0040, -0.0018, -0.0784]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:20:05 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 02:20:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3987,  0.5942,  1.4229,  ...,  0.3955,  0.7954, -0.3577],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.1416,  0.4387,  0.0561,  ..., -0.0132,  0.0760,  0.2190],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5498,  1.2715,  2.9355,  ...,  0.5234,  1.4707, -0.3884],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7222,  0.1973,  0.2939,  ..., -0.0991,  0.2683,  0.4680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:20:05 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:20:05 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 02:20:47 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 02:21:28 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 02:22:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3933e-03, -9.7275e-04, -1.9169e-04,  ..., -3.3522e-04,
          1.2655e-03, -3.9291e-03],
        [-2.0409e-04, -1.7805e-03,  3.1109e-03,  ..., -2.3594e-03,
         -1.4362e-03, -2.2640e-03],
        [-2.7990e-04, -1.0262e-03,  5.0449e-04,  ..., -8.1730e-04,
         -1.8063e-03, -1.7433e-03],
        ...,
        [-9.7656e-04, -1.4048e-03,  1.4534e-03,  ...,  7.9632e-04,
         -1.1091e-03,  1.4629e-03],
        [ 2.7962e-03, -9.0504e-04, -8.8215e-06,  ..., -1.6317e-03,
         -6.5346e-03, -3.4666e-04],
        [ 3.3474e-03, -2.1446e-04,  1.2798e-03,  ..., -2.3007e-04,
          2.4395e-03, -1.4153e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.4585e-02, -6.1188e-03, -6.8378e-04,  ..., -1.8854e-03,
         -6.9351e-03, -1.0796e-02],
        [ 1.0977e-03, -8.3374e-02,  1.8280e-02,  ...,  2.2545e-03,
          8.1024e-03,  5.9319e-03],
        [-7.2632e-03,  8.0729e-04, -6.1127e-02,  ..., -1.2321e-02,
         -1.1415e-03, -6.7101e-03],
        ...,
        [ 1.4210e-04, -5.1260e-05, -6.0654e-03,  ..., -8.5022e-02,
          2.1935e-04, -8.8043e-03],
        [ 1.1948e-02,  9.7046e-03,  6.9962e-03,  ..., -1.9440e-02,
         -5.8746e-02,  3.5782e-03],
        [ 6.5308e-03,  7.5150e-04, -3.7975e-03,  ..., -8.2550e-03,
          5.9814e-03, -6.8542e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1004,  0.0044, -0.0087,  ...,  0.0003,  0.0097, -0.0068],
        [ 0.0038, -0.1274,  0.0099,  ..., -0.0098, -0.0015,  0.0138],
        [-0.0043, -0.0022, -0.1190,  ..., -0.0063, -0.0119,  0.0072],
        ...,
        [ 0.0072,  0.0093, -0.0033,  ..., -0.1080, -0.0035,  0.0024],
        [-0.0074,  0.0055, -0.0047,  ..., -0.0021, -0.0978,  0.0076],
        [-0.0102,  0.0026, -0.0072,  ...,  0.0026,  0.0047, -0.1231]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:22:11 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 02:22:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0961,  0.7124,  1.5029,  ...,  0.5654,  1.1660, -0.0347],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7876,  0.4202,  0.2827,  ...,  0.2498,  0.2869, -0.0562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.2178,  1.5273,  3.2012,  ...,  0.7480,  1.3984, -1.3799],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7515,  0.6304,  0.9639,  ...,  0.0725,  0.1606,  0.5747],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:22:11 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:22:11 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 02:22:58 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 02:23:28 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 02:24:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0058,  0.0008, -0.0002,  ..., -0.0017, -0.0027, -0.0015],
        [ 0.0019, -0.0017,  0.0008,  ...,  0.0005, -0.0022,  0.0032],
        [-0.0011, -0.0003,  0.0015,  ...,  0.0009,  0.0010,  0.0007],
        ...,
        [ 0.0009, -0.0043, -0.0007,  ...,  0.0031, -0.0008,  0.0010],
        [-0.0034,  0.0032,  0.0018,  ...,  0.0008, -0.0034,  0.0004],
        [ 0.0021, -0.0016,  0.0028,  ...,  0.0005,  0.0032,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0947, -0.0089, -0.0111,  ..., -0.0080, -0.0075,  0.0141],
        [-0.0004, -0.1116, -0.0133,  ...,  0.0089, -0.0060, -0.0003],
        [-0.0029,  0.0041, -0.1046,  ...,  0.0231, -0.0095, -0.0026],
        ...,
        [-0.0098,  0.0071,  0.0191,  ..., -0.1106, -0.0107,  0.0141],
        [ 0.0008,  0.0020,  0.0144,  ...,  0.0075, -0.1126,  0.0082],
        [-0.0032, -0.0067, -0.0010,  ..., -0.0102, -0.0070, -0.1063]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6699e-01, -1.9760e-03,  8.1635e-03,  ...,  3.8528e-04,
         -4.2915e-06,  9.7847e-04],
        [ 2.7657e-05, -1.6272e-01, -1.2817e-02,  ...,  1.1780e-02,
          4.6730e-03, -4.2915e-04],
        [-3.7193e-03, -3.2444e-03, -1.4087e-01,  ...,  8.3771e-03,
         -4.9248e-03, -6.9046e-03],
        ...,
        [-2.4414e-03,  2.3193e-02,  1.6342e-02,  ..., -1.6016e-01,
          3.8948e-03,  7.1945e-03],
        [ 7.8201e-04,  2.6760e-03,  7.2594e-03,  ..., -8.1635e-03,
         -1.6309e-01, -1.7357e-03],
        [-6.1798e-03,  6.7406e-03,  6.2637e-03,  ..., -1.4244e-02,
         -1.1368e-03, -1.4697e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:24:14 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 02:24:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3750,  0.8516,  1.8623,  ...,  0.3418,  0.9570, -0.3162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5942,  0.1497,  0.1957,  ..., -0.0662,  0.2029,  0.3528],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2480,  2.2285,  3.9258,  ...,  0.8525,  1.6475, -1.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4114,  0.1990,  0.8140,  ..., -0.1676, -0.0044,  0.5537],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:24:14 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:24:14 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 02:25:03 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 02:25:46 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 02:26:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.7518e-03,  2.6131e-04,  1.7719e-03,  ..., -9.9897e-05,
          2.8372e-04,  1.1959e-03],
        [ 4.1890e-04,  7.4720e-04,  2.6512e-03,  ..., -2.1124e-04,
          5.0187e-05, -1.1044e-03],
        [ 1.2369e-03, -1.9264e-03, -2.7008e-03,  ...,  1.6403e-03,
          1.1082e-03, -4.0722e-04],
        ...,
        [ 4.1580e-03, -2.7523e-03,  2.9907e-03,  ..., -5.4474e-03,
         -1.3466e-03, -5.5504e-04],
        [ 6.2180e-04, -3.1548e-03, -7.6675e-04,  ...,  4.3297e-03,
         -3.0060e-03,  2.0027e-03],
        [-1.5411e-03, -3.0003e-03, -1.4515e-03,  ...,  4.0779e-03,
         -6.1321e-04, -4.5395e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1077,  0.0137,  0.0173,  ...,  0.0080, -0.0068, -0.0161],
        [ 0.0016, -0.1078,  0.0149,  ...,  0.0106,  0.0057, -0.0129],
        [ 0.0072, -0.0022, -0.1003,  ...,  0.0007, -0.0095, -0.0039],
        ...,
        [ 0.0029,  0.0013, -0.0043,  ..., -0.1041,  0.0116, -0.0236],
        [ 0.0056, -0.0099,  0.0067,  ...,  0.0072, -0.0940,  0.0033],
        [ 0.0125,  0.0167, -0.0008,  ...,  0.0062,  0.0071, -0.0879]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1002,  0.0016,  0.0062,  ...,  0.0098, -0.0058, -0.0013],
        [ 0.0096, -0.1013, -0.0002,  ..., -0.0089, -0.0151,  0.0009],
        [-0.0085,  0.0026, -0.1060,  ...,  0.0112, -0.0007,  0.0130],
        ...,
        [ 0.0050, -0.0014,  0.0081,  ..., -0.0864,  0.0055, -0.0076],
        [ 0.0034, -0.0169, -0.0069,  ...,  0.0110, -0.1009,  0.0010],
        [ 0.0088, -0.0025,  0.0052,  ...,  0.0066, -0.0041, -0.1009]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:26:38 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 02:26:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7983,  0.9678,  1.8779,  ...,  0.4148,  0.8433, -0.8975],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5864,  0.4695,  0.6470,  ...,  0.0199,  0.0989,  0.4468],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5015,  1.7197,  3.3984,  ...,  0.6924,  2.0195,  0.0850],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6934,  0.3599,  1.1357,  ...,  0.1754,  0.2281,  0.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:26:38 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:26:38 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 02:27:29 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 02:28:20 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 02:29:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.9035e-03, -9.3174e-04,  1.4858e-03,  ..., -2.4281e-03,
          9.7656e-04,  9.4509e-04],
        [-1.9407e-03,  6.6681e-03, -9.4795e-04,  ...,  2.2793e-03,
          1.7405e-03,  3.9291e-04],
        [-2.9716e-03,  6.7043e-04,  9.2010e-03,  ..., -1.0815e-03,
          5.0926e-03, -3.3784e-04],
        ...,
        [ 6.2180e-04,  4.4174e-03,  2.2526e-03,  ...,  1.0315e-02,
         -2.0638e-03,  7.2975e-03],
        [-8.3542e-04,  1.4124e-03, -1.5516e-03,  ..., -5.8472e-05,
          1.1658e-02,  2.5082e-03],
        [-2.9869e-03, -2.9221e-03,  4.4823e-03,  ...,  8.7833e-04,
         -3.7632e-03,  5.0240e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1608, -0.0076,  0.0002,  ..., -0.0154, -0.0072, -0.0067],
        [ 0.0087, -0.1489, -0.0126,  ..., -0.0080,  0.0057, -0.0130],
        [-0.0154, -0.0183, -0.1475,  ..., -0.0073, -0.0003, -0.0133],
        ...,
        [-0.0061, -0.0187,  0.0003,  ..., -0.1353,  0.0077,  0.0023],
        [-0.0009, -0.0020, -0.0015,  ...,  0.0073, -0.1573,  0.0063],
        [-0.0079, -0.0105, -0.0162,  ..., -0.0122,  0.0050, -0.1410]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.8787e-01,  1.5732e-02,  1.6052e-02,  ..., -9.6893e-03,
         -6.2027e-03, -5.4245e-03],
        [ 3.8834e-03, -2.1777e-01, -1.6617e-02,  ..., -4.1428e-03,
          1.1879e-02, -1.8301e-03],
        [ 1.9073e-04,  4.8981e-03, -1.9617e-01,  ...,  7.2899e-03,
          6.8207e-03, -1.4252e-02],
        ...,
        [-4.4708e-03, -1.7033e-03, -3.4294e-03,  ..., -2.2388e-01,
          1.2878e-02, -2.5139e-03],
        [-4.0054e-03,  1.5078e-03, -7.3509e-03,  ...,  1.7502e-02,
         -2.0361e-01, -4.3221e-03],
        [-1.6232e-03, -7.9880e-03,  6.9714e-04,  ..., -1.3018e-03,
         -2.9564e-04, -2.0398e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:29:14 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 02:29:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1924,  1.4102,  2.3223,  ...,  0.5234,  1.0254, -0.7163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3608,  0.1460,  0.5718,  ..., -0.1362, -0.0122,  0.4041],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4934,  2.1094,  3.6602,  ...,  0.9028,  2.9160, -0.1965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3196,  0.4897,  1.8438,  ..., -0.6958,  1.0918,  1.5010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:29:14 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:29:14 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 02:30:10 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 02:31:05 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 02:32:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0033,  0.0017,  0.0018,  ..., -0.0018, -0.0016, -0.0022],
        [-0.0019, -0.0027, -0.0001,  ..., -0.0027, -0.0027, -0.0014],
        [-0.0005,  0.0035, -0.0042,  ...,  0.0001, -0.0023, -0.0055],
        ...,
        [ 0.0007, -0.0016, -0.0024,  ..., -0.0056,  0.0024,  0.0014],
        [-0.0009,  0.0008, -0.0015,  ..., -0.0034, -0.0028, -0.0015],
        [ 0.0027,  0.0023,  0.0027,  ..., -0.0021,  0.0051, -0.0077]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0747,  0.0083,  0.0207,  ...,  0.0069, -0.0056,  0.0029],
        [ 0.0029, -0.0795, -0.0008,  ..., -0.0080, -0.0078,  0.0039],
        [-0.0029, -0.0028, -0.0774,  ...,  0.0027,  0.0035, -0.0027],
        ...,
        [-0.0070,  0.0002,  0.0051,  ..., -0.0625, -0.0018, -0.0036],
        [-0.0020, -0.0023,  0.0049,  ...,  0.0036, -0.0760,  0.0163],
        [-0.0088, -0.0067,  0.0115,  ..., -0.0090,  0.0009, -0.0745]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0850, -0.0045,  0.0115,  ..., -0.0071, -0.0046,  0.0071],
        [ 0.0011, -0.0717, -0.0121,  ...,  0.0016,  0.0147,  0.0045],
        [-0.0049,  0.0056, -0.0843,  ..., -0.0007, -0.0132,  0.0103],
        ...,
        [-0.0020, -0.0094, -0.0052,  ..., -0.0695,  0.0061,  0.0001],
        [-0.0069,  0.0047,  0.0019,  ...,  0.0043, -0.0738,  0.0085],
        [ 0.0049,  0.0046,  0.0030,  ...,  0.0045,  0.0106, -0.0750]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:32:03 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 02:32:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3176,  1.0010,  1.9287,  ...,  0.3752,  1.2041,  0.0237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5088,  0.2227,  0.7593,  ...,  0.1010,  0.1656,  0.3601],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4175,  1.9482,  3.0547,  ...,  0.5190,  3.0566,  0.2065],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9131, -0.4585,  0.9365,  ..., -0.2559,  2.1426,  1.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:32:03 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:32:03 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 02:33:02 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 02:34:01 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 02:35:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.0501e-03,  1.1292e-03, -1.4458e-03,  ..., -9.8515e-04,
          3.4542e-03, -4.7607e-03],
        [-7.3738e-03,  2.0599e-03, -3.1204e-03,  ...,  9.2506e-05,
          4.3297e-04, -5.2338e-03],
        [-7.3195e-04, -5.5504e-03, -8.7509e-03,  ..., -1.3027e-03,
         -7.3195e-04, -3.3607e-03],
        ...,
        [-5.2490e-03, -5.3062e-03,  1.3247e-03,  ...,  1.7872e-03,
          2.1610e-03,  9.9564e-03],
        [ 5.0507e-03, -1.1473e-03,  5.3368e-03,  ...,  1.9836e-03,
         -1.5274e-02, -2.8915e-03],
        [ 1.4706e-03,  7.2327e-03, -1.2808e-03,  ..., -7.0381e-03,
         -2.7409e-03, -6.2447e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1152,  0.0015, -0.0079,  ..., -0.0095, -0.0071,  0.0137],
        [-0.0080, -0.1210,  0.0010,  ...,  0.0070,  0.0170,  0.0056],
        [ 0.0144, -0.0087, -0.1063,  ...,  0.0226,  0.0082, -0.0001],
        ...,
        [-0.0127, -0.0095,  0.0090,  ..., -0.1092, -0.0063,  0.0030],
        [-0.0041,  0.0052,  0.0120,  ...,  0.0038, -0.1223,  0.0089],
        [ 0.0036, -0.0039, -0.0066,  ..., -0.0158,  0.0140, -0.1128]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2720e-01,  8.1024e-03,  7.1869e-03,  ...,  4.4022e-03,
          1.2062e-02,  1.0780e-02],
        [-1.1642e-02, -1.4941e-01,  3.1433e-03,  ...,  5.1346e-03,
          1.7567e-03,  1.3283e-02],
        [ 1.1902e-02,  4.6501e-03, -1.3318e-01,  ..., -8.6594e-04,
         -2.8954e-03, -1.1154e-02],
        ...,
        [-5.9814e-03, -4.0627e-03,  1.6022e-04,  ..., -1.3745e-01,
         -3.3836e-03,  4.7684e-03],
        [ 1.3443e-02,  1.5137e-02,  8.3733e-04,  ...,  1.2573e-02,
         -1.5259e-01,  1.6632e-02],
        [-2.1706e-03,  7.7009e-05,  1.2802e-02,  ..., -4.3488e-03,
          1.7395e-02, -1.4429e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:35:02 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 02:35:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3015,  1.1133,  1.8350,  ...,  0.4556,  1.6074, -0.1696],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2157,  0.2712,  1.0000,  ..., -0.4153,  0.6768,  0.8462],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3274,  1.6533,  3.4102,  ...,  0.4436,  3.0391,  0.4619],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5498, -0.7886,  0.8130,  ..., -0.7334,  1.1973,  1.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:35:02 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:35:02 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 02:35:59 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 02:36:59 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 02:37:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0027, -0.0006,  0.0022,  ..., -0.0043, -0.0107,  0.0011],
        [-0.0007,  0.0082, -0.0049,  ..., -0.0027,  0.0052,  0.0034],
        [-0.0045, -0.0021,  0.0069,  ..., -0.0031, -0.0037,  0.0018],
        ...,
        [ 0.0105, -0.0014, -0.0060,  ...,  0.0130, -0.0048, -0.0005],
        [ 0.0004, -0.0035,  0.0010,  ...,  0.0011,  0.0139,  0.0048],
        [ 0.0118,  0.0054, -0.0087,  ..., -0.0025,  0.0013,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0835,  0.0119, -0.0027,  ..., -0.0056,  0.0040, -0.0038],
        [ 0.0057, -0.0813, -0.0116,  ...,  0.0036,  0.0004, -0.0062],
        [ 0.0024, -0.0008, -0.0851,  ...,  0.0059,  0.0002,  0.0062],
        ...,
        [-0.0051, -0.0120,  0.0047,  ..., -0.0687,  0.0144, -0.0057],
        [-0.0042,  0.0134, -0.0054,  ...,  0.0061, -0.0881,  0.0034],
        [ 0.0033,  0.0190,  0.0054,  ..., -0.0034, -0.0159, -0.0832]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2189e-01, -3.7289e-03, -1.2604e-02,  ..., -2.0386e-02,
          1.2245e-03, -7.2479e-03],
        [ 6.8741e-03, -1.1420e-01, -1.1078e-02,  ...,  1.0872e-02,
          8.7738e-05,  1.5976e-02],
        [ 6.0616e-03, -7.3891e-03, -1.0394e-01,  ...,  1.2703e-02,
          2.3994e-03, -7.8583e-03],
        ...,
        [-1.2581e-02, -9.3384e-03, -1.5144e-03,  ..., -1.2408e-01,
          9.5901e-03,  9.2316e-04],
        [-6.0577e-03,  5.3940e-03, -1.1047e-02,  ...,  6.6071e-03,
         -1.1072e-01,  5.0583e-03],
        [-1.3039e-02,  4.2953e-03, -1.3752e-03,  ..., -1.3275e-02,
          4.0512e-03, -1.1047e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:38:02 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 02:38:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2222,  0.9365,  1.4395,  ...,  0.2357,  1.5020,  0.0663],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5356, -0.2925,  0.5068,  ..., -0.1523,  1.2070,  0.6772],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5625,  2.5508,  3.2754,  ...,  1.0293,  3.4023,  0.5322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1631, -0.9102,  0.1958,  ..., -0.1001,  1.0938,  1.1611],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:38:02 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:38:02 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 02:38:56 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 02:39:58 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 02:40:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.4053e-04,  5.0259e-04,  8.5068e-04,  ..., -6.4230e-04,
         -2.2869e-03, -2.0390e-03],
        [ 8.9741e-04,  1.5914e-04,  2.2907e-03,  ..., -2.5139e-03,
          4.0150e-04, -1.0748e-03],
        [ 2.8896e-03, -1.0462e-03, -6.8963e-05,  ...,  3.1319e-03,
         -5.7554e-04,  1.7366e-03],
        ...,
        [-3.7742e-04, -9.8133e-04, -7.0477e-04,  ..., -1.5097e-03,
         -2.0390e-03, -8.6880e-04],
        [ 1.1778e-03,  1.3151e-03, -1.1277e-04,  ...,  1.4172e-03,
         -1.4191e-03,  1.8606e-03],
        [ 1.1053e-03,  9.5463e-04,  7.9966e-04,  ...,  2.4967e-03,
          1.2517e-05,  3.3379e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.5266e-02, -8.7204e-03, -1.4435e-02,  ..., -7.2632e-03,
          2.3594e-03,  1.4145e-02],
        [-1.1391e-02, -9.6802e-02, -7.4844e-03,  ...,  7.1716e-04,
         -2.4776e-03, -1.0048e-02],
        [-4.5280e-03,  3.5381e-04, -9.5703e-02,  ...,  3.2272e-03,
         -6.8436e-03,  2.9259e-03],
        ...,
        [ 8.7280e-03,  1.3069e-02,  8.1940e-03,  ..., -8.5632e-02,
          9.8648e-03,  1.4366e-02],
        [ 1.9722e-03, -9.6359e-03, -1.1299e-02,  ...,  6.9809e-03,
         -9.6924e-02,  5.5313e-03],
        [-3.0804e-04,  6.0921e-03, -2.9564e-05,  ...,  2.0447e-03,
         -2.4548e-03, -8.7830e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0376e-01,  1.4009e-03, -1.2001e-02,  ..., -4.5443e-04,
         -1.3313e-02,  8.8577e-03],
        [-3.7918e-03, -1.2268e-01, -7.5111e-03,  ...,  5.2528e-03,
          3.4637e-03,  1.9855e-03],
        [-3.4122e-03, -7.6370e-03, -1.2018e-01,  ..., -7.6866e-03,
         -3.9291e-04,  9.2030e-05],
        ...,
        [ 7.2174e-03,  1.1665e-02, -7.2021e-03,  ..., -1.1035e-01,
         -5.2452e-04, -2.3804e-03],
        [ 6.3705e-03, -6.1378e-03, -8.5754e-03,  ...,  1.1765e-02,
         -1.1926e-01,  5.0049e-03],
        [ 1.4145e-02,  9.0027e-03,  7.8964e-04,  ..., -1.7975e-02,
          1.6861e-02, -1.1731e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:41:02 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 02:41:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2078,  0.8164,  1.5498,  ...,  0.2068,  1.4688,  0.1963],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3496, -0.4375,  0.4077,  ..., -0.3989,  0.6611,  0.5332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2393,  2.1953,  3.9785,  ...,  0.5762,  3.2793,  1.1309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1816, -1.1104,  0.5186,  ...,  0.1022,  1.2305,  0.7466],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:41:02 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:41:02 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 02:42:06 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 02:43:11 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 02:44:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.5520e-03, -5.0621e-03, -3.3073e-03,  ..., -4.6387e-03,
          5.0449e-04,  4.8876e-04],
        [-3.9978e-03, -4.4556e-03,  5.4836e-04,  ...,  5.5199e-03,
          2.5234e-03,  9.9564e-04],
        [-4.6043e-03,  3.6507e-03, -8.7128e-03,  ..., -2.5120e-03,
         -2.9144e-03, -2.5501e-03],
        ...,
        [ 4.8676e-03, -4.3178e-04, -4.1466e-03,  ..., -1.1086e-02,
         -4.3831e-03, -3.1300e-03],
        [ 2.2907e-03,  1.1244e-03,  9.4128e-04,  ..., -6.7115e-05,
         -1.1375e-02, -4.7135e-04],
        [-1.5450e-03,  6.0997e-03, -2.1954e-03,  ..., -5.3596e-03,
         -7.2002e-04, -1.7807e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0566, -0.0037,  0.0161,  ..., -0.0100, -0.0112, -0.0053],
        [-0.0149, -0.0748, -0.0168,  ...,  0.0010,  0.0082, -0.0015],
        [ 0.0130,  0.0145, -0.0675,  ..., -0.0108, -0.0100, -0.0012],
        ...,
        [ 0.0005,  0.0072,  0.0017,  ..., -0.0575, -0.0082, -0.0034],
        [-0.0139,  0.0170, -0.0016,  ...,  0.0038, -0.0627,  0.0026],
        [ 0.0013,  0.0058,  0.0083,  ...,  0.0078, -0.0065, -0.0593]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0859,  0.0151, -0.0020,  ..., -0.0071,  0.0088,  0.0012],
        [-0.0035, -0.0848, -0.0125,  ...,  0.0012,  0.0018, -0.0045],
        [ 0.0081,  0.0021, -0.0869,  ..., -0.0035, -0.0209, -0.0117],
        ...,
        [-0.0332, -0.0013, -0.0019,  ..., -0.0937, -0.0130,  0.0036],
        [ 0.0076,  0.0235,  0.0005,  ...,  0.0052, -0.0912,  0.0065],
        [ 0.0010, -0.0019,  0.0051,  ...,  0.0013, -0.0053, -0.0877]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:44:15 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 02:44:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2820,  1.1846,  1.4512,  ...,  0.4521,  1.5781,  0.2043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5933, -0.4553,  0.0951,  ..., -0.0511,  0.5498,  0.5337],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0759,  1.8018,  3.8359,  ...,  0.7227,  3.3730,  1.2988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.5645, -0.7676,  1.0469,  ...,  0.4272,  1.2803,  1.5176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:44:15 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:44:15 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 02:45:22 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 02:46:31 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 02:47:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0110, -0.0039,  0.0029,  ...,  0.0064, -0.0007,  0.0057],
        [-0.0007, -0.0137, -0.0023,  ...,  0.0049,  0.0055,  0.0003],
        [ 0.0032, -0.0007, -0.0203,  ...,  0.0019, -0.0003, -0.0014],
        ...,
        [-0.0031,  0.0040,  0.0042,  ..., -0.0157,  0.0039,  0.0018],
        [-0.0002,  0.0105, -0.0003,  ...,  0.0019, -0.0198, -0.0026],
        [ 0.0060,  0.0007, -0.0031,  ..., -0.0001, -0.0006, -0.0148]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0480,  0.0051,  0.0019,  ..., -0.0011,  0.0076,  0.0136],
        [-0.0097, -0.0575,  0.0144,  ...,  0.0019,  0.0025, -0.0154],
        [ 0.0028,  0.0042, -0.0553,  ..., -0.0164,  0.0149,  0.0026],
        ...,
        [ 0.0121, -0.0087, -0.0037,  ..., -0.0538, -0.0030, -0.0063],
        [ 0.0127, -0.0069,  0.0013,  ..., -0.0119, -0.0589, -0.0006],
        [-0.0147,  0.0037,  0.0138,  ..., -0.0110, -0.0014, -0.0489]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0643, -0.0038, -0.0161,  ..., -0.0058,  0.0017,  0.0121],
        [-0.0109, -0.0771, -0.0179,  ..., -0.0067, -0.0057, -0.0036],
        [ 0.0101, -0.0131, -0.0812,  ...,  0.0044,  0.0083, -0.0047],
        ...,
        [ 0.0084, -0.0010,  0.0187,  ..., -0.0568,  0.0138, -0.0011],
        [ 0.0086, -0.0093, -0.0074,  ...,  0.0124, -0.0853, -0.0035],
        [-0.0106, -0.0047, -0.0057,  ..., -0.0088,  0.0100, -0.0818]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:47:40 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 02:47:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1256,  0.9463,  1.6553,  ...,  0.2408,  1.4375,  0.4507],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5869, -0.5200,  0.2291,  ...,  0.0470,  0.6006,  0.3196],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4109,  2.4336,  3.3438,  ...,  1.1523,  3.4219,  1.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.6660, -0.8081,  0.2017,  ..., -0.3320,  1.8027,  2.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:47:40 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:47:41 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 02:48:51 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 02:49:59 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 02:51:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.0142e-03,  1.5783e-04,  3.9177e-03,  ...,  1.0252e-03,
          9.4032e-04, -3.1304e-04],
        [-5.1117e-03,  1.9627e-03,  2.2392e-03,  ..., -8.1253e-04,
         -3.4332e-04, -4.3335e-03],
        [-1.1530e-03, -8.7967e-03,  1.0204e-03,  ...,  5.5428e-03,
         -1.0786e-03,  1.1978e-03],
        ...,
        [ 2.3842e-03,  4.8409e-03, -5.8250e-03,  ..., -9.7752e-04,
         -4.6501e-03, -7.4997e-03],
        [ 1.8349e-03,  3.8853e-03,  7.0419e-03,  ..., -2.2144e-03,
         -2.7618e-03,  1.1520e-03],
        [-1.5631e-03, -4.2992e-03,  6.1989e-06,  ...,  6.7558e-03,
         -7.1955e-04, -3.1509e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.8289e-02,  6.7711e-03, -1.1040e-02,  ...,  1.8253e-03,
          7.2956e-04, -1.9135e-02],
        [ 1.6083e-02, -7.5989e-02, -6.6452e-03,  ..., -1.0933e-02,
         -1.5572e-02,  3.3531e-03],
        [-9.3460e-05, -5.1041e-03, -4.6448e-02,  ..., -1.3971e-04,
         -1.6708e-03, -1.5030e-03],
        ...,
        [ 2.0084e-03, -5.0430e-03, -1.8539e-02,  ..., -5.2979e-02,
         -8.2397e-03,  5.2490e-03],
        [-9.0027e-03, -2.7237e-03, -3.1109e-03,  ...,  7.2975e-03,
         -6.2317e-02,  2.2141e-02],
        [ 6.5613e-04,  4.6463e-03, -7.7209e-03,  ...,  6.2904e-03,
          6.6471e-04, -6.5979e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0793, -0.0045,  0.0035,  ...,  0.0033, -0.0007,  0.0024],
        [ 0.0038, -0.0929,  0.0087,  ..., -0.0109,  0.0027,  0.0227],
        [ 0.0009,  0.0093, -0.0793,  ..., -0.0185, -0.0010, -0.0088],
        ...,
        [-0.0053, -0.0038, -0.0015,  ..., -0.0914,  0.0024,  0.0029],
        [ 0.0075, -0.0167, -0.0127,  ...,  0.0017, -0.0771,  0.0003],
        [-0.0140,  0.0192,  0.0009,  ..., -0.0041, -0.0058, -0.0744]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:51:07 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 02:51:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0395,  0.7427,  1.5225,  ...,  0.2913,  1.4277,  0.5044],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6973, -0.3367,  0.4192,  ...,  0.1807,  0.5796,  0.6270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1714,  2.1484,  3.2773,  ...,  0.9751,  3.3242,  0.8394],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.5176, -0.6030, -1.2266,  ..., -1.1035,  2.3516,  1.9883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:51:07 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:51:07 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 02:52:12 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 02:53:18 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 02:54:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7052e-03, -5.1460e-03, -9.7427e-03,  ..., -2.7809e-03,
         -3.1452e-03, -5.5046e-03],
        [ 2.3212e-03,  9.2239e-03,  4.2572e-03,  ..., -1.3762e-03,
          5.5790e-04, -4.0894e-03],
        [ 1.7376e-03, -6.7863e-03,  6.1989e-04,  ..., -7.9727e-03,
          4.4346e-05,  1.0231e-02],
        ...,
        [ 4.8294e-03, -9.0942e-03, -9.4299e-03,  ..., -5.5265e-04,
         -5.4359e-05,  1.1497e-02],
        [-2.5845e-03, -2.7466e-03,  1.1635e-02,  ...,  2.5215e-03,
          4.7493e-03, -5.6572e-03],
        [-7.1373e-03,  8.3084e-03,  3.4866e-03,  ...,  1.1902e-03,
         -3.5629e-03,  7.4806e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0353, -0.0034,  0.0020,  ..., -0.0071,  0.0103, -0.0199],
        [ 0.0097, -0.0298, -0.0022,  ..., -0.0045,  0.0075, -0.0131],
        [ 0.0047,  0.0128, -0.0360,  ..., -0.0008,  0.0003,  0.0068],
        ...,
        [-0.0121, -0.0032, -0.0059,  ..., -0.0488,  0.0021,  0.0102],
        [ 0.0062, -0.0098, -0.0197,  ..., -0.0135, -0.0326,  0.0107],
        [-0.0104,  0.0066, -0.0070,  ..., -0.0034, -0.0049, -0.0349]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0538,  0.0027,  0.0062,  ..., -0.0252,  0.0050,  0.0091],
        [ 0.0007, -0.0412, -0.0105,  ..., -0.0036,  0.0083, -0.0123],
        [ 0.0043, -0.0258, -0.0665,  ..., -0.0072,  0.0146,  0.0014],
        ...,
        [-0.0116,  0.0059, -0.0246,  ..., -0.0713,  0.0036, -0.0218],
        [-0.0016, -0.0111, -0.0005,  ..., -0.0019, -0.0406,  0.0248],
        [-0.0033,  0.0157, -0.0018,  ...,  0.0061,  0.0030, -0.0585]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:54:27 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 02:54:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1737,  0.9849,  1.2852,  ...,  0.4639,  1.3662,  0.6021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6489, -0.3208,  0.0573,  ..., -0.1212,  0.6772,  0.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1113,  1.8076,  2.9375,  ...,  0.2710,  3.9258,  0.1440],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.3379, -0.2537, -1.1514,  ..., -0.8994,  2.2637,  2.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:54:27 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:54:27 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 02:55:36 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 02:56:45 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 02:57:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.4625e-05, -4.4823e-04, -1.1530e-03,  ...,  2.7294e-03,
         -2.4452e-03,  2.0618e-03],
        [-9.6359e-03,  1.7910e-03,  5.0468e-03,  ..., -1.3609e-03,
         -2.4629e-04,  6.2656e-04],
        [ 1.3283e-02,  4.6234e-03, -3.0365e-03,  ...,  4.6768e-03,
         -9.7656e-04, -5.8794e-04],
        ...,
        [-2.4915e-04, -1.3361e-03, -1.7405e-04,  ..., -6.9332e-04,
         -2.8400e-03,  2.0275e-03],
        [ 7.1383e-04,  1.0788e-05, -8.2922e-04,  ..., -7.3481e-04,
          3.1776e-03, -1.6003e-03],
        [ 4.7302e-03, -1.0300e-03, -2.7695e-03,  ...,  2.8248e-03,
          3.3998e-04,  4.4327e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0317, -0.0118, -0.0130,  ...,  0.0044, -0.0149, -0.0022],
        [-0.0068, -0.0157,  0.0031,  ..., -0.0014, -0.0083,  0.0002],
        [-0.0036,  0.0111, -0.0252,  ..., -0.0099,  0.0092, -0.0011],
        ...,
        [-0.0031, -0.0047, -0.0155,  ..., -0.0085,  0.0098, -0.0024],
        [-0.0023, -0.0149, -0.0147,  ...,  0.0082, -0.0132,  0.0017],
        [ 0.0042, -0.0084, -0.0097,  ...,  0.0051, -0.0028, -0.0209]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0559,  0.0082,  0.0158,  ...,  0.0094,  0.0117,  0.0015],
        [ 0.0167, -0.0574, -0.0064,  ..., -0.0007, -0.0122,  0.0200],
        [ 0.0015, -0.0161, -0.0573,  ..., -0.0048,  0.0047,  0.0027],
        ...,
        [-0.0001, -0.0075, -0.0197,  ..., -0.0549, -0.0065, -0.0068],
        [ 0.0078,  0.0096, -0.0095,  ..., -0.0154, -0.0485, -0.0243],
        [-0.0034,  0.0136, -0.0097,  ..., -0.0305,  0.0047, -0.0631]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 02:57:56 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 02:57:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0695,  0.8174,  1.2344,  ...,  0.3586,  1.2783,  0.2971],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9585, -0.2377, -0.4673,  ..., -0.4260,  0.8950,  0.7329],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1934,  0.9409,  3.4492,  ..., -0.2671,  3.9844,  0.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.8457, -0.1246, -0.4766,  ..., -1.0674,  2.2441,  2.3926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 02:57:56 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 02:57:56 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 02:59:10 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 03:00:27 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 03:01:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.1035e-05, -5.8031e-04, -2.1720e-04,  ...,  6.0558e-04,
         -9.6321e-04,  4.4632e-04],
        [-2.6512e-03, -4.3392e-04,  7.7724e-04,  ..., -7.5865e-04,
         -1.4424e-05,  5.6839e-04],
        [ 3.3665e-03, -1.8387e-03, -1.8606e-03,  ...,  4.1771e-04,
         -1.6820e-04, -3.5429e-04],
        ...,
        [-4.7588e-04,  7.2813e-04, -4.4775e-04,  ..., -1.8787e-04,
         -9.9277e-04,  2.5630e-04],
        [-9.6512e-04,  1.5907e-03,  8.8215e-04,  ...,  1.2875e-03,
         -1.0481e-03, -6.5374e-04],
        [-2.2964e-03,  1.1516e-04,  1.4257e-03,  ...,  3.7622e-04,
          2.6550e-03,  1.9288e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.7883e-02,  1.1330e-03,  6.8321e-03,  ..., -8.3618e-03,
          5.1346e-03, -3.7231e-03],
        [-1.0536e-02, -4.0649e-02, -7.2479e-05,  ..., -1.3329e-02,
          1.4687e-02, -5.3368e-03],
        [ 4.2496e-03,  6.0158e-03, -2.5299e-02,  ...,  5.8823e-03,
          6.4888e-03, -1.5388e-02],
        ...,
        [ 3.0375e-04, -2.3117e-03, -1.4252e-02,  ..., -1.9455e-02,
          1.3084e-02,  2.1484e-02],
        [-1.3000e-02, -1.2875e-04,  6.5279e-04,  ...,  3.8586e-03,
         -2.7710e-02, -2.3193e-03],
        [-6.8359e-03, -1.1040e-02,  4.8943e-03,  ...,  9.6588e-03,
         -6.7101e-03, -1.2146e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0532,  0.0095, -0.0068,  ...,  0.0048, -0.0106, -0.0002],
        [ 0.0026, -0.0764, -0.0166,  ..., -0.0133, -0.0062,  0.0103],
        [ 0.0082,  0.0064, -0.0549,  ...,  0.0031,  0.0035, -0.0121],
        ...,
        [ 0.0018,  0.0034, -0.0078,  ..., -0.0517,  0.0100,  0.0083],
        [-0.0153, -0.0273,  0.0055,  ...,  0.0028, -0.0580, -0.0034],
        [-0.0002, -0.0022, -0.0054,  ...,  0.0086,  0.0026, -0.0582]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:01:46 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 03:01:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4270,  0.6582,  1.0635,  ...,  0.1034,  1.4902,  0.0217],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9097, -0.0956, -0.4402,  ..., -0.3296,  0.8823,  0.8706],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.5156,  0.6865,  3.8867,  ..., -0.0896,  4.8633,  0.9492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4355,  0.1151, -0.0369,  ..., -1.1240,  2.8906,  2.6309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:01:46 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 03:01:46 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 03:03:03 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 03:04:24 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 03:05:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.6437e-04, -5.1832e-04,  1.1480e-04,  ..., -1.4448e-04,
          6.9141e-04,  4.0007e-04],
        [-7.4577e-04, -9.8705e-04, -2.1458e-06,  ..., -1.6093e-06,
          5.8556e-04, -6.7413e-05],
        [-9.9468e-04, -8.0347e-04, -4.0245e-04,  ..., -1.1086e-05,
          1.5488e-03,  1.5297e-03],
        ...,
        [-7.4244e-04,  1.0004e-03,  6.4373e-04,  ..., -9.4366e-04,
          7.9632e-04,  2.9826e-04],
        [ 7.5531e-04,  4.5204e-04, -1.2130e-04,  ..., -4.5085e-04,
         -8.4543e-04, -1.7214e-04],
        [ 8.1348e-04,  1.4191e-03,  1.5187e-04,  ...,  1.3018e-03,
         -1.7738e-03, -1.4710e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0696e-02,  3.7689e-03,  9.9945e-03,  ..., -5.0430e-03,
         -6.1378e-03,  6.9885e-03],
        [-6.1455e-03, -1.2680e-02, -4.5776e-05,  ...,  2.0889e-02,
          1.0786e-03, -1.1635e-04],
        [-1.2222e-02,  3.4370e-03, -1.1810e-02,  ..., -6.3858e-03,
         -1.8196e-03, -2.8419e-03],
        ...,
        [-4.1161e-03,  9.1553e-03, -1.3420e-02,  ..., -8.6136e-03,
          9.8267e-03, -7.7820e-04],
        [ 9.2316e-04,  2.9755e-03, -8.0719e-03,  ...,  1.4315e-03,
         -1.4847e-02,  4.1199e-03],
        [-4.3488e-03, -3.0079e-03, -1.0796e-02,  ...,  7.9041e-03,
          6.8283e-04, -2.3956e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0388, -0.0023,  0.0180,  ..., -0.0152, -0.0251,  0.0025],
        [-0.0034, -0.0342, -0.0063,  ...,  0.0055,  0.0161,  0.0029],
        [-0.0057, -0.0044, -0.0523,  ..., -0.0150, -0.0013,  0.0044],
        ...,
        [ 0.0010,  0.0206, -0.0112,  ..., -0.0327,  0.0199, -0.0019],
        [ 0.0004, -0.0118, -0.0154,  ..., -0.0195, -0.0510, -0.0077],
        [ 0.0033,  0.0294, -0.0200,  ..., -0.0258,  0.0161, -0.0571]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:05:48 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 03:05:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4312,  0.3313,  1.1895,  ..., -0.0908,  1.4619,  0.1283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6865, -0.0433, -0.1951,  ..., -0.3813,  0.8555,  0.8716],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.9668,  1.4346,  3.8848,  ...,  0.2415,  4.9961,  0.8589],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1064, -0.1871,  0.6289,  ..., -1.1396,  2.9062,  2.8262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:05:48 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 03:05:48 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 03:07:10 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 03:08:34 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 03:09:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.5572e-03,  1.6441e-03, -3.1257e-04,  ...,  4.4608e-04,
         -1.6956e-03, -1.0014e-03],
        [-1.6785e-03, -2.1172e-03,  6.5327e-04,  ...,  4.3440e-04,
         -4.4632e-04,  2.0943e-03],
        [-7.0286e-04,  1.9665e-03,  3.9101e-05,  ...,  6.1274e-04,
          1.3762e-03,  1.1027e-05],
        ...,
        [-2.3384e-03, -4.1962e-04,  6.5994e-04,  ..., -4.5471e-03,
         -1.2579e-03, -2.9373e-04],
        [-8.6641e-04, -6.7616e-04, -1.7834e-03,  ...,  5.9843e-04,
         -3.6964e-03,  1.1892e-03],
        [ 3.1948e-04, -6.8378e-04,  3.0212e-03,  ..., -5.5218e-04,
          1.8368e-03, -5.5695e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0365, -0.0003, -0.0205,  ..., -0.0122,  0.0101, -0.0049],
        [ 0.0085, -0.0008,  0.0112,  ...,  0.0258, -0.0062,  0.0058],
        [ 0.0222, -0.0037, -0.0068,  ..., -0.0070,  0.0115, -0.0066],
        ...,
        [-0.0149,  0.0035,  0.0029,  ..., -0.0032, -0.0102, -0.0108],
        [-0.0016, -0.0016, -0.0141,  ...,  0.0050, -0.0091, -0.0032],
        [-0.0027, -0.0034,  0.0169,  ..., -0.0033,  0.0210, -0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.7312e-02, -3.3474e-04, -1.4069e-02,  ..., -6.5536e-03,
          1.0109e-02, -2.7866e-03],
        [-3.2654e-03, -6.7993e-02,  5.5771e-03,  ..., -6.4240e-03,
         -1.7212e-02,  1.7487e-02],
        [-9.9182e-05, -2.1042e-02, -7.5806e-02,  ..., -1.4038e-03,
          1.0307e-02,  1.3405e-02],
        ...,
        [ 2.0828e-02, -4.4899e-03, -1.8509e-02,  ..., -6.7322e-02,
         -9.9564e-03, -2.0676e-03],
        [ 8.3160e-03,  1.1963e-02,  1.2199e-02,  ...,  1.4296e-03,
         -8.0994e-02,  1.8311e-02],
        [ 1.9855e-03, -5.5046e-03,  2.6131e-04,  ...,  2.3232e-03,
          6.3705e-03, -6.2500e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:09:58 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 03:09:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5342,  0.2556,  1.2988,  ..., -0.0409,  1.7246,  0.3074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5059,  0.0666, -0.0587,  ..., -0.3948,  1.0391,  0.9175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.2617,  1.1250,  4.4883,  ...,  0.4646,  5.2266,  0.6660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.8926, -0.5293,  0.9873,  ..., -0.4868,  3.2852,  4.2695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:09:58 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 03:09:58 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 03:11:22 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 03:12:47 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 03:14:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0027, -0.0002,  0.0019,  ..., -0.0008,  0.0019,  0.0030],
        [ 0.0010,  0.0015,  0.0005,  ..., -0.0003, -0.0015, -0.0016],
        [ 0.0020, -0.0001, -0.0034,  ...,  0.0032, -0.0023, -0.0052],
        ...,
        [ 0.0006,  0.0002, -0.0004,  ...,  0.0051, -0.0015, -0.0021],
        [-0.0002,  0.0012,  0.0048,  ..., -0.0026,  0.0069,  0.0031],
        [ 0.0012, -0.0019, -0.0066,  ...,  0.0046, -0.0030,  0.0015]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0196,  0.0070,  0.0070,  ...,  0.0020,  0.0136,  0.0098],
        [-0.0057, -0.0024, -0.0172,  ..., -0.0057,  0.0151,  0.0087],
        [-0.0106,  0.0142,  0.0201,  ...,  0.0017,  0.0152, -0.0099],
        ...,
        [ 0.0070,  0.0098, -0.0109,  ...,  0.0420,  0.0043, -0.0105],
        [-0.0045, -0.0068, -0.0072,  ..., -0.0192,  0.0205,  0.0117],
        [-0.0047,  0.0120, -0.0059,  ..., -0.0054,  0.0138,  0.0215]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.1035e-03, -2.5635e-02, -2.1973e-03,  ..., -9.7809e-03,
          1.0376e-02,  3.9444e-03],
        [ 8.6517e-03, -4.8157e-02,  1.5469e-03,  ..., -9.5901e-03,
         -2.5146e-02,  2.6428e-02],
        [ 1.2291e-02,  2.3682e-02,  1.4114e-02,  ...,  1.4252e-02,
          2.9869e-03, -1.6785e-02],
        ...,
        [-1.0880e-02, -1.0986e-02, -8.5220e-03,  ...,  1.7731e-02,
          7.7133e-03, -2.0111e-02],
        [-2.9755e-04, -1.2123e-02, -7.0190e-03,  ...,  5.3406e-03,
         -4.1618e-03, -1.0727e-02],
        [-1.6975e-03,  3.7750e-02, -9.6130e-03,  ...,  5.3406e-05,
          2.5665e-02, -1.8311e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:14:12 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 03:14:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3013,  0.4792,  1.2383,  ...,  0.0408,  1.6533,  0.2505],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3508, -0.0354,  0.1589,  ..., -0.4165,  0.9800,  0.9414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1191,  2.4219,  4.2461,  ...,  0.1213,  5.1367,  0.3530],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.0723, -0.3904,  1.3027,  ...,  0.3018,  1.5703,  5.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:14:12 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 03:14:12 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 03:15:39 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 03:17:05 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 03:18:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0414e-03, -1.4520e-04, -1.9360e-04,  ..., -8.6665e-05,
          1.7762e-04,  1.7416e-04],
        [ 1.1051e-04,  4.9055e-05,  1.4472e-04,  ..., -3.0136e-04,
          2.0313e-04, -4.2796e-05],
        [ 5.5933e-04,  5.6684e-05,  1.0185e-03,  ..., -1.5616e-04,
          1.7810e-04, -1.8144e-04],
        ...,
        [ 3.1114e-05, -9.9540e-05, -5.0783e-04,  ...,  1.0815e-03,
          5.8842e-04, -7.3016e-05],
        [ 2.9445e-04,  1.9217e-04,  3.2115e-04,  ..., -1.2207e-04,
          5.1928e-04, -5.9009e-05],
        [ 1.0586e-04, -1.6332e-04,  6.9046e-04,  ..., -3.3283e-04,
          2.8157e-04,  1.2159e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0075,  0.0051,  0.0101,  ...,  0.0050, -0.0011, -0.0030],
        [ 0.0015, -0.0047,  0.0070,  ...,  0.0078, -0.0048,  0.0030],
        [-0.0044, -0.0008,  0.0062,  ...,  0.0062, -0.0103, -0.0045],
        ...,
        [-0.0124, -0.0110, -0.0239,  ..., -0.0025,  0.0109,  0.0147],
        [ 0.0100,  0.0190,  0.0147,  ..., -0.0235,  0.0177, -0.0026],
        [-0.0020,  0.0030, -0.0165,  ..., -0.0048, -0.0058,  0.0096]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.3823e-02, -7.4310e-03, -2.2240e-03,  ...,  8.6060e-03,
          2.1469e-02,  2.7008e-03],
        [-1.8387e-02, -3.7811e-02, -5.0354e-03,  ...,  1.8661e-02,
          2.6703e-05, -7.6141e-03],
        [ 2.2110e-02, -3.0231e-03, -1.3596e-02,  ...,  7.4310e-03,
          3.6774e-03, -2.5604e-02],
        ...,
        [-2.1149e-02, -6.0577e-03, -1.2283e-02,  ..., -3.5339e-02,
         -7.1716e-03,  1.3885e-02],
        [ 1.3680e-02,  1.0017e-02, -2.0615e-02,  ..., -1.2459e-02,
         -2.9526e-02,  1.7639e-02],
        [ 1.6312e-02,  3.9635e-03, -6.7215e-03,  ..., -1.9159e-03,
          1.4305e-02, -3.2867e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:18:36 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 03:18:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3328,  0.3503,  1.2285,  ...,  0.0370,  1.5107,  0.1422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5610, -0.1329,  0.2252,  ..., -0.2488,  1.0107,  1.3252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1377,  2.3672,  2.8398,  ..., -0.4392,  4.8750, -0.0503],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1758, -0.8071, -0.0352,  ..., -0.4766,  1.2109,  5.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:18:36 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 03:18:36 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 03:20:01 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 03:21:28 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 03:22:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1063e-03, -2.0027e-04,  1.9145e-04,  ...,  1.7309e-04,
         -1.6999e-04,  1.6928e-04],
        [-1.0449e-04,  5.4693e-04, -2.1005e-04,  ..., -1.0312e-05,
         -3.1185e-04,  2.1458e-06],
        [ 1.8716e-04, -6.7472e-04,  1.0452e-03,  ..., -2.5010e-04,
          1.3053e-05,  1.8287e-04],
        ...,
        [-9.8944e-06,  1.4114e-04, -3.7253e-05,  ...,  1.6298e-03,
         -3.5048e-05, -2.6011e-04],
        [ 6.7949e-06,  1.1218e-04,  2.2602e-04,  ..., -2.7609e-04,
          1.3962e-03,  3.6001e-04],
        [-2.2650e-04, -3.8242e-04,  1.0496e-04,  ..., -8.1062e-06,
         -8.0526e-05,  1.7548e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0092,  0.0167, -0.0063,  ..., -0.0051, -0.0024,  0.0017],
        [ 0.0065, -0.0012,  0.0131,  ..., -0.0023,  0.0135, -0.0002],
        [-0.0120,  0.0027,  0.0127,  ..., -0.0053, -0.0109,  0.0056],
        ...,
        [-0.0211,  0.0058, -0.0049,  ...,  0.0267, -0.0107, -0.0040],
        [-0.0059, -0.0110, -0.0011,  ..., -0.0256,  0.0289,  0.0136],
        [-0.0236,  0.0139,  0.0126,  ..., -0.0090,  0.0066,  0.0240]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0181,  0.0200, -0.0030,  ..., -0.0048,  0.0059, -0.0022],
        [ 0.0186, -0.0331,  0.0182,  ..., -0.0068,  0.0023, -0.0022],
        [-0.0019,  0.0119,  0.0121,  ..., -0.0287,  0.0029, -0.0065],
        ...,
        [ 0.0105,  0.0155,  0.0173,  ...,  0.0105,  0.0157, -0.0085],
        [-0.0138, -0.0227,  0.0025,  ..., -0.0112, -0.0166,  0.0066],
        [-0.0117,  0.0088,  0.0185,  ...,  0.0014,  0.0104,  0.0038]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:22:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too spent, it is overspent
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too stressed, it is
2024-06-30 03:22:57 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 03:22:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0831,  0.0206, -0.5293,  ...,  0.4229, -0.8027, -0.7671],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1968, -0.1617,  0.1298,  ...,  0.2061, -0.3618, -0.5435],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1660,  0.2822, -0.0229,  ...,  0.2510, -0.1523, -0.9175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6484,  0.1543,  0.2123,  ...,  0.2277, -0.4224, -0.0608],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:22:57 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:22:57 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 03:23:20 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 03:23:43 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 03:24:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.4567e-03, -1.0014e-04, -1.3304e-04,  ...,  4.9448e-04,
          5.4419e-05, -8.6665e-05],
        [ 2.5296e-04, -2.2774e-03, -1.3518e-04,  ..., -8.8573e-05,
         -3.1281e-04,  5.1308e-04],
        [ 1.3351e-04,  3.0708e-04, -3.2730e-03,  ..., -3.2485e-05,
          7.7009e-05, -2.0981e-05],
        ...,
        [-8.1253e-04, -3.8564e-05, -3.4213e-05,  ..., -2.5463e-03,
          1.1051e-04,  4.4107e-06],
        [ 1.7190e-04, -6.6042e-05, -2.0611e-04,  ..., -9.7573e-05,
         -2.6398e-03, -2.6417e-04],
        [-4.9162e-04,  1.9050e-04, -2.0409e-04,  ...,  1.1802e-04,
         -7.1645e-05, -2.9182e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0306, -0.0009,  0.0065,  ...,  0.0032,  0.0053,  0.0010],
        [-0.0061, -0.0353,  0.0032,  ..., -0.0085,  0.0118, -0.0026],
        [-0.0003, -0.0015, -0.0419,  ..., -0.0032, -0.0014,  0.0012],
        ...,
        [-0.0026,  0.0018,  0.0011,  ..., -0.0437,  0.0033, -0.0077],
        [-0.0013,  0.0082, -0.0040,  ..., -0.0063, -0.0292, -0.0026],
        [ 0.0102, -0.0037,  0.0023,  ...,  0.0023, -0.0002, -0.0302]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0356, -0.0014,  0.0019,  ...,  0.0003,  0.0011, -0.0003],
        [ 0.0023, -0.0349, -0.0039,  ...,  0.0013,  0.0054, -0.0004],
        [-0.0063, -0.0016, -0.0307,  ..., -0.0012, -0.0035,  0.0012],
        ...,
        [-0.0012,  0.0008,  0.0028,  ..., -0.0328, -0.0009, -0.0015],
        [-0.0010,  0.0016,  0.0023,  ..., -0.0024, -0.0310,  0.0057],
        [-0.0011, -0.0024, -0.0028,  ...,  0.0050,  0.0020, -0.0309]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:24:09 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 03:24:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8003,  0.0828, -0.4512,  ..., -0.1302, -0.7817, -1.3408],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7764, -0.1277,  0.3860,  ..., -0.1028, -0.5347, -0.3257],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3708,  0.6060,  0.0510,  ..., -0.2812, -0.4072, -0.7407],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6284,  0.1132,  0.1621,  ..., -0.6089, -0.4226,  0.1646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:24:09 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:24:09 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 03:24:32 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 03:24:56 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 03:25:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2159e-03, -8.0109e-05,  2.6655e-04,  ..., -1.6708e-03,
          1.6594e-04, -4.3774e-04],
        [ 2.6131e-04, -3.4180e-03, -5.1260e-04,  ...,  8.9645e-04,
         -7.7534e-04, -1.4210e-04],
        [-5.6458e-04,  2.5606e-04, -2.6646e-03,  ...,  4.3154e-04,
         -8.3303e-04,  2.7108e-04],
        ...,
        [ 3.9721e-04,  8.0705e-05,  5.7220e-04,  ..., -2.2678e-03,
         -1.9426e-03, -4.3583e-04],
        [ 6.6662e-04,  1.7774e-04,  1.0204e-03,  ..., -4.5204e-04,
         -1.7509e-03, -2.6703e-04],
        [ 7.8011e-04, -4.5753e-04, -5.8079e-04,  ..., -1.1168e-03,
          4.5538e-04, -2.7733e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.2083e-02,  9.3765e-03, -1.1078e-02,  ...,  4.9820e-03,
          3.9024e-03, -5.5008e-03],
        [-2.9907e-03, -6.5796e-02, -1.5991e-02,  ...,  1.0429e-02,
         -1.8806e-03,  7.7705e-03],
        [ 9.4414e-04, -9.6588e-03, -6.1859e-02,  ..., -1.4153e-03,
         -2.8667e-03, -2.7313e-03],
        ...,
        [ 7.5188e-03,  4.2648e-03,  4.1504e-03,  ..., -6.1310e-02,
         -4.3259e-03,  7.0610e-03],
        [-4.3631e-05, -5.2109e-03,  3.7155e-03,  ...,  3.9940e-03,
         -6.6223e-02, -8.2932e-03],
        [-3.5763e-03, -1.9989e-03, -3.7975e-03,  ...,  1.0590e-02,
          8.7433e-03, -7.2021e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0700,  0.0018, -0.0062,  ..., -0.0007,  0.0073,  0.0005],
        [-0.0008, -0.0811, -0.0078,  ...,  0.0062,  0.0033,  0.0044],
        [ 0.0067,  0.0021, -0.0609,  ...,  0.0015, -0.0052, -0.0063],
        ...,
        [ 0.0018,  0.0105,  0.0037,  ..., -0.0773, -0.0073, -0.0046],
        [-0.0056,  0.0008,  0.0025,  ...,  0.0042, -0.0735,  0.0023],
        [ 0.0011,  0.0003,  0.0015,  ..., -0.0037,  0.0081, -0.0780]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:25:22 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 03:25:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2375,  0.3457, -0.0365,  ...,  0.3052, -0.1973, -1.2451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0205,  0.2268,  0.3254,  ...,  0.3403, -0.6357, -0.1163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2349,  0.2170,  0.1526,  ..., -0.0662, -0.4487, -0.8760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9390,  0.4194, -0.0112,  ..., -0.5586, -0.5918,  0.9897],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:25:22 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:25:22 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 03:25:48 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 03:26:13 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 03:26:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.2376e-03,  4.8876e-04, -2.1477e-03,  ...,  2.3627e-04,
          7.1096e-04, -1.4153e-03],
        [ 4.6396e-04, -6.0959e-03,  1.1101e-03,  ...,  3.6311e-04,
         -5.8842e-04, -2.3425e-05],
        [-2.1172e-04, -4.3058e-04, -4.4632e-03,  ..., -1.0967e-04,
         -2.9850e-04, -1.1129e-03],
        ...,
        [-1.0281e-03,  5.5933e-04, -3.5954e-04,  ..., -4.1809e-03,
          5.4169e-04, -3.7694e-04],
        [-1.4315e-03,  4.6372e-04, -1.3638e-03,  ..., -1.6212e-04,
         -4.3869e-03, -7.3242e-04],
        [ 8.1587e-04, -1.4286e-03,  1.5812e-03,  ..., -1.8835e-05,
          4.1914e-04, -4.8447e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0403,  0.0014, -0.0050,  ...,  0.0040, -0.0015, -0.0032],
        [ 0.0020, -0.0430, -0.0056,  ..., -0.0051, -0.0103, -0.0032],
        [ 0.0006,  0.0021, -0.0361,  ..., -0.0021, -0.0087, -0.0076],
        ...,
        [ 0.0048, -0.0004, -0.0132,  ..., -0.0367,  0.0050,  0.0022],
        [-0.0083, -0.0034,  0.0044,  ...,  0.0010, -0.0365, -0.0018],
        [-0.0021, -0.0063,  0.0021,  ..., -0.0032,  0.0050, -0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.8177e-02,  3.3722e-03, -1.6460e-03,  ...,  1.3819e-03,
          9.5510e-04, -1.8587e-03],
        [ 5.4474e-03, -3.1738e-02,  4.1428e-03,  ..., -1.1616e-03,
         -1.8892e-03,  5.5237e-03],
        [ 3.0518e-03,  1.1234e-03, -3.3661e-02,  ..., -7.9117e-03,
          2.3041e-03,  3.8795e-03],
        ...,
        [ 7.7248e-04, -1.6518e-03, -9.0332e-03,  ..., -3.0823e-02,
         -2.4700e-04, -1.8158e-03],
        [-4.3488e-03,  5.9662e-03,  6.1417e-03,  ...,  9.1743e-04,
         -2.3743e-02, -1.5259e-05],
        [-3.7689e-03,  3.6240e-03,  5.4779e-03,  ..., -8.1635e-04,
          7.2556e-03, -2.8931e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:26:41 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 03:26:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5068,  0.7603,  0.0624,  ..., -0.3428, -0.5298, -1.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9805,  0.1560,  0.2473,  ..., -0.8711, -0.6372,  0.2251],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4229,  0.1877,  0.6865,  ...,  0.1765,  0.2876, -0.6963],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7285,  1.0977,  0.3162,  ..., -1.0352, -0.1904,  0.7607],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:26:41 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:26:41 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 03:27:10 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 03:27:32 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 03:27:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.2479e-05, -8.2159e-04, -9.5963e-05,  ..., -1.3847e-03,
          3.1242e-03, -2.2364e-04],
        [ 2.9087e-03, -3.5076e-03, -8.4019e-04,  ..., -2.2721e-04,
          2.2774e-03, -3.9911e-04],
        [-6.6805e-04,  5.0831e-04, -1.3018e-03,  ...,  1.5745e-03,
          4.9591e-05,  1.7395e-03],
        ...,
        [-1.3447e-03, -2.8877e-03, -5.0735e-04,  ..., -2.9926e-03,
          5.3787e-04, -4.4918e-04],
        [ 9.0599e-04,  6.4754e-04, -1.4286e-03,  ..., -8.9359e-04,
         -1.1654e-03,  4.2248e-04],
        [ 1.2913e-03, -6.3038e-04,  3.3140e-04,  ...,  2.4128e-04,
         -6.0797e-04, -2.7332e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.2684e-02,  1.0513e-02, -5.9586e-03,  ...,  4.1428e-03,
          7.0419e-03,  9.6512e-04],
        [ 1.7944e-02, -4.2847e-02,  3.1719e-03,  ..., -7.9651e-03,
          1.1551e-02, -4.3869e-03],
        [-1.3245e-02,  4.0054e-03, -4.6570e-02,  ...,  8.5831e-06,
          5.4092e-03,  2.1286e-03],
        ...,
        [ 5.0774e-03, -8.8806e-03, -6.3324e-04,  ..., -3.7018e-02,
          1.0433e-03, -1.1110e-03],
        [ 2.9488e-03, -3.6888e-03, -3.4542e-03,  ...,  4.0054e-03,
         -3.8635e-02,  4.3449e-03],
        [ 7.6027e-03, -5.1537e-03, -1.0841e-02,  ...,  1.2161e-02,
         -3.4714e-03, -4.4678e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0532, -0.0008,  0.0040,  ..., -0.0023,  0.0020,  0.0027],
        [ 0.0052, -0.0337, -0.0016,  ...,  0.0054,  0.0116, -0.0077],
        [-0.0002, -0.0009, -0.0435,  ..., -0.0002, -0.0028,  0.0037],
        ...,
        [-0.0088, -0.0028,  0.0014,  ..., -0.0402,  0.0043, -0.0007],
        [ 0.0003, -0.0010, -0.0048,  ..., -0.0084, -0.0337,  0.0050],
        [-0.0010, -0.0016, -0.0023,  ..., -0.0071, -0.0005, -0.0445]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:27:57 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 03:27:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2686,  0.1934,  0.1597,  ..., -0.0792, -0.4592, -1.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0479,  0.4443, -0.0034,  ..., -0.5903, -0.6279,  1.1084],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5840,  0.2910,  1.0547,  ...,  0.0236,  0.5034, -0.1924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6636,  0.7109,  0.3066,  ..., -0.4038,  0.0428,  0.5000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:27:57 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:27:57 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 03:28:20 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 03:28:45 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 03:29:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3499e-03,  1.3847e-03, -2.9259e-03,  ...,  4.3094e-05,
         -1.4229e-03,  1.1578e-03],
        [-3.3169e-03,  5.5456e-04, -4.2510e-04,  ...,  1.0586e-03,
         -2.8372e-04,  7.0858e-04],
        [ 1.0948e-03,  1.2970e-04, -1.4009e-03,  ..., -1.7691e-03,
          7.3481e-04, -7.4768e-04],
        ...,
        [-1.6475e-04,  1.0862e-03, -5.6553e-04,  ..., -1.7872e-03,
         -3.2978e-03,  2.2755e-03],
        [ 2.3918e-03,  1.3466e-03, -6.2990e-04,  ...,  1.9836e-03,
          2.1896e-03, -1.3900e-04],
        [-6.1035e-04, -1.6479e-03,  1.2898e-04,  ..., -5.9795e-04,
         -1.4381e-03, -4.6158e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0869,  0.0021,  0.0040,  ...,  0.0097,  0.0032,  0.0048],
        [ 0.0068, -0.0747,  0.0156,  ...,  0.0060,  0.0089,  0.0137],
        [ 0.0031, -0.0086, -0.0740,  ...,  0.0007,  0.0070,  0.0059],
        ...,
        [-0.0012, -0.0018, -0.0025,  ..., -0.0707, -0.0101,  0.0125],
        [ 0.0063, -0.0007, -0.0058,  ...,  0.0055, -0.0836, -0.0059],
        [ 0.0019,  0.0124,  0.0082,  ...,  0.0054,  0.0011, -0.0877]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0911, -0.0071,  0.0078,  ..., -0.0019, -0.0056, -0.0024],
        [-0.0098, -0.1001,  0.0038,  ..., -0.0053, -0.0026,  0.0004],
        [-0.0052,  0.0009, -0.0919,  ..., -0.0005,  0.0076,  0.0057],
        ...,
        [-0.0024, -0.0024, -0.0012,  ..., -0.0831,  0.0094,  0.0047],
        [ 0.0006, -0.0024,  0.0025,  ...,  0.0030, -0.0952,  0.0069],
        [ 0.0054,  0.0043,  0.0068,  ..., -0.0086, -0.0072, -0.1008]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:29:17 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 03:29:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4326,  0.1747,  0.6470,  ...,  0.1725,  0.2651, -0.7417],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7891,  1.2080,  0.3210,  ..., -1.0664, -0.2167,  0.8237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7080, -0.2153,  0.9370,  ...,  0.3921,  0.6694, -0.0048],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2285,  0.1606,  0.4280,  ..., -0.1245, -0.0131,  0.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:29:17 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:29:17 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 03:29:54 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 03:30:29 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 03:31:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0018, -0.0003,  0.0023,  ...,  0.0004,  0.0044, -0.0034],
        [ 0.0050, -0.0085,  0.0033,  ..., -0.0004,  0.0031, -0.0020],
        [-0.0015,  0.0014, -0.0028,  ..., -0.0032, -0.0026,  0.0030],
        ...,
        [ 0.0022, -0.0013,  0.0003,  ..., -0.0036, -0.0004,  0.0027],
        [ 0.0049, -0.0035,  0.0005,  ..., -0.0004, -0.0047, -0.0030],
        [-0.0002, -0.0017,  0.0005,  ...,  0.0020, -0.0011,  0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0800,  0.0120, -0.0005,  ..., -0.0070,  0.0086, -0.0011],
        [ 0.0071, -0.1137, -0.0002,  ...,  0.0099,  0.0052,  0.0005],
        [ 0.0142,  0.0051, -0.0862,  ...,  0.0096,  0.0023,  0.0098],
        ...,
        [ 0.0096, -0.0106,  0.0067,  ..., -0.0847,  0.0025, -0.0051],
        [-0.0084,  0.0049,  0.0021,  ...,  0.0003, -0.0842, -0.0059],
        [ 0.0031,  0.0049,  0.0006,  ..., -0.0047, -0.0025, -0.0864]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0914,  0.0005, -0.0015,  ..., -0.0003,  0.0041,  0.0034],
        [ 0.0031, -0.0983, -0.0053,  ...,  0.0002, -0.0057,  0.0024],
        [ 0.0077, -0.0065, -0.0991,  ...,  0.0118,  0.0070, -0.0083],
        ...,
        [ 0.0045, -0.0029,  0.0053,  ..., -0.0960,  0.0008, -0.0068],
        [-0.0042, -0.0012, -0.0031,  ...,  0.0027, -0.0966,  0.0003],
        [ 0.0024,  0.0014, -0.0101,  ..., -0.0082,  0.0043, -0.1061]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:31:04 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 03:31:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5288,  0.2761,  0.8672,  ..., -0.0088,  0.4363, -0.2148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6528,  0.7339,  0.2693,  ..., -0.3953,  0.0398,  0.4724],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1782, -0.0095,  1.2676,  ...,  0.2883,  0.9727,  0.6357],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9619,  0.3140,  0.9512,  ...,  0.0487,  0.1906, -0.1023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:31:04 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:31:04 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 03:31:43 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 03:32:22 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 03:33:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.9210e-03,  6.6996e-04, -1.4610e-03,  ..., -1.7509e-03,
         -2.9850e-03, -1.2026e-03],
        [ 2.2869e-03, -3.8929e-03, -2.6875e-03,  ...,  1.6308e-03,
          1.9989e-03,  5.3310e-04],
        [ 8.0013e-04, -1.7843e-03, -2.1057e-03,  ..., -6.4611e-04,
         -2.0256e-03,  1.1129e-03],
        ...,
        [ 1.0891e-03,  4.9019e-03, -1.2410e-04,  ..., -5.9624e-03,
          2.9049e-03,  5.4932e-03],
        [-6.6566e-04, -1.9073e-05, -1.3390e-03,  ..., -2.7966e-04,
         -1.9331e-03, -1.4973e-03],
        [ 2.5673e-03, -1.9665e-03,  1.2980e-03,  ..., -8.9025e-04,
          3.1357e-03, -2.2373e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0876, -0.0012,  0.0036,  ..., -0.0093,  0.0043,  0.0122],
        [-0.0045, -0.0681, -0.0122,  ..., -0.0061,  0.0039,  0.0059],
        [ 0.0080, -0.0037, -0.0778,  ...,  0.0019, -0.0049, -0.0065],
        ...,
        [-0.0119,  0.0062,  0.0043,  ..., -0.0854, -0.0131, -0.0061],
        [-0.0003,  0.0127,  0.0027,  ...,  0.0067, -0.0760,  0.0139],
        [-0.0020,  0.0038, -0.0016,  ...,  0.0007,  0.0080, -0.0862]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0912,  0.0049,  0.0054,  ..., -0.0049, -0.0088, -0.0066],
        [ 0.0014, -0.0806, -0.0075,  ...,  0.0035,  0.0070, -0.0108],
        [ 0.0036,  0.0038, -0.0849,  ...,  0.0023, -0.0043,  0.0073],
        ...,
        [ 0.0003, -0.0014, -0.0019,  ..., -0.0891,  0.0091, -0.0003],
        [ 0.0037,  0.0057, -0.0013,  ...,  0.0112, -0.0812, -0.0059],
        [-0.0013, -0.0066,  0.0003,  ..., -0.0022, -0.0012, -0.0772]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:33:04 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 03:33:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6289, -0.2094,  0.7705,  ...,  0.3159,  0.5640, -0.0293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.1533,  0.1505,  0.3733,  ..., -0.1082, -0.0155,  0.2854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0845,  0.2441,  1.3066,  ..., -0.0654,  0.9102,  0.2822],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6289,  0.2360,  0.7275,  ..., -0.0668,  0.0702,  0.5088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:33:04 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:33:04 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 03:33:45 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 03:34:27 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 03:35:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0038, -0.0014,  0.0029,  ...,  0.0005, -0.0014, -0.0029],
        [ 0.0018, -0.0005, -0.0016,  ..., -0.0045,  0.0023, -0.0008],
        [-0.0011,  0.0002,  0.0002,  ...,  0.0005, -0.0013, -0.0002],
        ...,
        [-0.0018, -0.0010,  0.0022,  ..., -0.0014,  0.0008, -0.0010],
        [ 0.0016,  0.0007,  0.0003,  ...,  0.0006, -0.0060,  0.0009],
        [ 0.0045, -0.0005,  0.0031,  ...,  0.0008,  0.0015, -0.0037]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0793, -0.0047, -0.0136,  ...,  0.0041, -0.0083, -0.0031],
        [ 0.0098, -0.0819,  0.0168,  ..., -0.0123,  0.0134,  0.0017],
        [-0.0133,  0.0022, -0.0710,  ..., -0.0028,  0.0055, -0.0039],
        ...,
        [ 0.0066,  0.0126, -0.0066,  ..., -0.0928, -0.0068,  0.0002],
        [ 0.0158, -0.0012,  0.0020,  ..., -0.0139, -0.0696,  0.0068],
        [ 0.0005, -0.0065, -0.0065,  ..., -0.0039,  0.0019, -0.0807]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1026,  0.0062, -0.0074,  ..., -0.0038,  0.0054, -0.0102],
        [ 0.0058, -0.1233,  0.0063,  ..., -0.0089, -0.0031,  0.0133],
        [-0.0044,  0.0007, -0.1119,  ..., -0.0052, -0.0086,  0.0070],
        ...,
        [ 0.0087,  0.0091, -0.0062,  ..., -0.1047, -0.0037,  0.0022],
        [-0.0059,  0.0064, -0.0027,  ..., -0.0023, -0.0954,  0.0055],
        [-0.0089, -0.0002, -0.0073,  ...,  0.0027,  0.0045, -0.1202]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:35:10 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 03:35:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1565, -0.0136,  0.8599,  ...,  0.1812,  0.6929,  0.4692],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8535,  0.2769,  0.7393,  ...,  0.0220,  0.1469, -0.1054],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7251,  0.5840,  1.4033,  ..., -0.1448,  1.3223, -0.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9429,  0.6704,  1.5996,  ..., -0.0223, -0.0085,  0.5200],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:35:10 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:35:10 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 03:35:58 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 03:36:46 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 03:37:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.2907e-03,  3.1233e-05,  8.4925e-04,  ..., -1.4515e-03,
         -2.4433e-03, -2.3594e-03],
        [ 1.4811e-03, -1.2283e-03, -1.3733e-03,  ...,  7.0333e-04,
         -2.2030e-03,  2.8286e-03],
        [-2.4471e-03, -5.5456e-04,  1.2589e-03,  ..., -2.9802e-04,
          1.4210e-03,  2.9392e-03],
        ...,
        [-5.0735e-04, -3.4294e-03, -1.0605e-03,  ...,  3.8815e-03,
         -2.1267e-03, -6.7902e-04],
        [-2.7103e-03,  2.9774e-03, -9.7752e-04,  ...,  8.7500e-04,
         -1.9779e-03, -8.5068e-04],
        [ 1.9989e-03, -2.5139e-03,  2.9926e-03,  ..., -1.4973e-03,
          4.3068e-03,  3.0441e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1088,  0.0003,  0.0005,  ..., -0.0114, -0.0077,  0.0144],
        [ 0.0032, -0.1145, -0.0094,  ...,  0.0041, -0.0070,  0.0010],
        [ 0.0018,  0.0095, -0.0987,  ...,  0.0079, -0.0030, -0.0048],
        ...,
        [-0.0105,  0.0021,  0.0049,  ..., -0.1118, -0.0059,  0.0109],
        [ 0.0049,  0.0005,  0.0209,  ...,  0.0056, -0.1117, -0.0025],
        [ 0.0083, -0.0113,  0.0045,  ..., -0.0113, -0.0077, -0.0955]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1689,  0.0010,  0.0076,  ...,  0.0015, -0.0010,  0.0034],
        [-0.0023, -0.1626, -0.0102,  ...,  0.0136,  0.0068,  0.0031],
        [ 0.0016, -0.0094, -0.1450,  ...,  0.0060, -0.0044, -0.0062],
        ...,
        [-0.0017,  0.0261,  0.0122,  ..., -0.1632,  0.0056,  0.0083],
        [ 0.0017,  0.0048,  0.0083,  ..., -0.0094, -0.1649, -0.0010],
        [-0.0014,  0.0012,  0.0081,  ..., -0.0121,  0.0008, -0.1495]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:37:32 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 03:37:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0580,  0.1534,  0.8345,  ..., -0.0360,  0.6055,  0.1558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5205,  0.1836,  0.5425,  ..., -0.0411,  0.0433,  0.3906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5054,  1.3496,  1.9863,  ...,  0.4226,  1.1582, -0.4314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4587,  0.0830,  1.2266,  ..., -0.3857, -0.3667,  0.3660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:37:32 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:37:32 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 03:38:23 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 03:39:05 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 03:39:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0036,  0.0015,  0.0011,  ..., -0.0008,  0.0025,  0.0017],
        [-0.0001,  0.0010,  0.0027,  ...,  0.0012,  0.0008,  0.0005],
        [-0.0021,  0.0004, -0.0020,  ..., -0.0001, -0.0006, -0.0006],
        ...,
        [ 0.0040, -0.0014,  0.0027,  ..., -0.0047, -0.0015, -0.0004],
        [ 0.0006, -0.0020,  0.0009,  ...,  0.0034, -0.0014,  0.0040],
        [-0.0020, -0.0011, -0.0014,  ...,  0.0034, -0.0002, -0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0962,  0.0015, -0.0006,  ...,  0.0014,  0.0025, -0.0081],
        [ 0.0053, -0.1008,  0.0100,  ..., -0.0041,  0.0060,  0.0007],
        [-0.0116, -0.0022, -0.0844,  ...,  0.0005, -0.0191,  0.0049],
        ...,
        [-0.0015, -0.0109, -0.0004,  ..., -0.1017,  0.0124, -0.0120],
        [ 0.0008,  0.0149, -0.0016,  ...,  0.0104, -0.0958,  0.0059],
        [ 0.0059,  0.0063, -0.0107,  ...,  0.0139,  0.0063, -0.0903]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0921,  0.0002,  0.0007,  ...,  0.0083, -0.0039, -0.0031],
        [ 0.0135, -0.0958, -0.0057,  ..., -0.0129, -0.0088,  0.0013],
        [-0.0119,  0.0045, -0.1012,  ...,  0.0060, -0.0015,  0.0198],
        ...,
        [ 0.0016, -0.0054,  0.0115,  ..., -0.0792,  0.0062, -0.0078],
        [ 0.0110, -0.0171, -0.0062,  ...,  0.0110, -0.0959, -0.0023],
        [ 0.0029,  0.0013,  0.0051,  ...,  0.0056, -0.0029, -0.0942]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:39:53 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 03:39:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5015,  0.3728,  0.8325,  ..., -0.1278,  0.8330, -0.2153],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7368,  0.5039,  1.1104,  ..., -0.0485, -0.0262,  0.4072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6665,  1.0869,  1.5176,  ...,  0.0491,  0.8896,  0.7852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7285,  0.0316,  1.4844,  ...,  0.0061, -0.6436,  0.4534],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:39:53 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:39:53 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 03:40:45 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 03:41:38 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 03:42:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.2245e-03,  6.4850e-04, -6.3324e-04,  ..., -1.0033e-03,
          1.6956e-03,  2.3098e-03],
        [-2.5063e-03,  4.7951e-03, -1.2302e-03,  ...,  2.5864e-03,
          7.9966e-04, -1.6861e-03],
        [-6.6805e-04,  4.6730e-05,  7.9498e-03,  ..., -2.5702e-04,
          3.7079e-03,  1.7471e-03],
        ...,
        [-1.4811e-03,  2.5673e-03,  2.3632e-03,  ...,  6.7635e-03,
         -7.3576e-04,  4.0970e-03],
        [-1.3380e-03, -1.0786e-03, -1.0519e-03,  ..., -1.7004e-03,
          9.0561e-03,  2.4281e-03],
        [-1.7223e-03, -5.6505e-05,  2.4166e-03,  ...,  7.7057e-04,
          3.4428e-04,  4.8256e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.4893e-01, -6.0081e-03, -2.0294e-03,  ..., -4.6005e-03,
         -1.5163e-04,  6.4735e-03],
        [ 1.4030e-02, -1.4319e-01, -1.1742e-02,  ..., -5.3263e-04,
         -1.8253e-03, -1.2321e-02],
        [ 3.9978e-03, -5.5733e-03, -1.4746e-01,  ..., -2.4014e-03,
          8.8043e-03, -1.0941e-02],
        ...,
        [-1.4267e-02, -7.2937e-03,  1.1581e-02,  ..., -1.5259e-01,
         -7.7705e-03,  6.5994e-03],
        [-6.8436e-03,  7.7972e-03,  7.6771e-05,  ...,  5.1270e-03,
         -1.5808e-01,  7.6942e-03],
        [-4.6768e-03,  6.6452e-03,  1.9379e-03,  ..., -8.0681e-04,
          3.0212e-03, -1.5222e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.9263e-01,  1.0880e-02,  1.4366e-02,  ..., -9.9640e-03,
         -2.7599e-03, -5.4016e-03],
        [ 3.4065e-03, -2.1521e-01, -1.4297e-02,  ..., -3.2616e-03,
          4.7493e-04,  1.2970e-04],
        [ 6.1417e-03,  8.2855e-03, -1.9214e-01,  ...,  7.0610e-03,
          4.1313e-03, -1.2032e-02],
        ...,
        [-1.0681e-03, -3.0384e-03, -1.0996e-03,  ..., -2.2192e-01,
          1.0468e-02, -7.2861e-03],
        [-2.3651e-04,  2.7657e-03, -8.9340e-03,  ...,  1.1887e-02,
         -2.0300e-01,  1.3981e-03],
        [ 5.9814e-03, -8.8043e-03, -4.5090e-03,  ..., -3.9520e-03,
          2.4300e-03, -1.9800e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:42:34 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 03:42:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3679,  0.8799,  1.1943,  ...,  0.2661,  0.7456, -0.3511],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4016,  0.0529,  0.8936,  ..., -0.3098, -0.3020,  0.2512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3181,  1.3750,  1.5000,  ...,  0.3928,  1.1621,  0.7314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9502,  0.4829,  1.8750,  ..., -0.4348,  0.1919,  0.6699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:42:34 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:42:34 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 03:43:28 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 03:44:24 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 03:45:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.4964e-03,  2.8477e-03, -4.9114e-04,  ..., -2.2774e-03,
         -1.3943e-03, -3.8586e-03],
        [-1.8492e-03, -5.4169e-03, -2.6369e-04,  ..., -1.2207e-03,
         -3.3760e-03,  1.3995e-04],
        [-2.3937e-03,  2.3041e-03, -3.9825e-03,  ..., -1.4420e-03,
         -4.9362e-03, -3.7498e-03],
        ...,
        [ 6.4373e-04, -4.6730e-05, -3.2597e-03,  ..., -6.0616e-03,
          1.6823e-03, -1.6570e-05],
        [ 4.4632e-04, -1.1158e-03, -1.6985e-03,  ..., -3.6201e-03,
         -5.8060e-03,  6.5231e-04],
        [ 7.0286e-04,  3.2215e-03,  1.3647e-03,  ..., -6.7663e-04,
          2.7466e-03, -4.2305e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0764,  0.0102,  0.0229,  ...,  0.0051,  0.0072, -0.0127],
        [-0.0009, -0.0849, -0.0037,  ..., -0.0119, -0.0025,  0.0107],
        [-0.0053, -0.0039, -0.0784,  ...,  0.0136,  0.0045,  0.0151],
        ...,
        [-0.0104,  0.0033, -0.0086,  ..., -0.0674,  0.0025,  0.0039],
        [-0.0045,  0.0024,  0.0035,  ...,  0.0072, -0.0886,  0.0064],
        [ 0.0021, -0.0047,  0.0114,  ..., -0.0075,  0.0082, -0.0746]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0765, -0.0047,  0.0146,  ..., -0.0099, -0.0003,  0.0055],
        [-0.0014, -0.0699, -0.0114,  ...,  0.0019,  0.0153,  0.0045],
        [-0.0007,  0.0042, -0.0790,  ..., -0.0045, -0.0075,  0.0091],
        ...,
        [-0.0050, -0.0093, -0.0051,  ..., -0.0631,  0.0030, -0.0016],
        [-0.0031,  0.0025, -0.0029,  ...,  0.0027, -0.0772,  0.0065],
        [ 0.0080,  0.0011,  0.0061,  ...,  0.0044,  0.0090, -0.0776]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:45:21 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 03:45:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4331,  0.6436,  0.8857,  ...,  0.0062,  0.5508,  0.4717],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5400, -0.0126,  1.0068,  ..., -0.0146, -0.4553,  0.3103],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2844,  0.9492,  0.8359,  ...,  0.4268,  1.2773,  0.7759],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.3027, -0.0698,  1.3604,  ..., -0.0449,  1.3086,  0.5029],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:45:21 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:45:21 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 03:46:18 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 03:47:15 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 03:48:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.0185e-03,  3.4962e-03, -2.4748e-04,  ...,  8.9455e-04,
         -5.4836e-06, -4.3259e-03],
        [-5.4207e-03,  1.8444e-03, -4.5052e-03,  ...,  2.6894e-03,
         -2.0905e-03, -6.1264e-03],
        [-3.4142e-04, -1.4477e-03, -4.8485e-03,  ..., -8.4257e-04,
         -3.1071e-03, -3.2787e-03],
        ...,
        [-2.7294e-03, -1.7624e-03,  1.3742e-03,  ...,  2.0409e-03,
         -5.5027e-04,  6.0120e-03],
        [ 5.2872e-03, -4.3602e-03,  1.6584e-03,  ..., -1.6975e-04,
         -9.5215e-03, -2.4204e-03],
        [ 1.5841e-03,  7.2365e-03,  1.3618e-03,  ..., -3.8433e-03,
         -2.8076e-03, -7.5493e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1774e-01,  8.4076e-03, -1.1993e-02,  ..., -1.1528e-02,
         -6.9542e-03,  1.1330e-02],
        [-1.2550e-02, -1.0669e-01,  9.5367e-07,  ...,  6.5498e-03,
          3.0746e-03,  1.6602e-02],
        [ 3.9673e-03, -2.0790e-03, -1.0693e-01,  ...,  1.2054e-02,
         -2.5673e-03, -9.7122e-03],
        ...,
        [-1.2886e-02, -5.7411e-04,  1.5907e-03,  ..., -9.9854e-02,
         -1.2741e-02,  1.6769e-02],
        [ 4.2534e-03,  1.1635e-02, -1.6270e-03,  ...,  7.2708e-03,
         -1.0187e-01, -5.2528e-03],
        [ 1.6220e-02, -6.3820e-03, -1.0185e-02,  ..., -5.7373e-03,
          3.4847e-03, -1.1469e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1293,  0.0060,  0.0026,  ..., -0.0017,  0.0017,  0.0068],
        [-0.0086, -0.1416, -0.0008,  ...,  0.0061, -0.0005,  0.0207],
        [ 0.0125, -0.0047, -0.1371,  ..., -0.0010, -0.0051, -0.0068],
        ...,
        [-0.0082, -0.0041, -0.0021,  ..., -0.1356, -0.0055,  0.0074],
        [ 0.0140,  0.0163,  0.0043,  ...,  0.0130, -0.1455,  0.0134],
        [-0.0078, -0.0038,  0.0127,  ..., -0.0046,  0.0161, -0.1373]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:48:15 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 03:48:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2103,  0.7446,  0.7617,  ...,  0.1948,  0.6782,  0.3567],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5972,  0.2700,  1.0273,  ..., -0.2676,  0.1451,  0.3513],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8701,  1.0830,  1.3164,  ..., -0.1855,  1.4238,  1.9434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9175, -0.0408,  1.1904,  ..., -0.5200,  0.1523,  0.2036],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:48:15 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:48:15 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 03:49:15 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 03:50:15 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 03:51:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.6392e-03, -1.1177e-03,  1.6079e-03,  ..., -5.2986e-03,
         -5.9090e-03,  3.1376e-03],
        [-7.7057e-03,  1.5688e-03, -7.6962e-04,  ..., -5.5389e-03,
         -4.2963e-04,  7.1297e-03],
        [-5.4359e-03, -1.5526e-03,  3.1357e-03,  ..., -2.6035e-04,
         -6.7024e-03,  1.2922e-03],
        ...,
        [ 1.1360e-02,  5.5313e-05, -5.6038e-03,  ...,  7.7324e-03,
         -4.8637e-05, -6.1378e-03],
        [ 1.3323e-03, -3.6597e-04, -1.7099e-03,  ..., -1.7595e-03,
          4.0092e-03,  2.8133e-03],
        [ 2.7504e-03,  1.4772e-03, -7.1564e-03,  ...,  1.8847e-04,
          8.3089e-05, -1.1969e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0895, -0.0022,  0.0007,  ...,  0.0009, -0.0014, -0.0062],
        [ 0.0098, -0.0865,  0.0024,  ..., -0.0025, -0.0071, -0.0006],
        [ 0.0011,  0.0117, -0.0830,  ..., -0.0021,  0.0138,  0.0023],
        ...,
        [ 0.0137, -0.0112, -0.0021,  ..., -0.0578,  0.0166, -0.0018],
        [-0.0011,  0.0147, -0.0141,  ...,  0.0104, -0.0798, -0.0006],
        [ 0.0053,  0.0097, -0.0050,  ..., -0.0027, -0.0111, -0.0840]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1261, -0.0043, -0.0149,  ..., -0.0249,  0.0011, -0.0108],
        [ 0.0078, -0.1107, -0.0135,  ...,  0.0115, -0.0005,  0.0035],
        [-0.0017, -0.0088, -0.0991,  ...,  0.0169,  0.0022, -0.0107],
        ...,
        [-0.0131, -0.0103,  0.0095,  ..., -0.1180,  0.0095,  0.0080],
        [-0.0081,  0.0075, -0.0147,  ...,  0.0018, -0.1034,  0.0024],
        [-0.0022,  0.0074, -0.0068,  ..., -0.0079,  0.0038, -0.0968]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:51:18 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 03:51:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1562,  0.4495,  0.4019,  ...,  0.1968,  0.6436,  0.3621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7744, -0.0718,  0.7466,  ..., -0.0364,  0.7515,  0.2603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.1631, 2.5156, 1.2412,  ..., 0.1592, 2.1621, 1.9980], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.5703,  0.0347,  0.7178,  ...,  0.1807,  0.4238,  0.7725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:51:18 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:51:18 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 03:52:18 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 03:53:20 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 03:54:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.7504e-03,  9.7275e-04,  5.8651e-04,  ...,  5.0068e-06,
         -2.2545e-03, -1.1301e-03],
        [ 1.3762e-03,  6.0177e-04,  1.0223e-03,  ..., -3.0327e-03,
          2.6646e-03,  7.8678e-06],
        [ 1.0653e-03,  2.1839e-04,  3.7813e-04,  ...,  3.4547e-04,
         -1.2589e-03,  1.5430e-03],
        ...,
        [-3.2616e-03, -3.0708e-03, -2.0866e-03,  ...,  2.6741e-03,
         -1.7710e-03,  5.6505e-04],
        [ 5.3596e-03, -9.7275e-04,  2.7237e-03,  ...,  1.1187e-03,
          4.6463e-03,  2.3556e-03],
        [ 2.6932e-03,  2.3746e-04,  1.2531e-03,  ...,  9.2077e-04,
          1.6356e-04,  3.2539e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0997, -0.0116, -0.0073,  ..., -0.0083, -0.0034,  0.0113],
        [ 0.0032, -0.1240, -0.0028,  ...,  0.0090, -0.0041, -0.0007],
        [ 0.0108,  0.0026, -0.0980,  ..., -0.0056, -0.0126, -0.0060],
        ...,
        [-0.0043,  0.0138,  0.0016,  ..., -0.0977,  0.0009,  0.0131],
        [-0.0023, -0.0038, -0.0246,  ...,  0.0034, -0.1107, -0.0090],
        [-0.0024, -0.0028,  0.0067,  ..., -0.0071,  0.0111, -0.0950]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1002,  0.0040, -0.0154,  ...,  0.0023, -0.0129,  0.0048],
        [ 0.0052, -0.1283, -0.0047,  ...,  0.0007,  0.0020, -0.0023],
        [-0.0023, -0.0072, -0.1184,  ..., -0.0117,  0.0013,  0.0077],
        ...,
        [ 0.0037,  0.0113, -0.0006,  ..., -0.1039, -0.0034, -0.0062],
        [ 0.0050, -0.0049, -0.0081,  ...,  0.0107, -0.1165, -0.0013],
        [ 0.0144,  0.0055,  0.0015,  ..., -0.0152,  0.0210, -0.1184]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:54:26 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 03:54:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3970,  0.5488,  0.6011,  ..., -0.0955,  0.7061,  0.9482],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5571, -0.0185,  0.6064,  ..., -0.2834,  0.0892,  0.0878],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0696,  1.8828,  0.8569,  ...,  0.2195,  1.5000,  2.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.7139, -0.0360,  0.6641,  ...,  0.3242,  0.1440,  0.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:54:26 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:54:26 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 03:55:29 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 03:56:32 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 03:57:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.3825e-03, -7.1030e-03, -4.4403e-03,  ..., -5.3596e-03,
          1.3866e-03, -8.8882e-04],
        [ 1.8311e-04,  3.1567e-03,  8.5735e-04,  ...,  2.2087e-03,
         -1.2169e-03,  1.4400e-03],
        [-4.8542e-04,  1.0133e-06, -1.1391e-02,  ..., -7.9803e-03,
         -1.1225e-03,  2.2125e-03],
        ...,
        [ 3.1281e-03,  5.1594e-04, -4.3411e-03,  ..., -2.1839e-03,
         -1.4544e-03, -3.9940e-03],
        [-2.9874e-04, -3.3092e-03,  5.7449e-03,  ...,  2.4910e-03,
         -5.8098e-03, -3.2082e-03],
        [-3.1967e-03,  6.8283e-03,  1.6804e-03,  ..., -5.8708e-03,
         -2.9469e-03, -1.1421e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0620,  0.0133,  0.0001,  ..., -0.0086, -0.0126, -0.0126],
        [ 0.0004, -0.0639, -0.0046,  ..., -0.0085,  0.0167,  0.0089],
        [ 0.0119,  0.0037, -0.0530,  ..., -0.0146, -0.0063, -0.0042],
        ...,
        [-0.0073,  0.0081, -0.0060,  ..., -0.0615, -0.0106, -0.0119],
        [-0.0006,  0.0154,  0.0002,  ...,  0.0114, -0.0554,  0.0091],
        [ 0.0041,  0.0049,  0.0053,  ..., -0.0005,  0.0013, -0.0531]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0739,  0.0127, -0.0063,  ..., -0.0129,  0.0026,  0.0021],
        [-0.0047, -0.0791, -0.0020,  ...,  0.0026,  0.0064, -0.0028],
        [ 0.0115,  0.0025, -0.0871,  ..., -0.0039, -0.0147, -0.0147],
        ...,
        [-0.0176,  0.0032, -0.0039,  ..., -0.0845, -0.0080,  0.0011],
        [-0.0001,  0.0186,  0.0035,  ...,  0.0032, -0.0745,  0.0040],
        [-0.0038, -0.0017,  0.0024,  ...,  0.0043, -0.0081, -0.0736]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 03:57:40 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 03:57:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.0616, 1.1787, 0.5542,  ..., 0.0643, 1.0156, 0.8911], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7876,  0.0140,  0.3374,  ...,  0.0816,  0.2195,  0.3389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1145,  1.6758,  1.0410,  ...,  0.7754,  1.3574,  2.6289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.8398,  0.0750,  0.8467,  ...,  0.4375,  0.2268,  1.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 03:57:40 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 03:57:40 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 03:58:44 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 03:59:50 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 04:00:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.0763e-03, -1.3094e-03,  3.5973e-03,  ...,  2.8801e-03,
         -4.7350e-04,  2.2812e-03],
        [ 2.1315e-04, -7.3509e-03,  3.5763e-07,  ...,  2.7676e-03,
          1.3237e-03, -6.8784e-05],
        [-1.2846e-03,  2.6474e-03, -8.0719e-03,  ..., -8.2111e-04,
         -8.8215e-05, -1.0443e-03],
        ...,
        [-2.6455e-03,  2.7771e-03,  1.5278e-03,  ..., -8.4229e-03,
          6.2943e-04,  2.3937e-03],
        [ 7.6771e-04,  4.0474e-03,  8.1491e-04,  ...,  1.7023e-03,
         -1.2131e-02, -8.6164e-04],
        [ 3.1662e-03, -1.8988e-03, -4.9324e-03,  ..., -1.4048e-03,
         -5.0354e-04, -1.2619e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0390,  0.0077,  0.0205,  ..., -0.0079,  0.0074,  0.0065],
        [ 0.0096, -0.0518,  0.0040,  ...,  0.0184,  0.0196, -0.0136],
        [ 0.0115, -0.0013, -0.0673,  ..., -0.0012,  0.0159,  0.0037],
        ...,
        [ 0.0008, -0.0074,  0.0104,  ..., -0.0659,  0.0038, -0.0028],
        [ 0.0017, -0.0075, -0.0021,  ..., -0.0058, -0.0576,  0.0006],
        [-0.0032,  0.0038,  0.0050,  ...,  0.0036,  0.0100, -0.0530]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0587, -0.0102, -0.0066,  ...,  0.0011,  0.0001,  0.0087],
        [-0.0079, -0.0778, -0.0102,  ..., -0.0026, -0.0013,  0.0016],
        [ 0.0057, -0.0098, -0.0798,  ...,  0.0092,  0.0005,  0.0096],
        ...,
        [ 0.0025,  0.0047,  0.0188,  ..., -0.0581,  0.0029,  0.0041],
        [ 0.0025, -0.0035, -0.0060,  ...,  0.0064, -0.0768, -0.0019],
        [-0.0053, -0.0033, -0.0013,  ..., -0.0071,  0.0061, -0.0750]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:00:56 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 04:00:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0503,  0.8149,  0.3467,  ...,  0.0898,  0.6616,  0.9346],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8467, -0.0106,  0.2976,  ...,  0.1521,  0.0760,  0.3386],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5781,  1.5098,  0.8193,  ...,  0.8193,  1.5889,  2.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.6699,  0.4807, -0.0713,  ...,  0.6465,  0.7168,  1.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:00:56 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:00:56 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 04:02:01 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 04:03:11 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 04:04:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0003, -0.0016,  0.0025,  ...,  0.0018,  0.0015, -0.0030],
        [-0.0029,  0.0003, -0.0025,  ..., -0.0006,  0.0023, -0.0012],
        [-0.0036, -0.0056,  0.0016,  ...,  0.0048,  0.0023,  0.0015],
        ...,
        [ 0.0039,  0.0015, -0.0036,  ..., -0.0032,  0.0003,  0.0022],
        [ 0.0003,  0.0019,  0.0051,  ..., -0.0014, -0.0012,  0.0023],
        [-0.0021, -0.0038, -0.0022,  ...,  0.0065, -0.0014, -0.0083]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0724,  0.0065,  0.0055,  ..., -0.0096,  0.0033, -0.0021],
        [ 0.0067, -0.0764, -0.0027,  ..., -0.0082, -0.0032,  0.0074],
        [-0.0049,  0.0009, -0.0539,  ...,  0.0049,  0.0085, -0.0026],
        ...,
        [ 0.0020, -0.0066, -0.0070,  ..., -0.0567, -0.0157,  0.0096],
        [-0.0160, -0.0008, -0.0070,  ...,  0.0100, -0.0645,  0.0131],
        [-0.0009, -0.0048,  0.0051,  ..., -0.0062,  0.0017, -0.0609]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.2886e-02,  2.5253e-03,  7.8125e-03,  ...,  1.7872e-03,
         -1.0710e-03,  4.3564e-03],
        [ 1.3809e-03, -1.0712e-01,  2.7542e-03,  ..., -2.8076e-03,
          5.4131e-03,  1.9897e-02],
        [-1.5259e-05, -4.6730e-03, -9.4849e-02,  ..., -1.2802e-02,
          1.0849e-02, -9.1553e-03],
        ...,
        [-7.4043e-03, -5.9814e-03, -1.4267e-03,  ..., -1.0297e-01,
          1.1345e-02,  5.5695e-04],
        [ 2.8191e-03, -3.7537e-03, -3.7136e-03,  ..., -1.0384e-02,
         -9.3811e-02,  8.6021e-04],
        [-6.0158e-03,  7.2098e-03,  1.6785e-04,  ...,  6.8665e-05,
         -1.0239e-02, -8.0688e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:04:23 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 04:04:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0558,  0.6997,  0.4021,  ...,  0.3176,  0.5942,  1.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8433,  0.0289,  0.3450,  ...,  0.1901,  0.1252,  0.6558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4580,  1.0010,  0.6348,  ...,  0.5244,  1.2529,  2.3984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.0098,  0.0171, -1.3027,  ...,  0.7402,  0.8486,  1.3115],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:04:23 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:04:23 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 04:05:34 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 04:06:41 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 04:07:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.9929e-03, -2.6417e-03, -7.3738e-03,  ..., -3.4790e-03,
          1.1730e-03, -4.3373e-03],
        [ 3.9482e-03,  5.1193e-03,  5.6152e-03,  ...,  1.1930e-03,
         -2.7347e-04, -9.2459e-04],
        [ 2.6226e-04, -3.1586e-03,  2.9907e-03,  ..., -3.5419e-03,
         -2.1038e-03,  5.0812e-03],
        ...,
        [-1.4515e-03, -6.5851e-04, -2.6531e-03,  ...,  7.0724e-03,
         -2.1152e-03,  5.4121e-04],
        [-1.2465e-03, -6.9542e-03, -5.0879e-04,  ...,  2.5311e-03,
          5.9929e-03,  3.4943e-03],
        [ 7.2122e-06,  2.8439e-03,  1.0223e-02,  ..., -6.4011e-03,
         -6.2180e-03,  2.5349e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0418,  0.0184,  0.0141,  ..., -0.0098, -0.0043, -0.0126],
        [ 0.0044, -0.0355, -0.0069,  ..., -0.0022,  0.0072,  0.0014],
        [ 0.0047,  0.0014, -0.0315,  ...,  0.0112,  0.0078,  0.0126],
        ...,
        [-0.0193, -0.0240,  0.0005,  ..., -0.0473,  0.0044, -0.0009],
        [ 0.0165,  0.0075, -0.0079,  ..., -0.0087, -0.0258, -0.0003],
        [-0.0008,  0.0037, -0.0027,  ..., -0.0111, -0.0041, -0.0392]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0488, -0.0023,  0.0150,  ..., -0.0078,  0.0019,  0.0076],
        [-0.0057, -0.0436, -0.0056,  ...,  0.0004,  0.0059, -0.0105],
        [ 0.0170, -0.0190, -0.0603,  ..., -0.0107,  0.0141,  0.0060],
        ...,
        [-0.0155, -0.0079, -0.0068,  ..., -0.0544, -0.0137, -0.0148],
        [-0.0013, -0.0046, -0.0048,  ..., -0.0023, -0.0438,  0.0106],
        [-0.0042,  0.0097,  0.0021,  ...,  0.0050,  0.0078, -0.0391]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:07:48 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 04:07:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2405,  0.6021,  0.2976,  ...,  0.3284,  0.6274,  1.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6772,  0.1832, -0.0443,  ...,  0.2583,  0.2783,  0.5835],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2316,  0.7002,  0.2329,  ...,  0.5293,  1.5986,  2.1367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.6953,  0.0427, -1.4922,  ...,  0.5957,  0.4939,  1.2607],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:07:48 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:07:48 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 04:08:55 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 04:10:03 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 04:11:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0019, -0.0010,  0.0010,  ...,  0.0005, -0.0026,  0.0027],
        [-0.0039,  0.0050,  0.0018,  ..., -0.0019, -0.0021,  0.0034],
        [ 0.0003, -0.0010,  0.0029,  ..., -0.0003,  0.0005,  0.0008],
        ...,
        [-0.0009, -0.0031,  0.0003,  ...,  0.0011, -0.0016,  0.0030],
        [ 0.0045,  0.0010, -0.0013,  ...,  0.0029,  0.0045, -0.0091],
        [-0.0018, -0.0024, -0.0010,  ..., -0.0005, -0.0001,  0.0058]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0360, -0.0113, -0.0106,  ...,  0.0024,  0.0099, -0.0046],
        [ 0.0041, -0.0347,  0.0061,  ...,  0.0052, -0.0096, -0.0024],
        [-0.0042,  0.0049, -0.0160,  ..., -0.0100, -0.0015, -0.0096],
        ...,
        [ 0.0064, -0.0019, -0.0050,  ..., -0.0070, -0.0042, -0.0124],
        [ 0.0071, -0.0079, -0.0139,  ...,  0.0044, -0.0186,  0.0019],
        [-0.0041,  0.0016, -0.0080,  ...,  0.0004, -0.0036, -0.0191]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0552,  0.0091,  0.0052,  ...,  0.0159,  0.0051, -0.0018],
        [ 0.0252, -0.0557, -0.0155,  ..., -0.0014, -0.0133,  0.0199],
        [ 0.0020, -0.0019, -0.0612,  ..., -0.0006,  0.0030,  0.0030],
        ...,
        [-0.0057, -0.0046, -0.0255,  ..., -0.0616,  0.0047, -0.0018],
        [ 0.0120,  0.0147, -0.0068,  ..., -0.0087, -0.0490, -0.0115],
        [-0.0005,  0.0081, -0.0075,  ..., -0.0208, -0.0078, -0.0680]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:11:14 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 04:11:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1777,  0.3711,  0.2280,  ...,  0.1852,  0.4817,  0.8921],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7983, -0.0022, -0.5171,  ...,  0.2795,  0.3428,  0.4966],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0074,  0.1343,  0.5093,  ...,  0.1516,  1.5840,  2.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1729,  0.1168, -0.9619,  ...,  1.1562,  0.1477,  1.3154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:11:14 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:11:14 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 04:12:31 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 04:13:47 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 04:15:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.8858e-03, -9.6703e-04,  1.2026e-03,  ..., -8.3160e-04,
         -1.1482e-03,  1.3423e-04],
        [-1.4477e-03,  3.6278e-03, -1.2398e-04,  ...,  1.5707e-03,
          4.3106e-04,  5.8174e-04],
        [ 6.8367e-05, -1.2407e-03,  4.4060e-03,  ..., -4.4537e-04,
          1.8892e-03, -4.8089e-04],
        ...,
        [-6.9189e-04,  2.9469e-03, -2.2087e-03,  ...,  4.0970e-03,
         -9.2840e-04, -3.9506e-04],
        [-1.3008e-03,  9.9373e-04,  2.9068e-03,  ...,  2.0580e-03,
          1.9703e-03, -1.2457e-05],
        [-5.2452e-03,  1.9398e-03,  1.6479e-03,  ..., -3.7766e-04,
          2.2125e-03,  5.0888e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0202, -0.0044, -0.0097,  ...,  0.0031,  0.0117, -0.0083],
        [-0.0092, -0.0303,  0.0034,  ..., -0.0036,  0.0110,  0.0036],
        [ 0.0054,  0.0068, -0.0070,  ..., -0.0017, -0.0019, -0.0093],
        ...,
        [-0.0059, -0.0048, -0.0193,  ..., -0.0262,  0.0030,  0.0062],
        [-0.0141, -0.0071,  0.0026,  ...,  0.0049, -0.0079, -0.0034],
        [ 0.0023, -0.0059, -0.0102,  ..., -0.0005, -0.0070, -0.0145]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0566,  0.0099, -0.0069,  ...,  0.0002, -0.0119, -0.0029],
        [-0.0027, -0.0691, -0.0030,  ..., -0.0101, -0.0042,  0.0127],
        [ 0.0079,  0.0018, -0.0433,  ..., -0.0009,  0.0046, -0.0052],
        ...,
        [-0.0025, -0.0046, -0.0086,  ..., -0.0523,  0.0069, -0.0043],
        [-0.0153, -0.0224,  0.0145,  ..., -0.0030, -0.0547,  0.0063],
        [ 0.0011,  0.0057, -0.0029,  ...,  0.0070,  0.0014, -0.0610]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:15:07 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 04:15:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0891,  0.2512,  0.0721,  ...,  0.1975,  0.6079,  0.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6807,  0.0153, -0.5854,  ...,  0.2367,  0.2080,  0.4797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0058, -0.2593,  1.6348,  ...,  0.4431,  2.5059,  3.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.3516, -0.3672, -0.3545,  ...,  1.1875,  0.4204,  2.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:15:08 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:15:08 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 04:16:24 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 04:17:39 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 04:18:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.1621e-04, -1.3101e-04,  2.4843e-04,  ...,  1.3852e-04,
         -1.3351e-04, -1.9491e-05],
        [-7.0095e-04,  6.6698e-05,  3.3689e-04,  ...,  6.5386e-05,
          2.0802e-04, -2.9755e-04],
        [-4.1890e-04,  6.4564e-04, -6.5899e-04,  ...,  1.2982e-04,
          6.6710e-04, -1.2255e-04],
        ...,
        [-8.4591e-04,  3.5024e-04,  2.3508e-04,  ..., -1.1387e-03,
          3.9387e-04,  4.6039e-04],
        [-6.9761e-04,  1.5390e-04, -1.3399e-04,  ...,  1.1206e-05,
         -2.0742e-04,  6.8724e-05],
        [ 5.9795e-04, -5.1737e-04,  1.5426e-04,  ..., -3.3379e-04,
         -4.0579e-04, -1.0166e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0093,  0.0018, -0.0038,  ..., -0.0065, -0.0009,  0.0077],
        [-0.0009, -0.0257, -0.0018,  ...,  0.0067,  0.0111,  0.0039],
        [-0.0058,  0.0026, -0.0181,  ..., -0.0076,  0.0063, -0.0057],
        ...,
        [-0.0072,  0.0106, -0.0038,  ..., -0.0100,  0.0064,  0.0020],
        [-0.0019, -0.0040,  0.0079,  ..., -0.0130, -0.0272, -0.0006],
        [-0.0082, -0.0087, -0.0029,  ...,  0.0003, -0.0072, -0.0073]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0383, -0.0043, -0.0020,  ..., -0.0188, -0.0260, -0.0015],
        [-0.0072, -0.0440, -0.0013,  ...,  0.0038,  0.0085, -0.0104],
        [-0.0091, -0.0069, -0.0521,  ..., -0.0093,  0.0042,  0.0036],
        ...,
        [-0.0047,  0.0208,  0.0029,  ..., -0.0377,  0.0124,  0.0031],
        [ 0.0024, -0.0019,  0.0006,  ..., -0.0204, -0.0448, -0.0055],
        [ 0.0047,  0.0106, -0.0115,  ..., -0.0116,  0.0041, -0.0526]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:19:01 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 04:19:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.0068, 0.0466, 0.1519,  ..., 0.0576, 0.5840, 0.8823], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4453,  0.0453, -0.3809,  ...,  0.4395,  0.0777,  0.4805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1317,  0.2510,  1.2852,  ...,  1.2373,  2.2832,  3.3809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0527, -0.2571,  0.0938,  ...,  1.8789, -0.0215,  2.4707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:19:01 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:19:02 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 04:20:22 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 04:21:43 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 04:23:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2068e-03,  3.4904e-04,  5.6744e-05,  ..., -7.9274e-05,
          1.1225e-03,  7.1526e-05],
        [ 6.0415e-04,  1.2016e-03, -7.7105e-04,  ...,  6.5899e-04,
         -5.8031e-04, -1.4153e-03],
        [ 5.9509e-04,  2.7905e-03,  3.1948e-04,  ..., -4.6825e-04,
         -5.4932e-04, -2.1915e-03],
        ...,
        [ 3.2377e-04, -8.6546e-04, -2.7599e-03,  ...,  2.4662e-03,
          3.3092e-04, -2.5463e-03],
        [ 2.2392e-03,  4.3082e-04, -7.8344e-04,  ...,  1.2169e-03,
          7.8630e-04, -1.3113e-03],
        [-1.8902e-03,  5.1975e-04,  2.0771e-03,  ...,  1.0319e-03,
          1.2398e-03,  2.4471e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0262, -0.0066, -0.0151,  ..., -0.0162,  0.0128,  0.0066],
        [ 0.0099, -0.0053,  0.0121,  ..., -0.0012, -0.0019,  0.0176],
        [ 0.0114, -0.0007, -0.0066,  ..., -0.0018,  0.0119,  0.0045],
        ...,
        [-0.0053, -0.0137,  0.0027,  ..., -0.0058, -0.0197,  0.0078],
        [-0.0008, -0.0104, -0.0044,  ..., -0.0161, -0.0028,  0.0155],
        [ 0.0030,  0.0119,  0.0115,  ...,  0.0090,  0.0004, -0.0120]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0570, -0.0014, -0.0248,  ..., -0.0181,  0.0100,  0.0205],
        [ 0.0026, -0.0674,  0.0061,  ..., -0.0032, -0.0117,  0.0043],
        [ 0.0134, -0.0106, -0.0717,  ..., -0.0087,  0.0094,  0.0021],
        ...,
        [ 0.0144, -0.0082, -0.0050,  ..., -0.0771,  0.0062, -0.0079],
        [ 0.0005, -0.0201,  0.0007,  ...,  0.0027, -0.0876,  0.0284],
        [-0.0071,  0.0089,  0.0187,  ...,  0.0092,  0.0097, -0.0757]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:23:06 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 04:23:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0065, -0.0607,  0.5103,  ...,  0.1404,  0.8809,  1.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4939, -0.1018, -0.1743,  ...,  0.4177,  0.1671,  0.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5259,  0.3853,  1.5684,  ...,  1.5664,  2.8516,  3.3984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4492, -0.8447,  0.3235,  ...,  1.7842,  0.9824,  3.7695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:23:06 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:23:06 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 04:24:33 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 04:25:59 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 04:27:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.2708e-03,  2.5826e-03,  1.5612e-03,  ..., -2.4629e-04,
          2.3804e-03,  6.5117e-03],
        [ 4.6802e-04,  6.7377e-04,  5.7831e-03,  ..., -3.4542e-03,
         -5.6534e-03, -1.9932e-03],
        [ 3.2444e-03, -1.4086e-03,  3.4261e-04,  ..., -4.0722e-04,
          2.5654e-03,  9.7096e-05],
        ...,
        [ 1.7662e-03,  1.8396e-03,  4.1313e-03,  ...,  6.5613e-03,
         -1.3590e-03, -7.0572e-04],
        [ 4.7569e-03,  4.4937e-03, -8.0442e-04,  ...,  5.6114e-03,
          8.6594e-03, -5.1651e-03],
        [ 1.5173e-03, -3.3417e-03, -5.0507e-03,  ...,  2.9716e-03,
         -1.4582e-03,  1.1909e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 2.7527e-02,  1.3779e-02, -3.1452e-03,  ..., -7.9956e-03,
          4.3869e-05,  9.9106e-03],
        [-7.9880e-03, -2.5024e-02, -4.5013e-03,  ...,  1.3786e-02,
          1.0551e-02,  1.8204e-02],
        [-1.0223e-03,  8.4305e-04,  3.0396e-02,  ...,  1.1932e-02,
          9.0075e-04, -8.8196e-03],
        ...,
        [-8.2779e-03,  8.2855e-03, -1.5358e-02,  ...,  2.6093e-02,
          5.0964e-03,  3.2845e-03],
        [ 1.2299e-02, -8.0795e-03, -8.1177e-03,  ..., -1.3237e-02,
          1.0262e-02, -1.2817e-02],
        [-2.9716e-03, -6.3934e-03,  1.5831e-04,  ..., -4.4632e-03,
         -8.2016e-04,  1.2512e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0071, -0.0326,  0.0012,  ..., -0.0056,  0.0180,  0.0038],
        [ 0.0074, -0.0514,  0.0019,  ...,  0.0011, -0.0070,  0.0181],
        [-0.0016, -0.0104,  0.0167,  ...,  0.0025,  0.0057, -0.0012],
        ...,
        [-0.0079, -0.0010, -0.0092,  ...,  0.0147,  0.0222, -0.0064],
        [ 0.0112, -0.0021, -0.0050,  ...,  0.0115, -0.0014, -0.0054],
        [-0.0073,  0.0253, -0.0055,  ...,  0.0060,  0.0090,  0.0030]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:27:26 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 04:27:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0196,  0.1015,  0.3647,  ...,  0.3628,  0.7417,  1.0928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3396, -0.0598, -0.0222,  ...,  0.6060, -0.0081,  0.8350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6729,  0.9658,  1.9355,  ...,  1.2070,  3.2520,  3.5430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2646, -1.2266,  0.3772,  ...,  1.8340,  0.1753,  4.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:27:26 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:27:26 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 04:28:49 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 04:30:13 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 04:31:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.1900e-04, -2.6703e-05, -9.9182e-05,  ...,  1.0455e-04,
          1.7643e-04,  2.5368e-04],
        [ 7.4196e-04,  1.0443e-04,  4.6396e-04,  ..., -4.0841e-04,
         -1.6332e-04, -2.1195e-04],
        [ 8.6665e-05,  8.0884e-05,  7.9870e-04,  ..., -2.8062e-04,
          4.4632e-04, -3.4952e-04],
        ...,
        [ 3.4034e-05, -3.4690e-04, -4.0293e-04,  ...,  6.3992e-04,
          4.0007e-04, -3.0220e-05],
        [-4.2105e-04,  3.4595e-04, -2.6083e-04,  ..., -3.3140e-04,
          6.5088e-04,  4.7207e-05],
        [-3.6573e-04, -4.7624e-05,  6.9082e-05,  ...,  1.8895e-04,
          2.9683e-04,  1.2407e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0138, -0.0035,  0.0028,  ...,  0.0021,  0.0092,  0.0054],
        [-0.0096, -0.0181,  0.0096,  ...,  0.0081, -0.0109,  0.0029],
        [-0.0016,  0.0051, -0.0081,  ...,  0.0025, -0.0101,  0.0027],
        ...,
        [-0.0296,  0.0111, -0.0119,  ...,  0.0051, -0.0016, -0.0040],
        [ 0.0131,  0.0139,  0.0056,  ..., -0.0176,  0.0038, -0.0106],
        [ 0.0079, -0.0037, -0.0042,  ..., -0.0007, -0.0004,  0.0193]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0395, -0.0044,  0.0003,  ...,  0.0025,  0.0211,  0.0044],
        [-0.0194, -0.0298,  0.0019,  ...,  0.0222,  0.0029, -0.0116],
        [ 0.0089,  0.0051, -0.0107,  ...,  0.0070, -0.0070, -0.0080],
        ...,
        [-0.0219, -0.0060,  0.0005,  ..., -0.0208, -0.0039,  0.0091],
        [ 0.0159,  0.0082,  0.0025,  ..., -0.0088, -0.0061,  0.0095],
        [ 0.0052,  0.0032, -0.0231,  ..., -0.0040,  0.0169, -0.0297]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:31:42 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 04:31:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1062,  0.1372,  0.3662,  ...,  0.3542,  0.8003,  0.9536],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4192, -0.2311,  0.0172,  ...,  0.4666,  0.2864,  1.1689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.0068, 0.9683, 0.3379,  ..., 0.4697, 3.0117, 3.0742], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0596, -1.4629, -1.2939,  ...,  0.5820, -0.2671,  4.5820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:31:42 root INFO     [order_1_approx] starting weight calculation for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:31:42 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 04:33:10 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 04:34:36 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 04:36:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.5349e-03, -3.2854e-04,  9.8348e-06,  ..., -8.5711e-05,
          4.6909e-05, -2.9564e-05],
        [ 4.0603e-04,  1.5707e-03, -2.6405e-05,  ...,  2.1672e-04,
          4.1628e-04, -4.7565e-05],
        [ 3.7241e-04, -2.3341e-04,  2.2278e-03,  ..., -2.2924e-04,
         -5.2214e-04,  4.7088e-06],
        ...,
        [-7.5579e-05, -5.6386e-05,  3.3796e-05,  ...,  2.9221e-03,
          1.9848e-04, -4.4870e-04],
        [-3.3045e-04, -2.1160e-04,  5.3823e-05,  ..., -1.4102e-04,
          3.1433e-03,  4.1187e-05],
        [ 6.1154e-05,  2.1636e-05, -1.4973e-04,  ..., -1.3220e-04,
         -2.7204e-04,  3.1013e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.1090e-03,  6.7902e-03, -5.1737e-05,  ...,  1.1654e-03,
          1.1131e-02, -6.7139e-03],
        [-1.0376e-03, -7.3318e-03,  2.9659e-04,  ..., -6.8932e-03,
          1.1871e-02,  1.0094e-02],
        [-1.0048e-02,  4.6196e-03,  1.1635e-02,  ..., -1.5778e-02,
          5.2490e-03,  7.2403e-03],
        ...,
        [-1.2321e-02,  1.9424e-02, -1.3321e-02,  ...,  8.6823e-03,
         -5.2948e-03,  1.1765e-02],
        [ 1.4467e-03, -1.2459e-02, -3.5572e-03,  ..., -1.5202e-03,
          9.7351e-03,  1.2337e-02],
        [-5.1270e-03,  2.0218e-02,  3.7384e-04,  ...,  3.3970e-03,
          9.1934e-03,  7.6294e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0280,  0.0159,  0.0044,  ...,  0.0017,  0.0135, -0.0071],
        [ 0.0340, -0.0173, -0.0013,  ..., -0.0093, -0.0032,  0.0148],
        [-0.0015,  0.0228,  0.0197,  ..., -0.0099,  0.0109, -0.0037],
        ...,
        [ 0.0038, -0.0016,  0.0077,  ...,  0.0148, -0.0074, -0.0034],
        [-0.0007, -0.0145, -0.0099,  ..., -0.0065,  0.0027,  0.0218],
        [-0.0026,  0.0019,  0.0196,  ..., -0.0013,  0.0064,  0.0160]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:36:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too simplified, it is oversimplified
If something is too stressed, it is overstressed
If something is too spent, it is overspent
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too loaded, it is
2024-06-30 04:36:06 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 04:36:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2664, -0.2705, -0.0924,  ...,  0.3069, -0.3723, -0.1411],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1599, -0.1338,  0.1694,  ...,  0.1692, -0.3884, -0.5654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4441,  0.1340,  0.3518,  ...,  0.1019, -0.7046, -0.1008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6216,  0.1444,  0.2321,  ...,  0.2177, -0.4170, -0.0077],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:36:06 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:36:06 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 04:36:30 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 04:36:53 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 04:37:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.1242e-03, -1.7405e-04, -6.7353e-06,  ...,  4.4203e-04,
          3.1710e-04,  1.2517e-04],
        [ 7.9393e-04, -2.6779e-03, -4.4799e-04,  ..., -6.9714e-04,
         -1.7393e-04,  8.3542e-04],
        [ 1.0085e-04, -2.5034e-04, -3.3493e-03,  ...,  1.1909e-04,
         -9.9242e-05,  2.0957e-04],
        ...,
        [-5.8365e-04, -4.0865e-04,  2.0921e-04,  ..., -3.2597e-03,
         -5.8079e-04, -7.5340e-05],
        [-1.1265e-05, -3.2640e-04, -3.5644e-05,  ..., -2.2650e-04,
         -3.2864e-03, -8.6367e-05],
        [-8.9550e-04,  6.6996e-04, -6.6996e-05,  ...,  3.1137e-04,
         -5.8079e-04, -3.0499e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.8483e-02,  1.8530e-03,  1.2436e-03,  ...,  8.9569e-03,
         -3.3760e-03,  1.0347e-04],
        [-4.7874e-03, -3.7445e-02,  4.2953e-03,  ...,  2.1801e-03,
         -4.1199e-04, -3.5286e-03],
        [ 3.2730e-03, -7.8583e-03, -3.9581e-02,  ...,  7.2718e-04,
         -2.9964e-03,  5.4283e-03],
        ...,
        [ 1.1436e-02, -3.6964e-03, -9.8572e-03,  ..., -3.9429e-02,
          3.1776e-03, -5.2452e-04],
        [-3.9902e-03,  1.2436e-03,  9.6130e-04,  ...,  3.8910e-03,
         -3.3966e-02, -1.2398e-05],
        [ 2.8629e-03,  4.5052e-03,  2.7313e-03,  ...,  1.6994e-03,
         -1.1444e-04, -3.1433e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.6285e-02, -1.5507e-03,  1.8673e-03,  ..., -3.0422e-04,
          4.0150e-04, -2.8372e-04],
        [ 1.6747e-03, -3.5278e-02, -3.5839e-03,  ...,  1.4324e-03,
          5.5122e-03, -3.2187e-04],
        [-6.3438e-03, -2.0943e-03, -3.0930e-02,  ..., -9.4414e-04,
         -3.4714e-03,  1.4114e-03],
        ...,
        [-9.8801e-04,  5.2452e-05,  2.5806e-03,  ..., -3.3386e-02,
         -8.0156e-04, -2.0714e-03],
        [-1.4668e-03,  1.5965e-03,  1.9569e-03,  ..., -2.1133e-03,
         -3.1067e-02,  6.0921e-03],
        [-1.0090e-03, -3.3016e-03, -3.1090e-03,  ...,  5.4665e-03,
          1.4458e-03, -3.1860e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:37:19 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 04:37:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-5.1562e-01,  2.6250e-04,  4.6478e-02,  ..., -1.9092e-01,
        -5.3516e-01, -5.2197e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7114, -0.0773,  0.3806,  ..., -0.1284, -0.5151, -0.2920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6636,  0.3457,  0.3657,  ..., -0.3047, -0.9224,  0.3049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5752,  0.0550,  0.2078,  ..., -0.6528, -0.4197,  0.2147],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:37:19 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:37:19 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 04:37:43 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 04:38:06 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 04:38:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1496e-03, -2.9039e-04,  2.6524e-05,  ..., -1.6356e-03,
         -9.2220e-04,  1.6546e-04],
        [ 7.6008e-04, -4.1008e-03,  3.1424e-04,  ...,  8.4877e-04,
         -7.4816e-04, -5.3883e-04],
        [-5.1069e-04,  7.2622e-04, -4.0550e-03,  ...,  1.1082e-03,
         -6.2323e-04, -9.9421e-05],
        ...,
        [ 4.0126e-04, -5.2500e-04, -9.6893e-04,  ..., -4.2076e-03,
         -2.4338e-03, -3.4285e-04],
        [-9.8228e-05,  1.6975e-04,  9.5892e-04,  ...,  2.7609e-04,
         -3.3989e-03,  3.5763e-04],
        [ 1.1611e-04, -1.1539e-03, -2.8086e-04,  ..., -9.9850e-04,
         -3.9816e-04, -3.3474e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.0425e-02,  1.0780e-02, -4.6082e-03,  ...,  6.8283e-04,
          1.9007e-03, -6.2065e-03],
        [-3.8457e-04, -6.7627e-02, -1.5984e-03,  ...,  9.8724e-03,
          4.2458e-03,  6.5346e-03],
        [-4.1695e-03, -5.1308e-03, -5.1056e-02,  ...,  9.1629e-03,
         -6.8855e-03, -2.7199e-03],
        ...,
        [ 6.7558e-03, -2.1019e-03,  9.4986e-03,  ..., -6.1127e-02,
         -4.2915e-03,  8.4877e-04],
        [ 1.0178e-02, -1.1940e-02,  2.5272e-04,  ..., -3.4866e-03,
         -6.6040e-02,  7.0076e-03],
        [-1.0124e-02, -5.8937e-03,  7.6294e-05,  ..., -1.0109e-03,
          1.1263e-03, -6.8298e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0702,  0.0024, -0.0064,  ..., -0.0002,  0.0072,  0.0009],
        [-0.0005, -0.0811, -0.0085,  ...,  0.0063,  0.0036,  0.0042],
        [ 0.0064,  0.0023, -0.0613,  ...,  0.0012, -0.0050, -0.0072],
        ...,
        [ 0.0021,  0.0100,  0.0032,  ..., -0.0778, -0.0067, -0.0049],
        [-0.0052,  0.0008,  0.0024,  ...,  0.0048, -0.0751,  0.0026],
        [-0.0003,  0.0006,  0.0035,  ..., -0.0027,  0.0068, -0.0782]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:38:33 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 04:38:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5552,  0.1339,  0.4023,  ...,  0.1097, -0.8257, -0.1545],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9844,  0.2122,  0.3574,  ...,  0.3271, -0.6313, -0.0321],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5190,  0.2803,  0.4207,  ..., -0.2778, -0.5259,  0.0481],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8457,  0.3303,  0.0049,  ..., -0.5845, -0.5234,  1.1260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:38:33 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:38:33 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 04:38:58 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 04:39:23 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 04:39:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.4310e-03,  2.1935e-04, -2.6016e-03,  ...,  1.0717e-04,
         -1.4579e-04, -1.4257e-03],
        [ 2.7657e-04, -7.7057e-03,  1.9264e-03,  ...,  1.1320e-03,
         -5.2023e-04,  5.1069e-04],
        [ 8.9109e-05, -1.4019e-03, -5.5809e-03,  ...,  5.0020e-04,
         -1.8587e-03, -7.6234e-05],
        ...,
        [-1.6336e-03,  9.9659e-04, -4.6897e-04,  ..., -5.2071e-03,
          1.6489e-03, -6.8521e-04],
        [-1.0681e-03,  6.3562e-04, -1.6022e-03,  ..., -6.7616e-04,
         -5.1651e-03, -1.5888e-03],
        [ 1.3189e-03, -7.0810e-04,  2.4166e-03,  ..., -1.0967e-05,
          1.0977e-03, -6.1646e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.0039e-02, -4.4975e-03,  8.0872e-03,  ..., -1.5278e-03,
         -7.2136e-03, -5.4970e-03],
        [-2.8896e-03, -4.4708e-02, -5.5885e-04,  ..., -1.5802e-03,
         -4.6272e-03, -5.4283e-03],
        [ 9.3842e-03, -6.4850e-05, -4.4220e-02,  ..., -5.3024e-03,
         -1.9760e-03, -9.8610e-04],
        ...,
        [-2.4223e-03,  3.7498e-03, -2.6569e-03,  ..., -3.8086e-02,
          1.3838e-03,  2.5406e-03],
        [-6.1188e-03, -2.7618e-03,  4.0359e-03,  ..., -3.3474e-03,
         -3.5675e-02, -1.6909e-03],
        [ 1.1272e-03, -2.9583e-03, -2.4223e-03,  ..., -6.5994e-03,
         -5.5923e-03, -4.5898e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0398,  0.0040, -0.0033,  ...,  0.0023,  0.0017, -0.0027],
        [ 0.0070, -0.0317,  0.0043,  ..., -0.0025, -0.0008,  0.0049],
        [ 0.0035,  0.0012, -0.0312,  ..., -0.0083,  0.0031,  0.0031],
        ...,
        [ 0.0004, -0.0023, -0.0082,  ..., -0.0300,  0.0008, -0.0013],
        [-0.0060,  0.0057,  0.0079,  ...,  0.0015, -0.0231,  0.0004],
        [-0.0030,  0.0035,  0.0065,  ..., -0.0006,  0.0066, -0.0293]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:39:52 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 04:39:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8140,  0.3794,  0.4121,  ..., -0.3418, -1.0752,  0.3220],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9023,  0.0662,  0.3154,  ..., -0.9380, -0.6353,  0.3040],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7192,  0.6450,  0.3694,  ..., -0.1735,  0.2202,  0.0635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7051,  0.9102,  0.2292,  ..., -0.9482, -0.0654,  0.9307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:39:52 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:39:52 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 04:40:22 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 04:40:53 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 04:41:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.4496e-03,  5.6505e-04,  6.0081e-05,  ..., -3.2663e-04,
          1.4448e-03,  3.3069e-04],
        [ 7.8297e-04, -4.8141e-03, -1.8215e-04,  ..., -1.7147e-03,
          9.5510e-04,  8.1921e-04],
        [ 1.4091e-04, -6.2752e-04, -2.5043e-03,  ...,  3.8147e-04,
          2.0421e-04, -5.0783e-04],
        ...,
        [ 5.0545e-05, -2.8763e-03, -1.7643e-04,  ..., -3.4027e-03,
          1.7452e-03, -6.9904e-04],
        [-4.7922e-04, -1.5402e-04, -8.4496e-04,  ..., -1.4782e-03,
         -4.1351e-03,  1.3828e-05],
        [ 9.3412e-04, -2.2733e-04,  1.4782e-04,  ..., -3.8719e-04,
         -1.0300e-04, -3.1929e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0586,  0.0024, -0.0016,  ..., -0.0031,  0.0110, -0.0008],
        [ 0.0083, -0.0549, -0.0029,  ...,  0.0049,  0.0033, -0.0046],
        [-0.0009,  0.0072, -0.0578,  ...,  0.0113, -0.0168,  0.0038],
        ...,
        [ 0.0025,  0.0005,  0.0041,  ..., -0.0533,  0.0043, -0.0018],
        [ 0.0011, -0.0035, -0.0004,  ..., -0.0020, -0.0483,  0.0050],
        [ 0.0039, -0.0008, -0.0119,  ...,  0.0096, -0.0010, -0.0561]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0521, -0.0017,  0.0045,  ..., -0.0027,  0.0015,  0.0041],
        [ 0.0036, -0.0336, -0.0009,  ...,  0.0069,  0.0114, -0.0060],
        [ 0.0012, -0.0025, -0.0452,  ...,  0.0023, -0.0044,  0.0061],
        ...,
        [-0.0089, -0.0020, -0.0009,  ..., -0.0411,  0.0045, -0.0021],
        [-0.0018,  0.0005, -0.0044,  ..., -0.0080, -0.0345,  0.0031],
        [-0.0022, -0.0018, -0.0039,  ..., -0.0060, -0.0017, -0.0463]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:41:26 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 04:41:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5127,  0.2264,  0.3867,  ..., -0.2646, -0.4810,  0.0021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9595,  0.3467,  0.0138,  ..., -0.6274, -0.5601,  1.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7998,  0.7983,  0.5942,  ..., -0.3818,  1.0156, -0.0558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5850,  0.4800,  0.2125,  ..., -0.4946,  0.0076,  0.7881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:41:26 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:41:26 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 04:41:59 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 04:42:32 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 04:43:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.9226e-03,  2.5635e-03, -1.2865e-03,  ..., -7.5150e-04,
         -3.2654e-03,  2.2316e-03],
        [-2.2278e-03, -1.1644e-03, -1.2741e-03,  ...,  1.7204e-03,
          1.9159e-03,  5.1975e-04],
        [ 3.3169e-03, -1.1024e-03, -9.4223e-04,  ..., -2.1286e-03,
          9.6083e-04, -7.5626e-04],
        ...,
        [-1.2798e-03,  2.8381e-03, -2.0313e-03,  ..., -1.6651e-03,
         -4.8828e-03,  2.4662e-03],
        [ 1.2789e-03,  2.3346e-03, -1.1146e-04,  ...,  2.9030e-03,
         -1.2827e-04, -2.4319e-05],
        [-8.6975e-04, -3.0746e-03, -1.4591e-04,  ..., -9.2685e-05,
         -5.6696e-04, -1.7548e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0988, -0.0067,  0.0009,  ..., -0.0032,  0.0045,  0.0029],
        [-0.0026, -0.0884,  0.0023,  ...,  0.0089,  0.0009,  0.0067],
        [-0.0064, -0.0083, -0.0893,  ...,  0.0010,  0.0002,  0.0063],
        ...,
        [-0.0120, -0.0113, -0.0137,  ..., -0.0831,  0.0012, -0.0087],
        [ 0.0007,  0.0118,  0.0011,  ...,  0.0068, -0.0955,  0.0152],
        [-0.0045,  0.0008,  0.0103,  ..., -0.0028, -0.0063, -0.0902]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0886, -0.0069,  0.0059,  ..., -0.0019, -0.0032, -0.0014],
        [-0.0085, -0.0969,  0.0040,  ..., -0.0083, -0.0037, -0.0004],
        [-0.0037,  0.0016, -0.0908,  ...,  0.0002,  0.0077,  0.0059],
        ...,
        [-0.0009, -0.0029,  0.0004,  ..., -0.0822,  0.0074,  0.0047],
        [ 0.0033, -0.0024,  0.0021,  ...,  0.0006, -0.0952,  0.0068],
        [ 0.0033,  0.0014,  0.0064,  ..., -0.0080, -0.0072, -0.0981]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:43:07 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 04:43:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6641,  0.5806,  0.3057,  ..., -0.1516,  0.1748,  0.0309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7700,  1.0078,  0.2328,  ..., -0.9844, -0.0838,  1.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8145,  0.3933,  0.2615,  ..., -0.5146,  1.3721, -0.0696],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0156,  0.2192,  0.1771,  ..., -0.1809,  0.0267,  0.5859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:43:07 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:43:07 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 04:43:43 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 04:44:19 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 04:44:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0075, -0.0016,  0.0007,  ..., -0.0007,  0.0026, -0.0054],
        [ 0.0039, -0.0094,  0.0029,  ..., -0.0031,  0.0009, -0.0004],
        [-0.0003,  0.0020, -0.0084,  ..., -0.0006, -0.0003,  0.0012],
        ...,
        [ 0.0034, -0.0023,  0.0040,  ..., -0.0072, -0.0015,  0.0031],
        [ 0.0039, -0.0037,  0.0045,  ..., -0.0021, -0.0026,  0.0027],
        [ 0.0012, -0.0030,  0.0017,  ..., -0.0005, -0.0004, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0934,  0.0174,  0.0033,  ..., -0.0050, -0.0025, -0.0096],
        [ 0.0044, -0.1042,  0.0081,  ...,  0.0020, -0.0117,  0.0009],
        [-0.0041,  0.0218, -0.0958,  ..., -0.0006,  0.0116,  0.0002],
        ...,
        [ 0.0049, -0.0015,  0.0068,  ..., -0.0959,  0.0045,  0.0023],
        [-0.0108,  0.0023,  0.0004,  ...,  0.0027, -0.0906, -0.0077],
        [-0.0044,  0.0061, -0.0009,  ..., -0.0175, -0.0041, -0.1030]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0963,  0.0012, -0.0005,  ...,  0.0002, -0.0025,  0.0039],
        [ 0.0053, -0.1011, -0.0042,  ...,  0.0036, -0.0065,  0.0047],
        [ 0.0031, -0.0036, -0.1006,  ...,  0.0059,  0.0076, -0.0063],
        ...,
        [ 0.0081,  0.0022,  0.0062,  ..., -0.0996,  0.0038, -0.0063],
        [-0.0013, -0.0011, -0.0042,  ...,  0.0078, -0.0996, -0.0010],
        [-0.0024,  0.0045, -0.0074,  ..., -0.0061,  0.0039, -0.1136]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:44:59 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 04:44:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6797,  0.6943,  0.4458,  ..., -0.3313,  0.8296, -0.0889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5835,  0.5068,  0.1844,  ..., -0.4854,  0.0055,  0.7734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2246,  0.4507,  0.1991,  ..., -0.0747,  2.2305, -0.1294],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5005,  0.1227,  0.4600,  ..., -0.0317,  0.2712, -0.0664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:44:59 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:44:59 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 04:45:35 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 04:46:11 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 04:46:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.7073e-03,  3.3855e-04, -4.7207e-05,  ..., -9.7036e-04,
         -5.0392e-03,  2.5024e-03],
        [ 3.7117e-03, -8.4829e-04, -5.4979e-04,  ...,  2.0981e-03,
          1.6899e-03, -1.6851e-03],
        [ 1.0071e-03, -2.7142e-03, -3.5725e-03,  ..., -6.0892e-04,
         -2.3232e-03,  6.3848e-04],
        ...,
        [ 1.3618e-03,  4.7379e-03,  1.3037e-03,  ..., -4.1542e-03,
          2.1973e-03,  1.6336e-03],
        [-2.1553e-03,  3.6812e-04, -2.5806e-03,  ...,  7.1144e-04,
         -2.8324e-03,  2.1458e-05],
        [-3.9983e-04, -8.4352e-04,  7.3862e-04,  ..., -6.3658e-04,
          3.7880e-03, -3.9787e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0868, -0.0015,  0.0086,  ..., -0.0113,  0.0017, -0.0003],
        [-0.0081, -0.0872,  0.0027,  ..., -0.0009,  0.0021,  0.0036],
        [-0.0020, -0.0095, -0.0856,  ..., -0.0048, -0.0066,  0.0008],
        ...,
        [-0.0021,  0.0029, -0.0031,  ..., -0.0856, -0.0036, -0.0075],
        [ 0.0076, -0.0051,  0.0062,  ...,  0.0081, -0.0977,  0.0066],
        [ 0.0119,  0.0005, -0.0092,  ..., -0.0011,  0.0129, -0.0938]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.4482e-02,  5.0278e-03,  1.3447e-03,  ..., -4.3945e-03,
         -8.1024e-03, -7.7133e-03],
        [ 1.8482e-03, -8.3923e-02, -1.1047e-02,  ...,  3.3684e-03,
          7.3051e-03, -1.2222e-02],
        [ 2.0638e-03,  2.7809e-03, -8.6670e-02,  ...,  3.9177e-03,
         -1.4410e-03,  4.1924e-03],
        ...,
        [-4.6768e-03, -1.9073e-03, -5.7220e-06,  ..., -8.8257e-02,
          9.5444e-03,  7.4692e-03],
        [ 2.7409e-03,  1.1635e-04,  3.0975e-03,  ...,  1.0902e-02,
         -8.4839e-02, -8.4915e-03],
        [-2.6512e-03, -6.6032e-03,  6.4354e-03,  ..., -1.0471e-03,
         -2.5845e-03, -7.9712e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:46:51 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 04:46:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6694,  0.3159,  0.1851,  ..., -0.3977,  1.0723, -0.0853],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9697,  0.2106,  0.1521,  ..., -0.1606,  0.0207,  0.5532],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2583,  0.7373,  0.6606,  ..., -0.5347,  1.9746, -0.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2036, -0.0260,  0.2463,  ...,  0.0143,  0.0896,  0.2578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:46:51 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:46:51 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 04:47:34 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 04:48:15 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 04:48:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.3210e-03, -5.0163e-03,  2.1801e-03,  ..., -2.2650e-05,
         -3.0136e-03, -3.5210e-03],
        [ 2.1954e-03, -2.7905e-03, -1.7376e-03,  ..., -2.9697e-03,
         -1.6193e-03,  2.3537e-03],
        [-5.3024e-04, -1.1578e-03, -2.2354e-03,  ..., -4.8709e-04,
         -1.8864e-03, -7.0381e-04],
        ...,
        [-1.2331e-03, -1.2398e-03, -1.7557e-03,  ..., -1.4400e-03,
          3.1776e-03,  2.2240e-03],
        [ 1.1120e-03,  1.3771e-03,  1.3876e-04,  ..., -2.1019e-03,
         -4.6005e-03,  7.3099e-04],
        [ 5.9128e-03,  1.9464e-03, -1.0281e-03,  ..., -2.6474e-03,
          1.7309e-03, -9.3889e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.0027e-02,  9.9564e-04, -1.5572e-02,  ..., -3.2921e-03,
          1.2474e-03,  2.5196e-03],
        [ 1.2291e-02, -9.7717e-02,  1.7532e-02,  ...,  2.0828e-02,
          4.8523e-03,  2.0401e-02],
        [-9.4223e-03, -3.5076e-03, -8.0261e-02,  ..., -2.5269e-02,
         -7.0953e-04, -2.8248e-03],
        ...,
        [-5.4398e-03,  1.7975e-02, -2.5330e-03,  ..., -8.3313e-02,
         -3.6774e-03, -5.5847e-03],
        [ 8.5449e-03,  1.3039e-02,  9.0179e-03,  ...,  2.2507e-03,
         -7.8979e-02, -5.7907e-03],
        [ 1.8959e-03, -5.2719e-03,  3.2616e-03,  ...,  8.8215e-05,
          5.5656e-03, -1.1627e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0272e-01, -4.9591e-04, -7.3776e-03,  ..., -4.6616e-03,
          7.3929e-03, -1.1765e-02],
        [-6.4969e-05, -1.2817e-01,  1.0765e-02,  ..., -5.7602e-03,
          1.6804e-03,  1.3596e-02],
        [-2.9793e-03, -1.0366e-03, -1.1365e-01,  ..., -2.8152e-03,
         -9.7122e-03,  8.8348e-03],
        ...,
        [ 8.6823e-03,  1.1795e-02, -6.4774e-03,  ..., -1.0535e-01,
         -2.8114e-03,  1.2922e-03],
        [-7.3090e-03,  8.3237e-03, -1.0147e-02,  ..., -9.8228e-04,
         -9.8450e-02,  8.6060e-03],
        [-1.0490e-02,  4.4022e-03, -1.0040e-02,  ...,  3.5744e-03,
          4.7684e-03, -1.2329e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:48:59 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 04:48:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1318,  0.3086,  0.0758,  ..., -0.0720,  1.4688, -0.1128],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4500,  0.1066,  0.3301,  ..., -0.0435,  0.2130, -0.0737],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4326,  1.0469,  0.9453,  ..., -0.4294,  1.8535, -0.7402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5889,  0.1101,  0.8691,  ...,  0.2151, -0.1677,  0.3425],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:48:59 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:48:59 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 04:49:49 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 04:50:24 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 04:51:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0047,  0.0008, -0.0005,  ..., -0.0008, -0.0054, -0.0010],
        [ 0.0005, -0.0014, -0.0023,  ..., -0.0009, -0.0039,  0.0014],
        [-0.0011, -0.0030,  0.0037,  ...,  0.0003,  0.0030,  0.0034],
        ...,
        [ 0.0022, -0.0024,  0.0004,  ...,  0.0017, -0.0017,  0.0013],
        [-0.0010,  0.0012,  0.0011,  ...,  0.0014, -0.0041, -0.0015],
        [ 0.0036, -0.0016,  0.0028,  ...,  0.0002,  0.0067,  0.0033]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1066e-01, -1.2459e-02, -5.4474e-03,  ..., -1.0208e-02,
         -1.4305e-04,  3.3913e-03],
        [-4.4937e-03, -1.2201e-01, -1.0576e-03,  ...,  1.1040e-02,
         -3.2687e-04, -2.5902e-03],
        [-7.5455e-03,  6.3019e-03, -1.0742e-01,  ...,  2.2141e-02,
         -1.2150e-03, -4.0283e-03],
        ...,
        [-7.4081e-03,  4.4937e-03,  1.6235e-02,  ..., -1.2286e-01,
          1.1238e-02, -1.9379e-03],
        [-2.5902e-03,  1.5854e-02,  9.0332e-03,  ..., -1.9264e-03,
         -1.2561e-01,  8.2855e-03],
        [-3.3131e-03, -1.1223e-02, -3.0518e-05,  ..., -5.3253e-03,
         -9.7847e-04, -1.1890e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6785e-01, -1.1101e-03,  6.0196e-03,  ...,  8.0109e-05,
          1.6317e-03, -4.4680e-04],
        [-6.8130e-03, -1.6174e-01, -9.0256e-03,  ...,  7.1793e-03,
          5.0430e-03,  8.5754e-03],
        [-1.7357e-03, -4.5128e-03, -1.4539e-01,  ...,  1.0979e-02,
         -6.5804e-03, -7.9117e-03],
        ...,
        [-2.5463e-03,  2.3315e-02,  8.5983e-03,  ..., -1.5918e-01,
          4.5776e-04,  9.6283e-03],
        [ 1.8234e-03,  9.3613e-03,  5.0735e-03,  ..., -9.5825e-03,
         -1.6528e-01, -2.6836e-03],
        [ 3.5501e-04,  9.2545e-03,  1.4549e-02,  ..., -1.4221e-02,
          8.8882e-04, -1.5210e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:51:15 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 04:51:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1655,  0.4541,  0.3606,  ..., -0.3162,  1.2119, -0.0562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1626, -0.0368,  0.1571,  ...,  0.0224,  0.0580,  0.1747],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1533,  1.2842,  1.9941,  ..., -1.4053,  2.2168,  0.2764],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2358, -0.0963,  0.5791,  ...,  0.1460, -0.1844,  0.3159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:51:15 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:51:15 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 04:52:04 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 04:52:53 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 04:53:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.6523e-03,  6.6853e-04,  2.7823e-04,  ...,  1.2331e-03,
          7.9823e-04,  3.0327e-03],
        [ 5.8460e-04, -4.9667e-03,  2.5654e-03,  ...,  8.4114e-04,
          1.8988e-03,  1.1463e-03],
        [ 2.4719e-03, -2.0123e-03, -8.9645e-03,  ..., -2.0275e-03,
         -1.6327e-03, -2.3804e-03],
        ...,
        [ 1.8806e-03, -1.1024e-03,  3.0041e-03,  ..., -7.0648e-03,
         -1.3294e-03, -1.8716e-05],
        [ 4.4060e-04, -4.7340e-03,  1.9369e-03,  ...,  2.4185e-03,
         -4.7112e-03,  4.5395e-03],
        [-7.2145e-04, -3.3617e-04, -3.4924e-03,  ...,  2.6302e-03,
          1.2312e-03, -7.2060e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1105,  0.0097,  0.0087,  ...,  0.0128, -0.0051, -0.0067],
        [ 0.0006, -0.1178,  0.0102,  ...,  0.0039,  0.0072, -0.0037],
        [ 0.0163, -0.0095, -0.1086,  ...,  0.0038, -0.0202, -0.0016],
        ...,
        [ 0.0113, -0.0097, -0.0175,  ..., -0.1055,  0.0055, -0.0252],
        [ 0.0071, -0.0028,  0.0148,  ...,  0.0047, -0.1161, -0.0016],
        [ 0.0082,  0.0092, -0.0046,  ..., -0.0055,  0.0065, -0.1039]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0938,  0.0052,  0.0054,  ...,  0.0062, -0.0053, -0.0062],
        [ 0.0102, -0.0997, -0.0104,  ..., -0.0024, -0.0145, -0.0038],
        [-0.0073, -0.0024, -0.1083,  ...,  0.0094, -0.0032,  0.0162],
        ...,
        [ 0.0031, -0.0097,  0.0081,  ..., -0.0868,  0.0044, -0.0125],
        [ 0.0061, -0.0144, -0.0006,  ...,  0.0100, -0.0996, -0.0046],
        [ 0.0123, -0.0021,  0.0020,  ...,  0.0089, -0.0010, -0.1008]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:53:48 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 04:53:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2830,  0.6240,  0.4922,  ..., -0.2856,  1.0723, -0.4604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4663,  0.0670,  0.5840,  ...,  0.1238, -0.1454,  0.2695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2793,  1.2793,  1.8965,  ..., -2.5430,  2.3477,  0.6270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2529,  0.0240,  0.9907,  ...,  0.3530, -0.2764,  0.3662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:53:48 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:53:48 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 04:54:41 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 04:55:33 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 04:56:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0099, -0.0024,  0.0008,  ..., -0.0010, -0.0002,  0.0006],
        [-0.0023,  0.0105, -0.0022,  ...,  0.0028,  0.0013, -0.0038],
        [-0.0033,  0.0005,  0.0101,  ..., -0.0021,  0.0048, -0.0022],
        ...,
        [-0.0047,  0.0018,  0.0069,  ...,  0.0104, -0.0054,  0.0043],
        [-0.0022, -0.0014, -0.0004,  ..., -0.0025,  0.0140,  0.0011],
        [-0.0001,  0.0016,  0.0023,  ..., -0.0002, -0.0015,  0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1346, -0.0041, -0.0037,  ..., -0.0108,  0.0047, -0.0060],
        [ 0.0123, -0.1340, -0.0077,  ...,  0.0019, -0.0052, -0.0025],
        [-0.0127, -0.0012, -0.1283,  ..., -0.0009,  0.0023, -0.0221],
        ...,
        [-0.0238, -0.0114,  0.0094,  ..., -0.1364,  0.0054,  0.0149],
        [-0.0008, -0.0050,  0.0044,  ..., -0.0120, -0.1372,  0.0016],
        [-0.0068, -0.0083, -0.0075,  ..., -0.0197,  0.0054, -0.1207]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2081,  0.0175,  0.0209,  ..., -0.0033, -0.0055, -0.0049],
        [-0.0033, -0.2290, -0.0153,  ..., -0.0038,  0.0145, -0.0024],
        [ 0.0037,  0.0056, -0.2108,  ...,  0.0082,  0.0037, -0.0140],
        ...,
        [-0.0013, -0.0008, -0.0035,  ..., -0.2394,  0.0111, -0.0029],
        [ 0.0016,  0.0049, -0.0116,  ...,  0.0143, -0.2184,  0.0015],
        [ 0.0062, -0.0056, -0.0033,  ..., -0.0020,  0.0026, -0.2167]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:56:30 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 04:56:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0610,  0.7725,  1.1064,  ..., -0.8535,  1.3311,  0.1151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2217, -0.0942,  0.3979,  ...,  0.1119, -0.1575,  0.2106],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2590,  1.5781,  1.8887,  ..., -2.6641,  2.9492,  0.8843],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5835,  0.9756,  1.7168,  ...,  0.3564,  0.5264,  0.8042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:56:30 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:56:30 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 04:57:21 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 04:58:17 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 04:59:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.3853e-03, -1.8311e-04, -3.0303e-04,  ..., -8.2302e-04,
         -5.3787e-03, -2.4080e-05],
        [-1.4515e-03, -5.7983e-03,  1.7300e-03,  ..., -2.5749e-03,
         -3.9062e-03, -2.7027e-03],
        [ 3.2187e-05,  3.8948e-03, -7.8964e-03,  ..., -1.5774e-03,
         -2.2945e-03, -7.9346e-03],
        ...,
        [-1.0407e-04, -4.0770e-04, -5.1918e-03,  ..., -8.4763e-03,
          4.1275e-03,  4.3488e-04],
        [-1.3533e-03,  6.7568e-04, -4.0703e-03,  ..., -1.7977e-03,
         -8.5526e-03, -5.3453e-04],
        [ 5.5275e-03,  6.3419e-04,  2.2018e-04,  ..., -6.1464e-04,
          1.0586e-04, -4.2572e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0854, -0.0046,  0.0195,  ...,  0.0090,  0.0016,  0.0007],
        [-0.0049, -0.0870,  0.0050,  ..., -0.0091, -0.0078,  0.0008],
        [ 0.0012, -0.0049, -0.0878,  ..., -0.0010,  0.0129,  0.0035],
        ...,
        [-0.0028, -0.0010,  0.0028,  ..., -0.0808, -0.0043, -0.0121],
        [-0.0068,  0.0092, -0.0041,  ..., -0.0022, -0.0890,  0.0060],
        [-0.0060,  0.0056, -0.0091,  ...,  0.0053, -0.0050, -0.0844]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0729, -0.0064,  0.0102,  ...,  0.0024,  0.0016,  0.0053],
        [-0.0052, -0.0754, -0.0077,  ...,  0.0013,  0.0130,  0.0030],
        [-0.0102,  0.0021, -0.0823,  ..., -0.0103, -0.0087,  0.0061],
        ...,
        [-0.0042, -0.0029, -0.0081,  ..., -0.0750,  0.0048, -0.0012],
        [-0.0016,  0.0078,  0.0038,  ..., -0.0030, -0.0814,  0.0108],
        [ 0.0049,  0.0028,  0.0043,  ...,  0.0025,  0.0077, -0.0726]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 04:59:13 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 04:59:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1602,  0.7163,  1.0449,  ..., -1.4619,  1.3682,  0.3467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1907, -0.0183,  0.6738,  ...,  0.2272, -0.1949,  0.2483],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3708,  1.7422,  1.3799,  ..., -2.9043,  2.6895,  1.1045],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2422,  0.2368,  1.0986,  ...,  0.5015,  0.8164,  0.7456],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 04:59:13 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 04:59:13 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 05:00:09 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 05:01:06 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 05:02:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0094,  0.0029,  0.0053,  ..., -0.0024,  0.0009, -0.0064],
        [-0.0070,  0.0003, -0.0016,  ...,  0.0041,  0.0006, -0.0046],
        [-0.0018, -0.0032, -0.0096,  ..., -0.0015, -0.0012, -0.0041],
        ...,
        [-0.0029, -0.0011,  0.0029,  ..., -0.0006, -0.0028,  0.0051],
        [ 0.0035, -0.0069,  0.0049,  ..., -0.0019, -0.0129, -0.0028],
        [ 0.0037,  0.0072,  0.0006,  ..., -0.0063, -0.0060, -0.0114]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1069, -0.0042,  0.0030,  ..., -0.0098, -0.0025, -0.0005],
        [-0.0090, -0.1063,  0.0008,  ...,  0.0010,  0.0140,  0.0068],
        [ 0.0080, -0.0033, -0.1127,  ...,  0.0102,  0.0078,  0.0004],
        ...,
        [-0.0055, -0.0022,  0.0021,  ..., -0.0894, -0.0130,  0.0054],
        [ 0.0011,  0.0009,  0.0073,  ..., -0.0007, -0.0952, -0.0007],
        [-0.0027, -0.0012, -0.0034,  ..., -0.0009,  0.0019, -0.1117]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1405,  0.0002,  0.0060,  ..., -0.0071,  0.0046,  0.0099],
        [-0.0156, -0.1509,  0.0006,  ...,  0.0080, -0.0019,  0.0163],
        [ 0.0095,  0.0028, -0.1445,  ..., -0.0012, -0.0067, -0.0038],
        ...,
        [-0.0071, -0.0051,  0.0075,  ..., -0.1395, -0.0030,  0.0104],
        [ 0.0121,  0.0128, -0.0003,  ...,  0.0149, -0.1538,  0.0098],
        [-0.0079,  0.0031,  0.0095,  ..., -0.0004,  0.0160, -0.1493]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:02:05 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 05:02:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1063,  0.8110,  0.9146,  ..., -1.4033,  1.5967,  0.4163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3801,  0.5679,  0.9487,  ...,  0.1943,  0.3481,  0.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1309,  1.3291,  1.2725,  ..., -3.6875,  3.0098,  1.2812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3994, -0.0447,  1.0039,  ..., -0.0806,  0.1899, -0.2896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:02:06 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:02:06 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 05:03:05 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 05:04:05 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 05:05:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0098, -0.0019, -0.0025,  ..., -0.0032, -0.0089,  0.0027],
        [-0.0008,  0.0115, -0.0040,  ..., -0.0027,  0.0013, -0.0016],
        [-0.0035, -0.0031,  0.0091,  ..., -0.0008, -0.0025,  0.0031],
        ...,
        [ 0.0101, -0.0011, -0.0069,  ...,  0.0156, -0.0037,  0.0040],
        [-0.0016, -0.0033,  0.0043,  ...,  0.0003,  0.0153,  0.0097],
        [ 0.0058,  0.0080, -0.0078,  ...,  0.0009,  0.0022,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0820,  0.0085,  0.0008,  ...,  0.0033, -0.0029,  0.0069],
        [ 0.0093, -0.0879, -0.0044,  ...,  0.0008,  0.0093, -0.0116],
        [ 0.0108,  0.0039, -0.0782,  ..., -0.0038,  0.0090, -0.0030],
        ...,
        [ 0.0067, -0.0084,  0.0022,  ..., -0.0751,  0.0116,  0.0006],
        [ 0.0010,  0.0183, -0.0025,  ...,  0.0116, -0.0964, -0.0051],
        [ 0.0015,  0.0248,  0.0016,  ...,  0.0033, -0.0011, -0.0764]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1158, -0.0039, -0.0122,  ..., -0.0117, -0.0003, -0.0011],
        [ 0.0010, -0.1105, -0.0098,  ...,  0.0128,  0.0039,  0.0065],
        [ 0.0039, -0.0125, -0.1046,  ...,  0.0018,  0.0014, -0.0081],
        ...,
        [-0.0055, -0.0060, -0.0052,  ..., -0.1207,  0.0163, -0.0033],
        [ 0.0034,  0.0090, -0.0173,  ...,  0.0103, -0.1187,  0.0056],
        [-0.0076,  0.0054, -0.0033,  ..., -0.0102,  0.0045, -0.1046]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:05:06 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 05:05:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1777,  0.8311,  0.6465,  ..., -1.4199,  1.3184,  0.5151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7280,  0.1044,  0.5957,  ...,  0.2671,  0.4656,  0.3962],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8184,  1.4014,  1.3301,  ..., -3.3828,  2.9902,  1.6162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7588,  0.0737,  0.3804,  ...,  0.6060, -0.7603, -0.2698],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:05:06 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:05:06 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 05:06:07 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 05:07:08 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 05:08:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.3092e-03,  2.5845e-03,  1.5574e-03,  ..., -2.2793e-03,
         -4.0412e-05,  1.1702e-03],
        [ 3.9711e-03,  2.3479e-03,  2.5654e-04,  ..., -2.8572e-03,
          2.0180e-03, -3.1528e-03],
        [ 2.1744e-03, -3.2115e-04,  1.0796e-03,  ..., -1.7338e-03,
         -9.1362e-04, -2.4939e-04],
        ...,
        [ 1.4853e-04, -1.7891e-03, -9.3651e-04,  ...,  5.9433e-03,
         -3.6793e-03, -1.6522e-04],
        [ 1.2760e-03,  8.9931e-04,  3.9339e-04,  ...,  2.4343e-04,
         -1.1568e-03,  3.4389e-03],
        [ 1.5879e-04, -4.0865e-04,  1.2007e-03,  ...,  2.5101e-03,
          1.1520e-03,  2.2812e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0781, -0.0078, -0.0119,  ..., -0.0111,  0.0075,  0.0060],
        [-0.0030, -0.0919,  0.0003,  ...,  0.0002, -0.0016,  0.0010],
        [ 0.0010,  0.0061, -0.0794,  ...,  0.0139,  0.0007,  0.0011],
        ...,
        [ 0.0005,  0.0050, -0.0113,  ..., -0.0804,  0.0029,  0.0085],
        [ 0.0086, -0.0086, -0.0027,  ...,  0.0003, -0.0939, -0.0088],
        [ 0.0020,  0.0139,  0.0064,  ...,  0.0167, -0.0005, -0.0669]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1052,  0.0017, -0.0114,  ..., -0.0084, -0.0124,  0.0050],
        [-0.0121, -0.1433, -0.0111,  ..., -0.0019, -0.0046, -0.0058],
        [ 0.0006, -0.0028, -0.1328,  ..., -0.0098,  0.0067,  0.0056],
        ...,
        [ 0.0095,  0.0063,  0.0033,  ..., -0.1088, -0.0015, -0.0097],
        [-0.0004, -0.0015, -0.0061,  ...,  0.0122, -0.1240,  0.0117],
        [ 0.0148,  0.0142, -0.0014,  ..., -0.0119,  0.0140, -0.1344]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:08:15 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 05:08:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5220,  0.6655,  0.5732,  ..., -1.7998,  1.4766,  0.6074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2622, -0.0199,  0.5020,  ..., -0.0436,  0.1088, -0.1849],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7295,  0.6270,  1.4541,  ..., -3.0898,  2.7930,  1.8643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5332, -0.2695,  0.3013,  ...,  0.6855, -0.7432, -0.3206],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:08:15 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:08:15 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 05:09:17 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 05:10:21 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 05:11:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.2621e-03, -1.0834e-03, -2.5940e-03,  ...,  4.1504e-03,
         -9.5215e-03, -7.0610e-03],
        [-1.7226e-05, -6.8169e-03, -4.2839e-03,  ...,  1.7099e-03,
         -3.4370e-03,  2.9945e-04],
        [ 5.3825e-03, -8.6117e-04, -1.6373e-02,  ..., -3.2091e-04,
         -3.4752e-03,  2.4986e-03],
        ...,
        [-2.1076e-03, -2.6245e-03,  4.4441e-03,  ..., -1.8875e-02,
          5.3482e-03, -5.5838e-04],
        [ 5.5656e-03,  2.9125e-03,  4.2191e-03,  ...,  3.6955e-05,
         -2.2614e-02, -1.4651e-04],
        [ 9.9945e-04,  6.7329e-03, -7.5188e-03,  ..., -3.7880e-03,
         -1.4057e-03, -1.3741e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0515,  0.0055, -0.0004,  ..., -0.0048, -0.0116, -0.0131],
        [-0.0094, -0.0721, -0.0074,  ..., -0.0027,  0.0097,  0.0153],
        [-0.0034, -0.0101, -0.0566,  ...,  0.0044, -0.0068, -0.0020],
        ...,
        [-0.0008,  0.0016, -0.0027,  ..., -0.0460, -0.0165, -0.0082],
        [ 0.0025,  0.0230, -0.0003,  ...,  0.0017, -0.0621,  0.0127],
        [ 0.0061,  0.0008,  0.0087,  ...,  0.0063, -0.0047, -0.0642]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0946,  0.0032, -0.0041,  ..., -0.0061,  0.0071,  0.0031],
        [-0.0139, -0.0995, -0.0088,  ...,  0.0094,  0.0033,  0.0134],
        [ 0.0089,  0.0024, -0.0988,  ..., -0.0004, -0.0208, -0.0109],
        ...,
        [-0.0123, -0.0018,  0.0031,  ..., -0.0918, -0.0177,  0.0050],
        [ 0.0089,  0.0264, -0.0079,  ...,  0.0024, -0.0932,  0.0058],
        [ 0.0026, -0.0020,  0.0038,  ...,  0.0058, -0.0004, -0.0900]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:11:24 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 05:11:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3721,  0.6543,  0.5947,  ..., -1.5449,  1.4053,  0.7144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3899,  0.0334,  0.1818,  ...,  0.2839, -0.3572, -0.1683],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9697,  0.3613,  1.6562,  ..., -3.2969,  2.2637,  2.3438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8320,  0.3320,  0.4709,  ...,  0.6289, -0.7310, -0.3733],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:11:24 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:11:24 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 05:12:31 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 05:13:38 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 05:14:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0101, -0.0044,  0.0087,  ..., -0.0006,  0.0010, -0.0001],
        [ 0.0002,  0.0062, -0.0047,  ...,  0.0010, -0.0003,  0.0029],
        [-0.0046,  0.0012, -0.0088,  ..., -0.0042, -0.0005, -0.0022],
        ...,
        [ 0.0004,  0.0012, -0.0005,  ...,  0.0014,  0.0022,  0.0012],
        [ 0.0121,  0.0080, -0.0035,  ..., -0.0043, -0.0100, -0.0002],
        [ 0.0054,  0.0058,  0.0049,  ..., -0.0044,  0.0034, -0.0082]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.4912e-02,  6.4354e-03,  8.5068e-03,  ..., -2.2552e-02,
         -4.5547e-03,  6.9695e-03],
        [ 1.4168e-02, -5.3925e-02,  9.9258e-03,  ...,  5.8212e-03,
          9.8953e-03, -1.2459e-02],
        [ 5.0316e-03, -2.0981e-05, -4.8401e-02,  ..., -1.0429e-02,
          1.2383e-02,  1.1871e-02],
        ...,
        [ 6.3934e-03, -6.8741e-03, -6.1035e-05,  ..., -5.0110e-02,
          1.5945e-02, -1.3809e-02],
        [ 1.1078e-02, -7.3814e-03, -4.7951e-03,  ..., -3.9787e-03,
         -5.7281e-02,  7.3814e-03],
        [-6.4201e-03,  1.4442e-02,  7.4234e-03,  ..., -5.2986e-03,
          1.1581e-02, -3.8177e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0558, -0.0139, -0.0026,  ..., -0.0035, -0.0040,  0.0058],
        [-0.0011, -0.0834, -0.0118,  ..., -0.0016,  0.0050, -0.0030],
        [ 0.0018, -0.0097, -0.0914,  ..., -0.0025,  0.0110, -0.0031],
        ...,
        [ 0.0134,  0.0018,  0.0122,  ..., -0.0583,  0.0148, -0.0037],
        [ 0.0101, -0.0066, -0.0036,  ...,  0.0036, -0.0842,  0.0058],
        [-0.0233,  0.0058,  0.0029,  ..., -0.0145,  0.0106, -0.0787]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:14:42 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 05:14:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3079,  0.2798,  0.6152,  ..., -1.3730,  1.2666,  0.8018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2708, -0.1194,  0.1272,  ...,  0.3186, -0.3481, -0.1980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0791, -0.1572,  1.9355,  ..., -3.9648,  1.9092,  2.6641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9272,  0.3662, -0.1790,  ...,  0.3115, -0.5293, -0.2510],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:14:42 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:14:42 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 05:15:52 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 05:17:01 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 05:18:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0027, -0.0015,  0.0032,  ..., -0.0029,  0.0022, -0.0037],
        [-0.0054, -0.0006,  0.0009,  ..., -0.0019,  0.0004, -0.0067],
        [-0.0021, -0.0070,  0.0007,  ...,  0.0010,  0.0025, -0.0073],
        ...,
        [ 0.0022, -0.0005, -0.0022,  ..., -0.0007, -0.0037, -0.0031],
        [ 0.0029,  0.0050,  0.0063,  ..., -0.0007, -0.0014,  0.0063],
        [ 0.0011,  0.0013, -0.0005,  ...,  0.0067,  0.0020, -0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0460, -0.0010, -0.0038,  ...,  0.0111,  0.0037, -0.0115],
        [ 0.0065, -0.0414, -0.0180,  ..., -0.0080,  0.0063, -0.0019],
        [-0.0151,  0.0079, -0.0508,  ...,  0.0218,  0.0134, -0.0151],
        ...,
        [-0.0070,  0.0008,  0.0104,  ..., -0.0438, -0.0104,  0.0128],
        [-0.0049, -0.0140,  0.0028,  ...,  0.0007, -0.0391,  0.0172],
        [-0.0064,  0.0122,  0.0008,  ...,  0.0057, -0.0089, -0.0523]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0888,  0.0050,  0.0043,  ...,  0.0057,  0.0035, -0.0035],
        [ 0.0113, -0.1021, -0.0034,  ..., -0.0101,  0.0076,  0.0186],
        [ 0.0001,  0.0032, -0.0856,  ..., -0.0076,  0.0045, -0.0058],
        ...,
        [-0.0070,  0.0096, -0.0030,  ..., -0.0971,  0.0082,  0.0071],
        [ 0.0013, -0.0164, -0.0169,  ..., -0.0115, -0.0898,  0.0038],
        [-0.0101,  0.0022,  0.0044,  ..., -0.0013, -0.0041, -0.0893]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:18:12 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 05:18:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4268,  0.1484,  0.6777,  ..., -1.4365,  1.0127,  0.9990],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3794,  0.1425,  0.1818,  ...,  0.2722, -0.2988, -0.2112],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8540, -0.6353,  1.5947,  ..., -3.8379,  2.3203,  2.4355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4336, -0.2729, -1.1621,  ..., -0.2158,  0.0620, -0.4341],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:18:12 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:18:12 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 05:19:22 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 05:20:34 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 05:21:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0037, -0.0029, -0.0075,  ..., -0.0001,  0.0018, -0.0036],
        [ 0.0061, -0.0046, -0.0012,  ...,  0.0049, -0.0048,  0.0028],
        [ 0.0010, -0.0057, -0.0046,  ...,  0.0009, -0.0038,  0.0059],
        ...,
        [-0.0024, -0.0043,  0.0008,  ...,  0.0015, -0.0035,  0.0048],
        [ 0.0005, -0.0051,  0.0066,  ..., -0.0035, -0.0074, -0.0002],
        [-0.0020,  0.0047,  0.0054,  ..., -0.0076,  0.0005,  0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.9449e-02, -2.4395e-03,  2.4300e-03,  ..., -1.3855e-02,
          1.5163e-03, -5.8174e-03],
        [ 7.9117e-03, -2.1515e-02, -5.2185e-03,  ..., -1.3733e-02,
          7.8812e-03, -9.7122e-03],
        [ 4.0817e-03,  3.3989e-03, -1.5190e-02,  ..., -5.6534e-03,
          6.7711e-03, -3.2349e-03],
        ...,
        [-5.4131e-03,  6.4392e-03,  1.0014e-03,  ..., -2.9541e-02,
          3.9864e-04,  1.1688e-02],
        [ 6.9580e-03, -8.1329e-03, -8.8654e-03,  ..., -1.3542e-02,
         -2.8427e-02,  6.9122e-03],
        [ 3.1357e-03,  8.2731e-05, -6.5308e-03,  ...,  1.1597e-02,
          6.8703e-03, -2.6108e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.0476e-02,  2.6703e-05,  8.8501e-03,  ..., -1.8723e-02,
         -2.1076e-03,  1.8143e-02],
        [-9.5673e-03, -4.5868e-02, -2.3376e-02,  ..., -6.5231e-03,
          1.0864e-02, -9.6283e-03],
        [ 2.2259e-03, -1.6647e-02, -7.0923e-02,  ..., -1.9119e-02,
          1.4282e-02,  7.0572e-05],
        ...,
        [ 3.7498e-03, -1.7338e-03, -2.5345e-02,  ..., -6.7627e-02,
         -2.6054e-03, -1.1208e-02],
        [ 1.7662e-03, -2.0325e-02, -3.8605e-03,  ...,  7.4196e-04,
         -5.0568e-02,  3.0029e-02],
        [-2.1534e-03,  6.0425e-03,  4.7112e-03,  ...,  1.5793e-02,
         -2.4452e-03, -4.8767e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:21:43 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 05:21:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4683, -0.0837,  0.7734,  ..., -1.6836,  0.7983,  1.1230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3760,  0.1377, -0.0853,  ...,  0.1270, -0.2107, -0.1316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6694, -0.5879,  1.7441,  ..., -3.9980,  2.5938,  1.9004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0664, -0.0369, -0.5825,  ..., -0.2729,  0.2288, -0.1582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:21:43 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:21:43 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 05:22:52 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 05:23:57 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 05:25:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.3002e-03, -2.9583e-03, -1.3914e-03,  ...,  2.5864e-03,
         -2.1400e-03,  1.2655e-03],
        [ 3.5057e-03,  1.5747e-02, -1.4153e-03,  ...,  1.9350e-03,
         -2.7523e-03, -2.6798e-03],
        [ 1.0872e-02,  1.5144e-02,  1.7395e-03,  ...,  9.4528e-03,
         -3.4180e-03, -2.7485e-03],
        ...,
        [ 1.7281e-03, -7.5340e-04,  3.9411e-04,  ...,  6.4583e-03,
         -2.7351e-03,  2.7370e-03],
        [-8.9169e-04, -1.9836e-03,  3.4046e-04,  ...,  9.7561e-04,
          7.7744e-03,  5.9605e-05],
        [ 3.1357e-03,  2.7237e-03, -1.7920e-03,  ...,  2.0943e-03,
         -6.6662e-04,  8.6212e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0192, -0.0083,  0.0030,  ...,  0.0042, -0.0224, -0.0131],
        [ 0.0122, -0.0238, -0.0036,  ...,  0.0088, -0.0069,  0.0090],
        [ 0.0028, -0.0002, -0.0297,  ..., -0.0062, -0.0052, -0.0124],
        ...,
        [-0.0090, -0.0092, -0.0002,  ..., -0.0154,  0.0080, -0.0045],
        [-0.0080,  0.0035,  0.0002,  ...,  0.0115, -0.0076, -0.0014],
        [-0.0026,  0.0035,  0.0046,  ...,  0.0039, -0.0122, -0.0356]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0393,  0.0130,  0.0110,  ...,  0.0122,  0.0107, -0.0096],
        [ 0.0247, -0.0686, -0.0160,  ..., -0.0014, -0.0075,  0.0191],
        [ 0.0041, -0.0110, -0.0704,  ..., -0.0149, -0.0044,  0.0150],
        ...,
        [ 0.0018, -0.0013, -0.0136,  ..., -0.0452, -0.0030, -0.0073],
        [ 0.0148,  0.0093, -0.0054,  ..., -0.0245, -0.0315, -0.0074],
        [-0.0015,  0.0043, -0.0065,  ..., -0.0151,  0.0177, -0.0616]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:25:07 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 05:25:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3477, -0.2759,  0.6333,  ..., -1.5830,  0.9517,  0.9766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5620, -0.1155, -0.4563,  ..., -0.0945,  0.0340, -0.1947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4724, -1.0039,  1.7285,  ..., -4.0703,  2.4316,  1.7070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3018,  0.0229, -0.2671,  ..., -0.4277,  0.4150,  0.6802],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:25:07 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:25:07 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 05:26:21 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 05:27:38 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 05:28:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.1449e-03, -4.6272e-03, -3.6030e-03,  ...,  9.5415e-04,
         -2.7657e-03, -6.7770e-05],
        [-1.1721e-03,  2.7370e-03,  2.3098e-03,  ..., -3.7670e-03,
          4.6577e-03,  4.7255e-04],
        [-1.1120e-03, -2.7514e-04,  5.2605e-03,  ..., -1.7357e-03,
          7.5161e-05, -1.0338e-03],
        ...,
        [-7.3957e-04,  3.6831e-03, -2.1019e-03,  ...,  5.9547e-03,
         -5.2109e-03, -3.4022e-04],
        [-1.1797e-03,  2.9583e-03, -1.1959e-03,  ...,  3.8033e-03,
          1.3571e-03,  5.2214e-04],
        [-3.8166e-03, -3.1185e-03,  2.8839e-03,  ..., -3.6106e-03,
          8.6899e-03,  4.5929e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.5991e-02,  4.0436e-03, -8.9493e-03,  ..., -1.2083e-03,
          6.8779e-03,  6.0844e-03],
        [ 5.5847e-03, -3.3020e-02, -9.2392e-03,  ..., -1.1139e-02,
          1.4277e-03,  5.4932e-03],
        [ 4.7112e-03,  5.5885e-03, -1.4023e-02,  ..., -1.9028e-02,
         -1.5392e-03, -4.7226e-03],
        ...,
        [ 1.0086e-02, -7.5188e-03, -7.4387e-03,  ..., -3.8757e-03,
          3.9482e-03,  4.4250e-03],
        [-1.4015e-02, -2.6608e-04, -4.5681e-04,  ..., -1.3351e-05,
         -9.5215e-03, -1.2474e-02],
        [-1.3672e-02, -1.1040e-02, -5.5218e-04,  ..., -4.1733e-03,
         -2.8610e-06, -2.4506e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0507,  0.0136, -0.0059,  ...,  0.0093, -0.0081, -0.0001],
        [ 0.0067, -0.0688, -0.0016,  ..., -0.0227, -0.0028,  0.0111],
        [ 0.0145,  0.0119, -0.0375,  ..., -0.0008, -0.0017, -0.0003],
        ...,
        [-0.0056, -0.0056, -0.0150,  ..., -0.0631,  0.0127, -0.0087],
        [-0.0172, -0.0135, -0.0046,  ...,  0.0086, -0.0496, -0.0063],
        [-0.0097,  0.0090,  0.0033,  ..., -0.0004, -0.0082, -0.0622]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:28:57 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 05:28:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2700, -0.2366,  0.6694,  ..., -1.5703,  1.0547,  0.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4204, -0.0149, -0.2311,  ..., -0.0966,  0.1016, -0.0934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9268, -1.0518,  1.6348,  ..., -3.9023,  2.9258,  1.7852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4395,  0.3472, -0.4646,  ..., -0.7827,  0.6367,  0.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:28:57 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:28:57 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 05:30:16 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 05:31:35 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 05:32:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3994e-03, -9.7561e-04,  4.0865e-04,  ..., -2.0218e-04,
         -3.6478e-05, -7.6890e-06],
        [ 5.9605e-04, -1.3313e-03, -1.0979e-04,  ...,  3.3545e-04,
         -3.9482e-04, -8.6904e-05],
        [-8.9979e-04,  3.2973e-04, -1.8215e-03,  ..., -6.4087e-04,
          8.3828e-04,  1.7381e-04],
        ...,
        [ 7.9930e-05,  4.6551e-05, -7.4089e-05,  ..., -1.8358e-03,
          2.1040e-05, -1.7595e-04],
        [ 8.2016e-04,  8.7595e-04,  1.6391e-05,  ...,  5.2691e-05,
         -1.9779e-03, -7.3099e-04],
        [-6.8378e-04,  5.9986e-04, -2.2054e-05,  ...,  2.8086e-04,
          4.1771e-04, -2.0027e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0147,  0.0041,  0.0033,  ..., -0.0098, -0.0070,  0.0098],
        [ 0.0148, -0.0237, -0.0024,  ...,  0.0191,  0.0049, -0.0079],
        [-0.0161,  0.0073, -0.0262,  ...,  0.0018,  0.0117, -0.0035],
        ...,
        [-0.0087,  0.0069, -0.0146,  ...,  0.0039, -0.0026,  0.0035],
        [ 0.0050, -0.0078, -0.0063,  ...,  0.0083, -0.0327,  0.0007],
        [ 0.0042,  0.0026, -0.0023,  ...,  0.0108,  0.0033, -0.0215]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0470, -0.0114,  0.0197,  ..., -0.0049, -0.0179,  0.0016],
        [ 0.0074, -0.0426, -0.0042,  ...,  0.0140,  0.0093, -0.0221],
        [ 0.0034, -0.0010, -0.0434,  ..., -0.0178, -0.0060,  0.0061],
        ...,
        [-0.0066,  0.0158, -0.0053,  ..., -0.0384,  0.0141,  0.0037],
        [-0.0002, -0.0041, -0.0219,  ..., -0.0165, -0.0543, -0.0053],
        [ 0.0119,  0.0215, -0.0052,  ..., -0.0222,  0.0038, -0.0514]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:32:58 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 05:32:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1914, -0.3787,  0.6187,  ..., -1.5264,  0.9507,  0.6304],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1041,  0.0103, -0.1205,  ..., -0.1508,  0.1776,  0.2302],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7021, -0.4521,  1.1641,  ..., -3.8125,  2.8965,  1.9316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9814, -0.0093,  0.4812,  ..., -0.0659,  0.3506, -0.1226],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:32:58 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:32:58 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 05:34:21 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 05:35:41 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 05:37:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.6964e-03,  5.2834e-04,  4.8685e-04,  ..., -7.1812e-04,
          3.2091e-04, -9.1410e-04],
        [-8.5402e-04,  4.9667e-03,  3.3116e-04,  ...,  2.3308e-03,
         -2.0943e-03,  2.8019e-03],
        [ 3.4451e-05,  1.2360e-03,  8.7509e-03,  ..., -4.6682e-04,
          1.9188e-03,  1.7262e-03],
        ...,
        [-8.6594e-04, -1.0080e-03, -1.8001e-05,  ...,  4.4098e-03,
         -1.3709e-04, -1.6146e-03],
        [ 1.9293e-03, -7.5281e-05, -3.3360e-03,  ..., -6.5804e-04,
         -2.3878e-04,  1.6832e-04],
        [-1.1415e-03, -3.0470e-04, -1.6451e-04,  ...,  8.6546e-04,
          5.4264e-04,  4.4518e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0091, -0.0130, -0.0138,  ..., -0.0151,  0.0033, -0.0087],
        [ 0.0006, -0.0017,  0.0127,  ...,  0.0093,  0.0055,  0.0181],
        [ 0.0230,  0.0109, -0.0022,  ...,  0.0016, -0.0045,  0.0052],
        ...,
        [-0.0005, -0.0014, -0.0035,  ...,  0.0029, -0.0094,  0.0042],
        [-0.0016, -0.0056, -0.0222,  ...,  0.0036, -0.0023, -0.0030],
        [-0.0073, -0.0008,  0.0132,  ...,  0.0002,  0.0169, -0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0612,  0.0063, -0.0056,  ..., -0.0132,  0.0070,  0.0018],
        [-0.0128, -0.0543,  0.0128,  ...,  0.0060, -0.0006,  0.0120],
        [ 0.0113, -0.0104, -0.0632,  ..., -0.0053, -0.0033,  0.0165],
        ...,
        [ 0.0252, -0.0140, -0.0183,  ..., -0.0669,  0.0084, -0.0071],
        [ 0.0014, -0.0051, -0.0039,  ...,  0.0015, -0.0702,  0.0171],
        [ 0.0093,  0.0028,  0.0085,  ...,  0.0127, -0.0112, -0.0686]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:37:07 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 05:37:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3501, -0.3525,  0.5498,  ..., -1.4277,  1.1006,  0.6416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1678,  0.1484, -0.2128,  ..., -0.2847,  0.2448,  0.1621],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6670, -0.8057,  1.6875,  ..., -3.5820,  2.8984,  1.7715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1260, -0.6680,  1.0537,  ...,  0.1324,  1.0059,  0.9263],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:37:07 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:37:07 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 05:38:26 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 05:39:49 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 05:41:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.8670e-03,  6.3038e-04, -1.8954e-04,  ...,  1.0719e-03,
          2.7924e-03,  4.7379e-03],
        [ 3.5024e-04, -5.0879e-04,  3.2759e-04,  ...,  7.1621e-04,
         -4.3068e-03, -3.4180e-03],
        [ 3.5362e-03, -1.4591e-03, -1.8396e-03,  ...,  2.6512e-03,
         -2.2964e-03, -2.8667e-03],
        ...,
        [ 9.7179e-04,  7.5436e-04,  7.8917e-04,  ...,  6.1913e-03,
         -8.4782e-04, -1.7376e-03],
        [ 4.1275e-03,  3.0251e-03, -8.3208e-05,  ...,  4.1695e-03,
          5.7869e-03, -3.5305e-03],
        [ 1.3371e-03, -3.4790e-03, -3.3531e-03,  ...,  1.3447e-03,
         -9.5844e-05,  1.0735e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 2.6810e-02,  3.5629e-03, -6.9313e-03,  ..., -5.6114e-03,
          1.8753e-02,  4.1389e-03],
        [ 2.1648e-03,  8.9951e-03, -1.6754e-02,  ..., -8.6746e-03,
         -7.4539e-03,  2.0924e-03],
        [-7.3547e-03,  6.7520e-04,  3.2928e-02,  ...,  9.9869e-03,
          7.4272e-03, -4.6082e-03],
        ...,
        [-6.6986e-03,  7.6675e-03, -2.0844e-02,  ...,  4.0253e-02,
          1.1612e-02,  2.2888e-05],
        [ 9.3689e-03, -2.5845e-03, -4.9973e-04,  ..., -2.1484e-02,
          2.6520e-02, -3.2539e-03],
        [-5.8479e-03,  1.0666e-02, -3.4370e-03,  ..., -9.7504e-03,
          1.9058e-02,  2.9449e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0173, -0.0350, -0.0145,  ..., -0.0067,  0.0196, -0.0121],
        [-0.0135, -0.0593,  0.0152,  ..., -0.0103, -0.0100,  0.0271],
        [-0.0035,  0.0089,  0.0088,  ..., -0.0030,  0.0029, -0.0075],
        ...,
        [-0.0213, -0.0162, -0.0057,  ...,  0.0086,  0.0203, -0.0173],
        [ 0.0048, -0.0063,  0.0004,  ...,  0.0144,  0.0052,  0.0018],
        [ 0.0026,  0.0282, -0.0041,  ...,  0.0118,  0.0062, -0.0120]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:41:15 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 05:41:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2693, -0.1313,  0.3496,  ..., -1.3613,  1.0059,  0.6494],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3738,  0.0216,  0.1148,  ..., -0.0586,  0.1218, -0.0833],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8525, -0.2300,  1.6641,  ..., -3.7422,  3.4121,  1.8672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5146, -0.3232,  1.4277,  ...,  0.4521,  1.3242,  1.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:41:15 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:41:15 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 05:42:41 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 05:44:08 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 05:45:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0890e-04, -1.1361e-04,  1.3173e-04,  ..., -3.4750e-05,
          1.0794e-04,  6.1512e-05],
        [-1.3304e-04, -2.1100e-04,  1.7953e-04,  ..., -1.2898e-04,
          1.6391e-04, -8.6010e-05],
        [-3.2043e-04,  2.0480e-04,  1.5950e-04,  ...,  9.9361e-05,
          1.2469e-04, -6.0081e-05],
        ...,
        [ 4.3154e-05, -2.4199e-04, -1.3542e-04,  ...,  2.3723e-04,
          3.4428e-04, -1.5926e-04],
        [-1.0163e-04,  1.2177e-04,  4.1366e-05,  ..., -3.0136e-04,
         -3.7611e-05, -1.0431e-05],
        [ 9.0241e-05, -4.2772e-04,  6.1798e-04,  ..., -1.1611e-04,
          2.8825e-04,  2.5892e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0124, -0.0036,  0.0164,  ...,  0.0048, -0.0042, -0.0015],
        [-0.0064, -0.0195,  0.0126,  ...,  0.0080, -0.0103, -0.0082],
        [-0.0031,  0.0094, -0.0202,  ..., -0.0078, -0.0186, -0.0017],
        ...,
        [-0.0013,  0.0088, -0.0062,  ..., -0.0050, -0.0037,  0.0061],
        [ 0.0103,  0.0126,  0.0198,  ..., -0.0195, -0.0047,  0.0006],
        [-0.0182, -0.0030,  0.0004,  ...,  0.0030, -0.0174,  0.0003]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0424, -0.0070,  0.0033,  ...,  0.0057,  0.0157, -0.0011],
        [-0.0171, -0.0250, -0.0088,  ...,  0.0310, -0.0027, -0.0020],
        [ 0.0104,  0.0072, -0.0212,  ..., -0.0028, -0.0085,  0.0023],
        ...,
        [-0.0106, -0.0018,  0.0027,  ..., -0.0190, -0.0049,  0.0106],
        [ 0.0099, -0.0050, -0.0080,  ..., -0.0056, -0.0121,  0.0097],
        [-0.0088,  0.0038, -0.0157,  ..., -0.0101,  0.0075, -0.0207]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:45:35 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 05:45:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2576, -0.2144,  0.4233,  ..., -1.1885,  0.8550,  0.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0104, -0.1808,  0.2527,  ..., -0.0541,  0.2988,  0.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0566, -0.3213,  0.3477,  ..., -4.1680,  3.3340,  1.4707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1133, -0.1656,  0.4199,  ..., -0.5215,  1.2666,  0.7148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:45:36 root INFO     [order_1_approx] starting weight calculation for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:45:36 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 05:47:02 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 05:48:30 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 05:49:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.1847e-03, -8.1158e-04,  2.0170e-04,  ..., -5.5218e-04,
          1.4186e-04, -1.4436e-04],
        [ 5.9509e-04,  2.3212e-03, -9.2924e-05,  ...,  1.2147e-04,
          4.6182e-04,  1.5664e-04],
        [ 9.2840e-04, -4.8709e-04,  3.8261e-03,  ..., -7.5483e-04,
         -3.0231e-04,  2.0456e-04],
        ...,
        [-2.4843e-04, -1.9383e-04,  1.2398e-05,  ...,  3.8815e-03,
         -8.2850e-06, -9.8705e-04],
        [-5.9271e-04,  2.8729e-04, -2.0885e-04,  ...,  6.4373e-06,
          4.6577e-03,  1.4567e-04],
        [ 2.9373e-04,  3.0184e-04,  2.6512e-04,  ..., -5.2547e-04,
         -3.1352e-04,  5.1231e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0112,  0.0049,  0.0041,  ..., -0.0077,  0.0077, -0.0016],
        [ 0.0142,  0.0146,  0.0037,  ..., -0.0123,  0.0152,  0.0002],
        [-0.0240,  0.0084,  0.0112,  ..., -0.0107, -0.0171, -0.0037],
        ...,
        [-0.0120,  0.0116, -0.0130,  ...,  0.0289, -0.0042,  0.0062],
        [ 0.0045, -0.0114,  0.0009,  ..., -0.0085,  0.0284,  0.0149],
        [ 0.0052,  0.0156,  0.0104,  ...,  0.0052,  0.0103,  0.0285]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0192,  0.0145, -0.0045,  ...,  0.0095, -0.0013, -0.0009],
        [ 0.0218, -0.0115,  0.0037,  ..., -0.0245,  0.0210,  0.0006],
        [-0.0019,  0.0089,  0.0235,  ..., -0.0196,  0.0081, -0.0083],
        ...,
        [ 0.0089,  0.0107, -0.0006,  ...,  0.0234,  0.0052,  0.0008],
        [ 0.0064, -0.0061, -0.0020,  ..., -0.0105,  0.0017,  0.0247],
        [-0.0169,  0.0084,  0.0107,  ..., -0.0027,  0.0090,  0.0185]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:50:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too compensated, it is overcompensated
If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is
2024-06-30 05:50:01 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 05:50:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3623, -0.3762, -0.4087,  ..., -0.2058, -0.1171,  0.6069],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1653, -0.1558,  0.1218,  ...,  0.2360, -0.3604, -0.5732],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4255, -0.2598,  0.4473,  ..., -0.6470, -0.1501,  0.5801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6084,  0.1198,  0.1897,  ...,  0.2079, -0.4446, -0.0798],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:50:01 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 05:50:01 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 05:50:24 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 05:50:47 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 05:51:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.0828e-03, -3.5667e-04,  8.7380e-05,  ...,  3.4392e-05,
          1.4377e-04,  8.9049e-05],
        [ 5.7888e-04, -2.1973e-03, -1.2827e-04,  ..., -1.0568e-04,
         -1.0359e-04,  3.3855e-04],
        [-8.7142e-05, -9.5248e-05, -2.6131e-03,  ..., -2.6464e-04,
         -2.9230e-04, -1.7095e-04],
        ...,
        [-8.5115e-04, -3.6001e-04,  7.4029e-05,  ..., -2.1667e-03,
         -5.8413e-05,  2.9027e-05],
        [-8.7619e-06,  2.6107e-04, -1.6761e-04,  ..., -2.0397e-04,
         -2.6016e-03, -2.0206e-05],
        [-5.4312e-04,  1.5891e-04,  3.2783e-06,  ...,  1.3053e-05,
         -1.7214e-04, -2.4223e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.0100e-02,  2.5024e-03,  2.6245e-03,  ...,  6.7444e-03,
         -2.2392e-03,  3.9940e-03],
        [ 1.4877e-03, -2.7008e-02, -1.7776e-03,  ...,  5.2986e-03,
          5.7411e-03, -5.3177e-03],
        [-9.2983e-05, -9.2239e-03, -3.8940e-02,  ...,  7.7820e-04,
         -2.8038e-03, -1.3435e-02],
        ...,
        [-8.7433e-03, -6.5804e-04, -3.0098e-03,  ..., -3.8483e-02,
          4.9286e-03, -1.4030e-02],
        [-5.3596e-03,  2.2507e-04,  1.2703e-03,  ...,  1.8902e-03,
         -3.1067e-02,  8.1940e-03],
        [ 3.4599e-03,  3.4790e-03, -8.6365e-03,  ...,  1.0109e-04,
          9.6054e-03, -2.3941e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.5187e-02, -9.5081e-04,  2.1648e-03,  ...,  6.4373e-05,
          1.8978e-04, -3.7742e-04],
        [ 2.5482e-03, -3.5156e-02, -4.4975e-03,  ...,  1.4105e-03,
          5.5084e-03, -1.0471e-03],
        [-5.9357e-03, -2.6779e-03, -3.1250e-02,  ..., -1.2712e-03,
         -3.4294e-03,  7.4768e-04],
        ...,
        [-8.3351e-04,  4.7398e-04,  2.2354e-03,  ..., -3.2410e-02,
         -1.1234e-03, -2.5616e-03],
        [-9.8419e-04,  1.3027e-03,  1.8635e-03,  ..., -2.2755e-03,
         -3.0807e-02,  6.0806e-03],
        [-6.8092e-04, -2.2068e-03, -2.6264e-03,  ...,  4.8218e-03,
          1.5173e-03, -3.0762e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:51:12 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 05:51:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8276, -0.3784, -0.1989,  ..., -0.6079, -0.1370,  0.4985],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7178, -0.1047,  0.3286,  ..., -0.0884, -0.5259, -0.3315],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4521, -0.2656,  0.4048,  ..., -1.0117, -0.3240,  0.6416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5098,  0.0163,  0.0428,  ..., -0.6792, -0.3962,  0.1753],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:51:12 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 05:51:12 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 05:51:36 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 05:52:00 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 05:52:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1896e-03,  3.8815e-04,  6.2466e-04,  ..., -6.7806e-04,
         -1.3065e-03, -5.8508e-04],
        [ 3.4952e-04, -2.0523e-03,  3.3808e-04,  ...,  8.5688e-04,
         -7.0572e-04, -7.3314e-05],
        [ 1.6069e-04,  1.8287e-04, -1.4896e-03,  ...,  6.3229e-04,
         -1.8883e-03,  1.3590e-04],
        ...,
        [-5.5027e-04, -8.0299e-04, -6.3181e-05,  ..., -2.6436e-03,
         -1.2665e-03, -1.4305e-06],
        [ 6.1321e-04,  1.5163e-04, -2.1052e-04,  ..., -5.5647e-04,
         -1.6937e-03, -1.0881e-03],
        [ 5.4741e-04, -5.4932e-04, -4.2796e-04,  ..., -1.0605e-03,
         -7.1764e-05, -2.6093e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0532,  0.0088,  0.0037,  ...,  0.0101, -0.0074, -0.0018],
        [ 0.0096, -0.0490, -0.0050,  ...,  0.0106, -0.0029,  0.0060],
        [-0.0027, -0.0034, -0.0427,  ..., -0.0030, -0.0076,  0.0033],
        ...,
        [ 0.0028,  0.0064,  0.0077,  ..., -0.0516, -0.0051,  0.0067],
        [ 0.0047, -0.0025,  0.0035,  ..., -0.0028, -0.0595,  0.0109],
        [-0.0080,  0.0021, -0.0100,  ...,  0.0078,  0.0059, -0.0569]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0689,  0.0014, -0.0065,  ...,  0.0004,  0.0074, -0.0002],
        [-0.0010, -0.0795, -0.0075,  ...,  0.0063,  0.0035,  0.0037],
        [ 0.0068,  0.0020, -0.0597,  ...,  0.0017, -0.0062, -0.0068],
        ...,
        [ 0.0018,  0.0101,  0.0034,  ..., -0.0765, -0.0072, -0.0041],
        [-0.0054,  0.0011,  0.0022,  ...,  0.0050, -0.0722,  0.0023],
        [ 0.0016,  0.0011,  0.0014,  ..., -0.0039,  0.0074, -0.0771]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:52:28 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 05:52:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5537, -0.3552,  0.5386,  ..., -0.7661, -0.1892,  0.7100],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9595,  0.1719,  0.2905,  ...,  0.3110, -0.6704, -0.1472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2805, -0.5859,  0.6211,  ..., -0.8579, -0.2571,  0.6421],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8018,  0.1970, -0.0653,  ..., -0.5977, -0.4058,  0.9692],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:52:28 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 05:52:28 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 05:52:54 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 05:53:19 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 05:53:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.1956e-03,  2.3413e-04, -1.7500e-03,  ...,  1.2875e-03,
         -1.5032e-04, -1.0338e-03],
        [ 2.3901e-05, -5.5275e-03,  9.4795e-04,  ...,  7.8392e-04,
         -1.4086e-03,  5.9319e-04],
        [-1.3733e-04, -6.9714e-04, -5.1117e-03,  ..., -9.6798e-04,
         -1.5330e-04, -9.2697e-04],
        ...,
        [-1.4343e-03,  1.1415e-03,  2.8920e-04,  ..., -2.7866e-03,
          7.3576e-04, -8.0526e-05],
        [-1.6851e-03,  4.9782e-04, -3.3379e-04,  ...,  4.7565e-04,
         -3.5858e-03, -8.5068e-04],
        [ 7.0906e-04, -1.1063e-03,  1.5907e-03,  ...,  2.4748e-04,
          4.0054e-04, -4.9896e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0500, -0.0037, -0.0054,  ...,  0.0065,  0.0013, -0.0039],
        [-0.0048, -0.0419,  0.0083,  ..., -0.0117, -0.0084,  0.0001],
        [ 0.0049, -0.0034, -0.0428,  ...,  0.0024,  0.0022,  0.0041],
        ...,
        [-0.0024, -0.0028, -0.0089,  ..., -0.0376,  0.0012,  0.0011],
        [ 0.0003,  0.0028,  0.0018,  ..., -0.0020, -0.0315,  0.0002],
        [ 0.0014,  0.0046, -0.0016,  ..., -0.0072,  0.0028, -0.0437]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.9856e-02,  3.2768e-03, -2.1019e-03,  ...,  7.2479e-04,
         -2.7013e-04, -2.2449e-03],
        [ 5.1308e-03, -3.1799e-02,  4.3716e-03,  ..., -3.1700e-03,
          9.5272e-04,  4.8828e-03],
        [ 3.0041e-03,  1.4143e-03, -3.3997e-02,  ..., -7.0496e-03,
          3.5801e-03,  4.0855e-03],
        ...,
        [-9.0742e-04, -2.3632e-03, -7.1259e-03,  ..., -3.1403e-02,
         -5.3787e-04, -2.0161e-03],
        [-4.5776e-03,  4.9629e-03,  7.8964e-03,  ...,  7.3814e-04,
         -2.3911e-02,  7.6294e-06],
        [-4.0169e-03,  4.3945e-03,  4.3564e-03,  ..., -1.0653e-03,
          7.9193e-03, -2.9877e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:53:46 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 05:53:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5928, -0.3623,  0.4834,  ..., -1.1914, -0.4131,  0.7695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7954,  0.0061,  0.0703,  ..., -0.9683, -0.5957,  0.2399],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3352, -0.3760,  0.4722,  ..., -0.9062,  0.4895,  0.5283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5762,  0.7012,  0.2379,  ..., -0.8887, -0.0952,  0.8682],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:53:46 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 05:53:46 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 05:54:15 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 05:54:45 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 05:55:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.2187e-05,  6.0272e-04,  1.1444e-03,  ..., -3.4404e-04,
          2.1973e-03, -1.8215e-04],
        [-5.8222e-04, -3.1929e-03,  4.1723e-05,  ..., -3.3021e-04,
          6.7043e-04, -1.2898e-04],
        [-9.3746e-04, -3.9577e-04, -1.5211e-03,  ...,  5.4121e-04,
          7.7677e-04, -8.5115e-04],
        ...,
        [ 6.1607e-04, -2.5215e-03, -8.7023e-05,  ..., -1.4668e-03,
          5.2404e-04, -3.0446e-04],
        [-1.6260e-04,  2.8276e-04, -6.5756e-04,  ..., -9.7227e-04,
         -1.4400e-03, -1.1361e-04],
        [ 6.5660e-04, -1.0757e-03,  3.4094e-04,  ..., -1.9550e-04,
         -1.1826e-04, -1.2178e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0429,  0.0046, -0.0024,  ...,  0.0089,  0.0082,  0.0003],
        [ 0.0081, -0.0516,  0.0046,  ...,  0.0061, -0.0009, -0.0112],
        [-0.0050,  0.0002, -0.0466,  ..., -0.0043, -0.0074,  0.0030],
        ...,
        [-0.0093,  0.0045,  0.0046,  ..., -0.0439,  0.0009, -0.0041],
        [-0.0017, -0.0056,  0.0061,  ...,  0.0027, -0.0501, -0.0050],
        [-0.0036, -0.0019, -0.0031,  ...,  0.0067, -0.0088, -0.0416]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0533, -0.0012,  0.0045,  ..., -0.0024,  0.0032,  0.0017],
        [ 0.0041, -0.0343, -0.0008,  ...,  0.0054,  0.0100, -0.0039],
        [ 0.0008, -0.0032, -0.0451,  ...,  0.0001, -0.0042,  0.0055],
        ...,
        [-0.0074, -0.0017, -0.0011,  ..., -0.0405,  0.0036, -0.0034],
        [ 0.0015, -0.0006, -0.0044,  ..., -0.0074, -0.0363,  0.0025],
        [-0.0019, -0.0004, -0.0030,  ..., -0.0066,  0.0007, -0.0457]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:55:16 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 05:55:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3030, -0.6763,  0.6108,  ..., -0.8389, -0.2368,  0.6353],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9028,  0.1873, -0.0623,  ..., -0.6362, -0.4219,  1.0908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0581, -0.6396,  1.0039,  ..., -1.4082,  1.1514,  0.2783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5703,  0.4624,  0.3047,  ..., -0.3086,  0.0332,  0.4885],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:55:16 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 05:55:17 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 05:55:40 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 05:56:13 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 05:56:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.6226e-03,  1.4820e-03, -2.5787e-03,  ...,  7.7868e-04,
         -2.4776e-03,  2.5215e-03],
        [-4.5013e-04,  3.1531e-05,  5.1260e-05,  ...,  2.0945e-04,
         -5.8317e-04,  1.5163e-03],
        [ 1.2226e-03, -3.4511e-05, -1.3237e-03,  ..., -2.4199e-04,
          3.4523e-04, -4.9877e-04],
        ...,
        [-8.8882e-04,  3.2368e-03,  9.5272e-04,  ..., -9.3985e-04,
         -4.2000e-03,  1.4782e-03],
        [ 2.0618e-03,  1.0653e-03, -1.4248e-03,  ...,  3.6359e-04,
         -8.4400e-05,  1.0967e-05],
        [-1.4806e-04, -2.0180e-03, -8.5449e-04,  ..., -8.5783e-04,
         -5.0735e-04, -2.2435e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.9365e-02,  2.8915e-03,  5.3596e-03,  ..., -2.7332e-03,
          1.0620e-02,  2.7313e-03],
        [-9.2602e-04, -9.0637e-02,  1.2192e-02,  ...,  3.1223e-03,
          3.9887e-04,  1.2016e-02],
        [ 9.1400e-03, -7.4158e-03, -9.0759e-02,  ..., -1.3794e-02,
          1.6632e-02, -1.4105e-03],
        ...,
        [-3.5048e-04, -4.1122e-03, -7.3204e-03,  ..., -8.9966e-02,
         -6.5193e-03, -6.7997e-04],
        [ 4.1199e-03, -9.0718e-05, -4.2534e-03,  ..., -4.0054e-03,
         -9.4727e-02, -9.7961e-03],
        [-4.3144e-03,  1.4534e-02,  2.8095e-03,  ...,  7.7858e-03,
         -7.8278e-03, -8.3679e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0928, -0.0068,  0.0065,  ..., -0.0030, -0.0039, -0.0021],
        [-0.0069, -0.0959,  0.0038,  ..., -0.0070, -0.0028,  0.0023],
        [-0.0052,  0.0012, -0.0912,  ..., -0.0002,  0.0081,  0.0055],
        ...,
        [-0.0032, -0.0011,  0.0017,  ..., -0.0836,  0.0088,  0.0030],
        [ 0.0014, -0.0045,  0.0008,  ...,  0.0028, -0.0956,  0.0068],
        [ 0.0068,  0.0027,  0.0082,  ..., -0.0085, -0.0075, -0.1022]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:56:48 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 05:56:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3401, -0.4023,  0.4309,  ..., -0.8594,  0.4551,  0.5059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6323,  0.7769,  0.2428,  ..., -0.9263, -0.1166,  0.9541],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2177, -1.0137,  0.3335,  ..., -1.0967,  1.5869, -0.2185],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1445,  0.2100,  0.0615,  ...,  0.2041,  0.0454,  0.0247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:56:48 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 05:56:48 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 05:57:24 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 05:58:00 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 05:58:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.9139e-03, -5.5885e-04,  3.1261e-03,  ...,  1.4267e-03,
          3.4389e-03, -2.1114e-03],
        [ 3.1376e-03, -6.9275e-03,  2.2144e-03,  ..., -1.4782e-03,
          1.6117e-03,  1.1039e-04],
        [-1.7300e-03,  2.5215e-03, -1.9836e-03,  ..., -7.0143e-04,
          5.7817e-06,  1.0185e-03],
        ...,
        [ 7.9107e-04, -1.4801e-03,  1.3256e-04,  ..., -3.1872e-03,
         -1.3094e-03,  8.6069e-04],
        [ 2.0447e-03, -3.8471e-03,  1.8082e-03,  ..., -3.0003e-03,
         -2.8534e-03,  4.0650e-04],
        [-7.5912e-04, -1.6003e-03,  1.9045e-03,  ..., -9.7656e-04,
         -3.2959e-03,  2.7885e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.4697e-02,  1.1414e-02,  6.6605e-03,  ...,  1.1787e-02,
          7.2746e-03, -5.2261e-03],
        [ 2.2774e-03, -1.0516e-01, -5.9357e-03,  ...,  4.6234e-03,
         -2.1629e-03, -1.8692e-03],
        [ 1.3245e-02,  1.1795e-02, -7.4768e-02,  ...,  5.3787e-03,
          1.2321e-03, -9.7847e-04],
        ...,
        [ 3.4218e-03, -1.1757e-02,  6.0921e-03,  ..., -7.1777e-02,
          7.3433e-03, -2.0523e-03],
        [-1.7452e-03,  1.3901e-02, -2.1000e-03,  ...,  1.3847e-03,
         -8.0750e-02,  7.1526e-05],
        [-1.3763e-02,  3.9673e-04,  4.2229e-03,  ..., -6.4621e-03,
          1.5354e-04, -7.7087e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0963, -0.0021, -0.0011,  ...,  0.0028,  0.0004,  0.0021],
        [ 0.0023, -0.1056, -0.0062,  ...,  0.0032, -0.0054,  0.0019],
        [ 0.0019, -0.0053, -0.1027,  ...,  0.0083,  0.0048, -0.0041],
        ...,
        [ 0.0079,  0.0015,  0.0024,  ..., -0.1005,  0.0003, -0.0059],
        [-0.0047, -0.0033, -0.0035,  ...,  0.0048, -0.0989, -0.0023],
        [-0.0049,  0.0029, -0.0098,  ..., -0.0054,  0.0090, -0.1133]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 05:58:36 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 05:58:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0447, -0.5957,  0.8418,  ..., -1.2402,  1.0293,  0.2205],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5620,  0.4827,  0.2673,  ..., -0.3081,  0.0301,  0.4609],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0527, -0.7861,  0.5254,  ..., -0.4795,  2.1074,  0.0664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8643,  0.2859,  0.4148,  ...,  0.2261,  0.3569, -0.3230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 05:58:36 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 05:58:36 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 05:59:13 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 05:59:52 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 06:00:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.9812e-03,  1.4515e-03, -1.0757e-03,  ...,  1.1044e-03,
         -2.2640e-03,  1.5669e-03],
        [ 2.2202e-03,  2.1517e-05, -8.0776e-04,  ...,  2.5787e-03,
          1.3561e-03, -8.9169e-04],
        [ 1.8167e-03, -1.3123e-03, -4.1127e-04,  ..., -2.6131e-04,
         -1.4048e-03, -1.2028e-04],
        ...,
        [ 1.1158e-04,  3.8185e-03,  2.1477e-03,  ..., -2.4414e-03,
          2.1229e-03,  1.2274e-03],
        [ 1.8775e-04,  3.1233e-04, -2.1095e-03,  ...,  2.0733e-03,
         -8.6784e-04,  2.3098e-03],
        [ 1.5855e-05, -1.7681e-03,  3.4642e-04,  ..., -1.1969e-03,
          4.9133e-03, -4.1504e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0899, -0.0057,  0.0072,  ..., -0.0106, -0.0021,  0.0049],
        [-0.0123, -0.0654, -0.0135,  ..., -0.0015, -0.0111,  0.0147],
        [ 0.0067, -0.0106, -0.0646,  ..., -0.0029, -0.0048, -0.0018],
        ...,
        [-0.0136,  0.0089,  0.0035,  ..., -0.0742, -0.0013, -0.0161],
        [ 0.0043,  0.0086, -0.0061,  ..., -0.0030, -0.0779, -0.0049],
        [ 0.0126, -0.0037, -0.0077,  ..., -0.0071,  0.0038, -0.0729]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0941,  0.0048,  0.0058,  ..., -0.0067, -0.0049, -0.0053],
        [ 0.0029, -0.0874, -0.0091,  ...,  0.0034,  0.0067, -0.0106],
        [ 0.0048,  0.0038, -0.0846,  ...,  0.0066, -0.0005,  0.0050],
        ...,
        [-0.0046, -0.0025,  0.0037,  ..., -0.0939,  0.0071,  0.0017],
        [ 0.0010,  0.0014,  0.0020,  ...,  0.0129, -0.0856, -0.0039],
        [-0.0026, -0.0071,  0.0045,  ..., -0.0017, -0.0037, -0.0837]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:00:33 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 06:00:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1897, -0.9326,  0.2605,  ..., -0.9009,  1.3379, -0.2224],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0801,  0.1990,  0.0467,  ...,  0.1794,  0.0377,  0.0054],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0410, -0.4150,  0.9531,  ..., -1.0186,  2.3867,  0.1460],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6953,  0.0603,  0.1389,  ...,  0.0435,  0.2979,  0.0872],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:00:33 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:00:33 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 06:01:15 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 06:01:57 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 06:02:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.0117e-03, -8.1968e-04,  2.5215e-03,  ...,  1.2407e-03,
         -2.1858e-03,  5.9938e-04],
        [-6.7282e-04, -2.2373e-03, -9.3937e-05,  ..., -2.5463e-03,
         -1.9312e-05, -3.4928e-04],
        [ 2.4390e-04,  4.9019e-04, -2.3918e-03,  ...,  4.8089e-04,
          2.0051e-04,  5.9414e-04],
        ...,
        [-1.6356e-03, -1.5984e-03, -5.3501e-04,  ...,  2.2650e-05,
          1.1444e-03,  2.7447e-03],
        [-8.9550e-04,  5.2261e-04,  1.0614e-03,  ...,  2.6941e-04,
         -4.6501e-03, -3.3474e-03],
        [ 5.2910e-03,  5.6601e-04,  1.1282e-03,  ..., -1.0910e-03,
          1.2274e-03, -5.5504e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0718,  0.0074, -0.0010,  ...,  0.0008, -0.0065, -0.0010],
        [-0.0043, -0.0925,  0.0139,  ..., -0.0030,  0.0061,  0.0006],
        [-0.0109, -0.0023, -0.0645,  ..., -0.0110, -0.0065, -0.0006],
        ...,
        [-0.0031,  0.0155,  0.0010,  ..., -0.0875,  0.0036,  0.0043],
        [ 0.0046,  0.0025,  0.0104,  ..., -0.0122, -0.0651,  0.0105],
        [ 0.0105, -0.0024,  0.0034,  ..., -0.0053,  0.0074, -0.0917]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1038,  0.0017, -0.0086,  ..., -0.0015,  0.0101, -0.0116],
        [ 0.0034, -0.1212,  0.0104,  ..., -0.0103, -0.0060,  0.0108],
        [-0.0053,  0.0012, -0.1199,  ..., -0.0058, -0.0108,  0.0069],
        ...,
        [ 0.0055,  0.0088, -0.0038,  ..., -0.1032, -0.0053,  0.0030],
        [-0.0075,  0.0072, -0.0083,  ..., -0.0043, -0.0991,  0.0067],
        [-0.0093, -0.0021, -0.0124,  ...,  0.0031,  0.0041, -0.1204]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:02:40 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 06:02:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7554, -0.5986,  0.3149,  ..., -0.3542,  1.4854,  0.0282],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7690,  0.2517,  0.2949,  ...,  0.1656,  0.2866, -0.3013],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1611, -0.1897,  0.9536,  ..., -1.0928,  2.6074, -0.5029],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8608,  0.4001,  0.6982,  ...,  0.7627,  0.0452, -0.0033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:02:40 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:02:40 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 06:03:21 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 06:04:00 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 06:04:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.8109e-03,  1.4648e-03,  1.8253e-03,  ..., -1.8883e-03,
         -2.0943e-03, -1.8969e-03],
        [ 1.3399e-03, -2.4052e-03, -2.4738e-03,  ...,  5.7125e-04,
         -9.5510e-04,  3.5591e-03],
        [-3.1281e-03, -1.1082e-03,  1.1253e-03,  ...,  1.3189e-03,
          1.6699e-03,  2.6875e-03],
        ...,
        [ 1.4460e-04, -2.1610e-03,  1.0586e-04,  ...,  1.1501e-03,
          4.4060e-04, -1.2577e-04],
        [-2.6646e-03,  1.2106e-04,  3.2959e-03,  ...,  1.2770e-03,
         -5.2147e-03, -6.4898e-04],
        [ 1.0643e-03, -2.1515e-03,  4.5090e-03,  ..., -7.3957e-04,
          2.0714e-03, -3.6955e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.0078e-02, -1.3161e-02, -3.6850e-03,  ..., -1.0635e-02,
         -3.0842e-03,  1.4591e-03],
        [ 9.8515e-04, -9.4421e-02, -8.0872e-03,  ...,  1.1917e-02,
          3.8147e-05,  1.1475e-02],
        [-8.1329e-03,  4.8561e-03, -1.0327e-01,  ...,  1.7792e-02,
         -7.8354e-03,  4.2267e-03],
        ...,
        [-8.7128e-03,  5.5084e-03,  1.6510e-02,  ..., -9.8389e-02,
          6.1874e-03, -4.2877e-03],
        [-4.5276e-04,  2.8400e-03,  1.0689e-02,  ...,  4.2915e-03,
         -1.0107e-01,  4.2801e-03],
        [ 6.8436e-03, -1.5327e-02, -7.2670e-03,  ..., -8.1635e-03,
         -4.9629e-03, -8.9966e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6663e-01, -1.6079e-03,  1.1124e-02,  ...,  1.0071e-03,
         -6.1646e-03,  4.0207e-03],
        [-8.3466e-03, -1.5820e-01, -8.3008e-03,  ...,  1.0010e-02,
          6.2332e-03,  2.8343e-03],
        [-3.9825e-03, -9.6283e-03, -1.4136e-01,  ...,  7.0114e-03,
         -4.2343e-03, -6.6147e-03],
        ...,
        [-3.1452e-03,  2.3560e-02,  7.7896e-03,  ..., -1.5710e-01,
          1.5163e-04,  3.7899e-03],
        [-1.0223e-03,  2.3727e-03,  8.7433e-03,  ..., -1.2802e-02,
         -1.6089e-01, -2.0905e-03],
        [-1.2054e-03,  2.7809e-03,  9.0027e-03,  ..., -1.9699e-02,
          2.0981e-03, -1.4880e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:04:46 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 06:04:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6895, -0.2964,  0.5581,  ..., -0.6274,  1.5176,  0.0513],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5698,  0.0350,  0.0728,  ...,  0.0451,  0.2258,  0.0316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3704, -0.4050,  1.4541,  ..., -0.9458,  2.9062,  0.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5039, -0.0427,  0.6270,  ...,  0.3950,  0.2209,  0.3936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:04:46 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:04:46 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 06:05:36 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 06:06:27 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 06:07:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0016,  0.0005,  0.0008,  ..., -0.0009,  0.0007,  0.0003],
        [ 0.0014,  0.0055,  0.0016,  ...,  0.0018,  0.0013,  0.0021],
        [ 0.0002,  0.0008, -0.0008,  ...,  0.0009, -0.0011, -0.0021],
        ...,
        [ 0.0020, -0.0019,  0.0028,  ..., -0.0007, -0.0009,  0.0004],
        [ 0.0006, -0.0023, -0.0005,  ...,  0.0022, -0.0002,  0.0023],
        [-0.0013, -0.0015, -0.0016,  ...,  0.0016,  0.0029,  0.0015]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0891,  0.0154,  0.0097,  ..., -0.0003,  0.0038, -0.0059],
        [ 0.0092, -0.1035,  0.0193,  ...,  0.0106,  0.0085, -0.0044],
        [ 0.0044, -0.0044, -0.0892,  ...,  0.0096, -0.0169, -0.0048],
        ...,
        [ 0.0042, -0.0101, -0.0141,  ..., -0.0917,  0.0164, -0.0106],
        [ 0.0193,  0.0177,  0.0063,  ...,  0.0111, -0.0862,  0.0067],
        [ 0.0117,  0.0018, -0.0112,  ..., -0.0052,  0.0137, -0.0955]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0991,  0.0016,  0.0047,  ...,  0.0095, -0.0073, -0.0059],
        [ 0.0091, -0.0991,  0.0009,  ..., -0.0085, -0.0141,  0.0013],
        [-0.0076,  0.0088, -0.0984,  ...,  0.0103, -0.0034,  0.0139],
        ...,
        [ 0.0023, -0.0064,  0.0053,  ..., -0.0902,  0.0086, -0.0042],
        [ 0.0032, -0.0129, -0.0057,  ...,  0.0114, -0.0991, -0.0009],
        [ 0.0062, -0.0021,  0.0028,  ...,  0.0088, -0.0018, -0.1041]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:07:20 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 06:07:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0831, -0.1455,  0.5151,  ..., -0.6880,  1.5693, -0.3232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-6.6797e-01,  2.9028e-01,  4.5459e-01,  ...,  5.1611e-01,
         1.3367e-02,  3.8123e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0835, -1.0234,  0.8970,  ..., -1.4219,  2.6855,  0.8765],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7324, -0.2053,  0.6963,  ...,  1.0566,  0.1232,  0.3140],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:07:20 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:07:20 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 06:08:13 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 06:09:07 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 06:09:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.5689e-03, -1.1225e-03,  6.8378e-04,  ..., -3.9101e-05,
          2.2736e-03,  1.6499e-03],
        [-1.7881e-03,  3.9177e-03, -1.3676e-03,  ...,  5.8174e-04,
          1.7843e-03,  1.2884e-03],
        [-1.1368e-03,  1.4782e-03,  7.7095e-03,  ..., -6.6996e-04,
          2.3079e-03,  1.4877e-04],
        ...,
        [-2.8629e-03,  3.7403e-03,  3.9043e-03,  ...,  6.9008e-03,
         -2.8839e-03,  2.6779e-03],
        [-3.1328e-04,  2.8729e-04,  2.1815e-04,  ...,  1.2141e-04,
          1.0582e-02,  1.5001e-03],
        [ 2.8467e-04,  1.0490e-05, -2.0742e-04,  ...,  2.8110e-04,
         -2.4414e-03,  7.7515e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.4685e-01,  3.7460e-03, -6.7825e-03,  ..., -1.6586e-02,
         -7.3624e-03,  8.2016e-03],
        [ 1.2894e-02, -1.3818e-01, -1.3931e-02,  ..., -1.5259e-05,
         -4.7340e-03, -1.1925e-02],
        [-1.5060e-02, -6.9199e-03, -1.5601e-01,  ..., -3.3150e-03,
          5.9509e-03, -1.5572e-02],
        ...,
        [-2.7283e-02,  1.1963e-02,  1.2772e-02,  ..., -1.4636e-01,
          6.6986e-03, -4.0054e-05],
        [-8.1863e-03,  1.1452e-02,  7.3090e-03,  ..., -5.3482e-03,
         -1.4709e-01,  1.9474e-03],
        [-2.9716e-03, -7.7438e-03, -4.8218e-03,  ...,  1.7300e-03,
         -8.7967e-03, -1.4539e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2029,  0.0180,  0.0183,  ..., -0.0135, -0.0049, -0.0052],
        [ 0.0042, -0.2214, -0.0199,  ..., -0.0071,  0.0097,  0.0005],
        [ 0.0012,  0.0092, -0.2065,  ...,  0.0013,  0.0059, -0.0129],
        ...,
        [-0.0013, -0.0013,  0.0017,  ..., -0.2322, -0.0023, -0.0036],
        [ 0.0039,  0.0034, -0.0068,  ...,  0.0128, -0.2108,  0.0043],
        [ 0.0050, -0.0113, -0.0060,  ..., -0.0054, -0.0005, -0.2045]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:09:57 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 06:09:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2015, -0.2769,  0.8154,  ..., -0.5928,  1.7979,  0.1588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4465, -0.0507,  0.4409,  ...,  0.3145,  0.1714,  0.2798],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1909, -1.4453,  0.7773,  ..., -1.5898,  2.9648,  1.0146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1797,  0.4954,  1.8594,  ...,  1.1982,  0.4844,  0.9849],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:09:57 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:09:57 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 06:10:52 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 06:11:48 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 06:12:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.1722e-03,  3.0098e-03,  1.4000e-03,  ...,  1.1435e-03,
          5.9223e-04, -4.3907e-03],
        [-2.3956e-03, -3.4332e-03,  2.2717e-03,  ..., -1.6680e-03,
         -3.3150e-03,  1.2217e-03],
        [-7.4816e-04,  2.1000e-03, -3.8147e-03,  ..., -2.8114e-03,
         -3.3054e-03, -3.1376e-03],
        ...,
        [ 1.5688e-03, -5.7745e-04, -3.6297e-03,  ..., -4.3564e-03,
          1.0757e-03,  1.0700e-03],
        [ 1.0490e-03, -1.3847e-03, -1.6928e-03,  ..., -3.0098e-03,
         -2.7504e-03,  3.2578e-03],
        [ 2.3918e-03,  7.9155e-04,  1.0643e-03,  ..., -7.9107e-04,
         -1.9169e-04,  9.7752e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0845,  0.0031,  0.0235,  ...,  0.0059,  0.0043, -0.0112],
        [ 0.0022, -0.0885, -0.0014,  ..., -0.0010, -0.0112,  0.0013],
        [-0.0004, -0.0090, -0.0710,  ..., -0.0119,  0.0028,  0.0063],
        ...,
        [ 0.0052,  0.0062,  0.0002,  ..., -0.0662,  0.0049, -0.0099],
        [-0.0090,  0.0012,  0.0035,  ...,  0.0155, -0.0842,  0.0119],
        [-0.0101, -0.0043,  0.0056,  ..., -0.0091,  0.0163, -0.0723]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.4097e-02, -6.2027e-03,  1.3969e-02,  ..., -3.0060e-03,
         -7.9203e-04,  2.2736e-03],
        [ 2.9526e-03, -7.2021e-02, -9.2468e-03,  ..., -2.8229e-04,
          1.1223e-02,  3.2082e-03],
        [-6.0272e-03,  4.7226e-03, -8.1604e-02,  ..., -8.2016e-05,
         -8.6517e-03,  9.8267e-03],
        ...,
        [-9.8515e-04, -5.2376e-03, -8.4915e-03,  ..., -6.6833e-02,
          7.7133e-03,  6.1111e-03],
        [-2.7714e-03,  3.4714e-03,  2.3842e-03,  ...,  4.5395e-03,
         -7.8491e-02,  5.2338e-03],
        [ 1.2482e-02, -9.4986e-04, -5.8517e-03,  ...,  3.4122e-03,
          5.0850e-03, -7.8186e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:12:43 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 06:12:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0433, -0.6587,  0.4944,  ..., -0.8413,  1.5928,  0.5054],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5503, -0.1868,  0.4729,  ...,  0.7217,  0.0936,  0.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0807, -1.4365,  0.4753,  ..., -1.6758,  3.3398,  1.4189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.8662, -0.2019,  1.1367,  ...,  1.3223,  1.1328,  0.9458],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:12:43 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:12:43 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 06:13:30 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 06:14:28 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 06:15:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5732e-02,  1.3456e-03,  3.3741e-03,  ..., -4.7646e-03,
          3.8071e-03, -2.6836e-03],
        [-2.4700e-03, -3.6469e-03, -3.0136e-03,  ...,  1.9836e-03,
          3.6907e-04, -5.4741e-03],
        [ 9.1934e-04, -2.8706e-03, -1.2138e-02,  ..., -5.1498e-05,
         -3.3379e-03, -2.8038e-03],
        ...,
        [-1.8396e-03,  5.1689e-04,  7.7486e-04,  ..., -3.1681e-03,
         -1.4377e-04,  4.0474e-03],
        [ 3.8910e-03, -6.9809e-04,  2.8381e-03,  ..., -1.0896e-04,
         -1.9165e-02, -3.5858e-03],
        [ 9.8610e-04,  7.3471e-03,  4.7722e-03,  ..., -7.8659e-03,
         -3.1114e-04, -1.3382e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1096, -0.0039,  0.0009,  ..., -0.0173,  0.0131,  0.0100],
        [ 0.0048, -0.1012, -0.0003,  ...,  0.0091,  0.0073,  0.0175],
        [ 0.0081, -0.0094, -0.1129,  ...,  0.0030, -0.0018,  0.0063],
        ...,
        [-0.0196, -0.0063,  0.0097,  ..., -0.0960, -0.0126,  0.0027],
        [ 0.0099,  0.0078, -0.0025,  ..., -0.0018, -0.1036, -0.0120],
        [ 0.0042,  0.0048, -0.0070,  ..., -0.0171, -0.0026, -0.0974]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1375, -0.0012,  0.0059,  ..., -0.0016,  0.0061,  0.0119],
        [-0.0154, -0.1412, -0.0038,  ...,  0.0016,  0.0078,  0.0145],
        [ 0.0088,  0.0047, -0.1389,  ..., -0.0052,  0.0016, -0.0068],
        ...,
        [-0.0133, -0.0024, -0.0034,  ..., -0.1405, -0.0117,  0.0053],
        [ 0.0167,  0.0159, -0.0072,  ...,  0.0091, -0.1488,  0.0099],
        [-0.0026, -0.0013,  0.0105,  ..., -0.0089,  0.0136, -0.1376]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:15:28 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 06:15:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0688, -0.7739,  0.3523,  ..., -0.8315,  1.5781,  0.4780],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7363,  0.2781,  1.0215,  ...,  0.6831,  0.3208,  0.5435],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7974, -1.3203,  0.7939,  ..., -2.2344,  3.2539,  1.9160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.3984, -0.6504,  1.1846,  ...,  0.9038,  0.2510,  0.3545],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:15:28 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:15:28 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 06:16:25 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 06:17:25 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 06:18:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.6114e-03,  1.3838e-03, -1.1377e-03,  ..., -3.0975e-03,
         -6.0959e-03,  2.6627e-03],
        [-3.1376e-03,  4.6234e-03, -1.5984e-03,  ..., -8.6355e-04,
         -1.9236e-03, -2.1267e-03],
        [-4.3869e-03, -1.3037e-03,  7.9422e-03,  ..., -1.6699e-03,
         -1.9360e-03,  2.1381e-03],
        ...,
        [ 8.0414e-03,  1.7147e-03, -5.6000e-03,  ...,  1.1971e-02,
         -5.0426e-05, -1.8291e-03],
        [ 2.8539e-04, -4.1466e-03,  3.3379e-03,  ...,  3.8099e-04,
          8.6441e-03,  3.4523e-03],
        [ 1.4191e-03,  8.0566e-03, -6.3362e-03,  ..., -1.9102e-03,
          4.9248e-03,  1.1017e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.7952e-02,  2.1271e-02,  5.7144e-03,  ...,  3.4695e-03,
         -1.7557e-03, -1.4458e-02],
        [ 9.8572e-03, -1.0754e-01, -1.5121e-02,  ..., -1.2535e-02,
          9.4833e-03, -9.5749e-03],
        [ 1.8454e-03, -5.5161e-03, -9.9915e-02,  ...,  8.3923e-05,
          1.6724e-02, -5.5733e-03],
        ...,
        [ 9.0942e-03, -9.1705e-03, -1.4061e-02,  ..., -8.2703e-02,
          1.0864e-02,  2.0142e-03],
        [-1.0376e-02,  1.1665e-02, -3.4952e-04,  ..., -4.4179e-04,
         -9.3994e-02,  3.4580e-03],
        [-9.9564e-04,  1.3397e-02,  1.0614e-03,  ..., -5.4741e-03,
         -2.2354e-03, -9.3506e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1230,  0.0022, -0.0122,  ..., -0.0200,  0.0052,  0.0017],
        [ 0.0052, -0.1136, -0.0031,  ...,  0.0133,  0.0023,  0.0122],
        [ 0.0042, -0.0132, -0.1015,  ...,  0.0057, -0.0013, -0.0028],
        ...,
        [-0.0030, -0.0149,  0.0012,  ..., -0.1193,  0.0187, -0.0131],
        [-0.0043,  0.0122, -0.0140,  ...,  0.0134, -0.1107,  0.0074],
        [-0.0095,  0.0071, -0.0081,  ..., -0.0145,  0.0071, -0.1102]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:18:28 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 06:18:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0302, -0.7368,  0.2166,  ..., -0.8086,  1.6025,  0.6587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.1191, -0.1494,  0.6309,  ...,  0.7397,  0.6582,  0.5244],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2915, -1.1338,  0.0781,  ..., -1.6562,  3.2070,  2.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.6572, -0.7856,  0.6675,  ...,  1.9863,  0.0389,  0.3389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:18:28 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:18:28 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 06:19:31 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 06:20:38 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 06:21:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.1041e-03, -6.2132e-04,  1.2674e-03,  ...,  1.4467e-03,
         -7.0095e-04,  1.1740e-03],
        [ 2.7485e-03,  3.4618e-03,  1.6737e-04,  ..., -2.1648e-03,
          2.8782e-03, -2.0351e-03],
        [ 2.4261e-03, -1.6394e-03, -4.2295e-04,  ...,  3.8147e-04,
          8.2731e-04,  1.5316e-03],
        ...,
        [ 1.3514e-03, -1.0815e-03, -1.0452e-03,  ...,  2.4185e-03,
         -2.8801e-03,  9.3222e-04],
        [-3.1042e-04, -8.0109e-05,  2.1133e-03,  ..., -2.0275e-03,
          1.0214e-03, -8.2016e-04],
        [-1.7920e-03,  1.0605e-03,  3.9940e-03,  ..., -1.2856e-03,
          9.7847e-04,  2.4967e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0942, -0.0100, -0.0050,  ..., -0.0086,  0.0056,  0.0030],
        [-0.0184, -0.1071, -0.0051,  ..., -0.0011, -0.0224, -0.0101],
        [ 0.0075, -0.0136, -0.0966,  ...,  0.0046,  0.0048,  0.0021],
        ...,
        [-0.0075,  0.0038, -0.0074,  ..., -0.0911, -0.0089,  0.0070],
        [ 0.0111, -0.0122, -0.0030,  ...,  0.0054, -0.1212, -0.0049],
        [-0.0163,  0.0038, -0.0027,  ...,  0.0030,  0.0117, -0.0934]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.7778e-02,  1.4219e-03, -1.3412e-02,  ...,  1.3351e-03,
         -6.0081e-03, -1.1072e-03],
        [-7.5769e-04, -1.2115e-01, -4.0283e-03,  ...,  1.8063e-03,
          2.2430e-03, -3.5725e-03],
        [ 4.4556e-03, -4.7684e-06, -1.1609e-01,  ..., -1.0895e-02,
          9.1629e-03,  2.9335e-03],
        ...,
        [ 2.3193e-03,  9.7961e-03, -3.5286e-03,  ..., -1.0046e-01,
          2.3422e-03, -7.0572e-03],
        [ 8.4610e-03, -1.9970e-03, -8.4000e-03,  ...,  1.2978e-02,
         -1.2073e-01,  4.0207e-03],
        [ 9.9792e-03,  1.1368e-02, -2.3308e-03,  ..., -8.3160e-03,
          1.5076e-02, -1.0516e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:21:44 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 06:21:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3484, -0.6533,  0.3435,  ..., -1.0752,  1.5703,  0.9092],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8413, -0.3669,  0.6138,  ...,  0.4990,  0.1456,  0.1754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3015, -1.1895,  0.3809,  ..., -1.8379,  2.6914,  2.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1904, -0.7158,  1.0869,  ...,  1.9326, -0.0712, -0.0342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:21:44 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:21:44 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 06:22:51 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 06:23:52 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 06:24:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0069, -0.0051, -0.0012,  ..., -0.0037,  0.0010, -0.0011],
        [ 0.0006, -0.0040, -0.0008,  ..., -0.0042, -0.0025,  0.0041],
        [ 0.0013, -0.0022, -0.0018,  ..., -0.0022, -0.0037,  0.0023],
        ...,
        [ 0.0020, -0.0016,  0.0036,  ..., -0.0059, -0.0011, -0.0034],
        [ 0.0018, -0.0016, -0.0038,  ..., -0.0002, -0.0084,  0.0028],
        [ 0.0004,  0.0034, -0.0069,  ..., -0.0045, -0.0005, -0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.7007e-02,  9.5844e-05,  2.5730e-03,  ..., -2.0004e-02,
          1.3725e-02, -9.5444e-03],
        [-1.9474e-03, -6.3660e-02, -1.1330e-02,  ...,  1.4820e-03,
          6.8359e-03,  1.0078e-02],
        [-4.1618e-03, -7.8678e-04, -5.6152e-02,  ..., -6.0692e-03,
          8.3694e-03,  2.2049e-03],
        ...,
        [-1.3260e-02,  9.8801e-03, -4.8103e-03,  ..., -5.7922e-02,
          2.1133e-03, -9.0714e-03],
        [ 5.2986e-03,  2.2141e-02, -1.7834e-03,  ...,  2.2678e-03,
         -6.2225e-02,  8.5907e-03],
        [-2.5387e-03,  1.0757e-02,  9.3689e-03,  ...,  2.7466e-03,
         -1.3947e-02, -6.4331e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0753,  0.0178,  0.0028,  ..., -0.0072,  0.0158, -0.0003],
        [-0.0050, -0.0927, -0.0092,  ...,  0.0065,  0.0032,  0.0026],
        [ 0.0110, -0.0012, -0.0825,  ...,  0.0050, -0.0280, -0.0077],
        ...,
        [-0.0232,  0.0026, -0.0060,  ..., -0.0814, -0.0055,  0.0065],
        [-0.0050,  0.0221,  0.0004,  ..., -0.0035, -0.0856,  0.0070],
        [-0.0060,  0.0045, -0.0035,  ..., -0.0023, -0.0100, -0.0829]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:24:58 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 06:24:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1176, -0.5312,  0.0314,  ..., -0.7388,  1.4639,  0.8716],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8516, -0.3989,  0.3218,  ...,  0.9541,  0.0334,  0.1323],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6367, -1.1582,  1.0977,  ..., -1.4961,  2.2676,  2.8184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0469, -0.3550,  1.5068,  ...,  2.5117, -0.5693, -0.0815],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:24:58 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:24:58 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 06:26:05 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 06:27:12 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 06:28:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0019, -0.0092,  0.0084,  ...,  0.0057,  0.0011, -0.0065],
        [-0.0050, -0.0007,  0.0049,  ..., -0.0005,  0.0052, -0.0007],
        [-0.0047, -0.0033, -0.0009,  ..., -0.0053,  0.0049, -0.0046],
        ...,
        [ 0.0026, -0.0074,  0.0029,  ..., -0.0036,  0.0055, -0.0044],
        [ 0.0133,  0.0069, -0.0040,  ..., -0.0051, -0.0118,  0.0005],
        [ 0.0077,  0.0003,  0.0021,  ..., -0.0032,  0.0055, -0.0082]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0427, -0.0054,  0.0186,  ...,  0.0087,  0.0054, -0.0084],
        [ 0.0120, -0.0582,  0.0136,  ..., -0.0083,  0.0285, -0.0063],
        [ 0.0135,  0.0072, -0.0611,  ..., -0.0073,  0.0046,  0.0151],
        ...,
        [ 0.0088, -0.0081,  0.0011,  ..., -0.0571,  0.0189,  0.0047],
        [ 0.0055,  0.0091, -0.0007,  ...,  0.0060, -0.0481, -0.0050],
        [-0.0090,  0.0078, -0.0081,  ..., -0.0066,  0.0094, -0.0515]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0631, -0.0093, -0.0064,  ...,  0.0016, -0.0117, -0.0021],
        [-0.0057, -0.0728, -0.0116,  ..., -0.0029, -0.0042,  0.0059],
        [ 0.0075, -0.0118, -0.0928,  ...,  0.0075,  0.0053, -0.0011],
        ...,
        [ 0.0088, -0.0132,  0.0148,  ..., -0.0524,  0.0058, -0.0101],
        [ 0.0046, -0.0124, -0.0015,  ...,  0.0060, -0.0869,  0.0048],
        [-0.0175,  0.0017,  0.0055,  ..., -0.0155,  0.0124, -0.0730]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:28:20 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 06:28:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1112, -0.5137,  0.1453,  ..., -0.7979,  1.1895,  0.9692],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6040, -0.3406,  0.5034,  ...,  0.9297, -0.0290, -0.0612],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3406, -1.1895,  1.1543,  ..., -1.6729,  2.0703,  3.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4102,  0.0525,  1.0625,  ...,  2.3203, -0.1987,  0.0202],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:28:20 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:28:20 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 06:29:27 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 06:30:35 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 06:31:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0055, -0.0022,  0.0039,  ..., -0.0033,  0.0054, -0.0005],
        [-0.0060,  0.0037, -0.0033,  ..., -0.0006,  0.0013, -0.0049],
        [-0.0034, -0.0060,  0.0007,  ...,  0.0085, -0.0020, -0.0046],
        ...,
        [ 0.0029,  0.0013, -0.0084,  ..., -0.0037, -0.0008, -0.0070],
        [ 0.0065,  0.0065,  0.0088,  ...,  0.0007, -0.0006,  0.0083],
        [ 0.0034,  0.0029, -0.0048,  ...,  0.0168, -0.0018,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0516,  0.0103,  0.0057,  ..., -0.0130, -0.0052, -0.0106],
        [ 0.0091, -0.0522, -0.0082,  ...,  0.0002,  0.0050, -0.0025],
        [-0.0117,  0.0029, -0.0514,  ...,  0.0015, -0.0011, -0.0140],
        ...,
        [-0.0176,  0.0156,  0.0153,  ..., -0.0388, -0.0061,  0.0123],
        [-0.0035, -0.0049, -0.0025,  ...,  0.0025, -0.0425,  0.0085],
        [-0.0042, -0.0064, -0.0076,  ..., -0.0036,  0.0065, -0.0477]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0644,  0.0019,  0.0071,  ..., -0.0014,  0.0028,  0.0067],
        [ 0.0086, -0.0895,  0.0042,  ..., -0.0107, -0.0022,  0.0258],
        [-0.0003, -0.0076, -0.0603,  ..., -0.0176, -0.0073, -0.0100],
        ...,
        [-0.0057,  0.0074, -0.0049,  ..., -0.0678, -0.0131,  0.0171],
        [ 0.0048, -0.0071, -0.0102,  ..., -0.0200, -0.0601, -0.0038],
        [-0.0099,  0.0076, -0.0069,  ..., -0.0115, -0.0083, -0.0617]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:31:46 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 06:31:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2698, -0.5034,  0.4282,  ..., -0.6372,  0.9873,  1.1768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4744, -0.1603,  0.6211,  ...,  1.0879, -0.2261, -0.0795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0696, -1.8418,  0.7979,  ..., -1.4365,  2.2695,  3.3887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.6602, -0.5312,  0.4941,  ...,  1.9316,  0.1936, -0.0461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:31:46 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:31:46 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 06:32:56 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 06:34:05 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 06:35:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0129, -0.0045, -0.0079,  ..., -0.0069,  0.0053, -0.0034],
        [ 0.0100,  0.0013,  0.0053,  ...,  0.0009,  0.0016,  0.0021],
        [ 0.0027, -0.0050, -0.0067,  ..., -0.0017,  0.0005,  0.0063],
        ...,
        [-0.0041, -0.0010,  0.0037,  ..., -0.0020, -0.0035,  0.0006],
        [-0.0034, -0.0082,  0.0057,  ...,  0.0006, -0.0026,  0.0002],
        [ 0.0036,  0.0036,  0.0008,  ..., -0.0113, -0.0040, -0.0008]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0161, -0.0009, -0.0076,  ..., -0.0088,  0.0101, -0.0293],
        [ 0.0068, -0.0095, -0.0172,  ..., -0.0059,  0.0005,  0.0067],
        [-0.0042, -0.0006, -0.0172,  ...,  0.0032, -0.0051,  0.0073],
        ...,
        [-0.0206, -0.0066, -0.0038,  ..., -0.0226,  0.0002,  0.0068],
        [ 0.0231,  0.0077, -0.0138,  ..., -0.0126, -0.0337,  0.0111],
        [-0.0085,  0.0132, -0.0053,  ..., -0.0031,  0.0022, -0.0335]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0483,  0.0004,  0.0166,  ..., -0.0099,  0.0001,  0.0155],
        [-0.0245, -0.0487, -0.0122,  ..., -0.0067,  0.0106,  0.0057],
        [ 0.0091, -0.0127, -0.0632,  ..., -0.0179,  0.0040, -0.0076],
        ...,
        [-0.0019, -0.0021, -0.0057,  ..., -0.0629, -0.0122,  0.0020],
        [ 0.0004,  0.0047, -0.0141,  ...,  0.0021, -0.0374,  0.0197],
        [ 0.0012,  0.0056,  0.0144,  ...,  0.0033, -0.0027, -0.0524]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:35:21 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 06:35:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1404, -0.5112,  0.4365,  ..., -0.6860,  0.8374,  1.3457],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5566,  0.0112,  0.3784,  ...,  0.8940, -0.0784, -0.0219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5225, -2.0859,  0.5317,  ..., -1.4883,  2.7188,  2.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8828, -0.0239,  1.1055,  ...,  2.0098,  0.3914, -0.2473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:35:21 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:35:21 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 06:36:27 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 06:37:33 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 06:38:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0074,  0.0006, -0.0012,  ...,  0.0026, -0.0010, -0.0018],
        [ 0.0016,  0.0058, -0.0021,  ...,  0.0009, -0.0019, -0.0022],
        [ 0.0008,  0.0009,  0.0017,  ...,  0.0017,  0.0009,  0.0001],
        ...,
        [ 0.0016, -0.0015, -0.0022,  ...,  0.0047, -0.0003, -0.0006],
        [-0.0017, -0.0004,  0.0003,  ...,  0.0013,  0.0030,  0.0006],
        [-0.0011,  0.0003, -0.0017,  ..., -0.0019,  0.0008,  0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0292, -0.0031, -0.0025,  ...,  0.0056, -0.0100,  0.0007],
        [ 0.0132, -0.0192,  0.0007,  ...,  0.0001,  0.0100,  0.0197],
        [ 0.0078, -0.0023, -0.0300,  ..., -0.0073, -0.0014, -0.0042],
        ...,
        [-0.0075, -0.0135, -0.0208,  ..., -0.0253,  0.0057, -0.0029],
        [-0.0091, -0.0016,  0.0025,  ...,  0.0035, -0.0043,  0.0068],
        [-0.0026, -0.0029,  0.0034,  ..., -0.0206,  0.0039, -0.0234]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0507,  0.0085,  0.0137,  ..., -0.0029,  0.0163,  0.0008],
        [ 0.0164, -0.0557, -0.0093,  ...,  0.0061, -0.0026,  0.0326],
        [ 0.0075, -0.0107, -0.0590,  ..., -0.0040,  0.0047, -0.0018],
        ...,
        [ 0.0117, -0.0128, -0.0303,  ..., -0.0505,  0.0021, -0.0029],
        [ 0.0047,  0.0138,  0.0091,  ..., -0.0275, -0.0479, -0.0121],
        [-0.0107, -0.0050, -0.0053,  ..., -0.0223,  0.0058, -0.0712]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:38:45 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 06:38:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0233, -0.7358,  0.2957,  ..., -0.5737,  0.8877,  1.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6357, -0.2115,  0.1780,  ...,  0.7207,  0.0834, -0.0417],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4795, -2.3555,  0.9023,  ..., -2.1113,  2.9746,  3.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5322,  0.2861,  1.3438,  ...,  2.3359,  0.6924,  0.5244],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:38:45 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:38:45 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 06:39:59 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 06:41:18 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 06:42:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0004, -0.0047,  0.0026,  ..., -0.0018, -0.0032,  0.0045],
        [ 0.0015, -0.0027, -0.0049,  ...,  0.0019,  0.0011,  0.0008],
        [-0.0013,  0.0006, -0.0026,  ..., -0.0001, -0.0008,  0.0007],
        ...,
        [ 0.0063,  0.0019, -0.0046,  ...,  0.0023, -0.0021, -0.0032],
        [ 0.0008,  0.0049,  0.0012,  ...,  0.0052, -0.0036, -0.0024],
        [-0.0021, -0.0029,  0.0075,  ..., -0.0023,  0.0083,  0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0003, -0.0093, -0.0106,  ..., -0.0110,  0.0141,  0.0014],
        [-0.0056, -0.0324, -0.0037,  ..., -0.0093,  0.0108,  0.0005],
        [ 0.0127,  0.0008,  0.0014,  ..., -0.0059,  0.0008, -0.0193],
        ...,
        [ 0.0001, -0.0024, -0.0085,  ..., -0.0229, -0.0002, -0.0005],
        [-0.0027,  0.0014,  0.0214,  ...,  0.0079, -0.0014, -0.0117],
        [-0.0023, -0.0039,  0.0038,  ..., -0.0023, -0.0063, -0.0092]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0566,  0.0226, -0.0106,  ...,  0.0003, -0.0078,  0.0108],
        [ 0.0061, -0.0765, -0.0130,  ..., -0.0248,  0.0117,  0.0087],
        [ 0.0195,  0.0043, -0.0398,  ...,  0.0012, -0.0013, -0.0135],
        ...,
        [-0.0087, -0.0031, -0.0063,  ..., -0.0571,  0.0139, -0.0053],
        [-0.0058, -0.0226,  0.0020,  ..., -0.0140, -0.0457,  0.0052],
        [-0.0076,  0.0055,  0.0043,  ...,  0.0090, -0.0051, -0.0557]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:42:35 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 06:42:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2064, -0.7827,  0.1843,  ..., -0.5537,  1.0527,  1.1035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3418, -0.0096,  0.4019,  ...,  0.7573,  0.1627, -0.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.0732, -2.5020,  1.7031,  ..., -1.8975,  3.8066,  3.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0283, -0.3677,  1.4170,  ...,  1.6230,  1.1924,  0.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:42:35 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:42:35 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 06:43:53 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 06:45:11 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 06:46:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3351e-04,  2.5082e-04, -2.3544e-05,  ..., -1.7285e-04,
         -6.7711e-04, -4.2295e-04],
        [-2.9826e-04, -9.0313e-04,  3.6669e-04,  ..., -1.2755e-04,
          3.9124e-04,  7.0453e-05],
        [ 5.6982e-04,  1.8120e-04, -1.8907e-04,  ..., -3.1495e-04,
         -7.5519e-05, -3.5834e-04],
        ...,
        [ 3.8195e-04, -1.9503e-04, -9.6798e-04,  ..., -7.2813e-04,
         -6.9046e-04, -3.8719e-04],
        [ 3.1066e-04,  2.7156e-04,  4.2319e-06,  ...,  4.2260e-05,
         -1.0977e-03,  8.6403e-04],
        [ 1.3905e-03, -5.2691e-05, -1.0338e-03,  ...,  4.9210e-04,
         -1.1311e-03, -1.4257e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0040, -0.0038,  0.0054,  ..., -0.0169,  0.0052,  0.0032],
        [-0.0017, -0.0054,  0.0087,  ...,  0.0070,  0.0093,  0.0029],
        [-0.0047, -0.0018,  0.0015,  ...,  0.0051,  0.0101, -0.0085],
        ...,
        [ 0.0087,  0.0113, -0.0057,  ..., -0.0033, -0.0064,  0.0129],
        [ 0.0098,  0.0022, -0.0060,  ...,  0.0087, -0.0173,  0.0110],
        [ 0.0048,  0.0064, -0.0060,  ...,  0.0077,  0.0055, -0.0091]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0560, -0.0124, -0.0042,  ..., -0.0214, -0.0173,  0.0123],
        [-0.0099, -0.0337,  0.0071,  ...,  0.0006,  0.0157, -0.0003],
        [-0.0134,  0.0050, -0.0457,  ..., -0.0135,  0.0030,  0.0125],
        ...,
        [ 0.0069,  0.0092, -0.0059,  ..., -0.0542,  0.0033,  0.0166],
        [-0.0061,  0.0009, -0.0083,  ..., -0.0245, -0.0523, -0.0030],
        [-0.0014,  0.0156, -0.0086,  ..., -0.0173,  0.0101, -0.0548]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:46:31 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 06:46:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1718, -0.8477,  0.2971,  ..., -0.7573,  1.1133,  1.1152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1887,  0.1053,  0.4609,  ...,  0.8525,  0.2778,  0.1675],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.5244, -1.6494,  1.0293,  ..., -1.1914,  3.7090,  3.2461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2556, -0.2295,  2.3613,  ...,  2.7207,  0.7852,  1.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:46:31 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:46:31 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 06:47:49 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 06:49:08 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 06:50:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.5387e-03,  6.0368e-04, -9.7609e-04,  ..., -4.7708e-04,
         -1.3218e-03, -8.3113e-04],
        [ 1.9288e-04,  4.5166e-03,  8.6784e-04,  ...,  2.2831e-03,
         -6.8378e-04,  1.2722e-03],
        [-1.3328e-04,  2.2280e-04,  7.6523e-03,  ...,  1.5223e-04,
          2.1286e-03,  2.4242e-03],
        ...,
        [-1.7853e-03,  4.0233e-05,  1.8415e-03,  ...,  3.5248e-03,
          6.6102e-05, -1.4353e-03],
        [ 1.1520e-03,  1.4048e-03, -2.1935e-03,  ...,  1.1864e-03,
          1.1473e-03, -6.1274e-04],
        [-1.4229e-03,  5.6791e-04,  1.2283e-03,  ...,  3.6073e-04,
          1.5488e-03,  3.1776e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0090, -0.0043, -0.0141,  ..., -0.0122,  0.0064, -0.0121],
        [-0.0037,  0.0029,  0.0161,  ..., -0.0022,  0.0087,  0.0093],
        [ 0.0110,  0.0158,  0.0039,  ...,  0.0019,  0.0046, -0.0021],
        ...,
        [-0.0168,  0.0040,  0.0026,  ...,  0.0022, -0.0053, -0.0051],
        [ 0.0004, -0.0120,  0.0041,  ...,  0.0024,  0.0038,  0.0130],
        [-0.0081,  0.0060,  0.0089,  ...,  0.0043,  0.0191, -0.0179]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0754, -0.0009, -0.0225,  ..., -0.0083,  0.0146,  0.0215],
        [-0.0159, -0.0622,  0.0067,  ..., -0.0092, -0.0255,  0.0208],
        [-0.0195, -0.0094, -0.0724,  ..., -0.0082,  0.0040, -0.0004],
        ...,
        [ 0.0191, -0.0158, -0.0194,  ..., -0.0817, -0.0028, -0.0185],
        [ 0.0170, -0.0078,  0.0118,  ...,  0.0030, -0.0818,  0.0200],
        [ 0.0020,  0.0084,  0.0044,  ...,  0.0020, -0.0041, -0.0695]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:50:32 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 06:50:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3865, -0.8384,  0.5542,  ..., -0.6758,  1.3818,  1.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0035, -0.0983,  0.4529,  ...,  0.5576,  0.4395,  0.2238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.7930, -1.4854,  1.4561,  ..., -0.9116,  3.8203,  3.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8379, -0.3887,  2.5859,  ...,  3.2305,  1.4473,  2.4980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:50:32 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:50:32 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 06:51:54 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 06:53:15 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 06:54:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7576e-03, -3.0828e-04,  2.4509e-04,  ...,  3.7491e-05,
          1.3006e-04,  5.8699e-04],
        [ 7.2658e-05,  9.0408e-04, -4.6206e-04,  ..., -3.5405e-04,
         -4.1270e-04, -2.1350e-04],
        [-3.8505e-05, -9.9480e-05,  2.5520e-03,  ..., -1.3781e-03,
          1.8096e-04,  8.8453e-04],
        ...,
        [ 2.6751e-04,  1.3828e-04, -9.0408e-04,  ...,  3.2463e-03,
          1.2064e-04, -1.1835e-03],
        [ 2.2984e-04,  4.3035e-04, -2.6870e-04,  ...,  6.9523e-04,
          2.2736e-03, -5.9652e-04],
        [ 1.9193e-05, -4.9257e-04,  2.7359e-05,  ..., -1.5569e-04,
          8.5771e-05,  3.0899e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0277,  0.0023,  0.0120,  ...,  0.0035, -0.0026, -0.0061],
        [-0.0145,  0.0100, -0.0103,  ...,  0.0037, -0.0070,  0.0109],
        [-0.0029,  0.0023,  0.0251,  ...,  0.0091, -0.0014, -0.0035],
        ...,
        [-0.0026,  0.0033, -0.0145,  ...,  0.0163,  0.0056, -0.0018],
        [-0.0065, -0.0028,  0.0042,  ..., -0.0049,  0.0161, -0.0010],
        [-0.0041,  0.0019, -0.0016,  ..., -0.0073, -0.0001,  0.0130]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0140, -0.0193, -0.0021,  ..., -0.0070,  0.0107,  0.0087],
        [-0.0098, -0.0428,  0.0120,  ...,  0.0013, -0.0122,  0.0351],
        [ 0.0084, -0.0011,  0.0276,  ...,  0.0049,  0.0054, -0.0108],
        ...,
        [-0.0188,  0.0013, -0.0133,  ...,  0.0313,  0.0095, -0.0174],
        [-0.0067,  0.0049, -0.0009,  ...,  0.0173,  0.0177,  0.0011],
        [-0.0117,  0.0304, -0.0116,  ...,  0.0047,  0.0018, -0.0168]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:54:38 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 06:54:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5005, -0.5166,  0.2927,  ..., -0.4402,  1.2539,  1.0889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1149, -0.0508,  0.7612,  ...,  0.8916,  0.2688,  0.3169],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.7725, -0.6943,  1.5371,  ..., -1.3359,  4.3516,  2.3516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1680, -0.3540,  2.6465,  ...,  3.4238,  1.2656,  3.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:54:38 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:54:38 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 06:56:03 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 06:57:29 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 06:58:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.7411e-04,  5.9605e-06, -4.1318e-04,  ...,  3.8195e-04,
          4.6754e-04,  5.1022e-05],
        [-4.7445e-05, -2.1195e-04,  1.7333e-04,  ..., -1.4591e-04,
          1.6093e-06,  6.1631e-05],
        [-2.6882e-05,  1.1504e-04,  3.9506e-04,  ..., -1.4710e-04,
          1.7071e-04, -5.5134e-05],
        ...,
        [-1.4675e-04, -2.8074e-05, -2.5105e-04,  ...,  4.5824e-04,
          2.9469e-04, -1.8537e-05],
        [ 9.7573e-05, -4.7445e-05,  1.1528e-04,  ..., -5.7888e-04,
         -1.0395e-04, -1.1510e-04],
        [-1.4305e-04, -6.5923e-05,  5.1498e-04,  ..., -1.0657e-04,
         -3.4094e-05,  1.2887e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.5787e-02,  1.1513e-02, -4.4518e-03,  ...,  4.3945e-03,
          4.0245e-03,  4.0359e-03],
        [ 3.4409e-03, -2.6489e-02,  1.4496e-03,  ...,  1.1902e-02,
         -1.2573e-02,  4.2686e-03],
        [-1.5472e-02,  5.2948e-03, -1.1589e-02,  ..., -1.1612e-02,
         -4.8065e-03, -5.8937e-03],
        ...,
        [-1.8005e-03, -2.5864e-03, -1.1703e-02,  ..., -2.7828e-03,
          2.1648e-04,  4.7636e-04],
        [ 5.7831e-03,  3.5362e-03,  2.0798e-02,  ..., -2.2308e-02,
         -2.1935e-05, -1.7357e-03],
        [-1.2619e-02, -1.9417e-03, -4.2534e-04,  ...,  1.2913e-03,
         -2.4605e-03,  7.8535e-04]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0635, -0.0031,  0.0082,  ...,  0.0049,  0.0089,  0.0018],
        [ 0.0050, -0.0404, -0.0026,  ...,  0.0162, -0.0059, -0.0113],
        [ 0.0089,  0.0105, -0.0300,  ..., -0.0030, -0.0098, -0.0094],
        ...,
        [-0.0301, -0.0051, -0.0058,  ..., -0.0370, -0.0036, -0.0023],
        [ 0.0145,  0.0011, -0.0119,  ..., -0.0177, -0.0307,  0.0028],
        [ 0.0029,  0.0051, -0.0164,  ..., -0.0112,  0.0121, -0.0432]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 06:58:56 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 06:58:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5059, -0.4099,  0.3472,  ..., -0.3728,  1.1201,  0.8833],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2235, -0.0918,  0.7393,  ...,  0.9331,  0.4382,  0.7646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2295, -0.1826,  0.0488,  ..., -2.1094,  4.1523,  1.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7754, -0.0042,  1.1045,  ...,  2.2461,  1.7559,  2.9785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 06:58:57 root INFO     [order_1_approx] starting weight calculation for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 06:58:57 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 07:00:19 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 07:01:46 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 07:03:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2907e-03, -4.6682e-04,  1.2589e-04,  ...,  6.8426e-05,
         -2.8312e-05, -3.0708e-04],
        [ 4.2605e-04,  1.5984e-03, -2.6870e-04,  ...,  1.3185e-04,
          4.1389e-04,  1.2422e-04],
        [ 7.5436e-04, -3.4451e-05,  2.2106e-03,  ..., -1.2898e-04,
         -6.3372e-04, -1.9145e-04],
        ...,
        [ 2.6524e-05, -5.0402e-04, -2.9016e-04,  ...,  2.7733e-03,
          3.4475e-04, -4.2272e-04],
        [-8.0967e-04,  1.8597e-05,  4.1747e-04,  ...,  3.0780e-04,
          2.5711e-03,  2.3186e-05],
        [-1.0729e-06,  2.8896e-04,  1.7345e-04,  ...,  2.7561e-04,
         -2.6989e-04,  3.2749e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0061,  0.0068, -0.0077,  ..., -0.0002,  0.0024,  0.0123],
        [ 0.0083, -0.0027,  0.0024,  ..., -0.0025,  0.0045,  0.0099],
        [-0.0180,  0.0103, -0.0128,  ..., -0.0048, -0.0154, -0.0002],
        ...,
        [-0.0165,  0.0056, -0.0144,  ...,  0.0114, -0.0161,  0.0115],
        [-0.0059, -0.0054, -0.0081,  ..., -0.0115,  0.0084, -0.0017],
        [-0.0135,  0.0146, -0.0016,  ...,  0.0046, -0.0026,  0.0214]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0071,  0.0270, -0.0086,  ...,  0.0011,  0.0069, -0.0066],
        [ 0.0268, -0.0354, -0.0057,  ..., -0.0191,  0.0152,  0.0002],
        [-0.0081,  0.0186,  0.0089,  ..., -0.0182,  0.0196, -0.0041],
        ...,
        [ 0.0124,  0.0004,  0.0224,  ..., -0.0033,  0.0030,  0.0008],
        [-0.0051, -0.0045,  0.0049,  ..., -0.0023, -0.0343,  0.0320],
        [-0.0036,  0.0093,  0.0209,  ...,  0.0062,  0.0114, -0.0187]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:03:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too compensated, it is overcompensated
If something is too loaded, it is overloaded
If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is
2024-06-30 07:03:16 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 07:03:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6162, -0.2026,  0.1354,  ..., -0.1379, -0.2952, -0.2144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1620, -0.1614,  0.1700,  ...,  0.1871, -0.3672, -0.5522],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.9531,  0.1464,  0.9941,  ..., -0.0802, -0.4688, -0.6074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5835,  0.1338,  0.2148,  ...,  0.2030, -0.3899, -0.0673],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:03:16 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:03:16 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 07:03:40 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 07:04:03 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 07:04:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3861e-03, -2.4414e-04, -1.3590e-05,  ...,  1.9813e-04,
         -2.2829e-05, -1.3888e-05],
        [ 2.5892e-04, -2.3613e-03, -5.4955e-05,  ..., -1.1426e-04,
         -3.3879e-04,  8.0872e-04],
        [ 1.9503e-04,  3.2616e-04, -3.0918e-03,  ..., -1.1671e-04,
         -3.6955e-06, -2.6870e-04],
        ...,
        [-7.0715e-04, -3.5048e-04, -1.0133e-05,  ..., -2.1400e-03,
         -1.3995e-04, -2.7466e-04],
        [-1.4639e-04,  4.0889e-04, -4.4727e-04,  ..., -8.8930e-05,
         -2.6150e-03,  3.8242e-04],
        [-4.8232e-04,  2.3234e-04,  3.5882e-05,  ...,  2.0313e-04,
          2.2006e-04, -2.2526e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0300, -0.0006,  0.0114,  ...,  0.0094,  0.0030,  0.0002],
        [-0.0028, -0.0306, -0.0030,  ..., -0.0001,  0.0016,  0.0010],
        [ 0.0007, -0.0126, -0.0372,  ..., -0.0059, -0.0043, -0.0003],
        ...,
        [ 0.0077,  0.0006, -0.0023,  ..., -0.0276,  0.0047,  0.0004],
        [-0.0100, -0.0027,  0.0004,  ...,  0.0094, -0.0206,  0.0043],
        [-0.0016,  0.0066, -0.0030,  ...,  0.0014, -0.0011, -0.0275]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0356, -0.0015,  0.0023,  ...,  0.0004,  0.0004,  0.0005],
        [ 0.0023, -0.0354, -0.0040,  ...,  0.0014,  0.0052, -0.0005],
        [-0.0060, -0.0022, -0.0313,  ..., -0.0016, -0.0037,  0.0008],
        ...,
        [-0.0009, -0.0003,  0.0027,  ..., -0.0332, -0.0006, -0.0016],
        [-0.0015,  0.0018,  0.0023,  ..., -0.0017, -0.0307,  0.0055],
        [-0.0010, -0.0027, -0.0026,  ...,  0.0052,  0.0017, -0.0304]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:04:28 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 07:04:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.0430, -0.0573,  0.5952,  ..., -0.3101, -0.3779, -0.1899],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7168, -0.0830,  0.3318,  ..., -0.1199, -0.5049, -0.3457],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1875,  0.5688,  1.2324,  ..., -0.3179, -0.7031, -0.3540],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5464,  0.0284,  0.1566,  ..., -0.5962, -0.3047,  0.1273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:04:28 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:04:28 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 07:04:52 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 07:05:16 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 07:05:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.3264e-03,  3.5691e-04, -2.4986e-04,  ..., -6.8569e-04,
         -1.5831e-04, -1.1826e-04],
        [ 1.5373e-03, -3.3169e-03, -3.5524e-04,  ...,  7.6103e-04,
         -2.4533e-04,  5.7793e-04],
        [ 7.9679e-04,  1.3323e-03, -3.8090e-03,  ..., -7.2813e-04,
          3.3045e-04,  6.4659e-04],
        ...,
        [-2.2054e-04,  1.1673e-03, -1.6432e-03,  ..., -4.6577e-03,
         -1.0681e-03, -2.3007e-05],
        [ 3.2187e-05,  6.4087e-04,  3.6430e-04,  ...,  3.3855e-04,
         -3.4370e-03, -1.7118e-03],
        [-6.1035e-04,  3.4690e-05, -2.6524e-05,  ..., -4.8590e-04,
         -1.6344e-04, -2.4338e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.8868e-02,  8.8120e-03,  1.6270e-03,  ...,  3.7289e-03,
          4.8790e-03,  4.2725e-03],
        [ 7.8201e-03, -6.0638e-02, -1.8997e-02,  ...,  1.7227e-02,
         -9.2773e-03,  1.5388e-02],
        [ 1.4582e-03, -1.0185e-02, -6.1218e-02,  ..., -2.1915e-03,
          3.3021e-05, -4.6463e-03],
        ...,
        [ 8.9035e-03,  8.0109e-03,  4.2381e-03,  ..., -6.6528e-02,
         -8.2474e-03,  5.1537e-03],
        [ 8.5907e-03, -6.3705e-03,  1.5106e-03,  ..., -5.7297e-03,
         -6.7261e-02,  2.5978e-03],
        [-8.2779e-03,  1.8396e-03,  6.4850e-05,  ...,  6.3372e-04,
          8.4000e-03, -6.0059e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.9580e-02,  1.9197e-03, -6.7482e-03,  ..., -7.0190e-04,
          7.5340e-03, -1.6117e-04],
        [ 1.4710e-04, -7.9346e-02, -7.6752e-03,  ...,  6.2904e-03,
          3.9749e-03,  3.1872e-03],
        [ 6.4926e-03,  2.8572e-03, -5.9998e-02,  ...,  1.3905e-03,
         -4.3106e-03, -6.9046e-03],
        ...,
        [ 1.9970e-03,  1.0078e-02,  3.5324e-03,  ..., -7.6538e-02,
         -6.6490e-03, -3.9978e-03],
        [-5.6648e-03,  2.1577e-04,  2.5406e-03,  ...,  4.7569e-03,
         -7.2693e-02,  1.9093e-03],
        [-3.8505e-05,  2.5177e-04,  1.8644e-03,  ..., -3.7651e-03,
          6.7062e-03, -7.7087e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:05:42 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 07:05:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.1338,  0.1427,  1.1250,  ..., -0.0952, -0.5405, -0.7573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9331,  0.1965,  0.3333,  ...,  0.3076, -0.5957, -0.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7295,  0.4790,  1.0039,  ..., -0.1000, -0.7588, -0.3218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8115,  0.2544,  0.0422,  ..., -0.5645, -0.3496,  0.8745],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:05:42 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:05:42 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 07:06:07 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 07:06:32 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 07:06:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.6752e-03, -4.8518e-05, -2.2850e-03,  ...,  1.4954e-03,
         -1.1581e-04, -4.2939e-04],
        [ 4.4274e-04, -7.6599e-03,  9.5606e-04,  ...,  8.7917e-05,
         -1.4391e-03,  6.2561e-04],
        [-9.8038e-04, -1.0033e-03, -6.2141e-03,  ...,  2.0504e-04,
         -9.3651e-04, -9.6321e-04],
        ...,
        [-1.1606e-03,  8.6641e-04, -7.1764e-04,  ..., -6.5193e-03,
          7.8487e-04, -4.5872e-04],
        [-9.6512e-04,  3.6860e-04, -5.8532e-05,  ...,  8.3494e-04,
         -6.2790e-03, -1.3456e-03],
        [ 8.8310e-04, -1.0252e-03,  2.0695e-03,  ...,  2.1076e-04,
          1.7273e-04, -6.6071e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0432,  0.0007, -0.0011,  ...,  0.0074,  0.0063, -0.0019],
        [ 0.0009, -0.0410, -0.0029,  ..., -0.0089, -0.0020, -0.0009],
        [ 0.0053, -0.0011, -0.0349,  ..., -0.0044, -0.0039,  0.0022],
        ...,
        [ 0.0035,  0.0036, -0.0034,  ..., -0.0418,  0.0035,  0.0047],
        [-0.0109, -0.0065,  0.0022,  ...,  0.0057, -0.0387, -0.0032],
        [-0.0037, -0.0021,  0.0083,  ..., -0.0020, -0.0054, -0.0355]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.9825e-02,  2.8248e-03, -2.1973e-03,  ...,  1.4963e-03,
          8.6784e-04, -2.1648e-03],
        [ 4.8294e-03, -3.0762e-02,  4.5700e-03,  ..., -1.9779e-03,
          7.3004e-04,  3.7975e-03],
        [ 2.9755e-03,  1.1711e-03, -3.1799e-02,  ..., -7.2403e-03,
          2.6379e-03,  4.8904e-03],
        ...,
        [ 5.2929e-05, -1.2569e-03, -6.2943e-03,  ..., -3.1525e-02,
          1.0157e-03, -3.0079e-03],
        [-4.2915e-03,  3.8834e-03,  8.8882e-03,  ...,  9.4604e-04,
         -2.3178e-02,  1.5736e-05],
        [-4.3716e-03,  3.8109e-03,  4.6234e-03,  ...,  5.3501e-04,
          6.8359e-03, -2.9282e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:06:59 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 07:06:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.4619,  0.6548,  1.4238,  ..., -0.3652, -0.8428, -0.4783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8657,  0.0252,  0.2411,  ..., -0.8633, -0.4688,  0.1687],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3770,  0.2910,  0.9668,  ...,  0.2842,  0.3242, -0.3582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5884,  0.8325,  0.3005,  ..., -0.8018,  0.0403,  0.7637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:06:59 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:06:59 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 07:07:29 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 07:08:00 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 07:08:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.6784e-04,  7.1335e-04,  7.3338e-04,  ...,  5.2154e-05,
          1.2703e-03, -1.4210e-04],
        [ 1.6556e-03, -3.4733e-03,  2.3746e-03,  ...,  2.8515e-04,
         -6.0081e-04,  1.9321e-03],
        [-2.7370e-04,  8.1599e-05, -2.4471e-03,  ...,  6.3181e-04,
          9.9182e-04, -1.2350e-03],
        ...,
        [ 1.8005e-03, -2.4109e-03, -1.2112e-03,  ..., -2.7122e-03,
          1.1530e-03,  1.3742e-03],
        [ 2.2495e-04,  4.3702e-04, -1.4420e-03,  ..., -1.2159e-03,
         -1.5478e-03,  5.3453e-04],
        [ 1.6556e-03,  2.8014e-04,  1.8835e-03,  ..., -4.7350e-04,
          1.2312e-03, -2.7695e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0417, -0.0035, -0.0011,  ...,  0.0027,  0.0080,  0.0021],
        [ 0.0042, -0.0521, -0.0012,  ...,  0.0008,  0.0025,  0.0010],
        [-0.0026,  0.0097, -0.0438,  ...,  0.0054, -0.0060,  0.0075],
        ...,
        [-0.0037, -0.0048, -0.0019,  ..., -0.0481,  0.0079, -0.0004],
        [-0.0011, -0.0097,  0.0050,  ...,  0.0056, -0.0400,  0.0079],
        [ 0.0030,  0.0016, -0.0024,  ...,  0.0064,  0.0072, -0.0508]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.3009e-02, -2.5291e-03,  4.3716e-03,  ..., -2.2144e-03,
          5.8746e-04,  9.9373e-04],
        [ 3.7231e-03, -3.5583e-02, -1.5192e-03,  ...,  4.3678e-03,
          1.0483e-02, -5.8212e-03],
        [-6.6900e-04, -3.1204e-03, -4.4617e-02,  ...,  1.4153e-03,
         -4.1428e-03,  4.3564e-03],
        ...,
        [-9.2163e-03,  1.5631e-03,  2.0862e-05,  ..., -3.9917e-02,
          5.4855e-03, -4.2496e-03],
        [-8.1587e-04,  9.2602e-04, -1.5097e-03,  ..., -6.3934e-03,
         -3.8025e-02,  5.6534e-03],
        [-1.9026e-03, -1.5507e-03,  1.9073e-06,  ..., -6.3667e-03,
         -1.6403e-03, -4.4708e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:08:32 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 07:08:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7305,  0.4333,  0.9434,  ..., -0.1080, -0.7241, -0.3740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9263,  0.2581,  0.0543,  ..., -0.6094, -0.3640,  0.9951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0273,  0.3438,  1.2578,  ..., -0.0205,  0.8535, -0.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4529,  0.5859,  0.3135,  ..., -0.3462,  0.1554,  0.5381],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:08:33 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:08:33 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 07:09:05 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 07:09:38 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 07:10:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0059,  0.0033, -0.0034,  ..., -0.0001, -0.0028,  0.0014],
        [-0.0041, -0.0024, -0.0013,  ...,  0.0012,  0.0005,  0.0011],
        [-0.0007,  0.0008, -0.0025,  ...,  0.0002,  0.0004,  0.0006],
        ...,
        [-0.0030,  0.0022, -0.0007,  ..., -0.0017, -0.0037,  0.0030],
        [ 0.0007,  0.0011, -0.0013,  ...,  0.0025, -0.0009, -0.0007],
        [ 0.0010, -0.0030, -0.0017,  ..., -0.0010,  0.0013, -0.0020]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0836,  0.0049,  0.0053,  ...,  0.0100, -0.0006,  0.0014],
        [ 0.0077, -0.0913, -0.0004,  ...,  0.0012,  0.0063,  0.0095],
        [-0.0025,  0.0006, -0.0732,  ...,  0.0021,  0.0099,  0.0074],
        ...,
        [ 0.0047, -0.0003, -0.0054,  ..., -0.0692, -0.0036,  0.0103],
        [ 0.0046,  0.0012, -0.0094,  ..., -0.0019, -0.0750,  0.0030],
        [-0.0051,  0.0018,  0.0083,  ...,  0.0075,  0.0007, -0.0828]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0901, -0.0067,  0.0057,  ..., -0.0011, -0.0047,  0.0016],
        [-0.0085, -0.0969,  0.0061,  ..., -0.0050, -0.0050, -0.0020],
        [-0.0039, -0.0003, -0.0919,  ...,  0.0003,  0.0068,  0.0067],
        ...,
        [-0.0055, -0.0036,  0.0006,  ..., -0.0864,  0.0066,  0.0049],
        [-0.0017, -0.0050,  0.0016,  ...,  0.0032, -0.0945,  0.0084],
        [ 0.0047,  0.0037,  0.0076,  ..., -0.0078, -0.0070, -0.0995]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:10:13 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 07:10:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3552,  0.2491,  0.8262,  ...,  0.2471,  0.2676, -0.3640],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6499,  0.9307,  0.3103,  ..., -0.8403,  0.0301,  0.8423],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2935,  0.4287,  1.2383,  ...,  0.4951,  1.0781, -0.4478],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2100,  0.3809,  0.2554,  ...,  0.1968,  0.2369,  0.0918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:10:13 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:10:13 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 07:10:48 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 07:11:25 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 07:12:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0090,  0.0003,  0.0018,  ..., -0.0015,  0.0033,  0.0015],
        [ 0.0036, -0.0062,  0.0017,  ..., -0.0011,  0.0010, -0.0006],
        [-0.0006,  0.0019, -0.0031,  ..., -0.0018, -0.0011,  0.0023],
        ...,
        [ 0.0014, -0.0028,  0.0012,  ..., -0.0052, -0.0005,  0.0053],
        [ 0.0057, -0.0040,  0.0042,  ..., -0.0024, -0.0027,  0.0025],
        [-0.0003, -0.0004,  0.0009,  ..., -0.0005, -0.0039,  0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0690,  0.0117,  0.0009,  ...,  0.0068,  0.0181, -0.0049],
        [ 0.0062, -0.0942, -0.0043,  ...,  0.0063, -0.0082,  0.0020],
        [ 0.0124,  0.0115, -0.0718,  ...,  0.0008,  0.0045,  0.0052],
        ...,
        [ 0.0032, -0.0074,  0.0015,  ..., -0.0626,  0.0068, -0.0088],
        [-0.0048,  0.0109,  0.0106,  ...,  0.0042, -0.0818,  0.0002],
        [-0.0091, -0.0066,  0.0056,  ...,  0.0004, -0.0104, -0.0698]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1033, -0.0016, -0.0040,  ...,  0.0037,  0.0026,  0.0014],
        [ 0.0010, -0.1091, -0.0085,  ...,  0.0049, -0.0009,  0.0032],
        [ 0.0031, -0.0022, -0.1064,  ...,  0.0109,  0.0046, -0.0055],
        ...,
        [ 0.0071,  0.0014,  0.0029,  ..., -0.1021,  0.0030, -0.0077],
        [-0.0025,  0.0010, -0.0042,  ...,  0.0057, -0.0999, -0.0040],
        [-0.0046,  0.0005, -0.0090,  ..., -0.0067,  0.0057, -0.1154]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:12:03 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 07:12:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0338,  0.3022,  0.9746,  ..., -0.0490,  0.6987, -0.2644],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4480,  0.6099,  0.2764,  ..., -0.3440,  0.1493,  0.5127],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0569,  0.8213,  1.6846,  ...,  0.6406,  1.5820, -0.2310],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9629,  0.2856,  0.4607,  ...,  0.3252,  0.3994, -0.2297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:12:03 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:12:03 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 07:12:41 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 07:13:20 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 07:13:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0063,  0.0008, -0.0006,  ...,  0.0006, -0.0034,  0.0023],
        [ 0.0033, -0.0020,  0.0002,  ...,  0.0007,  0.0034, -0.0007],
        [ 0.0021, -0.0002, -0.0035,  ..., -0.0016, -0.0008,  0.0014],
        ...,
        [-0.0015,  0.0041,  0.0031,  ..., -0.0041,  0.0029,  0.0042],
        [-0.0004,  0.0012, -0.0020,  ...,  0.0009, -0.0022, -0.0010],
        [ 0.0005, -0.0005,  0.0010,  ..., -0.0012,  0.0047, -0.0034]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0963, -0.0003,  0.0005,  ..., -0.0209, -0.0035, -0.0079],
        [-0.0143, -0.0827, -0.0039,  ..., -0.0057, -0.0041,  0.0064],
        [-0.0002, -0.0133, -0.0645,  ...,  0.0125, -0.0131, -0.0060],
        ...,
        [-0.0104,  0.0067,  0.0019,  ..., -0.0846,  0.0068, -0.0014],
        [-0.0040,  0.0014, -0.0055,  ...,  0.0179, -0.0773, -0.0053],
        [ 0.0058,  0.0006, -0.0038,  ..., -0.0039,  0.0153, -0.0881]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.9539e-02,  1.6785e-03,  6.4163e-03,  ..., -4.7302e-03,
         -5.6381e-03, -6.8130e-03],
        [ 2.2583e-03, -8.0383e-02, -1.2909e-02,  ..., -1.7166e-05,
          4.1275e-03, -1.0048e-02],
        [ 3.4447e-03,  1.0452e-03, -8.3679e-02,  ...,  3.4065e-03,
         -1.0109e-04,  5.8899e-03],
        ...,
        [-3.5095e-03, -7.0190e-04,  2.6703e-04,  ..., -9.0027e-02,
          6.3477e-03,  2.0294e-03],
        [-1.2817e-03,  5.2986e-03,  1.1940e-03,  ...,  1.2421e-02,
         -8.2275e-02, -3.1319e-03],
        [-1.3161e-03, -4.5280e-03,  4.3488e-03,  ..., -9.7275e-04,
         -1.3466e-03, -7.9712e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:14:01 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 07:14:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2417,  0.3403,  0.9282,  ...,  0.3613,  0.8296, -0.3972],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.1221,  0.3594,  0.2164,  ...,  0.1700,  0.2096,  0.0687],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0466,  1.0293,  1.3330,  ...,  0.2705,  1.6758, -0.3755],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0068,  0.0603,  0.3179,  ..., -0.0186,  0.4048,  0.2356],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:14:01 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:14:01 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 07:14:36 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 07:15:18 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 07:16:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.9711e-03, -1.0643e-03,  3.3875e-03,  ...,  5.2977e-04,
         -1.8053e-03, -1.3962e-03],
        [ 9.7370e-04, -3.9139e-03,  2.5406e-03,  ..., -2.3727e-03,
          2.2686e-04, -7.6866e-04],
        [-4.0793e-04, -1.3866e-03,  9.5129e-05,  ..., -4.1962e-05,
         -2.4624e-03, -8.1158e-04],
        ...,
        [-4.2953e-03, -2.1229e-03,  1.8978e-03,  ..., -5.3024e-04,
          5.3167e-05, -7.1526e-04],
        [ 2.3117e-03,  2.4605e-04,  5.8937e-04,  ...,  6.0463e-04,
         -4.5738e-03, -2.7418e-04],
        [ 7.7209e-03,  1.7300e-03,  4.0483e-04,  ..., -1.6470e-03,
          2.1114e-03, -7.3433e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0674,  0.0021, -0.0009,  ..., -0.0016,  0.0106,  0.0010],
        [-0.0022, -0.1022,  0.0087,  ...,  0.0025,  0.0023,  0.0192],
        [-0.0011,  0.0084, -0.0732,  ...,  0.0009, -0.0015, -0.0070],
        ...,
        [-0.0044, -0.0021,  0.0026,  ..., -0.0872, -0.0079,  0.0030],
        [ 0.0126,  0.0158,  0.0080,  ..., -0.0026, -0.0779,  0.0178],
        [ 0.0042,  0.0104, -0.0059,  ..., -0.0078,  0.0021, -0.0986]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1389e-01,  6.6299e-03, -1.1292e-02,  ..., -2.4376e-03,
          1.1948e-02, -7.3700e-03],
        [ 5.4970e-03, -1.3708e-01,  9.9487e-03,  ..., -6.7863e-03,
         -4.8943e-03,  1.1139e-02],
        [-2.7008e-03, -2.9488e-03, -1.2817e-01,  ..., -7.8506e-03,
         -1.0330e-02,  5.5847e-03],
        ...,
        [ 2.3041e-03,  7.3547e-03, -1.3256e-03,  ..., -1.1279e-01,
         -6.0439e-05,  7.5607e-03],
        [-5.5695e-03,  6.4049e-03, -8.4534e-03,  ..., -3.2997e-03,
         -1.0754e-01,  3.8300e-03],
        [-1.3138e-02,  3.5706e-03, -1.2238e-02,  ...,  5.4855e-03,
          7.5912e-03, -1.2976e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:16:04 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 07:16:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0151,  0.5840,  1.0840,  ...,  0.3992,  1.0654, -0.1912],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8394,  0.2469,  0.3259,  ...,  0.2413,  0.3162, -0.2147],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4734,  1.3848,  1.5703,  ...,  0.4570,  1.8398, -0.5752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1738,  0.4719,  0.8984,  ...,  0.2888,  0.1509,  0.2439],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:16:05 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:16:05 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 07:16:51 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 07:17:38 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 07:18:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.8387e-03,  9.8133e-04,  2.7299e-05,  ..., -3.1338e-03,
         -4.1199e-03, -7.6294e-04],
        [ 2.0180e-03,  3.6335e-03, -3.0594e-03,  ..., -1.2660e-04,
         -1.3504e-03,  3.9101e-03],
        [-1.2102e-03, -1.1671e-04,  7.2823e-03,  ...,  1.3351e-04,
          4.2458e-03,  1.4820e-03],
        ...,
        [ 1.5526e-03, -2.7428e-03,  1.7719e-03,  ...,  4.9553e-03,
         -1.7757e-03,  9.7179e-04],
        [ 5.8413e-06,  2.0237e-03,  3.4275e-03,  ...,  1.8444e-03,
         -1.8473e-03, -7.5865e-04],
        [ 3.5248e-03,  3.1853e-04,  8.5831e-03,  ...,  2.1267e-03,
          7.4425e-03,  3.6812e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0908, -0.0139, -0.0051,  ..., -0.0081, -0.0056,  0.0094],
        [-0.0015, -0.0973, -0.0023,  ..., -0.0036,  0.0092, -0.0041],
        [-0.0065,  0.0032, -0.0978,  ...,  0.0164, -0.0062, -0.0130],
        ...,
        [-0.0188, -0.0020,  0.0129,  ..., -0.0914,  0.0051, -0.0041],
        [ 0.0036,  0.0129,  0.0170,  ...,  0.0090, -0.1013, -0.0019],
        [ 0.0122, -0.0062, -0.0048,  ..., -0.0114, -0.0002, -0.0831]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1727, -0.0013,  0.0079,  ..., -0.0012,  0.0014,  0.0027],
        [-0.0049, -0.1696, -0.0048,  ...,  0.0076,  0.0067,  0.0017],
        [-0.0081, -0.0060, -0.1504,  ...,  0.0071, -0.0070, -0.0085],
        ...,
        [-0.0050,  0.0231,  0.0048,  ..., -0.1703,  0.0004,  0.0045],
        [-0.0023,  0.0014,  0.0069,  ..., -0.0055, -0.1726, -0.0029],
        [ 0.0016,  0.0021,  0.0100,  ..., -0.0182, -0.0054, -0.1625]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:18:29 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 07:18:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0321,  0.6484,  0.7783,  ...,  0.1692,  1.0361, -0.2964],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8262,  0.0349,  0.2131,  ..., -0.0032,  0.3113,  0.1558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.0500, 2.0703, 1.8848,  ..., 0.5820, 1.8906, 0.1201], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7217,  0.2009,  0.6587,  ..., -0.0110,  0.1890,  0.3862],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:18:29 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:18:29 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 07:19:20 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 07:20:07 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 07:20:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.9340e-03,  2.6340e-03,  1.8044e-03,  ...,  3.4595e-04,
          4.6611e-04,  7.2861e-04],
        [ 3.2663e-04, -3.7613e-03,  7.3767e-04,  ..., -4.0889e-05,
          2.7418e-04, -3.5667e-04],
        [ 1.7128e-03, -1.5469e-03, -8.9951e-03,  ..., -2.0046e-03,
         -1.1778e-03, -1.5554e-03],
        ...,
        [ 3.6411e-03, -3.2120e-03,  1.6108e-03,  ..., -8.4076e-03,
         -2.1954e-03, -2.8152e-03],
        [-1.0118e-03, -3.8700e-03,  7.0691e-05,  ...,  1.5478e-03,
         -5.1613e-03,  2.2984e-03],
        [-2.0332e-03, -1.7929e-03, -1.3332e-03,  ...,  2.0561e-03,
         -5.8842e-04, -7.6599e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0881,  0.0184,  0.0023,  ...,  0.0037,  0.0061,  0.0016],
        [-0.0010, -0.0898,  0.0175,  ..., -0.0058,  0.0116, -0.0133],
        [ 0.0077, -0.0070, -0.0887,  ...,  0.0004, -0.0153, -0.0025],
        ...,
        [ 0.0187, -0.0131, -0.0101,  ..., -0.0947,  0.0101, -0.0227],
        [ 0.0110,  0.0008,  0.0008,  ...,  0.0075, -0.0864,  0.0028],
        [ 0.0021,  0.0107, -0.0135,  ..., -0.0029,  0.0120, -0.0901]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1014,  0.0025,  0.0028,  ...,  0.0069, -0.0007, -0.0007],
        [ 0.0133, -0.0990,  0.0012,  ..., -0.0079, -0.0219,  0.0066],
        [-0.0091,  0.0047, -0.1030,  ...,  0.0082, -0.0058,  0.0174],
        ...,
        [-0.0003, -0.0067,  0.0066,  ..., -0.0909,  0.0009,  0.0034],
        [ 0.0042, -0.0097, -0.0048,  ...,  0.0086, -0.1016, -0.0050],
        [ 0.0034,  0.0004,  0.0052,  ...,  0.0109, -0.0040, -0.1054]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:20:59 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 07:20:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3093,  0.8311,  0.8491,  ...,  0.2241,  1.0615, -0.3599],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9180,  0.3501,  0.6060,  ...,  0.1777,  0.0926,  0.1930],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6162,  2.3320,  1.0039,  ..., -0.2129,  2.0781,  0.8779],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9062,  0.2419,  0.7822,  ...,  0.2108,  0.2617,  0.3691],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:20:59 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:20:59 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 07:21:48 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 07:22:41 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 07:23:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.7515e-03, -3.5706e-03, -1.7118e-04,  ...,  2.9802e-04,
          1.5688e-03,  2.7847e-03],
        [-2.1763e-03,  5.3291e-03, -1.4210e-03,  ...,  2.5368e-03,
          1.3037e-03,  2.8729e-04],
        [-4.4346e-05, -1.3220e-04,  6.7902e-03,  ...,  8.1182e-05,
          2.6569e-03,  1.6332e-04],
        ...,
        [-2.8648e-03,  2.4986e-03,  4.1161e-03,  ...,  4.5395e-03,
         -3.6659e-03,  3.0727e-03],
        [-1.8387e-03, -1.9836e-03,  3.0303e-04,  ..., -2.7370e-04,
          8.7128e-03,  2.6073e-03],
        [ 8.7881e-04,  1.4429e-03,  6.1750e-04,  ..., -5.6791e-04,
         -8.9359e-04,  3.5458e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1571, -0.0037,  0.0078,  ..., -0.0062, -0.0041, -0.0039],
        [ 0.0014, -0.1570, -0.0096,  ..., -0.0149, -0.0110, -0.0061],
        [ 0.0037, -0.0189, -0.1578,  ..., -0.0120,  0.0012, -0.0221],
        ...,
        [-0.0262,  0.0140,  0.0139,  ..., -0.1603,  0.0074,  0.0099],
        [-0.0175,  0.0019,  0.0078,  ..., -0.0063, -0.1527, -0.0043],
        [ 0.0040, -0.0084, -0.0002,  ..., -0.0191, -0.0085, -0.1486]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2173,  0.0163,  0.0213,  ..., -0.0091, -0.0136, -0.0024],
        [-0.0016, -0.2375, -0.0146,  ..., -0.0056,  0.0096,  0.0024],
        [ 0.0025,  0.0071, -0.2203,  ...,  0.0015,  0.0030, -0.0177],
        ...,
        [-0.0022,  0.0019,  0.0007,  ..., -0.2581,  0.0038, -0.0081],
        [ 0.0033,  0.0015, -0.0094,  ...,  0.0113, -0.2245,  0.0044],
        [ 0.0036, -0.0150, -0.0033,  ..., -0.0080,  0.0004, -0.2258]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:23:37 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 07:23:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0047,  1.2295,  1.0195,  ...,  0.3315,  1.1084,  0.0135],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6265,  0.1512,  0.4651,  ..., -0.0135,  0.1449,  0.2732],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7339,  2.6758,  0.8223,  ...,  0.0283,  1.8604,  1.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4775,  1.1270,  1.4824,  ...,  0.0773,  0.2407,  0.9512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:23:37 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:23:37 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 07:24:33 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 07:25:22 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 07:25:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.5989e-03,  4.8561e-03,  1.4191e-03,  ...,  1.7891e-03,
         -1.4277e-03, -9.4795e-04],
        [-1.2283e-03, -3.6755e-03,  3.3045e-04,  ..., -2.8610e-03,
         -3.4428e-03, -1.6346e-03],
        [-4.0746e-04,  1.6909e-03, -3.1891e-03,  ..., -3.0193e-03,
         -3.9520e-03, -2.4891e-03],
        ...,
        [ 1.6079e-03, -3.4065e-03, -2.1992e-03,  ..., -5.9814e-03,
          4.4394e-04,  3.3188e-04],
        [ 2.3842e-05,  1.6747e-03, -8.2493e-04,  ..., -2.9144e-03,
         -5.9357e-03,  2.4199e-04],
        [ 2.0924e-03,  2.5730e-03,  6.4325e-04,  ..., -1.6022e-03,
          5.8985e-04, -6.3705e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.8125e-02,  7.0343e-03,  1.2283e-02,  ...,  7.6485e-03,
          8.1711e-03,  1.1311e-03],
        [ 7.6437e-04, -8.4290e-02,  4.9248e-03,  ..., -9.8343e-03,
         -3.2768e-03,  6.6719e-03],
        [-8.9417e-03,  4.7913e-03, -8.4106e-02,  ..., -5.0201e-03,
          3.2768e-03,  7.4883e-03],
        ...,
        [ 8.7738e-03, -2.2507e-03, -1.2083e-03,  ..., -7.0312e-02,
          6.4969e-05, -9.8419e-03],
        [-7.9269e-03,  2.2697e-03,  4.0512e-03,  ...,  1.2177e-02,
         -8.2947e-02,  1.5335e-02],
        [-1.4069e-02,  4.3259e-03,  7.4883e-03,  ..., -8.5754e-03,
          7.0152e-03, -7.2449e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0750, -0.0024,  0.0074,  ..., -0.0032,  0.0033,  0.0045],
        [ 0.0012, -0.0735, -0.0126,  ...,  0.0052,  0.0172,  0.0008],
        [-0.0064,  0.0055, -0.0785,  ..., -0.0059, -0.0095,  0.0084],
        ...,
        [-0.0036, -0.0083, -0.0063,  ..., -0.0659,  0.0098,  0.0005],
        [-0.0053,  0.0048,  0.0001,  ...,  0.0014, -0.0792,  0.0084],
        [ 0.0045,  0.0058,  0.0007,  ...,  0.0045,  0.0093, -0.0731]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:25:59 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 07:25:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3733,  1.3076,  0.5312,  ..., -0.1439,  1.1826,  0.4836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6816,  0.1422,  0.5327,  ...,  0.1287,  0.1938,  0.2520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.4043,  2.6270, -0.1816,  ...,  0.4089,  1.7969,  1.3955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.7363,  0.4482,  0.7217,  ...,  0.5537,  1.5254,  1.2598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:25:59 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:25:59 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 07:26:58 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 07:27:56 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 07:28:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0083,  0.0056, -0.0025,  ..., -0.0002,  0.0004, -0.0063],
        [-0.0094,  0.0074, -0.0030,  ...,  0.0036, -0.0022, -0.0045],
        [-0.0049, -0.0040, -0.0060,  ..., -0.0030, -0.0007, -0.0048],
        ...,
        [-0.0013,  0.0011,  0.0025,  ...,  0.0044, -0.0018,  0.0060],
        [ 0.0036,  0.0015,  0.0042,  ...,  0.0010, -0.0130, -0.0019],
        [ 0.0006,  0.0116,  0.0011,  ..., -0.0072, -0.0040, -0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1042,  0.0075, -0.0063,  ..., -0.0089, -0.0019,  0.0198],
        [-0.0166, -0.1065,  0.0029,  ...,  0.0069, -0.0026,  0.0051],
        [-0.0045,  0.0052, -0.0867,  ...,  0.0080, -0.0019, -0.0006],
        ...,
        [-0.0071, -0.0034,  0.0014,  ..., -0.1003, -0.0068,  0.0071],
        [-0.0019,  0.0129, -0.0033,  ...,  0.0121, -0.1113,  0.0004],
        [ 0.0121, -0.0047, -0.0056,  ..., -0.0109,  0.0051, -0.0785]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1399,  0.0033,  0.0063,  ..., -0.0055,  0.0093,  0.0148],
        [-0.0221, -0.1537,  0.0011,  ...,  0.0012, -0.0010,  0.0193],
        [ 0.0107,  0.0010, -0.1461,  ..., -0.0035, -0.0042, -0.0031],
        ...,
        [-0.0112, -0.0017, -0.0053,  ..., -0.1503, -0.0026,  0.0041],
        [ 0.0157,  0.0154, -0.0004,  ...,  0.0102, -0.1576,  0.0174],
        [ 0.0008, -0.0005,  0.0119,  ..., -0.0048,  0.0170, -0.1559]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:28:58 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 07:28:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4182,  1.3555,  0.3691,  ..., -0.0088,  0.9897,  0.5591],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8984,  0.6406,  0.7935,  ...,  0.0296,  0.1722,  0.5122],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6167,  2.6348,  0.1052,  ...,  0.4648,  1.7168,  1.9121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9570,  0.0144,  0.8623,  ..., -0.1504,  0.5479,  0.9761],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:28:58 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:28:58 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 07:30:00 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 07:30:59 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 07:31:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.6184e-03,  1.1568e-03,  2.6398e-03,  ..., -4.9934e-03,
         -1.1482e-02,  3.9177e-03],
        [-4.7035e-03,  5.8174e-03, -5.0125e-03,  ...,  1.5438e-04,
          1.3847e-03, -1.7490e-03],
        [-9.3689e-03, -1.4076e-03,  9.3460e-03,  ..., -8.3780e-04,
         -3.1929e-03,  5.9128e-03],
        ...,
        [ 8.8043e-03, -3.2043e-03, -9.0332e-03,  ...,  1.4122e-02,
         -1.6556e-03, -5.7678e-03],
        [-4.5955e-05, -4.3106e-03,  2.7962e-03,  ...,  3.2768e-03,
          8.3923e-03,  3.1033e-03],
        [ 5.9280e-03,  1.9112e-03, -8.5983e-03,  ...,  9.7811e-05,
          4.5891e-03,  3.2291e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0879,  0.0055, -0.0006,  ...,  0.0041, -0.0035,  0.0023],
        [ 0.0181, -0.0947, -0.0047,  ...,  0.0047,  0.0088, -0.0085],
        [-0.0089, -0.0088, -0.0948,  ..., -0.0069,  0.0053, -0.0105],
        ...,
        [ 0.0020, -0.0011, -0.0089,  ..., -0.0706,  0.0247,  0.0011],
        [-0.0123,  0.0071, -0.0033,  ..., -0.0009, -0.0740, -0.0030],
        [ 0.0094,  0.0051,  0.0053,  ...,  0.0055, -0.0121, -0.1011]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2537e-01, -2.0809e-03, -9.4986e-03,  ..., -1.7822e-02,
         -1.8616e-03, -6.0310e-03],
        [-8.0109e-05, -1.1340e-01, -4.4670e-03,  ...,  1.3863e-02,
          9.2926e-03,  1.2512e-02],
        [ 5.7220e-06, -1.5686e-02, -1.1169e-01,  ...,  9.3155e-03,
          2.4147e-03, -1.4053e-02],
        ...,
        [-1.0391e-02, -1.0086e-02,  6.3553e-03,  ..., -1.2585e-01,
          1.4389e-02, -6.0654e-04],
        [-4.1466e-03,  6.6071e-03, -1.2726e-02,  ...,  9.5444e-03,
         -1.1487e-01,  6.4659e-03],
        [-1.2703e-02,  3.6087e-03, -1.9531e-03,  ..., -1.5106e-02,
          9.0866e-03, -1.0370e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:32:02 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 07:32:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7109,  1.2422, -0.0884,  ...,  0.1753,  0.8608,  0.6450],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0107,  0.2238,  0.3901,  ...,  0.2944,  0.8594,  0.6880],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.9736,  2.9434,  0.2399,  ...,  1.0020,  1.7578,  1.6943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.5938,  0.4045, -0.0527,  ...,  0.8335, -0.2314,  1.2207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:32:02 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:32:02 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 07:33:06 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 07:34:09 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 07:35:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1253e-03,  3.5210e-03,  9.8896e-04,  ...,  3.1734e-04,
         -2.1350e-04,  3.5114e-03],
        [ 5.4283e-03,  2.3022e-03,  6.4278e-04,  ..., -1.6079e-03,
          5.3024e-04, -4.5853e-03],
        [ 5.3048e-05,  1.6060e-03,  1.8425e-03,  ...,  1.4007e-05,
         -3.1900e-04,  1.3132e-03],
        ...,
        [ 1.2951e-03, -2.0866e-03,  3.0470e-04,  ..., -5.1403e-04,
         -1.7262e-03, -2.2659e-03],
        [ 4.5319e-03, -1.3876e-03,  2.0943e-03,  ..., -3.1257e-04,
          3.7956e-03,  3.2806e-03],
        [ 7.5912e-04,  2.4776e-03,  1.6251e-03,  ...,  8.7690e-04,
          1.4267e-03,  4.7379e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.5703e-02, -1.3304e-04, -1.8311e-02,  ..., -9.5901e-03,
          4.2725e-03,  5.5313e-05],
        [-8.5678e-03, -1.0260e-01,  8.5373e-03,  ...,  4.6501e-03,
         -8.7891e-03,  1.4992e-03],
        [-6.2408e-03,  4.0855e-03, -8.2642e-02,  ...,  7.6218e-03,
         -2.6340e-03, -1.4524e-03],
        ...,
        [ 2.4185e-03,  1.5869e-02, -1.3359e-02,  ..., -9.5276e-02,
          8.6746e-03, -3.7498e-03],
        [ 1.3336e-02, -7.0267e-03, -5.2528e-03,  ..., -4.2686e-03,
         -1.0156e-01, -8.5297e-03],
        [-4.1580e-03, -2.9993e-04, -7.7896e-03,  ...,  6.6376e-04,
          5.9128e-03, -9.3506e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0980e-01, -4.0770e-04, -1.0925e-02,  ..., -2.2202e-03,
         -8.7433e-03,  1.3702e-02],
        [ 8.2855e-03, -1.3831e-01, -6.1989e-03,  ...,  3.8624e-03,
          3.2253e-03, -1.2360e-02],
        [-4.3983e-03, -5.0583e-03, -1.2549e-01,  ..., -6.5269e-03,
         -8.6021e-04,  1.4816e-02],
        ...,
        [ 1.0674e-02,  8.3923e-03, -2.4757e-03,  ..., -1.1383e-01,
          5.0783e-05, -1.9196e-02],
        [ 6.1150e-03, -3.4142e-03, -1.8520e-03,  ...,  1.0414e-02,
         -1.3318e-01,  4.1618e-03],
        [ 1.3641e-02,  6.2828e-03, -7.0572e-04,  ..., -2.3697e-02,
          1.9287e-02, -1.2976e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:35:13 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 07:35:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3528,  1.2920,  0.0240,  ...,  0.2129,  0.8232,  0.9014],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5732,  0.0126,  0.4299,  ..., -0.0815,  0.3032,  0.5132],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6011,  2.8281,  0.5806,  ...,  1.3408,  1.2373,  2.0859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4150,  0.3696,  0.0237,  ...,  0.8467, -0.0360,  0.6406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:35:13 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:35:13 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 07:36:17 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 07:37:23 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 07:38:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0083, -0.0080, -0.0086,  ..., -0.0071,  0.0036,  0.0015],
        [ 0.0002, -0.0023, -0.0031,  ...,  0.0013, -0.0021,  0.0022],
        [-0.0023, -0.0039, -0.0165,  ..., -0.0077, -0.0061,  0.0039],
        ...,
        [ 0.0041,  0.0037, -0.0054,  ..., -0.0072, -0.0045, -0.0007],
        [ 0.0035,  0.0002,  0.0028,  ...,  0.0015, -0.0119, -0.0022],
        [-0.0056,  0.0041, -0.0033,  ..., -0.0042,  0.0020, -0.0150]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0568,  0.0074,  0.0111,  ..., -0.0179,  0.0001, -0.0185],
        [ 0.0027, -0.0685, -0.0122,  ..., -0.0032,  0.0055, -0.0003],
        [ 0.0126, -0.0042, -0.0562,  ..., -0.0094, -0.0044, -0.0007],
        ...,
        [-0.0090, -0.0022, -0.0012,  ..., -0.0482, -0.0024, -0.0116],
        [-0.0156,  0.0116,  0.0069,  ...,  0.0137, -0.0425,  0.0042],
        [ 0.0035, -0.0031,  0.0120,  ..., -0.0041, -0.0101, -0.0601]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0790,  0.0096,  0.0021,  ..., -0.0142,  0.0093, -0.0018],
        [-0.0010, -0.0927,  0.0019,  ...,  0.0062,  0.0135,  0.0045],
        [ 0.0134, -0.0012, -0.0862,  ...,  0.0043, -0.0235, -0.0115],
        ...,
        [-0.0222, -0.0079,  0.0044,  ..., -0.0846, -0.0017,  0.0002],
        [ 0.0087,  0.0204, -0.0036,  ...,  0.0022, -0.0902,  0.0110],
        [ 0.0011,  0.0043,  0.0030,  ...,  0.0020, -0.0153, -0.0868]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:38:30 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 07:38:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4739,  1.3525,  0.1005,  ...,  0.4331,  0.8091,  0.7314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8110,  0.1984, -0.0222,  ...,  0.3940, -0.0998,  0.5649],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4033,  2.7988,  0.7158,  ...,  1.1289,  0.4341,  2.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9873,  0.6533, -0.3188,  ...,  0.5527, -0.6729,  0.6152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:38:30 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:38:30 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 07:39:34 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 07:40:43 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 07:41:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0064, -0.0074,  0.0010,  ...,  0.0042, -0.0022,  0.0002],
        [-0.0001, -0.0039, -0.0065,  ..., -0.0013,  0.0081, -0.0013],
        [ 0.0034,  0.0009, -0.0101,  ...,  0.0012, -0.0024,  0.0051],
        ...,
        [ 0.0004, -0.0046, -0.0029,  ..., -0.0075,  0.0020, -0.0052],
        [ 0.0028,  0.0096,  0.0049,  ..., -0.0026, -0.0104, -0.0025],
        [ 0.0066,  0.0038, -0.0057,  ...,  0.0011,  0.0011, -0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0538,  0.0022,  0.0145,  ..., -0.0004,  0.0213, -0.0005],
        [ 0.0010, -0.0645,  0.0092,  ...,  0.0054,  0.0143, -0.0107],
        [ 0.0047,  0.0060, -0.0636,  ..., -0.0155,  0.0241,  0.0073],
        ...,
        [ 0.0028, -0.0044,  0.0037,  ..., -0.0792,  0.0147, -0.0085],
        [ 0.0058,  0.0019,  0.0012,  ...,  0.0038, -0.0757, -0.0057],
        [-0.0157,  0.0155,  0.0128,  ...,  0.0037,  0.0038, -0.0526]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0646, -0.0116, -0.0125,  ..., -0.0124,  0.0014,  0.0003],
        [-0.0051, -0.0801, -0.0133,  ..., -0.0001, -0.0039,  0.0044],
        [ 0.0020, -0.0085, -0.0920,  ..., -0.0040,  0.0107,  0.0029],
        ...,
        [ 0.0031, -0.0048,  0.0183,  ..., -0.0557,  0.0141, -0.0099],
        [ 0.0055,  0.0048, -0.0049,  ...,  0.0125, -0.0936,  0.0009],
        [-0.0188,  0.0037,  0.0010,  ..., -0.0098,  0.0086, -0.0853]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:41:50 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 07:41:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2864,  1.2158,  0.2261,  ...,  0.5649,  0.5410,  0.8696],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-7.1289e-01,  1.8506e-01, -8.3327e-05,  ...,  4.0527e-01,
        -1.1688e-02,  2.7368e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7070,  3.5586,  0.5718,  ...,  0.9565,  0.1394,  3.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.3340,  1.6328, -1.0166,  ...,  0.5273, -0.1123,  0.5864],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:41:50 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:41:50 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 07:42:59 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 07:44:10 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 07:45:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0142, -0.0033,  0.0024,  ..., -0.0035,  0.0042, -0.0010],
        [-0.0048, -0.0045, -0.0027,  ..., -0.0038,  0.0026, -0.0117],
        [-0.0059, -0.0084, -0.0056,  ...,  0.0138, -0.0012,  0.0006],
        ...,
        [ 0.0066,  0.0023, -0.0088,  ..., -0.0099,  0.0029, -0.0076],
        [ 0.0044,  0.0021,  0.0055,  ...,  0.0026, -0.0060,  0.0073],
        [-0.0051,  0.0003, -0.0021,  ...,  0.0072, -0.0088, -0.0146]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.6895e-02, -2.6951e-03, -9.7198e-03,  ...,  4.8637e-05,
          1.7271e-03, -2.2984e-03],
        [ 1.4000e-02, -5.5634e-02, -8.5220e-03,  ..., -5.0259e-04,
         -6.8321e-03,  2.5711e-03],
        [-1.1627e-02,  6.4621e-03, -6.3843e-02,  ..., -9.6893e-04,
          6.0272e-04, -1.7960e-02],
        ...,
        [ 2.2888e-04, -9.9106e-03,  3.9253e-03,  ..., -5.4901e-02,
         -8.2703e-03,  7.6065e-03],
        [-6.1417e-03,  3.0460e-03, -2.3632e-03,  ...,  1.4618e-02,
         -5.8075e-02,  8.0109e-03],
        [ 2.4300e-03,  1.3733e-04,  3.0746e-03,  ...,  8.7929e-04,
          8.8501e-03, -7.1289e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0731, -0.0004,  0.0165,  ...,  0.0065,  0.0060,  0.0109],
        [ 0.0143, -0.0872,  0.0045,  ..., -0.0018,  0.0011,  0.0238],
        [-0.0008, -0.0106, -0.0738,  ..., -0.0168, -0.0097, -0.0162],
        ...,
        [ 0.0080,  0.0080, -0.0168,  ..., -0.0844, -0.0067, -0.0013],
        [ 0.0040, -0.0123, -0.0099,  ..., -0.0243, -0.0749, -0.0071],
        [-0.0015,  0.0079, -0.0018,  ..., -0.0009, -0.0058, -0.0756]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:45:23 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 07:45:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1838,  1.1660,  0.2651,  ...,  0.4600,  0.2003,  1.0107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4509,  0.2852, -0.1560,  ...,  0.2395, -0.2739,  0.2346],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.1606, 3.5566, 0.0488,  ..., 0.9805, 0.3740, 2.8418], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.6035,  0.1816, -1.8955,  ..., -0.3682,  1.2002,  0.7754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:45:23 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:45:23 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 07:46:32 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 07:47:43 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 07:48:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0145, -0.0038, -0.0032,  ..., -0.0008, -0.0013, -0.0127],
        [ 0.0094,  0.0005,  0.0019,  ..., -0.0006,  0.0015,  0.0052],
        [ 0.0083, -0.0023, -0.0125,  ..., -0.0020,  0.0010,  0.0081],
        ...,
        [-0.0082, -0.0128,  0.0004,  ..., -0.0013, -0.0055,  0.0057],
        [-0.0020, -0.0021,  0.0077,  ...,  0.0005, -0.0061, -0.0044],
        [ 0.0054,  0.0070, -0.0043,  ..., -0.0035, -0.0056,  0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0201,  0.0044, -0.0043,  ..., -0.0084, -0.0016, -0.0120],
        [-0.0027, -0.0339, -0.0006,  ...,  0.0055, -0.0012, -0.0059],
        [-0.0056, -0.0031, -0.0301,  ...,  0.0061,  0.0050, -0.0021],
        ...,
        [-0.0140, -0.0028, -0.0020,  ..., -0.0407,  0.0150,  0.0037],
        [ 0.0055,  0.0181, -0.0190,  ..., -0.0090, -0.0418,  0.0195],
        [-0.0137, -0.0072, -0.0037,  ...,  0.0070,  0.0070, -0.0428]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0458,  0.0017,  0.0095,  ..., -0.0176, -0.0018,  0.0211],
        [-0.0123, -0.0353, -0.0280,  ..., -0.0042,  0.0148, -0.0080],
        [ 0.0133, -0.0269, -0.0692,  ..., -0.0153,  0.0038, -0.0139],
        ...,
        [-0.0153,  0.0033, -0.0020,  ..., -0.0649,  0.0010, -0.0035],
        [ 0.0037,  0.0022, -0.0038,  ...,  0.0075, -0.0488,  0.0330],
        [ 0.0020,  0.0079,  0.0055,  ...,  0.0002,  0.0138, -0.0486]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:48:56 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 07:48:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2993,  1.4434,  0.1998,  ...,  0.3823,  0.0464,  1.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5317,  0.6353, -0.3989,  ...,  0.2085, -0.0459,  0.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5493,  3.8125, -0.1333,  ...,  1.0420,  0.7339,  2.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6206,  0.4731, -1.3105,  ...,  0.1475,  1.6895,  0.9287],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:48:57 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:48:57 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 07:50:06 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 07:51:10 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 07:52:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.7351e-03, -2.3594e-03, -1.6584e-03,  ...,  2.3899e-03,
         -5.0011e-03,  4.5891e-03],
        [ 4.2496e-03,  5.4512e-03, -4.4594e-03,  ...,  1.1505e-02,
         -5.8212e-03, -1.0666e-02],
        [ 1.2617e-03,  5.1916e-05,  2.8076e-03,  ...,  7.1526e-07,
          1.7376e-03,  3.7041e-03],
        ...,
        [-5.5695e-03,  2.2850e-03,  3.4409e-03,  ..., -6.1951e-03,
         -1.1129e-03,  5.1880e-03],
        [-1.3075e-03, -4.3526e-03,  7.6294e-04,  ...,  8.2064e-04,
          3.4084e-03, -1.0796e-03],
        [-9.4116e-05, -6.4659e-03, -4.5624e-03,  ...,  1.7586e-03,
          1.3189e-03,  3.7270e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.3102e-02, -5.1975e-05, -1.8402e-02,  ..., -7.0229e-03,
         -4.7035e-03, -8.7280e-03],
        [ 2.0111e-02, -2.4551e-02,  5.2109e-03,  ..., -3.2005e-03,
          1.3418e-03,  2.7351e-03],
        [-2.7504e-03,  4.7760e-03, -3.2806e-02,  ..., -1.7929e-02,
         -1.3323e-03, -1.2527e-02],
        ...,
        [ 6.9733e-03, -1.3542e-03, -1.4145e-02,  ..., -1.0231e-02,
          2.8343e-03, -1.2703e-03],
        [-1.1358e-03, -3.1281e-03, -9.0103e-03,  ...,  8.1177e-03,
         -1.6907e-02,  5.0888e-03],
        [-1.7939e-03,  1.2550e-03,  2.6245e-03,  ..., -1.5060e-02,
          6.0463e-04, -2.6138e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.5634e-02,  1.4542e-02,  1.1185e-02,  ...,  6.2256e-03,
          5.5075e-04, -7.0381e-03],
        [ 2.8931e-02, -6.9458e-02,  8.5831e-06,  ..., -3.1738e-03,
         -1.9493e-03,  1.4580e-02],
        [ 4.0207e-03, -1.8692e-02, -5.2551e-02,  ..., -3.5629e-03,
         -1.2512e-02,  3.7231e-03],
        ...,
        [-4.6635e-04, -7.4387e-04, -3.4882e-02,  ..., -5.0659e-02,
         -1.2337e-02, -4.9057e-03],
        [ 3.4027e-03,  7.4158e-03,  2.9526e-03,  ..., -1.2482e-02,
         -5.0354e-02, -2.0199e-03],
        [-1.3214e-02, -8.7738e-03, -6.6719e-03,  ..., -2.2552e-02,
          2.8210e-03, -6.1157e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:52:20 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 07:52:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.0564, 1.3555, 0.0043,  ..., 0.3574, 0.1467, 1.0674], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6260,  0.0621, -0.7354,  ..., -0.1528,  0.4731,  0.2786],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4873,  3.3105,  0.0417,  ...,  0.8452,  0.8647,  2.8027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6992,  0.4700, -0.7788,  ...,  0.1709,  1.8525,  0.6094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:52:20 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:52:20 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 07:53:34 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 07:54:50 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 07:56:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.3293e-04, -1.5116e-03, -1.2369e-03,  ..., -4.8232e-04,
         -1.9817e-03,  3.3779e-03],
        [-1.0405e-03, -1.1339e-03, -5.5599e-04,  ...,  9.5940e-04,
          1.4753e-03,  3.6502e-04],
        [-1.8091e-03,  1.4620e-03,  2.9697e-03,  ..., -7.0763e-04,
         -2.2297e-03,  1.2074e-03],
        ...,
        [ 1.0014e-03,  3.2673e-03, -4.2953e-03,  ...,  3.2616e-03,
         -1.9610e-05, -1.2646e-03],
        [-7.1373e-03,  4.1389e-03,  1.9741e-03,  ...,  1.0910e-03,
          1.1188e-04,  2.0542e-03],
        [-2.8019e-03, -8.8406e-04,  2.0790e-03,  ..., -1.4734e-03,
          5.0125e-03,  1.9817e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.4099e-02, -1.7996e-03, -9.4604e-03,  ..., -3.3379e-03,
          1.3992e-02, -5.1155e-03],
        [-1.2115e-02, -3.6560e-02, -1.5045e-02,  ..., -2.4509e-03,
          1.6266e-02,  8.7585e-03],
        [ 1.4771e-02,  1.1627e-02, -2.3254e-02,  ..., -3.8891e-03,
          9.3842e-03, -1.9714e-02],
        ...,
        [ 5.1308e-03, -7.3910e-06,  6.6910e-03,  ..., -2.2339e-02,
          6.7978e-03,  3.9864e-03],
        [-8.0566e-03, -1.2825e-02,  5.4646e-04,  ..., -8.3771e-03,
         -1.6373e-02, -1.0101e-02],
        [-1.3290e-02,  1.2016e-04, -4.3793e-03,  ..., -6.6261e-03,
          3.7651e-03, -1.5320e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.0852e-02,  1.9119e-02, -5.9052e-03,  ...,  7.2365e-03,
         -1.0338e-02, -2.3251e-03],
        [ 2.0828e-03, -7.6965e-02, -2.3376e-02,  ..., -1.9547e-02,
         -1.0086e-02, -5.7364e-04],
        [ 9.3002e-03,  4.0894e-03, -3.5614e-02,  ...,  1.1711e-03,
         -4.1885e-03, -1.3557e-02],
        ...,
        [ 3.6526e-03,  2.3289e-03, -1.6575e-03,  ..., -6.0944e-02,
          2.2278e-02, -1.2672e-02],
        [-1.9165e-02, -3.1219e-02,  1.2169e-02,  ...,  5.4836e-05,
         -7.2571e-02,  1.0353e-02],
        [-5.3711e-03,  4.7798e-03, -2.6093e-03,  ...,  2.0447e-03,
          2.5616e-03, -5.5756e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 07:56:07 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 07:56:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2170,  1.4043, -0.0654,  ...,  0.3879,  0.2864,  0.9927],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2454,  0.1792, -0.5093,  ...,  0.0634,  0.6748,  0.3413],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4243,  3.0195,  0.3623,  ...,  0.8496,  0.7637,  3.2402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7637,  0.1819, -0.6685,  ...,  0.3540,  1.7246,  1.1846],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 07:56:07 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 07:56:07 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 07:57:24 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 07:58:40 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 07:59:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.1362e-04, -1.0023e-03,  1.8358e-05,  ..., -9.6977e-05,
         -1.7071e-03, -5.4312e-04],
        [ 5.1165e-04,  4.6206e-04,  2.2185e-04,  ...,  3.5226e-05,
         -8.3160e-04, -1.2350e-03],
        [ 1.9372e-04,  7.4291e-04,  1.2362e-04,  ..., -5.0974e-04,
          3.7742e-04,  6.5684e-05],
        ...,
        [-1.9302e-03, -1.9538e-04,  7.0989e-05,  ..., -1.0452e-03,
          1.3609e-03,  1.1387e-03],
        [ 1.5807e-04, -1.0085e-04,  6.2704e-04,  ..., -3.8600e-04,
         -4.7207e-04,  1.5759e-04],
        [-3.4285e-04, -3.1996e-04,  4.4823e-04,  ...,  4.0126e-04,
          5.0926e-04,  3.2616e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0065,  0.0069, -0.0005,  ..., -0.0024, -0.0038,  0.0134],
        [-0.0090, -0.0154,  0.0059,  ..., -0.0041, -0.0048,  0.0002],
        [-0.0038, -0.0032, -0.0060,  ..., -0.0110,  0.0077, -0.0022],
        ...,
        [ 0.0105,  0.0100, -0.0101,  ..., -0.0109,  0.0025,  0.0002],
        [ 0.0011,  0.0033,  0.0028,  ...,  0.0123, -0.0232,  0.0132],
        [-0.0082, -0.0122,  0.0014,  ...,  0.0106,  0.0037, -0.0219]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0518, -0.0052,  0.0020,  ..., -0.0109, -0.0135,  0.0141],
        [-0.0060, -0.0439, -0.0066,  ..., -0.0038,  0.0161, -0.0016],
        [ 0.0023, -0.0036, -0.0505,  ..., -0.0105,  0.0047,  0.0100],
        ...,
        [-0.0030,  0.0125,  0.0058,  ..., -0.0421,  0.0124,  0.0039],
        [ 0.0089,  0.0007, -0.0080,  ..., -0.0210, -0.0521,  0.0023],
        [ 0.0048,  0.0178, -0.0090,  ...,  0.0023,  0.0038, -0.0675]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:00:01 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 08:00:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1750,  1.1758, -0.0132,  ...,  0.3032,  0.3318,  1.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2583,  0.1759, -0.3101,  ...,  0.0702,  0.7241,  0.2050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4993,  3.6172, -0.0151,  ...,  1.0449,  0.7002,  3.1152],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.7520, -0.4773, -0.3164,  ...,  1.0703,  1.3037,  1.4834],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:00:01 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 08:00:01 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 08:01:21 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 08:02:43 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 08:04:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.5095e-03, -2.4939e-04, -8.7786e-04,  ..., -8.2970e-04,
         -1.7462e-03, -2.0103e-03],
        [-2.6817e-03,  3.6278e-03,  2.3518e-03,  ...,  2.2411e-03,
          7.5221e-05,  5.5122e-03],
        [ 1.0452e-03,  1.7891e-03,  6.0768e-03,  ..., -5.2357e-04,
         -2.8419e-04, -7.6199e-04],
        ...,
        [-2.3727e-03, -1.0815e-03,  1.4610e-03,  ...,  4.0817e-03,
         -1.2808e-03, -2.9621e-03],
        [-3.2568e-04, -8.1444e-04, -4.5347e-04,  ...,  4.9686e-04,
          4.3526e-03,  4.6120e-03],
        [-1.7405e-03,  1.3847e-03,  2.2507e-03,  ...,  1.2779e-04,
          2.6894e-03,  4.9324e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0266, -0.0122, -0.0200,  ..., -0.0129,  0.0123, -0.0067],
        [ 0.0074, -0.0175,  0.0111,  ...,  0.0100,  0.0030, -0.0033],
        [ 0.0206, -0.0068, -0.0120,  ...,  0.0015, -0.0056, -0.0035],
        ...,
        [-0.0152,  0.0093, -0.0016,  ...,  0.0065, -0.0202, -0.0033],
        [ 0.0027,  0.0112, -0.0157,  ..., -0.0006, -0.0155,  0.0120],
        [-0.0070,  0.0090,  0.0092,  ..., -0.0045,  0.0097, -0.0126]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0576,  0.0023, -0.0142,  ..., -0.0192,  0.0191,  0.0130],
        [-0.0160, -0.0620,  0.0116,  ..., -0.0049, -0.0268,  0.0013],
        [ 0.0105, -0.0261, -0.0647,  ..., -0.0036, -0.0114,  0.0104],
        ...,
        [ 0.0268, -0.0073, -0.0150,  ..., -0.0775, -0.0004, -0.0104],
        [ 0.0132, -0.0006, -0.0130,  ...,  0.0135, -0.0970,  0.0173],
        [-0.0086,  0.0043, -0.0015,  ..., -0.0068,  0.0025, -0.0721]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:04:06 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 08:04:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1504,  1.0469,  0.0751,  ...,  0.2808,  0.2781,  1.1299],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2742,  0.0909, -0.2861,  ...,  0.1187,  0.6431,  0.4099],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8115,  3.3945,  0.6396,  ...,  0.7949,  0.6826,  3.3398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.9551, -0.6338, -0.4526,  ...,  1.8242,  2.0371,  2.9082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:04:06 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 08:04:06 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 08:05:28 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 08:06:51 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 08:08:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.5539e-03, -1.3113e-04,  2.1553e-04,  ...,  6.0368e-04,
          4.5133e-04,  1.3866e-03],
        [ 1.3053e-04,  2.0885e-03,  5.6839e-04,  ..., -1.0309e-03,
         -5.3787e-04, -6.0916e-05],
        [ 9.6893e-04,  6.7425e-04,  2.9564e-03,  ..., -1.6356e-03,
          7.3576e-04,  7.2050e-04],
        ...,
        [-3.3331e-04, -1.7786e-04, -4.8339e-05,  ...,  3.8013e-03,
         -6.9141e-04, -1.0052e-03],
        [-1.1530e-03,  1.4477e-03,  1.4868e-03,  ..., -8.9693e-04,
          4.4823e-03,  8.3590e-04],
        [-3.8385e-05, -1.5306e-03, -1.3895e-03,  ...,  1.7328e-03,
          8.5211e-04,  4.2152e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0358, -0.0067, -0.0027,  ...,  0.0043,  0.0017, -0.0020],
        [ 0.0016,  0.0037, -0.0134,  ...,  0.0203, -0.0035,  0.0079],
        [ 0.0039,  0.0020,  0.0296,  ..., -0.0011,  0.0042, -0.0100],
        ...,
        [-0.0096, -0.0036, -0.0127,  ...,  0.0452,  0.0062,  0.0010],
        [-0.0028, -0.0060,  0.0055,  ...,  0.0016,  0.0239,  0.0125],
        [-0.0061,  0.0006, -0.0035,  ..., -0.0048,  0.0166,  0.0299]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0054, -0.0273,  0.0029,  ..., -0.0028, -0.0009,  0.0051],
        [ 0.0058, -0.0434,  0.0086,  ..., -0.0122, -0.0178,  0.0235],
        [ 0.0216, -0.0013,  0.0496,  ...,  0.0091,  0.0053, -0.0075],
        ...,
        [-0.0238, -0.0036, -0.0156,  ...,  0.0356,  0.0065, -0.0141],
        [-0.0181,  0.0067, -0.0191,  ...,  0.0176,  0.0245, -0.0117],
        [-0.0114,  0.0160, -0.0126,  ...,  0.0010,  0.0121,  0.0103]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:08:16 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 08:08:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1467,  1.1738, -0.0652,  ...,  0.3035,  0.2262,  1.0186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5942, -0.1361, -0.1669,  ...,  0.3359,  0.4553,  0.4946],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7334,  4.5195,  1.2227,  ...,  0.6826,  0.9482,  3.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.9688, -0.7920,  0.0059,  ...,  1.9160,  1.3867,  3.8438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:08:16 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 08:08:16 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 08:09:40 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 08:11:07 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 08:12:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5116e-04,  1.5795e-04, -1.2082e-04,  ..., -4.5443e-04,
          7.9811e-05,  4.7541e-04],
        [-1.2941e-03,  1.8406e-04,  1.6203e-03,  ..., -5.2786e-04,
          2.9111e-04,  8.5688e-04],
        [-1.9312e-03,  3.0637e-04,  6.3944e-04,  ..., -3.9291e-04,
          1.6508e-03,  5.9462e-04],
        ...,
        [-4.7946e-04, -8.5878e-04, -6.9332e-04,  ...,  4.0388e-04,
          9.4652e-04,  1.2720e-04],
        [ 5.5790e-04, -4.7421e-04, -6.6519e-04,  ..., -8.1778e-04,
         -9.9945e-04, -7.8487e-04],
        [ 8.5235e-06, -7.2145e-04,  9.1600e-04,  ..., -4.9686e-04,
          3.6573e-04,  4.8971e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0192,  0.0012,  0.0040,  ..., -0.0014,  0.0136,  0.0065],
        [ 0.0005, -0.0288,  0.0122,  ...,  0.0179, -0.0148,  0.0042],
        [-0.0166,  0.0058, -0.0044,  ...,  0.0020, -0.0094,  0.0040],
        ...,
        [-0.0033,  0.0117, -0.0056,  ...,  0.0032,  0.0057,  0.0054],
        [ 0.0114,  0.0114,  0.0030,  ..., -0.0105,  0.0053,  0.0095],
        [-0.0044,  0.0021, -0.0059,  ..., -0.0083,  0.0056, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0604, -0.0060,  0.0099,  ..., -0.0057,  0.0180, -0.0059],
        [-0.0121, -0.0418, -0.0053,  ...,  0.0327,  0.0054, -0.0015],
        [ 0.0062,  0.0108, -0.0284,  ...,  0.0043,  0.0026, -0.0112],
        ...,
        [-0.0347, -0.0151, -0.0039,  ..., -0.0573, -0.0039,  0.0074],
        [ 0.0282, -0.0183,  0.0066,  ..., -0.0211, -0.0241,  0.0153],
        [ 0.0157,  0.0153, -0.0276,  ..., -0.0004,  0.0160, -0.0367]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:12:35 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 08:12:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1980,  0.9995,  0.0972,  ...,  0.1315,  0.1707,  0.9463],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9448, -0.1737, -0.2336,  ...,  0.4988,  0.6426,  0.9224],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8027,  4.6211, -0.2500,  ..., -0.1250,  0.7051,  2.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4688, -1.0566, -2.1836,  ...,  0.4922,  1.3955,  2.9727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:12:35 root INFO     [order_1_approx] starting weight calculation for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 08:12:35 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 08:14:01 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 08:15:26 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 08:16:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.5831e-04, -6.6519e-04,  3.0947e-04,  ...,  1.6022e-04,
         -2.0266e-04, -2.6536e-04],
        [ 8.0013e-04,  4.4727e-04, -4.1318e-04,  ...,  6.6471e-04,
         -8.8871e-05, -3.2616e-04],
        [ 8.0061e-04,  4.3452e-05,  1.2493e-03,  ..., -7.0333e-05,
         -3.2330e-04,  4.3631e-05],
        ...,
        [-1.3590e-04,  1.2946e-04, -1.4901e-05,  ...,  1.3857e-03,
          5.7411e-04, -3.2496e-04],
        [-6.5756e-04, -1.9670e-04,  7.0572e-05,  ..., -1.2207e-04,
          1.4639e-03,  2.1696e-04],
        [-4.3392e-04, -2.6798e-04,  4.3917e-04,  ...,  1.4269e-04,
         -1.2010e-04,  2.0676e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0007,  0.0128, -0.0071,  ...,  0.0027, -0.0069,  0.0087],
        [ 0.0164, -0.0028,  0.0088,  ..., -0.0009,  0.0104,  0.0011],
        [-0.0151,  0.0154, -0.0056,  ..., -0.0077, -0.0162,  0.0038],
        ...,
        [-0.0199,  0.0135, -0.0142,  ...,  0.0186, -0.0159,  0.0040],
        [ 0.0037, -0.0164, -0.0086,  ..., -0.0115,  0.0061,  0.0132],
        [-0.0151,  0.0189,  0.0112,  ...,  0.0040,  0.0084,  0.0052]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0015,  0.0053, -0.0004,  ...,  0.0006, -0.0091, -0.0002],
        [ 0.0275, -0.0388,  0.0038,  ..., -0.0164, -0.0024,  0.0132],
        [-0.0216,  0.0072,  0.0171,  ..., -0.0158,  0.0150, -0.0025],
        ...,
        [-0.0046,  0.0081,  0.0092,  ...,  0.0096,  0.0087, -0.0066],
        [ 0.0023, -0.0098,  0.0064,  ..., -0.0028, -0.0024,  0.0174],
        [-0.0225,  0.0081,  0.0060,  ...,  0.0043,  0.0115, -0.0051]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:16:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too spent, it is overspent
If something is too powered, it is overpowered
If something is too qualified, it is overqualified
If something is too filled, it is overfilled
If something is too stressed, it is overstressed
If something is too loaded, it is overloaded
If something is too simplified, it is oversimplified
If something is too compensated, it is
2024-06-30 08:16:55 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 08:16:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1997,  0.1331,  0.6626,  ..., -0.2181, -0.3979, -0.8008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1729, -0.1359,  0.1576,  ...,  0.2017, -0.3672, -0.5449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0092,  0.8115,  1.0000,  ..., -0.0656, -0.0317, -0.8403],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6016,  0.1779,  0.2469,  ...,  0.2360, -0.4155, -0.0869],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:16:55 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:16:55 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 08:17:19 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 08:17:42 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 08:18:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8896e-03, -2.9397e-04, -3.2187e-04,  ...,  3.6836e-04,
         -4.9114e-04, -3.1352e-05],
        [ 3.6955e-04, -2.5158e-03,  3.5822e-05,  ...,  7.3195e-05,
         -2.1863e-04,  8.3113e-04],
        [-1.0955e-04,  1.8024e-04, -3.3493e-03,  ...,  1.0490e-05,
          4.5633e-04,  1.4627e-04],
        ...,
        [-1.0033e-03,  1.5378e-05,  4.3440e-04,  ..., -2.6093e-03,
         -1.5187e-04, -1.2803e-04],
        [ 4.9472e-06, -7.4506e-05, -3.2902e-04,  ..., -4.8101e-05,
         -3.1090e-03, -1.5152e-04],
        [-7.7009e-04,  1.7786e-04, -5.9605e-08,  ..., -5.1141e-05,
         -3.9029e-04, -3.3226e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.2990e-02,  4.2725e-04,  4.3488e-03,  ...,  8.4686e-04,
          9.1705e-03,  2.3766e-03],
        [-5.6725e-03, -3.1097e-02, -3.0975e-03,  ...,  5.4741e-03,
          2.0103e-03,  1.0300e-03],
        [-2.7156e-04, -2.0962e-03, -4.1260e-02,  ...,  9.6893e-04,
         -2.8133e-03,  1.3447e-04],
        ...,
        [ 8.1787e-03,  4.7760e-03,  6.7482e-03,  ..., -3.8116e-02,
          3.5992e-03, -2.9678e-03],
        [-4.4022e-03,  5.6190e-03,  7.2060e-03,  ..., -9.1553e-05,
         -3.5858e-02,  3.6716e-03],
        [-2.3022e-03, -6.6833e-03,  1.4286e-03,  ...,  4.8904e-03,
          1.7643e-03, -2.9404e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0353, -0.0015,  0.0022,  ..., -0.0001,  0.0009, -0.0002],
        [ 0.0021, -0.0349, -0.0038,  ...,  0.0014,  0.0058, -0.0006],
        [-0.0064, -0.0019, -0.0311,  ..., -0.0012, -0.0037,  0.0018],
        ...,
        [-0.0007,  0.0005,  0.0024,  ..., -0.0331, -0.0012, -0.0019],
        [-0.0009,  0.0011,  0.0018,  ..., -0.0026, -0.0309,  0.0058],
        [-0.0009, -0.0020, -0.0025,  ...,  0.0054,  0.0020, -0.0306]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:18:07 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 08:18:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2688,  0.5869,  0.8765,  ..., -0.3403, -0.0939, -1.0322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7173, -0.0983,  0.3997,  ..., -0.0896, -0.5010, -0.3374],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1760,  1.0254,  1.2100,  ..., -0.5854, -0.2769, -0.8037],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5649,  0.0836,  0.2566,  ..., -0.6377, -0.3914,  0.1646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:18:07 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:18:07 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 08:18:31 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 08:18:54 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 08:19:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1248e-03,  8.1635e-04,  1.2910e-04,  ..., -9.5415e-04,
         -3.5667e-04, -4.8208e-04],
        [ 2.0552e-04, -3.7804e-03, -3.8409e-04,  ...,  1.3132e-03,
         -8.8406e-04, -8.5831e-04],
        [-2.2292e-04, -6.0940e-04, -3.0689e-03,  ...,  4.2105e-04,
         -3.9983e-04,  3.0208e-04],
        ...,
        [ 3.8362e-04,  5.0449e-04, -5.0831e-04,  ..., -2.9030e-03,
         -1.1072e-03, -1.3101e-04],
        [ 6.1607e-04,  6.2466e-04,  1.0939e-03,  ...,  1.8299e-04,
         -2.0905e-03, -3.5334e-04],
        [-3.5334e-04, -5.7459e-05, -4.0865e-04,  ..., -5.8699e-04,
          6.1703e-04, -2.6245e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0749,  0.0152, -0.0093,  ...,  0.0055,  0.0083, -0.0094],
        [-0.0029, -0.0715, -0.0111,  ...,  0.0123,  0.0068,  0.0047],
        [-0.0019, -0.0105, -0.0654,  ..., -0.0036, -0.0026, -0.0066],
        ...,
        [ 0.0047,  0.0004,  0.0005,  ..., -0.0747,  0.0011, -0.0004],
        [ 0.0047, -0.0068, -0.0036,  ...,  0.0029, -0.0682,  0.0001],
        [-0.0117, -0.0003, -0.0003,  ...,  0.0002,  0.0046, -0.0790]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.9458e-02,  2.1229e-03, -6.5689e-03,  ..., -8.4877e-05,
          6.9580e-03,  3.0518e-04],
        [-9.3460e-04, -8.0811e-02, -8.4686e-03,  ...,  5.9471e-03,
          3.5515e-03,  3.4580e-03],
        [ 5.9509e-03,  2.9602e-03, -5.9875e-02,  ...,  1.8940e-03,
         -4.7188e-03, -6.3858e-03],
        ...,
        [ 1.1616e-03,  1.1063e-02,  3.4523e-03,  ..., -7.6416e-02,
         -6.8130e-03, -4.7607e-03],
        [-5.2567e-03,  1.4067e-03,  3.0403e-03,  ...,  4.7455e-03,
         -7.3120e-02,  2.6188e-03],
        [ 1.0004e-03,  1.0872e-04,  1.7929e-03,  ..., -3.4866e-03,
          7.1411e-03, -7.7454e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:19:20 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 08:19:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0118,  1.0684,  1.2988,  ..., -0.0851, -0.0471, -1.1729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9536,  0.2654,  0.3804,  ...,  0.3542, -0.6294, -0.1591],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0698,  0.7246,  1.1846,  ..., -0.4053, -0.0734, -0.7617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8809,  0.2346,  0.0486,  ..., -0.5205, -0.4365,  0.8960],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:19:20 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:19:20 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 08:19:44 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 08:20:09 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 08:20:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1504e-03,  1.4639e-04, -2.1744e-03,  ...,  4.2033e-04,
          6.6853e-04, -1.8024e-03],
        [ 1.1081e-04, -5.6534e-03,  9.4032e-04,  ..., -6.2227e-05,
         -7.8726e-04,  9.7215e-05],
        [-5.3883e-04, -4.3941e-04, -3.8795e-03,  ...,  4.8685e-04,
         -5.7983e-04, -7.1001e-04],
        ...,
        [-7.5197e-04,  1.2445e-03, -9.3555e-04,  ..., -4.1962e-03,
          1.7786e-04, -6.5994e-04],
        [-1.1835e-03, -1.9884e-04, -6.0701e-04,  ...,  4.1485e-04,
         -4.1389e-03, -3.2282e-04],
        [ 7.6675e-04, -1.5869e-03,  1.1339e-03,  ...,  5.3692e-04,
          2.4986e-04, -4.5853e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.3549e-02, -4.2343e-03, -7.6675e-03,  ...,  2.2736e-03,
          1.0557e-03, -1.0147e-02],
        [-1.6327e-03, -3.5583e-02,  9.4748e-04,  ...,  1.0376e-03,
         -1.2421e-02, -1.8873e-03],
        [ 8.2016e-05, -2.0676e-03, -3.3539e-02,  ..., -5.5161e-03,
         -1.3397e-02, -1.5354e-03],
        ...,
        [ 8.7261e-04, -1.9388e-03, -5.9509e-03,  ..., -3.9795e-02,
          1.4162e-03,  4.1962e-03],
        [-1.0155e-02, -4.8332e-03,  1.8444e-03,  ...,  6.4583e-03,
         -3.8147e-02, -2.3537e-03],
        [-2.0180e-03, -5.0659e-03,  1.6575e-03,  ..., -2.4128e-03,
         -2.2888e-05, -3.1891e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0392,  0.0027, -0.0021,  ...,  0.0016,  0.0006, -0.0025],
        [ 0.0049, -0.0311,  0.0035,  ..., -0.0015, -0.0008,  0.0053],
        [ 0.0033,  0.0017, -0.0329,  ..., -0.0072,  0.0018,  0.0032],
        ...,
        [-0.0008, -0.0016, -0.0080,  ..., -0.0316, -0.0001, -0.0023],
        [-0.0044,  0.0039,  0.0067,  ...,  0.0008, -0.0240, -0.0003],
        [-0.0046,  0.0040,  0.0051,  ...,  0.0006,  0.0066, -0.0292]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:20:35 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 08:20:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2615,  1.3389,  1.5469,  ..., -0.7329, -0.3765, -1.1240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8877,  0.1106,  0.3884,  ..., -0.9170, -0.5938,  0.2261],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1708,  0.5498,  1.3047,  ..., -0.1935,  0.3721, -0.7593],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7065,  0.9414,  0.4448,  ..., -0.8950,  0.0415,  0.7490],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:20:35 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:20:35 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 08:21:05 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 08:21:35 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 08:22:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.1022e-05, -1.0490e-03, -2.2173e-04,  ...,  1.2493e-04,
          3.2692e-03, -5.4407e-04],
        [ 2.2793e-03, -3.4981e-03,  9.3508e-04,  ..., -1.6794e-03,
          3.7575e-04,  5.8174e-05],
        [-7.3767e-04, -6.5470e-04, -2.1648e-03,  ...,  9.0981e-04,
          7.1049e-04,  1.2770e-03],
        ...,
        [ 8.1253e-04, -1.9970e-03, -2.9373e-04,  ..., -2.1381e-03,
          3.6049e-04, -6.7568e-04],
        [ 1.4858e-03,  5.4836e-04, -8.5735e-04,  ..., -8.9216e-04,
         -2.6417e-03,  3.1769e-05],
        [ 1.3199e-03,  5.3358e-04,  9.1982e-04,  ..., -6.0320e-04,
         -9.6178e-04, -4.3564e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0417,  0.0029, -0.0009,  ...,  0.0047,  0.0066, -0.0045],
        [ 0.0107, -0.0535,  0.0074,  ..., -0.0083,  0.0081,  0.0018],
        [ 0.0009, -0.0042, -0.0457,  ...,  0.0069, -0.0042,  0.0063],
        ...,
        [ 0.0035,  0.0016, -0.0005,  ..., -0.0381,  0.0036, -0.0054],
        [-0.0054,  0.0036, -0.0016,  ...,  0.0039, -0.0432,  0.0041],
        [ 0.0083, -0.0016, -0.0021,  ...,  0.0042,  0.0035, -0.0518]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0541, -0.0001,  0.0035,  ..., -0.0034,  0.0016,  0.0022],
        [ 0.0038, -0.0335, -0.0019,  ...,  0.0043,  0.0119, -0.0075],
        [ 0.0002, -0.0020, -0.0445,  ..., -0.0003, -0.0029,  0.0037],
        ...,
        [-0.0091, -0.0016,  0.0012,  ..., -0.0392,  0.0034, -0.0010],
        [ 0.0003,  0.0014, -0.0038,  ..., -0.0075, -0.0361,  0.0043],
        [-0.0016, -0.0013, -0.0010,  ..., -0.0086, -0.0008, -0.0443]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:22:03 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 08:22:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0910,  0.7554,  1.2197,  ..., -0.4199, -0.0494, -0.8872],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9956,  0.2327,  0.0611,  ..., -0.5571, -0.4592,  1.0117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4780,  0.6475,  1.5986,  ..., -0.1552,  0.8027, -0.9414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6792,  0.7007,  0.6270,  ..., -0.3394,  0.0007,  0.4553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:22:03 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:22:03 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 08:22:32 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 08:23:04 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 08:23:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3447e-03,  1.5736e-03, -2.6245e-03,  ...,  1.5199e-05,
         -7.5459e-05,  2.9125e-03],
        [-2.0237e-03,  5.9032e-04, -7.9632e-04,  ..., -6.8545e-05,
         -5.1498e-04,  2.6073e-03],
        [ 9.0027e-04, -6.2466e-04, -2.0063e-04,  ..., -6.2227e-04,
          9.2745e-04, -1.3914e-03],
        ...,
        [-7.5865e-04,  1.1835e-03, -8.1062e-04,  ..., -7.8249e-04,
         -2.7409e-03,  7.0858e-04],
        [ 7.6008e-04,  1.4486e-03, -1.6189e-04,  ...,  1.6870e-03,
          2.0523e-03, -7.9632e-04],
        [-9.3997e-05, -2.3594e-03, -1.0405e-03,  ..., -5.3549e-04,
         -9.4700e-04,  6.1369e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0759,  0.0038, -0.0019,  ..., -0.0108, -0.0051,  0.0048],
        [ 0.0008, -0.0908,  0.0148,  ...,  0.0043,  0.0042,  0.0174],
        [ 0.0032, -0.0145, -0.0755,  ...,  0.0017,  0.0057,  0.0024],
        ...,
        [-0.0076, -0.0068,  0.0012,  ..., -0.0690, -0.0015,  0.0043],
        [ 0.0064, -0.0040, -0.0038,  ..., -0.0003, -0.0757, -0.0023],
        [-0.0046,  0.0007,  0.0057,  ...,  0.0044,  0.0010, -0.0883]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0896, -0.0048,  0.0069,  ..., -0.0019, -0.0063, -0.0003],
        [-0.0107, -0.0992,  0.0031,  ..., -0.0056, -0.0044, -0.0004],
        [-0.0041, -0.0009, -0.0932,  ...,  0.0008,  0.0079,  0.0059],
        ...,
        [-0.0048, -0.0023,  0.0002,  ..., -0.0839,  0.0084,  0.0043],
        [ 0.0004, -0.0046,  0.0012,  ...,  0.0008, -0.0961,  0.0073],
        [ 0.0047,  0.0042,  0.0068,  ..., -0.0074, -0.0072, -0.0994]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:23:39 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 08:23:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1826,  0.5601,  1.2676,  ..., -0.1896,  0.3562, -0.8237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7749,  1.0459,  0.4592,  ..., -0.9321,  0.0313,  0.8198],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4246,  0.5894,  1.3301,  ...,  0.1339,  1.2080, -0.9897],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4180,  0.2095,  0.5059,  ...,  0.2153, -0.1017,  0.1770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:23:39 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:23:39 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 08:24:15 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 08:24:51 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 08:25:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.5272e-04, -1.9341e-03,  3.9368e-03,  ...,  5.4359e-04,
          4.0970e-03, -3.6831e-03],
        [ 4.6234e-03, -6.2714e-03,  2.1629e-03,  ...,  5.3596e-04,
          3.9825e-03, -1.5717e-03],
        [-2.2907e-03,  1.3371e-03, -2.6627e-03,  ..., -2.5520e-03,
         -2.1458e-05, -1.7238e-04],
        ...,
        [ 8.0490e-04, -9.2697e-04, -2.4176e-04,  ..., -2.4090e-03,
          5.0163e-04,  2.9907e-03],
        [ 3.6736e-03, -1.6956e-03,  5.4455e-04,  ..., -1.3237e-03,
         -3.8452e-03, -7.7581e-04],
        [ 3.9339e-05, -2.6608e-03,  5.7507e-04,  ...,  1.0147e-03,
         -2.0657e-03, -1.1921e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0718,  0.0013, -0.0033,  ..., -0.0032,  0.0110, -0.0041],
        [ 0.0033, -0.0927, -0.0084,  ...,  0.0144, -0.0023, -0.0019],
        [ 0.0076,  0.0009, -0.0809,  ...,  0.0097, -0.0020,  0.0020],
        ...,
        [ 0.0010,  0.0013,  0.0064,  ..., -0.0714, -0.0002, -0.0036],
        [ 0.0034,  0.0095,  0.0034,  ...,  0.0002, -0.0833,  0.0072],
        [ 0.0020,  0.0081,  0.0017,  ..., -0.0086, -0.0141, -0.0782]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.6802e-02, -7.9536e-04, -1.5640e-03,  ..., -2.4929e-03,
          2.0943e-03, -1.1625e-03],
        [ 3.7537e-03, -1.0333e-01, -5.7449e-03,  ...,  6.1226e-04,
         -5.9052e-03,  1.0338e-03],
        [ 2.4090e-03, -3.7003e-03, -1.0223e-01,  ...,  9.0179e-03,
          5.1651e-03, -5.5237e-03],
        ...,
        [ 7.7515e-03, -8.6069e-05,  8.2321e-03,  ..., -9.8938e-02,
         -1.5049e-03, -4.6921e-03],
        [-5.9586e-03, -1.0948e-03, -5.1384e-03,  ...,  3.3493e-03,
         -9.8267e-02, -2.0027e-03],
        [-3.2921e-03,  4.3793e-03, -9.2163e-03,  ..., -8.2550e-03,
          3.2005e-03, -1.1060e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:25:30 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 08:25:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4407,  0.6108,  1.3418,  ..., -0.1614,  0.7090, -0.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6772,  0.7329,  0.5732,  ..., -0.3403, -0.0014,  0.4331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1326,  0.2671,  1.5898,  ...,  0.1614,  1.3779, -0.2021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0234,  0.3374,  0.7295,  ...,  0.3870, -0.0239, -0.3064],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:25:30 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:25:30 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 08:26:07 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 08:26:46 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 08:27:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.7302e-03,  7.5150e-04, -2.5787e-03,  ..., -1.0080e-03,
         -1.7042e-03,  1.7681e-03],
        [ 1.4267e-03, -1.2798e-03, -2.4738e-03,  ...,  2.1057e-03,
          1.5173e-03, -2.8610e-06],
        [ 1.0109e-03, -9.6130e-04, -1.5659e-03,  ..., -1.2693e-03,
         -9.4461e-04,  2.7580e-03],
        ...,
        [-7.5960e-04,  2.9449e-03,  9.0933e-04,  ..., -5.2223e-03,
          2.2240e-03,  5.0659e-03],
        [ 7.9775e-04, -4.2152e-04, -2.1248e-03,  ...,  3.0470e-04,
         -2.0428e-03, -2.6608e-03],
        [ 1.7872e-03, -2.8362e-03,  1.0004e-03,  ..., -4.6349e-04,
          2.1896e-03, -3.2177e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0236e-01,  8.9569e-03,  1.1749e-03,  ..., -1.8021e-02,
         -1.6060e-03,  5.5742e-04],
        [-9.0485e-03, -8.3130e-02, -1.1063e-03,  ...,  9.3794e-04,
         -8.2684e-04,  3.3045e-04],
        [ 7.4291e-04, -4.4136e-03, -7.2083e-02,  ..., -4.6577e-03,
         -9.3307e-03,  1.2985e-02],
        ...,
        [-8.2169e-03,  1.2093e-02,  9.8648e-03,  ..., -8.3801e-02,
         -6.1951e-03, -1.4359e-02],
        [ 1.2299e-02,  2.7866e-03, -8.3694e-03,  ...,  4.8828e-03,
         -8.1482e-02,  3.3855e-03],
        [-3.8414e-03, -1.4973e-03, -4.0054e-05,  ..., -1.0357e-03,
          6.1760e-03, -9.2957e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0911,  0.0050,  0.0043,  ..., -0.0032, -0.0027, -0.0045],
        [ 0.0023, -0.0841, -0.0080,  ...,  0.0030,  0.0074, -0.0106],
        [ 0.0065,  0.0024, -0.0871,  ...,  0.0035,  0.0002,  0.0086],
        ...,
        [-0.0055, -0.0025,  0.0006,  ..., -0.0922,  0.0101, -0.0002],
        [ 0.0030,  0.0078,  0.0013,  ...,  0.0100, -0.0837, -0.0036],
        [ 0.0004, -0.0096,  0.0026,  ..., -0.0026, -0.0011, -0.0800]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:27:27 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 08:27:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3752,  0.5215,  1.0918,  ...,  0.1028,  1.0195, -0.9121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.3408,  0.1987,  0.4451,  ...,  0.1895, -0.0972,  0.1525],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0464,  0.2593,  1.4854,  ..., -0.1626,  0.8037, -0.5630],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9673,  0.1106,  0.5542,  ...,  0.1945, -0.1295,  0.1409],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:27:28 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:27:28 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 08:28:09 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 08:28:50 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 08:29:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.2139e-03, -3.0327e-03,  2.8400e-03,  ...,  2.7895e-04,
          2.4033e-04, -5.4321e-03],
        [ 1.3866e-03, -4.3907e-03,  2.4199e-04,  ..., -6.8626e-03,
          1.0004e-03,  8.8406e-04],
        [-3.1424e-04,  2.5415e-04, -1.2455e-03,  ...,  1.6212e-04,
         -2.2812e-03, -1.1158e-03],
        ...,
        [-2.9278e-03, -2.0676e-03,  2.8968e-04,  ...,  1.1320e-03,
         -4.3797e-04,  3.6812e-04],
        [ 1.1854e-03,  1.1330e-03, -6.0463e-04,  ...,  9.3555e-04,
         -4.7455e-03,  2.3956e-03],
        [ 4.0665e-03, -5.8603e-04, -1.3256e-03,  ..., -8.4877e-05,
          1.0405e-03, -2.5311e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0760, -0.0018, -0.0091,  ...,  0.0030, -0.0078, -0.0011],
        [ 0.0081, -0.0934,  0.0168,  ..., -0.0061,  0.0069,  0.0053],
        [ 0.0004,  0.0095, -0.0643,  ..., -0.0075,  0.0047, -0.0102],
        ...,
        [ 0.0005,  0.0138, -0.0003,  ..., -0.0920, -0.0053,  0.0170],
        [ 0.0079,  0.0027, -0.0009,  ..., -0.0149, -0.0738, -0.0042],
        [ 0.0005, -0.0064, -0.0147,  ..., -0.0003,  0.0181, -0.0879]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1068,  0.0080, -0.0085,  ...,  0.0026,  0.0076, -0.0070],
        [ 0.0031, -0.1279,  0.0065,  ..., -0.0075, -0.0038,  0.0061],
        [-0.0030, -0.0018, -0.1203,  ..., -0.0091, -0.0129,  0.0023],
        ...,
        [ 0.0054,  0.0065, -0.0075,  ..., -0.1092, -0.0010,  0.0028],
        [-0.0048,  0.0076, -0.0061,  ..., -0.0033, -0.1005,  0.0036],
        [-0.0130, -0.0020, -0.0077,  ...,  0.0040,  0.0085, -0.1239]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:29:30 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 08:29:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0806,  0.2039,  1.1221,  ...,  0.0938,  1.0156, -0.1808],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9102,  0.2983,  0.5576,  ...,  0.2974, -0.0337, -0.2871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7378,  0.8179,  2.0664,  ..., -0.6538,  0.9302, -1.5322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0215,  0.1958,  1.2598,  ...,  0.4241, -0.1752, -0.2322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:29:30 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:29:30 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 08:29:57 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 08:30:35 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 08:31:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0055,  0.0021,  0.0013,  ..., -0.0029, -0.0027,  0.0002],
        [ 0.0027, -0.0014, -0.0024,  ...,  0.0009, -0.0050,  0.0031],
        [-0.0039, -0.0027,  0.0004,  ...,  0.0027,  0.0024,  0.0003],
        ...,
        [-0.0010, -0.0042, -0.0008,  ...,  0.0019,  0.0011,  0.0007],
        [-0.0024,  0.0020,  0.0005,  ...,  0.0039, -0.0054, -0.0003],
        [ 0.0003, -0.0007,  0.0025,  ..., -0.0007,  0.0018, -0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1169, -0.0041,  0.0096,  ..., -0.0188, -0.0041,  0.0215],
        [-0.0005, -0.1100, -0.0163,  ...,  0.0068,  0.0021,  0.0043],
        [ 0.0083, -0.0078, -0.1097,  ...,  0.0148, -0.0072,  0.0004],
        ...,
        [-0.0113,  0.0076,  0.0079,  ..., -0.1132,  0.0096,  0.0090],
        [ 0.0004,  0.0066,  0.0111,  ...,  0.0153, -0.1164, -0.0046],
        [ 0.0042, -0.0023,  0.0024,  ..., -0.0247, -0.0117, -0.1041]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6760e-01,  4.3755e-03,  7.1869e-03,  ..., -5.3482e-03,
         -1.0796e-03,  9.6130e-04],
        [-7.9575e-03, -1.6418e-01, -1.1406e-02,  ...,  1.2817e-02,
          5.9624e-03,  5.1994e-03],
        [-4.6730e-03, -7.8583e-03, -1.4685e-01,  ...,  1.0056e-02,
         -7.0114e-03, -6.8893e-03],
        ...,
        [-6.8130e-03,  2.8305e-02,  8.7509e-03,  ..., -1.6260e-01,
         -7.2479e-05,  5.6343e-03],
        [-2.3346e-03,  2.2144e-03,  9.4528e-03,  ..., -4.9973e-03,
         -1.6541e-01, -1.8234e-03],
        [-2.1248e-03,  5.7945e-03,  9.1095e-03,  ..., -1.5022e-02,
         -3.2959e-03, -1.4771e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:31:24 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 08:31:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0341,  0.1680,  0.9785,  ..., -0.1039,  0.5459, -0.4590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7944,  0.0770,  0.3997,  ...,  0.1627, -0.1182,  0.0768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5254,  1.1943,  2.7793,  ...,  0.3716,  0.8789, -1.7666],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6191, -0.2805,  0.6606,  ...,  0.3057, -0.1743, -0.0673],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:31:24 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:31:24 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 08:32:14 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 08:32:53 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 08:33:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6727e-03,  2.1439e-03, -2.0504e-03,  ..., -1.3409e-03,
          3.5584e-05,  3.4142e-03],
        [-2.5749e-05,  3.5915e-03,  3.8795e-03,  ...,  1.3685e-03,
          4.6196e-03,  2.3251e-03],
        [-1.4954e-03,  8.3637e-04, -1.3313e-03,  ...,  4.3273e-04,
          9.5463e-04,  3.6645e-04],
        ...,
        [ 4.1351e-03, -6.7520e-04,  5.1918e-03,  ..., -2.0943e-03,
         -2.0199e-03, -2.4281e-03],
        [ 3.4952e-04, -3.9368e-03,  8.9550e-04,  ...,  6.6223e-03,
         -6.5804e-04,  2.1973e-03],
        [-2.7637e-03,  3.3593e-04,  2.5129e-04,  ...,  3.9520e-03,
         -8.8358e-04,  2.7180e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0905,  0.0118, -0.0017,  ...,  0.0098,  0.0020, -0.0082],
        [ 0.0032, -0.1008,  0.0070,  ..., -0.0012, -0.0058, -0.0005],
        [-0.0061,  0.0031, -0.0967,  ...,  0.0121, -0.0130,  0.0229],
        ...,
        [ 0.0066, -0.0086,  0.0025,  ..., -0.1052,  0.0079, -0.0052],
        [ 0.0068, -0.0039, -0.0013,  ...,  0.0119, -0.0957,  0.0155],
        [ 0.0100,  0.0035, -0.0025,  ...,  0.0116,  0.0134, -0.0946]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1055, -0.0014,  0.0090,  ...,  0.0096, -0.0029, -0.0009],
        [ 0.0151, -0.0971, -0.0042,  ..., -0.0095, -0.0146,  0.0027],
        [-0.0089,  0.0066, -0.1060,  ...,  0.0101, -0.0033,  0.0127],
        ...,
        [-0.0003, -0.0058,  0.0109,  ..., -0.0895,  0.0054, -0.0014],
        [ 0.0075, -0.0149, -0.0068,  ...,  0.0120, -0.1004, -0.0085],
        [ 0.0053,  0.0021,  0.0029,  ...,  0.0108, -0.0082, -0.1100]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:33:37 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 08:33:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5073,  0.5269,  1.2402,  ..., -0.4470,  0.5742, -1.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7920,  0.1329,  0.8589,  ...,  0.2734, -0.1495, -0.1763],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6763,  1.4072,  1.7393,  ..., -0.0981,  0.9385, -1.1035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8516,  0.0193,  0.5000,  ...,  0.7471, -0.0114, -0.1625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:33:37 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:33:37 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 08:34:28 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 08:35:15 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 08:36:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0093,  0.0002, -0.0003,  ..., -0.0008,  0.0039,  0.0028],
        [-0.0016,  0.0058, -0.0020,  ...,  0.0025,  0.0017,  0.0027],
        [ 0.0008, -0.0010,  0.0091,  ..., -0.0024,  0.0024,  0.0044],
        ...,
        [-0.0020,  0.0024,  0.0080,  ...,  0.0083, -0.0036,  0.0047],
        [-0.0048, -0.0019, -0.0017,  ..., -0.0043,  0.0109,  0.0020],
        [-0.0007,  0.0017,  0.0014,  ..., -0.0017,  0.0002,  0.0062]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1636, -0.0035, -0.0062,  ..., -0.0131,  0.0011,  0.0145],
        [ 0.0028, -0.1763, -0.0115,  ...,  0.0027,  0.0017,  0.0095],
        [ 0.0133, -0.0054, -0.1552,  ..., -0.0057,  0.0021, -0.0233],
        ...,
        [-0.0256, -0.0103,  0.0096,  ..., -0.1685,  0.0053,  0.0051],
        [-0.0120,  0.0129, -0.0041,  ...,  0.0030, -0.1650,  0.0155],
        [ 0.0058,  0.0014, -0.0103,  ...,  0.0037,  0.0019, -0.1580]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.0532e-01,  9.7351e-03,  1.2909e-02,  ..., -1.1620e-02,
         -1.4595e-02, -7.9041e-03],
        [ 3.8013e-03, -2.2534e-01, -1.3344e-02,  ..., -2.9049e-03,
          1.2756e-02,  1.5795e-05],
        [ 1.5259e-05,  9.4299e-03, -2.0532e-01,  ...,  7.4692e-03,
         -1.5373e-03, -6.5002e-03],
        ...,
        [-1.2589e-04, -1.6499e-03, -4.2000e-03,  ..., -2.3730e-01,
          4.7531e-03, -9.8801e-03],
        [-1.6918e-03,  3.1109e-03, -6.9351e-03,  ...,  9.8267e-03,
         -2.2009e-01,  5.2404e-04],
        [ 1.9264e-03, -6.9122e-03, -4.0207e-03,  ..., -2.5768e-03,
          4.9133e-03, -2.1155e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:36:11 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 08:36:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3796,  0.7700,  1.6797,  ...,  0.2306,  0.5581, -1.2520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5410, -0.2474,  0.4663,  ...,  0.2418, -0.1506, -0.1110],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7397,  1.2715,  1.7959,  ...,  0.3013,  1.2891, -0.7754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9097,  0.2681,  1.0693,  ...,  0.3560,  1.0439,  0.0438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:36:11 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:36:11 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 08:37:06 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 08:38:00 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 08:38:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0070,  0.0017,  0.0001,  ..., -0.0023, -0.0002, -0.0016],
        [-0.0031, -0.0066,  0.0023,  ..., -0.0005, -0.0015, -0.0006],
        [-0.0040,  0.0041, -0.0030,  ..., -0.0009, -0.0031, -0.0038],
        ...,
        [ 0.0029, -0.0008, -0.0042,  ..., -0.0047,  0.0032,  0.0003],
        [-0.0036,  0.0042, -0.0007,  ..., -0.0044, -0.0042, -0.0025],
        [ 0.0049,  0.0011, -0.0003,  ..., -0.0035, -0.0008,  0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0803,  0.0081,  0.0070,  ..., -0.0009, -0.0053, -0.0083],
        [ 0.0026, -0.0809, -0.0003,  ..., -0.0058, -0.0026,  0.0144],
        [-0.0086, -0.0090, -0.0804,  ...,  0.0110,  0.0051,  0.0114],
        ...,
        [-0.0034,  0.0086,  0.0103,  ..., -0.0648,  0.0016, -0.0028],
        [-0.0048, -0.0047, -0.0086,  ...,  0.0027, -0.0870,  0.0083],
        [ 0.0010, -0.0021,  0.0146,  ..., -0.0025, -0.0042, -0.0728]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0788, -0.0059,  0.0046,  ..., -0.0031,  0.0021,  0.0078],
        [ 0.0008, -0.0762, -0.0095,  ..., -0.0011,  0.0132,  0.0073],
        [-0.0030, -0.0035, -0.0801,  ..., -0.0052, -0.0079,  0.0035],
        ...,
        [-0.0063, -0.0043, -0.0026,  ..., -0.0677,  0.0042,  0.0029],
        [-0.0006,  0.0034, -0.0027,  ...,  0.0029, -0.0757,  0.0150],
        [ 0.0012, -0.0033,  0.0041,  ..., -0.0005,  0.0065, -0.0852]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:38:53 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 08:38:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4343,  0.8320,  1.0029,  ..., -0.0820,  0.5723, -0.7188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6509, -0.0215,  0.3423,  ...,  0.5132, -0.0042, -0.1454],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6069,  0.7441,  1.2305,  ...,  0.1490,  1.0645, -0.1504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9805, -0.2627,  1.0107,  ...,  0.3721,  2.2539,  0.2013],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:38:53 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:38:54 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 08:39:50 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 08:40:44 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 08:41:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2769e-04,  7.6370e-03,  3.8338e-04,  ...,  3.3417e-03,
         -3.4885e-03, -5.0964e-03],
        [-5.2490e-03,  8.9188e-03, -4.4289e-03,  ...,  3.4142e-04,
         -2.6274e-04, -4.9324e-03],
        [-3.7503e-04, -3.1395e-03, -4.7188e-03,  ..., -7.7438e-04,
         -4.7913e-03, -6.4507e-03],
        ...,
        [-3.7823e-03, -2.6245e-03,  1.5068e-03,  ...,  7.8735e-03,
         -4.2419e-03,  5.9891e-03],
        [ 3.3970e-03, -2.0256e-03,  2.0676e-03,  ...,  1.1072e-03,
         -7.3586e-03, -5.8413e-06],
        [-2.2149e-04,  7.5722e-03, -3.5286e-04,  ..., -5.2719e-03,
         -6.0616e-03, -3.7384e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1057,  0.0003, -0.0105,  ..., -0.0066,  0.0025,  0.0087],
        [-0.0113, -0.1187, -0.0048,  ...,  0.0054,  0.0006,  0.0106],
        [ 0.0011, -0.0102, -0.1124,  ...,  0.0011,  0.0078, -0.0079],
        ...,
        [-0.0160,  0.0088, -0.0034,  ..., -0.0985, -0.0130,  0.0089],
        [-0.0033,  0.0136, -0.0035,  ..., -0.0115, -0.1165, -0.0030],
        [ 0.0099,  0.0106, -0.0211,  ..., -0.0026,  0.0088, -0.1132]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.4636e-01,  8.3084e-03,  8.5831e-03,  ...,  7.8354e-03,
          1.1032e-02,  6.9847e-03],
        [-1.5884e-02, -1.5320e-01, -2.4128e-03,  ...,  4.2076e-03,
          5.7487e-03,  2.1362e-02],
        [ 9.3918e-03, -6.6757e-06, -1.4575e-01,  ...,  5.8823e-03,
         -1.0395e-04, -6.6795e-03],
        ...,
        [-3.8452e-03, -1.1879e-02, -7.1335e-03,  ..., -1.5100e-01,
         -8.4457e-03,  2.4490e-03],
        [ 2.0691e-02,  8.0719e-03, -6.3705e-04,  ...,  1.5182e-02,
         -1.5515e-01,  1.0056e-02],
        [-8.7051e-03,  9.8038e-04,  5.3635e-03,  ..., -1.5022e-02,
          1.4824e-02, -1.4587e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:41:44 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 08:41:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4485,  0.6836,  0.9141,  ...,  0.1433,  0.7461, -0.5015],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5815,  0.1449,  0.5850,  ...,  0.1952,  0.6646, -0.0280],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4517,  0.9053,  1.9072,  ..., -0.4956,  1.0996, -0.0554],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6191, -0.8174,  1.1260,  ..., -0.3696,  1.5957, -0.3716],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:41:44 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:41:44 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 08:42:43 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 08:43:43 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 08:44:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0072, -0.0017, -0.0017,  ..., -0.0037, -0.0108, -0.0032],
        [-0.0092,  0.0066, -0.0063,  ..., -0.0018,  0.0025, -0.0034],
        [-0.0128, -0.0032,  0.0107,  ..., -0.0006, -0.0035,  0.0053],
        ...,
        [ 0.0091, -0.0025, -0.0098,  ...,  0.0127, -0.0022, -0.0003],
        [ 0.0031, -0.0043,  0.0059,  ...,  0.0011,  0.0087,  0.0025],
        [ 0.0015,  0.0055, -0.0062,  ..., -0.0005,  0.0030,  0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0596e-01,  5.6458e-04, -5.1231e-03,  ...,  7.4883e-03,
         -3.2749e-03, -2.4319e-05],
        [-5.2834e-03, -8.8867e-02,  3.7785e-03,  ..., -1.5521e-04,
         -6.5231e-03, -2.9488e-03],
        [-8.8120e-03, -1.4410e-03, -9.9182e-02,  ...,  9.3174e-04,
          1.1009e-02, -6.2866e-03],
        ...,
        [ 6.9656e-03, -2.1164e-02, -1.3802e-02,  ..., -7.6721e-02,
          1.2825e-02,  9.7561e-04],
        [-3.4332e-04,  8.8806e-03,  4.9591e-03,  ...,  3.3436e-03,
         -8.8989e-02,  5.5122e-03],
        [-7.6485e-03,  7.2174e-03, -6.4087e-03,  ..., -7.5436e-04,
         -1.0895e-02, -9.0332e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1227,  0.0003, -0.0092,  ..., -0.0153,  0.0025, -0.0002],
        [ 0.0046, -0.1112, -0.0030,  ...,  0.0150,  0.0072,  0.0053],
        [ 0.0022, -0.0128, -0.1090,  ...,  0.0104,  0.0027, -0.0097],
        ...,
        [-0.0030, -0.0084, -0.0031,  ..., -0.1105,  0.0102,  0.0021],
        [ 0.0015,  0.0049, -0.0118,  ...,  0.0071, -0.1058,  0.0051],
        [-0.0082,  0.0068, -0.0079,  ..., -0.0055, -0.0029, -0.1113]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:44:45 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 08:44:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3225,  0.3408,  0.5864,  ...,  0.0579,  0.5322, -0.1137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5815, -0.1826,  0.5537,  ...,  0.1974,  1.2852,  0.0844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.2644, 1.6748, 1.6748,  ..., 0.0166, 1.7578, 0.5757], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7051, -0.7158,  1.2012,  ...,  0.1572,  1.8867, -0.3972],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:44:45 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:44:45 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 08:45:47 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 08:46:47 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 08:47:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.1062e-05,  2.3384e-03,  1.1311e-03,  ...,  3.7136e-03,
         -8.0585e-04, -5.3310e-04],
        [ 2.7299e-04,  9.1124e-04,  2.0523e-03,  ..., -1.5087e-03,
         -3.9768e-04,  1.6236e-04],
        [ 4.2839e-03,  5.7030e-04, -1.4877e-03,  ...,  2.8553e-03,
         -2.9778e-04,  1.5697e-03],
        ...,
        [-7.3719e-04,  3.7098e-04, -1.3752e-03,  ..., -8.1635e-04,
         -8.1205e-04,  1.4658e-03],
        [ 4.6272e-03,  1.3723e-03, -1.9479e-04,  ...,  1.9608e-03,
         -8.4829e-04,  9.6798e-04],
        [ 8.2636e-04,  1.0800e-04,  1.2016e-03,  ...,  1.3847e-03,
          4.5490e-04,  2.1629e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1070, -0.0034,  0.0005,  ..., -0.0101,  0.0130,  0.0105],
        [-0.0044, -0.1220, -0.0131,  ...,  0.0084, -0.0043,  0.0014],
        [-0.0005,  0.0050, -0.1009,  ...,  0.0114, -0.0089,  0.0073],
        ...,
        [-0.0097,  0.0085,  0.0035,  ..., -0.1136,  0.0026,  0.0161],
        [-0.0003, -0.0043, -0.0032,  ...,  0.0021, -0.1201, -0.0043],
        [ 0.0022,  0.0133, -0.0077,  ..., -0.0002,  0.0078, -0.0967]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0785e-01,  6.5079e-03, -3.8567e-03,  ...,  8.7585e-03,
         -1.2451e-02,  1.3138e-02],
        [ 1.1187e-03, -1.2671e-01,  3.8757e-03,  ...,  1.7080e-03,
          1.9064e-03,  7.2517e-03],
        [-1.1444e-05, -5.8441e-03, -1.2000e-01,  ..., -4.2992e-03,
          4.4823e-04,  9.0027e-03],
        ...,
        [ 9.2926e-03,  4.9438e-03, -6.6757e-03,  ..., -1.1597e-01,
         -4.6577e-03, -1.2238e-02],
        [-9.0485e-03, -8.9188e-03, -1.1620e-02,  ...,  1.3748e-02,
         -1.2927e-01, -9.3412e-04],
        [ 1.4709e-02, -2.1439e-03, -4.0054e-03,  ..., -1.7502e-02,
          1.9974e-02, -1.2146e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:47:52 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 08:47:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1846,  0.4602,  0.8838,  ..., -0.2502,  0.5479, -0.0590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3804, -0.4429,  0.5591,  ..., -0.1964,  0.8604, -0.2278],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2571,  1.1426,  1.9053,  ...,  1.0889,  1.4277,  0.9199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4050, -0.2854,  1.5000,  ...,  0.6484,  2.0371, -0.7842],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:47:52 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:47:52 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 08:48:56 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 08:50:01 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 08:51:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.0193e-03, -8.2092e-03, -1.8225e-03,  ..., -5.2528e-03,
         -9.3222e-04,  1.7624e-03],
        [ 1.1092e-04,  7.2432e-04, -8.8811e-06,  ...,  3.3722e-03,
          3.9024e-03,  8.8692e-05],
        [-1.0567e-02, -5.2929e-04,  2.2850e-03,  ..., -1.9016e-03,
          3.5858e-03, -5.2376e-03],
        ...,
        [ 4.4861e-03,  2.0623e-04, -5.1575e-03,  ..., -3.0575e-03,
         -2.1687e-03, -5.5199e-03],
        [ 2.6112e-03, -3.1471e-03, -3.4485e-03,  ..., -4.0245e-04,
         -2.3651e-03,  4.1161e-03],
        [ 1.0662e-03,  7.7591e-03, -1.1778e-03,  ..., -4.8904e-03,
         -7.8869e-04, -1.4145e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0462,  0.0078, -0.0085,  ..., -0.0132,  0.0054, -0.0054],
        [-0.0028, -0.0493, -0.0089,  ..., -0.0208,  0.0003,  0.0076],
        [ 0.0007,  0.0005, -0.0498,  ..., -0.0188,  0.0040,  0.0040],
        ...,
        [-0.0030,  0.0048, -0.0051,  ..., -0.0463, -0.0148, -0.0140],
        [ 0.0023,  0.0065, -0.0118,  ...,  0.0147, -0.0505,  0.0153],
        [-0.0014,  0.0073,  0.0111,  ..., -0.0082, -0.0055, -0.0570]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0662,  0.0130, -0.0078,  ..., -0.0071,  0.0105, -0.0024],
        [ 0.0115, -0.0841, -0.0047,  ..., -0.0039,  0.0121,  0.0009],
        [ 0.0008,  0.0040, -0.0828,  ..., -0.0015, -0.0127, -0.0136],
        ...,
        [-0.0273, -0.0123, -0.0056,  ..., -0.0900, -0.0117,  0.0052],
        [ 0.0069,  0.0242, -0.0074,  ...,  0.0151, -0.0840,  0.0045],
        [-0.0057,  0.0051, -0.0013,  ...,  0.0014, -0.0182, -0.0827]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:51:08 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 08:51:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1082,  0.7788,  0.7446,  ..., -0.0011,  0.8237,  0.2260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3599, -0.3545,  0.5625,  ...,  0.0706,  0.9277, -0.2289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0917,  1.3164,  1.7793,  ...,  1.8691,  0.9717,  1.1309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7754, -0.1190,  1.6387,  ...,  1.0625,  2.2402, -0.1870],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:51:08 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:51:08 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 08:52:15 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 08:53:23 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 08:54:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.0185e-03, -7.6294e-04,  5.4970e-03,  ...,  2.6360e-03,
         -6.5756e-04, -3.3379e-06],
        [-3.3379e-04, -5.5542e-03,  1.0738e-03,  ...,  8.8644e-04,
          2.9373e-03,  3.0065e-04],
        [ 2.9354e-03,  1.3618e-03, -1.0124e-02,  ..., -2.6226e-03,
         -1.6146e-03,  2.9964e-03],
        ...,
        [-3.9558e-03,  1.0862e-03, -1.5545e-03,  ..., -3.3226e-03,
         -2.0523e-03, -3.5667e-03],
        [ 6.4735e-03,  1.6618e-04, -2.7828e-03,  ..., -2.4204e-03,
         -8.8882e-03,  6.5613e-04],
        [ 2.1820e-03,  2.2259e-03, -6.4433e-05,  ..., -2.3975e-03,
          3.0270e-03, -6.7978e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0597,  0.0143,  0.0108,  ..., -0.0044, -0.0132,  0.0064],
        [-0.0086, -0.0583,  0.0110,  ..., -0.0007,  0.0071, -0.0056],
        [ 0.0237,  0.0108, -0.0669,  ..., -0.0032,  0.0064, -0.0006],
        ...,
        [ 0.0053, -0.0095,  0.0030,  ..., -0.0596,  0.0113,  0.0062],
        [ 0.0005, -0.0023,  0.0115,  ...,  0.0047, -0.0580,  0.0114],
        [-0.0022,  0.0023,  0.0225,  ...,  0.0004,  0.0024, -0.0607]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0742, -0.0065, -0.0025,  ..., -0.0055, -0.0076, -0.0036],
        [-0.0094, -0.0810, -0.0110,  ..., -0.0042,  0.0005,  0.0084],
        [ 0.0171, -0.0144, -0.0828,  ...,  0.0033,  0.0006,  0.0020],
        ...,
        [ 0.0022,  0.0028,  0.0166,  ..., -0.0557,  0.0087,  0.0091],
        [ 0.0097, -0.0147, -0.0116,  ...,  0.0058, -0.0779,  0.0005],
        [-0.0076,  0.0125,  0.0058,  ..., -0.0054,  0.0058, -0.0780]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:54:33 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 08:54:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1322,  0.4897,  0.7783,  ...,  0.4563,  0.6221,  0.3545],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2096, -0.1270,  0.6758,  ...,  0.3013,  0.9790, -0.4211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4644,  1.2148,  1.5576,  ...,  2.0840,  1.0303,  0.7021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5425,  0.3511,  0.4570,  ...,  1.1318,  1.8262, -0.7085],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:54:33 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:54:33 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 08:55:40 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 08:56:45 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 08:57:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7138e-03, -8.0252e-04,  2.1935e-03,  ...,  1.1549e-03,
          8.9169e-04, -2.7847e-03],
        [-1.4162e-03, -2.4910e-03, -3.3283e-03,  ...,  1.8406e-04,
         -9.7084e-04, -4.6387e-03],
        [-1.3905e-03, -2.7008e-03, -2.3041e-03,  ..., -4.2915e-06,
          1.7440e-04,  1.6775e-03],
        ...,
        [ 2.6436e-03, -6.2561e-04, -1.4219e-03,  ..., -5.8975e-03,
         -2.5005e-03, -3.5362e-03],
        [-1.5173e-03,  5.2691e-04,  2.8076e-03,  ..., -1.7195e-03,
         -1.5697e-03, -2.7637e-03],
        [-1.6479e-03,  8.1635e-04, -1.4133e-03,  ...,  7.2145e-04,
          3.0756e-05, -1.1620e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0715,  0.0140, -0.0035,  ..., -0.0167, -0.0047, -0.0187],
        [ 0.0107, -0.0671, -0.0014,  ..., -0.0055, -0.0141,  0.0209],
        [-0.0205, -0.0036, -0.0782,  ..., -0.0025,  0.0053, -0.0141],
        ...,
        [-0.0046,  0.0017, -0.0058,  ..., -0.0720,  0.0015,  0.0096],
        [-0.0084,  0.0011,  0.0050,  ...,  0.0092, -0.0564,  0.0031],
        [ 0.0039,  0.0124,  0.0049,  ...,  0.0039,  0.0098, -0.0809]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0746,  0.0015,  0.0083,  ..., -0.0074,  0.0028, -0.0083],
        [ 0.0094, -0.1051,  0.0086,  ..., -0.0030,  0.0065,  0.0278],
        [ 0.0040, -0.0003, -0.0741,  ..., -0.0076,  0.0041, -0.0142],
        ...,
        [-0.0061, -0.0013,  0.0013,  ..., -0.0789,  0.0042,  0.0057],
        [-0.0009, -0.0042, -0.0058,  ..., -0.0062, -0.0839, -0.0074],
        [-0.0090,  0.0130, -0.0037,  ...,  0.0062, -0.0077, -0.0797]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 08:57:53 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 08:57:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0462,  0.5396,  0.6924,  ...,  0.7617,  0.4250,  0.4324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3552, -0.0569,  0.6836,  ...,  0.4634,  1.0195, -0.1276],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4814,  0.3877,  1.7070,  ...,  1.6797,  1.6104, -0.1147],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9141,  0.1265, -0.4756,  ...,  0.5947,  2.1133, -0.4834],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 08:57:53 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 08:57:53 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 08:59:04 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 09:00:15 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 09:01:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.1335e-03, -4.7913e-03, -2.6379e-03,  ..., -4.8828e-03,
         -8.2254e-05, -7.7057e-03],
        [ 2.3861e-03,  3.7327e-03,  9.5444e-03,  ..., -1.4048e-03,
          1.2760e-03,  6.8378e-04],
        [ 2.0771e-03, -5.4665e-03, -6.9962e-03,  ..., -1.0204e-03,
         -2.2869e-03,  7.6180e-03],
        ...,
        [ 1.3924e-03, -7.1945e-03,  8.1539e-04,  ..., -3.6087e-03,
         -1.9569e-03,  6.3171e-03],
        [-2.6054e-03, -5.2757e-03, -1.5984e-03,  ...,  7.4196e-03,
          8.2922e-04, -7.5150e-04],
        [ 2.2125e-03,  1.2016e-04, -1.3208e-03,  ..., -1.7281e-03,
         -5.2109e-03,  4.0817e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0324, -0.0034, -0.0126,  ..., -0.0133,  0.0089, -0.0016],
        [ 0.0101, -0.0352, -0.0038,  ...,  0.0169,  0.0141, -0.0044],
        [ 0.0013,  0.0080, -0.0338,  ...,  0.0066, -0.0035,  0.0053],
        ...,
        [-0.0203, -0.0110,  0.0065,  ..., -0.0388, -0.0128,  0.0176],
        [ 0.0145, -0.0043, -0.0153,  ..., -0.0161, -0.0397,  0.0094],
        [-0.0096,  0.0062, -0.0035,  ...,  0.0003,  0.0060, -0.0357]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0484, -0.0063,  0.0163,  ..., -0.0019,  0.0027,  0.0101],
        [-0.0022, -0.0492, -0.0185,  ...,  0.0079,  0.0174, -0.0150],
        [ 0.0099, -0.0165, -0.0570,  ..., -0.0222,  0.0147,  0.0107],
        ...,
        [-0.0182, -0.0222, -0.0058,  ..., -0.0611, -0.0115, -0.0133],
        [ 0.0109, -0.0003, -0.0094,  ..., -0.0059, -0.0514,  0.0210],
        [ 0.0038,  0.0217,  0.0076,  ...,  0.0053,  0.0155, -0.0589]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:01:29 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 09:01:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1892,  0.4690,  0.5684,  ...,  0.8120,  0.3936,  0.2467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2168,  0.1304,  0.1564,  ...,  0.4460,  0.7080, -0.3135],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3105, -0.4829,  1.2090,  ...,  1.5928,  2.7988, -0.3416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5669,  0.2448,  0.2183,  ...,  0.3357,  1.1816, -0.4802],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:01:29 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 09:01:29 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 09:02:40 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 09:03:51 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 09:05:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.0092e-03, -1.1520e-03,  7.6914e-04,  ..., -7.0274e-05,
         -5.4693e-04, -6.9284e-04],
        [-7.7438e-04,  4.4098e-03,  2.0790e-04,  ..., -1.0805e-03,
         -7.8249e-04,  6.4564e-04],
        [ 3.6764e-04, -9.1851e-05,  2.6627e-03,  ..., -8.4972e-04,
         -7.0035e-05,  1.1482e-03],
        ...,
        [ 8.8596e-04, -1.7023e-03, -5.7840e-04,  ...,  1.7338e-03,
          3.8648e-04,  1.1671e-04],
        [ 2.5768e-03, -2.8372e-04,  1.0042e-03,  ...,  3.3646e-03,
          3.0422e-03, -2.3098e-03],
        [-3.8166e-03, -5.7554e-04, -1.0147e-03,  ..., -3.5534e-03,
         -6.2323e-04,  4.8866e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0366, -0.0096, -0.0183,  ...,  0.0028, -0.0059, -0.0133],
        [ 0.0045, -0.0460, -0.0101,  ..., -0.0042, -0.0079,  0.0001],
        [-0.0015,  0.0032, -0.0217,  ..., -0.0010,  0.0087, -0.0111],
        ...,
        [ 0.0143,  0.0019,  0.0044,  ..., -0.0266, -0.0014, -0.0123],
        [ 0.0060,  0.0063, -0.0117,  ...,  0.0110, -0.0328, -0.0009],
        [ 0.0036, -0.0110, -0.0110,  ..., -0.0106, -0.0250, -0.0294]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.2754e-02,  1.4763e-03, -3.7003e-04,  ...,  5.3864e-03,
          1.0155e-02, -2.7409e-03],
        [ 1.2306e-02, -6.4270e-02, -2.1790e-02,  ...,  6.0272e-04,
         -2.0813e-02,  2.3666e-02],
        [ 6.1989e-03, -1.5625e-02, -7.0984e-02,  ..., -4.2381e-03,
         -1.3046e-02,  9.4757e-03],
        ...,
        [-3.8738e-03, -3.7193e-05, -3.0289e-02,  ..., -5.5389e-02,
         -4.6062e-04,  2.8725e-03],
        [ 6.9313e-03,  1.1292e-03, -1.7815e-03,  ..., -7.1106e-03,
         -6.1981e-02,  2.4242e-03],
        [-1.2871e-02, -8.3694e-03, -1.6754e-02,  ..., -1.2024e-02,
         -4.6883e-03, -7.0923e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:05:03 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 09:05:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1809,  0.1313,  0.6094,  ...,  0.6006,  0.5962, -0.0699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3613,  0.0412, -0.1931,  ...,  0.2217,  0.8359, -0.2156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2812, -0.7422,  1.7500,  ...,  1.6621,  2.6699, -0.1411],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1978,  0.1204,  0.5762,  ...,  0.5137,  1.0176, -0.5825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:05:03 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 09:05:03 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 09:06:17 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 09:07:27 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 09:08:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.0997e-03, -8.2254e-04,  2.7966e-04,  ...,  2.6894e-04,
         -4.7159e-04,  7.4208e-05],
        [-3.1292e-05,  2.2364e-04, -8.2254e-04,  ...,  2.3003e-03,
          1.1892e-03, -1.1063e-03],
        [ 2.5444e-03, -1.9951e-03,  3.0365e-03,  ..., -5.7793e-04,
          2.4014e-03, -2.7122e-03],
        ...,
        [-1.3447e-03,  3.2215e-03, -4.9067e-04,  ...,  4.0779e-03,
         -8.1539e-04,  3.1128e-03],
        [-2.1057e-03, -6.6471e-04,  7.2908e-04,  ...,  3.3512e-03,
         -2.0676e-03, -2.6207e-03],
        [ 7.3280e-03, -2.6321e-03,  1.8787e-04,  ..., -2.0943e-03,
          5.6686e-03,  4.7035e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0260,  0.0002,  0.0046,  ..., -0.0010,  0.0119, -0.0015],
        [-0.0096, -0.0452, -0.0109,  ...,  0.0050,  0.0128,  0.0074],
        [ 0.0129,  0.0018, -0.0118,  ...,  0.0050, -0.0095, -0.0030],
        ...,
        [ 0.0005, -0.0055, -0.0046,  ..., -0.0489, -0.0030,  0.0183],
        [-0.0147, -0.0031,  0.0076,  ...,  0.0076, -0.0233,  0.0101],
        [ 0.0084, -0.0052, -0.0040,  ..., -0.0084,  0.0031, -0.0323]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0564,  0.0134, -0.0155,  ...,  0.0052, -0.0107,  0.0024],
        [ 0.0088, -0.0706, -0.0175,  ..., -0.0008,  0.0050,  0.0031],
        [ 0.0042,  0.0236, -0.0424,  ..., -0.0040, -0.0015, -0.0075],
        ...,
        [-0.0032,  0.0027, -0.0067,  ..., -0.0631,  0.0111, -0.0019],
        [-0.0122, -0.0206,  0.0163,  ...,  0.0152, -0.0698,  0.0007],
        [ 0.0076, -0.0021,  0.0033,  ...,  0.0051,  0.0038, -0.0491]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:08:44 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 09:08:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1158, -0.1735,  0.4119,  ...,  0.5654,  1.0225, -0.1597],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2267,  0.0931,  0.0735,  ...,  0.1364,  0.4805, -0.2249],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2268, -0.9692,  2.7227,  ...,  1.7812,  3.2969, -0.4727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5708,  0.2052,  0.3950,  ...,  0.9150,  1.0664, -1.2881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:08:44 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 09:08:44 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 09:10:00 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 09:11:15 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 09:12:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3390e-03,  1.8013e-04, -5.3704e-05,  ..., -4.8161e-05,
          1.2338e-04, -2.1040e-05],
        [-1.6880e-04, -1.1044e-03, -9.6619e-05,  ...,  3.5143e-04,
          2.2233e-04, -2.3222e-04],
        [-5.4264e-04,  2.6202e-04, -1.3323e-03,  ...,  5.0366e-05,
          4.9305e-04, -2.0123e-04],
        ...,
        [-2.7084e-04,  4.1103e-04,  2.7347e-04,  ..., -2.1019e-03,
          5.1355e-04, -2.0075e-04],
        [ 9.3520e-05, -2.0802e-05,  7.4029e-05,  ..., -5.4979e-04,
         -1.1549e-03, -1.0687e-04],
        [-1.4043e-04,  2.8467e-04,  1.7965e-04,  ...,  1.7834e-04,
         -6.0797e-05, -1.2980e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0204,  0.0147, -0.0122,  ..., -0.0039, -0.0017, -0.0014],
        [-0.0085, -0.0316, -0.0010,  ...,  0.0057,  0.0262,  0.0110],
        [-0.0097,  0.0007, -0.0209,  ..., -0.0131,  0.0193, -0.0142],
        ...,
        [-0.0135,  0.0140, -0.0151,  ..., -0.0138,  0.0020,  0.0079],
        [ 0.0090,  0.0064,  0.0068,  ..., -0.0105, -0.0483,  0.0121],
        [-0.0072, -0.0093,  0.0011,  ..., -0.0001,  0.0021, -0.0277]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0715, -0.0051,  0.0089,  ..., -0.0170, -0.0257, -0.0109],
        [-0.0174, -0.0575,  0.0063,  ...,  0.0128,  0.0107,  0.0017],
        [-0.0015, -0.0101, -0.0688,  ..., -0.0171, -0.0016,  0.0094],
        ...,
        [-0.0055,  0.0138,  0.0062,  ..., -0.0386,  0.0050,  0.0108],
        [ 0.0080,  0.0002, -0.0131,  ..., -0.0252, -0.0521, -0.0083],
        [-0.0011,  0.0221, -0.0089,  ..., -0.0176,  0.0115, -0.0612]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:12:35 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 09:12:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0889, -0.2480,  0.5566,  ...,  0.5601,  0.9316, -0.0807],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0650,  0.0461,  0.1893,  ...,  0.1969,  0.4067, -0.2532],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0579, -0.7344,  2.2852,  ...,  2.4238,  3.1113, -0.2798],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.2510,  0.2974,  1.5898,  ...,  1.8838,  0.6646, -0.0225],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:12:35 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 09:12:35 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 09:13:54 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 09:15:11 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 09:16:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0008,  0.0008, -0.0015,  ..., -0.0002, -0.0007, -0.0010],
        [-0.0003, -0.0005,  0.0002,  ...,  0.0013, -0.0001,  0.0005],
        [-0.0005,  0.0021,  0.0027,  ..., -0.0004,  0.0011,  0.0009],
        ...,
        [-0.0023, -0.0021, -0.0003,  ..., -0.0003, -0.0002, -0.0015],
        [-0.0004, -0.0004, -0.0005,  ...,  0.0003, -0.0004,  0.0010],
        [-0.0002,  0.0021,  0.0036,  ...,  0.0007,  0.0016, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0225,  0.0007, -0.0134,  ..., -0.0176,  0.0017,  0.0224],
        [-0.0003, -0.0164,  0.0053,  ...,  0.0119, -0.0040,  0.0079],
        [ 0.0033, -0.0058, -0.0209,  ..., -0.0083,  0.0171,  0.0134],
        ...,
        [-0.0090,  0.0027,  0.0010,  ..., -0.0259, -0.0178,  0.0043],
        [-0.0043, -0.0021,  0.0094,  ..., -0.0035, -0.0257,  0.0100],
        [ 0.0075,  0.0056,  0.0141,  ...,  0.0041, -0.0089, -0.0122]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0514, -0.0028, -0.0135,  ..., -0.0015,  0.0052,  0.0111],
        [-0.0013, -0.0579,  0.0168,  ...,  0.0097, -0.0050, -0.0030],
        [-0.0066, -0.0115, -0.0757,  ..., -0.0130,  0.0031, -0.0090],
        ...,
        [ 0.0128, -0.0149, -0.0197,  ..., -0.0842, -0.0031, -0.0178],
        [ 0.0109, -0.0102,  0.0228,  ...,  0.0017, -0.0873,  0.0227],
        [-0.0088, -0.0005,  0.0226,  ...,  0.0015, -0.0127, -0.0885]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:16:32 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 09:16:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0729, -0.2869,  0.8521,  ...,  0.5723,  1.1191, -0.1919],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2147,  0.0983,  0.0948,  ...,  0.3154,  0.3992, -0.5020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3455, -0.5137,  2.6484,  ...,  2.4492,  3.9297, -0.4163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5288, -0.3496,  1.8994,  ...,  2.8145,  1.9121,  1.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:16:32 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 09:16:32 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 09:17:54 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 09:19:17 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 09:20:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.7828e-03,  4.6587e-04,  4.2419e-03,  ..., -1.8444e-03,
          1.0509e-03,  4.8332e-03],
        [-2.4748e-04,  2.2221e-03,  4.9438e-03,  ..., -2.9812e-03,
         -3.3684e-03,  2.9945e-04],
        [ 3.8242e-03, -9.2220e-04,  5.2738e-04,  ...,  6.9678e-05,
          1.4801e-03,  2.9850e-04],
        ...,
        [ 2.7418e-05, -3.4511e-05,  3.0384e-03,  ...,  3.9330e-03,
         -8.9598e-04, -6.2704e-04],
        [ 1.8702e-03,  2.0256e-03, -8.6164e-04,  ...,  4.4289e-03,
          5.3749e-03, -4.1351e-03],
        [ 9.3937e-04, -6.2227e-04,  1.2369e-03,  ..., -9.6083e-04,
         -1.2779e-03,  9.1782e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0066,  0.0303, -0.0051,  ..., -0.0195, -0.0024, -0.0119],
        [-0.0254, -0.0139,  0.0013,  ...,  0.0045, -0.0110,  0.0153],
        [-0.0068, -0.0002,  0.0295,  ...,  0.0051,  0.0064, -0.0047],
        ...,
        [-0.0249,  0.0094,  0.0018,  ...,  0.0238,  0.0067,  0.0022],
        [ 0.0046, -0.0071, -0.0089,  ..., -0.0053,  0.0039,  0.0045],
        [ 0.0112, -0.0110,  0.0047,  ..., -0.0157,  0.0054,  0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0410, -0.0092,  0.0060,  ..., -0.0126,  0.0145, -0.0045],
        [ 0.0109, -0.0665,  0.0045,  ..., -0.0035, -0.0136,  0.0188],
        [ 0.0023, -0.0162, -0.0026,  ..., -0.0073,  0.0018, -0.0066],
        ...,
        [-0.0144, -0.0020, -0.0011,  ...,  0.0030,  0.0247, -0.0182],
        [ 0.0005, -0.0037,  0.0079,  ...,  0.0346, -0.0120, -0.0111],
        [-0.0024,  0.0128,  0.0042,  ..., -0.0066,  0.0132, -0.0397]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:20:37 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 09:20:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0046, -0.2029,  0.6753,  ...,  0.7285,  0.9883, -0.1334],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4614,  0.1232,  0.4961,  ...,  0.6084,  0.2278, -0.0471],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5361, -0.2046,  3.3633,  ...,  2.3066,  4.7109, -0.5083],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5200, -0.5254,  1.7822,  ...,  2.9258,  1.4805,  0.9648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:20:37 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 09:20:37 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 09:22:02 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 09:23:27 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 09:24:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.2812e-03,  4.5538e-04, -9.4604e-04,  ...,  2.8872e-04,
          9.4771e-05,  8.0347e-04],
        [ 3.3975e-06, -2.5826e-03, -3.7456e-04,  ..., -1.2646e-03,
         -8.2254e-05, -2.3961e-05],
        [ 8.4877e-04,  1.5235e-04, -3.0842e-03,  ..., -2.9659e-04,
          5.0354e-04, -9.4461e-04],
        ...,
        [ 2.9445e-04, -6.5470e-04,  9.2602e-04,  ..., -5.1842e-03,
          7.1669e-04,  8.6641e-04],
        [-2.8038e-04,  5.5695e-04,  9.9277e-04,  ...,  5.9414e-04,
         -3.5000e-03, -1.1463e-03],
        [ 1.3952e-03,  6.6459e-05,  1.2321e-03,  ..., -2.9397e-04,
         -1.6108e-03, -3.5667e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0401,  0.0113,  0.0112,  ...,  0.0099, -0.0002,  0.0230],
        [ 0.0028, -0.0193, -0.0038,  ..., -0.0016, -0.0098,  0.0096],
        [-0.0067,  0.0005, -0.0213,  ..., -0.0037, -0.0263,  0.0143],
        ...,
        [-0.0225,  0.0045, -0.0204,  ..., -0.0103, -0.0047,  0.0027],
        [ 0.0059,  0.0039,  0.0066,  ..., -0.0180, -0.0152, -0.0002],
        [-0.0039, -0.0060, -0.0106,  ...,  0.0067,  0.0075, -0.0193]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.5012e-02,  1.9501e-02,  2.3251e-03,  ..., -7.2575e-04,
          2.0355e-02, -4.5357e-03],
        [-1.6663e-02, -3.8910e-02,  5.3940e-03,  ...,  1.4122e-02,
         -3.7479e-03, -8.7891e-03],
        [ 1.9287e-02,  1.4946e-02, -1.3977e-02,  ...,  1.1574e-02,
         -9.9003e-05, -5.7220e-03],
        ...,
        [-2.2583e-02,  3.2558e-03, -9.0599e-04,  ..., -4.0222e-02,
          7.4692e-03,  8.0566e-03],
        [-3.1738e-03,  8.6517e-03,  8.8577e-03,  ..., -2.2659e-02,
         -1.6586e-02,  1.8997e-02],
        [ 5.6801e-03, -2.2240e-03, -1.8967e-02,  ..., -1.2466e-02,
          1.6693e-02, -4.5959e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:24:54 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 09:24:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0533, -0.1182,  0.6753,  ...,  0.6064,  1.1094, -0.1825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2278, -0.0812,  0.5259,  ...,  0.8091,  0.5928,  0.2798],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3516,  0.0217,  1.6670,  ...,  1.4102,  4.2461, -1.1172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.3389, -0.3530, -0.1328,  ...,  1.7158,  2.0508,  0.9604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:24:54 root INFO     [order_1_approx] starting weight calculation for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 09:24:54 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 09:26:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 09:27:49 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 09:29:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.9788e-04, -2.2578e-04,  3.4022e-04,  ...,  5.8508e-04,
         -6.6757e-04, -2.6417e-04],
        [-1.4400e-04,  1.0653e-03, -2.1625e-04,  ...,  9.8646e-05,
         -6.7770e-05,  3.1734e-04],
        [ 9.2316e-04, -4.8447e-04,  1.2951e-03,  ..., -5.4646e-04,
         -1.8930e-04, -1.2255e-04],
        ...,
        [-4.8041e-04, -6.5446e-05,  1.3208e-04,  ...,  1.7157e-03,
         -2.4259e-04, -9.7573e-05],
        [-6.4373e-04, -1.9014e-05,  5.2595e-04,  ..., -2.3317e-04,
          1.3704e-03, -1.2386e-04],
        [ 1.6141e-04,  1.9455e-04,  3.7241e-04,  ...,  8.1718e-05,
         -1.2636e-05,  2.1820e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0162,  0.0042, -0.0096,  ..., -0.0016,  0.0065,  0.0014],
        [-0.0119, -0.0148, -0.0117,  ..., -0.0067,  0.0071,  0.0161],
        [-0.0070,  0.0046,  0.0009,  ..., -0.0026,  0.0030,  0.0031],
        ...,
        [-0.0140,  0.0385, -0.0080,  ...,  0.0069,  0.0012,  0.0070],
        [ 0.0117, -0.0104, -0.0113,  ..., -0.0057,  0.0065,  0.0235],
        [-0.0051,  0.0214,  0.0012,  ...,  0.0003, -0.0037,  0.0053]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0232,  0.0200,  0.0068,  ...,  0.0064, -0.0026, -0.0026],
        [ 0.0118, -0.0069, -0.0159,  ..., -0.0123,  0.0140,  0.0122],
        [-0.0003,  0.0039,  0.0205,  ..., -0.0150,  0.0196,  0.0042],
        ...,
        [ 0.0133,  0.0237,  0.0089,  ...,  0.0247,  0.0213, -0.0009],
        [-0.0089, -0.0221,  0.0018,  ..., -0.0090, -0.0009,  0.0187],
        [ 0.0011,  0.0100,  0.0203,  ...,  0.0106,  0.0049,  0.0286]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:29:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too qualified, it is overqualified
If something is too powered, it is overpowered
If something is too compensated, it is overcompensated
If something is too spent, it is overspent
If something is too stressed, it is overstressed
If something is too simplified, it is oversimplified
If something is too loaded, it is overloaded
If something is too filled, it is
2024-06-30 09:29:17 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 09:29:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0155, -0.0692, -0.4368,  ..., -0.3101, -0.2888, -0.1886],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2096, -0.1500,  0.1202,  ...,  0.2466, -0.3889, -0.5591],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1382,  0.4578,  0.2646,  ..., -0.0229, -0.3467,  0.0322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6187,  0.1577,  0.2455,  ...,  0.1824, -0.4709, -0.1031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:29:17 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:29:17 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 09:29:40 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 09:30:03 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 09:30:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.7103e-03, -2.3460e-04, -2.2531e-04,  ...,  5.5599e-04,
         -7.7724e-05, -3.5954e-04],
        [ 5.4550e-04, -2.3746e-03, -5.5134e-05,  ...,  1.9598e-04,
         -2.1648e-04,  9.5701e-04],
        [-3.6359e-05,  5.3215e-04, -3.2444e-03,  ..., -5.5075e-04,
         -6.5804e-05,  8.5783e-04],
        ...,
        [-3.2568e-04, -1.2410e-04,  2.2340e-04,  ..., -2.5196e-03,
         -2.9206e-04,  2.0695e-04],
        [-3.2246e-05,  1.5342e-04, -7.0858e-04,  ...,  1.9932e-04,
         -2.7275e-03,  1.7047e-04],
        [-1.1215e-03,  2.2817e-04,  2.5034e-04,  ...,  2.0373e-04,
         -2.2554e-04, -3.5305e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0381,  0.0024, -0.0036,  ...,  0.0055,  0.0006,  0.0059],
        [-0.0006, -0.0387,  0.0049,  ..., -0.0049,  0.0033, -0.0034],
        [ 0.0054, -0.0074, -0.0396,  ...,  0.0015, -0.0038, -0.0012],
        ...,
        [ 0.0024,  0.0056,  0.0004,  ..., -0.0424,  0.0026, -0.0065],
        [-0.0088, -0.0012, -0.0024,  ..., -0.0001, -0.0352,  0.0020],
        [-0.0020, -0.0042, -0.0063,  ...,  0.0033, -0.0001, -0.0293]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0346, -0.0013,  0.0024,  ...,  0.0003,  0.0009, -0.0007],
        [ 0.0024, -0.0345, -0.0040,  ...,  0.0013,  0.0056, -0.0003],
        [-0.0055, -0.0019, -0.0308,  ..., -0.0008, -0.0036,  0.0008],
        ...,
        [-0.0011,  0.0005,  0.0029,  ..., -0.0320, -0.0018, -0.0011],
        [-0.0005,  0.0017,  0.0016,  ..., -0.0031, -0.0299,  0.0054],
        [-0.0004, -0.0023, -0.0018,  ...,  0.0054,  0.0018, -0.0298]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:30:29 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 09:30:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4775,  0.4448,  0.0961,  ..., -0.2261, -0.5488, -0.3721],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7690, -0.1350,  0.3855,  ..., -0.1165, -0.6006, -0.3445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2734,  0.8877,  0.1641,  ..., -0.2729, -0.7129, -0.0715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5967,  0.0587,  0.1609,  ..., -0.6992, -0.3767,  0.1045],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:30:29 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:30:29 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 09:30:53 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 09:31:17 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 09:31:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.0054e-03, -1.8358e-05, -4.9686e-04,  ..., -9.8991e-04,
         -1.8656e-04, -7.1621e-04],
        [ 1.0500e-03, -4.6844e-03, -1.4305e-05,  ...,  8.2874e-04,
         -3.3522e-04, -7.0858e-04],
        [-8.7738e-04, -1.9598e-04, -4.2610e-03,  ..., -1.1289e-04,
         -1.2264e-03,  2.4247e-04],
        ...,
        [-4.0913e-04, -6.7091e-04, -3.6287e-04,  ..., -3.8319e-03,
         -1.8616e-03, -6.1452e-05],
        [ 2.6059e-04,  3.7050e-04,  1.0042e-03,  ...,  4.5156e-04,
         -3.2444e-03,  3.9911e-04],
        [-8.9121e-04, -6.3896e-04, -1.1563e-04,  ..., -1.8358e-03,
          3.6907e-04, -3.8452e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0700,  0.0051, -0.0055,  ...,  0.0028,  0.0041, -0.0131],
        [ 0.0033, -0.0671, -0.0068,  ...,  0.0124,  0.0054,  0.0008],
        [-0.0093, -0.0002, -0.0572,  ..., -0.0043, -0.0001,  0.0038],
        ...,
        [ 0.0063,  0.0025,  0.0066,  ..., -0.0624, -0.0115,  0.0065],
        [ 0.0079, -0.0041, -0.0037,  ...,  0.0044, -0.0612, -0.0016],
        [-0.0010,  0.0007, -0.0058,  ...,  0.0085,  0.0068, -0.0654]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0696,  0.0017, -0.0069,  ..., -0.0005,  0.0063,  0.0003],
        [-0.0009, -0.0800, -0.0084,  ...,  0.0059,  0.0037,  0.0033],
        [ 0.0056,  0.0018, -0.0584,  ...,  0.0029, -0.0066, -0.0073],
        ...,
        [ 0.0015,  0.0101,  0.0036,  ..., -0.0754, -0.0079, -0.0053],
        [-0.0057,  0.0009,  0.0029,  ...,  0.0040, -0.0723,  0.0023],
        [ 0.0025,  0.0005,  0.0009,  ..., -0.0036,  0.0078, -0.0759]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:31:44 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 09:31:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2095,  0.6001,  0.3425,  ..., -0.0320, -0.4600,  0.0159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9858,  0.2350,  0.3806,  ...,  0.2769, -0.7178, -0.1859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0261,  0.3008,  0.3828,  ...,  0.1748, -0.3740, -0.5723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8511,  0.2883, -0.0372,  ..., -0.6880, -0.5010,  0.9683],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:31:44 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:31:44 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 09:32:10 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 09:32:36 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 09:33:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.8828e-03,  8.2970e-05, -2.2964e-03,  ...,  1.1568e-03,
         -3.3927e-04, -1.2321e-03],
        [-2.9802e-04, -6.3324e-03,  1.2732e-03,  ...,  6.0654e-04,
         -4.4346e-04,  1.8919e-04],
        [-7.7128e-05, -5.8365e-04, -4.5586e-03,  ...,  1.0777e-04,
         -9.6369e-04,  7.1883e-05],
        ...,
        [-4.7898e-04,  1.1616e-03, -1.0433e-03,  ..., -4.8027e-03,
          3.1757e-04, -1.8091e-03],
        [-1.7290e-03, -6.1691e-05, -1.1463e-03,  ..., -1.3340e-04,
         -3.4904e-03, -5.4264e-04],
        [ 8.0681e-04, -1.6422e-03,  1.5898e-03,  ...,  2.6035e-04,
          3.5524e-04, -4.4403e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0395, -0.0040, -0.0047,  ..., -0.0028, -0.0050,  0.0004],
        [ 0.0001, -0.0337,  0.0029,  ..., -0.0004, -0.0066,  0.0055],
        [ 0.0029, -0.0077, -0.0320,  ..., -0.0015, -0.0054, -0.0008],
        ...,
        [-0.0026, -0.0037,  0.0001,  ..., -0.0395, -0.0026,  0.0018],
        [-0.0080, -0.0098, -0.0006,  ...,  0.0033, -0.0390,  0.0048],
        [-0.0022, -0.0035,  0.0051,  ...,  0.0007, -0.0111, -0.0348]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.8757e-02,  2.5272e-03, -7.9441e-04,  ...,  1.3380e-03,
         -6.1989e-06, -2.6436e-03],
        [ 4.9438e-03, -3.0396e-02,  3.4008e-03,  ..., -1.8578e-03,
         -4.0174e-04,  5.3749e-03],
        [ 2.8267e-03,  2.2545e-03, -3.2776e-02,  ..., -7.6370e-03,
          2.7752e-03,  4.5128e-03],
        ...,
        [-1.5240e-03, -1.3685e-03, -8.0719e-03,  ..., -3.1097e-02,
          2.0695e-04, -2.0714e-03],
        [-4.2801e-03,  4.9744e-03,  7.4959e-03,  ...,  1.8616e-03,
         -2.3560e-02,  2.2817e-04],
        [-5.7411e-03,  4.2458e-03,  5.5313e-03,  ...,  8.1062e-05,
          8.2855e-03, -2.9572e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:33:04 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 09:33:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4048,  1.1992,  0.2158,  ..., -0.3550, -0.9697, -0.1412],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9360,  0.0721,  0.2462,  ..., -1.0059, -0.5718,  0.1321],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2776,  0.1965,  0.4199,  ..., -0.1411, -0.0566, -0.2739],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7749,  0.8818,  0.3291,  ..., -1.1328, -0.0466,  0.7939],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:33:04 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:33:04 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 09:33:34 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 09:34:04 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 09:34:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3123e-03,  1.6117e-04,  1.4095e-03,  ..., -2.0850e-04,
          3.0823e-03,  3.0994e-04],
        [ 2.4872e-03, -4.7760e-03,  1.4877e-04,  ..., -1.9608e-03,
          1.5574e-03,  5.9605e-04],
        [-1.5106e-03, -5.9938e-04, -2.9774e-03,  ...,  1.5850e-03,
          1.4305e-03,  7.5531e-04],
        ...,
        [-1.5259e-04, -2.6093e-03, -1.1539e-03,  ..., -4.1962e-03,
         -5.5313e-05,  2.0230e-04],
        [ 1.8797e-03, -6.7806e-04, -6.1941e-04,  ..., -8.7500e-04,
         -1.5182e-03, -1.3912e-04],
        [ 1.2693e-03, -2.3899e-03,  4.8971e-04,  ...,  8.3733e-04,
          1.5230e-03, -3.5954e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0459,  0.0037,  0.0066,  ...,  0.0154, -0.0001, -0.0009],
        [ 0.0035, -0.0471,  0.0045,  ...,  0.0122,  0.0120, -0.0091],
        [-0.0120,  0.0109, -0.0426,  ...,  0.0008, -0.0033,  0.0190],
        ...,
        [-0.0083,  0.0079,  0.0016,  ..., -0.0300, -0.0026, -0.0050],
        [-0.0071, -0.0083,  0.0004,  ...,  0.0023, -0.0364,  0.0010],
        [ 0.0032, -0.0029, -0.0030,  ...,  0.0044,  0.0005, -0.0435]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0548, -0.0013,  0.0040,  ..., -0.0028,  0.0032,  0.0034],
        [ 0.0036, -0.0348, -0.0030,  ...,  0.0054,  0.0108, -0.0064],
        [ 0.0010, -0.0028, -0.0465,  ...,  0.0005, -0.0022,  0.0060],
        ...,
        [-0.0094, -0.0014,  0.0002,  ..., -0.0404,  0.0038, -0.0014],
        [ 0.0005,  0.0009, -0.0029,  ..., -0.0073, -0.0347,  0.0036],
        [ 0.0006, -0.0020, -0.0027,  ..., -0.0068, -0.0019, -0.0461]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:34:29 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 09:34:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0461,  0.2979,  0.4111,  ...,  0.1709, -0.3914, -0.7046],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9565,  0.2937, -0.0317,  ..., -0.7305, -0.5288,  1.0889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5493,  0.2119,  0.8027,  ..., -0.3237,  0.3516, -0.4666],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6982,  0.5527,  0.3794,  ..., -0.6206, -0.0192,  0.5322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:34:29 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:34:29 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 09:35:02 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 09:35:34 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 09:36:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0008,  0.0029, -0.0039,  ..., -0.0001, -0.0022,  0.0021],
        [-0.0014, -0.0003, -0.0006,  ...,  0.0007,  0.0002,  0.0023],
        [ 0.0016,  0.0002, -0.0013,  ..., -0.0013,  0.0010, -0.0012],
        ...,
        [ 0.0004,  0.0026, -0.0004,  ..., -0.0028, -0.0056,  0.0011],
        [ 0.0003,  0.0017, -0.0002,  ...,  0.0028,  0.0027, -0.0004],
        [-0.0005, -0.0011, -0.0001,  ..., -0.0002, -0.0022,  0.0009]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0729,  0.0113, -0.0021,  ..., -0.0034, -0.0105, -0.0067],
        [ 0.0083, -0.0706,  0.0083,  ..., -0.0023,  0.0078,  0.0165],
        [-0.0025, -0.0204, -0.0617,  ...,  0.0088,  0.0101,  0.0086],
        ...,
        [-0.0043,  0.0003, -0.0056,  ..., -0.0638, -0.0044, -0.0045],
        [ 0.0197, -0.0071, -0.0085,  ..., -0.0014, -0.0847,  0.0074],
        [-0.0054,  0.0026,  0.0185,  ..., -0.0013, -0.0039, -0.0853]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0892, -0.0025,  0.0044,  ..., -0.0033, -0.0056,  0.0018],
        [-0.0085, -0.0986,  0.0021,  ..., -0.0061, -0.0034,  0.0011],
        [-0.0044, -0.0008, -0.0928,  ...,  0.0008,  0.0072,  0.0051],
        ...,
        [-0.0034,  0.0006,  0.0008,  ..., -0.0854,  0.0088,  0.0062],
        [ 0.0007, -0.0033,  0.0028,  ...,  0.0031, -0.0961,  0.0078],
        [ 0.0060,  0.0042,  0.0079,  ..., -0.0076, -0.0074, -0.1003]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:36:10 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 09:36:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3008,  0.1925,  0.4092,  ..., -0.1421, -0.0808, -0.3223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8477,  0.9766,  0.3372,  ..., -1.1787, -0.0637,  0.8677],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3643, -0.1885,  0.3396,  ..., -0.1218,  0.4600, -1.0830],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1289,  0.0537,  0.3433,  ..., -0.1704,  0.0108,  0.0479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:36:10 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:36:10 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 09:36:45 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 09:37:20 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 09:37:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.7880e-03, -9.4366e-04,  2.8057e-03,  ..., -6.0368e-04,
          3.0060e-03, -1.7471e-03],
        [ 4.2152e-03, -6.8245e-03,  2.2717e-03,  ..., -4.4584e-05,
          1.4420e-03, -7.5293e-04],
        [-2.8973e-03,  1.3952e-03, -2.3155e-03,  ...,  2.8801e-04,
         -6.0368e-04, -9.5963e-05],
        ...,
        [ 9.5272e-04, -1.1387e-03,  4.7684e-07,  ..., -2.3994e-03,
         -1.4153e-03,  3.3073e-03],
        [ 2.4929e-03, -2.4509e-03,  1.6460e-03,  ..., -5.1641e-04,
         -2.7428e-03, -2.7943e-04],
        [ 8.0013e-04, -1.8959e-03,  1.3113e-05,  ...,  1.3185e-04,
         -1.9226e-03, -1.5812e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0636,  0.0023, -0.0074,  ..., -0.0062,  0.0120,  0.0010],
        [ 0.0179, -0.0822, -0.0003,  ...,  0.0018, -0.0113, -0.0075],
        [ 0.0097,  0.0127, -0.0801,  ...,  0.0100,  0.0035, -0.0011],
        ...,
        [ 0.0083, -0.0063,  0.0060,  ..., -0.0627,  0.0067, -0.0086],
        [-0.0089,  0.0066,  0.0111,  ...,  0.0015, -0.0826,  0.0041],
        [-0.0003,  0.0144,  0.0098,  ..., -0.0010, -0.0033, -0.0703]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0966, -0.0025, -0.0020,  ..., -0.0005,  0.0021,  0.0032],
        [ 0.0022, -0.1057, -0.0067,  ..., -0.0009, -0.0061,  0.0050],
        [ 0.0035, -0.0052, -0.1021,  ...,  0.0063,  0.0050, -0.0046],
        ...,
        [ 0.0090,  0.0003,  0.0040,  ..., -0.0996,  0.0011, -0.0060],
        [-0.0063, -0.0054, -0.0032,  ...,  0.0061, -0.0992, -0.0015],
        [-0.0041,  0.0029, -0.0091,  ..., -0.0092,  0.0050, -0.1141]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:37:58 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 09:37:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5166,  0.2089,  0.6777,  ..., -0.3110,  0.3118, -0.4824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6943,  0.5796,  0.3398,  ..., -0.6016, -0.0209,  0.5103],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3208, -0.3835,  0.1487,  ...,  0.1107,  1.1387, -0.3896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0771,  0.1628,  0.7969,  ..., -0.1277,  0.1887, -0.2952],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:37:58 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:37:58 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 09:38:38 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 09:39:15 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 09:39:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0037,  0.0004, -0.0015,  ..., -0.0017, -0.0019, -0.0009],
        [ 0.0017, -0.0028, -0.0017,  ...,  0.0017,  0.0025,  0.0007],
        [ 0.0011, -0.0015, -0.0017,  ..., -0.0016, -0.0013,  0.0024],
        ...,
        [ 0.0017,  0.0006,  0.0009,  ..., -0.0029,  0.0027,  0.0022],
        [-0.0007,  0.0017, -0.0021,  ...,  0.0009,  0.0003, -0.0005],
        [ 0.0012, -0.0004,  0.0018,  ...,  0.0002,  0.0044, -0.0025]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0912,  0.0019,  0.0041,  ..., -0.0032, -0.0001,  0.0042],
        [-0.0047, -0.0866, -0.0071,  ..., -0.0087, -0.0016,  0.0021],
        [ 0.0113, -0.0156, -0.0707,  ..., -0.0085,  0.0064,  0.0010],
        ...,
        [-0.0102,  0.0072,  0.0163,  ..., -0.0688, -0.0101, -0.0134],
        [ 0.0140, -0.0037, -0.0032,  ...,  0.0110, -0.0792,  0.0110],
        [-0.0029,  0.0068,  0.0041,  ...,  0.0095, -0.0009, -0.0782]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.4727e-02,  5.8479e-03,  6.8245e-03,  ..., -3.3340e-03,
         -3.4065e-03, -4.5815e-03],
        [ 2.5654e-03, -8.5388e-02, -9.2392e-03,  ...,  4.7073e-03,
          6.2370e-03, -1.0399e-02],
        [ 9.4376e-03,  1.5354e-03, -8.9478e-02,  ...,  4.0512e-03,
          8.1921e-04,  5.0201e-03],
        ...,
        [-5.1727e-03, -4.2076e-03, -1.3504e-03,  ..., -9.2346e-02,
          8.4534e-03,  2.9640e-03],
        [ 1.4954e-03,  7.4883e-03, -6.3515e-04,  ...,  1.0078e-02,
         -8.3557e-02, -6.2332e-03],
        [ 1.9283e-03, -9.4833e-03,  7.2823e-03,  ...,  8.9645e-05,
         -1.6737e-03, -8.3374e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:39:57 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 09:39:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3245, -0.1858,  0.2695,  ..., -0.1068,  0.3838, -1.0029],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0713,  0.0468,  0.3008,  ..., -0.1503,  0.0060,  0.0281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1581, -0.3887, -0.0293,  ..., -0.4810,  0.7412, -0.2144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8174, -0.1125,  0.2881,  ..., -0.4309,  0.0498,  0.1936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:39:57 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:39:57 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 09:40:38 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 09:41:19 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 09:42:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.3455e-03, -5.0068e-04,  1.2960e-03,  ..., -1.3847e-03,
         -4.9591e-05, -2.9640e-03],
        [ 1.1597e-03,  9.8133e-04,  1.5354e-04,  ..., -5.9814e-03,
          2.3136e-03,  5.0449e-04],
        [-2.1572e-03,  3.7670e-04,  1.5650e-03,  ...,  9.5081e-04,
         -1.0319e-03, -3.5114e-03],
        ...,
        [-2.6679e-04, -1.4658e-03,  4.6844e-03,  ..., -2.8944e-04,
         -7.0286e-04, -7.7677e-04],
        [ 9.1314e-04, -3.3283e-04, -1.6346e-03,  ..., -1.0133e-06,
         -4.9667e-03, -6.6996e-04],
        [ 2.1248e-03,  2.7895e-04,  1.3075e-03,  ...,  1.0986e-03,
          1.3866e-03, -4.9286e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.8745e-02,  2.6932e-03,  4.4060e-03,  ...,  2.6340e-03,
         -9.4147e-03, -3.2768e-03],
        [ 5.7487e-03, -9.9854e-02,  1.3687e-02,  ...,  6.5765e-03,
         -4.4899e-03,  1.0239e-02],
        [-4.7150e-03, -4.4746e-03, -7.5073e-02,  ..., -1.5650e-03,
         -2.5959e-03, -1.6861e-02],
        ...,
        [-2.7142e-03,  1.9188e-03, -1.9112e-03,  ..., -1.0669e-01,
          1.5774e-03,  3.8719e-03],
        [ 3.1757e-03,  7.9956e-03, -3.1090e-03,  ..., -1.6327e-02,
         -8.0444e-02, -8.4686e-04],
        [ 1.5144e-03,  5.0068e-05,  4.5509e-03,  ..., -9.0714e-03,
          6.2218e-03, -1.0626e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1064,  0.0059, -0.0099,  ..., -0.0016,  0.0072, -0.0078],
        [ 0.0035, -0.1251,  0.0030,  ..., -0.0110, -0.0044,  0.0098],
        [-0.0068, -0.0020, -0.1174,  ..., -0.0092, -0.0103,  0.0087],
        ...,
        [ 0.0023,  0.0107, -0.0060,  ..., -0.1070, -0.0041,  0.0002],
        [-0.0051,  0.0065, -0.0050,  ..., -0.0018, -0.0985,  0.0056],
        [-0.0089,  0.0006, -0.0101,  ...,  0.0017,  0.0044, -0.1246]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:42:04 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 09:42:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2629, -0.2996,  0.0519,  ...,  0.0543,  0.8057, -0.3181],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9458,  0.1418,  0.6060,  ..., -0.1202,  0.1439, -0.2739],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8462, -0.3359,  0.3345,  ..., -0.4937,  1.1025, -1.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9131,  0.1792,  0.9746,  ...,  0.0315, -0.1665,  0.1506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:42:04 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:42:04 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 09:42:51 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 09:43:37 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 09:44:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0039,  0.0005,  0.0019,  ..., -0.0009, -0.0024, -0.0028],
        [ 0.0029, -0.0025, -0.0013,  ...,  0.0007, -0.0048,  0.0050],
        [-0.0029,  0.0017,  0.0012,  ..., -0.0009,  0.0020,  0.0026],
        ...,
        [ 0.0024, -0.0044,  0.0013,  ...,  0.0031, -0.0011, -0.0013],
        [-0.0043,  0.0020,  0.0024,  ...,  0.0037, -0.0047, -0.0016],
        [ 0.0027, -0.0023,  0.0043,  ..., -0.0034,  0.0026,  0.0046]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0853, -0.0130, -0.0081,  ..., -0.0076, -0.0039, -0.0034],
        [ 0.0005, -0.0896, -0.0112,  ...,  0.0089,  0.0037,  0.0077],
        [ 0.0060,  0.0021, -0.0847,  ...,  0.0190, -0.0173,  0.0013],
        ...,
        [-0.0068,  0.0089,  0.0069,  ..., -0.0948,  0.0032,  0.0064],
        [-0.0003,  0.0077,  0.0053,  ...,  0.0133, -0.0908,  0.0090],
        [ 0.0059, -0.0088, -0.0073,  ..., -0.0077, -0.0026, -0.0815]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.7004e-01,  9.8991e-04,  6.5804e-03,  ...,  1.9646e-03,
         -4.4556e-03,  4.8876e-04],
        [-5.6152e-03, -1.6650e-01, -5.5161e-03,  ...,  1.0910e-02,
          8.9874e-03,  5.2261e-03],
        [-4.4403e-03, -8.7280e-03, -1.4917e-01,  ...,  9.4299e-03,
         -5.5618e-03, -9.1248e-03],
        ...,
        [ 1.1396e-03,  2.4170e-02,  9.7885e-03,  ..., -1.6345e-01,
          2.7657e-05,  7.8430e-03],
        [ 1.3752e-03,  8.3542e-03,  1.2131e-02,  ..., -9.3155e-03,
         -1.6296e-01,  4.3869e-04],
        [-3.1509e-03,  3.2425e-04,  7.5073e-03,  ..., -1.6663e-02,
         -2.5406e-03, -1.4917e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:44:27 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 09:44:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1066, -0.2859, -0.0599,  ..., -0.3010,  0.4722, -0.1943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6709, -0.1086,  0.1907,  ..., -0.3242,  0.0264,  0.1215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0386,  0.1274,  0.4614,  ..., -0.7275,  1.2676, -1.5947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7236, -0.2666,  0.4121,  ..., -0.0096, -0.2410,  0.2415],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:44:27 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:44:27 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 09:45:18 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 09:45:59 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 09:46:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.9875e-03, -5.5599e-04, -3.7813e-04,  ..., -1.1330e-03,
         -4.7135e-04,  1.5478e-03],
        [-2.0962e-03,  4.2839e-03,  3.6659e-03,  ...,  2.7962e-03,
          1.1768e-03,  1.7710e-03],
        [ 4.3225e-04, -3.3073e-03, -2.9755e-03,  ..., -1.4343e-03,
          4.0913e-04, -2.0278e-04],
        ...,
        [ 3.0632e-03,  6.7186e-04,  4.5815e-03,  ..., -3.2272e-03,
         -4.2572e-03,  2.0838e-04],
        [-2.0790e-03, -1.0681e-03,  1.5812e-03,  ...,  4.6654e-03,
          9.6560e-05,  3.2406e-03],
        [-1.6994e-03, -1.3447e-03, -1.5440e-03,  ...,  2.1172e-03,
         -2.1439e-03, -1.6212e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.6782e-02,  7.2899e-03,  1.7548e-02,  ...,  3.1166e-03,
          2.7618e-03, -1.8520e-03],
        [ 1.7595e-03, -1.1102e-01,  1.5015e-02,  ...,  1.6451e-03,
         -5.0507e-03, -7.2708e-03],
        [-4.0970e-03, -5.4703e-03, -8.7402e-02,  ...,  6.2943e-05,
         -5.6458e-03, -2.2583e-03],
        ...,
        [-3.6678e-03, -1.1627e-02,  4.5624e-03,  ..., -9.3628e-02,
          9.4452e-03, -2.2217e-02],
        [ 1.2657e-02, -2.9564e-04,  9.0408e-03,  ..., -4.0550e-03,
         -8.6121e-02,  1.2436e-02],
        [ 1.0742e-02,  9.8515e-04,  4.1122e-03,  ...,  1.1864e-02,
          3.0708e-03, -8.1848e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1026, -0.0015,  0.0068,  ...,  0.0046, -0.0056, -0.0033],
        [ 0.0111, -0.0987, -0.0039,  ..., -0.0094, -0.0131, -0.0034],
        [-0.0066,  0.0040, -0.1056,  ...,  0.0058, -0.0034,  0.0133],
        ...,
        [-0.0019, -0.0015,  0.0083,  ..., -0.0890,  0.0049, -0.0051],
        [ 0.0097, -0.0183, -0.0097,  ...,  0.0124, -0.1020, -0.0021],
        [ 0.0077, -0.0013,  0.0067,  ...,  0.0089, -0.0028, -0.1068]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:46:51 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 09:46:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5483, -0.2372,  0.1481,  ..., -0.3293,  0.6465, -0.9058],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7026,  0.1191,  0.6484,  ..., -0.0095, -0.1416,  0.1186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0158, -0.0444, -0.4360,  ..., -0.5542,  1.1299, -0.7998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8813,  0.0156,  0.5127,  ...,  0.6846, -0.0226,  0.2230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:46:51 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:46:51 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 09:47:44 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 09:48:36 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 09:49:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.3357e-03, -3.4237e-04, -7.4291e-04,  ...,  1.3626e-04,
          2.9030e-03, -6.6090e-04],
        [-1.2474e-03,  7.6141e-03, -3.5942e-05,  ...,  3.0231e-03,
         -1.2767e-04,  1.6947e-03],
        [-1.4715e-03, -1.6441e-03,  6.4888e-03,  ..., -1.8492e-03,
          4.3869e-03,  2.0733e-03],
        ...,
        [ 8.6844e-05,  2.3823e-03,  5.8365e-03,  ...,  8.5220e-03,
         -3.7384e-03,  4.3106e-03],
        [-3.1490e-03, -8.3256e-04, -2.4185e-03,  ..., -5.0392e-03,
          1.0391e-02,  1.0815e-03],
        [ 3.2330e-04,  1.3714e-03,  5.7220e-04,  ...,  5.3787e-04,
          3.2711e-04,  4.7493e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.5576e-01,  5.9700e-03, -8.4534e-03,  ..., -2.5986e-02,
         -1.2054e-02,  1.3290e-02],
        [ 1.1032e-02, -1.5393e-01, -1.2634e-02,  ..., -1.1349e-03,
          2.0332e-03, -1.2199e-02],
        [-1.8616e-03, -1.6312e-02, -1.5491e-01,  ..., -5.9509e-04,
         -5.0888e-03, -1.5419e-02],
        ...,
        [-1.3695e-02, -6.4240e-03,  1.9730e-02,  ..., -1.5076e-01,
          8.9722e-03,  7.2861e-03],
        [-1.2039e-02,  7.6294e-03, -2.3842e-05,  ...,  4.6997e-03,
         -1.3977e-01,  8.7433e-03],
        [ 3.0289e-03, -1.4610e-03, -9.6741e-03,  ...,  5.6410e-04,
         -2.5768e-03, -1.3538e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2170,  0.0157,  0.0125,  ..., -0.0120, -0.0119, -0.0009],
        [ 0.0009, -0.2407, -0.0153,  ..., -0.0002,  0.0099, -0.0032],
        [-0.0013,  0.0090, -0.2172,  ...,  0.0090,  0.0031, -0.0141],
        ...,
        [ 0.0012, -0.0062, -0.0022,  ..., -0.2437,  0.0119, -0.0083],
        [ 0.0023,  0.0013, -0.0111,  ...,  0.0156, -0.2302,  0.0024],
        [ 0.0028, -0.0079, -0.0046,  ..., -0.0021,  0.0030, -0.2256]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:49:32 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 09:49:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0564,  0.0610,  0.2197,  ..., -0.4521,  0.7690, -1.0811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6162, -0.2316,  0.2671,  ..., -0.0115, -0.2009,  0.1473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0633, -0.1150, -1.1084,  ..., -1.0283,  1.3691, -0.1899],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9131,  0.7236,  1.4902,  ...,  0.3728,  1.1904,  0.5664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:49:32 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:49:32 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 09:50:24 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 09:51:20 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 09:52:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0067,  0.0041,  0.0016,  ..., -0.0007, -0.0005, -0.0046],
        [-0.0008, -0.0104,  0.0018,  ..., -0.0022, -0.0041,  0.0004],
        [ 0.0006,  0.0030, -0.0058,  ..., -0.0011, -0.0025, -0.0014],
        ...,
        [-0.0005, -0.0018, -0.0039,  ..., -0.0055,  0.0001, -0.0002],
        [ 0.0002,  0.0007, -0.0025,  ..., -0.0035, -0.0075,  0.0013],
        [ 0.0026,  0.0022,  0.0002,  ...,  0.0004,  0.0008, -0.0088]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0643,  0.0076,  0.0235,  ...,  0.0167, -0.0007, -0.0081],
        [ 0.0051, -0.0729,  0.0063,  ..., -0.0109,  0.0015,  0.0036],
        [-0.0003, -0.0023, -0.0834,  ...,  0.0091,  0.0096,  0.0189],
        ...,
        [-0.0078, -0.0005,  0.0028,  ..., -0.0670,  0.0030, -0.0107],
        [ 0.0038,  0.0021, -0.0113,  ...,  0.0041, -0.0934,  0.0155],
        [ 0.0036, -0.0076,  0.0049,  ..., -0.0030, -0.0006, -0.0684]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.4839e-02,  3.2043e-04,  8.3771e-03,  ..., -2.5463e-03,
          1.8702e-03,  8.6746e-03],
        [ 1.1368e-03, -8.3557e-02, -1.1940e-02,  ...,  2.2812e-03,
          1.4267e-02,  2.1782e-03],
        [ 1.3008e-03,  3.4523e-04, -8.7891e-02,  ..., -2.9049e-03,
         -1.3321e-02,  7.2861e-03],
        ...,
        [-3.1853e-03, -1.1055e-02, -3.6545e-03,  ..., -7.2998e-02,
          5.1041e-03, -3.0289e-03],
        [-7.0419e-03,  7.5951e-03, -5.3406e-05,  ..., -2.4605e-04,
         -8.2581e-02,  8.5678e-03],
        [ 7.4310e-03,  5.1880e-04,  3.0041e-03,  ..., -1.1768e-03,
          9.3613e-03, -7.8796e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:52:17 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 09:52:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0025, -0.0670, -0.2590,  ..., -0.3367,  0.6587, -0.5059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6602, -0.0240,  0.3450,  ...,  0.4600, -0.0117,  0.1432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1166, -0.5347, -1.8672,  ..., -0.9077,  1.1182, -0.0920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4570, -0.0400,  0.4785,  ...,  0.8428,  2.1133,  0.4976],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:52:17 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:52:17 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 09:53:13 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 09:54:11 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 09:55:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0056, -0.0009, -0.0020,  ..., -0.0009,  0.0017, -0.0015],
        [-0.0027,  0.0115,  0.0017,  ...,  0.0026, -0.0026, -0.0103],
        [-0.0001, -0.0026, -0.0063,  ..., -0.0029, -0.0027, -0.0013],
        ...,
        [-0.0041,  0.0009,  0.0023,  ...,  0.0053, -0.0048,  0.0080],
        [ 0.0069,  0.0013,  0.0045,  ...,  0.0041, -0.0126, -0.0018],
        [ 0.0004,  0.0078,  0.0021,  ..., -0.0063, -0.0044, -0.0039]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1161, -0.0015, -0.0169,  ..., -0.0204,  0.0062,  0.0075],
        [-0.0146, -0.1204,  0.0008,  ...,  0.0054,  0.0097,  0.0142],
        [ 0.0087, -0.0009, -0.1182,  ...,  0.0098,  0.0095, -0.0084],
        ...,
        [-0.0127,  0.0032,  0.0057,  ..., -0.1014, -0.0012,  0.0116],
        [ 0.0047,  0.0221,  0.0031,  ...,  0.0108, -0.1181, -0.0084],
        [-0.0003,  0.0037, -0.0019,  ..., -0.0044,  0.0175, -0.1163]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1400,  0.0024,  0.0025,  ..., -0.0008,  0.0068,  0.0064],
        [-0.0290, -0.1476,  0.0033,  ...,  0.0107, -0.0006,  0.0232],
        [ 0.0017,  0.0052, -0.1395,  ..., -0.0006, -0.0022, -0.0008],
        ...,
        [-0.0103, -0.0021, -0.0029,  ..., -0.1417, -0.0038,  0.0073],
        [ 0.0107,  0.0143, -0.0002,  ...,  0.0142, -0.1537,  0.0134],
        [-0.0056, -0.0015,  0.0082,  ..., -0.0062,  0.0127, -0.1492]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:55:11 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 09:55:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0656, -0.0834, -0.5884,  ..., -0.5576,  0.7598, -0.1642],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5776,  0.4155,  0.8174,  ...,  0.2035,  0.7471,  0.2910],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0732,  0.0771, -1.2295,  ..., -1.7334,  1.1992, -0.0953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6133, -0.2151,  0.4697,  ...,  0.4297,  0.9199,  0.0967],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:55:11 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:55:12 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 09:56:07 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 09:57:06 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 09:58:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0077, -0.0024, -0.0015,  ..., -0.0044, -0.0094, -0.0013],
        [-0.0066,  0.0062, -0.0048,  ..., -0.0023,  0.0016,  0.0004],
        [-0.0021, -0.0011,  0.0084,  ..., -0.0029, -0.0025,  0.0018],
        ...,
        [ 0.0079, -0.0009, -0.0030,  ...,  0.0130, -0.0048, -0.0013],
        [ 0.0029, -0.0043,  0.0013,  ...,  0.0019,  0.0131,  0.0043],
        [ 0.0035,  0.0056, -0.0066,  ..., -0.0016,  0.0021,  0.0081]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0887,  0.0166,  0.0087,  ...,  0.0054,  0.0081, -0.0020],
        [ 0.0085, -0.0961, -0.0081,  ..., -0.0064,  0.0091,  0.0041],
        [-0.0037,  0.0001, -0.0908,  ...,  0.0070,  0.0024, -0.0101],
        ...,
        [ 0.0092, -0.0198, -0.0123,  ..., -0.0810,  0.0242, -0.0037],
        [-0.0071,  0.0103, -0.0139,  ...,  0.0092, -0.0784, -0.0063],
        [-0.0049,  0.0057, -0.0118,  ..., -0.0049, -0.0067, -0.0808]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1133e-01,  1.5011e-03, -1.4343e-02,  ..., -1.4061e-02,
          4.7760e-03, -4.7188e-03],
        [ 2.0844e-02, -1.0394e-01, -3.7899e-03,  ...,  1.5717e-02,
          2.6379e-03,  3.9330e-03],
        [ 6.7520e-03, -8.4229e-03, -9.7900e-02,  ...,  2.5444e-03,
         -1.6975e-03, -8.3313e-03],
        ...,
        [-6.6643e-03, -1.0605e-02,  7.5150e-04,  ..., -1.1096e-01,
          1.7517e-02,  8.7261e-05],
        [-1.0994e-02,  4.0398e-03, -1.7853e-02,  ...,  3.9597e-03,
         -9.9426e-02,  1.7500e-03],
        [-1.1444e-02,  4.7379e-03, -2.3994e-03,  ..., -1.1436e-02,
          3.6373e-03, -1.0242e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 09:58:07 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 09:58:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0673, -0.2979, -0.8682,  ..., -0.4473,  0.5425, -0.0822],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8672, -0.0544,  0.2649,  ...,  0.4636,  1.2129,  0.2581],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2090,  0.3672, -1.3359,  ..., -1.7139,  1.4678,  0.2803],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7959, -0.4385, -0.2017,  ...,  1.5059,  0.7959, -0.0662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 09:58:07 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 09:58:07 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 09:59:09 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 10:00:11 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 10:01:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.2910e-03,  3.0670e-03, -2.8038e-04,  ...,  2.3308e-03,
          6.0415e-04,  2.7027e-03],
        [ 3.0441e-03,  2.4872e-03,  1.9989e-03,  ...,  1.1909e-04,
          7.3957e-04, -1.6832e-04],
        [ 5.6505e-04,  6.1607e-04,  1.5278e-03,  ...,  1.3428e-03,
         -2.0180e-03,  6.3229e-04],
        ...,
        [-4.3058e-04, -3.2406e-03,  9.9182e-05,  ..., -1.0681e-03,
         -4.4403e-03, -3.0494e-04],
        [ 5.9242e-03,  3.2482e-03,  1.9379e-03,  ...,  3.0556e-03,
          5.8031e-04,  4.0398e-03],
        [-3.2330e-03, -2.1496e-03,  3.2806e-03,  ..., -3.2187e-04,
         -2.8849e-05,  1.1845e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.4106e-02, -7.6294e-03, -1.1795e-02,  ..., -6.1188e-03,
          3.3550e-03,  8.6899e-03],
        [-1.1688e-02, -1.0571e-01, -1.1444e-05,  ...,  6.3400e-03,
          1.4038e-03, -5.0926e-03],
        [ 1.1169e-02,  2.2354e-03, -1.0571e-01,  ...,  1.7853e-03,
          4.9286e-03,  5.4016e-03],
        ...,
        [ 2.3918e-03,  1.6159e-02,  1.9588e-03,  ..., -9.7839e-02,
          6.3477e-03,  1.3695e-02],
        [ 1.1292e-02,  1.2611e-02,  7.3242e-04,  ...,  1.4984e-02,
         -1.1206e-01, -2.1973e-03],
        [ 8.7585e-03,  3.6964e-03,  8.2321e-03,  ...,  1.2192e-02,
          2.5864e-03, -8.6426e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0577e-01, -3.4428e-04, -1.3641e-02,  ...,  5.8670e-03,
         -1.8692e-02,  1.7986e-03],
        [-1.0242e-03, -1.1621e-01, -2.5673e-03,  ...,  6.8283e-04,
         -3.8719e-03,  4.8752e-03],
        [-1.3332e-03, -1.3939e-02, -1.2286e-01,  ..., -3.1929e-03,
          6.6757e-03,  1.3027e-03],
        ...,
        [ 2.7885e-03,  2.3975e-03, -5.3940e-03,  ..., -1.0120e-01,
         -2.9202e-03,  8.2970e-05],
        [ 3.0060e-03,  2.9449e-03, -1.6510e-02,  ...,  1.4999e-02,
         -1.2042e-01,  9.3918e-03],
        [ 1.8036e-02,  7.5607e-03, -5.3406e-04,  ..., -8.1329e-03,
          1.8555e-02, -1.1041e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:01:15 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 10:01:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4819,  0.0379, -0.5830,  ..., -0.8276,  0.5757, -0.0767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3813, -0.1146,  0.2264,  ...,  0.2303,  0.5049,  0.0278],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3416,  0.2236, -1.0527,  ..., -1.3281,  1.0273,  0.3740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5781, -0.0571, -0.1522,  ...,  1.6572,  0.5903, -0.4231],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:01:15 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:01:15 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 10:02:17 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 10:03:24 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 10:04:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0058, -0.0046,  0.0047,  ..., -0.0011, -0.0004,  0.0005],
        [-0.0023, -0.0067,  0.0025,  ..., -0.0003,  0.0022,  0.0023],
        [-0.0007,  0.0015, -0.0120,  ...,  0.0003,  0.0004, -0.0023],
        ...,
        [ 0.0084,  0.0023, -0.0084,  ..., -0.0074, -0.0027, -0.0026],
        [ 0.0009,  0.0018, -0.0015,  ...,  0.0020, -0.0074, -0.0002],
        [ 0.0030,  0.0036, -0.0134,  ..., -0.0068, -0.0044, -0.0081]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.9092e-02,  4.2381e-03,  1.1589e-02,  ..., -1.8356e-02,
          3.5534e-03,  4.2725e-03],
        [-6.5231e-03, -5.6213e-02, -1.4160e-02,  ...,  9.3460e-05,
          4.9438e-03,  3.0212e-03],
        [-5.0011e-03,  1.1971e-02, -4.2755e-02,  ..., -1.1887e-02,
         -3.8414e-03, -1.8978e-03],
        ...,
        [-2.5482e-03,  1.3229e-02,  3.0441e-03,  ..., -6.4880e-02,
         -8.8348e-03, -1.4305e-02],
        [-2.6798e-04,  7.2250e-03, -5.6419e-03,  ...,  1.4130e-02,
         -6.1310e-02, -3.7289e-03],
        [-1.2703e-03,  7.0038e-03,  1.6998e-02,  ..., -1.2331e-03,
          3.1128e-03, -6.8298e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0751,  0.0102, -0.0029,  ..., -0.0044,  0.0113,  0.0112],
        [ 0.0044, -0.0787,  0.0045,  ...,  0.0012,  0.0101, -0.0012],
        [ 0.0007,  0.0112, -0.0837,  ..., -0.0023, -0.0202, -0.0107],
        ...,
        [-0.0188, -0.0032, -0.0028,  ..., -0.0923, -0.0040, -0.0063],
        [ 0.0027,  0.0184, -0.0051,  ...,  0.0092, -0.0839,  0.0092],
        [-0.0017, -0.0062,  0.0044,  ..., -0.0038, -0.0166, -0.0843]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:04:30 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 10:04:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0807,  0.1620, -0.5898,  ..., -0.7695,  0.6802,  0.0870],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4102, -0.2214, -0.0923,  ...,  0.7134,  0.4045, -0.0689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0442,  0.0631, -0.7939,  ..., -1.0820,  0.6123,  0.6167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.3320,  0.4590,  0.1578,  ...,  2.2461,  0.5068,  0.5254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:04:30 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:04:30 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 10:05:35 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 10:06:40 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 10:07:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2535e-02,  2.4071e-03,  8.9340e-03,  ...,  4.0703e-03,
          4.7207e-04,  4.1656e-03],
        [ 9.3603e-04, -1.1589e-02, -2.3060e-03,  ...,  3.3150e-03,
          3.6850e-03, -3.5667e-03],
        [ 2.9964e-03, -4.8141e-03, -1.2863e-02,  ...,  1.3113e-03,
          7.3433e-05, -2.1152e-03],
        ...,
        [-4.4441e-03, -6.7425e-04,  1.8129e-03,  ..., -8.7051e-03,
          5.6725e-03, -5.2338e-03],
        [ 8.9169e-04,  4.2877e-03, -3.6011e-03,  ...,  1.2608e-03,
         -1.3412e-02, -2.3117e-03],
        [ 2.6379e-03,  2.5997e-03,  1.1654e-03,  ..., -2.0847e-03,
          2.0146e-04, -1.2253e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0534, -0.0007,  0.0074,  ..., -0.0146, -0.0003,  0.0161],
        [-0.0140, -0.0554,  0.0026,  ..., -0.0131,  0.0170, -0.0078],
        [-0.0003, -0.0149, -0.0729,  ..., -0.0170,  0.0180,  0.0038],
        ...,
        [ 0.0013,  0.0041,  0.0045,  ..., -0.0401,  0.0085, -0.0058],
        [ 0.0151, -0.0171, -0.0073,  ..., -0.0003, -0.0525, -0.0018],
        [-0.0086,  0.0103,  0.0137,  ..., -0.0020,  0.0036, -0.0541]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0693, -0.0089, -0.0055,  ..., -0.0077,  0.0002,  0.0091],
        [-0.0128, -0.0843, -0.0162,  ..., -0.0016,  0.0018,  0.0062],
        [ 0.0036, -0.0069, -0.0931,  ...,  0.0098,  0.0019, -0.0026],
        ...,
        [ 0.0100,  0.0027,  0.0165,  ..., -0.0678,  0.0101, -0.0027],
        [ 0.0051, -0.0070, -0.0063,  ...,  0.0059, -0.0909, -0.0054],
        [-0.0126,  0.0028,  0.0122,  ..., -0.0079,  0.0082, -0.0843]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:07:48 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 10:07:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1311,  0.1001, -0.4663,  ..., -0.5850,  0.4607,  0.1196],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2986, -0.0208, -0.0822,  ...,  0.7881,  0.2944, -0.2522],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0176, -0.0980, -0.6436,  ..., -1.0645,  0.4790,  0.8115],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0996,  0.8032, -0.8853,  ...,  1.9248,  0.3823,  0.4094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:07:49 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:07:49 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 10:08:58 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 10:10:08 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 10:11:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0376e-02, -3.3970e-03,  2.8973e-03,  ..., -2.3079e-03,
          1.0605e-03,  6.8092e-03],
        [-2.2411e-03,  6.1302e-03, -1.8144e-04,  ...,  1.9302e-03,
         -2.0351e-03, -1.0742e-02],
        [-1.2627e-03, -7.8354e-03,  9.8038e-03,  ...,  2.7294e-03,
          1.5945e-03, -2.4300e-03],
        ...,
        [ 1.5650e-03,  2.9602e-03,  1.5736e-05,  ...,  8.5907e-03,
         -6.4049e-03, -1.3031e-02],
        [ 9.8801e-04,  3.1853e-04,  6.3896e-03,  ..., -4.7188e-03,
          4.7646e-03,  3.5076e-03],
        [-1.3704e-03,  2.7955e-05, -1.5917e-03,  ...,  5.7068e-03,
          4.2343e-03,  5.7449e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0412,  0.0115,  0.0022,  ..., -0.0146, -0.0057,  0.0062],
        [ 0.0056, -0.0583, -0.0058,  ..., -0.0099,  0.0002,  0.0077],
        [-0.0052,  0.0186, -0.0494,  ..., -0.0007,  0.0045, -0.0131],
        ...,
        [-0.0016,  0.0022, -0.0098,  ..., -0.0388,  0.0006,  0.0034],
        [-0.0022,  0.0108, -0.0090,  ...,  0.0112, -0.0492,  0.0042],
        [ 0.0015, -0.0013, -0.0069,  ...,  0.0055, -0.0042, -0.0455]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.0374e-02, -1.9169e-03, -5.4932e-04,  ..., -8.4991e-03,
         -3.8147e-06, -4.3945e-03],
        [ 1.1406e-02, -9.4788e-02,  9.3536e-03,  ..., -2.0676e-03,
         -1.1559e-03,  2.2400e-02],
        [-4.4136e-03, -1.3723e-03, -6.2561e-02,  ..., -1.5732e-02,
         -6.2943e-04, -1.6617e-02],
        ...,
        [-9.5463e-04,  1.0765e-02, -1.6823e-03,  ..., -7.6172e-02,
         -2.4338e-03,  2.5749e-03],
        [ 2.6894e-03, -5.4703e-03, -8.4534e-03,  ..., -8.4305e-03,
         -7.3120e-02, -1.3809e-03],
        [-1.2604e-02,  1.3107e-02, -8.0719e-03,  ..., -1.0803e-02,
         -5.1346e-03, -7.5073e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:11:20 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 10:11:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0118,  0.0184, -0.3538,  ..., -0.4656,  0.2834,  0.2225],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6006,  0.1969,  0.0474,  ...,  0.9692,  0.2466,  0.1915],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0712, -0.9629, -0.6890,  ..., -0.7192,  0.7271,  0.8267],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.3350,  0.7920, -1.5518,  ...,  1.4014,  0.8276,  0.6689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:11:20 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:11:21 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 10:12:31 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 10:13:42 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 10:14:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.7755e-03, -7.7553e-03, -1.0750e-02,  ..., -5.7907e-03,
          1.0672e-03, -5.8098e-03],
        [ 4.7188e-03,  4.0970e-03,  6.7139e-03,  ..., -9.4128e-04,
         -7.9918e-04,  2.1801e-03],
        [-2.5082e-03,  8.5115e-04,  1.3113e-06,  ..., -3.5591e-03,
         -6.0415e-04,  2.2869e-03],
        ...,
        [-2.3258e-04, -1.7958e-03, -6.2828e-03,  ...,  4.8103e-03,
         -1.2655e-03,  4.1885e-03],
        [-2.7924e-03, -1.0971e-02,  6.4812e-03,  ...,  4.5681e-04,
          3.9368e-03,  6.3848e-04],
        [-5.2605e-03,  7.1297e-03,  1.1566e-02,  ..., -6.6299e-03,
         -6.4125e-03,  1.9932e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0185, -0.0036, -0.0146,  ..., -0.0061,  0.0068, -0.0007],
        [ 0.0141, -0.0212,  0.0050,  ...,  0.0154,  0.0018, -0.0085],
        [ 0.0036,  0.0068, -0.0273,  ...,  0.0159, -0.0070,  0.0059],
        ...,
        [-0.0273, -0.0051, -0.0028,  ..., -0.0196,  0.0145,  0.0063],
        [ 0.0091,  0.0056, -0.0149,  ..., -0.0227, -0.0213,  0.0078],
        [ 0.0013, -0.0011, -0.0028,  ...,  0.0039, -0.0131, -0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.9835e-02, -1.5572e-02,  1.2817e-02,  ..., -1.5045e-02,
          6.0005e-03,  1.1612e-02],
        [ 8.0109e-05, -5.1392e-02, -1.1536e-02,  ..., -3.2616e-04,
          1.4519e-02, -1.6785e-02],
        [ 1.7334e-02, -1.4587e-02, -6.9946e-02,  ..., -8.9417e-03,
          1.8524e-02,  1.0300e-04],
        ...,
        [-1.2489e-02, -7.0496e-03, -2.8038e-03,  ..., -6.4880e-02,
         -1.7197e-02, -6.5613e-04],
        [ 2.1591e-03, -8.2397e-03, -8.9874e-03,  ...,  2.6417e-03,
         -5.1758e-02,  2.5528e-02],
        [-6.0043e-03,  1.6312e-02,  8.2855e-03,  ...,  1.2161e-02,
         -1.9951e-03, -6.4453e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:14:55 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 10:14:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0043, -0.0552, -0.2773,  ..., -0.4365,  0.1882,  0.3062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4365,  0.3064, -0.3484,  ...,  0.7466,  0.1444,  0.1321],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1814, -1.5977, -1.1445,  ..., -0.5791,  1.1211,  0.4150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8193,  1.3574, -1.4492,  ...,  1.4375,  0.2529,  0.6392],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:14:55 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:14:55 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 10:16:08 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 10:17:18 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 10:18:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2736e-02, -8.4534e-03, -3.6931e-04,  ...,  5.6534e-03,
         -1.7490e-03, -9.6226e-04],
        [-1.6918e-03,  2.0691e-02, -1.3571e-03,  ..., -5.6839e-03,
         -5.6267e-05,  2.8267e-03],
        [-1.6127e-03,  7.9679e-04,  1.6510e-02,  ..., -2.2545e-03,
         -2.5215e-03,  4.6806e-03],
        ...,
        [ 1.0643e-03, -2.6655e-04, -2.4681e-03,  ...,  1.3939e-02,
         -5.2261e-04,  1.1578e-03],
        [-3.5667e-04, -1.1169e-02, -1.9670e-04,  ...,  3.4714e-03,
          1.2939e-02, -1.2817e-03],
        [-2.9716e-03,  6.7616e-04, -1.1530e-03,  ..., -1.8063e-03,
          3.0060e-03,  1.8616e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0153, -0.0175, -0.0032,  ...,  0.0082, -0.0083, -0.0004],
        [ 0.0022, -0.0293,  0.0032,  ...,  0.0152,  0.0054,  0.0052],
        [ 0.0005,  0.0128, -0.0109,  ...,  0.0004,  0.0179, -0.0076],
        ...,
        [ 0.0051,  0.0040, -0.0133,  ..., -0.0146,  0.0003,  0.0093],
        [ 0.0048, -0.0028, -0.0104,  ...,  0.0111, -0.0149, -0.0032],
        [-0.0033, -0.0100, -0.0137,  ..., -0.0087, -0.0059, -0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.2887e-02,  7.6447e-03,  1.0658e-02,  ...,  1.4969e-02,
          6.3019e-03, -9.3155e-03],
        [ 2.6077e-02, -5.7312e-02, -1.0529e-03,  ..., -1.2222e-02,
         -1.5087e-03,  1.1314e-02],
        [ 1.3351e-02, -6.5231e-03, -6.7444e-02,  ...,  6.1073e-03,
          6.1035e-05,  8.0338e-03],
        ...,
        [ 5.4016e-03, -7.0038e-03, -2.1194e-02,  ..., -5.9540e-02,
         -3.9139e-03, -5.9853e-03],
        [ 5.7793e-03,  1.5427e-02, -6.5880e-03,  ..., -3.4847e-03,
         -6.3599e-02, -6.8283e-03],
        [-8.2397e-03,  2.5005e-03, -1.8005e-02,  ..., -2.7374e-02,
         -1.5888e-03, -5.2277e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:18:33 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 10:18:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0245, -0.3916, -0.2793,  ..., -0.2952,  0.2896,  0.2979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5122,  0.2944, -0.5938,  ...,  0.5205,  0.3237,  0.2324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0889, -2.4590, -0.6265,  ..., -0.6230,  1.1523,  0.9668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2402,  1.1045, -0.6338,  ...,  1.1094,  0.3999,  0.3071],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:18:33 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:18:33 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 10:19:50 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 10:21:05 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 10:22:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.9776e-03,  5.6744e-04,  8.3017e-04,  ...,  2.4390e-04,
         -3.0303e-04, -5.3883e-04],
        [-2.6073e-03,  6.9733e-03,  6.8951e-04,  ...,  2.0466e-03,
          9.1028e-04,  5.7077e-04],
        [ 2.3308e-03, -3.4027e-03,  7.9117e-03,  ...,  2.6083e-04,
          1.2093e-03, -3.3684e-03],
        ...,
        [ 9.9123e-05,  2.9240e-03, -3.7060e-03,  ...,  8.9035e-03,
         -1.6470e-03, -1.5030e-03],
        [ 1.8682e-03,  5.1451e-04,  2.4910e-03,  ...,  1.9550e-03,
          6.9695e-03,  1.7319e-03],
        [-2.1572e-03, -1.4153e-03, -7.9441e-04,  ..., -3.6240e-04,
          4.3144e-03,  9.3231e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0063,  0.0082, -0.0111,  ..., -0.0059,  0.0114, -0.0074],
        [-0.0232, -0.0155,  0.0026,  ..., -0.0135,  0.0073,  0.0068],
        [-0.0043,  0.0139, -0.0165,  ...,  0.0051,  0.0135, -0.0064],
        ...,
        [-0.0037, -0.0015, -0.0077,  ..., -0.0186,  0.0022,  0.0103],
        [-0.0138, -0.0054,  0.0026,  ..., -0.0007,  0.0028,  0.0147],
        [ 0.0093, -0.0070, -0.0096,  ..., -0.0003,  0.0097, -0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0526,  0.0089, -0.0014,  ...,  0.0091, -0.0150,  0.0014],
        [-0.0059, -0.0818, -0.0170,  ..., -0.0112,  0.0012, -0.0005],
        [-0.0088,  0.0108, -0.0479,  ..., -0.0041, -0.0127, -0.0052],
        ...,
        [ 0.0114,  0.0122, -0.0114,  ..., -0.0601,  0.0099, -0.0066],
        [-0.0207, -0.0283, -0.0026,  ...,  0.0084, -0.0596,  0.0119],
        [ 0.0064, -0.0048, -0.0092,  ...,  0.0097,  0.0044, -0.0651]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:22:20 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 10:22:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0677, -0.5991, -0.4404,  ..., -0.2128,  0.4382,  0.1282],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3176,  0.5044, -0.5508,  ...,  0.5435,  0.1091,  0.2195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2047, -2.6094, -0.1982,  ..., -0.2981,  2.0820,  0.2637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0369,  1.4336, -0.5200,  ...,  0.8799,  1.0469, -0.0649],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:22:20 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:22:20 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 10:23:35 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 10:24:52 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 10:26:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.4305e-03,  2.6703e-04,  6.8378e-04,  ..., -8.0872e-04,
         -2.6631e-04, -1.4365e-05],
        [ 2.8563e-04, -1.8234e-03,  3.7766e-04,  ...,  2.3949e-04,
         -6.4993e-04, -1.1277e-04],
        [ 2.9624e-05, -4.6921e-04, -1.8177e-03,  ...,  5.8985e-04,
         -3.9196e-04, -1.9884e-04],
        ...,
        [-4.0531e-06, -5.4121e-05,  1.4746e-04,  ..., -1.5650e-03,
          4.0817e-04, -7.0393e-05],
        [-8.3447e-05, -2.4509e-04,  1.1396e-04,  ..., -5.6410e-04,
         -2.4242e-03, -6.4659e-04],
        [ 1.3804e-04,  9.2459e-04,  3.3426e-04,  ..., -1.0711e-04,
          5.3406e-04, -1.9379e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.4428e-03,  2.5272e-05,  5.8479e-03,  ..., -1.5610e-02,
         -2.4738e-03,  1.6754e-02],
        [-2.8706e-03, -2.4597e-02, -5.2834e-04,  ...,  5.1956e-03,
          7.0000e-03,  1.0014e-05],
        [ 7.2937e-03, -2.3079e-03, -9.5139e-03,  ..., -3.7217e-04,
          3.1128e-03, -3.9411e-04],
        ...,
        [-1.0429e-02,  1.3855e-02, -4.5891e-03,  ..., -2.1515e-02,
          2.0027e-03, -4.6043e-03],
        [ 5.8441e-03,  5.3940e-03, -1.0195e-03,  ..., -4.8790e-03,
         -1.2268e-02,  1.6270e-03],
        [-1.0834e-02, -1.5686e-02, -1.3514e-03,  ..., -4.2229e-03,
          1.7204e-03, -2.2827e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0555, -0.0051,  0.0094,  ..., -0.0207, -0.0276,  0.0031],
        [-0.0061, -0.0574, -0.0034,  ..., -0.0006,  0.0296,  0.0103],
        [-0.0016, -0.0023, -0.0551,  ..., -0.0079, -0.0118,  0.0051],
        ...,
        [-0.0052,  0.0131, -0.0061,  ..., -0.0535, -0.0033,  0.0103],
        [ 0.0065,  0.0028, -0.0084,  ..., -0.0296, -0.0622, -0.0066],
        [-0.0047,  0.0153, -0.0025,  ..., -0.0151,  0.0076, -0.0673]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:26:13 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 10:26:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0413, -0.8848, -0.2505,  ..., -0.2211,  0.4424,  0.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0798,  0.4021, -0.2524,  ...,  0.4099,  0.1697,  0.0861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1327, -1.6318, -0.2258,  ...,  0.1543,  1.8164,  0.4751],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([0.5957, 1.4902, 0.4238,  ..., 1.4277, 0.9917, 0.4727], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:26:13 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:26:13 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 10:27:33 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 10:28:52 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 10:30:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2188e-03,  1.2827e-03,  1.5135e-03,  ...,  2.3193e-03,
          8.7690e-04, -1.4896e-03],
        [-3.0785e-03, -2.6941e-04,  2.8267e-03,  ...,  3.0613e-03,
          2.6894e-04,  3.0708e-03],
        [-7.7426e-05,  2.9564e-05,  1.7529e-03,  ..., -1.5564e-03,
          1.6146e-03, -1.5140e-04],
        ...,
        [-2.2659e-03, -1.9484e-03,  1.9646e-03,  ..., -1.0586e-03,
         -1.2827e-03, -4.1485e-04],
        [ 3.6263e-04,  4.3440e-04, -1.1349e-03,  ...,  1.0967e-03,
          8.2254e-06,  1.0548e-03],
        [-9.4318e-04,  3.0289e-03,  2.7561e-03,  ...,  2.0103e-03,
          3.2635e-03, -2.9583e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0316, -0.0073, -0.0176,  ..., -0.0126,  0.0105, -0.0007],
        [-0.0027, -0.0018,  0.0259,  ...,  0.0063,  0.0060, -0.0067],
        [ 0.0111, -0.0138, -0.0095,  ..., -0.0029,  0.0022, -0.0019],
        ...,
        [ 0.0025,  0.0061, -0.0023,  ..., -0.0024, -0.0149, -0.0059],
        [ 0.0038, -0.0024, -0.0077,  ..., -0.0055,  0.0041, -0.0020],
        [-0.0080, -0.0055,  0.0152,  ..., -0.0050,  0.0069, -0.0088]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0620,  0.0025, -0.0028,  ..., -0.0078,  0.0112,  0.0036],
        [-0.0219, -0.0767,  0.0171,  ...,  0.0026, -0.0119,  0.0052],
        [ 0.0004, -0.0150, -0.0853,  ..., -0.0068, -0.0011,  0.0113],
        ...,
        [ 0.0235, -0.0104, -0.0144,  ..., -0.0791, -0.0122, -0.0208],
        [ 0.0150,  0.0023,  0.0227,  ...,  0.0054, -0.0707,  0.0108],
        [ 0.0024, -0.0089,  0.0128,  ...,  0.0259, -0.0054, -0.0721]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:30:14 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 10:30:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0769, -0.8730, -0.1197,  ..., -0.1149,  0.7578,  0.0640],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0075,  0.5215, -0.2313,  ...,  0.3010,  0.3899, -0.0527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0360, -1.5918, -0.0143,  ...,  0.1071,  2.2266,  0.3760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7051,  1.0508,  0.9009,  ...,  2.1367,  1.7207,  1.7998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:30:14 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:30:14 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 10:31:36 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 10:33:00 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 10:34:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.4697e-03, -1.8466e-04, -7.4434e-04,  ...,  1.0500e-03,
          3.5439e-03,  4.6234e-03],
        [ 5.3120e-04,  1.0595e-03,  2.1248e-03,  ..., -6.2323e-04,
         -3.8052e-03, -3.7727e-03],
        [ 2.2240e-03, -4.2229e-03, -1.8177e-03,  ...,  2.9135e-04,
         -9.1362e-04, -3.1071e-03],
        ...,
        [ 4.9162e-04,  6.3324e-04,  5.0688e-04,  ...,  9.0942e-03,
         -1.3466e-03, -2.1057e-03],
        [ 3.7498e-03,  6.1684e-03,  4.8103e-03,  ...,  2.5196e-03,
          1.0742e-02, -1.8587e-03],
        [ 2.5043e-03, -3.5267e-03, -2.4586e-03,  ...,  1.7872e-03,
          3.9339e-06,  1.4030e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0141,  0.0112, -0.0009,  ...,  0.0055,  0.0029,  0.0086],
        [-0.0080, -0.0052, -0.0097,  ..., -0.0032, -0.0030,  0.0089],
        [ 0.0006, -0.0025,  0.0146,  ...,  0.0030,  0.0154, -0.0010],
        ...,
        [-0.0161,  0.0115, -0.0051,  ...,  0.0023,  0.0121,  0.0088],
        [-0.0068,  0.0008, -0.0097,  ..., -0.0189, -0.0028, -0.0074],
        [-0.0041,  0.0060, -0.0081,  ..., -0.0054,  0.0040,  0.0210]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0112, -0.0089, -0.0004,  ..., -0.0027,  0.0141,  0.0034],
        [-0.0029, -0.0323, -0.0056,  ..., -0.0038, -0.0261,  0.0245],
        [ 0.0041,  0.0108,  0.0102,  ...,  0.0086,  0.0131, -0.0130],
        ...,
        [-0.0045, -0.0072, -0.0024,  ...,  0.0243,  0.0134, -0.0233],
        [-0.0082,  0.0016, -0.0117,  ...,  0.0061,  0.0050, -0.0082],
        [ 0.0163,  0.0257, -0.0099,  ..., -0.0002,  0.0041, -0.0012]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:34:26 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 10:34:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0676, -0.5068, -0.1351,  ...,  0.0125,  0.6074,  0.1218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([0.2305, 0.5117, 0.0897,  ..., 0.4463, 0.3359, 0.1259], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5088, -0.3818,  0.0780,  ...,  0.1124,  2.1660,  0.2126],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2617,  1.2061,  1.5254,  ...,  3.0371,  0.6582,  2.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:34:26 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:34:26 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 10:35:50 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 10:37:14 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 10:38:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.2602e-04,  1.5080e-04, -2.4843e-04,  ..., -3.0398e-04,
          1.2517e-04,  3.2234e-04],
        [ 2.4104e-04, -5.8699e-04,  4.6134e-05,  ...,  1.2219e-05,
          1.5831e-04, -1.7738e-04],
        [-2.1446e-04,  7.8499e-05, -1.7524e-05,  ..., -3.9053e-04,
          4.0817e-04,  2.8729e-05],
        ...,
        [ 3.1161e-04,  9.1791e-06, -1.0031e-04,  ..., -1.0663e-04,
          5.0545e-04, -1.6546e-04],
        [ 4.2892e-04,  1.2517e-06,  4.3654e-04,  ...,  1.3971e-04,
         -5.7793e-04, -7.9393e-05],
        [-4.4167e-05, -8.2493e-05,  2.0289e-04,  ...,  1.5604e-04,
         -4.1533e-04, -2.6178e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0204,  0.0121,  0.0047,  ..., -0.0032, -0.0072,  0.0131],
        [-0.0049, -0.0117,  0.0102,  ...,  0.0041, -0.0142, -0.0071],
        [-0.0118,  0.0068, -0.0033,  ...,  0.0033,  0.0021,  0.0029],
        ...,
        [-0.0013, -0.0032, -0.0153,  ..., -0.0012, -0.0255,  0.0160],
        [ 0.0120,  0.0110,  0.0100,  ..., -0.0143, -0.0024,  0.0190],
        [-0.0042,  0.0096, -0.0085,  ...,  0.0118, -0.0032, -0.0151]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0591,  0.0001, -0.0089,  ..., -0.0064,  0.0162,  0.0038],
        [-0.0158, -0.0374, -0.0066,  ...,  0.0076,  0.0002, -0.0168],
        [ 0.0177, -0.0102, -0.0082,  ...,  0.0082,  0.0070, -0.0136],
        ...,
        [-0.0157,  0.0113,  0.0047,  ..., -0.0292,  0.0082,  0.0102],
        [ 0.0151,  0.0076, -0.0121,  ..., -0.0021, -0.0229,  0.0170],
        [-0.0004,  0.0085, -0.0198,  ...,  0.0066,  0.0203, -0.0388]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:38:43 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 10:38:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0600, -0.4365, -0.0929,  ..., -0.0679,  0.6343,  0.0554],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1796,  0.3564,  0.2003,  ...,  0.5815,  0.5229,  0.5322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3203, -0.5488, -1.5615,  ..., -0.7124,  2.0625, -0.7705],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5850,  1.0957, -0.1270,  ...,  1.9707,  0.5430,  2.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:38:43 root INFO     [order_1_approx] starting weight calculation for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:38:43 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 10:40:09 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 10:41:38 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 10:43:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.8888e-03, -1.2598e-03, -7.7724e-05,  ..., -4.6301e-04,
          5.0020e-04, -4.5395e-04],
        [ 7.7581e-04,  3.7346e-03,  2.8670e-05,  ...,  6.8724e-05,
          2.3150e-04,  4.5824e-04],
        [ 2.9421e-04, -2.9325e-04,  6.9504e-03,  ..., -8.6021e-04,
         -1.1072e-03,  3.6669e-04],
        ...,
        [-1.1053e-03, -4.3774e-04, -2.3127e-04,  ...,  8.5144e-03,
         -4.7803e-04, -1.0481e-03],
        [-1.3280e-04, -4.6158e-04, -3.2187e-04,  ..., -4.4632e-04,
          9.9335e-03, -1.2887e-04],
        [-3.1924e-04,  3.8052e-04, -2.7561e-04,  ..., -1.1377e-03,
         -2.0075e-04,  1.0628e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0094,  0.0129,  0.0039,  ..., -0.0050,  0.0043,  0.0185],
        [ 0.0206,  0.0027, -0.0057,  ..., -0.0069,  0.0137, -0.0040],
        [-0.0069,  0.0020,  0.0020,  ..., -0.0097, -0.0137, -0.0184],
        ...,
        [-0.0113,  0.0094, -0.0187,  ...,  0.0042, -0.0024, -0.0137],
        [-0.0044, -0.0124,  0.0017,  ..., -0.0155,  0.0114,  0.0124],
        [-0.0144,  0.0121,  0.0034,  ..., -0.0080,  0.0038,  0.0081]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0049,  0.0183, -0.0018,  ..., -0.0057, -0.0041, -0.0170],
        [ 0.0118, -0.0294,  0.0040,  ..., -0.0034, -0.0002, -0.0049],
        [ 0.0115,  0.0084,  0.0152,  ..., -0.0226,  0.0128, -0.0070],
        ...,
        [ 0.0077,  0.0141,  0.0135,  ...,  0.0028,  0.0053,  0.0019],
        [ 0.0061, -0.0203,  0.0086,  ..., -0.0132, -0.0237,  0.0054],
        [-0.0126,  0.0199,  0.0320,  ...,  0.0038, -0.0061,  0.0134]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:43:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too stressed, it is overstressed
If something is too compensated, it is overcompensated
If something is too powered, it is overpowered
If something is too simplified, it is oversimplified
If something is too filled, it is overfilled
If something is too qualified, it is overqualified
If something is too loaded, it is overloaded
If something is too spent, it is
2024-06-30 10:43:06 root INFO     total operator prediction time: 35211.62637901306 seconds
2024-06-30 10:43:07 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-06-30 10:43:09 root INFO     building operator hypernyms - animals
2024-06-30 10:43:09 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 10:43:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0036, -0.5107,  0.4026,  ..., -0.6045, -0.1447,  0.0107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4543, -0.1143, -0.5791,  ..., -0.1499, -0.9219, -0.3677],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6660, -0.5425,  0.0479,  ..., -0.9819,  0.2465, -0.3828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4705,  0.1071, -0.2766,  ..., -0.4971, -0.4082, -0.5176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:43:09 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:43:09 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 10:43:31 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 10:43:54 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 10:44:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.8528e-04, -2.7919e-04,  5.6982e-05,  ..., -3.0017e-04,
          8.7440e-05,  2.3472e-04],
        [-7.2002e-05, -2.0742e-04, -2.6727e-04,  ..., -3.7551e-06,
          4.7851e-04, -1.9550e-04],
        [-5.9783e-05, -5.8830e-05, -7.0333e-04,  ..., -5.8711e-05,
         -5.3263e-04, -1.8585e-04],
        ...,
        [-2.5868e-05, -7.3624e-04,  1.5521e-04,  ..., -2.2912e-04,
          2.4056e-04,  1.0043e-04],
        [ 1.2636e-04,  1.7369e-04,  7.6175e-05,  ...,  9.7334e-05,
         -6.2227e-04,  7.3969e-05],
        [-1.6928e-04, -5.1498e-05,  4.5347e-04,  ..., -2.7561e-04,
          1.7238e-04, -4.4203e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0333,  0.0018,  0.0025,  ..., -0.0013,  0.0021,  0.0023],
        [-0.0047, -0.0295, -0.0028,  ...,  0.0030, -0.0098,  0.0018],
        [ 0.0020,  0.0018, -0.0325,  ..., -0.0054,  0.0054,  0.0078],
        ...,
        [ 0.0013,  0.0042, -0.0020,  ..., -0.0324,  0.0088,  0.0077],
        [-0.0038, -0.0011,  0.0052,  ..., -0.0014, -0.0195,  0.0018],
        [-0.0021,  0.0017, -0.0009,  ...,  0.0045,  0.0034, -0.0271]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0296,  0.0005,  0.0062,  ..., -0.0010, -0.0013,  0.0003],
        [ 0.0008, -0.0261, -0.0058,  ..., -0.0018,  0.0023,  0.0003],
        [-0.0008,  0.0027, -0.0250,  ..., -0.0001, -0.0020,  0.0058],
        ...,
        [ 0.0021,  0.0037,  0.0007,  ..., -0.0229,  0.0027,  0.0019],
        [-0.0013,  0.0021, -0.0003,  ..., -0.0002, -0.0248,  0.0005],
        [-0.0014, -0.0022, -0.0029,  ...,  0.0009,  0.0001, -0.0273]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:44:20 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 10:44:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3354, -0.8047,  0.0765,  ..., -0.8672, -0.0793, -0.3096],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5283,  0.1813, -0.3975,  ..., -1.0498, -0.4485, -0.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5806, -0.6392,  0.1015,  ..., -1.1182,  0.2759, -0.5674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1887, -0.1444,  0.1545,  ..., -1.1074, -0.6025, -0.6260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:44:20 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:44:20 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 10:44:44 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 10:45:07 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 10:45:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.2043e-03,  7.7772e-04, -5.9032e-04,  ..., -1.4696e-03,
         -6.5565e-04, -6.6137e-04],
        [ 1.1623e-04, -5.2872e-03,  7.0333e-05,  ...,  1.2093e-03,
         -7.5912e-04,  4.0388e-04],
        [-2.5225e-04,  5.0116e-04, -5.2071e-03,  ..., -8.2874e-04,
          4.1902e-05, -1.9670e-04],
        ...,
        [-1.6272e-05, -7.5698e-05,  3.9721e-04,  ..., -4.2000e-03,
         -1.1864e-03, -5.7220e-05],
        [ 1.2136e-04,  1.4267e-03,  6.7806e-04,  ..., -7.0477e-04,
         -4.5624e-03, -1.3471e-04],
        [ 2.6464e-04,  2.8062e-04,  8.4400e-04,  ..., -3.8767e-04,
         -9.3162e-05, -4.5395e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0426,  0.0015,  0.0023,  ...,  0.0016, -0.0104,  0.0022],
        [ 0.0017, -0.0450,  0.0025,  ...,  0.0063, -0.0005,  0.0060],
        [-0.0063,  0.0005, -0.0419,  ...,  0.0050, -0.0013,  0.0152],
        ...,
        [ 0.0028,  0.0034, -0.0047,  ..., -0.0322, -0.0037, -0.0007],
        [ 0.0016, -0.0103, -0.0046,  ...,  0.0021, -0.0420,  0.0041],
        [ 0.0033, -0.0012,  0.0056,  ..., -0.0003,  0.0043, -0.0540]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0597,  0.0007, -0.0035,  ...,  0.0068,  0.0056,  0.0014],
        [-0.0031, -0.0639, -0.0037,  ..., -0.0009, -0.0020, -0.0039],
        [ 0.0004,  0.0029, -0.0605,  ...,  0.0018,  0.0026, -0.0003],
        ...,
        [ 0.0028, -0.0041,  0.0014,  ..., -0.0582, -0.0062, -0.0098],
        [-0.0068, -0.0062,  0.0039,  ..., -0.0053, -0.0608,  0.0066],
        [ 0.0032, -0.0123,  0.0052,  ...,  0.0018,  0.0008, -0.0547]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:45:33 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 10:45:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7695, -0.6436,  0.0440,  ..., -1.0449,  0.2615, -0.4692],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7612,  0.1530, -0.4331,  ..., -0.7422, -0.6289, -0.8628],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4854, -0.7524,  0.2856,  ..., -0.6475,  0.1410, -0.0903],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2769,  0.3584, -0.0105,  ..., -0.8032, -0.7280, -0.9541],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:45:33 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:45:33 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 10:45:58 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 10:46:23 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 10:46:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.3101e-03, -2.5988e-05, -3.1829e-04,  ...,  2.0897e-04,
          5.4979e-04,  2.5940e-04],
        [-6.6102e-05, -3.2616e-03, -3.3379e-04,  ...,  8.6784e-04,
          9.8419e-04,  9.6369e-04],
        [ 7.9870e-04, -4.2892e-04, -3.4351e-03,  ...,  5.8651e-04,
          3.9291e-04, -7.0143e-04],
        ...,
        [ 3.7074e-04,  1.6251e-03,  6.9714e-04,  ..., -3.2101e-03,
          2.5702e-04, -9.2888e-04],
        [-3.0518e-04, -5.5599e-04, -1.0300e-03,  ...,  1.3323e-03,
         -2.7809e-03, -9.5272e-04],
        [ 7.4208e-05,  8.1682e-04, -9.2328e-05,  ..., -3.8576e-04,
         -7.6115e-05, -2.4090e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0361, -0.0018, -0.0019,  ...,  0.0092,  0.0044, -0.0006],
        [-0.0054, -0.0306, -0.0009,  ..., -0.0104, -0.0008, -0.0055],
        [ 0.0094,  0.0021, -0.0394,  ..., -0.0030,  0.0021, -0.0035],
        ...,
        [ 0.0014,  0.0032, -0.0025,  ..., -0.0394, -0.0020,  0.0046],
        [-0.0030, -0.0033,  0.0006,  ...,  0.0048, -0.0382, -0.0031],
        [-0.0004,  0.0005, -0.0009,  ...,  0.0036,  0.0024, -0.0365]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.8717e-02,  1.5020e-04, -2.4128e-03,  ..., -3.8147e-06,
          3.5477e-03,  5.0583e-03],
        [-4.0817e-03, -3.1555e-02, -1.7738e-04,  ...,  6.6414e-03,
          3.6755e-03,  4.6158e-04],
        [ 8.2922e-04,  6.9618e-05, -3.5980e-02,  ..., -1.9703e-03,
         -4.3259e-03, -3.5515e-03],
        ...,
        [ 1.3065e-03,  4.6349e-04, -1.0700e-03,  ..., -2.9465e-02,
         -5.5809e-03,  3.8319e-03],
        [-1.5402e-04,  4.7531e-03, -1.3428e-03,  ..., -5.7106e-03,
         -2.8046e-02,  8.7051e-03],
        [ 2.8229e-03,  5.5695e-03,  4.0359e-03,  ..., -4.5319e-03,
         -1.8358e-04, -2.8900e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:46:49 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 10:46:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7046, -0.7769,  0.1113,  ..., -1.2295,  0.2869, -0.7129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2959, -0.2327,  0.2234,  ..., -1.5195, -0.8643, -0.9619],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0154, -0.8379,  0.2622,  ..., -0.5352,  0.2949, -0.0793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1298,  0.6484, -0.3352,  ..., -0.7588, -0.2844, -0.5830],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:46:49 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:46:49 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 10:47:19 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 10:47:49 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 10:48:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3384e-03,  9.7942e-04,  3.5763e-06,  ...,  4.4894e-04,
         -6.6042e-04,  3.0875e-05],
        [ 1.0185e-03, -1.6279e-03, -4.7159e-04,  ...,  5.6267e-04,
         -3.3379e-05, -3.2425e-04],
        [ 5.9605e-04, -4.5085e-04, -1.1854e-03,  ...,  1.1320e-03,
          1.4615e-04, -7.7248e-04],
        ...,
        [-8.1110e-04, -2.1458e-03, -1.4496e-03,  ..., -3.5744e-03,
          1.0605e-03, -1.8482e-03],
        [-3.6836e-04, -5.7745e-04,  1.1101e-03,  ...,  3.8362e-04,
         -2.2163e-03, -6.1274e-05],
        [ 1.6880e-03,  3.2592e-04, -4.5919e-04,  ...,  2.3675e-04,
         -3.1376e-04, -3.4561e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0475, -0.0016, -0.0076,  ...,  0.0021,  0.0042,  0.0073],
        [-0.0059, -0.0581, -0.0094,  ...,  0.0042,  0.0021,  0.0050],
        [-0.0061, -0.0090, -0.0498,  ...,  0.0013, -0.0017,  0.0089],
        ...,
        [-0.0068, -0.0050,  0.0015,  ..., -0.0421, -0.0123, -0.0050],
        [-0.0013,  0.0014, -0.0008,  ..., -0.0008, -0.0428, -0.0026],
        [ 0.0091, -0.0063, -0.0024,  ..., -0.0012, -0.0022, -0.0354]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.6488e-02,  3.6049e-03,  5.9700e-04,  ..., -4.1656e-03,
          8.2932e-03, -8.3694e-03],
        [ 4.2572e-03, -4.6844e-02, -3.0727e-03,  ...,  2.4223e-03,
         -1.8740e-04, -1.5688e-04],
        [-1.6060e-03, -6.1722e-03, -4.1840e-02,  ...,  6.0349e-03,
         -1.7395e-03, -9.6226e-04],
        ...,
        [-4.0359e-03, -6.8359e-03, -3.1185e-04,  ..., -6.0913e-02,
         -7.5912e-04, -1.2947e-02],
        [-9.5558e-04,  3.1319e-03, -1.0880e-02,  ..., -4.6844e-03,
         -4.1687e-02, -6.2981e-03],
        [-1.7910e-03, -2.5959e-03,  9.1553e-05,  ..., -3.9368e-03,
         -1.4400e-03, -5.3040e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:48:22 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 10:48:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4763, -0.7974,  0.2617,  ..., -0.5928,  0.1644, -0.1333],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2927,  0.3398, -0.0029,  ..., -0.7827, -0.7188, -1.0527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2612, -0.5918,  0.4856,  ..., -0.5347, -0.0723, -0.2876],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0371,  0.1868, -0.2174,  ..., -0.6313, -0.3765, -0.8242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:48:22 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:48:22 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 10:48:54 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 10:49:27 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 10:49:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8858e-03,  1.3418e-03, -3.8280e-03,  ..., -4.2391e-04,
         -6.6853e-04, -7.9155e-05],
        [-9.3222e-04, -9.3651e-04, -8.5163e-04,  ...,  4.2939e-04,
          4.8828e-04,  4.6730e-05],
        [ 2.3060e-03,  2.8076e-03, -4.7264e-03,  ..., -9.9754e-04,
         -2.3079e-03, -2.3174e-04],
        ...,
        [-2.8038e-03,  1.0996e-03,  1.0643e-03,  ..., -1.4286e-03,
         -3.7785e-03,  1.6861e-03],
        [ 1.6012e-03,  2.6631e-04, -4.4823e-04,  ..., -2.0962e-03,
         -3.2997e-03,  2.2197e-04],
        [ 7.5531e-04,  1.5235e-04, -5.9080e-04,  ..., -1.4124e-03,
         -1.1530e-03, -5.0964e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0820, -0.0001,  0.0093,  ..., -0.0066, -0.0073, -0.0082],
        [ 0.0006, -0.0744,  0.0022,  ..., -0.0035,  0.0173,  0.0039],
        [-0.0025, -0.0052, -0.0718,  ..., -0.0092, -0.0010, -0.0002],
        ...,
        [ 0.0053, -0.0011, -0.0138,  ..., -0.0629, -0.0059,  0.0009],
        [-0.0025, -0.0004, -0.0023,  ...,  0.0015, -0.0784,  0.0072],
        [-0.0118,  0.0023, -0.0020,  ...,  0.0051, -0.0012, -0.0792]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0309e-01, -6.3229e-04,  1.2428e-02,  ..., -9.6321e-04,
         -1.0166e-03, -3.6659e-03],
        [ 8.0538e-04, -1.1450e-01,  6.5651e-03,  ..., -4.0741e-03,
         -8.7662e-03, -5.9280e-03],
        [ 4.8447e-04,  3.3970e-03, -1.0822e-01,  ...,  6.1417e-03,
          6.1798e-03,  8.2397e-04],
        ...,
        [-5.7888e-04,  3.8433e-04,  4.9591e-03,  ..., -9.4910e-02,
          1.1017e-02, -2.0027e-04],
        [ 8.4305e-04, -6.2823e-05,  2.2717e-03,  ..., -4.4022e-03,
         -1.0620e-01,  5.8327e-03],
        [ 5.6839e-04, -2.1801e-03,  2.5511e-04,  ..., -3.2768e-03,
          6.1646e-03, -1.0541e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:49:58 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 10:49:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0201, -0.7754,  0.2063,  ..., -0.4500,  0.2345, -0.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1417,  0.7124, -0.3567,  ..., -0.7861, -0.3208, -0.6689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7739, -0.1074,  0.6772,  ..., -0.3335, -0.1810, -0.3159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6309,  0.1896, -0.2288,  ...,  0.0503, -0.4263, -0.9004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:49:58 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:49:58 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 10:50:34 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 10:51:12 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 10:51:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0040, -0.0032,  0.0053,  ..., -0.0001,  0.0013, -0.0015],
        [ 0.0008, -0.0055,  0.0019,  ..., -0.0008,  0.0012,  0.0008],
        [-0.0006,  0.0032, -0.0070,  ..., -0.0003, -0.0002, -0.0016],
        ...,
        [ 0.0012,  0.0008,  0.0012,  ..., -0.0049,  0.0005,  0.0005],
        [ 0.0033, -0.0005, -0.0015,  ..., -0.0010, -0.0036, -0.0020],
        [ 0.0019,  0.0012,  0.0004,  ..., -0.0012, -0.0014, -0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0814,  0.0014, -0.0028,  ...,  0.0096,  0.0071,  0.0044],
        [-0.0022, -0.0723,  0.0114,  ..., -0.0021, -0.0068, -0.0089],
        [ 0.0106,  0.0048, -0.0867,  ..., -0.0036, -0.0068, -0.0081],
        ...,
        [ 0.0143,  0.0154, -0.0031,  ..., -0.0718, -0.0125, -0.0033],
        [ 0.0014, -0.0060, -0.0001,  ...,  0.0044, -0.0836, -0.0083],
        [ 0.0075,  0.0129,  0.0009,  ..., -0.0060, -0.0058, -0.0820]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1124,  0.0075, -0.0069,  ..., -0.0004,  0.0032, -0.0010],
        [ 0.0025, -0.1102, -0.0077,  ...,  0.0037, -0.0047,  0.0061],
        [ 0.0020,  0.0014, -0.1023,  ..., -0.0023,  0.0128, -0.0030],
        ...,
        [ 0.0020, -0.0062, -0.0025,  ..., -0.1026, -0.0060, -0.0054],
        [-0.0005,  0.0064, -0.0042,  ...,  0.0040, -0.1031, -0.0016],
        [-0.0032, -0.0012, -0.0025,  ..., -0.0108,  0.0006, -0.1019]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:51:45 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 10:51:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2274, -0.5039,  0.3604,  ..., -0.4512, -0.0699, -0.2876],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0377,  0.2019, -0.2167,  ..., -0.6050, -0.3674, -0.8618],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7202,  0.6089,  0.4209,  ..., -0.1843, -0.4556, -0.6670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3042,  0.1681, -0.4434,  ..., -0.4688, -0.5620, -0.9541],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:51:45 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:51:45 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 10:52:27 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 10:53:06 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 10:53:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.6182e-03,  1.0262e-03, -1.1263e-03,  ...,  6.2704e-04,
         -2.5787e-03, -4.8041e-05],
        [ 1.3943e-03, -1.7605e-03, -3.4499e-04,  ...,  4.3182e-03,
          2.2614e-04, -9.5367e-04],
        [ 1.6699e-03, -9.8228e-04, -3.1834e-03,  ..., -4.0722e-04,
          8.2827e-04, -7.5912e-04],
        ...,
        [ 1.0133e-04, -2.5988e-04,  2.7523e-03,  ..., -1.5049e-03,
          1.2236e-03,  1.6651e-03],
        [-1.1377e-03, -1.2407e-03, -3.0365e-03,  ...,  1.0357e-03,
         -2.1896e-03, -9.7871e-05],
        [ 2.7001e-05, -1.7109e-03,  6.3705e-04,  ..., -2.7390e-03,
          3.2711e-03, -1.0699e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.1177e-02,  1.1539e-03,  2.9011e-03,  ..., -1.3840e-02,
         -2.3327e-03,  7.5188e-03],
        [ 3.3817e-03, -7.9773e-02,  1.5549e-02,  ..., -3.1090e-03,
          1.1429e-02,  8.8654e-03],
        [-2.4033e-03,  2.6398e-03, -7.1167e-02,  ...,  7.4844e-03,
         -1.1673e-02,  2.9678e-03],
        ...,
        [ 3.7289e-03, -3.1281e-04,  1.7120e-02,  ..., -7.6111e-02,
         -3.2578e-03,  1.2558e-02],
        [-4.0092e-03,  2.9526e-03, -1.0925e-02,  ...,  9.2468e-03,
         -8.0200e-02,  7.4506e-05],
        [ 8.1100e-03, -3.2196e-03,  4.0512e-03,  ..., -1.4328e-02,
          6.2485e-03, -7.7332e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0925e-01, -2.2583e-03,  3.2654e-03,  ..., -1.3664e-02,
         -1.6556e-02, -1.3161e-03],
        [ 7.9498e-03, -9.6619e-02, -1.2039e-02,  ...,  7.7820e-03,
          3.9902e-03, -6.0368e-04],
        [-1.0017e-02, -4.7264e-03, -9.7290e-02,  ..., -6.1951e-03,
         -6.1035e-05, -1.0796e-03],
        ...,
        [-1.3323e-03, -4.7493e-03,  3.5419e-03,  ..., -1.0974e-01,
          1.1795e-02, -7.3662e-03],
        [-8.1682e-04,  4.0741e-03,  3.9558e-03,  ...,  1.2878e-02,
         -1.1182e-01, -6.8092e-03],
        [ 1.8148e-03, -5.4092e-03,  5.3787e-03,  ...,  2.7542e-03,
          2.4242e-03, -1.0358e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:53:47 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 10:53:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6323, -0.1045,  0.5044,  ..., -0.2588, -0.1545, -0.2881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6274,  0.1877, -0.2261,  ...,  0.0453, -0.4182, -0.9360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5669,  0.9463,  0.1389,  ..., -0.5664, -0.8657, -0.0864],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3696, -0.5488, -0.8818,  ..., -0.7168, -0.2808, -0.1396],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:53:47 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:53:47 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 10:54:30 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 10:55:09 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 10:55:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0029, -0.0038, -0.0002,  ...,  0.0004,  0.0005, -0.0024],
        [-0.0023, -0.0044,  0.0029,  ..., -0.0060, -0.0022, -0.0015],
        [-0.0003,  0.0024, -0.0026,  ...,  0.0003,  0.0017, -0.0011],
        ...,
        [ 0.0007,  0.0009, -0.0025,  ..., -0.0009,  0.0028, -0.0016],
        [-0.0007, -0.0014, -0.0016,  ..., -0.0009, -0.0067,  0.0009],
        [ 0.0037,  0.0011,  0.0015,  ..., -0.0018,  0.0011, -0.0030]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0843, -0.0019, -0.0078,  ..., -0.0129, -0.0102,  0.0054],
        [-0.0046, -0.0945, -0.0013,  ..., -0.0094, -0.0072, -0.0054],
        [-0.0145,  0.0086, -0.0831,  ..., -0.0098,  0.0012, -0.0098],
        ...,
        [-0.0056,  0.0090,  0.0017,  ..., -0.0737,  0.0014,  0.0078],
        [-0.0022, -0.0009, -0.0048,  ..., -0.0056, -0.0732,  0.0058],
        [ 0.0028, -0.0063,  0.0005,  ...,  0.0012,  0.0020, -0.0996]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1003,  0.0125, -0.0054,  ..., -0.0017,  0.0041,  0.0011],
        [ 0.0058, -0.1078,  0.0065,  ..., -0.0072, -0.0090,  0.0089],
        [-0.0078,  0.0025, -0.1084,  ..., -0.0076, -0.0114,  0.0148],
        ...,
        [ 0.0062,  0.0013, -0.0038,  ..., -0.0982,  0.0015, -0.0041],
        [-0.0013,  0.0014, -0.0093,  ...,  0.0058, -0.0999,  0.0002],
        [ 0.0034,  0.0028, -0.0090,  ...,  0.0033,  0.0091, -0.1058]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:55:50 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 10:55:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5361,  0.4329,  0.2302,  ..., -0.1462, -0.3335, -0.5049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2913,  0.1511, -0.4292,  ..., -0.4116, -0.5029, -0.8887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0732,  1.1660,  1.2109,  ..., -0.6396, -0.6436, -0.6401],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3184, -0.1345, -0.7881,  ..., -0.5854, -0.2563,  0.0863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:55:51 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:55:51 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 10:56:38 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 10:57:16 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 10:57:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0007,  0.0006,  0.0015,  ..., -0.0077,  0.0002, -0.0042],
        [ 0.0031, -0.0046,  0.0023,  ..., -0.0025, -0.0014,  0.0038],
        [-0.0066,  0.0031,  0.0002,  ...,  0.0025,  0.0053, -0.0028],
        ...,
        [-0.0012, -0.0046,  0.0006,  ..., -0.0020, -0.0050,  0.0009],
        [-0.0079, -0.0026,  0.0049,  ...,  0.0021, -0.0041,  0.0025],
        [-0.0023, -0.0026,  0.0025,  ..., -0.0044,  0.0031, -0.0005]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0910, -0.0088,  0.0090,  ...,  0.0045, -0.0031, -0.0069],
        [-0.0039, -0.0955, -0.0064,  ..., -0.0176, -0.0104,  0.0201],
        [-0.0034, -0.0152, -0.0988,  ...,  0.0083, -0.0025, -0.0111],
        ...,
        [ 0.0026, -0.0133,  0.0167,  ..., -0.0999,  0.0046,  0.0020],
        [ 0.0038,  0.0010,  0.0046,  ...,  0.0082, -0.1049,  0.0086],
        [-0.0027,  0.0072,  0.0025,  ..., -0.0086,  0.0042, -0.0768]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1654, -0.0109,  0.0131,  ...,  0.0073, -0.0075,  0.0098],
        [-0.0005, -0.1735, -0.0073,  ...,  0.0057,  0.0004, -0.0042],
        [-0.0073, -0.0071, -0.1606,  ...,  0.0031,  0.0003, -0.0108],
        ...,
        [-0.0110,  0.0083,  0.0094,  ..., -0.1604, -0.0051,  0.0124],
        [-0.0026,  0.0028,  0.0030,  ..., -0.0032, -0.1746, -0.0042],
        [-0.0067,  0.0006, -0.0109,  ..., -0.0067, -0.0132, -0.1536]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 10:58:00 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 10:58:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3684,  0.5996,  0.0448,  ..., -0.3406, -0.5679, -0.1038],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2964, -0.4661, -0.7212,  ..., -0.5396, -0.2375, -0.1576],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1641,  1.3369,  1.4004,  ..., -0.3264, -1.1172, -0.5220],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0103, -0.5996, -0.8418,  ..., -0.0886, -0.6670,  0.3701],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 10:58:00 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 10:58:00 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 10:58:50 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 10:59:41 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 11:00:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0006, -0.0003, -0.0054,  ...,  0.0048,  0.0054,  0.0022],
        [ 0.0010,  0.0028,  0.0009,  ...,  0.0017,  0.0003,  0.0004],
        [ 0.0023,  0.0009, -0.0003,  ...,  0.0018, -0.0068,  0.0009],
        ...,
        [-0.0016, -0.0020,  0.0044,  ..., -0.0012,  0.0015, -0.0008],
        [-0.0007, -0.0032, -0.0007,  ...,  0.0037,  0.0015,  0.0002],
        [-0.0012, -0.0002, -0.0047,  ..., -0.0001,  0.0030,  0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1041e-01,  1.5612e-03, -1.5572e-02,  ..., -5.4779e-03,
          1.6541e-02,  7.5531e-04],
        [ 1.6083e-02, -9.4116e-02,  6.5155e-03,  ..., -2.3518e-03,
          5.0850e-03, -2.0599e-03],
        [ 4.5891e-03, -3.3894e-03, -1.1078e-01,  ...,  6.7043e-04,
          9.6970e-03,  5.2490e-03],
        ...,
        [ 1.9722e-03,  5.2376e-03,  6.2408e-03,  ..., -1.1761e-01,
          3.6736e-03,  7.2956e-04],
        [ 1.2344e-02,  5.0201e-03,  1.0014e-05,  ...,  1.7563e-02,
         -1.0999e-01,  1.6357e-02],
        [ 9.9869e-03,  4.3068e-03, -5.3406e-03,  ...,  4.8637e-05,
         -5.3329e-03, -1.1902e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1111,  0.0083,  0.0118,  ...,  0.0071, -0.0035, -0.0116],
        [ 0.0102, -0.1152,  0.0030,  ...,  0.0047, -0.0080,  0.0089],
        [-0.0012, -0.0107, -0.1214,  ...,  0.0024,  0.0055, -0.0025],
        ...,
        [-0.0066,  0.0020, -0.0026,  ..., -0.1210,  0.0194, -0.0092],
        [ 0.0014, -0.0029, -0.0026,  ...,  0.0037, -0.1219,  0.0197],
        [-0.0067,  0.0019, -0.0036,  ..., -0.0064, -0.0090, -0.1027]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:00:34 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 11:00:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0264,  0.6870,  0.6343,  ..., -0.3994, -0.3992, -0.3906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2378, -0.1151, -0.5684,  ..., -0.4231, -0.1956,  0.0647],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0320,  0.9854,  0.5825,  ...,  0.4290, -0.5479,  0.5991],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2930, -0.5981, -0.9033,  ...,  0.1316, -0.3433,  0.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:00:34 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:00:34 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 11:01:18 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 11:01:46 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 11:02:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.4866e-03,  5.6887e-04,  2.0885e-03,  ..., -1.4935e-03,
         -1.0700e-03,  2.4796e-03],
        [-3.6926e-03,  7.4844e-03,  1.3056e-03,  ...,  9.5129e-04,
         -5.0306e-04,  8.7643e-04],
        [-1.7948e-03, -1.6041e-03,  7.3547e-03,  ..., -3.7823e-03,
          1.5306e-03, -6.6662e-04],
        ...,
        [ 6.4964e-03,  3.2902e-03,  5.1689e-03,  ...,  1.1299e-02,
         -9.4681e-03,  1.1826e-03],
        [-2.0504e-05, -3.6030e-03,  3.9597e-03,  ..., -1.8616e-03,
          7.0000e-03, -3.8548e-03],
        [-4.1771e-04, -8.7738e-04,  1.7128e-03,  ...,  2.0771e-03,
         -4.9782e-04,  4.9667e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1383, -0.0228,  0.0135,  ...,  0.0009,  0.0046, -0.0257],
        [-0.0046, -0.1376,  0.0002,  ...,  0.0045, -0.0033,  0.0004],
        [ 0.0027, -0.0096, -0.1287,  ..., -0.0086,  0.0010,  0.0051],
        ...,
        [-0.0069, -0.0050,  0.0119,  ..., -0.1266, -0.0004, -0.0078],
        [ 0.0063,  0.0020,  0.0100,  ..., -0.0041, -0.1252, -0.0018],
        [ 0.0018, -0.0131, -0.0032,  ..., -0.0090,  0.0066, -0.1429]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2637, -0.0018,  0.0023,  ..., -0.0106, -0.0082, -0.0029],
        [ 0.0141, -0.2617, -0.0022,  ..., -0.0058,  0.0095,  0.0072],
        [-0.0033,  0.0140, -0.2507,  ...,  0.0028, -0.0073, -0.0121],
        ...,
        [-0.0079, -0.0037, -0.0040,  ..., -0.2742,  0.0156, -0.0032],
        [-0.0088, -0.0142, -0.0176,  ...,  0.0025, -0.2489,  0.0012],
        [-0.0082, -0.0142, -0.0120,  ..., -0.0106,  0.0088, -0.2695]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:02:42 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 11:02:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1296,  0.7793,  0.7358,  ..., -0.1973, -0.6675, -0.3760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0203, -0.4819, -0.6685,  ..., -0.0715, -0.5195,  0.2408],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4763,  1.3535,  0.7676,  ...,  0.8682, -1.2129,  0.4404],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3496, -0.7397, -0.9287,  ...,  0.2891,  0.0874,  0.3237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:02:42 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:02:42 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 11:03:37 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 11:04:29 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 11:05:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.1013e-03,  6.2847e-04,  2.2392e-03,  ...,  1.0717e-04,
         -1.8797e-03, -2.8820e-03],
        [ 2.2221e-04, -1.3609e-03, -1.8921e-03,  ..., -2.9163e-03,
          1.8873e-03, -1.9188e-03],
        [ 6.5384e-03,  1.1549e-03, -8.4381e-03,  ..., -1.5259e-05,
         -5.9586e-03, -3.6860e-04],
        ...,
        [ 3.6030e-03, -4.4727e-04, -7.2765e-04,  ..., -6.1531e-03,
          5.9700e-04,  4.8218e-03],
        [-1.8959e-03,  5.7220e-05, -5.9080e-04,  ..., -1.8597e-03,
         -4.9667e-03,  2.3613e-03],
        [-2.2674e-04,  3.1137e-04,  3.2377e-04,  ...,  2.4271e-04,
         -1.7033e-03, -4.7607e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.2712e-02,  1.0986e-02, -3.2730e-03,  ..., -8.5602e-03,
         -8.9264e-03, -7.8201e-05],
        [ 1.2985e-02, -7.9529e-02,  3.9062e-03,  ...,  3.4142e-03,
          1.0117e-02,  7.3166e-03],
        [-7.3051e-04,  7.0572e-05, -9.3567e-02,  ..., -4.8828e-04,
          5.0163e-04,  2.3956e-03],
        ...,
        [ 9.1248e-03, -3.4389e-03,  4.2725e-03,  ..., -9.4788e-02,
          9.9945e-03,  3.7193e-03],
        [ 7.5188e-03, -6.9656e-03, -2.7161e-03,  ...,  2.0170e-04,
         -9.5093e-02,  1.2932e-02],
        [ 4.0245e-03,  1.1826e-02,  2.5177e-04,  ...,  1.2875e-03,
         -6.8245e-03, -8.4473e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0831, -0.0065, -0.0029,  ...,  0.0060, -0.0053,  0.0033],
        [-0.0026, -0.0967,  0.0069,  ..., -0.0105,  0.0041,  0.0022],
        [ 0.0009, -0.0073, -0.0991,  ..., -0.0036, -0.0071,  0.0136],
        ...,
        [ 0.0024,  0.0031,  0.0054,  ..., -0.0884,  0.0057, -0.0085],
        [-0.0034,  0.0029,  0.0012,  ...,  0.0107, -0.0884,  0.0043],
        [-0.0074,  0.0010,  0.0032,  ...,  0.0081, -0.0015, -0.0826]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:05:25 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 11:05:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0124,  0.5176,  0.2969,  ...,  0.2084, -0.3047,  0.3159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2246, -0.4814, -0.6450,  ...,  0.0732, -0.2477,  0.1805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2961,  1.3848,  0.5327,  ...,  1.4648, -0.5137,  0.7095],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2539, -0.4722, -1.7969,  ...,  0.2051,  0.0879,  0.1084],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:05:25 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:05:25 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 11:06:21 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 11:07:18 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 11:08:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2247e-02, -2.4819e-04, -6.8321e-03,  ...,  6.6948e-03,
         -7.5817e-05, -2.1324e-03],
        [-4.7798e-03,  2.7466e-02,  2.2278e-03,  ...,  3.7956e-03,
         -9.1314e-04, -2.9612e-04],
        [-1.0805e-03,  7.2002e-04,  2.0660e-02,  ..., -2.7905e-03,
          2.3804e-03, -1.2960e-03],
        ...,
        [-1.6093e-05,  5.3825e-03,  2.7428e-03,  ...,  2.7557e-02,
         -1.3542e-02,  3.6182e-03],
        [ 1.1683e-05, -8.2302e-04,  4.2000e-03,  ..., -7.2002e-04,
          2.9984e-02, -3.9196e-04],
        [ 3.8433e-03, -7.3776e-03, -7.8583e-04,  ..., -7.5722e-03,
         -3.3455e-03,  2.2873e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1077, -0.0025,  0.0066,  ..., -0.0071, -0.0069,  0.0092],
        [ 0.0061, -0.1169, -0.0089,  ..., -0.0005, -0.0061, -0.0093],
        [ 0.0082, -0.0148, -0.1111,  ..., -0.0063,  0.0134, -0.0220],
        ...,
        [-0.0217,  0.0069, -0.0019,  ..., -0.0999,  0.0043,  0.0088],
        [ 0.0054,  0.0013,  0.0073,  ...,  0.0094, -0.1045, -0.0086],
        [-0.0039, -0.0006, -0.0038,  ..., -0.0002,  0.0049, -0.1113]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1663, -0.0131,  0.0117,  ..., -0.0193,  0.0065,  0.0050],
        [-0.0082, -0.1771, -0.0002,  ...,  0.0007, -0.0019, -0.0003],
        [ 0.0095, -0.0013, -0.1552,  ..., -0.0129,  0.0060, -0.0063],
        ...,
        [-0.0013, -0.0158, -0.0048,  ..., -0.1594,  0.0006, -0.0024],
        [ 0.0051,  0.0023,  0.0034,  ...,  0.0022, -0.1611,  0.0047],
        [ 0.0045,  0.0044, -0.0004,  ..., -0.0059,  0.0129, -0.1592]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:08:19 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 11:08:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2712,  0.6553,  0.3342,  ...,  0.4060, -0.5845,  0.1656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2440, -0.4705, -0.5635,  ...,  0.1575,  0.0832,  0.1466],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.8818, 1.2061, 0.3655,  ..., 1.1367, 0.1763, 0.9062], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1133, -0.4355, -2.0684,  ..., -0.3872,  0.4268,  0.5542],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:08:19 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:08:19 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 11:09:19 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 11:10:16 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 11:11:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0014, -0.0052,  0.0026,  ..., -0.0020, -0.0072,  0.0005],
        [-0.0024,  0.0015, -0.0035,  ..., -0.0006, -0.0013, -0.0021],
        [-0.0020, -0.0013, -0.0019,  ..., -0.0028, -0.0035,  0.0037],
        ...,
        [ 0.0041, -0.0022,  0.0026,  ..., -0.0026, -0.0003,  0.0012],
        [ 0.0032,  0.0007,  0.0022,  ..., -0.0027,  0.0027, -0.0030],
        [ 0.0005,  0.0044,  0.0022,  ..., -0.0015, -0.0009, -0.0029]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.8237e-02, -9.4147e-03, -1.2465e-03,  ..., -6.4888e-03,
          5.5313e-05,  1.1566e-02],
        [-4.4708e-03, -7.2083e-02,  6.9427e-03,  ..., -1.9180e-02,
          7.7477e-03,  7.7667e-03],
        [-1.4221e-02, -2.9182e-04, -8.9172e-02,  ...,  3.6678e-03,
         -5.8861e-03,  9.4748e-04],
        ...,
        [ 1.4238e-03, -1.2405e-02,  2.3117e-03,  ..., -8.3313e-02,
          1.8883e-04,  6.4087e-03],
        [ 9.8495e-03,  1.4124e-03,  1.7776e-02,  ...,  2.1706e-03,
         -7.7026e-02,  5.3406e-04],
        [-5.0259e-04,  5.9357e-03, -1.1940e-02,  ..., -3.2158e-03,
          1.2875e-03, -9.7778e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1052,  0.0022,  0.0026,  ..., -0.0238,  0.0076,  0.0109],
        [ 0.0053, -0.1145, -0.0023,  ...,  0.0008,  0.0006,  0.0115],
        [-0.0057, -0.0040, -0.1180,  ..., -0.0056,  0.0029, -0.0004],
        ...,
        [-0.0064, -0.0120, -0.0009,  ..., -0.1161,  0.0142,  0.0127],
        [ 0.0044,  0.0153,  0.0024,  ..., -0.0055, -0.1074,  0.0077],
        [ 0.0006,  0.0073, -0.0120,  ..., -0.0042,  0.0032, -0.1170]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:11:16 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 11:11:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1353,  0.6240,  0.2384,  ...,  0.6616, -0.2365,  0.3032],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1578, -0.3096, -0.9966,  ...,  0.1051,  0.0570,  0.0306],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1387,  1.1152,  0.6826,  ...,  0.8862,  0.4524,  1.6494],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6162, -0.7607, -2.6250,  ..., -0.1528, -0.1670,  0.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:11:16 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:11:16 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 11:12:18 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 11:13:20 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 11:14:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0071,  0.0019,  0.0019,  ...,  0.0099,  0.0004,  0.0019],
        [ 0.0072,  0.0149, -0.0069,  ..., -0.0036,  0.0011, -0.0036],
        [-0.0016, -0.0023, -0.0011,  ..., -0.0066, -0.0068,  0.0004],
        ...,
        [-0.0061,  0.0008, -0.0030,  ...,  0.0138, -0.0071,  0.0003],
        [ 0.0176, -0.0020,  0.0044,  ..., -0.0004,  0.0139,  0.0044],
        [-0.0036,  0.0063,  0.0087,  ..., -0.0045,  0.0017,  0.0194]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0871, -0.0044,  0.0135,  ..., -0.0026,  0.0034,  0.0088],
        [ 0.0107, -0.1147, -0.0064,  ..., -0.0025,  0.0063, -0.0071],
        [ 0.0138,  0.0152, -0.0986,  ..., -0.0020, -0.0032,  0.0113],
        ...,
        [-0.0065, -0.0023,  0.0010,  ..., -0.0988,  0.0071, -0.0050],
        [ 0.0042, -0.0239, -0.0282,  ...,  0.0088, -0.1273,  0.0188],
        [ 0.0037,  0.0197,  0.0104,  ..., -0.0009,  0.0088, -0.0968]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1331, -0.0057,  0.0062,  ..., -0.0013,  0.0060,  0.0004],
        [ 0.0030, -0.1644,  0.0009,  ..., -0.0012, -0.0014, -0.0164],
        [-0.0050,  0.0121, -0.1632,  ..., -0.0036, -0.0131,  0.0109],
        ...,
        [ 0.0113,  0.0054,  0.0057,  ..., -0.1602, -0.0004, -0.0099],
        [ 0.0057, -0.0190, -0.0126,  ...,  0.0108, -0.1556,  0.0218],
        [ 0.0134,  0.0024,  0.0020,  ...,  0.0063,  0.0172, -0.1481]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:14:25 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 11:14:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.3699, 0.5659, 0.1395,  ..., 0.5117, 0.0829, 0.3928], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5557, -0.2283, -1.0479,  ..., -0.2012,  0.2286,  0.2688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.5508, 1.4463, 0.5088,  ..., 1.2480, 0.6738, 1.9160], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7803, -1.2422, -2.6250,  ...,  0.7578,  0.0820,  1.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:14:25 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:14:25 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 11:15:29 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 11:16:35 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 11:17:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.3433e-04,  8.7500e-05, -4.0932e-03,  ...,  4.1122e-03,
         -1.7242e-03, -2.8934e-03],
        [-2.6054e-03,  3.9787e-03, -1.1730e-04,  ...,  6.2943e-04,
          7.2241e-04,  1.3399e-03],
        [ 1.7786e-03, -2.3727e-03, -7.3385e-04,  ...,  2.7504e-03,
          6.2513e-04,  3.3164e-04],
        ...,
        [-3.6583e-03,  1.1482e-03, -3.9787e-03,  ...,  1.1883e-03,
         -5.2795e-03, -3.6955e-05],
        [ 8.4162e-04,  1.2741e-03, -8.8358e-04,  ...,  2.1935e-03,
         -1.3638e-03, -1.2465e-03],
        [-2.5444e-03,  5.2977e-04, -2.7771e-03,  ..., -1.4000e-03,
          4.7722e-03, -1.3852e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0554,  0.0045, -0.0173,  ...,  0.0064, -0.0009, -0.0068],
        [-0.0014, -0.0530,  0.0013,  ...,  0.0141, -0.0181,  0.0090],
        [ 0.0004, -0.0106, -0.0679,  ..., -0.0137, -0.0096, -0.0122],
        ...,
        [-0.0019,  0.0022, -0.0067,  ..., -0.0637, -0.0059,  0.0002],
        [ 0.0066,  0.0092, -0.0011,  ...,  0.0054, -0.0659, -0.0027],
        [ 0.0043, -0.0047,  0.0164,  ..., -0.0002, -0.0071, -0.0706]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.5327e-02, -6.8283e-03, -1.5305e-02,  ...,  7.5645e-03,
         -1.1063e-03, -2.0676e-02],
        [ 1.9440e-02, -8.7952e-02,  5.9471e-03,  ...,  2.9373e-04,
         -9.2239e-03,  1.8860e-02],
        [ 1.8814e-02,  3.9399e-05, -9.2224e-02,  ..., -7.2365e-03,
         -1.8616e-02, -1.3893e-02],
        ...,
        [-3.9101e-03,  5.1155e-03, -7.4463e-03,  ..., -8.4900e-02,
         -6.1455e-03,  1.0941e-02],
        [ 2.0798e-02,  2.4216e-02, -8.0719e-03,  ...,  1.3527e-02,
         -8.5693e-02, -2.3804e-03],
        [-1.1497e-02,  1.1520e-02,  1.3344e-02,  ...,  5.6686e-03,
         -1.8494e-02, -9.3323e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:17:41 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 11:17:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0745,  0.4680,  0.2751,  ...,  0.3542,  0.2006,  0.6543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2876, -0.3711, -1.2002,  ..., -0.0745, -0.0659,  0.2915],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.1812, 1.9932, 1.7256,  ..., 1.6504, 0.6289, 2.0234], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7334, -1.2676, -2.4590,  ...,  0.4290, -0.8369,  0.1504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:17:41 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:17:41 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 11:18:48 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 11:19:52 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 11:20:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.3057e-03, -2.1706e-03,  1.4429e-03,  ...,  1.4896e-03,
          6.8235e-04,  3.7937e-03],
        [-1.5240e-03, -4.8218e-03, -5.1880e-04,  ...,  4.6492e-04,
          1.9989e-03, -1.6298e-03],
        [-5.6553e-04, -5.3787e-04, -6.3057e-03,  ..., -5.2547e-04,
          1.7529e-03, -7.2479e-04],
        ...,
        [ 1.3247e-03, -5.3501e-04,  1.8463e-03,  ..., -3.2597e-03,
          1.6680e-03, -1.0567e-03],
        [ 2.1648e-03,  2.5101e-03, -4.6897e-04,  ...,  1.2100e-05,
         -9.3536e-03, -3.2406e-03],
        [-1.0023e-03,  1.5335e-03,  6.5470e-04,  ..., -1.7452e-03,
         -1.9016e-03, -6.9237e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0851, -0.0029,  0.0179,  ..., -0.0042,  0.0024,  0.0097],
        [-0.0026, -0.0903,  0.0128,  ..., -0.0004,  0.0105, -0.0197],
        [-0.0002, -0.0102, -0.0792,  ..., -0.0041,  0.0062, -0.0016],
        ...,
        [-0.0100, -0.0191,  0.0168,  ..., -0.0839,  0.0099, -0.0035],
        [ 0.0223, -0.0017,  0.0033,  ...,  0.0245, -0.0830, -0.0018],
        [-0.0037,  0.0078,  0.0061,  ..., -0.0225, -0.0023, -0.0759]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0927,  0.0102,  0.0092,  ...,  0.0100,  0.0061,  0.0108],
        [ 0.0061, -0.0861, -0.0128,  ..., -0.0076, -0.0042, -0.0166],
        [ 0.0119,  0.0050, -0.0978,  ...,  0.0023,  0.0082,  0.0076],
        ...,
        [-0.0021, -0.0201, -0.0007,  ..., -0.0981,  0.0040, -0.0070],
        [ 0.0055,  0.0110,  0.0116,  ...,  0.0097, -0.1116,  0.0055],
        [-0.0058,  0.0089,  0.0005,  ..., -0.0059,  0.0081, -0.0870]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:21:02 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 11:21:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.2032, 0.5786, 0.1838,  ..., 0.4890, 0.2764, 0.7349], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3423, -0.5557, -1.1709,  ...,  0.3394,  0.0440,  0.6416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7046,  1.5312,  2.4531,  ...,  0.9268, -0.1436,  2.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1826, -0.9546, -1.3877,  ...,  0.3428, -1.8320,  0.1170],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:21:02 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:21:02 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 11:22:06 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 11:23:14 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 11:24:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0112, -0.0007, -0.0016,  ..., -0.0005, -0.0030, -0.0005],
        [ 0.0011, -0.0116,  0.0029,  ...,  0.0010,  0.0021, -0.0043],
        [-0.0011, -0.0026, -0.0168,  ...,  0.0024,  0.0018, -0.0012],
        ...,
        [-0.0002,  0.0029,  0.0021,  ..., -0.0146, -0.0023, -0.0002],
        [-0.0001,  0.0002,  0.0057,  ..., -0.0012, -0.0172, -0.0005],
        [-0.0004,  0.0007, -0.0006,  ..., -0.0006,  0.0020, -0.0181]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0800,  0.0001, -0.0039,  ..., -0.0107, -0.0096, -0.0095],
        [ 0.0234, -0.1023,  0.0070,  ..., -0.0173,  0.0158,  0.0032],
        [-0.0056, -0.0003, -0.1164,  ...,  0.0122,  0.0087, -0.0180],
        ...,
        [-0.0005, -0.0043, -0.0071,  ..., -0.1182, -0.0034,  0.0087],
        [-0.0048,  0.0038,  0.0084,  ...,  0.0164, -0.1008,  0.0183],
        [-0.0141,  0.0020,  0.0087,  ..., -0.0011,  0.0082, -0.1094]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1057,  0.0135, -0.0100,  ..., -0.0019, -0.0097, -0.0049],
        [ 0.0109, -0.1169,  0.0058,  ..., -0.0073,  0.0071, -0.0051],
        [-0.0024, -0.0021, -0.1194,  ..., -0.0038,  0.0151, -0.0076],
        ...,
        [ 0.0044, -0.0062,  0.0100,  ..., -0.1091, -0.0022,  0.0070],
        [ 0.0040,  0.0059, -0.0214,  ..., -0.0058, -0.1109,  0.0078],
        [-0.0069,  0.0214, -0.0153,  ..., -0.0006, -0.0068, -0.1154]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:24:26 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 11:24:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.0657, 0.7593, 0.6196,  ..., 0.6216, 0.2639, 0.7471], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3352, -0.5771, -1.0928,  ...,  0.1882, -0.3545,  0.0252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.4473, 2.1133, 2.8086,  ..., 2.0742, 0.4141, 1.0898], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1055, -1.2334, -0.3320,  ...,  0.2798, -1.3887,  0.9233],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:24:26 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:24:26 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 11:25:36 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 11:26:50 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 11:28:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0053,  0.0005,  0.0027,  ...,  0.0011, -0.0054, -0.0045],
        [ 0.0065,  0.0120, -0.0067,  ...,  0.0065,  0.0009, -0.0055],
        [ 0.0004,  0.0015,  0.0117,  ..., -0.0099, -0.0026,  0.0060],
        ...,
        [-0.0001, -0.0037, -0.0058,  ...,  0.0122,  0.0025, -0.0008],
        [-0.0013, -0.0061, -0.0015,  ..., -0.0003,  0.0142,  0.0094],
        [-0.0015, -0.0019,  0.0053,  ..., -0.0039, -0.0029,  0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0312,  0.0011,  0.0012,  ...,  0.0042,  0.0194,  0.0022],
        [ 0.0189, -0.0161, -0.0068,  ...,  0.0011, -0.0012, -0.0113],
        [-0.0069,  0.0030, -0.0120,  ..., -0.0042, -0.0031,  0.0038],
        ...,
        [ 0.0021, -0.0161, -0.0171,  ..., -0.0136,  0.0005, -0.0134],
        [ 0.0127, -0.0079, -0.0011,  ...,  0.0143, -0.0302, -0.0111],
        [-0.0091,  0.0040,  0.0218,  ..., -0.0025, -0.0040, -0.0079]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0531,  0.0014,  0.0090,  ..., -0.0130,  0.0002, -0.0118],
        [ 0.0154, -0.0309,  0.0067,  ...,  0.0151,  0.0037,  0.0047],
        [ 0.0033,  0.0168, -0.0449,  ..., -0.0077, -0.0006,  0.0177],
        ...,
        [ 0.0090,  0.0110, -0.0168,  ..., -0.0484, -0.0144, -0.0119],
        [-0.0026,  0.0075, -0.0096,  ...,  0.0066, -0.0442,  0.0142],
        [-0.0065, -0.0044,  0.0153,  ..., -0.0111,  0.0129, -0.0379]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:28:03 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 11:28:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2542,  0.5347,  0.8149,  ...,  0.3264, -0.0555,  0.8018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4968, -0.4072, -0.5664,  ...,  0.1417, -0.7480,  0.0169],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.8877,  2.2012,  2.6680,  ...,  1.7734, -0.5107,  0.1113],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.8281,  0.2930, -1.1328,  ...,  0.1265, -2.0098,  0.9946],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:28:03 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:28:03 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 11:29:17 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 11:30:31 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 11:31:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.0065e-03,  3.8218e-04,  7.4816e-04,  ...,  4.7064e-04,
         -6.9427e-04, -8.0490e-04],
        [-9.5081e-04, -3.3131e-03, -2.2869e-03,  ..., -4.0359e-03,
         -5.4932e-03,  6.3324e-03],
        [-3.4857e-04, -4.0169e-03, -7.0648e-03,  ..., -2.6569e-03,
          2.1210e-03,  4.2114e-03],
        ...,
        [ 3.4904e-04, -1.9836e-03, -2.6112e-03,  ..., -5.6152e-03,
          3.1166e-03,  6.0558e-04],
        [-4.7493e-03,  1.8835e-05,  2.6321e-03,  ...,  1.1625e-03,
         -5.7106e-03, -5.9357e-03],
        [-3.2444e-03,  7.3051e-04, -4.4403e-03,  ..., -1.9073e-03,
         -7.4196e-04, -1.1692e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.8061e-02,  6.1178e-04, -8.1396e-04,  ..., -3.3760e-04,
         -1.4626e-02,  1.9336e-04],
        [-6.2561e-04, -3.6499e-02, -5.3062e-03,  ...,  6.3744e-03,
          1.9417e-03, -9.6436e-03],
        [ 1.2264e-03,  1.3382e-02, -4.2572e-02,  ..., -3.7718e-04,
          1.3329e-02, -1.0147e-02],
        ...,
        [-6.5956e-03,  1.0498e-02, -2.1179e-02,  ..., -1.0536e-02,
         -3.6144e-03, -1.3680e-02],
        [ 9.8038e-03,  5.1842e-03, -1.6266e-02,  ..., -6.4774e-03,
         -3.1403e-02,  1.2413e-02],
        [-1.0681e-03, -9.6588e-03, -3.6469e-03,  ..., -6.7711e-05,
          6.3095e-03, -3.3386e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0432,  0.0186,  0.0016,  ...,  0.0216, -0.0228,  0.0140],
        [-0.0026, -0.0613,  0.0040,  ...,  0.0236, -0.0016,  0.0117],
        [ 0.0028, -0.0077, -0.0685,  ...,  0.0004, -0.0015, -0.0022],
        ...,
        [-0.0095,  0.0056, -0.0179,  ..., -0.0490,  0.0137,  0.0045],
        [ 0.0012,  0.0042,  0.0023,  ...,  0.0039, -0.0535,  0.0006],
        [-0.0003, -0.0247, -0.0101,  ...,  0.0035,  0.0074, -0.0627]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:31:46 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 11:31:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.4836, 0.6958, 0.9146,  ..., 0.6743, 0.1451, 0.3391], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4387, -0.5015, -0.1406,  ...,  0.0970, -0.5391,  0.3413],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3848,  2.9902,  2.4922,  ...,  1.1777, -0.5742,  0.2549],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.5879, -0.0266, -0.6660,  ...,  0.8057, -2.2754, -0.8784],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:31:46 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:31:46 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 11:33:07 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 11:34:24 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 11:35:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.0485e-03, -2.2392e-03, -5.6419e-03,  ...,  5.9471e-03,
         -3.9558e-03, -3.5703e-05],
        [-9.4795e-04, -7.3624e-04,  9.2506e-04,  ...,  4.8180e-03,
          2.9907e-03,  5.4979e-04],
        [-4.0007e-04, -3.5820e-03,  1.2291e-02,  ..., -1.1683e-03,
          1.0939e-03,  7.8678e-04],
        ...,
        [ 3.0842e-03,  4.0359e-03, -4.4785e-03,  ...,  1.3504e-02,
          5.2738e-04,  1.0700e-03],
        [-2.4586e-03, -2.8563e-04,  4.1084e-03,  ...,  2.8744e-03,
          1.0700e-03, -3.1223e-03],
        [-1.7366e-03, -2.3251e-03,  7.8278e-03,  ..., -5.1165e-04,
          9.7046e-03,  1.0719e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0319, -0.0117, -0.0003,  ...,  0.0070,  0.0051,  0.0154],
        [-0.0041, -0.0279, -0.0057,  ..., -0.0005,  0.0064, -0.0108],
        [ 0.0049,  0.0006, -0.0212,  ...,  0.0126, -0.0017,  0.0085],
        ...,
        [-0.0049, -0.0162,  0.0033,  ..., -0.0329,  0.0142, -0.0111],
        [-0.0167, -0.0031, -0.0045,  ..., -0.0017, -0.0381,  0.0060],
        [ 0.0047, -0.0008, -0.0013,  ..., -0.0125, -0.0065, -0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0249,  0.0039, -0.0034,  ...,  0.0051,  0.0110,  0.0025],
        [-0.0040, -0.0359, -0.0099,  ...,  0.0081,  0.0193, -0.0038],
        [-0.0062,  0.0096, -0.0466,  ..., -0.0007, -0.0047,  0.0017],
        ...,
        [ 0.0085, -0.0220, -0.0058,  ..., -0.0470,  0.0077, -0.0041],
        [ 0.0069, -0.0097, -0.0010,  ..., -0.0110, -0.0537, -0.0077],
        [ 0.0035, -0.0060,  0.0013,  ..., -0.0259, -0.0083, -0.0349]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:35:40 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 11:35:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6255,  0.6968,  0.8364,  ...,  0.5703, -0.1567,  0.0047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.0967,  0.1053, -0.4348,  ...,  0.0515, -0.7603,  0.3557],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([2.9336, 2.9922, 4.2383,  ..., 0.9512, 0.2129, 0.6553], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.3828,  0.8291, -0.0635,  ...,  1.3447, -2.7461, -0.4578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:35:40 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:35:40 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 11:36:56 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 11:38:13 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 11:39:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.4370e-04,  3.3212e-04,  1.5712e-04,  ..., -3.5405e-05,
         -2.0790e-04, -1.2994e-04],
        [-2.3782e-04,  5.7757e-05,  2.7609e-04,  ...,  2.2745e-04,
         -2.3830e-04,  3.9577e-04],
        [-2.8872e-04,  3.9768e-04, -2.5296e-04,  ..., -1.8311e-04,
         -1.2398e-04, -9.4652e-05],
        ...,
        [ 3.0935e-05, -2.1291e-04,  9.8705e-05,  ..., -4.0364e-04,
          1.9407e-04,  1.3804e-04],
        [-2.7919e-04,  2.0862e-04, -4.4346e-05,  ..., -4.8757e-05,
         -5.0020e-04,  2.3556e-04],
        [ 7.4148e-05, -3.0088e-04,  7.2300e-05,  ..., -1.3769e-05,
          3.5024e-04, -4.7684e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0476,  0.0070, -0.0170,  ...,  0.0221,  0.0045,  0.0046],
        [ 0.0064, -0.0450,  0.0052,  ..., -0.0089,  0.0107, -0.0002],
        [-0.0011, -0.0005, -0.0344,  ..., -0.0084,  0.0160,  0.0094],
        ...,
        [ 0.0116,  0.0072, -0.0074,  ..., -0.0346, -0.0066,  0.0177],
        [ 0.0083, -0.0015,  0.0080,  ...,  0.0104, -0.0464, -0.0027],
        [-0.0139, -0.0180,  0.0096,  ..., -0.0175, -0.0089, -0.0203]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0667,  0.0060,  0.0047,  ...,  0.0013,  0.0056,  0.0122],
        [ 0.0222, -0.0269, -0.0050,  ..., -0.0095,  0.0055,  0.0024],
        [ 0.0109, -0.0009, -0.0508,  ..., -0.0018,  0.0222,  0.0012],
        ...,
        [ 0.0194,  0.0132,  0.0018,  ..., -0.0575, -0.0194,  0.0064],
        [ 0.0034, -0.0120, -0.0008,  ...,  0.0102, -0.0518, -0.0121],
        [-0.0086, -0.0040,  0.0164,  ..., -0.0140, -0.0110, -0.0463]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:39:34 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 11:39:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7720,  0.9165,  0.7368,  ...,  0.3669, -0.1608,  0.0500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9619, -0.0104, -0.2603,  ...,  0.2891, -0.8057, -0.3545],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.0977,  3.0527,  3.9434,  ..., -0.6895, -0.1499,  1.0908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.7969,  0.6509,  0.5049,  ...,  1.9453, -3.8359, -0.0735],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:39:34 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:39:34 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 11:40:53 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 11:42:12 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 11:43:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.5510e-04, -9.2745e-05,  1.1808e-04,  ...,  2.2793e-04,
          4.3869e-05, -1.9014e-05],
        [-1.4791e-03,  5.6314e-04,  1.4651e-04,  ...,  2.4021e-04,
          1.1806e-03, -5.1737e-04],
        [ 4.1175e-04,  3.8767e-04, -4.6945e-04,  ..., -3.3498e-04,
         -4.1842e-04,  1.8811e-04],
        ...,
        [ 8.3566e-05, -3.3045e-04, -5.9557e-04,  ...,  1.6081e-04,
         -2.9445e-04, -4.8637e-04],
        [ 1.2512e-03, -8.0872e-04, -1.9431e-05,  ...,  1.1597e-03,
         -2.4986e-04,  1.0328e-03],
        [-1.6999e-04,  7.3791e-05,  9.6035e-04,  ...,  5.5122e-04,
         -2.5368e-04, -2.8038e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0229, -0.0059,  0.0059,  ..., -0.0005,  0.0028,  0.0062],
        [ 0.0131, -0.0426, -0.0001,  ..., -0.0011,  0.0089, -0.0183],
        [-0.0087,  0.0041, -0.0229,  ..., -0.0184,  0.0197, -0.0031],
        ...,
        [-0.0026,  0.0009, -0.0053,  ..., -0.0139,  0.0199, -0.0053],
        [-0.0078, -0.0095, -0.0038,  ...,  0.0013, -0.0190,  0.0203],
        [ 0.0019, -0.0210,  0.0138,  ..., -0.0057,  0.0177, -0.0288]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0511, -0.0036, -0.0194,  ..., -0.0235,  0.0033, -0.0177],
        [-0.0068, -0.0678, -0.0039,  ..., -0.0062,  0.0178,  0.0013],
        [ 0.0008,  0.0055, -0.0524,  ..., -0.0102, -0.0060, -0.0017],
        ...,
        [-0.0146,  0.0016, -0.0157,  ..., -0.0438, -0.0041, -0.0035],
        [ 0.0042, -0.0090,  0.0057,  ..., -0.0059, -0.0789, -0.0021],
        [-0.0061,  0.0039,  0.0062,  ..., -0.0002, -0.0032, -0.0615]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:43:35 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 11:43:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.9131, 0.9058, 1.2354,  ..., 0.2751, 0.0754, 0.1736], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1914,  0.3010, -0.0711,  ...,  0.4460, -0.9507, -0.1935],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([2.6562, 3.2363, 4.1875,  ..., 0.1152, 0.2437, 1.9492], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6973e+00,  2.1016e+00,  4.5874e-01,  ...,  1.9043e+00,
        -3.5195e+00, -2.4414e-03], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:43:35 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:43:35 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 11:44:57 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 11:46:18 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 11:47:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8530e-03,  1.3864e-04,  9.5224e-04,  ...,  1.9484e-03,
          2.6855e-03,  8.4019e-04],
        [-7.2479e-04, -9.1791e-06, -6.8092e-04,  ...,  8.4305e-04,
         -3.5572e-03,  3.0556e-03],
        [ 1.0185e-03, -9.4891e-04,  3.7651e-03,  ..., -1.6499e-04,
          1.3695e-03, -1.7958e-03],
        ...,
        [ 1.6413e-03, -1.1463e-03,  1.5059e-03,  ...,  3.0918e-03,
         -4.2319e-04, -1.5125e-03],
        [ 1.1349e-03,  8.0824e-04, -6.5994e-04,  ...,  1.8024e-03,
          3.0365e-03, -6.4278e-03],
        [-6.8009e-05, -2.4700e-03, -2.3937e-03,  ...,  1.6928e-04,
         -6.1274e-04,  5.1651e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0229, -0.0037, -0.0023,  ..., -0.0038,  0.0063,  0.0135],
        [-0.0168, -0.0245,  0.0131,  ...,  0.0044,  0.0130, -0.0053],
        [ 0.0123,  0.0116,  0.0039,  ...,  0.0134,  0.0032, -0.0089],
        ...,
        [-0.0155,  0.0102, -0.0052,  ...,  0.0526,  0.0106, -0.0123],
        [ 0.0097, -0.0054, -0.0005,  ...,  0.0308,  0.0090,  0.0070],
        [ 0.0049,  0.0198, -0.0198,  ..., -0.0038,  0.0054,  0.0050]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0281, -0.0230,  0.0085,  ..., -0.0065, -0.0282,  0.0264],
        [-0.0122, -0.0627,  0.0148,  ...,  0.0299,  0.0183,  0.0114],
        [ 0.0062, -0.0062, -0.0339,  ...,  0.0041,  0.0063, -0.0117],
        ...,
        [-0.0168,  0.0172, -0.0143,  ..., -0.0174,  0.0174, -0.0194],
        [ 0.0177,  0.0032,  0.0093,  ..., -0.0066, -0.0328,  0.0292],
        [-0.0089,  0.0144, -0.0063,  ...,  0.0195,  0.0110, -0.0323]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:47:43 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 11:47:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9502,  0.8911,  1.1172,  ..., -0.2411, -0.0485,  0.2900],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9697,  0.2317,  0.1125,  ...,  0.6079, -1.2881, -0.0670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.7822, 3.0469, 3.4551,  ..., 0.4397, 0.0358, 2.0352], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2109,  1.2871, -0.0369,  ...,  2.8555, -4.4844, -0.4648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:47:43 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:47:43 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 11:49:06 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 11:50:28 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 11:51:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3752e-03,  1.1116e-04, -4.3225e-04,  ...,  1.8091e-03,
          4.4107e-04,  5.2547e-04],
        [ 3.2783e-06, -2.6798e-03, -1.3351e-03,  ..., -2.9421e-04,
          3.4428e-04,  4.9591e-04],
        [-7.0047e-04, -7.6675e-04, -3.2539e-03,  ..., -9.4604e-04,
          2.5139e-03, -2.2316e-03],
        ...,
        [ 3.0823e-03,  1.2660e-04, -2.8572e-03,  ...,  1.5583e-03,
         -2.5320e-04, -1.9360e-04],
        [ 2.4357e-03, -3.5024e-04, -3.0184e-04,  ...,  7.6890e-06,
         -3.8624e-03, -9.0694e-04],
        [ 2.0065e-03,  3.8433e-04,  2.1324e-03,  ...,  4.6229e-04,
          1.7948e-03, -3.5477e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0005,  0.0197, -0.0060,  ..., -0.0100,  0.0077, -0.0043],
        [-0.0102, -0.0180,  0.0128,  ...,  0.0071,  0.0046, -0.0175],
        [ 0.0260, -0.0100, -0.0011,  ...,  0.0107,  0.0038,  0.0034],
        ...,
        [ 0.0009, -0.0093, -0.0124,  ...,  0.0043,  0.0042, -0.0136],
        [-0.0166,  0.0233, -0.0028,  ..., -0.0035, -0.0182,  0.0021],
        [ 0.0054, -0.0152, -0.0179,  ...,  0.0126, -0.0193, -0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0156,  0.0120,  0.0109,  ..., -0.0173,  0.0078, -0.0031],
        [ 0.0011, -0.0331,  0.0025,  ..., -0.0125, -0.0028,  0.0077],
        [ 0.0106, -0.0039, -0.0355,  ...,  0.0015, -0.0322,  0.0153],
        ...,
        [ 0.0016, -0.0034, -0.0247,  ..., -0.0421,  0.0165, -0.0177],
        [ 0.0049,  0.0095, -0.0060,  ...,  0.0098, -0.0388,  0.0442],
        [ 0.0092,  0.0023, -0.0251,  ...,  0.0101,  0.0152, -0.0216]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:51:54 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 11:51:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7788,  0.8701,  1.0254,  ..., -0.0682,  0.0373,  0.4749],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5898,  0.6621,  0.0534,  ...,  0.4875, -1.1172, -0.0596],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.7012,  3.3398,  1.3398,  ..., -1.5078, -0.0895,  0.5400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.0859,  1.6143, -1.3916,  ...,  2.4980, -5.2227, -0.2754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:51:54 root INFO     [order_1_approx] starting weight calculation for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:51:54 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 11:53:14 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 11:54:40 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 11:56:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.5002e-03, -1.2875e-03, -4.9496e-04,  ...,  1.4839e-03,
         -3.2043e-04,  4.0948e-05],
        [ 6.2513e-04, -2.7084e-03,  7.3195e-04,  ..., -4.2939e-04,
          8.4734e-04,  7.0477e-04],
        [ 1.6394e-03, -1.5850e-03, -3.8662e-03,  ..., -2.7370e-04,
         -7.8726e-04,  9.3460e-04],
        ...,
        [ 5.1451e-04,  6.9571e-04,  2.9039e-04,  ..., -5.7793e-03,
          6.4421e-04, -3.3069e-04],
        [ 1.3027e-03, -2.4128e-04,  3.4928e-04,  ..., -1.0347e-03,
         -3.4237e-03, -2.0676e-03],
        [-3.3021e-04,  1.0271e-03, -3.8266e-04,  ...,  8.1682e-04,
         -7.5197e-04, -3.7670e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0296, -0.0031, -0.0063,  ...,  0.0126, -0.0134, -0.0001],
        [ 0.0038,  0.0029,  0.0020,  ..., -0.0123,  0.0183,  0.0098],
        [-0.0201, -0.0033,  0.0328,  ..., -0.0109,  0.0072,  0.0036],
        ...,
        [ 0.0063, -0.0068, -0.0008,  ...,  0.0691,  0.0014, -0.0128],
        [ 0.0018, -0.0177, -0.0226,  ..., -0.0042,  0.0157,  0.0248],
        [-0.0043,  0.0217, -0.0002,  ...,  0.0076, -0.0045,  0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0525, -0.0209,  0.0035,  ..., -0.0011,  0.0014,  0.0006],
        [ 0.0118, -0.0374, -0.0093,  ...,  0.0084,  0.0228,  0.0010],
        [-0.0322,  0.0005, -0.0218,  ..., -0.0059, -0.0093, -0.0017],
        ...,
        [ 0.0007, -0.0018, -0.0175,  ..., -0.0293,  0.0084, -0.0006],
        [ 0.0165,  0.0067, -0.0024,  ...,  0.0141, -0.0265, -0.0212],
        [-0.0399,  0.0239,  0.0141,  ...,  0.0099, -0.0097, -0.0207]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:56:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The jackal falls into the category of canine
The falcon falls into the category of raptor
The leopard falls into the category of feline
The butterfly falls into the category of
2024-06-30 11:56:09 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 11:56:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3162, -0.0758, -0.8608,  ...,  0.0305, -0.2343,  0.2343],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4744, -0.1161, -0.5581,  ..., -0.1461, -0.9219, -0.4143],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2335, -0.3350, -0.6748,  ...,  0.3333, -0.7290,  0.0895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4575,  0.0859, -0.2391,  ..., -0.5610, -0.4097, -0.5171],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:56:09 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 11:56:09 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 11:56:32 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 11:56:54 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 11:57:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.0585e-04, -1.6165e-04,  1.4579e-04,  ..., -2.9922e-05,
         -2.0254e-04, -2.7955e-05],
        [ 1.5759e-04, -5.2166e-04, -9.4056e-05,  ..., -8.4639e-05,
          1.6999e-04,  5.9187e-05],
        [ 3.3045e-04,  1.8239e-04, -8.8406e-04,  ..., -1.5163e-04,
         -1.3256e-04,  1.2118e-04],
        ...,
        [-1.2910e-04, -2.2769e-05, -1.0520e-04,  ..., -2.9039e-04,
          3.5119e-04,  2.4939e-04],
        [ 1.0669e-04,  6.9261e-05, -1.8907e-04,  ..., -6.5148e-05,
         -6.1893e-04, -1.7297e-04],
        [-6.0201e-05, -3.3975e-06,  2.9922e-04,  ..., -1.6928e-04,
          3.8743e-04, -7.3671e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0115,  0.0117,  0.0032,  ...,  0.0007, -0.0102,  0.0072],
        [-0.0024, -0.0222, -0.0005,  ..., -0.0010,  0.0102, -0.0019],
        [-0.0006, -0.0023, -0.0238,  ...,  0.0003,  0.0019,  0.0020],
        ...,
        [ 0.0033, -0.0039,  0.0017,  ..., -0.0130,  0.0042,  0.0112],
        [-0.0014, -0.0034, -0.0012,  ...,  0.0010, -0.0128,  0.0011],
        [-0.0095,  0.0060, -0.0007,  ..., -0.0076, -0.0087, -0.0103]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0518e-02,  3.7861e-04,  6.4545e-03,  ..., -1.1816e-03,
         -1.5869e-03,  4.3774e-04],
        [ 7.1239e-04, -2.6657e-02, -6.3553e-03,  ..., -2.0046e-03,
          2.5311e-03,  6.1798e-04],
        [-3.0446e-04,  2.1801e-03, -2.5299e-02,  ...,  2.6226e-04,
         -2.0599e-03,  5.5313e-03],
        ...,
        [ 2.4147e-03,  3.5648e-03,  8.5640e-04,  ..., -2.2247e-02,
          3.2043e-03,  1.7366e-03],
        [-1.5774e-03,  2.0809e-03, -1.1313e-04,  ...,  9.0837e-05,
         -2.5131e-02,  9.1505e-04],
        [-3.8719e-04, -2.2240e-03, -2.9297e-03,  ...,  1.1997e-03,
          4.6706e-04, -2.8305e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:57:19 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 11:57:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2708, -0.3318, -1.2422,  ...,  0.0728, -0.7085,  0.3469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5376,  0.1589, -0.3601,  ..., -1.0596, -0.4570, -0.4790],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2467, -0.6572, -0.7666,  ...,  0.3594, -0.4253, -0.4512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2827, -0.1272,  0.2666,  ..., -1.2354, -0.5190, -0.5332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:57:20 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 11:57:20 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 11:57:44 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 11:58:08 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 11:58:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0891e-03, -1.6117e-04, -4.1699e-04,  ..., -5.1737e-05,
          3.3784e-04, -4.7731e-04],
        [ 3.0088e-04, -2.2316e-03, -1.9073e-05,  ...,  1.0033e-03,
         -1.8895e-04,  8.2612e-05],
        [-3.0518e-04,  3.3402e-04, -2.2717e-03,  ..., -2.1195e-04,
          5.2989e-05, -3.0971e-04],
        ...,
        [ 1.9264e-04, -2.3150e-04, -3.7074e-04,  ..., -1.2989e-03,
         -5.5695e-04, -6.8486e-05],
        [-1.2517e-04,  7.0620e-04,  4.8542e-04,  ..., -3.2854e-04,
         -1.8082e-03, -3.0851e-04],
        [-6.1512e-05,  7.3552e-05,  7.4196e-04,  ...,  1.7822e-04,
          1.9574e-04, -1.9760e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.0248e-02, -5.8327e-03, -4.4746e-03,  ..., -8.9264e-04,
         -1.0818e-02, -4.2963e-04],
        [-7.8201e-05, -3.6713e-02,  7.2823e-03,  ...,  5.6381e-03,
         -1.8631e-02,  3.4428e-03],
        [-5.0507e-03, -6.8283e-04, -3.2654e-02,  ..., -3.5820e-03,
         -9.5596e-03,  5.2834e-04],
        ...,
        [ 6.6605e-03,  8.0872e-03, -9.0866e-03,  ..., -2.6016e-02,
          3.8681e-03, -2.2945e-03],
        [-1.2184e-02, -7.3929e-03,  3.9291e-03,  ..., -3.0136e-03,
         -2.5497e-02,  1.5831e-03],
        [ 5.0430e-03,  2.1095e-03,  1.2405e-02,  ...,  2.6131e-03,
         -6.8169e-03, -2.8107e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.9631e-02,  4.4060e-04, -2.2354e-03,  ...,  7.5531e-03,
          5.5618e-03,  1.6556e-03],
        [-1.9894e-03, -6.4453e-02, -2.9182e-03,  ...,  4.4441e-04,
         -1.3514e-03, -3.5934e-03],
        [ 9.4032e-04,  2.9926e-03, -6.0760e-02,  ...,  2.3460e-03,
          2.5558e-03,  5.7602e-04],
        ...,
        [ 3.1281e-03, -4.3945e-03,  8.9645e-05,  ..., -5.8594e-02,
         -6.5346e-03, -9.5215e-03],
        [-7.9346e-03, -5.3368e-03,  4.2725e-03,  ..., -5.4703e-03,
         -6.2683e-02,  4.6730e-03],
        [ 2.4586e-03, -1.2802e-02,  5.5923e-03,  ...,  3.0861e-03,
          1.3132e-03, -5.4169e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:58:33 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 11:58:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2781, -0.4475, -0.8389,  ...,  0.4026, -0.8940,  0.0951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7456,  0.1200, -0.3767,  ..., -0.8433, -0.6353, -0.8672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6226, -1.5117, -0.3618,  ...,  0.4885, -0.2029,  0.2246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5142,  0.3777,  0.1855,  ..., -0.9434, -0.6714, -0.7568],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:58:33 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 11:58:33 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 11:58:58 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 11:59:23 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 11:59:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.3112e-03,  8.4341e-05, -1.6928e-04,  ...,  3.4809e-04,
         -2.3305e-05,  5.2595e-04],
        [ 4.9543e-04, -1.8692e-03,  1.6868e-04,  ..., -3.6240e-05,
         -1.9038e-04,  2.0266e-04],
        [ 3.4952e-04, -8.5163e-04, -2.2831e-03,  ...,  3.4714e-04,
          3.0160e-04, -3.9482e-04],
        ...,
        [ 2.7132e-04,  4.6730e-04,  3.2663e-05,  ..., -1.8692e-03,
          6.7139e-04, -3.0565e-04],
        [-4.2796e-04, -2.9039e-04, -1.1234e-03,  ...,  9.9945e-04,
         -1.7815e-03, -1.0834e-03],
        [ 2.4676e-04,  1.4830e-04,  3.0327e-04,  ..., -2.4748e-04,
         -5.0545e-04, -1.7414e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0082,  0.0061,  0.0022,  ...,  0.0084,  0.0074, -0.0060],
        [-0.0005, -0.0287, -0.0021,  ..., -0.0098,  0.0086,  0.0002],
        [-0.0022, -0.0101, -0.0186,  ...,  0.0007, -0.0010, -0.0028],
        ...,
        [-0.0072, -0.0076, -0.0084,  ..., -0.0272, -0.0086,  0.0070],
        [ 0.0012,  0.0044, -0.0117,  ...,  0.0092, -0.0165,  0.0181],
        [-0.0058,  0.0113,  0.0052,  ..., -0.0007,  0.0033, -0.0335]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0300, -0.0009, -0.0042,  ...,  0.0018,  0.0026,  0.0062],
        [-0.0033, -0.0315, -0.0009,  ...,  0.0066,  0.0032,  0.0015],
        [ 0.0004,  0.0003, -0.0348,  ..., -0.0021, -0.0025, -0.0054],
        ...,
        [ 0.0003,  0.0019, -0.0013,  ..., -0.0307, -0.0059,  0.0035],
        [-0.0009,  0.0027, -0.0015,  ..., -0.0052, -0.0293,  0.0089],
        [ 0.0038,  0.0045,  0.0035,  ..., -0.0048,  0.0010, -0.0280]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 11:59:51 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 11:59:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2849, -0.8359, -0.9077,  ...,  0.4265, -0.5215, -0.5991],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4329, -0.2072,  0.3811,  ..., -1.6953, -0.7461, -0.8237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3022, -1.0693, -0.3726,  ...,  0.4946,  0.0776,  0.2090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2104,  0.6021, -0.3169,  ..., -1.0391, -0.3501, -0.3701],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 11:59:51 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 11:59:51 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 12:00:21 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 12:00:51 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 12:01:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6546e-03,  3.7622e-04,  1.5998e-04,  ...,  8.3208e-04,
         -6.1035e-04, -1.0026e-04],
        [-3.8862e-04, -1.4458e-03,  6.3848e-04,  ..., -1.4257e-04,
          8.2791e-05, -4.3726e-04],
        [-3.2234e-04,  7.1526e-04, -1.6260e-03,  ..., -1.0401e-04,
          5.7983e-04, -4.0817e-04],
        ...,
        [-5.6887e-04, -4.3535e-04, -1.3227e-03,  ..., -1.3962e-03,
         -1.3390e-03,  1.3375e-04],
        [-6.2656e-04,  1.4460e-04, -2.2531e-04,  ..., -2.3127e-05,
         -1.0223e-03, -3.8457e-04],
        [ 8.7023e-04, -1.0786e-03,  3.6430e-04,  ...,  1.0357e-03,
          6.8665e-04, -2.4357e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0369,  0.0102,  0.0021,  ..., -0.0013,  0.0055,  0.0021],
        [-0.0136, -0.0286,  0.0019,  ...,  0.0013,  0.0085,  0.0013],
        [ 0.0003, -0.0073, -0.0249,  ..., -0.0156,  0.0050, -0.0149],
        ...,
        [-0.0007, -0.0036, -0.0118,  ..., -0.0244, -0.0095,  0.0037],
        [-0.0011, -0.0053, -0.0004,  ...,  0.0002, -0.0414, -0.0063],
        [ 0.0091,  0.0023, -0.0077,  ...,  0.0042,  0.0015, -0.0255]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0575,  0.0012,  0.0007,  ..., -0.0029,  0.0096, -0.0058],
        [ 0.0043, -0.0472,  0.0003,  ...,  0.0041, -0.0006,  0.0010],
        [-0.0009, -0.0035, -0.0398,  ...,  0.0049, -0.0034,  0.0004],
        ...,
        [-0.0057, -0.0074,  0.0008,  ..., -0.0603, -0.0011, -0.0134],
        [-0.0001,  0.0036, -0.0111,  ..., -0.0057, -0.0386, -0.0068],
        [-0.0026, -0.0006, -0.0044,  ..., -0.0065, -0.0024, -0.0504]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:01:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 12:01:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6118, -1.6279, -0.3433,  ...,  0.4565, -0.1696,  0.1974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5366,  0.3623,  0.1920,  ..., -0.9219, -0.6626, -0.8452],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2993, -1.9531, -0.0391,  ...,  1.0303, -0.6123, -0.0072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1580,  0.2874,  0.0071,  ..., -0.8477, -0.3809, -0.4900],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:01:21 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:01:21 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 12:01:48 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 12:02:21 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 12:02:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.8161e-05,  1.1368e-03, -1.6384e-03,  ...,  6.7425e-04,
          8.7166e-04, -6.8486e-05],
        [ 7.0667e-04,  5.7745e-04, -2.4700e-04,  ...,  1.1373e-04,
          2.2030e-04, -2.1756e-04],
        [ 1.4896e-03,  1.4029e-03, -4.5204e-04,  ..., -4.5323e-04,
         -6.4135e-04,  4.1723e-04],
        ...,
        [ 1.7500e-04,  3.7599e-04, -1.1473e-03,  ..., -1.8797e-03,
         -1.0614e-03,  1.9703e-03],
        [ 5.0974e-04,  3.0994e-04, -1.1044e-03,  ..., -7.5722e-04,
         -5.1785e-04, -7.4577e-04],
        [-6.3992e-04, -8.4543e-04, -9.0265e-04,  ..., -3.4428e-04,
         -2.1350e-04, -1.6937e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0714,  0.0089,  0.0051,  ..., -0.0123,  0.0073, -0.0072],
        [-0.0043, -0.0681,  0.0034,  ...,  0.0075, -0.0016,  0.0119],
        [-0.0109, -0.0086, -0.0704,  ..., -0.0019,  0.0064,  0.0078],
        ...,
        [-0.0014, -0.0037, -0.0072,  ..., -0.0606, -0.0123,  0.0045],
        [ 0.0032,  0.0046, -0.0035,  ...,  0.0012, -0.0764,  0.0032],
        [-0.0061, -0.0045,  0.0045,  ...,  0.0030, -0.0049, -0.0642]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1035,  0.0012,  0.0139,  ...,  0.0003, -0.0013, -0.0060],
        [ 0.0009, -0.1159,  0.0044,  ..., -0.0035, -0.0095, -0.0059],
        [ 0.0004,  0.0017, -0.1155,  ...,  0.0055,  0.0070, -0.0005],
        ...,
        [-0.0001, -0.0012,  0.0073,  ..., -0.0997,  0.0088,  0.0011],
        [-0.0001,  0.0019,  0.0029,  ..., -0.0038, -0.1075,  0.0047],
        [-0.0037, -0.0023, -0.0038,  ..., -0.0043,  0.0110, -0.1104]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:02:56 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 12:02:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2795, -1.0264, -0.3362,  ...,  0.4458,  0.0558,  0.1772],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2281,  0.6567, -0.3352,  ..., -1.0723, -0.3887, -0.4290],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1660, -2.1074, -0.1375,  ...,  0.5981, -0.7026, -0.3145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4565,  0.3477, -0.1863,  ..., -0.1997, -0.6650, -0.5522],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:02:56 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:02:56 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 12:03:32 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 12:04:03 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 12:04:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.4925e-03, -7.5865e-04,  2.0084e-03,  ..., -1.1921e-04,
          2.3782e-04,  5.3823e-05],
        [ 9.2745e-04, -1.5202e-03,  1.4000e-03,  ...,  1.5235e-04,
          8.7929e-04, -9.2125e-04],
        [-5.9652e-04, -3.8242e-04, -2.7428e-03,  ..., -6.1393e-05,
          7.0000e-04, -2.1935e-03],
        ...,
        [-2.9182e-04, -2.8324e-04,  3.9935e-04,  ..., -1.7862e-03,
         -6.8069e-05, -3.2759e-04],
        [ 6.4516e-04, -1.6918e-03, -3.8886e-04,  ..., -1.6413e-03,
         -4.1914e-04, -1.1454e-03],
        [ 1.1358e-03,  1.2255e-03,  1.4896e-03,  ..., -7.2002e-05,
         -1.3638e-03,  1.3046e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.4768e-02,  3.7594e-03,  5.8594e-03,  ...,  5.6610e-03,
          1.1452e-02,  1.0117e-02],
        [-3.8185e-03, -6.6711e-02, -8.1787e-03,  ..., -6.9542e-03,
         -5.2338e-03, -6.0997e-03],
        [ 6.7062e-03, -1.1082e-03, -7.8430e-02,  ...,  3.6602e-03,
          5.2719e-03,  3.9787e-03],
        ...,
        [-3.4637e-03,  1.0880e-02, -1.0262e-02,  ..., -5.2063e-02,
         -6.4125e-03,  5.2547e-04],
        [-5.3368e-03, -8.6594e-04,  1.4786e-02,  ..., -3.6316e-03,
         -7.1350e-02,  7.7171e-03],
        [ 4.7722e-03,  4.1733e-03,  1.0422e-02,  ..., -2.0981e-05,
         -3.6697e-03, -7.6111e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1161,  0.0107, -0.0057,  ...,  0.0013,  0.0060, -0.0017],
        [ 0.0012, -0.1122, -0.0091,  ..., -0.0007, -0.0035,  0.0068],
        [ 0.0050,  0.0019, -0.1011,  ..., -0.0013,  0.0090,  0.0006],
        ...,
        [-0.0020, -0.0047, -0.0013,  ..., -0.1044, -0.0050, -0.0049],
        [-0.0001,  0.0025, -0.0022,  ...,  0.0011, -0.1066,  0.0004],
        [-0.0044, -0.0020, -0.0010,  ..., -0.0090, -0.0024, -0.1049]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:04:32 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 12:04:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2527, -1.6943, -0.0479,  ...,  0.7974, -0.5171, -0.0402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1549,  0.3020, -0.0092,  ..., -0.7988, -0.3691, -0.5225],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2308, -2.0371, -0.5879,  ...,  0.7803, -0.5317,  0.1582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1870,  0.3850, -0.5557,  ..., -0.6279, -0.4841, -0.7793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:04:32 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:04:32 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 12:05:10 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 12:05:50 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 12:06:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.8845e-03,  9.9564e-04, -8.5545e-04,  ..., -7.3910e-06,
         -9.2888e-04,  6.7329e-04],
        [ 4.1127e-04, -1.3781e-03, -7.4577e-04,  ...,  5.2166e-04,
          1.5011e-03, -5.0879e-04],
        [ 7.6485e-04, -7.8630e-04, -2.3823e-03,  ..., -2.1038e-03,
          7.5865e-04, -4.4250e-04],
        ...,
        [-5.1117e-04,  3.0708e-04,  3.4022e-04,  ..., -2.1172e-03,
         -2.7514e-04,  3.5667e-04],
        [-1.0920e-03,  3.2353e-04, -1.3981e-03,  ...,  8.8263e-04,
         -1.7138e-03,  4.2152e-04],
        [ 7.5197e-04, -1.1940e-03, -9.8169e-05,  ..., -2.1782e-03,
          8.6164e-04, -2.5463e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0776,  0.0080,  0.0103,  ..., -0.0073, -0.0044,  0.0117],
        [-0.0012, -0.0704,  0.0186,  ...,  0.0023,  0.0184, -0.0086],
        [-0.0001,  0.0066, -0.0634,  ...,  0.0043,  0.0042,  0.0003],
        ...,
        [ 0.0051, -0.0007,  0.0096,  ..., -0.0753, -0.0015, -0.0048],
        [ 0.0012, -0.0104, -0.0136,  ...,  0.0046, -0.0734, -0.0059],
        [ 0.0172, -0.0122,  0.0029,  ..., -0.0161, -0.0087, -0.0639]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1089, -0.0011,  0.0018,  ..., -0.0149, -0.0182,  0.0001],
        [ 0.0070, -0.0916, -0.0145,  ...,  0.0052,  0.0053, -0.0011],
        [-0.0053, -0.0033, -0.0953,  ..., -0.0043,  0.0024,  0.0004],
        ...,
        [ 0.0018, -0.0028,  0.0056,  ..., -0.1055,  0.0104, -0.0065],
        [ 0.0014,  0.0015, -0.0016,  ...,  0.0146, -0.1055, -0.0067],
        [ 0.0007, -0.0052,  0.0033,  ...,  0.0022, -0.0010, -0.1042]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:06:31 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 12:06:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1381, -1.7500, -0.1145,  ...,  0.4429, -0.5518, -0.2769],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4446,  0.3452, -0.1827,  ..., -0.1830, -0.6387, -0.5723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1252, -1.8789, -0.7461,  ...,  0.8555, -0.4302, -0.0962],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3870, -0.1477, -0.7305,  ..., -0.7925, -0.3125,  0.0791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:06:31 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:06:32 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 12:07:12 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 12:07:55 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 12:08:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.2940e-03, -7.5817e-04, -1.3275e-03,  ...,  8.1873e-04,
         -2.2831e-03, -2.3975e-03],
        [-1.8120e-03, -2.5921e-03,  6.2656e-04,  ..., -1.6546e-03,
         -5.9748e-04, -4.6945e-04],
        [-1.6146e-03, -4.0126e-04, -2.0885e-03,  ...,  7.9203e-04,
          1.8144e-04, -1.0586e-03],
        ...,
        [ 2.5749e-05,  6.0844e-04, -4.8733e-04,  ..., -2.9278e-04,
          1.6346e-03,  1.3657e-03],
        [-1.0366e-03, -1.8072e-03, -7.0810e-05,  ..., -4.4870e-04,
         -2.3136e-03, -1.3781e-03],
        [ 1.2283e-03,  1.6642e-04,  7.2002e-05,  ..., -7.9918e-04,
          4.1246e-04, -1.9464e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0521,  0.0032, -0.0066,  ..., -0.0166, -0.0104,  0.0072],
        [-0.0028, -0.0862,  0.0034,  ...,  0.0025, -0.0004,  0.0058],
        [-0.0110,  0.0076, -0.0705,  ..., -0.0053, -0.0108, -0.0036],
        ...,
        [-0.0068, -0.0055, -0.0011,  ..., -0.0671,  0.0070, -0.0015],
        [ 0.0028,  0.0045,  0.0037,  ..., -0.0085, -0.0574,  0.0249],
        [-0.0004,  0.0068, -0.0050,  ...,  0.0003,  0.0096, -0.0652]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0443e-01,  9.1782e-03,  7.3099e-04,  ..., -2.7657e-03,
          6.6376e-03, -9.2125e-04],
        [ 7.8964e-03, -1.0669e-01,  7.8278e-03,  ..., -8.7662e-03,
         -1.0803e-02,  1.1978e-02],
        [-8.2397e-03,  1.0490e-04, -1.0535e-01,  ..., -4.6234e-03,
         -1.3008e-02,  1.1909e-02],
        ...,
        [ 3.5534e-03,  6.4659e-04, -1.1772e-02,  ..., -9.9792e-02,
         -5.4398e-03,  3.7193e-04],
        [-4.0321e-03, -1.4992e-03, -2.7847e-03,  ..., -1.6193e-03,
         -1.0901e-01,  9.9564e-03],
        [-5.9748e-04,  6.0768e-03, -1.5274e-02,  ...,  3.3054e-03,
          5.8823e-03, -1.0962e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:08:39 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 12:08:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1459, -1.4707, -0.4468,  ...,  0.4971, -0.3792,  0.0978],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1864,  0.3503, -0.5264,  ..., -0.5464, -0.4363, -0.7305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1545, -1.1172, -0.6411,  ...,  0.9756, -0.4138, -0.8472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4167, -0.0593, -0.5889,  ..., -0.6948, -0.5029, -0.0743],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:08:39 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:08:39 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 12:09:27 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 12:10:14 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 12:11:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2732e-03,  3.6850e-03,  6.1512e-04,  ..., -4.7569e-03,
         -6.2370e-04, -3.3817e-03],
        [ 4.0793e-04, -1.5850e-03, -2.9831e-03,  ..., -9.9564e-04,
         -6.5804e-04,  3.2883e-03],
        [ 6.3896e-04,  2.1687e-03,  2.0771e-03,  ..., -9.8896e-04,
          3.3045e-04, -1.9693e-04],
        ...,
        [-1.8196e-03, -2.2430e-03, -1.6060e-03,  ..., -1.4477e-03,
         -3.0785e-03, -3.5954e-03],
        [-4.7760e-03, -1.2121e-03,  2.4109e-03,  ...,  1.2708e-04,
         -3.8910e-03,  2.4948e-03],
        [-1.6422e-03, -1.0624e-03,  5.4665e-03,  ..., -3.2368e-03,
          1.5078e-03,  4.3869e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.7534e-02, -7.4921e-03,  2.6665e-03,  ..., -1.0353e-02,
          9.5215e-03, -3.5400e-03],
        [-6.4507e-03, -9.7290e-02,  1.1711e-03,  ...,  9.6512e-04,
         -3.5133e-03, -9.1553e-03],
        [-3.6182e-03,  1.8215e-04, -7.9163e-02,  ...,  5.7983e-03,
         -6.3553e-03, -5.0812e-03],
        ...,
        [-6.9122e-03,  2.2640e-03,  1.2405e-02,  ..., -8.4717e-02,
         -1.1658e-02,  6.6757e-05],
        [ 8.8272e-03, -1.9669e-02, -8.8930e-04,  ...,  1.1101e-02,
         -9.0454e-02,  6.2828e-03],
        [ 3.4714e-03,  1.1120e-03, -3.4904e-04,  ..., -1.9217e-04,
          8.5297e-03, -8.0444e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1677,  0.0029,  0.0007,  ...,  0.0036, -0.0061,  0.0174],
        [-0.0065, -0.1731, -0.0057,  ..., -0.0030, -0.0072, -0.0036],
        [-0.0159, -0.0064, -0.1643,  ..., -0.0041, -0.0043, -0.0073],
        ...,
        [-0.0076,  0.0054,  0.0074,  ..., -0.1544,  0.0011,  0.0050],
        [-0.0037,  0.0047, -0.0017,  ..., -0.0027, -0.1796, -0.0076],
        [-0.0063, -0.0066, -0.0066,  ..., -0.0128, -0.0126, -0.1486]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:11:02 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 12:11:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0863, -1.2363, -0.4954,  ...,  0.5312, -0.2849, -0.1050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3103, -0.1366, -0.6035,  ..., -0.5972, -0.2625,  0.0237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4592, -1.5830, -0.7920,  ...,  0.0557, -0.9121, -1.2256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4026, -0.2012, -0.5400,  ..., -0.2849, -0.5762,  0.2998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:11:02 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:11:02 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 12:11:53 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 12:12:42 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 12:13:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7157e-03,  4.6730e-05, -2.2926e-03,  ..., -1.0347e-03,
          1.1549e-03, -1.2951e-03],
        [ 1.3533e-03,  4.1509e-04,  4.0245e-03,  ...,  1.7252e-03,
          2.0390e-03,  1.3990e-03],
        [ 2.3327e-03,  1.0090e-03, -3.9902e-03,  ...,  1.9760e-03,
         -6.0043e-03,  5.0068e-04],
        ...,
        [-2.0313e-04, -3.4657e-03,  5.5542e-03,  ..., -2.2659e-03,
          2.0943e-03, -1.3409e-03],
        [ 3.2578e-03, -7.2517e-03,  2.0695e-03,  ...,  2.4719e-03,
          1.1024e-03,  1.2503e-03],
        [-7.5054e-04,  1.3304e-03, -5.6953e-03,  ...,  1.3704e-03,
         -1.0071e-03, -7.0763e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0980,  0.0055, -0.0080,  ..., -0.0218,  0.0073,  0.0065],
        [ 0.0172, -0.0992, -0.0091,  ...,  0.0039,  0.0056,  0.0067],
        [-0.0032, -0.0127, -0.0980,  ...,  0.0033,  0.0088,  0.0050],
        ...,
        [ 0.0082,  0.0056,  0.0031,  ..., -0.0887, -0.0035, -0.0038],
        [ 0.0189, -0.0101, -0.0058,  ...,  0.0078, -0.0980,  0.0176],
        [-0.0018,  0.0143, -0.0131,  ..., -0.0118,  0.0060, -0.1031]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1093,  0.0060,  0.0017,  ...,  0.0187, -0.0084, -0.0103],
        [ 0.0099, -0.1116,  0.0099,  ...,  0.0107, -0.0061,  0.0091],
        [ 0.0017, -0.0096, -0.1198,  ..., -0.0009,  0.0084,  0.0048],
        ...,
        [-0.0073,  0.0016,  0.0096,  ..., -0.1203,  0.0139, -0.0082],
        [ 0.0035, -0.0061, -0.0004,  ...,  0.0028, -0.1153,  0.0225],
        [-0.0081, -0.0043,  0.0007,  ..., -0.0022, -0.0065, -0.1077]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:13:34 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 12:13:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1046, -0.6895, -0.4019,  ...,  0.5127, -0.2576, -0.5044],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3103, -0.0614, -0.4404,  ..., -0.5010, -0.3682, -0.0505],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4475, -1.9473, -0.7319,  ...,  1.2998, -0.3940, -0.6436],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6260, -0.4663, -0.4751,  ..., -0.5308, -0.3354,  0.5225],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:13:34 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:13:34 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 12:14:23 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 12:15:03 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 12:15:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.0325e-02, -3.1776e-03,  4.2725e-04,  ..., -4.3464e-04,
          1.2034e-04,  4.3640e-03],
        [-4.2000e-03,  1.1642e-02,  1.2703e-03,  ..., -9.6226e-04,
         -2.1591e-03, -2.4080e-05],
        [-2.4338e-03, -6.1951e-03,  1.0475e-02,  ...,  9.7847e-04,
          2.4910e-03,  3.4409e-03],
        ...,
        [ 5.1498e-03,  4.3640e-03,  5.9013e-03,  ...,  2.0416e-02,
         -7.7820e-03,  3.7575e-03],
        [-2.4014e-03, -2.1839e-03,  1.0157e-03,  ..., -4.2000e-03,
          1.2833e-02, -3.2597e-03],
        [-3.3736e-04, -2.1858e-03,  7.8869e-04,  ..., -3.5458e-03,
         -1.3933e-03,  1.1711e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1453,  0.0037,  0.0118,  ...,  0.0102,  0.0085, -0.0185],
        [ 0.0057, -0.1526,  0.0053,  ...,  0.0011, -0.0027,  0.0030],
        [-0.0163, -0.0098, -0.1417,  ...,  0.0085, -0.0153,  0.0062],
        ...,
        [ 0.0027,  0.0075,  0.0107,  ..., -0.1433, -0.0102,  0.0017],
        [-0.0066, -0.0029, -0.0007,  ..., -0.0044, -0.1366, -0.0044],
        [-0.0114, -0.0100, -0.0012,  ..., -0.0009,  0.0149, -0.1425]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.4414e-01,  7.9498e-03,  6.5765e-03,  ..., -1.3474e-02,
         -8.7595e-04, -8.8120e-03],
        [ 5.5771e-03, -2.4451e-01, -3.0403e-03,  ..., -1.1665e-02,
          5.9471e-03,  7.1564e-03],
        [-2.2888e-05,  2.3956e-02, -2.3181e-01,  ...,  9.8038e-03,
         -1.9592e-02, -6.4316e-03],
        ...,
        [-1.5030e-02, -5.7831e-03, -4.9744e-03,  ..., -2.5171e-01,
          1.5762e-02,  1.3153e-02],
        [-7.9193e-03, -5.0430e-03, -1.1124e-02,  ..., -2.5368e-04,
         -2.3767e-01, -5.0507e-03],
        [-4.6310e-03, -1.5411e-02, -1.2024e-02,  ..., -3.3302e-03,
          4.1008e-03, -2.6050e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:16:01 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 12:16:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2300, -0.8989, -0.4663,  ...,  0.0275, -0.5088, -0.7534],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3354, -0.1685, -0.4390,  ..., -0.2159, -0.4412,  0.1805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2944, -1.8516, -0.6689,  ...,  1.4297, -1.1328, -0.7910],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2539, -0.3384, -0.4709,  ..., -0.3074,  0.5757,  0.0913],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:16:01 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:16:01 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 12:16:57 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 12:17:52 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 12:18:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0022,  0.0032,  0.0034,  ..., -0.0008,  0.0012, -0.0027],
        [ 0.0007, -0.0026,  0.0018,  ..., -0.0020,  0.0054, -0.0003],
        [ 0.0116,  0.0026, -0.0063,  ..., -0.0037, -0.0027, -0.0002],
        ...,
        [ 0.0044,  0.0011, -0.0028,  ...,  0.0017, -0.0060, -0.0007],
        [-0.0027, -0.0008, -0.0008,  ..., -0.0021, -0.0073,  0.0007],
        [-0.0037, -0.0018, -0.0040,  ...,  0.0003,  0.0017, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1069,  0.0038,  0.0117,  ..., -0.0017, -0.0149, -0.0114],
        [ 0.0034, -0.1036, -0.0112,  ...,  0.0078,  0.0009, -0.0011],
        [ 0.0048,  0.0085, -0.0963,  ..., -0.0077,  0.0142,  0.0067],
        ...,
        [ 0.0066, -0.0017,  0.0031,  ..., -0.0871, -0.0102, -0.0078],
        [ 0.0105, -0.0046, -0.0026,  ...,  0.0136, -0.1006,  0.0054],
        [ 0.0075,  0.0013,  0.0065,  ...,  0.0020, -0.0015, -0.0997]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0887, -0.0068, -0.0016,  ...,  0.0124, -0.0125,  0.0028],
        [ 0.0089, -0.1080,  0.0065,  ..., -0.0058,  0.0075,  0.0010],
        [-0.0020, -0.0129, -0.0953,  ..., -0.0016, -0.0002,  0.0079],
        ...,
        [ 0.0004,  0.0030,  0.0100,  ..., -0.0864, -0.0036, -0.0027],
        [-0.0009, -0.0006, -0.0049,  ...,  0.0081, -0.0913, -0.0047],
        [-0.0014,  0.0077,  0.0084,  ...,  0.0042, -0.0028, -0.0850]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:18:49 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 12:18:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2466, -1.0947, -0.3855,  ...,  0.6553, -0.2059, -0.3752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4734, -0.3809, -0.3423,  ..., -0.3933, -0.2402,  0.3667],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4768, -1.9150, -0.9727,  ...,  1.2969, -0.3389, -0.4741],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0303, -0.3135, -1.1162,  ..., -0.3984,  0.5659,  0.0724],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:18:49 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:18:49 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 12:19:47 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 12:20:47 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 12:21:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.6510e-02, -1.6241e-03, -4.6921e-04,  ...,  2.7981e-03,
          2.0771e-03, -1.8721e-03],
        [-5.5656e-03,  1.8539e-02, -1.6365e-03,  ...,  1.3628e-03,
         -6.7997e-04, -4.6349e-04],
        [-5.9395e-03,  1.5438e-04,  1.8539e-02,  ..., -1.0262e-03,
          1.1539e-03, -1.0576e-03],
        ...,
        [ 8.0872e-04, -6.5184e-04,  6.2752e-03,  ...,  1.8234e-02,
         -1.0231e-02,  5.9204e-03],
        [ 5.7161e-05, -1.8251e-04,  4.7798e-03,  ..., -1.5488e-03,
          1.7761e-02,  6.4201e-03],
        [ 1.3876e-03, -2.5921e-03, -2.1706e-03,  ..., -9.4833e-03,
         -5.8937e-03,  1.5701e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1013, -0.0260, -0.0094,  ..., -0.0030,  0.0009,  0.0108],
        [-0.0007, -0.1209, -0.0004,  ..., -0.0058, -0.0191, -0.0055],
        [ 0.0045, -0.0081, -0.1046,  ...,  0.0023,  0.0003, -0.0128],
        ...,
        [-0.0046, -0.0024, -0.0045,  ..., -0.1234,  0.0118,  0.0097],
        [-0.0080,  0.0104,  0.0090,  ...,  0.0100, -0.1190,  0.0011],
        [ 0.0090, -0.0141, -0.0147,  ..., -0.0138,  0.0120, -0.1107]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1606, -0.0122,  0.0009,  ..., -0.0184,  0.0158,  0.0029],
        [-0.0136, -0.1771,  0.0096,  ..., -0.0024,  0.0046,  0.0061],
        [ 0.0115, -0.0020, -0.1571,  ..., -0.0093,  0.0014, -0.0061],
        ...,
        [-0.0046, -0.0103, -0.0108,  ..., -0.1683,  0.0149, -0.0004],
        [-0.0017, -0.0011,  0.0054,  ...,  0.0006, -0.1628,  0.0014],
        [ 0.0074,  0.0051, -0.0008,  ..., -0.0026,  0.0093, -0.1591]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:21:46 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 12:21:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1228, -0.9399, -0.3403,  ...,  0.6836, -0.5396, -0.4587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-7.9150e-01, -2.2083e-01, -2.9321e-01,  ..., -1.9702e-01,
         3.7866e-01,  3.2330e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7612, -2.3262, -0.5752,  ...,  0.6895,  0.5835, -1.3652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8755, -0.8691, -1.4551,  ..., -1.0723,  0.5698, -0.0519],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:21:47 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:21:47 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 12:22:44 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 12:23:44 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 12:24:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0767e-03, -3.2406e-03, -6.9094e-04,  ...,  1.8520e-03,
         -7.2670e-03,  1.4257e-04],
        [-3.3283e-04,  2.5864e-03, -1.2474e-03,  ..., -3.8505e-04,
          1.8473e-03,  7.9918e-04],
        [-3.6716e-04,  2.7704e-04,  6.4039e-04,  ..., -1.2178e-03,
         -1.0977e-03,  2.5444e-03],
        ...,
        [ 4.7569e-03, -7.1526e-04, -1.9836e-03,  ...,  3.1796e-03,
         -1.9884e-04, -7.1907e-04],
        [ 2.1324e-03,  1.5688e-04, -2.6932e-03,  ...,  2.7027e-03,
          3.5286e-03, -3.7003e-04],
        [-1.0357e-03,  2.4738e-03,  2.8381e-03,  ..., -1.4353e-03,
         -6.4611e-05,  3.2215e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0918, -0.0015, -0.0104,  ...,  0.0009,  0.0109,  0.0042],
        [-0.0064, -0.1029,  0.0031,  ..., -0.0082,  0.0102,  0.0070],
        [-0.0155, -0.0001, -0.0927,  ..., -0.0085,  0.0052, -0.0063],
        ...,
        [ 0.0023,  0.0008, -0.0028,  ..., -0.0883,  0.0133,  0.0061],
        [ 0.0107,  0.0115, -0.0058,  ...,  0.0153, -0.0974,  0.0083],
        [ 0.0040,  0.0014, -0.0101,  ..., -0.0081, -0.0007, -0.1037]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1234, -0.0061,  0.0024,  ..., -0.0158,  0.0057,  0.0037],
        [ 0.0068, -0.1235, -0.0100,  ...,  0.0086,  0.0011,  0.0132],
        [-0.0002,  0.0019, -0.1154,  ..., -0.0029, -0.0056, -0.0042],
        ...,
        [ 0.0019, -0.0252,  0.0047,  ..., -0.1179,  0.0163,  0.0031],
        [-0.0021,  0.0092, -0.0042,  ...,  0.0071, -0.1086, -0.0014],
        [-0.0042,  0.0071, -0.0018,  ..., -0.0077,  0.0031, -0.1249]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:24:48 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 12:24:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2277, -0.9463, -0.4370,  ...,  0.5903, -0.1520, -0.2605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6235, -0.2163, -0.6191,  ..., -0.2390,  0.3335,  0.0095],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4614, -3.0391, -0.1921,  ..., -0.4463,  0.6426, -1.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.6250, -1.3945, -2.4453,  ..., -1.9258,  0.1770,  0.3896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:24:48 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:24:48 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 12:25:51 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 12:26:52 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 12:27:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1162e-02,  1.7338e-03,  4.4975e-03,  ..., -2.8467e-04,
         -2.0561e-03, -9.6917e-05],
        [ 6.7177e-03,  7.3357e-03,  4.5490e-04,  ...,  6.8951e-04,
          4.3907e-03, -6.0120e-03],
        [ 5.9128e-04, -6.2714e-03,  1.0384e-02,  ..., -2.0199e-03,
         -3.3722e-03,  1.2112e-04],
        ...,
        [-3.7060e-03, -4.3602e-03, -7.6199e-04,  ...,  7.0229e-03,
         -1.0223e-02,  1.1473e-03],
        [ 1.1307e-02,  5.2309e-04,  8.5297e-03,  ..., -6.1798e-03,
          1.0063e-02, -5.0583e-03],
        [ 4.5204e-03,  3.1166e-03,  7.2594e-03,  ..., -3.9902e-03,
          7.7581e-04,  1.2604e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0303e-01, -2.5063e-03, -5.0430e-03,  ..., -7.1487e-03,
          5.6314e-04,  1.2383e-02],
        [-1.8835e-04, -1.0577e-01, -3.3760e-03,  ...,  6.6757e-05,
          1.2505e-02,  3.9825e-03],
        [-3.7727e-03,  9.3994e-03, -1.0870e-01,  ...,  5.0430e-03,
          2.9373e-04,  3.7842e-03],
        ...,
        [ 7.6866e-03,  1.2856e-03, -7.5388e-04,  ..., -1.0211e-01,
         -9.3460e-04, -2.5139e-03],
        [-2.6665e-03, -1.0651e-02, -5.2490e-03,  ...,  8.6136e-03,
         -1.1237e-01,  1.1116e-02],
        [ 6.1836e-03,  8.7280e-03, -3.6983e-03,  ...,  3.2310e-03,
          1.5404e-02, -1.1548e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3513e-01,  9.8343e-03, -3.0327e-03,  ..., -8.2779e-04,
         -8.1158e-04, -1.5044e-04],
        [-2.6321e-03, -1.5259e-01, -5.0812e-03,  ..., -1.6937e-03,
          1.7281e-03, -8.8730e-03],
        [-4.6158e-03,  6.2103e-03, -1.5466e-01,  ...,  3.5172e-03,
          1.7700e-03,  7.8278e-03],
        ...,
        [ 2.4185e-03,  7.2479e-04,  4.9973e-03,  ..., -1.5381e-01,
         -1.0933e-02, -3.3722e-03],
        [ 2.6360e-03, -1.7120e-02, -1.6052e-02,  ...,  1.3344e-02,
         -1.4722e-01,  2.1271e-02],
        [ 2.2766e-02, -1.4534e-03, -5.1918e-03,  ...,  1.7075e-02,
          2.0767e-02, -1.4331e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:27:57 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 12:27:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3286, -1.1240, -0.2773,  ...,  0.3225,  0.2817, -0.6846],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5317, -0.4817, -0.7759,  ..., -0.5815,  0.3167, -0.0550],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5801, -2.0625, -0.0043,  ..., -0.8340,  0.1448, -1.2686],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.5410, -2.0469, -2.0859,  ..., -1.3984,  0.2124,  0.9331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:27:57 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:27:57 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 12:29:01 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 12:30:07 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 12:31:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0046, -0.0018,  0.0014,  ...,  0.0042,  0.0016, -0.0042],
        [-0.0042,  0.0087,  0.0036,  ...,  0.0037,  0.0054,  0.0018],
        [-0.0025, -0.0016,  0.0037,  ...,  0.0040,  0.0005, -0.0026],
        ...,
        [ 0.0062, -0.0009,  0.0003,  ...,  0.0044, -0.0094, -0.0061],
        [-0.0033,  0.0010, -0.0027,  ...,  0.0053,  0.0058, -0.0012],
        [ 0.0017,  0.0026,  0.0006,  ..., -0.0056,  0.0073,  0.0003]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0722,  0.0116, -0.0130,  ...,  0.0023,  0.0025, -0.0094],
        [ 0.0032, -0.0710, -0.0105,  ...,  0.0160, -0.0154, -0.0022],
        [-0.0091, -0.0017, -0.0522,  ..., -0.0070, -0.0085,  0.0028],
        ...,
        [-0.0034,  0.0085, -0.0131,  ..., -0.0746, -0.0016, -0.0013],
        [-0.0055,  0.0056, -0.0229,  ...,  0.0134, -0.0764, -0.0050],
        [ 0.0149, -0.0003,  0.0073,  ..., -0.0007,  0.0013, -0.0798]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0752,  0.0057, -0.0056,  ...,  0.0069,  0.0028, -0.0138],
        [ 0.0147, -0.0748, -0.0062,  ...,  0.0077, -0.0082,  0.0053],
        [ 0.0087, -0.0054, -0.0756,  ..., -0.0099, -0.0137,  0.0006],
        ...,
        [-0.0005,  0.0104, -0.0187,  ..., -0.0709,  0.0073,  0.0048],
        [ 0.0202,  0.0046, -0.0033,  ...,  0.0069, -0.0797, -0.0047],
        [-0.0108,  0.0066,  0.0101,  ..., -0.0013, -0.0077, -0.0789]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:31:18 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 12:31:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2245, -1.3896, -0.0814,  ..., -0.1993,  0.3018, -0.7319],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8184, -0.6909, -1.1406,  ..., -0.9126,  0.0996,  0.1530],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1929, -1.6348,  0.1649,  ..., -1.1367,  0.5459, -0.7437],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4082, -1.6240, -1.4854,  ..., -1.2959,  0.0266, -0.1011],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:31:18 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:31:18 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 12:32:23 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 12:33:26 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 12:34:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1024e-02, -1.8454e-03,  1.7996e-03,  ...,  2.9430e-03,
          3.5763e-07,  4.6272e-03],
        [-1.8454e-03, -1.0124e-02,  1.4782e-05,  ...,  7.0000e-04,
          7.8106e-04, -4.1504e-03],
        [-1.0557e-03,  2.0313e-03, -1.0811e-02,  ...,  2.1958e-04,
         -2.7561e-03, -3.0499e-03],
        ...,
        [ 8.4543e-04, -1.0109e-03,  1.7843e-03,  ..., -1.0384e-02,
          2.6970e-03, -2.9736e-03],
        [ 1.9207e-03,  7.5035e-03, -3.9387e-04,  ...,  7.2241e-04,
         -1.7670e-02, -6.5804e-03],
        [-2.5463e-04,  3.3236e-04, -1.2770e-03,  ..., -1.7185e-03,
         -3.2539e-03, -1.0948e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.1055e-02,  7.7438e-03,  1.6006e-02,  ...,  4.9744e-03,
         -6.3019e-03,  1.3046e-02],
        [ 1.1978e-02, -9.3201e-02,  7.3013e-03,  ...,  3.0251e-03,
          1.5350e-02, -5.1651e-03],
        [ 4.1199e-03, -4.7951e-03, -8.4229e-02,  ...,  4.5776e-05,
          2.4681e-03,  6.6872e-03],
        ...,
        [ 8.2321e-03, -1.1742e-02,  2.3479e-03,  ..., -7.2327e-02,
          5.7907e-03, -1.0696e-02],
        [ 9.5367e-03, -1.1414e-02,  1.5259e-02,  ...,  6.2103e-03,
         -9.8694e-02, -5.6076e-04],
        [ 1.3672e-02, -1.1826e-04, -1.0155e-02,  ..., -6.4545e-03,
         -7.8087e-03, -6.7322e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0813,  0.0046,  0.0018,  ..., -0.0014,  0.0037,  0.0080],
        [ 0.0005, -0.0861,  0.0033,  ..., -0.0004,  0.0010, -0.0208],
        [ 0.0074, -0.0027, -0.0988,  ...,  0.0053,  0.0027, -0.0086],
        ...,
        [-0.0005, -0.0188, -0.0019,  ..., -0.0921,  0.0063, -0.0075],
        [ 0.0002,  0.0064,  0.0185,  ...,  0.0013, -0.1028,  0.0016],
        [ 0.0109,  0.0043,  0.0008,  ..., -0.0089,  0.0051, -0.0930]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:34:35 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 12:34:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2773, -0.9019, -0.0138,  ..., -0.3669,  0.0701, -0.6182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7456, -0.9448, -0.9575,  ..., -0.6470,  0.1067,  0.4011],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0081, -2.5293,  0.0128,  ..., -1.5684,  0.2578, -0.4841],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.3262, -1.8369, -1.8516,  ..., -0.8677, -0.0698,  0.5571],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:34:35 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:34:35 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 12:35:41 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 12:36:50 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 12:37:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.1083e-04, -9.1696e-04, -1.1129e-03,  ..., -2.8591e-03,
          1.7147e-03, -1.0929e-03],
        [ 4.6301e-04,  6.3705e-04,  1.9646e-03,  ..., -1.1148e-03,
         -1.6689e-05,  6.1178e-04],
        [-3.4785e-04, -1.3399e-03,  2.0790e-03,  ..., -6.4325e-04,
          7.9727e-04, -2.0580e-03],
        ...,
        [ 4.4394e-04,  2.6112e-03,  3.7289e-04,  ...,  4.4670e-03,
         -4.0779e-03,  2.0361e-04],
        [ 1.6346e-03, -8.7166e-04,  2.0847e-03,  ..., -2.9588e-04,
         -6.5804e-04, -1.1292e-03],
        [-1.6670e-03, -3.4142e-04,  3.2878e-04,  ..., -4.4084e-04,
          3.6359e-04, -1.4076e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0732,  0.0112,  0.0019,  ..., -0.0013,  0.0007,  0.0023],
        [-0.0072, -0.0711, -0.0068,  ..., -0.0193,  0.0102,  0.0057],
        [ 0.0084, -0.0027, -0.0725,  ...,  0.0068,  0.0070, -0.0192],
        ...,
        [-0.0024, -0.0051,  0.0012,  ..., -0.0833, -0.0029,  0.0119],
        [-0.0070,  0.0026, -0.0114,  ...,  0.0088, -0.0594,  0.0073],
        [-0.0037, -0.0059, -0.0063,  ...,  0.0064,  0.0161, -0.0729]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1008,  0.0097, -0.0078,  ..., -0.0098, -0.0034,  0.0051],
        [ 0.0032, -0.1162, -0.0035,  ...,  0.0030,  0.0069, -0.0019],
        [ 0.0131,  0.0031, -0.1010,  ..., -0.0158,  0.0044, -0.0024],
        ...,
        [-0.0012, -0.0056, -0.0031,  ..., -0.0975, -0.0017, -0.0094],
        [-0.0150, -0.0044, -0.0197,  ..., -0.0111, -0.0999,  0.0012],
        [-0.0101,  0.0065, -0.0112,  ...,  0.0151, -0.0087, -0.1112]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:38:00 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 12:38:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0886, -0.7041,  0.0476,  ..., -0.4829,  0.2568, -0.3684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6797, -0.7661, -0.6934,  ..., -0.6025,  0.0360, -0.0923],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5703, -2.2246,  0.7441,  ..., -1.0615,  0.0515, -0.7598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.0859, -2.7949,  0.1016,  ..., -1.3535,  0.0920,  1.6582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:38:00 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:38:00 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 12:39:12 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 12:40:22 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 12:41:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0076, -0.0007,  0.0028,  ...,  0.0064, -0.0066, -0.0098],
        [ 0.0027,  0.0129, -0.0063,  ...,  0.0074,  0.0015,  0.0005],
        [-0.0003, -0.0004,  0.0138,  ..., -0.0123, -0.0012,  0.0030],
        ...,
        [ 0.0009, -0.0017, -0.0068,  ...,  0.0131,  0.0005, -0.0018],
        [ 0.0044, -0.0073, -0.0038,  ...,  0.0078,  0.0170,  0.0044],
        [-0.0037, -0.0003,  0.0041,  ..., -0.0027, -0.0063,  0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0461,  0.0083,  0.0071,  ...,  0.0188,  0.0074,  0.0145],
        [-0.0041, -0.0244,  0.0039,  ...,  0.0107,  0.0068, -0.0032],
        [-0.0161,  0.0076, -0.0367,  ...,  0.0128, -0.0090,  0.0019],
        ...,
        [ 0.0007, -0.0073, -0.0065,  ..., -0.0544,  0.0082, -0.0116],
        [-0.0054, -0.0017,  0.0007,  ...,  0.0051, -0.0557,  0.0042],
        [ 0.0008, -0.0030,  0.0044,  ..., -0.0154,  0.0109, -0.0400]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0498,  0.0036,  0.0075,  ..., -0.0064,  0.0006, -0.0115],
        [-0.0023, -0.0388, -0.0004,  ...,  0.0101, -0.0050,  0.0097],
        [-0.0005,  0.0143, -0.0487,  ..., -0.0010,  0.0024,  0.0129],
        ...,
        [-0.0048,  0.0121, -0.0098,  ..., -0.0496, -0.0014, -0.0152],
        [ 0.0041,  0.0049, -0.0072,  ...,  0.0083, -0.0408,  0.0211],
        [-0.0091, -0.0020,  0.0121,  ..., -0.0293,  0.0130, -0.0532]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:41:35 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 12:41:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0029, -1.0303, -0.0133,  ..., -0.6177,  0.0976, -0.2279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5732, -0.7944, -0.7700,  ..., -0.3606, -0.0337,  0.2072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7422, -2.3066,  0.9565,  ..., -1.2109, -1.0156, -0.9795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.2832, -3.0352, -0.0830,  ..., -2.0215,  0.0647,  1.6377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:41:36 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:41:36 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 12:42:49 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 12:44:03 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 12:45:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1826e-03, -1.6079e-03, -1.4334e-03,  ...,  6.8235e-04,
         -8.4162e-04,  6.9714e-04],
        [-1.2779e-03,  7.7915e-04, -1.3008e-03,  ..., -1.4772e-03,
         -6.8903e-04,  1.5545e-03],
        [-3.0851e-04, -1.6546e-04,  2.6369e-04,  ..., -5.4216e-04,
         -6.7759e-04,  5.2786e-04],
        ...,
        [-1.8263e-04, -5.8889e-04, -2.3699e-04,  ...,  9.6369e-04,
         -6.7651e-05,  8.1491e-04],
        [-5.9223e-04,  2.8181e-04, -7.1239e-04,  ..., -2.5415e-04,
          1.0719e-03,  1.1129e-03],
        [ 4.9400e-04,  9.1076e-04,  6.8378e-04,  ...,  6.7651e-05,
          9.9182e-04,  1.9741e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0443,  0.0019,  0.0075,  ...,  0.0070, -0.0022, -0.0087],
        [-0.0182, -0.0762, -0.0069,  ...,  0.0106, -0.0174,  0.0092],
        [ 0.0009,  0.0002, -0.0675,  ..., -0.0079,  0.0153, -0.0293],
        ...,
        [ 0.0122, -0.0035, -0.0013,  ..., -0.0296, -0.0130, -0.0189],
        [ 0.0074, -0.0004,  0.0013,  ...,  0.0031, -0.0622,  0.0071],
        [-0.0158,  0.0098, -0.0016,  ..., -0.0093,  0.0074, -0.0595]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0528,  0.0142, -0.0042,  ...,  0.0159,  0.0038,  0.0160],
        [-0.0145, -0.0789, -0.0010,  ...,  0.0114, -0.0026,  0.0293],
        [-0.0109, -0.0162, -0.0619,  ..., -0.0123,  0.0145, -0.0229],
        ...,
        [ 0.0058, -0.0009, -0.0085,  ..., -0.0412, -0.0012, -0.0107],
        [ 0.0078, -0.0163,  0.0042,  ...,  0.0119, -0.0565, -0.0099],
        [-0.0134, -0.0023, -0.0019,  ...,  0.0063, -0.0021, -0.0850]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:45:15 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 12:45:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2122, -0.8345,  0.2632,  ..., -0.4014,  0.0285, -0.3074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8540, -1.1494,  0.0305,  ..., -0.5591,  0.0451,  0.6514],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3965, -1.9580,  0.9048,  ..., -1.2627, -1.0791, -0.7368],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-3.5156, -3.0664,  0.2407,  ..., -0.2803, -1.1787,  0.6567],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:45:15 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:45:15 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 12:46:34 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 12:47:50 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 12:49:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.6196e-03, -2.0962e-03, -7.0906e-04,  ..., -7.3624e-04,
         -7.1383e-04,  8.4305e-04],
        [ 3.2604e-05,  4.3182e-03,  1.6689e-03,  ...,  5.3253e-03,
          1.2426e-03,  2.5234e-03],
        [ 4.1628e-04, -2.2182e-03,  6.9427e-03,  ...,  2.0180e-03,
          1.7767e-03,  1.9395e-04],
        ...,
        [-2.7676e-03,  2.2736e-03, -3.5248e-03,  ...,  6.2943e-03,
          5.8651e-04, -2.3007e-04],
        [-9.2030e-04, -5.1737e-04,  3.3131e-03,  ...,  1.2369e-03,
          5.2261e-03, -4.9233e-05],
        [-3.3245e-03,  1.0529e-03, -1.9226e-03,  ..., -1.7929e-03,
          6.0959e-03,  5.7793e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0263, -0.0166, -0.0174,  ...,  0.0015,  0.0027,  0.0130],
        [-0.0023, -0.0416, -0.0234,  ...,  0.0005,  0.0162,  0.0057],
        [ 0.0053, -0.0107, -0.0275,  ...,  0.0101,  0.0021,  0.0142],
        ...,
        [-0.0018, -0.0075, -0.0007,  ..., -0.0347,  0.0055, -0.0099],
        [-0.0006, -0.0077, -0.0014,  ...,  0.0217, -0.0556, -0.0007],
        [ 0.0002,  0.0056, -0.0031,  ...,  0.0003, -0.0020, -0.0473]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0535, -0.0097, -0.0046,  ..., -0.0075,  0.0059,  0.0102],
        [-0.0011, -0.0671, -0.0255,  ...,  0.0135,  0.0126,  0.0184],
        [-0.0032,  0.0007, -0.0734,  ..., -0.0087, -0.0083,  0.0117],
        ...,
        [ 0.0162, -0.0202, -0.0175,  ..., -0.0587, -0.0110,  0.0050],
        [ 0.0218, -0.0028, -0.0255,  ...,  0.0003, -0.0855, -0.0121],
        [-0.0020,  0.0026, -0.0115,  ..., -0.0030, -0.0090, -0.0718]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:49:06 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 12:49:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2729, -0.8120,  0.3259,  ..., -0.4202, -0.3555, -0.3926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.9219, -1.1758, -0.0448,  ..., -0.7783,  0.0356,  0.6318],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0332, -2.1582,  2.3320,  ..., -1.1738, -0.1357,  1.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-3.4805, -3.0469,  1.3262,  ..., -0.6602, -2.7969,  1.2754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:49:06 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:49:06 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 12:50:21 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 12:51:34 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 12:52:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.1764e-05, -4.7803e-05, -5.6922e-05,  ...,  3.0041e-05,
          5.3763e-05, -7.6473e-05],
        [ 8.3745e-05, -2.4176e-04,  2.0933e-04,  ...,  2.0051e-04,
         -2.0313e-04,  2.1160e-05],
        [ 3.5763e-06,  1.4925e-04, -2.1863e-04,  ...,  1.1528e-04,
          1.4305e-04, -1.3423e-04],
        ...,
        [-9.7990e-05,  1.5914e-04,  7.9274e-05,  ..., -3.2616e-04,
          2.9159e-04,  8.7261e-05],
        [-6.6221e-05,  5.6744e-05, -1.2338e-05,  ..., -2.2948e-05,
         -3.9625e-04,  2.2101e-04],
        [ 6.9737e-05,  1.5438e-04,  2.3675e-04,  ..., -1.1516e-04,
          4.8018e-04, -3.8075e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.9099e-02,  1.0460e-02, -2.0714e-03,  ...,  3.2806e-04,
         -1.7242e-02,  1.4472e-04],
        [ 9.2545e-03, -2.5238e-02, -7.1678e-03,  ..., -3.9978e-03,
          3.2291e-03, -4.4823e-05],
        [ 3.1300e-03, -3.5667e-04, -4.4586e-02,  ..., -1.1299e-02,
         -5.2872e-03,  2.1935e-03],
        ...,
        [-6.0387e-03, -2.3022e-03, -2.4719e-02,  ..., -3.2684e-02,
          3.6736e-03,  2.1988e-02],
        [-1.5812e-03, -5.8632e-03, -7.3910e-04,  ...,  7.2098e-04,
         -5.2765e-02, -3.4676e-03],
        [-1.2718e-02, -1.1108e-02,  3.4161e-03,  ..., -1.5427e-02,
         -4.6730e-03, -2.1805e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0462,  0.0285, -0.0076,  ...,  0.0082,  0.0005, -0.0034],
        [ 0.0177, -0.0290, -0.0161,  ..., -0.0043,  0.0096,  0.0032],
        [ 0.0047, -0.0121, -0.0598,  ..., -0.0031,  0.0007,  0.0002],
        ...,
        [ 0.0052, -0.0047, -0.0108,  ..., -0.0701, -0.0006,  0.0202],
        [ 0.0075, -0.0019, -0.0111,  ...,  0.0127, -0.0560, -0.0137],
        [ 0.0015, -0.0105, -0.0052,  ..., -0.0092, -0.0163, -0.0274]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:52:53 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 12:52:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5039, -0.6602,  0.2822,  ..., -0.4216, -0.3530, -0.2881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.3379, -1.1270,  0.0630,  ..., -0.0989, -0.4250,  0.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.9492, -2.2793,  2.4102,  ..., -2.7070, -0.0510,  0.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-3.2812, -2.8535,  1.9082,  ..., -0.5742, -2.7344,  0.5425],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:52:53 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:52:53 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 12:54:12 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 12:55:28 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 12:56:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.6750e-04,  8.0109e-04,  3.8147e-05,  ..., -2.8968e-04,
         -1.2531e-03,  5.1260e-04],
        [-4.1437e-04,  1.1997e-03,  1.6856e-04,  ...,  6.5613e-04,
          3.7050e-04, -4.8923e-04],
        [ 1.2703e-03,  1.6298e-03,  1.1616e-03,  ...,  2.4462e-04,
         -5.8270e-04,  3.5644e-04],
        ...,
        [ 6.5088e-04, -3.9339e-04, -9.8467e-05,  ...,  1.5373e-03,
          1.4973e-04, -4.2963e-04],
        [-6.3753e-04, -7.4768e-04, -8.7786e-04,  ...,  4.9829e-04,
          1.4143e-03, -2.8181e-04],
        [ 1.6422e-03,  1.7014e-03,  7.3671e-04,  ..., -1.2703e-03,
         -7.1239e-04,  1.3819e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0280, -0.0108,  0.0150,  ...,  0.0033,  0.0077,  0.0120],
        [ 0.0338, -0.0472,  0.0089,  ...,  0.0033,  0.0041,  0.0055],
        [ 0.0080,  0.0079, -0.0178,  ..., -0.0096,  0.0071,  0.0016],
        ...,
        [ 0.0143, -0.0083, -0.0014,  ..., -0.0186, -0.0114, -0.0025],
        [-0.0133, -0.0287,  0.0078,  ...,  0.0054, -0.0563,  0.0153],
        [-0.0022, -0.0186, -0.0014,  ...,  0.0022,  0.0109, -0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0465, -0.0128, -0.0063,  ..., -0.0091,  0.0129,  0.0014],
        [-0.0066, -0.0601, -0.0049,  ...,  0.0016, -0.0012,  0.0066],
        [ 0.0186,  0.0112, -0.0704,  ..., -0.0127, -0.0082,  0.0033],
        ...,
        [ 0.0008, -0.0047, -0.0069,  ..., -0.0517, -0.0018,  0.0038],
        [-0.0063, -0.0031,  0.0103,  ..., -0.0055, -0.0969, -0.0109],
        [ 0.0084, -0.0134, -0.0190,  ..., -0.0133, -0.0003, -0.0697]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 12:56:50 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 12:56:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7002, -0.6733,  0.7319,  ..., -0.3948, -0.0344,  0.3220],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.2627, -1.0293,  0.4236,  ..., -0.2417, -1.0029,  0.4365],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.5508, -1.9199,  2.7539,  ..., -1.9316,  0.5229,  1.2559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-3.3438, -2.2070,  2.6230,  ...,  0.4902, -0.5137,  0.8848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 12:56:50 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 12:56:50 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 12:58:13 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 12:59:34 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 13:00:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.3479e-03,  3.0899e-04,  3.5477e-04,  ...,  5.7697e-04,
         -1.9050e-04,  8.9169e-04],
        [-1.4222e-04,  1.7147e-03, -3.6621e-04,  ...,  1.8883e-04,
          7.3290e-04,  6.7902e-04],
        [-2.2316e-04, -2.1076e-04,  2.2736e-03,  ..., -1.9467e-04,
          9.5224e-04, -3.9005e-04],
        ...,
        [-5.0163e-04,  9.5367e-05,  7.8559e-05,  ...,  1.9102e-03,
          8.3399e-04, -1.3685e-03],
        [-1.2398e-05, -1.3285e-03, -3.0994e-04,  ...,  7.6914e-04,
          1.9388e-03, -8.0109e-04],
        [ 1.2839e-04, -4.4441e-04, -5.9128e-04,  ..., -5.2977e-04,
          1.8048e-04,  2.2774e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0131,  0.0006, -0.0028,  ..., -0.0021,  0.0173, -0.0010],
        [ 0.0025, -0.0479,  0.0244,  ...,  0.0023, -0.0017,  0.0188],
        [ 0.0029, -0.0137, -0.0368,  ...,  0.0179,  0.0037, -0.0052],
        ...,
        [-0.0231,  0.0125, -0.0144,  ...,  0.0071, -0.0040, -0.0076],
        [-0.0018, -0.0277,  0.0166,  ...,  0.0114, -0.0073, -0.0015],
        [ 0.0093, -0.0019, -0.0058,  ..., -0.0058, -0.0036, -0.0175]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0332, -0.0011,  0.0119,  ...,  0.0023, -0.0072,  0.0045],
        [-0.0071, -0.0252,  0.0355,  ...,  0.0240, -0.0186,  0.0121],
        [ 0.0020, -0.0142, -0.0333,  ...,  0.0219,  0.0094,  0.0042],
        ...,
        [-0.0199, -0.0068, -0.0183,  ..., -0.0279, -0.0155, -0.0052],
        [ 0.0071, -0.0254, -0.0015,  ..., -0.0072, -0.0391,  0.0208],
        [-0.0085,  0.0129, -0.0053,  ...,  0.0324, -0.0015, -0.0473]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:00:58 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 13:00:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0088, -0.7002,  0.7446,  ..., -0.9243, -0.0194,  0.1531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.1328, -0.9341,  0.6123,  ..., -0.2367, -0.9575,  0.1530],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.1270, -1.3525,  2.0195,  ..., -1.7568,  0.3711,  1.8223],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2754, -0.9150,  2.7578,  ..., -0.6455, -1.2188,  0.8403],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:00:58 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 13:00:58 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 13:02:20 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 13:03:35 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 13:04:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.4240e-03, -9.1124e-04,  5.1498e-04,  ..., -4.3511e-04,
          1.0958e-03, -3.4618e-04],
        [-9.3269e-04,  3.5019e-03,  1.2836e-03,  ..., -1.5235e-04,
         -1.1921e-06, -6.2227e-05],
        [-3.0470e-04,  5.8126e-04,  6.1111e-03,  ..., -1.6117e-04,
         -2.1970e-04, -6.9797e-05],
        ...,
        [-5.5695e-04, -7.9918e-04, -8.0681e-04,  ...,  6.6299e-03,
          5.3883e-04,  2.3508e-04],
        [-2.0981e-05,  9.9182e-04, -1.1692e-03,  ..., -2.3699e-04,
          6.2332e-03,  4.2009e-04],
        [ 4.0436e-04, -7.1001e-04,  6.1083e-04,  ..., -5.4240e-06,
          2.9683e-04,  6.7177e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0209,  0.0087, -0.0053,  ..., -0.0074, -0.0124,  0.0013],
        [-0.0107, -0.0449,  0.0095,  ...,  0.0207,  0.0131, -0.0133],
        [ 0.0102, -0.0145, -0.0107,  ...,  0.0023,  0.0003,  0.0042],
        ...,
        [-0.0118,  0.0116, -0.0175,  ..., -0.0164,  0.0257, -0.0070],
        [-0.0102, -0.0033, -0.0260,  ..., -0.0036, -0.0486,  0.0111],
        [-0.0054, -0.0010,  0.0005,  ...,  0.0165, -0.0103, -0.0422]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0305, -0.0180,  0.0032,  ...,  0.0147, -0.0152, -0.0102],
        [-0.0005, -0.0436,  0.0049,  ...,  0.0149,  0.0250, -0.0049],
        [ 0.0013,  0.0095,  0.0055,  ..., -0.0028, -0.0284,  0.0089],
        ...,
        [ 0.0080, -0.0067,  0.0031,  ..., -0.0260,  0.0182, -0.0111],
        [ 0.0050,  0.0110, -0.0435,  ..., -0.0071, -0.0407,  0.0125],
        [ 0.0029, -0.0014,  0.0020,  ...,  0.0219,  0.0109, -0.0459]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:04:57 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 13:04:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8301, -0.5283,  0.7280,  ..., -0.6685,  0.1289,  0.3252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0713, -0.6753,  0.7642,  ...,  0.0603, -0.1949,  0.2374],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.1914, -1.3027,  1.1191,  ..., -2.4648, -0.2007,  0.9189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4121, -1.1016,  1.8242,  ..., -0.3552, -0.9648, -0.0088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:04:57 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 13:04:57 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 13:06:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 13:07:46 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 13:09:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.9464e-03, -2.5349e-03, -1.6184e-03,  ...,  4.8971e-04,
         -6.7902e-04,  1.4639e-04],
        [ 3.2139e-04,  2.6836e-03,  1.0977e-03,  ..., -3.7599e-04,
          1.5612e-03,  4.7207e-04],
        [ 3.2234e-03, -4.4212e-03,  7.9489e-04,  ..., -1.1282e-03,
         -2.3460e-03,  1.5049e-03],
        ...,
        [-9.6416e-04,  2.1923e-04, -2.2495e-04,  ...,  1.9016e-03,
         -1.7941e-04, -2.1935e-04],
        [ 1.1415e-03, -3.0470e-04, -2.0528e-04,  ..., -1.1759e-03,
          4.6158e-03, -1.1053e-03],
        [-9.6798e-04,  8.8120e-04, -1.1282e-03,  ..., -1.5318e-05,
         -4.1819e-04,  4.9973e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0196,  0.0124, -0.0006,  ..., -0.0017,  0.0134,  0.0040],
        [ 0.0052, -0.0244,  0.0046,  ..., -0.0305,  0.0181, -0.0100],
        [-0.0156, -0.0098,  0.0010,  ..., -0.0213,  0.0101,  0.0138],
        ...,
        [ 0.0124,  0.0098,  0.0057,  ...,  0.0256, -0.0037,  0.0014],
        [ 0.0085,  0.0049, -0.0246,  ..., -0.0179,  0.0093,  0.0153],
        [-0.0049,  0.0370,  0.0058,  ..., -0.0065,  0.0076,  0.0155]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0193,  0.0127,  0.0168,  ..., -0.0118,  0.0133, -0.0110],
        [ 0.0302, -0.0428, -0.0090,  ..., -0.0345,  0.0231, -0.0049],
        [-0.0084,  0.0019, -0.0370,  ..., -0.0226, -0.0045,  0.0072],
        ...,
        [-0.0038, -0.0224, -0.0167,  ..., -0.0049, -0.0034,  0.0338],
        [ 0.0156, -0.0103, -0.0222,  ..., -0.0126, -0.0247,  0.0051],
        [-0.0035,  0.0172,  0.0246,  ...,  0.0041, -0.0054, -0.0267]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:09:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The falcon falls into the category of raptor
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The goat falls into the category of bovid
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The jackal falls into the category of
2024-06-30 13:09:16 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 13:09:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2067, -1.1836, -1.1826,  ...,  0.7100, -0.5977,  0.4089],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4753, -0.1415, -0.5713,  ..., -0.1464, -0.9028, -0.3726],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6436, -1.1328, -1.0225,  ...,  0.6758, -0.3347,  0.9062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5273,  0.0797, -0.2104,  ..., -0.5259, -0.3599, -0.4897],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:09:16 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:09:16 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 13:09:38 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 13:10:01 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 13:10:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.0211e-04,  2.2602e-04,  5.7364e-04,  ..., -1.0490e-05,
          2.3246e-04,  1.8358e-04],
        [ 4.5061e-04, -1.3006e-04, -5.0962e-05,  ...,  3.6359e-05,
          5.9128e-04, -6.5625e-05],
        [ 3.9172e-04, -2.4986e-04, -8.7118e-04,  ..., -2.0266e-04,
         -3.6907e-04, -1.5140e-05],
        ...,
        [ 1.5843e-04, -3.0041e-04,  9.1314e-05,  ...,  8.5592e-05,
          2.7490e-04, -9.5963e-06],
        [ 4.9210e-04,  2.2888e-05, -1.2720e-04,  ..., -1.3781e-04,
         -4.3440e-04,  5.3763e-05],
        [ 2.7835e-05, -3.6049e-04,  8.6212e-04,  ...,  6.1393e-05,
          1.5020e-04, -3.5405e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0380, -0.0006, -0.0038,  ...,  0.0011, -0.0045,  0.0006],
        [-0.0039, -0.0376, -0.0006,  ...,  0.0005,  0.0007, -0.0011],
        [-0.0019, -0.0061, -0.0370,  ...,  0.0027,  0.0027,  0.0042],
        ...,
        [ 0.0017, -0.0024, -0.0023,  ..., -0.0440,  0.0016,  0.0033],
        [-0.0003, -0.0008,  0.0050,  ...,  0.0036, -0.0325,  0.0015],
        [-0.0039,  0.0058,  0.0024,  ..., -0.0020, -0.0014, -0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0655e-02,  5.5885e-04,  6.7635e-03,  ..., -1.3475e-03,
         -1.7614e-03,  6.4945e-04],
        [ 7.4530e-04, -2.6184e-02, -6.1836e-03,  ..., -2.0294e-03,
          2.3746e-03,  1.9073e-04],
        [-2.7871e-04,  1.9913e-03, -2.4979e-02,  ..., -7.2479e-05,
         -2.0180e-03,  5.4855e-03],
        ...,
        [ 2.0905e-03,  3.2368e-03,  6.7997e-04,  ..., -2.2430e-02,
          2.7885e-03,  2.0142e-03],
        [-9.1219e-04,  2.4433e-03, -2.3961e-04,  ..., -2.6751e-04,
         -2.4811e-02,  3.0494e-04],
        [-9.5367e-04, -2.2621e-03, -3.0289e-03,  ...,  5.9652e-04,
          1.4055e-04, -2.7710e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:10:27 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 13:10:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4355, -1.2988, -1.5391,  ...,  0.3088, -0.4412,  0.5781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5679,  0.1542, -0.3386,  ..., -1.0625, -0.4241, -0.4312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7031, -1.3135, -1.3135,  ...,  0.6865, -0.5464,  0.7964],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1973, -0.2031,  0.2327,  ..., -1.0977, -0.5547, -0.5386],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:10:27 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:10:27 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 13:10:50 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 13:11:14 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 13:11:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.8752e-03, -9.6798e-04, -4.6611e-04,  ..., -5.8591e-05,
         -2.9421e-04, -7.0286e-04],
        [ 4.8041e-04, -5.9547e-03, -7.2145e-04,  ...,  1.3237e-03,
         -3.0994e-04,  2.0289e-04],
        [-3.4857e-04,  1.4219e-03, -4.8637e-03,  ..., -6.8855e-04,
         -2.7418e-04,  2.2173e-04],
        ...,
        [ 7.8678e-04,  4.0531e-04,  7.0989e-05,  ..., -4.6425e-03,
         -9.3746e-04, -2.2936e-04],
        [-7.3910e-04,  9.3937e-04,  8.1301e-04,  ..., -3.3975e-04,
         -5.4550e-03, -2.5225e-04],
        [-3.2282e-04, -2.8706e-04, -1.3387e-04,  ...,  5.5218e-04,
          1.5831e-04, -4.7493e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0477, -0.0091,  0.0020,  ...,  0.0004, -0.0089, -0.0054],
        [ 0.0055, -0.0457,  0.0019,  ...,  0.0099,  0.0024,  0.0033],
        [-0.0025, -0.0023, -0.0435,  ...,  0.0037, -0.0077, -0.0006],
        ...,
        [ 0.0038,  0.0032,  0.0025,  ..., -0.0435, -0.0061, -0.0003],
        [ 0.0041, -0.0111, -0.0031,  ..., -0.0046, -0.0439,  0.0024],
        [ 0.0028, -0.0078,  0.0098,  ..., -0.0018, -0.0065, -0.0491]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.9357e-02,  5.5313e-05, -3.1700e-03,  ...,  7.3051e-03,
          5.9013e-03,  1.4114e-03],
        [-2.1973e-03, -6.4514e-02, -2.8172e-03,  ..., -4.3726e-04,
         -2.2259e-03, -3.4199e-03],
        [ 4.4346e-04,  3.4580e-03, -6.0974e-02,  ...,  2.7847e-03,
          2.8324e-03,  8.7643e-04],
        ...,
        [ 2.5520e-03, -4.3335e-03,  1.0357e-03,  ..., -5.7373e-02,
         -6.3019e-03, -8.4534e-03],
        [-7.4692e-03, -5.8174e-03,  5.2261e-03,  ..., -5.4169e-03,
         -6.1951e-02,  4.8409e-03],
        [ 1.8349e-03, -1.2360e-02,  5.9052e-03,  ...,  2.8915e-03,
          1.3504e-03, -5.4443e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:11:41 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 13:11:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7793, -1.3809, -1.1934,  ...,  0.7549, -0.3879,  1.0713],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8481,  0.1089, -0.3284,  ..., -0.7827, -0.5522, -0.8149],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5859, -1.3457, -1.0068,  ...,  1.3066, -0.8623,  1.2168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2810,  0.3364,  0.0361,  ..., -0.9033, -0.6221, -0.8867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:11:41 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:11:41 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 13:12:03 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 13:12:28 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 13:12:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.9973e-03,  2.8658e-04, -1.7285e-04,  ...,  5.9175e-04,
          6.0368e-04,  2.4319e-04],
        [ 3.6359e-05, -2.3308e-03, -3.3975e-06,  ...,  3.0971e-04,
          4.3011e-04,  7.9393e-04],
        [ 8.9216e-04, -8.3923e-04, -3.1776e-03,  ...,  5.6648e-04,
          1.9538e-04, -6.8521e-04],
        ...,
        [ 1.7762e-04,  1.7052e-03,  5.1498e-05,  ..., -2.4185e-03,
          7.6723e-04, -2.0111e-04],
        [-1.8585e-04, -7.7200e-04, -1.1969e-03,  ...,  8.0585e-04,
         -2.7294e-03, -1.0586e-03],
        [-1.8108e-04,  7.3433e-04, -1.7071e-04,  ..., -8.1539e-05,
          4.3869e-05, -2.4643e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0325,  0.0036,  0.0050,  ...,  0.0102, -0.0006,  0.0002],
        [-0.0087, -0.0399,  0.0013,  ..., -0.0058, -0.0012, -0.0050],
        [ 0.0067,  0.0013, -0.0370,  ...,  0.0023,  0.0073,  0.0009],
        ...,
        [ 0.0028, -0.0026, -0.0046,  ..., -0.0288, -0.0022, -0.0023],
        [ 0.0051, -0.0013, -0.0037,  ...,  0.0033, -0.0379,  0.0023],
        [-0.0014,  0.0041,  0.0065,  ...,  0.0025,  0.0060, -0.0384]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0297,  0.0002, -0.0026,  ...,  0.0008,  0.0026,  0.0040],
        [-0.0044, -0.0327, -0.0014,  ...,  0.0067,  0.0046,  0.0005],
        [ 0.0004, -0.0004, -0.0357,  ..., -0.0014, -0.0038, -0.0044],
        ...,
        [-0.0004,  0.0005, -0.0019,  ..., -0.0293, -0.0049,  0.0036],
        [-0.0010,  0.0036, -0.0018,  ..., -0.0067, -0.0299,  0.0095],
        [ 0.0032,  0.0050,  0.0039,  ..., -0.0056,  0.0003, -0.0300]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:12:56 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 13:12:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8667, -1.6055, -1.5156,  ...,  0.7793, -0.6504,  0.9307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3110, -0.3215,  0.3369,  ..., -1.5215, -0.8042, -0.8403],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3235, -1.2227, -1.2598,  ...,  1.1699, -0.2256,  1.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4414e-04,  5.6348e-01, -3.6035e-01,  ..., -1.0137e+00,
        -2.6367e-02, -5.0586e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:12:56 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:12:56 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 13:13:26 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 13:13:55 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 13:14:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.5864e-03, -2.4748e-04, -1.1832e-04,  ...,  1.3103e-03,
         -7.1573e-04, -2.4676e-04],
        [ 3.1877e-04, -2.8324e-03, -1.2684e-03,  ..., -3.1042e-04,
         -1.4572e-03, -3.9625e-04],
        [ 7.5912e-04,  1.4055e-04, -2.4014e-03,  ...,  6.5899e-04,
          1.0138e-03, -8.4448e-04],
        ...,
        [ 1.0943e-04, -8.1730e-04, -6.0177e-04,  ..., -2.9697e-03,
         -7.1192e-04,  2.3842e-04],
        [ 1.3089e-04,  6.8283e-04, -7.1526e-06,  ..., -9.4032e-04,
         -1.2703e-03, -4.7231e-04],
        [-2.8372e-05, -1.3399e-04, -2.5177e-04,  ...,  6.3229e-04,
         -7.3242e-04, -3.2082e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.8889e-02,  4.1237e-03,  3.5591e-03,  ..., -2.9716e-03,
          8.8120e-03, -6.5136e-04],
        [-4.1008e-03, -4.9072e-02, -8.6823e-03,  ..., -2.9564e-05,
          2.4586e-03, -8.2588e-04],
        [ 3.1700e-03, -1.1528e-02, -4.2450e-02,  ..., -1.4133e-03,
         -2.9526e-03, -3.6182e-03],
        ...,
        [ 5.7182e-03,  1.3065e-03, -9.0790e-03,  ..., -4.2664e-02,
         -6.5918e-03,  5.3596e-03],
        [ 0.0000e+00,  3.1414e-03, -8.6117e-04,  ..., -3.9558e-03,
         -4.1382e-02, -8.8043e-03],
        [ 7.7324e-03, -2.3098e-03, -5.9853e-03,  ...,  3.6335e-03,
         -1.3046e-03, -4.0405e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0559,  0.0024,  0.0009,  ..., -0.0035,  0.0088, -0.0076],
        [ 0.0029, -0.0458,  0.0004,  ...,  0.0032, -0.0019,  0.0022],
        [-0.0006, -0.0049, -0.0412,  ...,  0.0062, -0.0019,  0.0004],
        ...,
        [-0.0071, -0.0072, -0.0007,  ..., -0.0609, -0.0010, -0.0133],
        [ 0.0001,  0.0043, -0.0122,  ..., -0.0041, -0.0380, -0.0074],
        [-0.0013, -0.0015,  0.0006,  ..., -0.0036, -0.0005, -0.0510]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:14:28 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 13:14:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5645, -1.3740, -0.9131,  ...,  1.1533, -0.7905,  1.1514],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2979,  0.3184,  0.0436,  ..., -0.8838, -0.6113, -0.9849],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5161, -1.6299, -0.8076,  ...,  1.0605, -0.5342,  1.5020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1567,  0.0959, -0.1847,  ..., -0.9370, -0.1707, -0.6187],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:14:28 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:14:28 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 13:15:00 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 13:15:33 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 13:16:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0022,  0.0011, -0.0030,  ...,  0.0013, -0.0006, -0.0002],
        [ 0.0012,  0.0016, -0.0025,  ..., -0.0003, -0.0005,  0.0008],
        [ 0.0022,  0.0007, -0.0020,  ..., -0.0012, -0.0012,  0.0007],
        ...,
        [ 0.0002,  0.0011,  0.0005,  ..., -0.0015, -0.0028,  0.0017],
        [ 0.0002,  0.0006, -0.0013,  ..., -0.0024, -0.0009, -0.0004],
        [-0.0003, -0.0013, -0.0015,  ..., -0.0003, -0.0009, -0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.1848e-02,  1.0239e-02,  3.1681e-03,  ..., -4.8065e-03,
         -9.5825e-03, -2.6779e-03],
        [ 9.6588e-03, -7.7393e-02,  2.2583e-03,  ..., -4.7922e-05,
         -5.0774e-03,  3.1471e-04],
        [-5.6076e-03, -7.0686e-03, -7.2754e-02,  ..., -8.0109e-05,
         -2.8839e-03,  4.7493e-04],
        ...,
        [ 1.2836e-03, -1.1950e-03, -7.7744e-03,  ..., -6.0059e-02,
         -7.4158e-03, -3.4428e-03],
        [ 1.3142e-03, -9.6588e-03, -6.4240e-03,  ...,  6.1569e-03,
         -8.0750e-02,  7.5684e-03],
        [-6.1455e-03, -8.1062e-04,  1.6203e-03,  ...,  7.4244e-04,
          5.0545e-03, -7.9041e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0394e-01, -6.1989e-06,  1.2909e-02,  ..., -5.2357e-04,
         -7.9393e-05, -6.6948e-03],
        [ 2.6245e-03, -1.1462e-01,  4.2000e-03,  ..., -4.9477e-03,
         -1.0414e-02, -6.4621e-03],
        [ 9.9373e-04,  3.8605e-03, -1.1273e-01,  ...,  5.3406e-03,
          6.4621e-03,  1.0729e-03],
        ...,
        [ 2.5444e-03,  3.4981e-03,  5.2948e-03,  ..., -9.7412e-02,
          9.7504e-03,  8.3923e-04],
        [-1.8864e-03, -1.2140e-03,  3.4180e-03,  ..., -4.2267e-03,
         -1.1047e-01,  4.9667e-03],
        [-4.2439e-04, -4.2915e-03, -6.4516e-04,  ..., -3.8624e-03,
          6.7482e-03, -1.0577e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:16:08 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 13:16:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2900, -1.1250, -1.0742,  ...,  0.9966, -0.2148,  1.2979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 8.0156e-04,  6.1328e-01, -3.7988e-01,  ..., -1.0449e+00,
        -4.2450e-02, -5.7861e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4429, -1.6172, -0.8271,  ...,  1.0381, -0.9995,  1.4424],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4438,  0.0239, -0.2490,  ..., -0.2954, -0.2944, -0.6895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:16:08 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:16:08 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 13:16:44 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 13:17:21 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 13:17:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.5286e-03, -1.4553e-03,  3.4046e-03,  ..., -1.0431e-04,
          9.1076e-04, -4.7159e-04],
        [-1.2958e-04, -4.6959e-03,  1.8501e-03,  ..., -1.2159e-04,
          2.2793e-03, -4.3631e-04],
        [-2.4509e-04,  2.7122e-03, -6.0501e-03,  ..., -7.7724e-04,
         -1.7703e-04, -2.2182e-03],
        ...,
        [ 2.5034e-04,  1.9956e-04, -9.6381e-05,  ..., -2.9240e-03,
          1.3504e-03, -4.1938e-04],
        [ 2.5330e-03, -2.4681e-03, -1.6737e-04,  ..., -1.8349e-03,
         -2.0466e-03, -2.0809e-03],
        [-1.4782e-05, -2.7299e-04,  1.9217e-03,  ...,  3.8171e-04,
         -1.3456e-03,  9.6607e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0848, -0.0001, -0.0032,  ...,  0.0023, -0.0006,  0.0065],
        [ 0.0061, -0.0863,  0.0053,  ..., -0.0098, -0.0011,  0.0002],
        [ 0.0058,  0.0004, -0.0925,  ..., -0.0016,  0.0076, -0.0059],
        ...,
        [ 0.0047,  0.0023, -0.0029,  ..., -0.0819, -0.0075, -0.0018],
        [-0.0052,  0.0028,  0.0119,  ..., -0.0048, -0.0967, -0.0041],
        [ 0.0032,  0.0048, -0.0010,  ..., -0.0019, -0.0051, -0.0964]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1124,  0.0109, -0.0069,  ..., -0.0013,  0.0050, -0.0007],
        [ 0.0021, -0.1129, -0.0093,  ...,  0.0003, -0.0047,  0.0068],
        [ 0.0033,  0.0011, -0.1035,  ..., -0.0030,  0.0087, -0.0014],
        ...,
        [-0.0026, -0.0070,  0.0002,  ..., -0.1066, -0.0065, -0.0055],
        [ 0.0029,  0.0049, -0.0037,  ...,  0.0042, -0.1030, -0.0016],
        [-0.0051,  0.0007, -0.0024,  ..., -0.0088,  0.0010, -0.1065]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:18:00 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 13:18:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4419, -1.4082, -0.6626,  ...,  0.8145, -0.4526,  1.2646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1501,  0.1089, -0.1831,  ..., -0.8706, -0.1649, -0.6436],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4341, -1.3535, -1.2256,  ...,  1.2773, -1.1992,  1.4512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2549,  0.2585, -0.3613,  ..., -0.6890, -0.1279, -1.0449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:18:00 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:18:00 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 13:18:39 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 13:19:18 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 13:19:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3027e-03, -9.1600e-04, -5.1355e-04,  ..., -1.3094e-03,
         -6.0940e-04,  6.1631e-05],
        [ 1.0014e-03, -1.1339e-03,  9.0599e-05,  ...,  1.7471e-03,
         -3.7766e-04, -2.8276e-04],
        [-1.1349e-03, -1.1282e-03, -3.9043e-03,  ..., -1.6727e-03,
         -9.3365e-04, -7.9012e-04],
        ...,
        [ 1.8415e-03, -7.8344e-04,  6.3896e-04,  ..., -5.6028e-04,
          7.1573e-04,  3.1738e-03],
        [-2.0409e-03,  3.0327e-04, -2.4529e-03,  ...,  1.0424e-03,
         -2.4529e-03,  3.5429e-04],
        [ 1.4305e-03, -2.4624e-03,  1.2016e-03,  ..., -1.7033e-03,
          1.1683e-03, -2.1191e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0859,  0.0007, -0.0056,  ..., -0.0086,  0.0016,  0.0139],
        [ 0.0059, -0.0842, -0.0054,  ...,  0.0165,  0.0137, -0.0068],
        [-0.0010,  0.0014, -0.0577,  ..., -0.0045, -0.0032,  0.0132],
        ...,
        [-0.0074, -0.0008,  0.0074,  ..., -0.0695, -0.0030, -0.0073],
        [-0.0010,  0.0062,  0.0035,  ...,  0.0036, -0.0797, -0.0060],
        [ 0.0158, -0.0079,  0.0068,  ..., -0.0048,  0.0086, -0.0781]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1088, -0.0038,  0.0004,  ..., -0.0118, -0.0166,  0.0001],
        [ 0.0058, -0.0959, -0.0143,  ...,  0.0102,  0.0023, -0.0036],
        [-0.0076, -0.0077, -0.0978,  ..., -0.0074,  0.0005,  0.0009],
        ...,
        [-0.0015, -0.0052,  0.0052,  ..., -0.1091,  0.0107, -0.0082],
        [ 0.0002,  0.0029,  0.0012,  ...,  0.0141, -0.1111, -0.0056],
        [ 0.0017, -0.0070,  0.0060,  ..., -0.0003, -0.0003, -0.1026]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:19:59 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 13:19:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3765, -1.4287, -0.6787,  ...,  0.8135, -0.8325,  1.2246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4297,  0.0170, -0.2396,  ..., -0.2686, -0.2839, -0.7056],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6152, -1.7998, -1.5859,  ...,  1.1787, -1.4453,  1.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4448, -0.3245, -0.6050,  ..., -1.0498, -0.0523, -0.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:19:59 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:19:59 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 13:20:36 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 13:21:15 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 13:21:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0048,  0.0008, -0.0017,  ...,  0.0024, -0.0020, -0.0027],
        [-0.0004, -0.0042,  0.0003,  ..., -0.0064, -0.0007, -0.0025],
        [ 0.0002,  0.0022, -0.0029,  ...,  0.0001,  0.0006, -0.0011],
        ...,
        [-0.0003,  0.0005, -0.0023,  ...,  0.0004,  0.0014,  0.0006],
        [ 0.0010, -0.0008, -0.0004,  ..., -0.0008, -0.0051, -0.0012],
        [ 0.0023,  0.0011,  0.0008,  ..., -0.0019, -0.0002, -0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0720,  0.0088, -0.0078,  ..., -0.0041, -0.0099,  0.0111],
        [ 0.0048, -0.0910, -0.0072,  ..., -0.0004,  0.0014,  0.0019],
        [ 0.0004,  0.0121, -0.0668,  ..., -0.0024, -0.0090, -0.0056],
        ...,
        [-0.0029,  0.0015, -0.0087,  ..., -0.0708,  0.0075,  0.0129],
        [-0.0064,  0.0019, -0.0106,  ..., -0.0063, -0.0723,  0.0120],
        [-0.0009,  0.0005, -0.0015,  ..., -0.0021,  0.0006, -0.0765]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1061,  0.0111, -0.0028,  ..., -0.0036,  0.0018,  0.0022],
        [ 0.0068, -0.1070,  0.0081,  ..., -0.0081, -0.0084,  0.0100],
        [-0.0036,  0.0039, -0.1114,  ..., -0.0044, -0.0133,  0.0105],
        ...,
        [ 0.0037,  0.0011, -0.0043,  ..., -0.0995, -0.0040, -0.0040],
        [-0.0039,  0.0023, -0.0007,  ...,  0.0008, -0.1071,  0.0108],
        [ 0.0028,  0.0036, -0.0173,  ...,  0.0074,  0.0089, -0.1095]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:21:59 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 13:21:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3545, -1.0615, -0.9482,  ...,  0.8911, -0.9072,  1.1123],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2430,  0.2305, -0.3538,  ..., -0.5869, -0.1238, -0.9565],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4666, -1.2129, -1.6855,  ...,  0.8447, -0.9941,  0.7646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0864,  0.1262, -0.5029,  ..., -1.3945, -0.1814, -0.0936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:21:59 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:21:59 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 13:22:46 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 13:23:32 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 13:24:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.4815e-03,  1.5521e-04,  3.7785e-03,  ..., -4.2496e-03,
         -5.7220e-06, -4.0131e-03],
        [ 1.8034e-03, -2.2354e-03,  8.5926e-04,  ..., -2.1782e-03,
         -3.0022e-03,  4.9858e-03],
        [-2.7714e-03,  8.2779e-04,  3.7003e-03,  ...,  1.2741e-03,
          2.7580e-03, -1.2455e-03],
        ...,
        [-3.1223e-03,  1.1492e-03, -2.1820e-03,  ..., -8.5831e-05,
         -3.3855e-03, -1.3847e-03],
        [-4.8103e-03, -8.0872e-04,  4.6539e-03,  ..., -3.0279e-05,
         -1.4296e-03,  2.7809e-03],
        [-1.9932e-04, -5.2834e-03,  1.2369e-03,  ..., -2.0561e-03,
         -1.1549e-03,  1.0281e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.8918e-02, -4.1351e-03,  4.1771e-03,  ..., -3.5524e-04,
          6.9695e-03, -2.2964e-02],
        [-5.5313e-03, -9.2773e-02,  2.2755e-03,  ..., -7.4043e-03,
         -1.2207e-02,  6.0616e-03],
        [-1.8784e-02, -4.5624e-03, -7.8308e-02,  ...,  1.0468e-02,
          2.4910e-03, -1.0719e-02],
        ...,
        [-3.8548e-03, -1.0948e-03,  2.2522e-02,  ..., -6.7688e-02,
          7.0572e-05, -2.6970e-03],
        [ 1.1398e-02, -7.7591e-03, -5.3253e-03,  ...,  1.5984e-03,
         -9.3750e-02, -2.4185e-03],
        [ 4.3945e-03, -1.8044e-03, -3.6240e-03,  ..., -1.3065e-03,
          4.7722e-03, -7.3181e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6284e-01, -6.4316e-03,  3.0403e-03,  ...,  1.4019e-04,
         -7.2327e-03,  9.0637e-03],
        [-1.6603e-03, -1.7310e-01, -6.2904e-03,  ...,  3.2806e-04,
         -6.4373e-04, -3.0479e-03],
        [-1.0040e-02, -7.1869e-03, -1.5710e-01,  ...,  1.2016e-03,
          1.6947e-03, -9.8953e-03],
        ...,
        [-1.0185e-02,  4.9706e-03,  5.9357e-03,  ..., -1.5491e-01,
          6.1798e-04,  6.7062e-03],
        [-6.8436e-03,  4.7722e-03, -6.2027e-03,  ..., -5.8327e-03,
         -1.6882e-01, -8.8348e-03],
        [-7.6752e-03, -4.4441e-03, -3.0842e-03,  ..., -1.2169e-02,
         -1.4267e-02, -1.4954e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:24:22 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 13:24:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4116, -1.2363, -1.0547,  ...,  0.7549, -0.9639,  1.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3521, -0.2776, -0.4993,  ..., -0.7832, -0.0550, -0.2201],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1145, -1.5195, -1.4609,  ...,  0.9580, -0.9038,  0.4988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1180, -0.1550, -0.7324,  ..., -0.8330, -0.4514, -0.0675],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:24:22 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:24:22 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 13:25:11 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 13:25:59 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 13:26:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8629e-03,  6.6471e-04, -3.2482e-03,  ...,  3.1681e-03,
          2.3899e-03,  1.6499e-03],
        [-2.9993e-04, -1.2970e-03,  1.3103e-03,  ...,  3.9635e-03,
          3.7432e-04,  4.8828e-03],
        [ 4.0550e-03, -2.1458e-04, -4.6501e-03,  ...,  2.3346e-03,
         -2.7142e-03, -8.9884e-05],
        ...,
        [ 5.7983e-04, -6.3934e-03,  5.0507e-03,  ..., -4.1809e-03,
          2.3003e-03, -2.1763e-03],
        [ 2.7809e-03, -5.0659e-03, -2.0456e-04,  ...,  3.2291e-03,
         -1.5879e-03,  3.8109e-03],
        [-3.0117e-03, -1.0014e-04, -8.0643e-03,  ...,  2.4433e-03,
         -1.7223e-03, -5.4131e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0162e-01,  7.1754e-03,  1.5087e-03,  ...,  6.5613e-04,
          1.2970e-03,  5.4398e-03],
        [ 1.2772e-02, -1.0852e-01, -3.3073e-03,  ..., -1.9646e-04,
         -5.5046e-03, -3.7556e-03],
        [ 1.0319e-03,  6.4087e-03, -9.8450e-02,  ...,  2.2079e-02,
          4.6463e-03, -9.8419e-04],
        ...,
        [ 1.1024e-02,  5.0354e-03,  8.2550e-03,  ..., -1.0077e-01,
          1.2009e-02, -2.7771e-03],
        [ 1.6266e-02,  7.6294e-06, -3.8719e-04,  ...,  5.9280e-03,
         -1.0236e-01,  3.0960e-02],
        [ 4.6921e-03,  7.0610e-03, -1.4572e-03,  ..., -3.7537e-03,
          2.6283e-03, -1.0986e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1100,  0.0060,  0.0069,  ...,  0.0124, -0.0054, -0.0065],
        [ 0.0079, -0.1115,  0.0091,  ...,  0.0095, -0.0084,  0.0114],
        [ 0.0023, -0.0081, -0.1174,  ..., -0.0024,  0.0071, -0.0023],
        ...,
        [-0.0035,  0.0040,  0.0043,  ..., -0.1140,  0.0153, -0.0061],
        [-0.0006, -0.0054,  0.0090,  ...,  0.0081, -0.1158,  0.0247],
        [-0.0049, -0.0039, -0.0046,  ..., -0.0062, -0.0090, -0.0982]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:26:52 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 13:26:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3042, -0.7817, -1.0273,  ...,  0.4578, -0.6187,  0.4778],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0737,  0.0720, -0.3784,  ..., -0.9614, -0.1438, -0.0635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1886, -2.1934, -2.2266,  ...,  1.9990, -0.3306,  1.3496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3018, -0.3264, -0.5820,  ..., -0.9629,  0.0686, -0.2522],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:26:52 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:26:52 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 13:27:43 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 13:28:35 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 13:29:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8845e-02, -1.6212e-03,  6.2084e-04,  ..., -1.5907e-03,
         -9.3222e-04,  5.3101e-03],
        [-2.2812e-03,  1.4435e-02, -2.0742e-04,  ...,  2.0580e-03,
         -1.3475e-03,  3.5801e-03],
        [-8.2016e-03, -4.6043e-03,  9.4070e-03,  ..., -4.9629e-03,
          4.6844e-03, -8.2970e-05],
        ...,
        [-1.2169e-03,  3.2387e-03,  3.9825e-03,  ...,  1.7578e-02,
         -7.9651e-03,  1.8272e-03],
        [-3.5992e-03, -5.0850e-03,  2.2793e-03,  ..., -3.4943e-03,
          1.3542e-02, -2.8191e-03],
        [ 6.4325e-04, -2.0218e-03, -4.4751e-04,  ...,  8.6594e-04,
         -6.3753e-04,  9.9335e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.4294e-01,  1.4515e-03,  4.7112e-03,  ...,  1.3542e-02,
          3.2558e-03, -2.0538e-02],
        [ 5.3215e-03, -1.3977e-01,  1.3323e-03,  ...,  4.2000e-03,
         -4.4975e-03,  1.2970e-04],
        [-1.5717e-02, -1.6899e-03, -1.4563e-01,  ..., -4.6349e-03,
         -8.7280e-03,  8.1787e-03],
        ...,
        [-2.1915e-03, -7.6523e-03,  1.1681e-02,  ..., -1.5015e-01,
         -7.1869e-03, -4.7035e-03],
        [-2.0027e-03, -8.3694e-03,  5.1575e-03,  ...,  7.0992e-03,
         -1.3794e-01, -1.2619e-02],
        [-1.4124e-03, -5.4588e-03, -5.9700e-04,  ..., -1.4664e-02,
          1.9531e-02, -1.4832e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.5098e-01,  1.1742e-02,  7.6065e-03,  ..., -9.7351e-03,
         -2.8057e-03, -1.4511e-02],
        [ 1.4442e-02, -2.4805e-01,  5.3406e-05,  ..., -5.4741e-03,
         -2.0599e-04,  1.3092e-02],
        [ 5.9814e-03,  1.3687e-02, -2.3840e-01,  ...,  8.7357e-03,
         -7.1640e-03, -1.0925e-02],
        ...,
        [-1.1993e-02,  2.1629e-03, -9.2545e-03,  ..., -2.5830e-01,
          1.1337e-02,  1.4664e-02],
        [-6.8741e-03, -9.4910e-03, -1.3222e-02,  ..., -2.2411e-03,
         -2.4304e-01, -3.7956e-03],
        [-1.7033e-03, -1.9577e-02, -1.4877e-02,  ..., -2.0771e-03,
          1.3704e-03, -2.6538e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:29:30 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 13:29:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0391, -0.9321, -0.8818,  ...,  0.5557, -0.5454,  0.2517],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0616, -0.1323, -0.5737,  ..., -0.6191, -0.3450, -0.1059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2622, -2.2656, -2.3359,  ...,  1.7773, -1.3809,  1.0068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7153, -0.2651, -0.5088,  ..., -0.6846,  0.5684, -0.3010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:29:30 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:29:30 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 13:30:26 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 13:31:21 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 13:32:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.3482e-03,  2.0561e-03,  1.0185e-03,  ..., -2.5158e-03,
         -2.7561e-03, -3.2730e-03],
        [ 1.2350e-03, -5.5389e-03, -1.2417e-03,  ..., -4.6196e-03,
          3.4356e-04, -1.0595e-03],
        [ 6.3438e-03,  2.2888e-04, -1.0468e-02,  ..., -1.8644e-03,
         -1.7042e-03, -9.8228e-04],
        ...,
        [ 4.4441e-03,  3.8757e-03, -1.4315e-03,  ..., -2.7637e-03,
         -1.5841e-03,  3.6240e-03],
        [-1.6356e-03,  2.8572e-03,  9.5248e-05,  ..., -4.4365e-03,
         -8.0414e-03,  2.3670e-03],
        [ 1.7586e-03, -2.7108e-04, -7.1239e-04,  ..., -2.8458e-03,
         -1.2150e-03, -5.7182e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1058,  0.0033, -0.0012,  ...,  0.0006, -0.0147, -0.0046],
        [ 0.0171, -0.0919, -0.0016,  ...,  0.0026, -0.0025,  0.0075],
        [-0.0019, -0.0069, -0.0864,  ..., -0.0064,  0.0019,  0.0076],
        ...,
        [ 0.0005,  0.0023,  0.0036,  ..., -0.0799,  0.0013,  0.0141],
        [ 0.0002, -0.0032,  0.0023,  ..., -0.0006, -0.0952,  0.0137],
        [ 0.0090,  0.0026,  0.0060,  ...,  0.0080, -0.0030, -0.0764]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0905, -0.0052, -0.0051,  ...,  0.0101, -0.0061,  0.0040],
        [ 0.0066, -0.1011,  0.0019,  ..., -0.0101,  0.0129, -0.0050],
        [-0.0029, -0.0044, -0.0954,  ..., -0.0090, -0.0018,  0.0112],
        ...,
        [ 0.0016,  0.0075,  0.0121,  ..., -0.0865,  0.0052, -0.0101],
        [-0.0015,  0.0003,  0.0010,  ...,  0.0083, -0.0957,  0.0056],
        [-0.0065,  0.0075,  0.0047,  ...,  0.0020,  0.0034, -0.0857]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:32:19 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 13:32:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1079, -1.3232, -1.2441,  ...,  1.0947, -0.1888,  0.7734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2255, -0.2732, -0.4094,  ..., -0.6851,  0.0527, -0.2078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1074, -2.6113, -2.6758,  ...,  1.8359, -0.9990,  0.9438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5332, -0.3601, -1.2520,  ..., -0.9600,  0.8071, -0.4792],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:32:19 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:32:19 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 13:33:13 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 13:34:11 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 13:35:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0209, -0.0056, -0.0012,  ...,  0.0074,  0.0029, -0.0003],
        [-0.0053,  0.0268, -0.0045,  ...,  0.0028,  0.0004, -0.0045],
        [-0.0062,  0.0027,  0.0205,  ..., -0.0003,  0.0029, -0.0020],
        ...,
        [ 0.0022,  0.0028,  0.0072,  ...,  0.0224, -0.0106,  0.0049],
        [ 0.0020, -0.0006,  0.0075,  ..., -0.0010,  0.0252,  0.0072],
        [ 0.0012, -0.0063,  0.0004,  ..., -0.0084, -0.0072,  0.0200]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0979,  0.0022, -0.0083,  ..., -0.0036, -0.0019,  0.0035],
        [-0.0060, -0.1321,  0.0121,  ..., -0.0074,  0.0091,  0.0096],
        [ 0.0172,  0.0045, -0.1069,  ...,  0.0025,  0.0082, -0.0107],
        ...,
        [-0.0132,  0.0024, -0.0005,  ..., -0.1247, -0.0024, -0.0018],
        [ 0.0043,  0.0124,  0.0059,  ...,  0.0108, -0.1235,  0.0030],
        [ 0.0063, -0.0036, -0.0191,  ..., -0.0164,  0.0079, -0.1246]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1711, -0.0069,  0.0024,  ..., -0.0200,  0.0112, -0.0031],
        [-0.0124, -0.1990,  0.0126,  ..., -0.0092, -0.0028,  0.0159],
        [ 0.0136, -0.0049, -0.1638,  ..., -0.0117,  0.0038,  0.0005],
        ...,
        [-0.0082, -0.0151, -0.0055,  ..., -0.1729,  0.0070, -0.0052],
        [ 0.0037,  0.0037, -0.0010,  ...,  0.0036, -0.1749, -0.0010],
        [ 0.0083,  0.0013, -0.0006,  ..., -0.0051,  0.0112, -0.1715]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:35:12 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 13:35:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1665, -1.1924, -1.1719,  ...,  0.8838, -0.6934,  0.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4629, -0.1770, -0.3147,  ..., -0.4194,  0.3738, -0.2411],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3054, -3.1387, -2.5078,  ...,  1.2471, -0.6504,  0.1274],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.8828e-04, -1.1904e+00, -1.7471e+00,  ..., -1.3525e+00,
         7.6758e-01, -5.0488e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:35:12 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:35:12 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 13:36:12 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 13:37:13 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 13:38:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.8166e-03, -5.2166e-04,  1.3351e-04,  ..., -1.4448e-03,
         -6.5765e-03,  1.0462e-03],
        [ 3.6836e-04, -3.4599e-03, -1.1177e-03,  ..., -1.7719e-03,
          1.8537e-04,  2.7924e-03],
        [ 1.8253e-03,  5.3883e-04, -6.3782e-03,  ...,  1.8129e-03,
         -1.7347e-03,  3.5133e-03],
        ...,
        [ 6.2332e-03, -1.8921e-03, -4.4823e-05,  ..., -4.7302e-03,
          4.4417e-04, -5.9128e-05],
        [ 1.0109e-03, -3.6621e-04, -4.2267e-03,  ...,  4.2725e-04,
         -1.8120e-05,  2.1763e-03],
        [-3.1376e-04,  2.4071e-03,  7.9775e-04,  ...,  1.9693e-04,
         -1.1806e-03, -5.4665e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.7158e-02, -8.9645e-03,  9.1629e-03,  ...,  4.5853e-03,
          1.2007e-03,  1.3145e-02],
        [-5.9853e-03, -9.1736e-02,  5.0468e-03,  ..., -6.3553e-03,
          1.3985e-02, -1.4629e-03],
        [-2.2964e-03,  3.0136e-03, -9.2529e-02,  ..., -9.0408e-04,
          8.4610e-03, -2.9430e-03],
        ...,
        [ 5.8632e-03, -9.4414e-05, -8.9264e-03,  ..., -9.6191e-02,
          1.6747e-03,  3.5954e-03],
        [ 2.1225e-02,  1.2703e-03,  6.1722e-03,  ...,  6.4087e-03,
         -9.3140e-02,  1.2421e-02],
        [ 6.4468e-04, -2.0065e-03, -1.5793e-02,  ..., -2.1248e-03,
          2.3308e-03, -1.0132e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1761e-01,  2.1911e-04, -2.6054e-03,  ..., -1.8280e-02,
          1.0345e-02,  6.5565e-05],
        [ 9.8648e-03, -1.2189e-01, -1.0643e-02,  ...,  8.6212e-03,
          4.4022e-03,  9.7504e-03],
        [-1.2321e-03, -2.6550e-03, -1.1676e-01,  ..., -2.0466e-03,
         -3.7823e-03, -2.8839e-03],
        ...,
        [ 7.3967e-03, -1.4938e-02, -1.1272e-03,  ..., -1.2244e-01,
          1.1276e-02,  4.4022e-03],
        [ 4.4441e-04,  7.5226e-03,  4.0283e-03,  ...,  5.5199e-03,
         -1.1670e-01,  1.3031e-02],
        [-1.0651e-02,  1.1856e-02, -5.8746e-03,  ...,  2.9182e-03,
          2.6550e-03, -1.3135e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:38:16 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 13:38:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0608, -1.3115, -1.2383,  ...,  0.8584, -0.4758,  0.4299],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3247, -0.2434, -0.6924,  ..., -0.5581,  0.4707, -0.3164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0994, -3.3633, -2.1797,  ...,  1.1133, -1.0498,  0.0913],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2465, -1.0107, -2.6406,  ..., -1.7109, -0.0581, -0.4316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:38:16 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:38:16 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 13:39:13 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 13:40:16 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 13:41:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.4557e-02,  4.0436e-03,  2.4261e-03,  ...,  3.9291e-03,
         -5.2185e-03,  3.4161e-03],
        [ 8.0185e-03,  1.1169e-02,  5.1422e-03,  ...,  3.4752e-03,
          5.6534e-03, -4.2915e-03],
        [-8.4686e-04, -7.2708e-03,  9.9106e-03,  ..., -1.6165e-03,
         -5.9586e-03, -1.3313e-03],
        ...,
        [-4.7913e-03, -5.3749e-03,  2.1756e-05,  ...,  1.0323e-02,
         -1.2299e-02, -3.8452e-03],
        [ 1.2047e-02, -4.2458e-03,  9.6130e-03,  ..., -6.7368e-03,
          1.6296e-02, -5.3444e-03],
        [ 4.0359e-03, -2.1229e-03,  9.0485e-03,  ...,  1.9574e-04,
         -1.1683e-05,  1.7349e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1005,  0.0006,  0.0008,  ..., -0.0016, -0.0086, -0.0033],
        [ 0.0142, -0.1013, -0.0067,  ..., -0.0013,  0.0095, -0.0023],
        [ 0.0088,  0.0090, -0.1184,  ..., -0.0089, -0.0037,  0.0067],
        ...,
        [-0.0030,  0.0028,  0.0186,  ..., -0.1096, -0.0114, -0.0047],
        [-0.0036, -0.0107, -0.0088,  ...,  0.0031, -0.1158,  0.0201],
        [ 0.0156,  0.0194,  0.0094,  ...,  0.0083,  0.0164, -0.1062]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3831e-01,  7.4196e-04, -1.5736e-04,  ...,  1.6384e-03,
          1.0674e-02, -6.7139e-04],
        [ 6.3705e-03, -1.5979e-01,  1.4181e-03,  ..., -2.6627e-03,
         -2.4719e-03, -1.5495e-02],
        [-6.4278e-03,  5.4131e-03, -1.6101e-01,  ..., -1.7548e-03,
         -7.1106e-03,  1.4206e-02],
        ...,
        [ 2.4891e-03, -9.9945e-04,  2.6627e-03,  ..., -1.7249e-01,
         -2.7447e-03, -6.8817e-03],
        [-4.4174e-03, -9.9869e-03, -1.9012e-02,  ...,  1.3550e-02,
         -1.6614e-01,  2.1011e-02],
        [ 2.2614e-02,  5.4283e-03,  3.2272e-03,  ...,  1.2848e-02,
          1.4168e-02, -1.4954e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:41:20 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 13:41:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1028, -1.4922, -1.1328,  ...,  0.5723, -0.2993,  0.0322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0411, -0.6465, -0.9072,  ..., -0.7168,  0.4148, -0.3008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2114, -3.4277, -2.2383,  ...,  0.9258, -1.1279,  0.6650],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1124, -1.5322, -2.6738,  ..., -1.0664, -0.0607,  0.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:41:20 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:41:20 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 13:42:24 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 13:43:26 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 13:44:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0024, -0.0027, -0.0002,  ...,  0.0013,  0.0002, -0.0026],
        [-0.0037,  0.0027, -0.0038,  ...,  0.0044,  0.0047,  0.0041],
        [-0.0023, -0.0001,  0.0041,  ..., -0.0008,  0.0034, -0.0025],
        ...,
        [ 0.0037,  0.0012,  0.0013,  ...,  0.0033, -0.0037, -0.0053],
        [ 0.0023,  0.0015,  0.0048,  ...,  0.0010,  0.0022, -0.0002],
        [ 0.0029,  0.0037,  0.0021,  ..., -0.0017,  0.0057,  0.0010]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0729,  0.0017, -0.0004,  ...,  0.0005, -0.0103, -0.0189],
        [-0.0143, -0.0758, -0.0117,  ...,  0.0103, -0.0101,  0.0045],
        [-0.0046, -0.0124, -0.0589,  ..., -0.0106,  0.0002,  0.0075],
        ...,
        [-0.0067, -0.0039, -0.0254,  ..., -0.0765,  0.0033, -0.0050],
        [ 0.0147,  0.0096, -0.0126,  ...,  0.0029, -0.0775,  0.0016],
        [-0.0059,  0.0012,  0.0065,  ..., -0.0042,  0.0022, -0.0845]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0781,  0.0010, -0.0122,  ...,  0.0036,  0.0012, -0.0158],
        [ 0.0147, -0.0862, -0.0026,  ...,  0.0064, -0.0100,  0.0164],
        [ 0.0082,  0.0018, -0.0932,  ..., -0.0154, -0.0116, -0.0048],
        ...,
        [-0.0029,  0.0082, -0.0150,  ..., -0.0879,  0.0037, -0.0058],
        [ 0.0136,  0.0252, -0.0232,  ...,  0.0071, -0.0712, -0.0076],
        [-0.0152,  0.0189,  0.0042,  ...,  0.0007, -0.0037, -0.0778]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:44:33 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 13:44:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-5.7739e-02, -1.4727e+00, -9.0137e-01,  ...,  4.5874e-01,
        -4.3994e-01,  5.3644e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1334, -0.4968, -1.2188,  ..., -0.8027, -0.0148, -0.2452],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2974, -2.6445, -2.0078,  ...,  1.1582, -0.8452,  1.6074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.3384, -1.5332, -2.1953,  ..., -1.3574, -0.4744, -0.0815],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:44:33 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:44:33 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 13:45:37 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 13:46:44 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 13:47:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.6512e-03, -2.9354e-03,  1.8101e-03,  ...,  2.5711e-03,
          4.1466e-03,  7.2670e-03],
        [-2.1057e-03, -7.0190e-03, -8.0967e-04,  ...,  1.1034e-03,
          1.1530e-03, -2.7885e-03],
        [-1.3189e-03,  1.1263e-03, -9.9106e-03,  ...,  8.8692e-04,
         -8.7833e-04,  8.1480e-05],
        ...,
        [ 2.3022e-03, -5.0879e-04,  2.1038e-03,  ..., -7.7438e-03,
          2.0123e-03, -3.2349e-03],
        [ 1.3905e-03,  6.7024e-03, -2.9087e-04,  ...,  2.1286e-03,
         -1.5625e-02, -4.9248e-03],
        [ 1.2684e-03,  1.8158e-03,  8.4281e-05,  ..., -1.8253e-03,
         -6.2752e-03, -1.1528e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0980,  0.0010,  0.0082,  ...,  0.0008,  0.0051,  0.0127],
        [ 0.0106, -0.0884, -0.0025,  ..., -0.0112,  0.0068, -0.0113],
        [ 0.0095, -0.0010, -0.0994,  ..., -0.0112,  0.0078,  0.0020],
        ...,
        [-0.0065, -0.0119,  0.0030,  ..., -0.0853,  0.0101, -0.0087],
        [ 0.0029, -0.0031,  0.0036,  ...,  0.0047, -0.0991,  0.0012],
        [-0.0001,  0.0051, -0.0038,  ..., -0.0172,  0.0062, -0.0697]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0986,  0.0105,  0.0040,  ...,  0.0066,  0.0025,  0.0128],
        [-0.0007, -0.0955, -0.0040,  ..., -0.0041, -0.0065, -0.0201],
        [ 0.0097,  0.0084, -0.1052,  ..., -0.0029,  0.0022,  0.0054],
        ...,
        [-0.0025, -0.0172, -0.0096,  ..., -0.1031,  0.0105, -0.0068],
        [ 0.0061,  0.0125,  0.0156,  ..., -0.0016, -0.1075,  0.0038],
        [ 0.0053, -0.0065,  0.0017,  ...,  0.0048,  0.0072, -0.0906]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:47:52 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 13:47:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1075, -1.4111, -0.9155,  ...,  0.3767, -0.4702,  0.2358],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0700, -0.6992, -1.2139,  ..., -0.4897, -0.0229,  0.2590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1157, -2.1289, -1.8418,  ...,  0.9326, -0.9907,  2.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2905, -0.1826, -3.1953,  ..., -0.3662, -0.9619,  0.7446],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:47:52 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:47:52 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 13:49:00 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 13:50:04 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 13:51:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.8348e-03, -5.3787e-04, -3.4122e-03,  ...,  6.0320e-04,
          4.1962e-04,  2.0599e-03],
        [ 9.3174e-04, -1.0384e-02,  3.7212e-03,  ..., -8.5640e-04,
         -8.4877e-05, -2.1195e-04],
        [-1.8692e-03, -6.6280e-04, -7.4005e-03,  ...,  1.1663e-03,
          1.8482e-03, -1.7891e-03],
        ...,
        [-3.0613e-04,  7.3910e-04,  1.8396e-03,  ..., -7.9269e-03,
         -5.7173e-04, -1.3237e-03],
        [-3.2425e-04, -1.2989e-03,  2.1896e-03,  ..., -4.4250e-04,
         -1.0872e-02, -1.3361e-03],
        [ 8.7261e-05, -4.8733e-04, -3.9029e-04,  ..., -3.7909e-04,
         -1.0471e-03, -1.0094e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.7168e-02, -1.5778e-02, -3.0899e-03,  ..., -2.2736e-03,
          7.3357e-03, -6.5079e-03],
        [-6.5231e-03, -1.1017e-01,  2.0828e-03,  ..., -6.8970e-03,
          7.2861e-03,  9.7961e-03],
        [ 1.6052e-02,  2.8515e-03, -9.6069e-02,  ...,  8.6441e-03,
          5.6496e-03, -1.0056e-02],
        ...,
        [-6.7635e-03,  1.2674e-03, -7.7438e-03,  ..., -1.0797e-01,
         -8.4229e-03,  3.8834e-03],
        [-5.5313e-04,  1.2138e-02,  6.5041e-04,  ...,  3.2196e-03,
         -1.0883e-01,  1.5549e-02],
        [-2.6245e-03,  3.8605e-03, -5.0163e-03,  ..., -6.8665e-05,
         -1.2913e-03, -1.1707e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1287,  0.0124, -0.0055,  ..., -0.0126, -0.0090,  0.0021],
        [ 0.0047, -0.1310,  0.0082,  ...,  0.0048,  0.0179,  0.0057],
        [-0.0037,  0.0016, -0.1228,  ..., -0.0096,  0.0144, -0.0087],
        ...,
        [-0.0029, -0.0046,  0.0048,  ..., -0.1230, -0.0013,  0.0062],
        [-0.0109,  0.0026, -0.0252,  ..., -0.0143, -0.1273,  0.0075],
        [-0.0093,  0.0064, -0.0164,  ...,  0.0101, -0.0083, -0.1399]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:51:08 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 13:51:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1289, -1.0791, -0.8091,  ...,  0.4595, -0.3210,  0.6191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1581, -0.7266, -1.0186,  ..., -0.6333, -0.2004, -0.0839],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5952, -1.5371, -2.1465,  ...,  1.8447, -0.4731,  2.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2380, -0.7021, -2.5625,  ..., -0.6777, -0.3242,  1.5391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:51:08 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:51:08 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 13:52:11 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 13:53:23 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 13:54:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.9776e-03, -6.6936e-05,  2.7542e-03,  ...,  3.2082e-03,
         -3.8795e-03, -6.4621e-03],
        [ 2.8191e-03,  1.1658e-02, -5.7220e-03,  ...,  1.6785e-02,
         -4.7417e-03, -1.8196e-03],
        [-3.8815e-04,  3.7408e-04,  1.0551e-02,  ..., -1.9562e-02,
          2.6417e-03,  5.0392e-03],
        ...,
        [ 1.9283e-03, -2.3823e-03, -5.9090e-03,  ...,  1.9394e-02,
         -2.4776e-03, -1.8835e-03],
        [ 1.7033e-03, -3.2883e-03, -2.0409e-03,  ...,  3.8757e-03,
          1.4679e-02,  2.8744e-03],
        [-1.0529e-03, -1.9321e-03,  3.4618e-03,  ..., -1.4424e-04,
         -2.8496e-03,  1.2154e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.5593e-02, -7.0572e-05,  7.8583e-03,  ...,  8.2474e-03,
         -5.2109e-03, -5.3520e-03],
        [-1.1806e-03, -4.3884e-02,  4.3182e-03,  ...,  1.9424e-02,
          9.1553e-04, -1.0338e-02],
        [-6.7863e-03,  1.3870e-02, -3.0396e-02,  ...,  1.6308e-03,
         -7.4348e-03, -3.3493e-03],
        ...,
        [-1.2695e-02, -1.3306e-02, -6.6605e-03,  ..., -3.7689e-02,
         -1.0208e-02, -1.0651e-02],
        [ 2.3537e-03, -3.6621e-04, -3.1929e-03,  ...,  1.6495e-02,
         -4.5563e-02,  4.7531e-03],
        [-1.2039e-02,  1.3123e-03, -4.7798e-03,  ..., -5.3482e-03,
          1.1246e-02, -3.5370e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0504, -0.0029,  0.0050,  ..., -0.0128, -0.0056, -0.0105],
        [-0.0076, -0.0427,  0.0077,  ...,  0.0216,  0.0035,  0.0001],
        [-0.0045,  0.0190, -0.0460,  ..., -0.0083,  0.0057,  0.0117],
        ...,
        [-0.0065,  0.0010, -0.0082,  ..., -0.0483, -0.0065, -0.0209],
        [-0.0026,  0.0083, -0.0091,  ...,  0.0161, -0.0406,  0.0270],
        [-0.0011, -0.0105,  0.0154,  ..., -0.0218,  0.0097, -0.0495]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:54:38 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 13:54:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0444, -0.8311, -0.6938,  ...,  0.3538, -0.3779,  0.9180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1243, -0.0895, -1.3105,  ..., -0.1508, -0.4045,  0.2859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3809, -1.2998, -1.9121,  ...,  1.3086, -1.5547,  1.8984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0850, -0.2349, -3.1797,  ..., -1.4199, -0.3467,  1.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:54:38 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:54:38 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 13:55:49 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 13:57:01 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 13:58:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6642e-03, -3.8385e-04, -1.5128e-04,  ..., -1.5438e-04,
          2.7847e-04, -2.6226e-06],
        [-7.8869e-04, -1.7433e-03,  4.4155e-04,  ..., -2.4815e-03,
         -2.5768e-03,  1.3895e-03],
        [-1.5631e-03, -2.6894e-03, -1.3819e-03,  ..., -2.1386e-04,
          7.8297e-04,  4.9925e-04],
        ...,
        [-1.6475e-04, -1.1826e-03, -8.0776e-04,  ..., -1.9875e-03,
          3.6049e-04,  3.6526e-04],
        [-2.5597e-03, -6.8998e-04,  1.8349e-03,  ...,  1.8129e-03,
         -1.1034e-03, -2.2488e-03],
        [ 4.4107e-04,  1.2493e-03, -2.3594e-03,  ..., -1.9417e-03,
         -2.5253e-03,  3.8958e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0386, -0.0131,  0.0091,  ...,  0.0159, -0.0073,  0.0046],
        [-0.0060, -0.0575, -0.0043,  ...,  0.0271, -0.0129,  0.0140],
        [ 0.0064,  0.0134, -0.0449,  ..., -0.0155,  0.0086, -0.0110],
        ...,
        [ 0.0040, -0.0072, -0.0069,  ..., -0.0243, -0.0036, -0.0155],
        [ 0.0088,  0.0066, -0.0096,  ..., -0.0013, -0.0367,  0.0106],
        [-0.0161, -0.0014,  0.0103,  ...,  0.0043,  0.0062, -0.0510]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.6570e-02,  1.0689e-02,  1.0490e-02,  ...,  2.0233e-02,
          1.0204e-03,  9.8801e-03],
        [-8.6784e-05, -7.2021e-02,  6.7978e-03,  ...,  1.9241e-02,
         -1.2178e-03,  2.9633e-02],
        [-1.6678e-02, -7.4539e-03, -6.9641e-02,  ...,  5.2929e-04,
          5.4407e-04, -7.6370e-03],
        ...,
        [ 9.3002e-03,  4.2229e-03, -2.0237e-03,  ..., -4.2175e-02,
         -1.1349e-03, -9.0332e-03],
        [ 2.0332e-03, -4.3869e-03,  1.1864e-02,  ...,  5.9891e-03,
         -4.9042e-02, -2.7828e-03],
        [-6.9504e-03,  1.8778e-03, -5.4169e-03,  ..., -1.5373e-03,
         -1.0052e-03, -7.5867e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 13:58:15 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 13:58:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2131, -0.5620, -0.7690,  ...,  0.6436, -0.1599,  0.7319],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0948, -0.2966, -1.0371,  ..., -0.2864, -0.1232,  0.6006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7559, -1.1377, -2.5918,  ...,  1.2178, -1.4004,  2.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.5645, -0.2347, -3.1172,  ..., -0.3027, -0.5781,  1.1953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 13:58:15 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 13:58:16 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 13:59:35 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 14:00:56 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 14:02:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.8354e-03, -4.2152e-03,  2.5082e-04,  ..., -8.7309e-04,
         -1.4763e-03,  2.5883e-03],
        [-1.4758e-04,  3.2978e-03, -1.6203e-03,  ...,  3.8548e-03,
          1.1044e-03,  2.8670e-05],
        [-1.3590e-03, -2.0924e-03,  7.5493e-03,  ..., -1.4772e-03,
          1.3533e-03,  2.7680e-04],
        ...,
        [ 7.8619e-05,  5.1498e-03, -3.9978e-03,  ...,  6.6376e-03,
          1.2035e-03, -1.7014e-03],
        [-8.9502e-04, -8.7070e-04,  1.4458e-03,  ...,  7.7152e-04,
          4.3106e-03, -1.1396e-03],
        [-1.6537e-03,  2.2869e-03, -3.0594e-03,  ...,  2.0390e-03,
          6.0158e-03,  7.2823e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.8564e-02, -1.5106e-02, -9.4986e-03,  ..., -8.2855e-03,
          3.4332e-03,  1.9592e-02],
        [-9.4376e-03, -5.5603e-02, -6.0234e-03,  ...,  1.4175e-02,
         -5.3406e-05,  2.0966e-02],
        [ 3.1910e-03,  1.6737e-03, -2.6031e-02,  ...,  1.5114e-02,
         -5.4893e-03, -2.7218e-03],
        ...,
        [-9.0027e-03, -7.3395e-03, -1.7532e-02,  ..., -6.2012e-02,
          8.8882e-04,  6.7234e-04],
        [ 4.2343e-04, -6.5765e-03, -1.1108e-02,  ...,  1.9943e-02,
         -6.3538e-02, -1.4515e-03],
        [ 5.3482e-03,  8.2092e-03,  7.6370e-03,  ..., -5.9700e-03,
         -1.0406e-02, -4.2816e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0945e-02,  5.2147e-03,  2.3060e-03,  ..., -1.2932e-02,
          7.9575e-03,  8.2474e-03],
        [-8.8196e-03, -5.7129e-02, -1.5610e-02,  ..., -4.4670e-03,
          2.1637e-02,  1.4305e-02],
        [-3.0518e-05,  7.2212e-03, -5.8258e-02,  ...,  2.4471e-03,
         -1.6708e-02,  1.9775e-02],
        ...,
        [ 8.3923e-03, -2.9724e-02, -8.1635e-03,  ..., -4.5441e-02,
         -5.5923e-03,  1.5465e-02],
        [ 2.3239e-02, -1.3237e-02, -1.0246e-02,  ...,  1.1795e-02,
         -5.8807e-02, -7.4615e-03],
        [-1.3924e-02, -1.3535e-02, -9.9945e-04,  ..., -1.6083e-02,
         -1.0521e-02, -5.7800e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:02:19 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 14:02:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4966, -0.4507, -0.6719,  ...,  0.4580, -0.5415,  0.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4346, -0.0944, -1.2402,  ..., -0.5449, -0.1283,  0.6279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0410, -1.4209, -1.3096,  ...,  0.9199, -1.1943,  2.8105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2031, -0.0573, -2.6328,  ..., -0.3472, -1.8115,  1.4219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:02:19 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 14:02:19 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 14:03:36 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 14:04:52 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 14:06:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.5940e-04,  1.4591e-04, -4.7028e-05,  ..., -1.7524e-04,
         -4.1223e-04, -3.5191e-04],
        [ 1.7679e-04, -1.0786e-03,  1.3232e-04,  ...,  2.9612e-04,
         -2.9027e-05,  9.6202e-05],
        [-1.0705e-04,  4.7731e-04, -3.2139e-04,  ...,  1.1450e-04,
          1.4615e-04, -5.4502e-04],
        ...,
        [-8.3804e-05,  3.5810e-04, -1.8191e-04,  ..., -8.9216e-04,
          3.7313e-04, -1.7715e-04],
        [ 2.9945e-04,  6.8128e-05, -1.3757e-04,  ..., -1.6975e-04,
         -8.4782e-04,  4.7350e-04],
        [-5.0974e-04,  9.6846e-04,  6.5184e-04,  ...,  2.3341e-04,
          7.8487e-04, -1.5745e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0311,  0.0120, -0.0080,  ...,  0.0008,  0.0003,  0.0044],
        [ 0.0011, -0.0347, -0.0047,  ..., -0.0030,  0.0065,  0.0092],
        [-0.0015, -0.0047, -0.0471,  ..., -0.0119,  0.0089,  0.0102],
        ...,
        [-0.0070, -0.0108, -0.0200,  ..., -0.0350,  0.0071,  0.0266],
        [ 0.0212, -0.0047,  0.0146,  ...,  0.0064, -0.0569,  0.0062],
        [ 0.0011, -0.0116,  0.0053,  ..., -0.0266,  0.0025, -0.0570]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0588,  0.0220, -0.0073,  ...,  0.0116, -0.0002,  0.0042],
        [ 0.0315, -0.0453, -0.0130,  ..., -0.0130, -0.0027,  0.0030],
        [-0.0015, -0.0206, -0.0844,  ..., -0.0066,  0.0065, -0.0031],
        ...,
        [ 0.0074, -0.0004, -0.0110,  ..., -0.0957,  0.0086,  0.0131],
        [ 0.0145, -0.0003, -0.0147,  ...,  0.0237, -0.0757, -0.0213],
        [ 0.0055, -0.0129,  0.0172,  ..., -0.0126, -0.0152, -0.0839]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:06:10 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 14:06:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6147, -0.3748, -0.8770,  ...,  0.4087, -0.4539,  0.6558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5977, -0.0857, -1.1475,  ..., -0.1057, -0.1956,  0.4160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.6328, -1.2891, -1.8857,  ...,  0.1821, -0.6650,  2.9219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.9736,  0.4893, -2.6855,  ..., -0.5005, -1.8828,  1.6582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:06:10 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 14:06:10 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 14:07:27 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 14:08:45 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 14:10:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.5613e-04,  1.8954e-04, -4.1366e-04,  ...,  2.8419e-04,
         -1.0061e-03,  6.9618e-04],
        [-5.6410e-04,  1.3599e-03,  3.3998e-04,  ...,  1.3323e-03,
          5.1546e-04, -2.0385e-04],
        [ 1.6298e-03,  2.0428e-03,  1.2045e-03,  ...,  5.2357e-04,
         -2.8491e-04,  8.2588e-04],
        ...,
        [ 7.1669e-04, -1.8616e-03, -3.9959e-04,  ...,  1.5688e-03,
          4.8065e-04, -3.9244e-04],
        [-1.2130e-04, -1.6606e-04, -1.3466e-03,  ...,  3.5429e-04,
          8.6069e-04, -8.2254e-05],
        [ 6.3753e-04,  2.3003e-03,  1.1921e-03,  ..., -1.2283e-03,
         -4.3011e-04,  8.7929e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0288, -0.0033,  0.0038,  ..., -0.0052,  0.0115,  0.0190],
        [ 0.0216, -0.0315,  0.0179,  ..., -0.0012,  0.0059, -0.0168],
        [ 0.0041,  0.0004, -0.0265,  ..., -0.0077,  0.0162, -0.0026],
        ...,
        [ 0.0064, -0.0063, -0.0076,  ..., -0.0062,  0.0040,  0.0011],
        [-0.0060, -0.0112, -0.0015,  ..., -0.0025, -0.0148,  0.0088],
        [ 0.0027, -0.0192,  0.0069,  ...,  0.0031,  0.0193, -0.0363]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0423, -0.0335, -0.0100,  ..., -0.0125, -0.0002, -0.0037],
        [ 0.0012, -0.0531,  0.0009,  ...,  0.0044, -0.0059, -0.0088],
        [ 0.0207,  0.0015, -0.0635,  ..., -0.0053, -0.0135, -0.0245],
        ...,
        [-0.0102,  0.0051,  0.0074,  ..., -0.0428, -0.0107, -0.0001],
        [-0.0031, -0.0039, -0.0051,  ...,  0.0034, -0.0870, -0.0105],
        [ 0.0141, -0.0123, -0.0089,  ...,  0.0053,  0.0013, -0.0773]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:10:06 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 14:10:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6826, -0.4226, -0.4729,  ...,  0.2864, -0.3838,  0.9087],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8057,  0.0046, -0.9863,  ..., -0.1323, -0.6470,  0.4895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.6543, -0.6357, -1.3887,  ...,  0.8872,  0.1094,  2.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4395,  1.6143, -1.8662,  ...,  0.5015,  0.1992,  1.2979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:10:06 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 14:10:06 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 14:11:25 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 14:12:46 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 14:14:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.0092e-03,  5.0545e-05,  3.3557e-05,  ...,  1.5774e-03,
          3.9935e-04,  1.0757e-03],
        [-1.7762e-04,  2.9144e-03, -2.6965e-04,  ..., -2.8014e-05,
         -1.0633e-03, -4.8494e-04],
        [ 2.2197e-04, -3.1424e-04,  4.9248e-03,  ..., -6.3610e-04,
          2.5654e-04, -4.3869e-04],
        ...,
        [-4.6313e-05, -2.8324e-04, -2.8586e-04,  ...,  4.7569e-03,
          1.0767e-03, -5.1737e-04],
        [ 7.8821e-04,  4.2248e-04, -9.0599e-04,  ...,  1.6165e-03,
          4.5929e-03, -1.4849e-03],
        [ 5.2166e-04, -8.2541e-04, -8.2922e-04,  ..., -4.5359e-05,
         -1.0490e-04,  6.1531e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 1.8433e-02, -4.8981e-03,  2.1545e-02,  ...,  1.5812e-03,
          9.0179e-03,  9.6130e-04],
        [-6.4240e-03, -4.5349e-02, -9.0866e-03,  ...,  6.6681e-03,
          1.1206e-03,  1.0269e-02],
        [ 7.5035e-03, -2.2842e-02, -4.3449e-03,  ...,  3.8528e-04,
         -7.1449e-03, -4.2191e-03],
        ...,
        [-7.8659e-03,  8.4915e-03,  4.0512e-03,  ...,  1.0895e-02,
         -5.8174e-05, -4.6196e-03],
        [ 6.7444e-03, -9.5215e-03,  6.6986e-03,  ...,  2.4597e-02,
          1.5099e-02,  2.6581e-02],
        [-6.8188e-05, -6.9809e-04, -1.7471e-02,  ..., -1.4511e-02,
          1.0048e-02,  2.6093e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.8513e-02,  7.6294e-05,  1.4130e-02,  ...,  1.4679e-02,
         -2.0790e-03, -9.0485e-03],
        [ 2.5749e-04, -2.9831e-02,  7.3318e-03,  ...,  1.2840e-02,
         -2.1072e-02,  1.5373e-02],
        [ 1.0902e-02, -2.1500e-02, -8.0643e-03,  ...,  1.4091e-02,
         -9.7504e-03,  4.6501e-03],
        ...,
        [-1.2276e-02,  2.4776e-03, -1.0101e-02,  ..., -5.8823e-03,
          1.4282e-02, -2.5845e-03],
        [ 7.0572e-03, -1.1139e-02, -1.6525e-02,  ...,  9.6741e-03,
         -2.3041e-02,  2.1240e-02],
        [ 8.3065e-04,  1.2215e-02, -1.1414e-02,  ...,  1.5053e-02,
          8.3771e-03, -3.8147e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:14:09 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 14:14:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8599, -0.3667, -0.6533,  ...,  0.0191, -0.2123,  0.9023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7173,  0.1857, -0.9990,  ..., -0.2114, -0.6597,  0.5513],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0801,  0.1152, -2.0898,  ...,  1.2637,  0.4038,  2.5723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.3398,  2.5176, -2.0391,  ..., -0.8228,  0.4126,  1.0723],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:14:09 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 14:14:09 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 14:15:32 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 14:16:56 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 14:18:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7147e-03,  3.1471e-05,  3.8981e-05,  ...,  8.0872e-04,
          1.2422e-04, -2.5928e-05],
        [-4.5753e-04, -4.3273e-04,  4.4370e-04,  ..., -3.4642e-04,
          2.1887e-04, -8.2827e-04],
        [ 2.1243e-04, -4.0221e-04,  7.3147e-04,  ..., -1.7989e-04,
          4.5681e-04, -7.8487e-04],
        ...,
        [ 5.6601e-04,  3.1233e-04, -1.2045e-03,  ...,  7.6485e-04,
          2.2054e-04, -5.3942e-05],
        [ 5.9223e-04,  1.1024e-03, -7.4959e-04,  ..., -3.3736e-05,
          5.1308e-04,  6.3300e-05],
        [-8.5783e-04, -1.1969e-03,  4.1342e-04,  ..., -6.8426e-05,
          6.4325e-04,  8.4305e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0128,  0.0133,  0.0118,  ..., -0.0087,  0.0118,  0.0018],
        [-0.0153, -0.0314,  0.0003,  ...,  0.0053,  0.0070, -0.0103],
        [ 0.0162, -0.0023,  0.0002,  ..., -0.0158, -0.0088,  0.0087],
        ...,
        [-0.0075, -0.0024, -0.0182,  ..., -0.0067,  0.0093, -0.0034],
        [-0.0102,  0.0076, -0.0176,  ..., -0.0035, -0.0234,  0.0048],
        [ 0.0059, -0.0032,  0.0021,  ...,  0.0113, -0.0111, -0.0157]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0449,  0.0011,  0.0201,  ...,  0.0094, -0.0010, -0.0005],
        [-0.0039, -0.0441, -0.0070,  ...,  0.0024,  0.0015,  0.0188],
        [-0.0031,  0.0153, -0.0179,  ..., -0.0054, -0.0427,  0.0096],
        ...,
        [ 0.0034,  0.0101, -0.0198,  ..., -0.0230,  0.0393, -0.0145],
        [ 0.0087,  0.0054, -0.0456,  ...,  0.0089, -0.0441,  0.0164],
        [-0.0165,  0.0161,  0.0015,  ...,  0.0283, -0.0043, -0.0538]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:18:24 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 14:18:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8174, -0.1465, -0.4758,  ...,  0.1498,  0.0037,  0.7817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8677,  0.5410, -0.6943,  ...,  0.0635,  0.0369,  0.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.2520,  0.4375, -4.0391,  ...,  0.1172,  0.0083,  1.6230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.9102,  2.1191, -2.9375,  ..., -0.7109,  0.4294,  0.9248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:18:24 root INFO     [order_1_approx] starting weight calculation for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 14:18:24 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 14:19:51 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 14:21:15 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 14:22:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.6654e-03, -2.1458e-04, -3.3069e-04,  ...,  7.1287e-04,
          2.7752e-04, -1.3523e-03],
        [ 2.7180e-04, -2.1572e-03,  7.1239e-04,  ..., -2.3746e-04,
          5.4359e-04,  1.2579e-03],
        [ 1.8654e-03, -1.6937e-03, -3.4828e-03,  ..., -3.5167e-04,
         -9.8133e-04,  7.0286e-04],
        ...,
        [ 8.0109e-05, -3.1829e-05, -9.4593e-05,  ..., -4.3831e-03,
         -1.2934e-04,  8.6880e-04],
        [ 9.2697e-04, -1.2197e-03, -3.1877e-04,  ..., -1.0233e-03,
         -2.9202e-03, -1.0657e-04],
        [-2.5058e-04,  1.9064e-03, -4.8542e-04,  ...,  8.2159e-04,
         -3.8242e-04, -3.1109e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0497, -0.0043, -0.0058,  ...,  0.0024, -0.0101, -0.0063],
        [ 0.0172, -0.0101,  0.0063,  ..., -0.0381,  0.0251, -0.0037],
        [-0.0165, -0.0082,  0.0184,  ..., -0.0162,  0.0049,  0.0114],
        ...,
        [ 0.0028,  0.0073,  0.0002,  ...,  0.0643,  0.0056, -0.0125],
        [-0.0004, -0.0086, -0.0345,  ..., -0.0127,  0.0397,  0.0062],
        [-0.0226,  0.0268,  0.0064,  ..., -0.0038,  0.0167,  0.0505]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0222,  0.0098,  0.0136,  ..., -0.0219,  0.0164, -0.0121],
        [ 0.0391, -0.0443, -0.0122,  ..., -0.0411,  0.0210, -0.0073],
        [-0.0140, -0.0140, -0.0386,  ..., -0.0270, -0.0102,  0.0130],
        ...,
        [ 0.0033, -0.0129, -0.0226,  ..., -0.0268,  0.0168,  0.0182],
        [ 0.0136, -0.0060, -0.0204,  ...,  0.0031, -0.0328, -0.0071],
        [-0.0150,  0.0099,  0.0384,  ...,  0.0050, -0.0237, -0.0311]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:22:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The falcon falls into the category of raptor
The allosaurus falls into the category of dinosaur
The butterfly falls into the category of insect
The jackal falls into the category of canine
The vulture falls into the category of raptor
The gorilla falls into the category of primate
The leopard falls into the category of feline
The goat falls into the category of
2024-06-30 14:22:46 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 14:22:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1852,  0.2893,  0.4812,  ...,  0.2688, -0.0593,  0.3174],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4666, -0.1385, -0.5571,  ..., -0.1677, -0.9136, -0.3987],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4705,  0.0059, -0.0999,  ..., -0.2786,  0.2158,  0.0925],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4829,  0.0854, -0.2578,  ..., -0.4990, -0.3958, -0.4736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:22:46 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:22:46 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 14:23:10 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 14:23:33 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 14:23:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.3850e-05, -8.2612e-05, -7.6473e-05,  ..., -4.7565e-05,
          1.1706e-04,  2.1756e-04],
        [-1.9085e-04, -1.1295e-04, -1.0633e-04,  ...,  1.5509e-04,
         -3.2604e-05,  3.4761e-04],
        [-3.4928e-05, -1.0908e-05, -5.5981e-04,  ...,  2.1160e-05,
         -5.7840e-04,  1.0979e-04],
        ...,
        [-9.6738e-05, -5.5075e-04, -6.1035e-05,  ..., -5.8699e-04,
         -3.8528e-04, -1.9598e-04],
        [ 2.1315e-04,  7.2360e-05, -1.2141e-04,  ..., -1.8096e-04,
         -1.8859e-04, -2.3317e-04],
        [-3.4523e-04, -1.6332e-04,  4.2415e-04,  ..., -4.8423e-04,
         -1.1194e-04, -5.9032e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.0365e-02, -1.0818e-02, -5.6565e-05,  ..., -3.7804e-03,
          5.8098e-03,  3.6469e-03],
        [-1.7548e-04, -1.4984e-02,  1.2569e-03,  ...,  1.0773e-02,
          2.3937e-03, -1.0443e-04],
        [-1.1223e-02,  6.5384e-03, -3.7567e-02,  ...,  2.9068e-03,
          3.6373e-03, -2.3708e-03],
        ...,
        [-2.4796e-05,  5.3864e-03, -3.8567e-03,  ..., -3.0640e-02,
          5.1041e-03,  7.6370e-03],
        [ 1.1299e-02,  1.0433e-03,  1.2589e-03,  ...,  3.8280e-03,
         -2.2491e-02,  3.1738e-03],
        [ 1.1053e-03,  5.4359e-03,  5.9586e-03,  ...,  6.6643e-03,
          1.1581e-02, -1.6129e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0472e-02,  5.1117e-04,  6.7139e-03,  ..., -9.1219e-04,
         -1.0529e-03,  3.5763e-04],
        [ 5.4693e-04, -2.6489e-02, -5.8212e-03,  ..., -1.9817e-03,
          1.9627e-03,  6.2037e-04],
        [-3.4356e-04,  2.5864e-03, -2.5085e-02,  ...,  1.2398e-05,
         -1.4372e-03,  5.8479e-03],
        ...,
        [ 2.1286e-03,  3.3474e-03,  7.3862e-04,  ..., -2.2446e-02,
          3.1395e-03,  2.2869e-03],
        [-1.4973e-03,  2.0409e-03, -2.0230e-04,  ..., -7.9274e-06,
         -2.5024e-02,  4.5562e-04],
        [-7.1478e-04, -2.5215e-03, -2.9716e-03,  ...,  6.7997e-04,
          4.3917e-04, -2.8107e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:23:58 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 14:23:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2766,  0.5781, -0.2771,  ..., -0.0705, -0.0078,  0.3501],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5737,  0.1558, -0.3494,  ..., -1.0430, -0.4336, -0.4578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8301, -0.5464, -0.5576,  ...,  0.0715,  0.1262, -0.3806],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2480, -0.0930,  0.2212,  ..., -1.1641, -0.5381, -0.5420],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:23:58 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:23:58 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 14:24:22 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 14:24:46 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 14:25:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2827e-03, -8.4937e-05, -7.0858e-04,  ..., -1.3638e-03,
         -5.5408e-04, -1.0128e-03],
        [-6.8426e-05, -3.4294e-03, -1.1545e-04,  ...,  4.9973e-04,
         -5.6362e-04,  3.9768e-04],
        [-2.0468e-04,  1.0109e-04, -3.4447e-03,  ...,  2.5725e-04,
          1.2314e-04, -8.8930e-05],
        ...,
        [-4.2152e-04,  1.4651e-04,  8.5592e-05,  ..., -2.6970e-03,
         -1.1082e-03, -2.8944e-04],
        [ 1.5771e-04,  8.4400e-04,  9.3269e-04,  ...,  8.1062e-05,
         -2.4948e-03,  2.0671e-04],
        [-6.4516e-04, -4.6158e-04,  7.9298e-04,  ...,  1.5295e-04,
          1.3590e-04, -2.9125e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0290,  0.0032, -0.0066,  ..., -0.0178,  0.0019,  0.0050],
        [ 0.0054, -0.0311, -0.0048,  ..., -0.0050, -0.0018, -0.0037],
        [-0.0051,  0.0017, -0.0236,  ..., -0.0046, -0.0081, -0.0088],
        ...,
        [ 0.0035,  0.0077,  0.0072,  ..., -0.0384, -0.0017, -0.0135],
        [ 0.0035, -0.0087,  0.0049,  ..., -0.0059, -0.0197, -0.0033],
        [ 0.0052, -0.0033, -0.0074,  ..., -0.0227, -0.0028, -0.0464]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.0455e-02,  8.9645e-05, -3.3398e-03,  ...,  7.4196e-03,
          4.6844e-03,  7.9632e-04],
        [-1.2388e-03, -6.3354e-02, -3.2520e-03,  ..., -1.1005e-03,
         -1.4305e-03, -3.7899e-03],
        [ 7.8344e-04,  2.6875e-03, -6.0211e-02,  ...,  2.9049e-03,
          2.8057e-03, -5.2738e-04],
        ...,
        [ 2.6569e-03, -5.1537e-03,  1.3781e-03,  ..., -5.8380e-02,
         -6.8474e-03, -9.2392e-03],
        [-7.3242e-03, -5.8403e-03,  3.6316e-03,  ..., -6.0768e-03,
         -6.1646e-02,  4.8904e-03],
        [ 2.6360e-03, -1.2512e-02,  6.5842e-03,  ...,  3.4065e-03,
          1.3790e-03, -5.2887e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:25:12 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 14:25:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5835, -0.0134, -0.1296,  ..., -0.3369,  0.2678,  0.0979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7808,  0.1188, -0.4031,  ..., -0.7446, -0.6094, -0.7910],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1680, -1.3945, -1.0752,  ...,  0.2620,  0.4197,  0.2825],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3286,  0.3999,  0.0881,  ..., -0.8608, -0.6729, -0.7881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:25:12 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:25:12 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 14:25:37 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 14:26:02 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 14:26:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8229e-03, -1.7571e-04, -1.1981e-04,  ...,  2.2542e-04,
         -3.8552e-04,  6.3515e-04],
        [ 3.2246e-05, -2.1858e-03, -1.8358e-05,  ...,  3.7479e-04,
         -1.2684e-04,  1.3447e-04],
        [-2.5094e-05,  1.7405e-04, -2.7485e-03,  ...,  7.1526e-06,
          5.9891e-04, -2.6631e-04],
        ...,
        [ 1.1313e-04,  3.5095e-04, -3.8862e-05,  ..., -2.1076e-03,
          4.6134e-04, -3.0565e-04],
        [ 5.4419e-05,  2.3091e-04, -1.7834e-04,  ...,  1.0788e-04,
         -2.2202e-03, -5.7936e-04],
        [ 3.5191e-04, -1.1247e-04,  3.4595e-04,  ..., -1.7440e-04,
         -2.7275e-04, -1.7414e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0219, -0.0048,  0.0065,  ...,  0.0114,  0.0026, -0.0063],
        [ 0.0073, -0.0300, -0.0011,  ...,  0.0050,  0.0043, -0.0067],
        [-0.0010, -0.0016, -0.0348,  ..., -0.0099,  0.0006, -0.0136],
        ...,
        [-0.0022, -0.0066,  0.0054,  ..., -0.0260,  0.0045,  0.0203],
        [-0.0019, -0.0010, -0.0081,  ...,  0.0042, -0.0226,  0.0093],
        [ 0.0007,  0.0019,  0.0048,  ...,  0.0152, -0.0097, -0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0283,  0.0010, -0.0037,  ...,  0.0024,  0.0019,  0.0065],
        [-0.0024, -0.0327, -0.0007,  ...,  0.0073,  0.0035,  0.0014],
        [ 0.0008, -0.0007, -0.0351,  ..., -0.0024, -0.0032, -0.0037],
        ...,
        [ 0.0012,  0.0023, -0.0014,  ..., -0.0299, -0.0061,  0.0032],
        [-0.0016,  0.0027, -0.0020,  ..., -0.0052, -0.0298,  0.0089],
        [ 0.0023,  0.0051,  0.0022,  ..., -0.0053,  0.0017, -0.0298]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:26:30 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 14:26:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9561, -0.6709, -0.6313,  ...,  0.0844,  0.1262, -0.4917],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3816, -0.1565,  0.3176,  ..., -1.5957, -0.7720, -0.8359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8398, -1.3633, -1.4531,  ...,  0.8271,  0.4551,  0.9844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1648,  0.6211, -0.3450,  ..., -0.9985, -0.3970, -0.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:26:30 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:26:30 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 14:27:00 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 14:27:27 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 14:27:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.8501e-03, -4.2629e-04, -3.9864e-04,  ..., -3.8719e-04,
          7.1287e-04, -3.3379e-05],
        [ 1.5473e-04, -1.7319e-03,  1.9789e-05,  ..., -3.9625e-04,
          5.9700e-04, -9.1791e-04],
        [-5.7888e-04, -1.1259e-04, -1.2922e-03,  ...,  4.3297e-04,
          4.5371e-04, -4.0412e-04],
        ...,
        [ 1.9741e-04, -3.3617e-04, -1.3876e-03,  ..., -1.7920e-03,
         -5.4502e-04, -8.9169e-04],
        [-5.3692e-04, -6.3133e-04,  1.2022e-04,  ..., -6.9046e-04,
         -1.7681e-03,  8.9824e-05],
        [ 2.2817e-04,  3.7014e-05,  2.8944e-04,  ..., -5.0640e-04,
         -1.7571e-04, -2.6360e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.4525e-02, -4.2648e-03, -4.4708e-03,  ..., -3.1357e-03,
          3.3951e-03,  2.0142e-03],
        [-3.4962e-03, -4.2725e-02, -6.2943e-05,  ...,  1.3374e-02,
          6.3858e-03,  2.3670e-03],
        [ 1.3752e-03, -1.6281e-02, -2.8366e-02,  ...,  6.7978e-03,
          8.6117e-04, -7.5760e-03],
        ...,
        [-5.9280e-03,  8.9874e-03, -9.7733e-03,  ..., -4.1901e-02,
         -8.8787e-04,  1.2627e-02],
        [-1.3580e-02,  5.7650e-04, -7.0000e-03,  ...,  4.5090e-03,
         -3.5492e-02, -9.1934e-03],
        [-8.2207e-04, -3.3913e-03, -1.9264e-03,  ..., -3.2749e-03,
          6.6986e-03, -3.7231e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.5969e-02,  2.1458e-03,  2.1648e-03,  ..., -3.4370e-03,
          8.3771e-03, -7.8735e-03],
        [ 5.3291e-03, -4.6631e-02, -8.4686e-04,  ...,  2.9526e-03,
          8.7452e-04, -6.8665e-05],
        [-6.1989e-04, -5.9891e-03, -3.7842e-02,  ...,  4.5776e-03,
         -1.2484e-03, -9.3031e-04],
        ...,
        [-4.0627e-03, -8.5449e-03,  1.5831e-03,  ..., -5.9601e-02,
          6.9141e-04, -1.1223e-02],
        [-1.7309e-04,  4.0359e-03, -1.1482e-02,  ..., -5.8365e-03,
         -4.0436e-02, -7.5226e-03],
        [-1.9627e-03, -1.2922e-03,  2.1458e-04,  ..., -4.7379e-03,
         -1.8730e-03, -5.1056e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:27:59 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 14:27:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0850, -1.4209, -0.9746,  ...,  0.2250,  0.4348,  0.2377],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3462,  0.3862,  0.0954,  ..., -0.8408, -0.6631, -0.8779],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2822, -1.5479, -1.2266,  ...,  1.2959,  0.1978,  0.7100],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1219,  0.0811, -0.0356,  ..., -0.7646, -0.4463, -0.5405],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:27:59 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:27:59 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 14:28:28 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 14:29:00 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 14:29:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.9618e-04,  1.6899e-03, -2.6531e-03,  ...,  7.8344e-04,
          9.7513e-05, -8.7595e-04],
        [ 1.5175e-04, -4.0436e-04,  2.2256e-04,  ...,  5.5742e-04,
         -6.3896e-04, -3.8052e-04],
        [ 2.2240e-03,  9.7132e-04, -2.3689e-03,  ..., -1.5965e-03,
          5.7077e-04,  1.7118e-03],
        ...,
        [-7.0238e-04,  7.4387e-04, -2.7132e-04,  ..., -2.5501e-03,
         -1.2341e-03,  2.0256e-03],
        [ 9.1887e-04,  4.0340e-04, -1.9493e-03,  ..., -1.2150e-03,
         -8.1420e-05,  7.9489e-04],
        [-2.4700e-04, -6.0749e-04, -3.9864e-04,  ..., -5.9068e-05,
         -2.7037e-04, -2.0905e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0822,  0.0043,  0.0069,  ...,  0.0064, -0.0028, -0.0134],
        [ 0.0030, -0.0803,  0.0077,  ..., -0.0011,  0.0053,  0.0078],
        [ 0.0001, -0.0020, -0.0875,  ..., -0.0066,  0.0094, -0.0040],
        ...,
        [ 0.0061,  0.0030, -0.0126,  ..., -0.0636,  0.0021, -0.0025],
        [ 0.0005, -0.0006, -0.0085,  ...,  0.0011, -0.0871,  0.0093],
        [-0.0067, -0.0076,  0.0083,  ...,  0.0061, -0.0075, -0.0893]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0638e-01, -8.5831e-05,  1.3504e-02,  ..., -5.5456e-04,
          3.5977e-04, -6.3782e-03],
        [ 1.8902e-03, -1.1505e-01,  4.9133e-03,  ..., -2.7676e-03,
         -8.0948e-03, -6.9199e-03],
        [ 2.4128e-03,  4.7607e-03, -1.1359e-01,  ...,  3.3073e-03,
          5.3596e-03, -4.1199e-04],
        ...,
        [-1.2379e-03,  1.4725e-03,  2.5520e-03,  ..., -1.0034e-01,
          9.8572e-03,  1.6861e-03],
        [-3.2806e-04,  1.0328e-03,  3.9291e-03,  ..., -3.1128e-03,
         -1.0571e-01,  5.2719e-03],
        [-3.5763e-03, -2.4452e-03, -3.0899e-03,  ..., -4.1428e-03,
          6.7940e-03, -1.1072e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:29:34 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 14:29:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7036, -1.1885, -1.1738,  ...,  0.6709,  0.3596,  0.8213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1815,  0.6899, -0.3704,  ..., -1.0479, -0.4460, -0.5142],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0559, -1.4883, -1.4609,  ...,  1.3350,  0.1523,  0.4819],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4873,  0.0978, -0.1698,  ..., -0.1685, -0.6758, -0.5430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:29:34 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:29:35 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 14:30:10 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 14:30:46 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 14:31:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5726e-03, -2.1057e-03,  2.1095e-03,  ...,  5.4932e-04,
          1.7679e-04, -5.4359e-04],
        [-6.1226e-04, -1.0586e-03,  2.0027e-03,  ..., -7.7105e-04,
          1.8654e-03,  2.0695e-04],
        [-2.2721e-04,  4.8065e-04, -3.8872e-03,  ..., -8.3876e-04,
         -2.3937e-04, -2.2449e-03],
        ...,
        [ 3.7980e-04,  8.5831e-04,  7.1716e-04,  ..., -2.3651e-03,
         -4.7493e-04,  1.4305e-06],
        [ 1.2350e-03, -1.1463e-03, -1.2255e-03,  ..., -1.5364e-03,
         -1.6558e-04, -2.0866e-03],
        [-2.1875e-04,  1.7166e-03,  8.8596e-04,  ..., -2.1601e-04,
         -1.0481e-03,  1.5364e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0859, -0.0075,  0.0077,  ...,  0.0084,  0.0013, -0.0007],
        [-0.0087, -0.0897,  0.0119,  ..., -0.0107,  0.0003, -0.0048],
        [ 0.0087,  0.0056, -0.0911,  ..., -0.0108,  0.0073, -0.0096],
        ...,
        [ 0.0072,  0.0077,  0.0002,  ..., -0.0817,  0.0057,  0.0014],
        [-0.0012, -0.0160, -0.0067,  ..., -0.0083, -0.0781, -0.0038],
        [ 0.0054,  0.0072,  0.0084,  ..., -0.0101, -0.0037, -0.0924]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1050,  0.0095, -0.0049,  ...,  0.0018,  0.0029, -0.0012],
        [ 0.0001, -0.1096, -0.0075,  ...,  0.0013, -0.0002,  0.0044],
        [ 0.0035,  0.0004, -0.0962,  ..., -0.0040,  0.0094, -0.0018],
        ...,
        [ 0.0003, -0.0045,  0.0007,  ..., -0.0982, -0.0081, -0.0063],
        [ 0.0037,  0.0050, -0.0029,  ...,  0.0010, -0.0991,  0.0014],
        [-0.0030, -0.0008, -0.0035,  ..., -0.0117, -0.0030, -0.1006]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:31:25 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 14:31:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2214, -1.2588, -0.9390,  ...,  0.9438,  0.1499,  0.5444],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1215,  0.0964, -0.0488,  ..., -0.7334, -0.4382, -0.5811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8076, -1.3760, -1.9180,  ...,  1.3330,  0.7520,  0.7148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2690,  0.0150, -0.1913,  ..., -0.5664, -0.6143, -0.9365],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:31:25 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:31:25 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 14:32:01 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 14:32:38 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 14:33:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6270e-03,  1.4362e-03, -9.3174e-04,  ...,  1.4229e-03,
         -4.9353e-04, -2.4033e-04],
        [ 2.2411e-04, -1.1692e-03, -2.2960e-04,  ...,  1.0748e-03,
          6.9904e-04,  9.9659e-05],
        [ 5.9700e-04, -9.0599e-04, -3.5934e-03,  ..., -2.0447e-03,
          1.6367e-04, -1.6508e-03],
        ...,
        [-7.0143e-04, -2.5330e-03,  5.9986e-04,  ..., -2.0103e-03,
          5.7840e-04,  1.1120e-03],
        [-2.3842e-06,  2.5702e-04, -2.3003e-03,  ...,  2.8324e-03,
         -1.1196e-03, -7.1335e-04],
        [ 1.5726e-03, -1.5717e-03, -7.7057e-04,  ..., -2.8896e-04,
          4.9686e-04, -2.4090e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0923,  0.0149, -0.0011,  ..., -0.0128, -0.0032,  0.0072],
        [ 0.0094, -0.0783, -0.0015,  ..., -0.0023,  0.0188, -0.0009],
        [-0.0010,  0.0037, -0.0750,  ...,  0.0138, -0.0141,  0.0004],
        ...,
        [ 0.0013, -0.0015,  0.0165,  ..., -0.0798, -0.0115,  0.0024],
        [-0.0004,  0.0041, -0.0030,  ...,  0.0030, -0.0807, -0.0068],
        [ 0.0098,  0.0052,  0.0095,  ..., -0.0066, -0.0011, -0.0795]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0913e-01, -9.6321e-05,  3.6221e-03,  ..., -1.2177e-02,
         -1.9165e-02,  2.1696e-04],
        [ 3.7079e-03, -9.4666e-02, -1.4374e-02,  ...,  8.3389e-03,
          3.9978e-03, -2.9335e-03],
        [-5.1880e-03, -5.5122e-03, -9.3567e-02,  ..., -6.5193e-03,
          1.6174e-03, -3.7956e-04],
        ...,
        [ 2.0237e-03, -4.0321e-03,  5.4321e-03,  ..., -1.0400e-01,
          1.0651e-02, -5.7564e-03],
        [-1.1406e-03,  3.8929e-03,  1.8473e-03,  ...,  1.3756e-02,
         -1.0748e-01, -6.3324e-03],
        [ 8.9645e-05, -7.3929e-03,  9.8724e-03,  ...,  6.5994e-03,
         -1.0986e-03, -9.7412e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:33:16 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 14:33:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0447, -1.1465, -1.0361,  ...,  0.9141,  0.1020,  0.3416],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4866,  0.0942, -0.1713,  ..., -0.1582, -0.6641, -0.5762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8496, -1.1504, -1.8701,  ...,  1.2588,  0.6099,  0.5034],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0669, -0.4678, -0.5229,  ..., -0.6318, -0.6514, -0.4683],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:33:16 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:33:16 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 14:33:56 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 14:34:33 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 14:35:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.1689e-03,  1.7285e-04, -1.5659e-03,  ...,  5.0049e-03,
         -1.4353e-03, -3.1776e-03],
        [-1.4935e-03, -2.1954e-03,  1.7166e-03,  ..., -4.8828e-03,
          3.8147e-04, -3.4580e-03],
        [-1.2197e-03,  7.8106e-04, -9.8801e-04,  ...,  2.3384e-03,
          4.3058e-04, -1.0357e-03],
        ...,
        [-8.8692e-04,  8.5258e-04, -1.3332e-03,  ...,  5.0068e-04,
          2.8095e-03,  1.6155e-03],
        [ 1.2035e-03, -1.7071e-03, -2.2411e-05,  ..., -7.5197e-04,
         -4.6234e-03,  5.4932e-04],
        [ 3.9139e-03,  1.9035e-03, -4.9829e-04,  ...,  1.6499e-04,
         -1.1196e-03,  1.2093e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0828, -0.0039, -0.0009,  ..., -0.0175, -0.0011,  0.0128],
        [ 0.0025, -0.1036,  0.0021,  ..., -0.0102, -0.0013, -0.0012],
        [-0.0052,  0.0159, -0.0859,  ...,  0.0010,  0.0004,  0.0084],
        ...,
        [-0.0035, -0.0042, -0.0020,  ..., -0.0863,  0.0064, -0.0043],
        [-0.0060,  0.0043, -0.0054,  ..., -0.0042, -0.0854,  0.0220],
        [-0.0021,  0.0083, -0.0025,  ..., -0.0030,  0.0095, -0.0979]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1006,  0.0072,  0.0037,  ..., -0.0018,  0.0056,  0.0023],
        [ 0.0066, -0.1090,  0.0069,  ..., -0.0086, -0.0060,  0.0109],
        [-0.0065,  0.0006, -0.1006,  ..., -0.0055, -0.0088,  0.0101],
        ...,
        [-0.0011,  0.0002, -0.0090,  ..., -0.1010, -0.0053, -0.0029],
        [-0.0048,  0.0004, -0.0060,  ..., -0.0002, -0.1062,  0.0069],
        [ 0.0059,  0.0077, -0.0152,  ...,  0.0080,  0.0107, -0.1093]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:35:09 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 14:35:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5127, -0.9248, -1.2529,  ...,  0.7983,  0.4624,  0.4612],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2576,  0.0116, -0.2120,  ..., -0.4897, -0.5439, -0.8662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2441, -0.6758, -1.5146,  ...,  1.7363,  0.8037, -0.3110],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1074, -0.3132, -0.4111,  ..., -0.9233, -0.6318, -0.7070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:35:09 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:35:09 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 14:35:57 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 14:36:44 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 14:37:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0014,  0.0022,  0.0004,  ..., -0.0050, -0.0006, -0.0031],
        [ 0.0023, -0.0013,  0.0016,  ..., -0.0006, -0.0010,  0.0024],
        [-0.0019,  0.0018,  0.0017,  ..., -0.0009,  0.0028,  0.0003],
        ...,
        [-0.0022, -0.0033, -0.0005,  ...,  0.0019, -0.0026, -0.0020],
        [-0.0040, -0.0021,  0.0038,  ...,  0.0002, -0.0007,  0.0014],
        [ 0.0009, -0.0023, -0.0004,  ..., -0.0022, -0.0012,  0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1060e-01, -7.6065e-03,  3.7994e-03,  ..., -3.3951e-03,
          4.3755e-03, -1.4200e-03],
        [ 1.0061e-04, -1.0150e-01, -3.6926e-03,  ..., -4.6082e-03,
         -5.2643e-03, -1.7834e-03],
        [-1.4297e-02, -8.7280e-03, -9.7229e-02,  ...,  2.4166e-03,
         -3.7136e-03, -9.0179e-03],
        ...,
        [-1.7052e-03,  1.0170e-02,  1.3077e-02,  ..., -9.8022e-02,
          7.1526e-04, -9.2316e-03],
        [ 1.3618e-02, -4.3793e-03,  1.7548e-03,  ...,  8.2245e-03,
         -1.0803e-01, -3.7956e-04],
        [ 1.2274e-03, -5.0125e-03,  4.2343e-04,  ..., -8.3733e-04,
          8.5449e-03, -9.4727e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.7371e-01, -9.5654e-04,  8.8806e-03,  ...,  3.3283e-04,
         -1.6434e-02,  7.9880e-03],
        [-3.9787e-03, -1.7627e-01, -3.1357e-03,  ...,  2.5616e-03,
         -2.6131e-03,  4.3488e-03],
        [-9.8419e-03, -6.2866e-03, -1.6687e-01,  ..., -3.1910e-03,
         -6.1951e-03, -9.6588e-03],
        ...,
        [-1.0376e-02,  1.3535e-02,  4.1504e-03,  ..., -1.5649e-01,
         -1.5259e-04,  1.9398e-03],
        [-2.0523e-03,  6.0654e-03,  1.0204e-03,  ..., -3.5954e-03,
         -1.7993e-01, -3.9215e-03],
        [-6.9199e-03,  1.6308e-03, -3.1967e-03,  ..., -7.0114e-03,
         -1.5076e-02, -1.5186e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:37:30 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 14:37:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5327, -0.7368, -1.1445,  ...,  0.7471,  0.3538,  0.2747],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0486, -0.3970, -0.4402,  ..., -0.4714, -0.5288, -0.4272],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2979, -0.5703, -1.0283,  ...,  1.1191,  0.4653,  0.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0877, -0.1992, -0.2200,  ..., -0.3716, -1.1201, -0.1875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:37:30 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:37:30 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 14:38:23 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 14:39:14 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 14:40:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.2166e-04, -9.4223e-04, -2.4185e-03,  ..., -2.0504e-04,
          1.8120e-03,  2.0194e-04],
        [-1.5106e-03,  2.0275e-03,  5.3501e-04,  ...,  6.6376e-04,
          4.1771e-04,  6.2466e-04],
        [ 2.0924e-03,  8.3208e-04, -3.5114e-03,  ...,  1.0815e-03,
         -3.5172e-03, -4.9472e-05],
        ...,
        [-1.2531e-03, -1.9531e-03,  3.0289e-03,  ..., -3.6678e-03,
          5.2071e-04, -1.6356e-03],
        [ 2.4128e-03, -3.5381e-03, -3.4046e-04,  ...,  2.3499e-03,
         -1.0529e-03,  2.3060e-03],
        [-1.5421e-03, -5.6744e-04, -3.4943e-03,  ...,  1.0881e-03,
          3.4924e-03, -2.0542e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1172,  0.0009, -0.0045,  ..., -0.0074,  0.0206,  0.0019],
        [ 0.0135, -0.1072,  0.0038,  ..., -0.0012, -0.0197,  0.0019],
        [-0.0010, -0.0060, -0.0996,  ..., -0.0020,  0.0064, -0.0017],
        ...,
        [ 0.0039,  0.0042,  0.0079,  ..., -0.1053,  0.0087,  0.0009],
        [ 0.0139, -0.0089, -0.0090,  ...,  0.0129, -0.1049,  0.0183],
        [ 0.0018,  0.0200, -0.0085,  ..., -0.0137,  0.0026, -0.1034]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1103,  0.0152, -0.0054,  ...,  0.0093,  0.0040, -0.0089],
        [ 0.0124, -0.1164,  0.0063,  ...,  0.0056, -0.0043, -0.0030],
        [ 0.0050, -0.0029, -0.1273,  ...,  0.0020,  0.0079,  0.0041],
        ...,
        [-0.0028, -0.0011,  0.0122,  ..., -0.1161,  0.0149, -0.0052],
        [-0.0019, -0.0022, -0.0007,  ...,  0.0010, -0.1216,  0.0189],
        [-0.0006, -0.0006,  0.0009,  ..., -0.0050, -0.0132, -0.1082]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:40:06 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 14:40:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7085, -0.4189, -0.8750,  ...,  0.9199,  0.4319, -0.1815],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0914, -0.2505, -0.3271,  ..., -0.6689, -0.4673, -0.5190],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1191, -0.6797, -1.0088,  ...,  2.0352,  0.4468,  0.7622],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4709, -0.2852, -0.0935,  ..., -0.6162, -0.6108, -0.1172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:40:06 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:40:06 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 14:40:57 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 14:41:50 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 14:42:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0150, -0.0013,  0.0005,  ..., -0.0019,  0.0002,  0.0057],
        [-0.0037,  0.0088,  0.0011,  ...,  0.0014,  0.0007,  0.0007],
        [-0.0028, -0.0052,  0.0078,  ..., -0.0035,  0.0037,  0.0028],
        ...,
        [ 0.0037,  0.0040,  0.0004,  ...,  0.0152, -0.0060,  0.0035],
        [-0.0037, -0.0023,  0.0021,  ..., -0.0023,  0.0107, -0.0008],
        [ 0.0036, -0.0003, -0.0006,  ...,  0.0013, -0.0020,  0.0081]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1554, -0.0028,  0.0081,  ...,  0.0014, -0.0017, -0.0143],
        [-0.0017, -0.1555,  0.0110,  ...,  0.0129,  0.0081, -0.0060],
        [-0.0038, -0.0036, -0.1545,  ...,  0.0082, -0.0052, -0.0029],
        ...,
        [-0.0008, -0.0068,  0.0094,  ..., -0.1473, -0.0068, -0.0046],
        [-0.0073, -0.0119, -0.0024,  ...,  0.0063, -0.1427, -0.0042],
        [-0.0059, -0.0181, -0.0061,  ..., -0.0077,  0.0133, -0.1570]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2384,  0.0060,  0.0003,  ..., -0.0134, -0.0018, -0.0089],
        [ 0.0099, -0.2532, -0.0012,  ..., -0.0048,  0.0052,  0.0065],
        [-0.0008,  0.0150, -0.2302,  ...,  0.0087, -0.0084, -0.0175],
        ...,
        [-0.0114,  0.0021, -0.0095,  ..., -0.2571,  0.0147,  0.0159],
        [-0.0079, -0.0033, -0.0069,  ...,  0.0078, -0.2384, -0.0035],
        [-0.0101, -0.0175, -0.0116,  ..., -0.0057, -0.0039, -0.2617]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:42:36 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 14:42:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7295, -0.3486, -0.6172,  ...,  0.6318,  0.2583, -0.0192],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0397, -0.1688, -0.2100,  ..., -0.2834, -0.8594, -0.2018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9434, -1.1006, -0.5601,  ...,  2.2871,  0.2430,  0.5527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.3174, -0.8022, -0.2134,  ..., -0.2070, -0.0918, -0.9448],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:42:36 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:42:36 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 14:43:27 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 14:44:23 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 14:45:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.0278e-03,  6.3820e-03,  5.2109e-03,  ..., -7.2861e-04,
         -7.1526e-06, -3.0823e-03],
        [ 2.1324e-03, -5.9090e-03, -2.6779e-03,  ..., -2.1343e-03,
         -9.8109e-05, -2.6360e-03],
        [ 8.2626e-03, -4.8494e-04, -8.1940e-03,  ..., -7.1573e-04,
         -4.2267e-03, -3.2921e-03],
        ...,
        [-2.0480e-04,  8.6975e-04,  1.1015e-03,  ..., -3.7918e-03,
          1.1444e-04,  1.8797e-03],
        [-3.7746e-03,  3.9825e-03,  1.4992e-03,  ..., -7.7772e-04,
         -9.2697e-03,  2.5024e-03],
        [-7.8106e-04,  5.7411e-04, -1.0586e-04,  ...,  4.6134e-04,
          5.0449e-04, -4.1771e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1015,  0.0072,  0.0076,  ...,  0.0011, -0.0002,  0.0010],
        [ 0.0124, -0.0928, -0.0023,  ...,  0.0011,  0.0041, -0.0019],
        [ 0.0033,  0.0013, -0.0934,  ..., -0.0045, -0.0058, -0.0041],
        ...,
        [-0.0041,  0.0066,  0.0066,  ..., -0.0859,  0.0047, -0.0030],
        [ 0.0067,  0.0024, -0.0028,  ..., -0.0002, -0.0912,  0.0106],
        [ 0.0098, -0.0005,  0.0084,  ...,  0.0087, -0.0072, -0.0888]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0941, -0.0030,  0.0043,  ...,  0.0073, -0.0084,  0.0055],
        [ 0.0018, -0.1133,  0.0017,  ..., -0.0059,  0.0062,  0.0032],
        [-0.0023, -0.0082, -0.0976,  ..., -0.0060, -0.0059,  0.0147],
        ...,
        [ 0.0027, -0.0049,  0.0028,  ..., -0.0842,  0.0047, -0.0106],
        [-0.0033,  0.0011, -0.0075,  ...,  0.0044, -0.0946,  0.0015],
        [-0.0046,  0.0080,  0.0108,  ...,  0.0078, -0.0110, -0.0740]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:45:24 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 14:45:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6323, -0.4158, -0.5425,  ...,  1.0615,  0.2487,  0.4060],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3567, -0.2471, -0.0762,  ..., -0.4531, -0.4402, -0.1104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0977, -0.7427, -0.5391,  ...,  2.7051,  0.8662,  0.3188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1680, -0.8218, -0.5454,  ..., -0.3286,  0.0797, -0.8652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:45:24 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:45:24 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 14:46:18 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 14:47:15 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 14:48:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.5391e-02, -1.6174e-03, -6.6519e-05,  ...,  2.8591e-03,
          1.4009e-03, -3.1548e-03],
        [-5.6190e-03,  2.8137e-02, -3.0746e-03,  ..., -4.3726e-04,
          2.9335e-03, -1.9684e-03],
        [-4.8790e-03, -1.1320e-03,  2.7878e-02,  ..., -1.6785e-03,
          3.2845e-03, -2.9659e-03],
        ...,
        [ 2.1267e-03, -1.2579e-03,  8.5678e-03,  ...,  2.6962e-02,
         -1.0834e-02,  9.8419e-03],
        [ 3.5648e-03, -3.1815e-03,  7.6408e-03,  ..., -2.7771e-03,
          2.9907e-02,  9.1629e-03],
        [ 2.2831e-03, -1.7176e-03,  1.8139e-03,  ..., -1.1024e-02,
         -1.1047e-02,  2.1667e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0894, -0.0153, -0.0099,  ..., -0.0151,  0.0006,  0.0033],
        [ 0.0027, -0.1007,  0.0022,  ...,  0.0080, -0.0093,  0.0031],
        [ 0.0029, -0.0047, -0.0871,  ..., -0.0064,  0.0034, -0.0063],
        ...,
        [-0.0206,  0.0037,  0.0020,  ..., -0.1045, -0.0038, -0.0037],
        [-0.0044,  0.0012,  0.0075,  ...,  0.0047, -0.0947,  0.0084],
        [ 0.0103, -0.0071, -0.0011,  ..., -0.0210,  0.0084, -0.1046]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.7078e-01, -2.2888e-05,  3.6163e-03,  ..., -1.3336e-02,
          1.0483e-02,  3.9673e-03],
        [-9.2163e-03, -1.8518e-01,  9.7809e-03,  ...,  5.1117e-04,
          3.6278e-03,  1.2039e-02],
        [ 1.4858e-03,  1.8282e-03, -1.7297e-01,  ..., -1.6861e-02,
          2.8191e-03, -9.7427e-03],
        ...,
        [-9.3994e-03, -3.8090e-03, -9.4986e-03,  ..., -1.6980e-01,
          1.2459e-02, -5.3787e-03],
        [-2.9240e-03,  3.7003e-03,  3.6774e-03,  ..., -1.4963e-03,
         -1.7566e-01,  4.0131e-03],
        [ 6.4850e-03,  1.6281e-02, -9.0790e-04,  ..., -7.2403e-03,
          2.1500e-02, -1.6785e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:48:06 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 14:48:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4524, -0.5703, -0.2920,  ...,  1.1074,  0.1514,  0.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8218, -0.4946, -0.1453,  ..., -0.1365, -0.0255, -0.6304],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5801, -0.8438, -0.5117,  ...,  2.3711,  1.4756,  0.0083],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6035, -0.3755, -0.8726,  ..., -0.6309,  0.3208, -0.3787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:48:06 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:48:06 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 14:49:08 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 14:50:07 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 14:51:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.0327e-04, -8.9550e-04,  9.2602e-04,  ..., -2.8419e-03,
         -3.4351e-03,  7.8964e-04],
        [-9.6798e-04,  9.5177e-04, -1.6670e-03,  ..., -1.8969e-03,
          1.1911e-03, -3.2997e-04],
        [ 1.5879e-04, -2.2125e-03, -1.4248e-03,  ..., -1.6413e-03,
          3.6478e-05,  1.4105e-03],
        ...,
        [ 2.4300e-03,  2.7895e-04, -1.6556e-03,  ...,  8.1348e-04,
          1.2665e-03,  5.5981e-04],
        [-3.0518e-04, -8.0252e-04,  1.1759e-03,  ...,  2.6073e-03,
          4.6806e-03, -1.2503e-03],
        [ 3.7646e-04,  9.8991e-04,  1.6804e-03,  ..., -1.7872e-03,
         -1.9512e-03,  2.4719e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0989,  0.0044, -0.0109,  ..., -0.0004,  0.0094,  0.0034],
        [-0.0107, -0.1156, -0.0034,  ..., -0.0072,  0.0116,  0.0075],
        [-0.0064, -0.0035, -0.1021,  ...,  0.0026,  0.0037, -0.0162],
        ...,
        [-0.0061, -0.0072, -0.0022,  ..., -0.0972,  0.0016,  0.0055],
        [ 0.0105, -0.0015,  0.0083,  ...,  0.0161, -0.1007, -0.0013],
        [ 0.0025,  0.0131, -0.0170,  ..., -0.0009, -0.0020, -0.1176]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1272,  0.0087, -0.0039,  ..., -0.0136,  0.0020,  0.0029],
        [ 0.0047, -0.1232, -0.0003,  ...,  0.0068, -0.0016,  0.0138],
        [ 0.0026, -0.0021, -0.1225,  ...,  0.0049, -0.0017, -0.0049],
        ...,
        [ 0.0018, -0.0169,  0.0091,  ..., -0.1324,  0.0121, -0.0006],
        [-0.0045,  0.0058,  0.0012,  ...,  0.0050, -0.1168,  0.0040],
        [ 0.0022,  0.0028, -0.0063,  ...,  0.0025,  0.0004, -0.1338]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:51:11 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 14:51:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5405, -0.3955, -0.2482,  ...,  1.2695,  0.4214,  0.1225],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6948, -0.5073, -0.2966,  ..., -0.1960,  0.0519, -0.5371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2949, -1.0576,  0.2241,  ...,  1.9805,  1.5635,  0.2798],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.6719, -0.9678, -1.4141,  ..., -0.2546, -0.2964, -0.6992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:51:11 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:51:11 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 14:52:10 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 14:53:12 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 14:54:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6141e-04, -1.7195e-03,  7.0333e-05,  ...,  1.1311e-03,
         -6.5804e-03,  4.2081e-05],
        [ 5.8174e-03,  1.8966e-04, -3.9253e-03,  ..., -1.7672e-03,
         -2.0752e-03, -1.1635e-03],
        [ 5.0545e-03, -1.1959e-03,  1.1158e-04,  ..., -1.7700e-03,
         -3.4084e-03,  2.8193e-05],
        ...,
        [-4.5662e-03,  1.4663e-04, -3.4714e-03,  ...,  5.3215e-03,
         -8.8501e-03,  1.6079e-03],
        [ 1.2283e-02, -5.7449e-03,  2.1534e-03,  ..., -2.4490e-03,
          6.3934e-03, -3.9673e-03],
        [-8.5220e-03,  2.1172e-03,  3.2063e-03,  ..., -5.5122e-03,
         -6.9923e-03,  1.2367e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1097,  0.0109,  0.0120,  ..., -0.0041, -0.0120,  0.0177],
        [ 0.0092, -0.1182,  0.0072,  ...,  0.0037,  0.0102, -0.0026],
        [ 0.0098,  0.0119, -0.1067,  ...,  0.0004,  0.0001, -0.0078],
        ...,
        [ 0.0004, -0.0003, -0.0065,  ..., -0.1032,  0.0016,  0.0020],
        [-0.0056, -0.0135, -0.0075,  ...,  0.0103, -0.1083,  0.0158],
        [ 0.0106,  0.0077, -0.0021,  ..., -0.0036,  0.0121, -0.1119]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2561e-01,  3.8147e-06,  1.5602e-03,  ..., -1.5240e-03,
         -1.2627e-03,  4.2534e-04],
        [-2.9316e-03, -1.4624e-01,  5.8746e-04,  ..., -6.3782e-03,
          2.2221e-03, -9.3031e-04],
        [-6.9160e-03,  1.5144e-02, -1.3342e-01,  ..., -6.3438e-03,
         -3.1033e-03,  3.5515e-03],
        ...,
        [ 5.7144e-03, -4.6692e-03,  4.6768e-03,  ..., -1.3965e-01,
         -4.0627e-03, -6.2027e-03],
        [ 9.9182e-05, -2.5387e-03, -1.2535e-02,  ...,  9.9640e-03,
         -1.2585e-01,  1.5854e-02],
        [ 1.6113e-02, -8.1558e-03,  4.9210e-03,  ...,  8.3618e-03,
          9.7122e-03, -1.1987e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:54:18 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 14:54:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7520, -0.4214, -0.2585,  ...,  1.1494,  0.7275, -0.0240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3799, -0.2062, -0.4729,  ..., -0.3433,  0.1808, -0.2371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3162, -0.8838,  0.5957,  ...,  1.6289,  1.5967,  0.5986],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.1055, -1.4238, -0.9937,  ...,  0.8457,  0.1704, -0.2012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:54:18 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:54:18 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 14:55:21 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 14:56:24 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 14:57:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.2490e-03, -5.6572e-03,  4.3831e-03,  ...,  2.4452e-03,
          3.1700e-03, -7.1716e-03],
        [-2.5101e-03,  8.9569e-03,  6.1417e-03,  ...,  4.3411e-03,
          5.7068e-03,  1.0757e-03],
        [-7.6332e-03, -1.3542e-03,  2.9087e-05,  ...,  3.2597e-03,
          3.6001e-04, -3.2043e-03],
        ...,
        [ 1.5669e-03, -3.8967e-03, -5.1422e-03,  ...,  8.4686e-03,
         -9.6512e-03, -6.3057e-03],
        [-2.9373e-03,  2.5892e-04, -8.4381e-03,  ...,  6.6910e-03,
          3.3402e-04,  2.5678e-04],
        [ 8.5754e-03,  3.2787e-03,  3.8300e-03,  ..., -8.1482e-03,
          9.1324e-03, -7.9803e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0511,  0.0015, -0.0039,  ..., -0.0049, -0.0020, -0.0129],
        [-0.0162, -0.0657, -0.0065,  ...,  0.0116, -0.0071, -0.0009],
        [-0.0065, -0.0149, -0.0588,  ..., -0.0048, -0.0117, -0.0050],
        ...,
        [-0.0158,  0.0037, -0.0049,  ..., -0.0625,  0.0028, -0.0074],
        [ 0.0099,  0.0075, -0.0083,  ...,  0.0078, -0.0554, -0.0007],
        [ 0.0097,  0.0108,  0.0058,  ...,  0.0045, -0.0098, -0.0687]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0881,  0.0068, -0.0213,  ...,  0.0013,  0.0062, -0.0153],
        [ 0.0150, -0.0811,  0.0015,  ...,  0.0034, -0.0072, -0.0036],
        [ 0.0156, -0.0003, -0.0797,  ..., -0.0173, -0.0158, -0.0029],
        ...,
        [ 0.0004,  0.0049, -0.0025,  ..., -0.0908,  0.0073,  0.0030],
        [ 0.0184,  0.0017,  0.0042,  ...,  0.0176, -0.0968, -0.0114],
        [-0.0117,  0.0148,  0.0008,  ...,  0.0011, -0.0007, -0.0801]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 14:57:29 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 14:57:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1239, -0.4980,  0.0993,  ...,  0.8760,  0.7290,  0.0898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8418, -0.4807, -0.6587,  ..., -0.1242, -0.1305, -0.3777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0552, -1.0098,  1.4199,  ...,  1.7119,  2.2070,  1.1572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2773, -1.4385, -0.4780,  ...,  0.8037, -0.3726, -1.6221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 14:57:29 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 14:57:29 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 14:58:37 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 14:59:44 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 15:00:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.1395e-03, -3.3741e-03,  6.0463e-04,  ...,  1.2083e-03,
          1.6141e-04,  1.3361e-03],
        [-1.0386e-03, -4.1962e-03,  4.4584e-04,  ...,  2.7442e-04,
         -7.6246e-04, -2.0695e-03],
        [-1.2541e-03,  8.6737e-04, -3.9520e-03,  ..., -1.2522e-03,
          8.7619e-05, -1.4420e-03],
        ...,
        [-7.7868e-04, -9.4128e-04,  9.3508e-04,  ..., -2.2030e-03,
          1.6575e-03, -4.5037e-04],
        [ 1.8682e-03,  3.0785e-03, -4.0960e-04,  ..., -6.0892e-04,
         -4.6921e-03, -1.0405e-03],
        [ 3.6621e-04, -5.0354e-04, -6.7616e-04,  ..., -4.3821e-04,
         -8.9550e-04, -4.6234e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0775,  0.0085,  0.0163,  ..., -0.0042, -0.0067,  0.0037],
        [ 0.0061, -0.0786,  0.0012,  ..., -0.0095,  0.0157, -0.0087],
        [ 0.0061, -0.0021, -0.0765,  ..., -0.0051,  0.0029,  0.0064],
        ...,
        [ 0.0053, -0.0215,  0.0050,  ..., -0.0762,  0.0002, -0.0082],
        [ 0.0187, -0.0007, -0.0088,  ..., -0.0039, -0.0778, -0.0014],
        [ 0.0026,  0.0017, -0.0083,  ..., -0.0053, -0.0020, -0.0603]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0774,  0.0029,  0.0144,  ...,  0.0064, -0.0017,  0.0176],
        [-0.0042, -0.0873, -0.0126,  ..., -0.0042,  0.0044, -0.0211],
        [ 0.0083,  0.0116, -0.0958,  ...,  0.0011,  0.0030,  0.0003],
        ...,
        [-0.0171, -0.0213, -0.0125,  ..., -0.0899,  0.0068, -0.0106],
        [ 0.0007,  0.0074,  0.0109,  ..., -0.0037, -0.1074,  0.0002],
        [ 0.0119, -0.0034, -0.0044,  ..., -0.0024,  0.0004, -0.0850]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:00:51 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 15:00:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1268, -0.3975,  0.2507,  ...,  0.7319,  0.7427,  0.2325],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.0195, -0.6602, -0.4653,  ...,  0.3918,  0.0871, -0.1411],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3765, -1.4893,  1.5771,  ...,  1.1309,  1.5332,  1.9004],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1904, -1.4170, -0.5386,  ...,  0.5654, -0.8530, -1.7285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:00:52 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:00:52 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 15:01:59 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 15:03:08 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 15:04:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.8889e-04, -4.8518e-05, -1.8015e-03,  ...,  1.3571e-03,
          1.3971e-03, -1.1406e-03],
        [-2.3961e-04, -2.4486e-04,  3.9177e-03,  ..., -8.8835e-04,
         -4.8375e-04, -1.3933e-03],
        [ 2.6054e-03, -7.4005e-04, -2.4719e-03,  ...,  1.0796e-03,
         -5.3406e-04, -1.9388e-03],
        ...,
        [-1.5507e-03,  4.0483e-04,  1.9293e-03,  ...,  1.7471e-03,
         -1.1568e-03, -2.6016e-03],
        [ 7.0953e-04, -1.6775e-03,  1.1806e-03,  ..., -1.4410e-03,
          3.2616e-04, -7.8058e-04],
        [ 1.0628e-04, -1.3351e-04,  1.5259e-05,  ...,  8.0729e-04,
         -1.0662e-03, -1.0157e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0558,  0.0094, -0.0074,  ...,  0.0003, -0.0129, -0.0008],
        [ 0.0096, -0.0569, -0.0107,  ..., -0.0048, -0.0008,  0.0041],
        [ 0.0066,  0.0115, -0.0662,  ..., -0.0004,  0.0080, -0.0057],
        ...,
        [-0.0065,  0.0078, -0.0057,  ..., -0.0538, -0.0110,  0.0095],
        [ 0.0058, -0.0057, -0.0033,  ...,  0.0035, -0.0480,  0.0061],
        [-0.0088,  0.0081,  0.0007,  ...,  0.0003,  0.0033, -0.0591]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0911,  0.0187, -0.0120,  ..., -0.0080, -0.0141,  0.0070],
        [ 0.0199, -0.1107,  0.0025,  ...,  0.0077,  0.0004,  0.0151],
        [ 0.0126, -0.0022, -0.0955,  ..., -0.0040,  0.0072, -0.0054],
        ...,
        [ 0.0047, -0.0024,  0.0046,  ..., -0.0923,  0.0097,  0.0003],
        [-0.0089, -0.0089, -0.0289,  ..., -0.0158, -0.0911,  0.0006],
        [-0.0032,  0.0099, -0.0164,  ...,  0.0053, -0.0047, -0.0971]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:04:20 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 15:04:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0191, -0.4448,  0.5742,  ...,  0.7290,  0.9810,  0.4666],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6196, -0.6816, -0.2379,  ...,  0.3699, -0.1522, -0.8218],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3887, -0.3955,  1.8643,  ...,  1.6924,  1.5117,  1.6875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.8438, -1.9463,  1.2148,  ...,  0.5146, -0.7021, -0.8755],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:04:20 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:04:21 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 15:05:31 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 15:06:43 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 15:07:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0101,  0.0020,  0.0042,  ...,  0.0052, -0.0072, -0.0118],
        [ 0.0021,  0.0134, -0.0072,  ...,  0.0079,  0.0003,  0.0018],
        [-0.0004,  0.0034,  0.0150,  ..., -0.0138, -0.0009,  0.0034],
        ...,
        [-0.0007, -0.0014, -0.0077,  ...,  0.0156,  0.0006, -0.0012],
        [ 0.0033, -0.0070, -0.0028,  ...,  0.0108,  0.0218,  0.0063],
        [-0.0018, -0.0013,  0.0038,  ..., -0.0049, -0.0048,  0.0189]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.1250e-02, -1.1482e-03,  1.2161e-02,  ..., -4.7379e-03,
          1.6235e-02,  6.9122e-03],
        [ 4.3640e-03, -1.5396e-02,  1.0147e-02,  ..., -2.2621e-03,
          9.8801e-04, -8.8425e-03],
        [-1.3161e-03, -2.7122e-03, -1.1887e-02,  ...,  6.5231e-03,
         -2.1530e-02,  9.1248e-03],
        ...,
        [-3.0766e-03, -1.7532e-02, -3.2806e-03,  ..., -2.8961e-02,
         -7.5073e-03, -9.6741e-03],
        [-4.5180e-05, -1.6403e-03,  7.8583e-03,  ...,  3.1128e-03,
         -2.8244e-02,  7.2861e-03],
        [-1.5381e-02,  7.4005e-03,  5.2147e-03,  ...,  2.5177e-04,
          4.0588e-03, -2.8793e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0436,  0.0015,  0.0076,  ..., -0.0235,  0.0038, -0.0179],
        [-0.0077, -0.0381,  0.0108,  ...,  0.0164, -0.0055,  0.0026],
        [-0.0052,  0.0148, -0.0499,  ..., -0.0010,  0.0100,  0.0092],
        ...,
        [-0.0130,  0.0135, -0.0087,  ..., -0.0462, -0.0143, -0.0194],
        [-0.0066,  0.0098, -0.0075,  ..., -0.0022, -0.0439,  0.0131],
        [ 0.0006, -0.0055,  0.0125,  ..., -0.0151,  0.0115, -0.0516]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:07:56 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 15:07:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1515, -0.6035,  0.5781,  ...,  0.4434,  0.5918,  0.7285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5244, -0.6270, -0.2417,  ...,  0.2428, -0.3672, -0.7881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6621, -0.7705,  1.9375,  ...,  1.2705,  0.4209,  0.7207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0225, -1.2871,  0.1562,  ..., -0.1348, -0.8398, -1.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:07:56 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:07:56 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 15:09:07 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 15:10:21 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 15:11:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3103e-03, -4.9067e-04, -1.4448e-03,  ...,  9.9945e-04,
          3.8505e-05,  1.3323e-03],
        [-1.0147e-03, -2.5940e-04, -1.5240e-03,  ..., -1.4000e-03,
         -1.8482e-03,  2.2736e-03],
        [-8.1778e-04, -3.4809e-04, -8.4162e-04,  ..., -5.8365e-04,
          3.8481e-04, -1.1292e-03],
        ...,
        [ 1.3375e-04, -1.6699e-03,  3.3092e-04,  ..., -1.9312e-03,
         -4.0472e-05, -1.2712e-03],
        [-1.6584e-03,  1.3008e-03,  1.3475e-03,  ...,  2.5225e-04,
          4.0722e-04, -1.6594e-03],
        [-1.1110e-03, -6.3658e-05, -9.4032e-04,  ...,  4.3917e-04,
         -1.1551e-04,  8.1730e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0057, -0.0060,  0.0020,  ...,  0.0061, -0.0100, -0.0006],
        [-0.0014, -0.0231, -0.0133,  ...,  0.0136,  0.0072, -0.0140],
        [-0.0124,  0.0043, -0.0250,  ...,  0.0046,  0.0050, -0.0050],
        ...,
        [-0.0093, -0.0062, -0.0068,  ..., -0.0083, -0.0070, -0.0176],
        [ 0.0122,  0.0012, -0.0063,  ..., -0.0051, -0.0194,  0.0088],
        [-0.0157,  0.0025, -0.0104,  ...,  0.0063,  0.0113, -0.0227]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0359,  0.0022,  0.0062,  ...,  0.0152, -0.0060,  0.0132],
        [-0.0142, -0.0540, -0.0065,  ...,  0.0163, -0.0054,  0.0057],
        [-0.0145, -0.0054, -0.0670,  ...,  0.0017,  0.0005, -0.0144],
        ...,
        [-0.0023, -0.0009, -0.0077,  ..., -0.0315, -0.0064, -0.0081],
        [ 0.0160,  0.0014, -0.0010,  ...,  0.0185, -0.0496,  0.0070],
        [-0.0069, -0.0042,  0.0084,  ...,  0.0015,  0.0103, -0.0627]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:11:37 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 15:11:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5181, -0.1576,  0.6753,  ...,  0.6133,  0.5669,  0.6055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7949, -0.8457,  0.5020,  ...,  0.2051, -0.2910, -0.4033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0664, -0.6055,  2.2617,  ...,  1.3945,  0.2344,  1.2754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9219, -0.6450,  0.3794,  ...,  1.9277, -0.9604, -2.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:11:37 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:11:37 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 15:12:57 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 15:14:14 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 15:15:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.1395e-03, -4.1485e-05, -3.1872e-03,  ..., -1.6232e-03,
         -2.8753e-04, -2.8992e-03],
        [-2.5005e-03,  1.0773e-02,  1.0920e-03,  ...,  6.7863e-03,
          3.5782e-03,  3.3188e-03],
        [-2.9373e-03, -2.4338e-03,  1.3977e-02,  ...,  4.7531e-03,
          5.1765e-03, -2.0275e-03],
        ...,
        [-6.8932e-03,  5.4474e-03, -8.7967e-03,  ...,  1.3382e-02,
          3.3722e-03,  4.0627e-03],
        [-8.4066e-04, -1.6375e-03,  6.5842e-03,  ...,  1.8654e-03,
          7.0190e-03,  2.0885e-04],
        [-1.6632e-03,  1.9836e-03, -9.5940e-04,  ..., -2.4319e-03,
          8.1940e-03,  1.0857e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0153, -0.0125, -0.0042,  ..., -0.0031,  0.0077,  0.0133],
        [-0.0204, -0.0260, -0.0119,  ..., -0.0030,  0.0080,  0.0007],
        [ 0.0229, -0.0079, -0.0024,  ...,  0.0077, -0.0078,  0.0096],
        ...,
        [-0.0063, -0.0086,  0.0034,  ..., -0.0122,  0.0009, -0.0090],
        [-0.0133,  0.0023,  0.0064,  ...,  0.0013, -0.0068, -0.0059],
        [-0.0018,  0.0046, -0.0007,  ..., -0.0068, -0.0084, -0.0138]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0470, -0.0093,  0.0084,  ..., -0.0226,  0.0191, -0.0107],
        [ 0.0011, -0.0466, -0.0165,  ..., -0.0041, -0.0039,  0.0145],
        [ 0.0038, -0.0038, -0.0569,  ..., -0.0024, -0.0232,  0.0180],
        ...,
        [ 0.0198, -0.0124, -0.0212,  ..., -0.0349, -0.0107,  0.0106],
        [ 0.0162, -0.0085, -0.0213,  ..., -0.0107, -0.0640, -0.0141],
        [-0.0079, -0.0085,  0.0074,  ..., -0.0106, -0.0068, -0.0616]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:15:37 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 15:15:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6079, -0.2722,  0.6680,  ...,  0.4524,  0.1631,  0.2339],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0117, -0.5234,  0.0497,  ..., -0.0507, -0.3398, -0.6304],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2305, -0.9546,  4.2539,  ...,  1.1113,  0.6362,  1.7295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.0117, -0.3911, -1.6797,  ...,  2.3828, -1.5498, -0.8203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:15:37 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:15:37 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 15:16:58 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 15:18:12 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 15:19:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.7013e-04, -1.4067e-04, -8.2016e-05,  ..., -3.2127e-05,
         -1.1587e-04,  5.7936e-05],
        [ 6.5625e-05, -6.0368e-04,  3.0470e-04,  ...,  2.4343e-04,
         -3.3832e-04,  2.8229e-04],
        [-2.2745e-04,  1.3351e-04, -3.0375e-04,  ..., -4.2498e-05,
         -1.5008e-04, -1.1653e-04],
        ...,
        [-9.0420e-05,  6.4373e-06,  5.2035e-05,  ..., -4.6802e-04,
          1.9264e-04, -5.2810e-05],
        [-1.1581e-04,  3.2425e-04, -1.3256e-04,  ..., -1.5402e-04,
         -3.5930e-04,  2.3925e-04],
        [-9.2983e-06,  4.2677e-05,  5.1022e-05,  ..., -4.8518e-05,
          3.0899e-04, -5.7364e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0102,  0.0115, -0.0048,  ...,  0.0061,  0.0080, -0.0027],
        [-0.0117, -0.0247, -0.0120,  ..., -0.0028, -0.0019, -0.0051],
        [-0.0051,  0.0016, -0.0081,  ..., -0.0150,  0.0018,  0.0019],
        ...,
        [ 0.0084, -0.0034, -0.0104,  ..., -0.0161,  0.0058,  0.0174],
        [ 0.0154,  0.0093,  0.0039,  ..., -0.0022, -0.0299,  0.0054],
        [-0.0060,  0.0006,  0.0144,  ..., -0.0116,  0.0005, -0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0450,  0.0296, -0.0005,  ...,  0.0006, -0.0058, -0.0027],
        [ 0.0064, -0.0450, -0.0201,  ...,  0.0073,  0.0056,  0.0090],
        [ 0.0016, -0.0013, -0.0765,  ..., -0.0208,  0.0223,  0.0031],
        ...,
        [ 0.0108,  0.0025, -0.0125,  ..., -0.0786, -0.0037,  0.0165],
        [ 0.0019, -0.0051, -0.0138,  ..., -0.0004, -0.0522, -0.0140],
        [ 0.0088, -0.0074,  0.0050,  ..., -0.0115, -0.0141, -0.0520]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:19:29 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 15:19:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7324, -0.2018,  0.7319,  ...,  0.4744,  0.1010,  0.4136],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3621, -0.2496,  0.1197,  ...,  0.7476, -0.3611, -1.0791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.8809, -0.9043,  4.5508,  ..., -0.0664,  0.1167,  1.6943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.1367, -0.1062, -0.9839,  ...,  4.0703, -1.1123, -0.8442],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:19:29 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:19:29 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 15:20:46 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 15:22:01 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 15:23:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.4502e-04,  5.4741e-04,  2.6894e-04,  ...,  3.2401e-04,
         -9.7752e-04,  6.0844e-04],
        [-1.0900e-03, -2.3127e-04, -2.4676e-04,  ...,  1.3065e-03,
          1.1673e-03, -2.9325e-04],
        [ 7.3433e-04,  1.6747e-03, -2.4700e-04,  ..., -3.7730e-05,
         -6.0654e-04,  9.2697e-04],
        ...,
        [ 1.0242e-03,  1.3304e-04, -8.3447e-07,  ...,  2.1458e-04,
          7.2777e-05, -2.3556e-04],
        [ 1.6332e-05, -4.6277e-04, -2.3329e-04,  ...,  3.2723e-05,
         -3.9291e-04, -2.8014e-04],
        [ 8.0109e-04,  3.2711e-04,  1.2655e-03,  ..., -6.7806e-04,
         -1.0757e-03, -1.1425e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0025,  0.0074, -0.0039,  ...,  0.0030,  0.0127,  0.0046],
        [ 0.0116, -0.0320,  0.0122,  ..., -0.0041,  0.0065, -0.0093],
        [ 0.0054,  0.0028, -0.0107,  ..., -0.0233,  0.0123,  0.0070],
        ...,
        [ 0.0070, -0.0154, -0.0014,  ..., -0.0087, -0.0021, -0.0022],
        [-0.0109, -0.0153, -0.0053,  ...,  0.0035, -0.0133,  0.0178],
        [ 0.0030, -0.0141, -0.0039,  ..., -0.0080,  0.0227, -0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0671, -0.0241, -0.0192,  ..., -0.0091, -0.0162, -0.0225],
        [-0.0069, -0.0894,  0.0141,  ..., -0.0019,  0.0010,  0.0152],
        [ 0.0193,  0.0121, -0.0948,  ..., -0.0027, -0.0191,  0.0136],
        ...,
        [ 0.0142, -0.0043, -0.0040,  ..., -0.1132, -0.0152,  0.0143],
        [-0.0232, -0.0072,  0.0052,  ...,  0.0048, -0.1226, -0.0052],
        [-0.0007, -0.0034,  0.0011,  ..., -0.0166, -0.0074, -0.1240]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:23:19 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 15:23:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7417, -0.2734,  1.3262,  ...,  0.3462,  0.2200,  0.5454],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7710, -0.1190, -0.6816,  ...,  0.8755, -0.5845, -0.3494],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0469, -0.4604,  5.0430,  ...,  0.0073,  0.8521,  1.6338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.5801,  0.2856, -0.7207,  ...,  4.1562, -0.0146, -1.3770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:23:19 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:23:19 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 15:24:32 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 15:25:52 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 15:27:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.5917e-03, -1.3962e-03, -7.7772e-04,  ...,  4.4560e-04,
         -2.3246e-04,  3.6359e-06],
        [ 1.1797e-03,  1.8749e-03,  2.7490e-04,  ..., -4.1342e-04,
         -1.2093e-03, -4.9782e-04],
        [-1.2100e-05, -4.0245e-04,  2.2869e-03,  ..., -9.0122e-04,
          6.8378e-04, -4.5478e-05],
        ...,
        [-7.6818e-04, -1.1902e-03, -2.5082e-04,  ...,  2.7046e-03,
         -4.5109e-04, -5.0545e-04],
        [-1.7586e-03, -3.7122e-04, -1.1892e-03,  ...,  8.5640e-04,
          2.2030e-03, -1.0672e-03],
        [ 4.8614e-04,  1.7381e-04, -2.8849e-04,  ...,  7.8773e-04,
          1.6737e-04,  4.2191e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0321, -0.0122,  0.0113,  ..., -0.0055, -0.0065,  0.0107],
        [-0.0088, -0.0231, -0.0006,  ...,  0.0084, -0.0076,  0.0094],
        [ 0.0131, -0.0021,  0.0217,  ...,  0.0030, -0.0054, -0.0090],
        ...,
        [-0.0041,  0.0096, -0.0013,  ...,  0.0358,  0.0032, -0.0054],
        [-0.0006, -0.0102, -0.0002,  ...,  0.0233,  0.0114,  0.0151],
        [ 0.0034, -0.0054, -0.0050,  ..., -0.0082,  0.0075,  0.0144]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0367,  0.0095, -0.0129,  ..., -0.0079, -0.0117,  0.0336],
        [ 0.0010, -0.0720, -0.0009,  ...,  0.0089, -0.0051,  0.0268],
        [-0.0120,  0.0044, -0.0484,  ...,  0.0025,  0.0150,  0.0104],
        ...,
        [-0.0311,  0.0117, -0.0175,  ..., -0.0351,  0.0233, -0.0281],
        [ 0.0183, -0.0169, -0.0070,  ..., -0.0175, -0.0562,  0.0301],
        [-0.0036,  0.0113, -0.0068,  ...,  0.0187,  0.0047, -0.0382]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:27:11 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 15:27:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9102, -0.2406,  1.3359,  ..., -0.0567,  0.0333,  0.4893],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7915, -0.0168, -0.4316,  ...,  1.4834, -0.4238, -0.3694],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4902, -0.2708,  4.4297,  ..., -0.0271,  0.7178,  1.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.1445,  0.4775, -1.3438,  ...,  3.3203, -0.0105, -0.5518],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:27:11 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:27:11 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 15:28:32 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 15:29:54 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 15:31:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.6022e-03, -5.0354e-04,  7.3969e-05,  ..., -1.9765e-04,
          3.6120e-04,  1.1396e-04],
        [-3.6550e-04,  1.3947e-04,  5.8842e-04,  ..., -4.1389e-04,
         -1.2755e-04, -6.3300e-05],
        [-3.1638e-04, -1.9908e-05,  1.2188e-03,  ..., -2.0695e-04,
          3.8218e-04,  2.6822e-06],
        ...,
        [ 2.4819e-04, -3.8147e-04, -6.0797e-04,  ...,  1.5345e-03,
          1.9503e-04,  1.1146e-04],
        [ 3.6597e-04,  5.5933e-04, -4.4656e-04,  ..., -1.1623e-05,
          1.0233e-03,  2.3663e-05],
        [ 3.3855e-04, -9.1934e-04,  7.5722e-04,  ..., -1.9598e-04,
          5.8222e-04,  1.5726e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0110,  0.0060,  0.0098,  ..., -0.0088,  0.0110,  0.0047],
        [-0.0156, -0.0185,  0.0095,  ...,  0.0140,  0.0019, -0.0258],
        [ 0.0144, -0.0059,  0.0229,  ..., -0.0094, -0.0040,  0.0014],
        ...,
        [-0.0011,  0.0045, -0.0088,  ...,  0.0104,  0.0046, -0.0041],
        [-0.0014,  0.0202, -0.0125,  ..., -0.0121, -0.0018,  0.0058],
        [-0.0061, -0.0089, -0.0140,  ...,  0.0207, -0.0144,  0.0178]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0329, -0.0157,  0.0124,  ..., -0.0052, -0.0052,  0.0009],
        [ 0.0029, -0.0406,  0.0116,  ...,  0.0044,  0.0127,  0.0050],
        [ 0.0035, -0.0072, -0.0382,  ..., -0.0134, -0.0112,  0.0090],
        ...,
        [-0.0006, -0.0160,  0.0060,  ..., -0.0485,  0.0087, -0.0067],
        [ 0.0008,  0.0299, -0.0413,  ...,  0.0009, -0.0534,  0.0313],
        [ 0.0029, -0.0228, -0.0247,  ..., -0.0019,  0.0142, -0.0469]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:31:21 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 15:31:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6196, -0.0923,  1.2695,  ..., -0.0951,  0.2040,  0.3955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8848,  0.1249, -0.3411,  ...,  1.3564, -0.0334, -0.5562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3086,  0.4998,  2.6211,  ..., -1.2451,  0.7246,  0.4434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1650,  0.2820, -2.4414,  ...,  3.2559, -0.8047, -1.1006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:31:21 root INFO     [order_1_approx] starting weight calculation for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:31:21 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 15:32:47 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 15:34:10 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 15:35:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.2513e-04, -3.7909e-04,  2.3758e-04,  ...,  1.5759e-04,
         -5.7316e-04, -8.1599e-05],
        [ 2.7919e-04,  6.7234e-04,  4.1902e-05,  ..., -1.8358e-05,
         -1.5914e-05,  6.1893e-04],
        [ 3.4857e-04, -7.8058e-04,  7.9250e-04,  ..., -3.8552e-04,
         -2.1338e-04, -1.5044e-04],
        ...,
        [-3.7479e-04,  4.0770e-05, -9.5546e-05,  ...,  1.3666e-03,
         -1.8597e-04, -2.8706e-04],
        [-2.3365e-04,  3.6538e-05,  1.8382e-04,  ...,  7.3850e-05,
          1.2875e-03, -4.6897e-04],
        [-4.6551e-05,  1.4722e-04, -5.6922e-05,  ..., -1.5628e-04,
         -2.7657e-04,  1.2884e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0542,  0.0047, -0.0016,  ...,  0.0021,  0.0048,  0.0033],
        [ 0.0056, -0.0046,  0.0069,  ..., -0.0175,  0.0143,  0.0068],
        [-0.0174, -0.0119,  0.0402,  ..., -0.0131, -0.0080,  0.0040],
        ...,
        [ 0.0098, -0.0018,  0.0157,  ...,  0.0740, -0.0013, -0.0127],
        [ 0.0042, -0.0028, -0.0325,  ..., -0.0054,  0.0357,  0.0195],
        [-0.0179,  0.0228,  0.0007,  ..., -0.0054, -0.0027,  0.0595]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.4209e-02,  2.9259e-03,  1.3306e-02,  ..., -7.6408e-03,
          5.2986e-03, -1.5411e-02],
        [ 2.0691e-02, -4.1962e-02,  1.5396e-02,  ..., -9.1476e-03,
          2.1530e-02,  1.6403e-04],
        [-3.3264e-02, -2.4567e-03, -2.6550e-02,  ..., -1.8036e-02,
         -5.2567e-03,  2.3605e-02],
        ...,
        [ 1.3016e-02,  9.8572e-03, -1.6647e-02,  ..., -3.2135e-02,
          1.7578e-02,  5.1308e-03],
        [ 1.0361e-02,  9.5749e-04, -1.5106e-02,  ..., -5.2795e-03,
         -2.3209e-02, -1.2054e-03],
        [-7.6294e-06,  2.9907e-03,  1.9821e-02,  ...,  1.8311e-04,
          4.3440e-04, -2.3575e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:35:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The allosaurus falls into the category of dinosaur
The jackal falls into the category of canine
The leopard falls into the category of feline
The gorilla falls into the category of primate
The goat falls into the category of bovid
The butterfly falls into the category of insect
The falcon falls into the category of raptor
The vulture falls into the category of
2024-06-30 15:35:40 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 15:35:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5605,  0.0720, -1.0566,  ..., -0.2974,  0.1301, -0.3518],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4700, -0.1379, -0.5771,  ..., -0.1432, -0.8994, -0.4160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0469,  0.0215, -0.6724,  ..., -0.4011,  0.0806, -0.4980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4688,  0.0777, -0.2939,  ..., -0.5605, -0.4209, -0.6064],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:35:40 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:35:40 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 15:36:03 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 15:36:27 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 15:36:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.7220e-04, -2.6608e-04,  5.0688e-04,  ...,  1.4687e-04,
          1.0484e-04,  2.1768e-04],
        [ 4.4286e-05, -6.4850e-04,  9.5546e-05,  ..., -3.3045e-04,
          5.9307e-05, -2.2960e-04],
        [ 1.9360e-04,  1.1742e-04, -1.1797e-03,  ...,  1.3292e-04,
         -1.3113e-04, -1.1408e-04],
        ...,
        [-6.0463e-04, -4.1628e-04,  3.2115e-04,  ..., -5.9509e-04,
          1.6189e-04,  4.4870e-04],
        [-2.0051e-04,  6.8545e-06,  3.4750e-05,  ...,  2.5916e-04,
         -6.1703e-04, -8.2672e-05],
        [-3.6144e-04, -1.3685e-04,  9.4843e-04,  ..., -4.7684e-04,
          3.0875e-05, -4.7398e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0338,  0.0085, -0.0020,  ..., -0.0034, -0.0007, -0.0064],
        [-0.0027, -0.0286, -0.0003,  ...,  0.0026, -0.0022,  0.0010],
        [ 0.0054,  0.0026, -0.0298,  ..., -0.0101,  0.0027, -0.0012],
        ...,
        [ 0.0074, -0.0015, -0.0009,  ..., -0.0200,  0.0048,  0.0040],
        [ 0.0032,  0.0024, -0.0021,  ...,  0.0071, -0.0199,  0.0014],
        [ 0.0004, -0.0035,  0.0039,  ..., -0.0045, -0.0025, -0.0317]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0380e-02,  8.4877e-05,  6.3324e-03,  ..., -9.3269e-04,
         -1.0881e-03,  3.7861e-04],
        [ 5.4789e-04, -2.6398e-02, -6.3171e-03,  ..., -1.8110e-03,
          1.8921e-03,  5.7697e-04],
        [-7.7486e-04,  1.9894e-03, -2.5284e-02,  ...,  1.9550e-04,
         -2.1095e-03,  5.3711e-03],
        ...,
        [ 2.3079e-03,  4.0092e-03,  1.0653e-03,  ..., -2.2156e-02,
          2.9545e-03,  2.2106e-03],
        [-1.6708e-03,  2.2945e-03,  8.8811e-05,  ...,  2.1219e-05,
         -2.4857e-02,  1.0071e-03],
        [-8.4400e-04, -1.5125e-03, -3.1357e-03,  ...,  4.4394e-04,
          6.1083e-04, -2.7725e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:36:52 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 15:36:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6265, -0.1567, -1.0527,  ..., -0.4624,  0.1525, -0.5537],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5874,  0.1499, -0.3967,  ..., -1.0977, -0.4258, -0.4846],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3027,  0.0837, -0.5977,  ..., -0.1794, -0.1404, -0.3513],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2131, -0.1677,  0.0972,  ..., -1.1328, -0.5010, -0.7036],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:36:52 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:36:52 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 15:37:16 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 15:37:40 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 15:38:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.4490e-03,  3.0327e-04, -3.1757e-04,  ..., -1.2455e-03,
         -2.9850e-04, -4.0054e-04],
        [ 6.6280e-05, -4.9858e-03, -1.6034e-04,  ...,  1.2913e-03,
         -6.9904e-04,  3.4857e-04],
        [-3.8052e-04,  1.1387e-03, -5.4626e-03,  ..., -6.3705e-04,
         -3.7909e-04, -6.9046e-04],
        ...,
        [ 5.3978e-04,  4.6396e-04, -1.1820e-04,  ..., -3.8013e-03,
         -1.4324e-03,  3.2568e-04],
        [-1.0843e-03,  1.1215e-03,  5.2261e-04,  ...,  1.1265e-04,
         -4.5395e-03,  3.3021e-05],
        [ 7.0512e-05, -3.7193e-05,  9.4128e-04,  ..., -5.9652e-04,
          6.1274e-04, -3.4428e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.9774e-02, -1.1536e-02,  1.0323e-02,  ...,  7.4387e-03,
         -1.1108e-02, -3.9139e-03],
        [-6.3248e-03, -4.5563e-02,  4.1847e-03,  ...,  1.4771e-02,
         -1.1663e-03, -2.4319e-05],
        [-1.8368e-03, -6.5727e-03, -4.4556e-02,  ..., -1.0117e-02,
          5.2567e-03,  4.5929e-03],
        ...,
        [-2.6760e-03,  6.7291e-03,  5.8985e-04,  ..., -6.2042e-02,
         -8.2397e-03, -8.5526e-03],
        [-5.4932e-03, -8.4076e-03,  1.7014e-02,  ..., -3.2806e-04,
         -5.2948e-02, -7.7324e-03],
        [-1.0109e-04,  1.5440e-03,  5.3864e-03,  ...,  5.7220e-04,
         -1.8644e-03, -6.5247e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.8960e-02,  1.1454e-03, -2.8324e-03,  ...,  7.1945e-03,
          5.8060e-03,  1.6136e-03],
        [-2.6627e-03, -6.3049e-02, -3.1147e-03,  ..., -1.0462e-03,
         -1.4372e-03, -3.8395e-03],
        [ 1.5659e-03,  2.3804e-03, -6.0852e-02,  ...,  3.1376e-03,
          2.3499e-03, -7.0572e-05],
        ...,
        [ 3.6430e-03, -5.1498e-03, -4.9591e-05,  ..., -5.8563e-02,
         -6.0883e-03, -9.5978e-03],
        [-6.1226e-03, -5.0888e-03,  4.2953e-03,  ..., -5.8708e-03,
         -6.1218e-02,  4.0321e-03],
        [ 1.0815e-03, -1.3626e-02,  5.3711e-03,  ...,  1.6232e-03,
          2.3937e-04, -5.6915e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:38:07 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 15:38:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1758, -0.0015, -0.7690,  ..., -0.4397,  0.0831, -0.6162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7603,  0.1060, -0.4609,  ..., -0.8389, -0.6499, -1.0088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3750,  0.1328, -0.6875,  ..., -0.1764,  0.0242,  0.2283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3892,  0.3430, -0.0131,  ..., -0.7798, -0.5986, -1.0303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:38:07 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:38:07 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 15:38:32 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 15:38:57 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 15:39:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.1613e-03,  1.1665e-04, -2.2626e-04,  ...,  3.3593e-04,
          1.1754e-04,  5.1785e-04],
        [ 2.9778e-04, -3.7975e-03,  2.3794e-04,  ...,  3.4094e-04,
          5.4657e-05,  9.4652e-05],
        [ 1.4436e-04, -1.0471e-03, -4.0779e-03,  ...,  1.0242e-03,
          6.7902e-04, -2.6178e-04],
        ...,
        [-3.9816e-04,  5.9605e-04,  1.0788e-05,  ..., -2.3460e-03,
          1.5287e-03,  1.9741e-04],
        [ 1.5616e-05, -1.8907e-04, -9.6607e-04,  ...,  1.2827e-03,
         -3.5877e-03, -1.4486e-03],
        [ 4.4525e-05,  4.3726e-04, -4.6968e-04,  ..., -9.2506e-05,
         -3.0994e-05, -2.7218e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0110,  0.0024, -0.0019,  ...,  0.0082, -0.0008, -0.0059],
        [ 0.0007, -0.0164, -0.0084,  ...,  0.0016, -0.0040,  0.0076],
        [ 0.0059,  0.0085, -0.0003,  ...,  0.0008,  0.0011, -0.0021],
        ...,
        [-0.0031,  0.0004,  0.0043,  ..., -0.0178,  0.0117, -0.0150],
        [ 0.0060,  0.0005, -0.0153,  ..., -0.0104, -0.0170,  0.0057],
        [ 0.0047,  0.0030,  0.0006,  ...,  0.0096, -0.0062, -0.0123]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0289e-02,  4.8447e-04, -2.5082e-03,  ...,  2.1858e-03,
          4.2000e-03,  5.5046e-03],
        [-3.3150e-03, -3.2471e-02, -1.4114e-03,  ...,  6.0081e-03,
          3.1853e-03,  8.8406e-04],
        [-3.6335e-04,  4.2105e-04, -3.4454e-02,  ..., -2.3880e-03,
         -3.3836e-03, -3.8433e-03],
        ...,
        [ 3.9577e-05,  2.8095e-03, -9.1124e-04,  ..., -2.9922e-02,
         -4.4289e-03,  3.3836e-03],
        [-2.1248e-03,  1.1120e-03, -1.1864e-03,  ..., -6.6223e-03,
         -2.8778e-02,  8.5373e-03],
        [ 3.7193e-03,  5.4131e-03,  1.6623e-03,  ..., -4.3640e-03,
         -1.0490e-04, -2.8656e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:39:24 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 15:39:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.4678,  0.0675, -0.6646,  ..., -0.1951, -0.1783, -0.4514],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3325, -0.2676,  0.1429,  ..., -1.5605, -0.7231, -1.0811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7412,  0.5933, -0.9072,  ..., -0.5151,  0.7822,  0.4624],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1547,  0.4946, -0.4297,  ..., -0.8486, -0.0732, -0.4795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:39:25 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:39:25 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 15:39:55 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 15:40:25 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 15:40:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.5306e-04,  6.9284e-04, -8.4734e-04,  ...,  5.1403e-04,
         -2.9588e-04, -1.0414e-03],
        [ 1.8578e-03, -9.4175e-04,  4.9925e-04,  ...,  3.6716e-04,
         -1.0939e-03,  1.6332e-04],
        [-2.9039e-04, -2.2626e-04, -9.0218e-04,  ..., -7.5960e-04,
         -7.8154e-04, -1.1721e-03],
        ...,
        [ 9.6130e-04,  4.6539e-04, -4.4322e-04,  ..., -1.1950e-03,
         -1.2131e-03,  4.0531e-04],
        [-1.0014e-03,  7.6103e-04, -4.9877e-04,  ..., -1.0843e-03,
         -9.5272e-04, -9.4461e-04],
        [ 9.9182e-04, -2.3022e-03,  1.3709e-05,  ...,  2.0847e-03,
          3.2783e-05, -2.7447e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0303, -0.0002, -0.0111,  ..., -0.0069,  0.0047,  0.0128],
        [ 0.0021, -0.0216, -0.0037,  ..., -0.0047,  0.0112,  0.0044],
        [ 0.0023, -0.0065, -0.0210,  ...,  0.0033, -0.0029, -0.0013],
        ...,
        [ 0.0017, -0.0024,  0.0005,  ..., -0.0247, -0.0120,  0.0059],
        [-0.0028, -0.0088, -0.0041,  ...,  0.0018, -0.0336,  0.0052],
        [ 0.0029,  0.0036,  0.0117,  ..., -0.0068, -0.0011, -0.0342]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.4260e-02,  1.2350e-03, -2.4796e-05,  ..., -4.1199e-03,
          9.3918e-03, -6.9122e-03],
        [ 4.6005e-03, -4.6234e-02, -2.1858e-03,  ...,  3.5019e-03,
         -1.3876e-03,  2.2297e-03],
        [ 2.8229e-04, -3.3722e-03, -3.9886e-02,  ...,  5.6839e-03,
         -1.7042e-03,  1.2560e-03],
        ...,
        [-3.7594e-03, -6.4926e-03,  3.2139e-04,  ..., -6.3416e-02,
          3.8147e-06, -1.1047e-02],
        [-6.3133e-04,  2.8801e-03, -1.2909e-02,  ..., -7.0114e-03,
         -3.7415e-02, -7.0915e-03],
        [-1.6785e-03, -1.8024e-04, -1.4505e-03,  ..., -3.7403e-03,
         -1.4744e-03, -5.3375e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:40:58 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 15:40:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.3369,  0.0848, -0.6572,  ..., -0.1781,  0.0526,  0.1898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4124,  0.3281, -0.0056,  ..., -0.7700, -0.5923, -1.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5767,  0.4321, -0.7153,  ..., -0.8730,  0.6763,  0.8110],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1052,  0.1743, -0.3359,  ..., -0.5645, -0.2155, -0.5225],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:40:58 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:40:58 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 15:41:31 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 15:42:05 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 15:42:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6670e-03,  1.6012e-03, -1.8139e-03,  ...,  1.2045e-03,
          8.3399e-04, -1.0509e-03],
        [-8.4257e-04, -1.2426e-03, -7.6437e-04,  ..., -1.5092e-04,
         -1.5678e-03,  2.2626e-04],
        [ 3.0098e-03,  2.4948e-03, -4.0398e-03,  ...,  5.5122e-04,
          1.3294e-03,  1.8330e-03],
        ...,
        [ 5.2547e-04, -5.7602e-04, -4.8518e-05,  ..., -1.1282e-03,
         -4.6730e-04,  2.3251e-03],
        [-1.1997e-03,  1.1349e-03, -2.3823e-03,  ...,  1.6699e-03,
         -1.4191e-03,  1.4591e-03],
        [-4.7731e-04, -1.8492e-03, -1.3704e-03,  ..., -7.8726e-04,
         -3.0732e-04, -2.2659e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.2286e-02, -3.7518e-03,  1.0239e-02,  ...,  4.8752e-03,
          1.7166e-05, -1.1009e-02],
        [ 1.6098e-03, -5.7007e-02,  6.2561e-03,  ..., -4.5509e-03,
         -9.8114e-03, -3.3741e-03],
        [ 1.1673e-02, -7.6332e-03, -6.2347e-02,  ...,  3.8795e-03,
         -2.5063e-03, -2.9182e-03],
        ...,
        [ 4.0321e-03, -1.2999e-03,  8.8501e-04,  ..., -3.8696e-02,
          8.9264e-04, -5.8899e-03],
        [ 5.8985e-04,  4.0169e-03, -8.2245e-03,  ...,  9.0179e-03,
         -7.2388e-02,  4.5700e-03],
        [-1.1124e-02, -5.1308e-03, -2.0905e-03,  ..., -6.1111e-03,
         -1.6546e-03, -4.7791e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0419e-01,  5.2834e-04,  1.2573e-02,  ...,  9.0361e-04,
          9.4986e-04, -3.7880e-03],
        [ 2.7943e-04, -1.1237e-01,  5.2032e-03,  ..., -4.6196e-03,
         -8.8959e-03, -7.8011e-03],
        [ 1.1978e-03,  2.1896e-03, -1.1041e-01,  ...,  4.2343e-03,
          4.5280e-03,  1.9073e-05],
        ...,
        [-3.8719e-04,  2.1744e-03,  2.8687e-03,  ..., -9.2957e-02,
          9.8572e-03, -2.2697e-04],
        [-2.1782e-03,  7.0810e-04,  5.3482e-03,  ..., -6.3324e-03,
         -1.0791e-01,  4.3716e-03],
        [-7.9956e-03, -2.3155e-03, -2.5978e-03,  ..., -6.6986e-03,
          7.6218e-03, -1.0834e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:42:39 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 15:42:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6431,  0.5122, -0.7715,  ..., -0.4309,  0.6533,  0.3865],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1656,  0.5308, -0.4468,  ..., -0.8643, -0.0918, -0.5439],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4700,  0.2993, -1.0850,  ..., -1.3848,  0.8550,  1.1230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3630,  0.3706, -0.4268,  ..., -0.1216, -0.3916, -0.4963],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:42:39 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:42:39 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 15:43:10 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 15:43:46 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 15:44:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0040,  0.0002,  0.0024,  ..., -0.0011,  0.0006,  0.0010],
        [ 0.0010, -0.0065,  0.0025,  ...,  0.0022,  0.0040, -0.0038],
        [-0.0011,  0.0020, -0.0049,  ..., -0.0019, -0.0002, -0.0007],
        ...,
        [-0.0001,  0.0010, -0.0001,  ..., -0.0042, -0.0002,  0.0002],
        [ 0.0024,  0.0005, -0.0006,  ..., -0.0022, -0.0020,  0.0005],
        [ 0.0001, -0.0014,  0.0034,  ...,  0.0020, -0.0002, -0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0776, -0.0065, -0.0090,  ...,  0.0069, -0.0024, -0.0031],
        [ 0.0026, -0.0628,  0.0046,  ...,  0.0035,  0.0132,  0.0031],
        [ 0.0110,  0.0070, -0.0649,  ...,  0.0093, -0.0033, -0.0012],
        ...,
        [ 0.0029, -0.0019,  0.0028,  ..., -0.0675, -0.0062,  0.0105],
        [ 0.0007,  0.0002, -0.0035,  ...,  0.0030, -0.0632,  0.0092],
        [ 0.0099,  0.0006,  0.0056,  ..., -0.0064, -0.0025, -0.0654]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2463e-01,  8.5602e-03, -7.7133e-03,  ..., -2.4014e-03,
          3.0098e-03, -3.0155e-03],
        [ 6.8779e-03, -1.2158e-01, -6.9580e-03,  ...,  3.8452e-03,
         -1.2054e-03,  7.0457e-03],
        [ 2.0885e-03,  1.4992e-03, -1.1182e-01,  ..., -2.1100e-04,
          1.1803e-02, -1.2398e-05],
        ...,
        [-2.9755e-03, -4.2877e-03,  4.2496e-03,  ..., -1.1548e-01,
         -8.0414e-03, -4.5128e-03],
        [ 2.8610e-05,  3.6335e-03, -2.7618e-03,  ...,  3.7804e-03,
         -1.1273e-01, -2.4490e-03],
        [-3.5286e-05,  1.9913e-03, -4.1962e-04,  ..., -8.9874e-03,
         -4.9896e-03, -1.1377e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:44:22 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 15:44:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4753,  0.3789, -0.5859,  ..., -0.7163,  0.5488,  0.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1028,  0.1873, -0.3215,  ..., -0.5361, -0.2085, -0.5513],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1006,  0.3865, -1.7178,  ..., -1.4648,  1.0498,  1.4600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0322, -0.0354, -0.5991,  ..., -0.5889, -0.3257, -0.4241],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:44:22 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:44:22 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 15:44:57 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 15:45:35 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 15:46:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.8845e-03,  9.1887e-04, -6.8605e-05,  ...,  1.6947e-03,
         -1.9188e-03, -2.5749e-05],
        [ 6.6662e-04, -2.0142e-03, -7.3624e-04,  ...,  1.4801e-03,
          7.8583e-04, -1.9426e-03],
        [ 1.7824e-03, -1.1063e-03, -3.6545e-03,  ..., -7.3016e-05,
         -7.7868e-04, -1.6093e-04],
        ...,
        [-6.9857e-04, -7.1764e-04,  1.1406e-03,  ..., -3.6602e-03,
          2.0905e-03,  1.3459e-04],
        [-9.6321e-04,  7.7343e-04, -2.0943e-03,  ...,  1.3876e-03,
         -1.8101e-03,  1.1530e-03],
        [ 1.1969e-03, -1.3485e-03, -3.9935e-04,  ..., -2.0256e-03,
          2.0289e-04, -2.1248e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0766,  0.0082,  0.0089,  ..., -0.0021, -0.0017,  0.0024],
        [ 0.0018, -0.0685,  0.0132,  ...,  0.0134,  0.0102, -0.0058],
        [-0.0032, -0.0032, -0.0579,  ..., -0.0006, -0.0001,  0.0021],
        ...,
        [ 0.0093,  0.0034,  0.0035,  ..., -0.0556,  0.0084, -0.0047],
        [-0.0115,  0.0067, -0.0033,  ...,  0.0040, -0.0695,  0.0015],
        [-0.0019,  0.0025, -0.0106,  ...,  0.0100, -0.0048, -0.0605]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1090e-01, -1.9398e-03,  2.3613e-03,  ..., -1.3733e-02,
         -1.5793e-02,  1.2398e-05],
        [ 6.9809e-03, -9.4177e-02, -1.2238e-02,  ...,  4.7417e-03,
          4.4899e-03,  1.5659e-03],
        [-1.0078e-02, -7.4043e-03, -9.6558e-02,  ..., -3.0384e-03,
          2.9488e-03,  2.2926e-03],
        ...,
        [ 2.8362e-03,  3.1013e-03,  1.5030e-03,  ..., -1.0681e-01,
          1.1490e-02, -4.8294e-03],
        [ 2.6379e-03,  1.8692e-03, -1.1539e-04,  ...,  1.1459e-02,
         -1.0742e-01, -3.2692e-03],
        [-3.3531e-03, -5.4703e-03,  7.2174e-03,  ...,  1.4114e-03,
         -3.1281e-04, -1.0461e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:46:17 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 15:46:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3738,  0.2317, -0.8311,  ..., -1.0273,  0.6470,  0.8828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3564,  0.3716, -0.4106,  ..., -0.1132, -0.3821, -0.5215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1440,  0.3899, -1.6836,  ..., -2.0391,  1.2461,  1.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1384, -0.5322, -1.0127,  ..., -1.2207, -0.8188,  0.2839],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:46:18 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:46:18 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 15:46:57 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 15:47:39 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 15:48:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0036, -0.0012, -0.0016,  ...,  0.0005, -0.0022, -0.0026],
        [-0.0004, -0.0024,  0.0016,  ..., -0.0057,  0.0007, -0.0020],
        [-0.0027, -0.0008, -0.0029,  ...,  0.0003, -0.0024, -0.0042],
        ...,
        [ 0.0007,  0.0026, -0.0024,  ..., -0.0022,  0.0027,  0.0033],
        [-0.0024, -0.0014, -0.0031,  ...,  0.0008, -0.0071,  0.0014],
        [ 0.0030,  0.0013,  0.0009,  ..., -0.0010, -0.0006, -0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0845, -0.0106, -0.0060,  ..., -0.0100,  0.0059,  0.0067],
        [-0.0023, -0.0884, -0.0021,  ...,  0.0059, -0.0012,  0.0005],
        [-0.0081,  0.0077, -0.0849,  ..., -0.0043, -0.0095, -0.0043],
        ...,
        [-0.0072, -0.0011, -0.0153,  ..., -0.0789, -0.0049, -0.0102],
        [-0.0039,  0.0095,  0.0007,  ...,  0.0016, -0.0787,  0.0165],
        [ 0.0074, -0.0034,  0.0116,  ..., -0.0154, -0.0044, -0.0856]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1086,  0.0109, -0.0023,  ..., -0.0006,  0.0054,  0.0006],
        [ 0.0058, -0.1127,  0.0091,  ..., -0.0074, -0.0106,  0.0101],
        [-0.0098, -0.0019, -0.1128,  ..., -0.0017, -0.0103,  0.0141],
        ...,
        [ 0.0023, -0.0009, -0.0059,  ..., -0.1020, -0.0034,  0.0015],
        [-0.0086,  0.0024, -0.0113,  ...,  0.0013, -0.1107,  0.0047],
        [ 0.0016,  0.0046, -0.0109,  ...,  0.0033,  0.0053, -0.1146]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:48:28 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 15:48:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0470,  0.2642, -1.1836,  ..., -0.9663,  0.6812,  1.0049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0468, -0.0348, -0.5605,  ..., -0.5103, -0.2966, -0.4026],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3716,  0.6768, -1.7549,  ..., -1.9473,  1.3584,  1.1191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0071, -0.5352, -0.8159,  ..., -1.2852, -0.9722,  0.3413],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:48:28 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:48:28 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 15:49:16 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 15:50:04 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 15:50:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.4847e-03,  1.5821e-03,  4.5929e-03,  ..., -6.6147e-03,
         -2.9945e-04, -6.0501e-03],
        [ 6.1798e-03, -6.1340e-03, -1.0214e-03,  ...,  1.6441e-03,
          1.6708e-03,  3.6621e-03],
        [-7.8249e-04,  4.6806e-03,  1.7452e-03,  ..., -3.1204e-03,
          5.5313e-04, -3.4008e-03],
        ...,
        [-3.4256e-03, -2.3794e-04, -1.5326e-03,  ...,  4.5776e-05,
         -6.0081e-03, -4.7455e-03],
        [-4.9782e-03,  1.1702e-03,  2.4490e-03,  ..., -1.7319e-03,
         -1.7405e-03,  6.1798e-04],
        [ 3.8433e-04, -2.4414e-03,  4.7226e-03,  ..., -6.0577e-03,
          3.9711e-03,  3.5286e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1032, -0.0080,  0.0086,  ..., -0.0072,  0.0095, -0.0073],
        [-0.0111, -0.0955,  0.0080,  ...,  0.0003,  0.0106, -0.0005],
        [-0.0059,  0.0144, -0.1031,  ...,  0.0033, -0.0019, -0.0190],
        ...,
        [-0.0130, -0.0052,  0.0191,  ..., -0.1056, -0.0002, -0.0014],
        [ 0.0005, -0.0038, -0.0041,  ...,  0.0046, -0.1007,  0.0140],
        [ 0.0046, -0.0028, -0.0068,  ..., -0.0006,  0.0169, -0.0957]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1609, -0.0025,  0.0075,  ..., -0.0008, -0.0117,  0.0102],
        [-0.0129, -0.1642, -0.0056,  ...,  0.0005, -0.0034,  0.0024],
        [-0.0090, -0.0024, -0.1646,  ...,  0.0024, -0.0078, -0.0099],
        ...,
        [-0.0097,  0.0084,  0.0114,  ..., -0.1584, -0.0041,  0.0102],
        [-0.0041, -0.0006, -0.0035,  ..., -0.0039, -0.1792, -0.0103],
        [-0.0118,  0.0038, -0.0128,  ..., -0.0117, -0.0148, -0.1514]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:50:49 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 15:50:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0913,  0.2252, -1.0391,  ..., -1.1895,  0.7383,  1.0273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1066, -0.4480, -0.8149,  ..., -0.9170, -0.6582,  0.1906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2137,  0.7524, -1.2314,  ..., -2.0410,  1.0107,  1.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0068, -0.6025, -0.5264,  ..., -0.7368, -1.4043,  1.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:50:49 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:50:49 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 15:51:38 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 15:52:14 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 15:52:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0001, -0.0012, -0.0003,  ...,  0.0003,  0.0024,  0.0008],
        [-0.0021,  0.0025,  0.0040,  ...,  0.0020,  0.0058, -0.0041],
        [ 0.0031, -0.0009, -0.0036,  ...,  0.0033, -0.0032,  0.0029],
        ...,
        [-0.0003, -0.0035,  0.0105,  ..., -0.0002, -0.0043,  0.0003],
        [ 0.0018, -0.0029,  0.0028,  ...,  0.0077, -0.0050,  0.0040],
        [-0.0019, -0.0059, -0.0045,  ...,  0.0022,  0.0059, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0431e-01, -3.9635e-03, -1.0017e-02,  ...,  4.0054e-03,
          5.0354e-04,  3.3607e-03],
        [ 1.4481e-02, -8.2581e-02, -8.9645e-04,  ..., -4.8904e-03,
         -5.8746e-04, -1.4565e-02],
        [ 2.9659e-03, -3.0556e-03, -8.6487e-02,  ...,  1.0324e-04,
          1.1589e-02,  2.8687e-03],
        ...,
        [ 1.1574e-02, -1.6373e-02,  6.5880e-03,  ..., -8.6792e-02,
          7.5760e-03,  5.1117e-04],
        [ 1.5350e-02, -4.2267e-03,  1.0574e-02,  ...,  2.1805e-02,
         -1.0065e-01,  1.9897e-02],
        [ 5.0354e-04,  6.6452e-03, -3.4199e-03,  ...,  2.0370e-03,
         -1.1238e-02, -9.2163e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1383e-01,  1.2405e-02,  4.6196e-03,  ...,  1.2569e-03,
         -1.5202e-03, -1.6037e-02],
        [ 9.7198e-03, -1.1450e-01,  7.5684e-03,  ...,  9.5978e-03,
         -5.4016e-03,  2.6550e-03],
        [ 3.5706e-03, -8.3618e-03, -1.2634e-01,  ..., -2.2240e-03,
          1.2611e-02,  4.9639e-04],
        ...,
        [-1.0986e-02, -3.1261e-03,  8.8425e-03,  ..., -1.2378e-01,
          1.4008e-02, -1.1391e-02],
        [ 2.4261e-03, -1.4915e-03, -2.6894e-03,  ...,  8.4305e-04,
         -1.2073e-01,  1.9272e-02],
        [-8.6975e-03,  9.1553e-05, -3.1967e-03,  ..., -1.0056e-02,
         -1.4296e-03, -1.1810e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:53:00 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 15:53:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2313,  0.3735, -1.0010,  ..., -1.0977,  0.7363,  0.6523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0082, -0.4009, -0.5850,  ..., -0.8867, -0.6836,  0.2458],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1625,  1.2305, -1.5723,  ..., -0.9668,  1.6357,  1.9580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4082, -0.8398, -0.3628,  ..., -0.8867, -0.8589,  0.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:53:00 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:53:00 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 15:53:54 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 15:54:49 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 15:55:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.5220e-03,  4.3297e-03,  2.1019e-03,  ...,  9.9277e-04,
         -1.0710e-03,  6.3133e-03],
        [-4.7150e-03,  3.8700e-03, -2.7218e-03,  ...,  2.3327e-03,
          1.4791e-03,  4.2229e-03],
        [-9.2163e-03, -6.3515e-04,  5.6572e-03,  ..., -4.1389e-03,
          3.5496e-03,  4.6387e-03],
        ...,
        [-6.4802e-04,  5.3024e-03, -2.6345e-04,  ...,  1.1055e-02,
         -2.3079e-03,  4.6844e-03],
        [-1.1950e-03, -3.6259e-03,  6.1111e-03,  ...,  1.2560e-03,
          5.8327e-03, -3.9177e-03],
        [-2.1343e-03,  3.1624e-03,  4.9171e-03,  ..., -8.7166e-04,
         -4.5180e-05,  4.1351e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1442,  0.0145,  0.0159,  ...,  0.0043,  0.0021, -0.0010],
        [ 0.0041, -0.1461,  0.0003,  ...,  0.0079, -0.0029, -0.0097],
        [-0.0065, -0.0202, -0.1555,  ...,  0.0102, -0.0031,  0.0031],
        ...,
        [-0.0056, -0.0007,  0.0084,  ..., -0.1356, -0.0057, -0.0064],
        [-0.0109,  0.0070, -0.0118,  ...,  0.0036, -0.1232, -0.0090],
        [-0.0035, -0.0011, -0.0167,  ..., -0.0093,  0.0100, -0.1469]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2598,  0.0090,  0.0061,  ..., -0.0055, -0.0040, -0.0024],
        [ 0.0025, -0.2634, -0.0077,  ..., -0.0076,  0.0089,  0.0005],
        [-0.0029,  0.0154, -0.2573,  ...,  0.0054, -0.0110, -0.0217],
        ...,
        [-0.0107, -0.0080, -0.0043,  ..., -0.2808,  0.0165,  0.0074],
        [-0.0046, -0.0065, -0.0121,  ..., -0.0005, -0.2556, -0.0066],
        [-0.0155, -0.0121, -0.0154,  ..., -0.0048,  0.0059, -0.2852]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:55:44 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 15:55:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1509,  0.4058, -0.7056,  ..., -1.1240,  0.5479,  0.8335],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0335, -0.4714, -0.4258,  ..., -0.5474, -1.0537,  0.7744],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2249,  1.0205, -1.4648,  ..., -0.4785,  1.5830,  2.1680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3271, -0.6982, -0.2412,  ..., -0.8877, -0.5801,  0.2661],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:55:44 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:55:44 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 15:56:41 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 15:57:35 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 15:58:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3289e-03,  1.8768e-03,  4.0894e-03,  ..., -1.4668e-03,
         -5.0354e-04, -4.6387e-03],
        [ 1.4544e-03, -3.2825e-03,  1.7834e-03,  ...,  5.6601e-04,
          2.1286e-03, -7.3910e-05],
        [ 6.8970e-03, -1.3173e-04, -8.7051e-03,  ...,  6.6948e-04,
         -6.4011e-03,  2.4307e-04],
        ...,
        [-3.6120e-04,  2.8934e-03, -4.7836e-03,  ...,  5.4646e-04,
         -3.9368e-03,  4.3411e-03],
        [-4.8637e-03, -2.7752e-04, -2.7084e-03,  ..., -8.4066e-04,
         -5.9090e-03,  4.9858e-03],
        [ 2.3346e-03,  2.4724e-04, -4.1695e-03,  ..., -6.6519e-04,
          2.3232e-03,  1.1654e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0905,  0.0012,  0.0117,  ..., -0.0014,  0.0054, -0.0019],
        [ 0.0144, -0.0918, -0.0031,  ...,  0.0029,  0.0002, -0.0027],
        [ 0.0023, -0.0011, -0.0897,  ...,  0.0132,  0.0073, -0.0076],
        ...,
        [-0.0074, -0.0010,  0.0038,  ..., -0.0901, -0.0006,  0.0001],
        [ 0.0146, -0.0005, -0.0008,  ...,  0.0022, -0.0933,  0.0082],
        [ 0.0056, -0.0045, -0.0058,  ..., -0.0008, -0.0006, -0.0778]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.2285e-02, -4.1008e-05,  6.5422e-03,  ...,  1.3168e-02,
         -5.4245e-03,  2.8801e-03],
        [ 7.1640e-03, -1.1029e-01,  6.0921e-03,  ..., -8.0414e-03,
          6.0120e-03,  1.7757e-03],
        [-6.4049e-03, -1.1650e-02, -1.0175e-01,  ..., -7.0343e-03,
         -9.3079e-03,  2.1439e-02],
        ...,
        [-7.0724e-03, -4.8561e-03,  2.1019e-03,  ..., -9.3384e-02,
         -1.1311e-03, -7.3357e-03],
        [-5.2414e-03, -2.2583e-03, -5.6686e-03,  ...,  4.2343e-03,
         -9.6863e-02, -1.9188e-03],
        [-1.0590e-02,  1.7204e-03,  7.0305e-03,  ...,  1.3863e-02,
          1.5335e-03, -8.4656e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 15:58:32 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 15:58:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0924,  0.6143, -0.7998,  ..., -0.5098,  0.8555,  1.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3010, -0.6396, -0.2568,  ..., -0.6265, -0.6035,  0.6030],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6514,  1.1660, -1.0713,  ..., -0.3472,  2.3086,  2.6582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4792, -0.7041, -0.6958,  ..., -0.8672, -0.6641,  0.7920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 15:58:32 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 15:58:32 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 15:59:30 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 16:00:28 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 16:01:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.5564e-02,  1.0099e-03, -1.1139e-03,  ...,  4.9248e-03,
          8.0585e-05, -9.4414e-04],
        [-6.6490e-03,  1.7960e-02, -2.9316e-03,  ...,  2.7847e-04,
          1.6441e-03, -3.7651e-03],
        [-5.0468e-03,  1.1988e-03,  1.6403e-02,  ...,  1.3313e-03,
          1.6413e-03, -4.2391e-04],
        ...,
        [-8.1921e-04, -5.9986e-04,  6.8588e-03,  ...,  1.3947e-02,
         -8.2855e-03,  2.4681e-03],
        [-1.2178e-03, -4.3869e-04,  2.6646e-03,  ..., -1.2512e-03,
          1.8204e-02,  5.5618e-03],
        [ 4.7326e-05, -3.1509e-03, -1.4944e-03,  ..., -7.2708e-03,
         -8.7433e-03,  1.4984e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0883e-01, -6.8436e-03, -7.8430e-03,  ..., -6.9695e-03,
         -8.4877e-04,  1.4175e-02],
        [-5.4092e-03, -1.1493e-01, -6.4278e-03,  ...,  1.0872e-03,
         -3.0098e-03, -1.3214e-02],
        [ 1.3672e-02, -9.4604e-03, -1.0803e-01,  ..., -8.2626e-03,
          1.0727e-02, -1.5465e-02],
        ...,
        [-1.0971e-02, -9.7046e-03, -3.5942e-05,  ..., -1.0266e-01,
          1.0452e-02,  3.1986e-03],
        [ 4.5624e-03,  9.9564e-03,  2.1362e-03,  ...,  1.9302e-02,
         -1.2164e-01,  6.6280e-04],
        [-6.2294e-03, -4.7150e-03, -1.7929e-04,  ..., -1.6159e-02,
          1.3618e-02, -1.0181e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.8066e-01, -1.3962e-02, -3.7308e-03,  ..., -2.1271e-02,
          7.0229e-03,  8.9111e-03],
        [-1.0406e-02, -1.9507e-01,  7.4692e-03,  ..., -2.8038e-04,
         -2.4796e-04,  1.2184e-02],
        [ 3.1528e-03,  1.0468e-02, -1.6809e-01,  ..., -1.3618e-02,
          1.3359e-02, -6.7368e-03],
        ...,
        [-2.3346e-03, -9.6283e-03, -1.6079e-03,  ..., -1.8384e-01,
          1.6937e-02, -1.8682e-03],
        [ 3.9825e-03, -3.5286e-03,  1.1627e-02,  ...,  1.3351e-04,
         -1.8286e-01,  1.9398e-03],
        [ 9.3842e-03,  9.9106e-03,  4.2772e-04,  ..., -3.4981e-03,
          1.2901e-02, -1.7200e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:01:27 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 16:01:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1388,  0.4709, -0.6943,  ..., -0.2439,  0.7944,  1.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2272, -0.4392, -0.1631,  ..., -0.5415, -0.3240,  0.1085],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1572,  0.4932, -1.1699,  ..., -0.4941,  2.8359,  2.5957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2278, -1.5332, -1.5898,  ..., -1.5068, -0.1985,  1.2832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:01:27 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:01:27 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 16:02:24 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 16:03:21 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 16:04:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0021, -0.0027,  0.0015,  ..., -0.0031, -0.0133, -0.0009],
        [-0.0009,  0.0075, -0.0060,  ...,  0.0029, -0.0002, -0.0014],
        [-0.0014, -0.0029,  0.0023,  ...,  0.0028, -0.0012,  0.0016],
        ...,
        [ 0.0027, -0.0003, -0.0035,  ...,  0.0078, -0.0049,  0.0041],
        [ 0.0027,  0.0011,  0.0049,  ..., -0.0016,  0.0035,  0.0008],
        [ 0.0041,  0.0045,  0.0014,  ..., -0.0030,  0.0030,  0.0030]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0709, -0.0007, -0.0025,  ..., -0.0019, -0.0191, -0.0005],
        [ 0.0001, -0.0895, -0.0101,  ..., -0.0016,  0.0018,  0.0102],
        [-0.0038, -0.0081, -0.0828,  ..., -0.0034,  0.0063, -0.0101],
        ...,
        [-0.0106, -0.0165, -0.0032,  ..., -0.0784, -0.0002,  0.0007],
        [ 0.0046,  0.0013,  0.0082,  ...,  0.0126, -0.0779, -0.0056],
        [-0.0064,  0.0088,  0.0026,  ..., -0.0089, -0.0008, -0.1043]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1072, -0.0045,  0.0012,  ..., -0.0157,  0.0019, -0.0050],
        [ 0.0023, -0.1221, -0.0137,  ...,  0.0089, -0.0006,  0.0199],
        [-0.0035, -0.0027, -0.1287,  ..., -0.0082, -0.0047, -0.0018],
        ...,
        [-0.0038, -0.0170,  0.0033,  ..., -0.1205,  0.0074, -0.0011],
        [ 0.0049,  0.0188, -0.0025,  ...,  0.0079, -0.1086, -0.0100],
        [-0.0073,  0.0113, -0.0124,  ..., -0.0105,  0.0039, -0.1207]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:04:24 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 16:04:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3164,  0.5078, -0.4712,  ..., -0.1703,  1.0586,  1.2080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2913, -0.4434, -0.3828,  ..., -0.5034, -0.3750,  0.4324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8652, -0.1367, -1.3086,  ..., -1.0713,  2.8926,  3.1348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6494, -2.2539, -2.4883,  ..., -1.6064, -0.6123,  2.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:04:24 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:04:24 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 16:05:24 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 16:06:24 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 16:07:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0091, -0.0006, -0.0039,  ...,  0.0080, -0.0033,  0.0026],
        [ 0.0102,  0.0117, -0.0039,  ..., -0.0038,  0.0104, -0.0052],
        [ 0.0015, -0.0040,  0.0006,  ..., -0.0087, -0.0056, -0.0036],
        ...,
        [-0.0112, -0.0024, -0.0093,  ...,  0.0106, -0.0133,  0.0025],
        [ 0.0184, -0.0023,  0.0043,  ..., -0.0060,  0.0105,  0.0018],
        [ 0.0003,  0.0047,  0.0009,  ..., -0.0024, -0.0027,  0.0212]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1219, -0.0036, -0.0126,  ..., -0.0043, -0.0018,  0.0140],
        [ 0.0074, -0.1136,  0.0003,  ...,  0.0122,  0.0162, -0.0065],
        [ 0.0034,  0.0132, -0.1122,  ..., -0.0044, -0.0173,  0.0048],
        ...,
        [-0.0080, -0.0079, -0.0129,  ..., -0.1259, -0.0052, -0.0047],
        [-0.0035, -0.0151, -0.0046,  ...,  0.0217, -0.1246,  0.0092],
        [ 0.0203,  0.0100,  0.0056,  ...,  0.0019,  0.0139, -0.1266]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1526,  0.0113,  0.0016,  ..., -0.0060,  0.0087,  0.0068],
        [ 0.0056, -0.1704, -0.0033,  ...,  0.0113, -0.0063, -0.0073],
        [ 0.0024, -0.0016, -0.1691,  ..., -0.0037, -0.0141,  0.0053],
        ...,
        [ 0.0037, -0.0155,  0.0083,  ..., -0.1774, -0.0064, -0.0104],
        [-0.0030, -0.0087, -0.0229,  ...,  0.0233, -0.1630,  0.0091],
        [ 0.0224, -0.0026,  0.0044,  ...,  0.0072,  0.0137, -0.1566]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:07:27 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 16:07:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0308,  0.2354, -0.5386,  ..., -0.2316,  1.3193,  1.1973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0845, -0.8384, -0.8320,  ..., -0.8032, -0.1013,  0.6753],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0264, -0.3975, -1.6523,  ..., -1.0215,  3.0391,  3.5254],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3062, -2.9121, -2.2383,  ..., -0.7539, -0.3257,  2.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:07:27 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:07:27 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 16:08:31 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 16:09:35 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 16:10:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.9962e-03, -7.1487e-03,  5.8289e-03,  ...,  6.3629e-03,
         -5.4312e-04, -7.2403e-03],
        [-4.6234e-03,  1.3474e-02,  4.3640e-03,  ...,  3.8509e-03,
          8.5297e-03,  5.1003e-03],
        [-5.0621e-03, -3.7885e-04,  4.6883e-03,  ..., -2.8551e-05,
          9.1782e-03,  1.6804e-03],
        ...,
        [ 5.5351e-03, -2.4071e-03, -2.3613e-03,  ...,  9.3002e-03,
         -4.9133e-03, -7.8354e-03],
        [ 2.9697e-03, -2.4738e-03, -2.3956e-03,  ...,  6.5002e-03,
          3.8776e-03, -2.0409e-03],
        [ 2.1114e-03,  1.0498e-02,  1.6069e-03,  ..., -3.1471e-03,
          6.7520e-03, -1.9550e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0523, -0.0047,  0.0044,  ...,  0.0007,  0.0029, -0.0186],
        [-0.0124, -0.0454, -0.0004,  ...,  0.0085, -0.0131,  0.0082],
        [-0.0018,  0.0016, -0.0506,  ..., -0.0042, -0.0044,  0.0047],
        ...,
        [-0.0036,  0.0020, -0.0045,  ..., -0.0526,  0.0014, -0.0027],
        [ 0.0123,  0.0043, -0.0076,  ...,  0.0172, -0.0670,  0.0011],
        [-0.0003,  0.0127,  0.0152,  ...,  0.0064, -0.0114, -0.0658]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.0139e-02,  2.0409e-03, -6.7711e-03,  ...,  3.2635e-03,
         -5.5237e-03, -1.4160e-02],
        [ 3.7270e-03, -8.0872e-02,  5.9967e-03,  ...,  2.5444e-03,
         -1.1162e-02,  4.3640e-03],
        [ 8.1062e-06,  1.0376e-02, -9.5154e-02,  ..., -1.4587e-02,
         -8.6880e-04,  2.1420e-03],
        ...,
        [-6.3782e-03,  8.0643e-03, -8.0795e-03,  ..., -8.5266e-02,
          3.7117e-03,  2.3441e-03],
        [ 1.3313e-02,  1.0727e-02, -7.0801e-03,  ...,  9.6436e-03,
         -9.0271e-02,  1.8845e-03],
        [-5.2223e-03,  1.2825e-02,  1.8539e-02,  ...,  5.9776e-03,
         -2.4643e-03, -9.1797e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:10:41 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 16:10:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3921, -0.0657, -0.5381,  ..., -0.4507,  1.2461,  1.3027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3210, -1.0703, -1.1143,  ..., -0.7310, -0.2717,  0.9097],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5928,  0.6221, -0.8223,  ..., -1.3320,  2.9785,  3.6328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1938, -2.7539, -2.0000,  ..., -0.8428, -0.7007,  1.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:10:41 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:10:41 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 16:11:46 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 16:12:53 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 16:13:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2505e-02, -1.9131e-03,  1.2751e-03,  ...,  2.0771e-03,
         -1.6975e-04,  1.0353e-02],
        [-3.4046e-03, -8.7738e-03,  8.0466e-05,  ...,  1.7662e-03,
          2.9640e-03, -3.3169e-03],
        [-1.5097e-03,  1.2951e-03, -9.8648e-03,  ..., -9.4795e-04,
         -5.0449e-04, -3.9139e-03],
        ...,
        [ 2.0814e-04, -1.9398e-03,  1.1740e-03,  ..., -8.0795e-03,
          5.0163e-03, -4.9114e-04],
        [ 1.4567e-04,  9.3994e-03, -3.3894e-03,  ...,  2.8305e-03,
         -1.6220e-02,  2.5768e-03],
        [-1.4534e-03,  2.6474e-03, -1.1092e-04,  ..., -1.8826e-03,
         -3.5229e-03, -1.0506e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1022,  0.0086,  0.0125,  ..., -0.0172,  0.0097,  0.0011],
        [ 0.0274, -0.1110,  0.0075,  ..., -0.0134,  0.0204, -0.0179],
        [ 0.0184,  0.0031, -0.1122,  ...,  0.0046,  0.0004, -0.0164],
        ...,
        [ 0.0019, -0.0105,  0.0013,  ..., -0.0933,  0.0103, -0.0141],
        [ 0.0137,  0.0148, -0.0049,  ...,  0.0058, -0.1077, -0.0020],
        [ 0.0033,  0.0201, -0.0215,  ..., -0.0125, -0.0104, -0.0916]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1639e-01, -8.5983e-03,  5.3711e-03,  ..., -5.1003e-03,
          7.1049e-05,  1.5976e-02],
        [ 1.1681e-02, -1.0828e-01, -1.5144e-02,  ..., -1.4526e-02,
         -1.4877e-04, -1.7548e-02],
        [ 1.7731e-02,  5.0354e-04, -1.2830e-01,  ...,  4.9362e-03,
          2.2736e-03, -7.1716e-03],
        ...,
        [ 1.2016e-03, -2.2110e-02, -1.0330e-02,  ..., -1.2659e-01,
          5.4932e-03,  7.3929e-03],
        [-1.1559e-03,  1.4633e-02,  2.5589e-02,  ..., -1.4105e-03,
         -1.2170e-01, -6.7291e-03],
        [ 5.9433e-03,  9.3937e-04, -1.8425e-03,  ..., -4.7073e-03,
         -1.0895e-02, -1.0828e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:14:02 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 16:14:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0300, -0.1565, -0.6655,  ..., -0.4141,  1.2549,  1.4170],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1581, -1.3135, -1.0020,  ..., -0.3411, -0.1443,  1.0371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8057, -0.8496, -0.1323,  ..., -2.0566,  2.1426,  4.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4058, -4.5391, -1.9492,  ..., -1.0830, -1.2910,  0.8311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:14:02 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:14:02 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 16:15:08 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 16:16:18 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 16:17:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.4229e-03, -2.4281e-03, -6.9847e-03,  ...,  1.0672e-03,
          1.5059e-03, -2.8782e-03],
        [ 8.8692e-04, -1.8730e-03,  9.0694e-04,  ...,  9.3555e-04,
         -7.2527e-04,  2.1782e-03],
        [-1.4820e-03, -5.5313e-05,  4.1723e-04,  ...,  4.3869e-05,
          1.7529e-03, -1.6422e-03],
        ...,
        [-8.1825e-04, -3.9649e-04,  1.8120e-03,  ...,  1.4362e-03,
         -3.8147e-03, -1.2388e-03],
        [-2.1267e-03, -1.4486e-03,  1.9779e-03,  ..., -7.9727e-04,
         -1.6575e-03,  1.0853e-03],
        [ 2.7771e-03, -8.7929e-04, -1.0738e-03,  ...,  1.4000e-03,
         -1.3256e-03, -3.2120e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0551,  0.0032, -0.0080,  ...,  0.0128, -0.0222,  0.0019],
        [ 0.0102, -0.0654,  0.0001,  ..., -0.0088,  0.0009,  0.0124],
        [-0.0016,  0.0074, -0.0585,  ..., -0.0006,  0.0171, -0.0215],
        ...,
        [ 0.0054, -0.0062, -0.0118,  ..., -0.0703, -0.0137,  0.0014],
        [-0.0104, -0.0081,  0.0062,  ...,  0.0078, -0.0523,  0.0218],
        [-0.0093, -0.0003,  0.0148,  ...,  0.0016,  0.0140, -0.0760]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1173, -0.0031, -0.0072,  ..., -0.0117, -0.0156,  0.0036],
        [ 0.0217, -0.1279,  0.0020,  ...,  0.0027, -0.0013,  0.0010],
        [ 0.0139, -0.0063, -0.1179,  ..., -0.0111,  0.0107, -0.0140],
        ...,
        [ 0.0107, -0.0112, -0.0051,  ..., -0.1147,  0.0041,  0.0046],
        [-0.0142, -0.0090, -0.0129,  ..., -0.0057, -0.1100,  0.0142],
        [ 0.0066, -0.0011, -0.0043,  ...,  0.0019, -0.0009, -0.1311]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:17:31 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 16:17:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2463,  0.2395, -0.3372,  ..., -0.5259,  1.2031,  1.4209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0872, -1.2744, -0.9116,  ..., -0.3867, -0.3000,  0.4915],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0376, -0.3713,  0.2288,  ..., -1.2744,  2.3262,  3.6758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.3965, -4.8086, -0.5674,  ..., -0.8198, -0.9263,  1.6465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:17:31 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:17:31 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 16:18:41 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 16:19:53 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 16:21:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0132,  0.0007,  0.0063,  ...,  0.0042, -0.0091, -0.0116],
        [ 0.0047,  0.0166, -0.0072,  ...,  0.0085,  0.0016,  0.0012],
        [ 0.0001,  0.0035,  0.0130,  ..., -0.0110,  0.0033,  0.0055],
        ...,
        [-0.0015, -0.0028, -0.0070,  ...,  0.0144,  0.0010, -0.0014],
        [ 0.0026, -0.0092, -0.0070,  ...,  0.0091,  0.0241,  0.0047],
        [-0.0049,  0.0042,  0.0063,  ..., -0.0066, -0.0031,  0.0198]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0233, -0.0087,  0.0013,  ...,  0.0019,  0.0119,  0.0019],
        [ 0.0168, -0.0152, -0.0037,  ...,  0.0139,  0.0028, -0.0118],
        [-0.0297,  0.0137, -0.0145,  ..., -0.0044, -0.0049,  0.0127],
        ...,
        [ 0.0042, -0.0233, -0.0134,  ..., -0.0232, -0.0129, -0.0063],
        [ 0.0282, -0.0060, -0.0042,  ..., -0.0034, -0.0349, -0.0024],
        [-0.0084,  0.0062,  0.0180,  ..., -0.0094,  0.0115, -0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0547,  0.0058, -0.0024,  ..., -0.0175,  0.0039, -0.0040],
        [ 0.0051, -0.0328,  0.0084,  ...,  0.0097, -0.0064,  0.0116],
        [-0.0111,  0.0177, -0.0384,  ..., -0.0044, -0.0084,  0.0082],
        ...,
        [-0.0050,  0.0053, -0.0041,  ..., -0.0590, -0.0112, -0.0055],
        [-0.0002,  0.0022, -0.0098,  ..., -0.0032, -0.0397,  0.0116],
        [-0.0034, -0.0030,  0.0061,  ..., -0.0224,  0.0006, -0.0431]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:21:03 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 16:21:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2922, -0.3154, -0.0643,  ..., -0.7188,  0.7432,  1.5205],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1697, -1.8799, -0.7827,  ..., -0.4353, -0.5244,  0.3120],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3887, -0.7290,  0.3159,  ..., -2.0234,  0.9219,  3.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1152, -4.6875, -0.2466,  ..., -1.0918, -1.1875,  2.8086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:21:03 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:21:03 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 16:22:20 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 16:23:33 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 16:24:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.0942e-03, -1.0738e-03, -4.6806e-03,  ...,  2.5749e-04,
          3.6201e-03, -2.4433e-03],
        [ 2.8744e-03, -8.4915e-03, -3.6240e-03,  ..., -1.4277e-03,
         -6.8588e-03,  6.5384e-03],
        [-6.7997e-04,  1.2274e-03, -1.0284e-02,  ..., -2.3937e-03,
         -7.4911e-04, -4.7493e-04],
        ...,
        [-1.0128e-03,  1.2106e-04, -2.3003e-03,  ..., -9.2545e-03,
          2.2049e-03,  3.1586e-03],
        [-3.3927e-04,  9.7036e-05, -1.8082e-03,  ...,  2.0580e-03,
         -5.6190e-03, -3.5210e-03],
        [-8.1062e-04,  4.1351e-03,  2.6169e-03,  ...,  1.3685e-03,
          1.9798e-03, -9.9106e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0229, -0.0038,  0.0146,  ...,  0.0111,  0.0025, -0.0065],
        [-0.0098, -0.0425, -0.0011,  ...,  0.0131, -0.0132, -0.0010],
        [-0.0100,  0.0216, -0.0465,  ..., -0.0007,  0.0004, -0.0144],
        ...,
        [-0.0094,  0.0077, -0.0149,  ..., -0.0122, -0.0119, -0.0051],
        [ 0.0066,  0.0109, -0.0083,  ...,  0.0128, -0.0308,  0.0028],
        [ 0.0084, -0.0059,  0.0076,  ...,  0.0013,  0.0140, -0.0401]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0363,  0.0087,  0.0217,  ...,  0.0309,  0.0112,  0.0196],
        [-0.0142, -0.0854, -0.0099,  ...,  0.0119, -0.0038,  0.0182],
        [-0.0241, -0.0065, -0.0769,  ..., -0.0011,  0.0097, -0.0100],
        ...,
        [ 0.0039, -0.0072, -0.0115,  ..., -0.0366, -0.0053, -0.0097],
        [ 0.0320,  0.0209,  0.0083,  ...,  0.0166, -0.0554, -0.0279],
        [-0.0184, -0.0108,  0.0031,  ...,  0.0069,  0.0077, -0.0707]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:24:48 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 16:24:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0110, -0.1361,  0.0656,  ..., -0.4387,  0.7852,  1.2168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1549, -1.9131, -0.2321,  ..., -0.3347, -0.3557,  0.6260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6157, -0.6411,  0.9346,  ..., -2.1836,  0.7202,  3.6895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1870, -5.0430,  2.3926,  ...,  1.5879, -1.1777,  1.6904],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:24:48 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:24:48 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 16:26:09 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 16:27:31 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 16:28:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.1095e-03, -4.2725e-03,  3.8290e-04,  ..., -9.1791e-06,
          8.3780e-04,  5.5580e-03],
        [-1.8101e-03,  7.8735e-03,  2.3708e-03,  ...,  7.6828e-03,
          4.0932e-03,  5.5847e-03],
        [-3.1891e-03, -1.5569e-04,  1.4008e-02,  ...,  1.9855e-03,
          5.9166e-03, -2.1133e-03],
        ...,
        [-3.2768e-03,  5.8594e-03, -5.4245e-03,  ...,  1.3977e-02,
          2.4681e-03,  3.1548e-03],
        [ 3.5071e-04,  1.1187e-03,  4.3106e-03,  ...,  2.7294e-03,
          8.2703e-03, -2.8534e-03],
        [-5.8708e-03,  1.8387e-03, -4.2648e-03,  ..., -1.8120e-03,
          9.4299e-03,  9.7885e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0244, -0.0100, -0.0149,  ...,  0.0012,  0.0059,  0.0013],
        [-0.0092, -0.0380, -0.0218,  ..., -0.0009,  0.0175,  0.0029],
        [ 0.0124, -0.0116, -0.0255,  ...,  0.0015, -0.0031,  0.0165],
        ...,
        [-0.0026, -0.0119,  0.0010,  ..., -0.0353,  0.0005, -0.0079],
        [-0.0096,  0.0095, -0.0051,  ...,  0.0012, -0.0471, -0.0037],
        [-0.0102,  0.0168, -0.0052,  ..., -0.0164, -0.0059, -0.0421]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0628,  0.0113, -0.0063,  ...,  0.0047,  0.0192, -0.0136],
        [-0.0063, -0.0799, -0.0321,  ...,  0.0129,  0.0190,  0.0040],
        [ 0.0005,  0.0100, -0.0745,  ...,  0.0077, -0.0089,  0.0017],
        ...,
        [ 0.0117, -0.0188, -0.0248,  ..., -0.0714, -0.0063, -0.0089],
        [ 0.0190, -0.0038, -0.0217,  ..., -0.0070, -0.0948, -0.0005],
        [-0.0054,  0.0048, -0.0007,  ..., -0.0085, -0.0142, -0.0789]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:28:55 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 16:28:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1278, -0.2343,  0.0881,  ..., -0.6392,  0.3118,  0.9805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4185, -1.6963, -0.1024,  ..., -0.3914, -0.4321,  1.0322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9756, -0.7744,  2.8711,  ..., -2.5039,  1.5791,  4.0117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2427, -5.0000,  2.1719,  ...,  1.2256, -3.1055,  2.2461],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:28:55 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:28:55 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 16:30:18 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 16:31:39 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 16:32:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.5456e-04,  7.7772e-04,  5.5456e-04,  ...,  4.7874e-04,
         -3.7551e-04,  1.6689e-06],
        [-2.5511e-04, -1.5926e-03,  4.0531e-04,  ...,  1.0128e-03,
          4.5395e-04,  9.8324e-04],
        [ 1.1480e-04,  9.2983e-04, -1.7328e-03,  ...,  1.6141e-04,
         -1.8291e-03, -1.4677e-03],
        ...,
        [-8.1730e-04, -7.1526e-06,  9.7084e-04,  ..., -1.3561e-03,
          1.5917e-03, -4.8709e-04],
        [ 6.6614e-04, -2.7990e-04, -3.4094e-05,  ..., -4.2510e-04,
         -7.9441e-04,  4.5538e-05],
        [-1.3027e-03,  2.1601e-04,  6.0272e-04,  ..., -9.5069e-05,
          1.3981e-03, -1.2817e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.2718e-02,  1.6891e-02, -2.3098e-03,  ...,  7.5302e-03,
         -4.1389e-04,  6.8741e-03],
        [ 8.7891e-03, -3.0685e-02, -5.0812e-03,  ..., -1.0803e-02,
         -1.3580e-03, -2.1324e-03],
        [-5.6877e-03, -8.8043e-03, -3.8361e-02,  ...,  1.5774e-03,
          1.4572e-02,  3.6392e-03],
        ...,
        [ 5.9433e-03, -1.2693e-03, -7.0839e-03,  ..., -4.7394e-02,
         -4.7684e-06,  1.2695e-02],
        [ 1.7029e-02,  4.7874e-03, -2.6512e-03,  ...,  1.0330e-02,
         -3.7140e-02, -3.7746e-03],
        [ 1.4668e-03, -5.5809e-03, -6.5155e-03,  ..., -1.6136e-03,
         -2.0309e-02, -2.2766e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0632,  0.0093, -0.0149,  ...,  0.0173, -0.0359,  0.0034],
        [ 0.0210, -0.0491, -0.0117,  ..., -0.0019,  0.0067,  0.0014],
        [ 0.0025, -0.0100, -0.0648,  ..., -0.0138,  0.0114,  0.0113],
        ...,
        [ 0.0046,  0.0073, -0.0076,  ..., -0.0855, -0.0082,  0.0349],
        [ 0.0225,  0.0083, -0.0030,  ...,  0.0070, -0.0562, -0.0010],
        [ 0.0097,  0.0119, -0.0007,  ...,  0.0006, -0.0205, -0.0615]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:32:56 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 16:32:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2048, -0.1946,  0.2585,  ..., -0.6602,  0.2439,  1.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0753, -1.7363,  0.7949,  ...,  0.5513, -0.3975,  0.5713],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0000, -0.6270,  3.1504,  ..., -3.8047,  1.0371,  4.0312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2087, -4.8555,  3.0938,  ...,  1.7041, -3.8867,  2.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:32:56 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:32:56 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 16:34:13 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 16:35:28 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 16:36:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.9160e-03,  2.8458e-03,  2.9743e-05,  ..., -2.6369e-04,
         -5.7030e-03,  2.1954e-03],
        [-6.0558e-04, -7.5722e-03,  7.0000e-04,  ...,  5.2719e-03,
         -2.7618e-03, -7.1754e-03],
        [-3.0956e-03,  3.0117e-03, -1.2398e-02,  ..., -4.0102e-04,
          5.4665e-03,  4.1351e-03],
        ...,
        [ 6.3744e-03,  4.3869e-03, -1.3371e-03,  ..., -1.1383e-02,
         -1.0115e-04,  5.0259e-04],
        [ 5.6839e-04, -4.7913e-03,  1.0262e-03,  ..., -1.2541e-03,
         -9.7961e-03, -4.5090e-03],
        [-2.6393e-04, -2.5158e-03,  1.6775e-03,  ..., -1.5564e-03,
         -2.9297e-03, -1.4427e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0113,  0.0028,  0.0117,  ...,  0.0087,  0.0025,  0.0153],
        [ 0.0298, -0.0361,  0.0094,  ...,  0.0023,  0.0005, -0.0217],
        [ 0.0029,  0.0171, -0.0277,  ..., -0.0007,  0.0065,  0.0163],
        ...,
        [-0.0019,  0.0014,  0.0045,  ..., -0.0214,  0.0159,  0.0012],
        [-0.0116, -0.0219, -0.0083,  ..., -0.0043, -0.0345,  0.0156],
        [ 0.0129, -0.0267, -0.0061,  ..., -0.0040,  0.0078, -0.0237]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0759, -0.0069,  0.0086,  ...,  0.0035, -0.0036,  0.0132],
        [ 0.0055, -0.0896,  0.0246,  ...,  0.0059, -0.0005,  0.0151],
        [ 0.0570,  0.0066, -0.1031,  ..., -0.0008, -0.0170,  0.0071],
        ...,
        [-0.0028, -0.0170, -0.0024,  ..., -0.0801, -0.0070,  0.0031],
        [-0.0168, -0.0240, -0.0005,  ..., -0.0014, -0.1334, -0.0139],
        [-0.0077, -0.0354, -0.0040,  ..., -0.0011,  0.0250, -0.1123]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:36:46 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 16:36:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3044, -0.2015,  0.8159,  ..., -0.7544,  0.4934,  1.2119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0815, -1.6309,  0.6904,  ...,  0.4019, -1.0674,  0.7554],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9102,  0.0840,  3.7891,  ..., -3.9512,  1.1211,  4.9062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8496, -3.2812,  4.6328,  ...,  2.8398, -2.4766,  3.0488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:36:46 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:36:47 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 16:38:05 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 16:39:24 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 16:40:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.3030e-03,  1.1134e-04,  7.1824e-05,  ...,  6.7568e-04,
         -6.0892e-04, -5.5885e-04],
        [ 4.2152e-04,  1.7853e-03,  3.4046e-04,  ..., -2.5511e-05,
         -7.1621e-04,  8.9109e-05],
        [ 1.0872e-04,  3.1185e-04,  3.6793e-03,  ..., -5.1785e-04,
          9.2602e-04,  2.3627e-04],
        ...,
        [ 5.5850e-05,  2.1744e-04,  5.4932e-04,  ...,  4.0550e-03,
          7.1168e-05,  8.4817e-05],
        [ 6.0463e-04,  3.7491e-05, -3.1304e-04,  ...,  1.5430e-03,
          3.8929e-03, -4.7278e-04],
        [ 4.6825e-04, -1.3685e-03, -1.0757e-03,  ...,  8.8024e-04,
         -4.2439e-04,  4.8294e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0269, -0.0055, -0.0085,  ..., -0.0033,  0.0098,  0.0078],
        [-0.0202, -0.0012,  0.0124,  ...,  0.0175,  0.0036,  0.0238],
        [ 0.0086, -0.0072,  0.0165,  ...,  0.0090,  0.0045, -0.0043],
        ...,
        [-0.0298, -0.0023, -0.0147,  ...,  0.0575, -0.0088, -0.0037],
        [ 0.0117, -0.0062, -0.0126,  ...,  0.0251,  0.0184,  0.0179],
        [ 0.0140, -0.0095, -0.0174,  ..., -0.0126,  0.0088,  0.0317]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0114,  0.0091,  0.0037,  ...,  0.0104, -0.0032,  0.0162],
        [-0.0202, -0.0260,  0.0156,  ...,  0.0160, -0.0102,  0.0180],
        [-0.0124, -0.0067, -0.0320,  ...,  0.0274,  0.0158,  0.0035],
        ...,
        [-0.0094, -0.0095, -0.0131,  ...,  0.0052,  0.0176, -0.0070],
        [-0.0044, -0.0115, -0.0201,  ..., -0.0020, -0.0227,  0.0149],
        [ 0.0111,  0.0091, -0.0070,  ...,  0.0061, -0.0038, -0.0064]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:40:43 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 16:40:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6099, -0.1525,  0.8618,  ..., -1.1328,  0.2971,  1.1602],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0932, -1.5352,  0.9805,  ...,  0.5254, -1.3008,  0.9136],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6616, -0.2654,  3.8438,  ..., -3.7910,  1.2988,  4.9766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6357, -4.2188,  5.7109,  ...,  2.6445, -3.2383,  3.9434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:40:43 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:40:43 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 16:42:07 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 16:43:31 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 16:44:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2888e-04, -3.7742e-04, -5.7220e-06,  ..., -1.1259e-04,
          4.3583e-04,  4.8518e-05],
        [ 3.2425e-04, -9.0301e-05,  1.1683e-04,  ...,  5.0545e-05,
          1.2958e-04, -3.4618e-04],
        [-1.5392e-03, -5.5790e-05,  4.4298e-04,  ..., -2.2578e-04,
          4.3297e-04,  1.7977e-04],
        ...,
        [ 8.5533e-05, -5.8174e-05, -3.3331e-04,  ...,  9.1410e-04,
          4.0531e-04, -2.3508e-04],
        [ 6.4754e-04,  3.4237e-04, -1.2791e-04,  ..., -9.2983e-06,
          5.5790e-04,  6.3300e-05],
        [-2.5368e-04, -4.6968e-04,  3.9506e-04,  ...,  3.3498e-05,
          1.2577e-04,  3.1304e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0112,  0.0075,  0.0124,  ...,  0.0003, -0.0025,  0.0070],
        [-0.0093, -0.0267,  0.0055,  ...,  0.0043,  0.0061, -0.0187],
        [ 0.0204,  0.0091,  0.0054,  ...,  0.0015, -0.0084,  0.0053],
        ...,
        [-0.0066, -0.0010, -0.0094,  ...,  0.0188,  0.0126,  0.0002],
        [-0.0008,  0.0101, -0.0011,  ..., -0.0008, -0.0087,  0.0100],
        [-0.0036,  0.0161, -0.0069,  ...,  0.0165,  0.0021, -0.0068]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0313, -0.0160,  0.0197,  ...,  0.0183,  0.0024,  0.0079],
        [ 0.0153, -0.0595,  0.0110,  ...,  0.0100, -0.0031,  0.0225],
        [ 0.0122, -0.0032,  0.0129,  ..., -0.0110, -0.0085,  0.0119],
        ...,
        [-0.0090, -0.0154, -0.0185,  ..., -0.0261, -0.0071, -0.0149],
        [ 0.0036,  0.0191, -0.0336,  ...,  0.0091, -0.0589,  0.0157],
        [ 0.0116,  0.0132, -0.0297,  ...,  0.0095,  0.0092, -0.0294]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:44:56 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 16:44:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2947,  0.0489,  0.8989,  ..., -1.1260,  0.2654,  1.2568],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2219, -0.9692,  1.3477,  ...,  0.7803, -0.7979,  0.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3418,  0.1265,  1.3203,  ..., -5.1406,  1.7412,  3.8379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4395, -3.6953,  4.6758,  ...,  1.8408, -3.2441,  3.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:44:56 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:44:56 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 16:46:20 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 16:47:45 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 16:49:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.5000e-04,  1.5938e-04,  6.4433e-05,  ...,  3.7336e-04,
         -3.0756e-04, -2.8467e-04],
        [ 4.3297e-04, -1.0312e-05,  9.4473e-05,  ...,  2.1672e-04,
          3.3474e-04,  3.7050e-04],
        [ 5.5552e-04, -7.8630e-04,  6.9809e-04,  ..., -1.3900e-04,
         -4.8733e-04,  2.2018e-04],
        ...,
        [-1.3757e-04,  3.6669e-04, -1.9956e-04,  ...,  1.4696e-03,
          3.4952e-04,  2.5797e-04],
        [-2.7466e-04, -6.2370e-04,  5.7638e-05,  ..., -8.1301e-05,
          5.8270e-04, -1.6212e-04],
        [-6.2585e-06,  4.8876e-04,  7.5221e-05,  ..., -1.9610e-05,
         -2.2411e-04,  1.1635e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0354, -0.0064, -0.0002,  ...,  0.0076,  0.0151, -0.0079],
        [ 0.0157, -0.0105,  0.0099,  ..., -0.0172,  0.0076, -0.0003],
        [-0.0312,  0.0068,  0.0216,  ..., -0.0176, -0.0064,  0.0061],
        ...,
        [ 0.0022,  0.0026,  0.0032,  ...,  0.0726, -0.0025, -0.0111],
        [ 0.0055,  0.0027, -0.0359,  ..., -0.0102,  0.0409,  0.0149],
        [-0.0214,  0.0245,  0.0047,  ...,  0.0111, -0.0106,  0.0505]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0375, -0.0136,  0.0285,  ..., -0.0159,  0.0294, -0.0105],
        [ 0.0389, -0.0466, -0.0203,  ..., -0.0116,  0.0077, -0.0077],
        [-0.0326, -0.0054, -0.0337,  ..., -0.0140, -0.0239,  0.0322],
        ...,
        [ 0.0069, -0.0011, -0.0331,  ..., -0.0382,  0.0181,  0.0010],
        [ 0.0041,  0.0133, -0.0131,  ...,  0.0119, -0.0323,  0.0123],
        [-0.0084,  0.0132,  0.0226,  ..., -0.0005, -0.0182, -0.0078]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:49:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leopard falls into the category of feline
The jackal falls into the category of canine
The gorilla falls into the category of primate
The falcon falls into the category of raptor
The vulture falls into the category of raptor
The goat falls into the category of bovid
The butterfly falls into the category of insect
The allosaurus falls into the category of
2024-06-30 16:49:09 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 16:49:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1583, -1.3867, -0.7720,  ...,  0.5103, -1.0312,  0.1748],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4592, -0.1163, -0.5713,  ..., -0.1368, -0.9385, -0.3774],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3418, -0.7490, -1.2578,  ...,  0.1375, -0.6616, -0.1639],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4861,  0.0976, -0.2651,  ..., -0.5195, -0.4253, -0.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:49:09 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 16:49:09 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 16:49:33 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 16:49:56 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 16:50:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.5374e-04, -6.3848e-04,  1.6022e-04,  ..., -1.5974e-05,
          4.1533e-04,  1.8597e-04],
        [ 5.2834e-04, -3.3998e-04, -1.5783e-04,  ..., -2.7466e-04,
          2.4271e-04,  1.0908e-05],
        [-3.5405e-04, -4.9448e-04, -1.0509e-03,  ..., -1.2022e-04,
         -1.3828e-04, -9.9599e-05],
        ...,
        [ 3.1137e-04, -2.8229e-04,  1.9264e-04,  ..., -8.2493e-05,
          9.6679e-05,  3.8147e-05],
        [ 8.4043e-05,  1.7619e-04, -2.4128e-04,  ..., -2.0933e-04,
         -6.5708e-04, -1.0812e-04],
        [ 6.7472e-04, -3.4273e-05,  1.4067e-04,  ..., -5.2691e-04,
         -2.6870e-04, -5.6839e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0347, -0.0027,  0.0022,  ...,  0.0035, -0.0110, -0.0042],
        [-0.0095, -0.0314,  0.0018,  ...,  0.0045,  0.0043, -0.0033],
        [ 0.0059, -0.0036, -0.0330,  ..., -0.0004,  0.0102, -0.0014],
        ...,
        [-0.0027,  0.0006,  0.0072,  ..., -0.0338,  0.0032,  0.0011],
        [-0.0064,  0.0035, -0.0041,  ...,  0.0027, -0.0265,  0.0002],
        [-0.0004,  0.0016,  0.0044,  ..., -0.0039,  0.0047, -0.0308]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0716e-02,  4.0054e-05,  6.5575e-03,  ..., -7.5436e-04,
         -1.7452e-03,  6.9189e-04],
        [ 9.4748e-04, -2.6138e-02, -6.3477e-03,  ..., -2.1477e-03,
          2.2678e-03,  5.7650e-04],
        [-2.6941e-04,  2.3689e-03, -2.4963e-02,  ..., -2.4128e-04,
         -2.1553e-03,  5.4855e-03],
        ...,
        [ 2.0504e-03,  3.9978e-03,  8.2445e-04,  ..., -2.2522e-02,
          2.5711e-03,  2.5539e-03],
        [-1.6861e-03,  2.0447e-03, -1.1849e-04,  ..., -4.6945e-04,
         -2.5421e-02,  9.3842e-04],
        [-3.3808e-04, -2.5787e-03, -2.7905e-03,  ...,  9.0837e-04,
          6.7234e-05, -2.7939e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:50:20 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 16:50:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0699, -1.2412, -1.4434,  ...,  0.2764, -1.0020, -0.2350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5596,  0.1760, -0.3423,  ..., -1.0283, -0.4744, -0.4487],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1960, -0.8115, -1.2197,  ..., -0.0353, -0.6279, -0.0861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2046, -0.1721,  0.2144,  ..., -1.1621, -0.5669, -0.5117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:50:20 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 16:50:20 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 16:50:43 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 16:51:07 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 16:51:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.4008e-03, -6.0606e-04, -8.1825e-04,  ..., -1.0958e-03,
         -4.5562e-04, -6.6948e-04],
        [ 3.8719e-04, -5.1079e-03, -2.6941e-04,  ...,  1.0796e-03,
         -8.2636e-04,  6.7520e-04],
        [ 4.9233e-05,  1.3952e-03, -4.8409e-03,  ..., -5.4312e-04,
         -7.7486e-05, -5.6124e-04],
        ...,
        [-1.2660e-04,  3.9053e-04,  4.7624e-05,  ..., -4.2419e-03,
         -1.0042e-03, -1.4663e-05],
        [ 6.5386e-05,  9.7847e-04,  1.1311e-03,  ..., -1.2010e-04,
         -4.9706e-03, -4.4560e-04],
        [-4.1485e-04, -1.8799e-04,  5.8770e-05,  ...,  3.7003e-04,
          5.0402e-04, -4.5090e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.8147e-02, -4.6654e-03, -8.6365e-03,  ..., -3.6182e-03,
          4.7455e-03,  5.7983e-03],
        [ 3.0975e-03, -3.5675e-02, -4.8904e-03,  ...,  5.7983e-03,
         -1.1322e-02,  3.9558e-03],
        [-5.3062e-03, -2.0790e-03, -3.3875e-02,  ..., -4.6082e-03,
         -7.7362e-03, -1.2207e-03],
        ...,
        [ 3.4924e-03,  6.4392e-03, -8.4877e-05,  ..., -4.0497e-02,
         -1.9608e-03,  2.5005e-03],
        [ 3.3703e-03, -2.7962e-03, -7.3509e-03,  ..., -1.5488e-03,
         -2.9755e-02,  3.3226e-03],
        [ 6.4697e-03, -5.0926e-03,  9.1705e-03,  ...,  6.4468e-03,
         -2.4796e-05, -5.0018e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0599,  0.0003, -0.0036,  ...,  0.0064,  0.0048,  0.0022],
        [-0.0007, -0.0641, -0.0030,  ..., -0.0003, -0.0012, -0.0041],
        [ 0.0010,  0.0034, -0.0612,  ...,  0.0027,  0.0033,  0.0006],
        ...,
        [ 0.0024, -0.0045,  0.0006,  ..., -0.0577, -0.0064, -0.0098],
        [-0.0078, -0.0055,  0.0038,  ..., -0.0064, -0.0623,  0.0046],
        [ 0.0019, -0.0126,  0.0061,  ...,  0.0030,  0.0017, -0.0532]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:51:33 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 16:51:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4292, -0.9316, -1.4844,  ...,  0.1544, -0.7725, -0.2272],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7861,  0.1384, -0.4148,  ..., -0.7754, -0.6553, -0.8467],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2249, -1.2627, -0.9307,  ...,  0.4116, -0.3296,  0.2216],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3599,  0.3821, -0.0164,  ..., -0.8774, -0.8115, -0.8481],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:51:33 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 16:51:33 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 16:51:58 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 16:52:23 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 16:52:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.9926e-03, -8.6367e-05, -4.1676e-04,  ...,  3.7575e-04,
          2.4724e-04,  5.4240e-05],
        [ 4.5538e-05, -2.0256e-03,  1.7178e-04,  ...,  1.5879e-04,
          1.6391e-05,  2.6989e-04],
        [ 1.0049e-04, -7.4863e-04, -2.5158e-03,  ...,  3.9363e-04,
          5.1403e-04, -1.9991e-04],
        ...,
        [ 3.5787e-04,  8.1968e-04,  6.4039e-04,  ..., -2.1515e-03,
          3.0100e-05, -2.8396e-04],
        [-1.3196e-04,  6.8426e-05, -4.3726e-04,  ...,  6.3467e-04,
         -2.1172e-03, -5.9748e-04],
        [-6.4433e-05,  3.9649e-04, -1.3804e-04,  ...,  2.4140e-05,
         -2.0075e-04, -1.4944e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.1255e-02, -8.0109e-05,  4.0131e-03,  ...,  8.7662e-03,
          6.8512e-03, -2.4090e-03],
        [-6.5155e-03, -3.6072e-02, -5.6038e-03,  ..., -1.1925e-02,
          3.0136e-04, -3.7136e-03],
        [ 6.2256e-03, -2.5253e-03, -2.6337e-02,  ...,  3.9482e-04,
          1.7281e-03,  4.5013e-03],
        ...,
        [ 7.5769e-04,  3.1528e-03, -6.8092e-03,  ..., -2.2766e-02,
          5.0201e-03,  5.5199e-03],
        [ 3.9940e-03,  3.8147e-06, -6.8016e-03,  ...,  1.6937e-03,
         -2.1973e-02,  9.8267e-03],
        [ 8.1024e-03,  2.8095e-03, -9.2316e-03,  ...,  1.3550e-02,
          8.0948e-03, -2.9526e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.9144e-02,  3.8862e-05, -3.3340e-03,  ...,  1.9493e-03,
          1.4009e-03,  4.8676e-03],
        [-3.4065e-03, -3.2593e-02, -1.3580e-03,  ...,  7.0038e-03,
          3.9787e-03,  1.8339e-03],
        [ 2.0456e-04, -3.1900e-04, -3.5980e-02,  ..., -2.6054e-03,
         -4.1580e-03, -5.5161e-03],
        ...,
        [ 1.3657e-03,  1.0204e-03, -2.2278e-03,  ..., -2.9816e-02,
         -5.4550e-03,  4.3411e-03],
        [-1.9264e-03,  1.9836e-03, -3.2101e-03,  ..., -5.6648e-03,
         -3.0777e-02,  9.0408e-03],
        [ 2.5997e-03,  5.7182e-03,  3.1796e-03,  ..., -5.4550e-03,
          1.2169e-03, -3.1097e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:52:50 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 16:52:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2656, -1.0244, -1.4395,  ..., -0.0386, -0.7617, -0.1459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3188, -0.2729,  0.3083,  ..., -1.5957, -0.8140, -0.7925],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2930, -1.1602, -1.0010,  ...,  0.5840, -0.0281,  0.3364],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1860,  0.5869, -0.4958,  ..., -1.0234, -0.3889, -0.5562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:52:50 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 16:52:50 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 16:53:20 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 16:53:50 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 16:54:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.9741e-04,  3.9387e-04, -3.9983e-04,  ...,  1.5354e-04,
         -5.6171e-04, -1.9622e-04],
        [-5.1498e-05, -1.7405e-03, -8.4400e-05,  ...,  2.4796e-05,
          3.0661e-04, -2.5606e-04],
        [-5.0831e-04,  8.8871e-05, -1.1759e-03,  ...,  7.9632e-04,
          2.7514e-04,  6.0081e-04],
        ...,
        [-1.5736e-05, -4.4513e-04, -3.8052e-04,  ..., -3.8242e-04,
         -1.3704e-03, -8.3506e-05],
        [-7.7438e-04, -1.1325e-04,  5.4073e-04,  ..., -6.1560e-04,
         -1.2994e-05, -4.3464e-04],
        [-5.7995e-05, -9.7930e-05, -5.2023e-04,  ..., -2.1291e-04,
         -4.8637e-04, -1.7977e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0472,  0.0003, -0.0019,  ..., -0.0089,  0.0024,  0.0009],
        [-0.0022, -0.0384, -0.0078,  ..., -0.0034, -0.0054,  0.0050],
        [-0.0039, -0.0155, -0.0375,  ..., -0.0001, -0.0023,  0.0014],
        ...,
        [-0.0063,  0.0014, -0.0032,  ..., -0.0383, -0.0007,  0.0041],
        [-0.0077,  0.0022, -0.0015,  ..., -0.0060, -0.0414, -0.0105],
        [ 0.0084, -0.0071, -0.0063,  ...,  0.0039, -0.0070, -0.0337]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0570,  0.0031, -0.0001,  ..., -0.0042,  0.0101, -0.0082],
        [ 0.0042, -0.0460, -0.0014,  ...,  0.0007,  0.0001,  0.0007],
        [-0.0005, -0.0044, -0.0399,  ...,  0.0044, -0.0020,  0.0006],
        ...,
        [-0.0048, -0.0086,  0.0010,  ..., -0.0599,  0.0005, -0.0131],
        [-0.0003,  0.0022, -0.0126,  ..., -0.0042, -0.0384, -0.0082],
        [-0.0013, -0.0019,  0.0016,  ..., -0.0039, -0.0025, -0.0505]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:54:17 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 16:54:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2023, -1.3291, -0.8691,  ...,  0.3665, -0.2920,  0.1818],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3740,  0.3623, -0.0083,  ..., -0.8472, -0.7979, -0.9321],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3857, -1.0654, -0.5498,  ...,  0.9746, -0.2883,  0.1709],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0103,  0.1167, -0.2651,  ..., -0.7861, -0.3979, -0.7329],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:54:17 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 16:54:17 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 16:54:50 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 16:55:23 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 16:55:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.4663e-04,  1.5965e-03, -1.2617e-03,  ...,  1.7319e-03,
          3.3641e-04,  5.4121e-04],
        [ 9.5749e-04,  1.5850e-03, -8.6880e-04,  ...,  9.7156e-06,
         -2.7919e-04, -3.6621e-04],
        [ 2.5630e-04,  8.0824e-04, -9.8419e-04,  ..., -6.9332e-04,
         -4.1866e-04,  1.3781e-03],
        ...,
        [-6.5327e-04,  1.5235e-04, -8.7929e-04,  ..., -1.6851e-03,
         -1.4019e-03,  2.2850e-03],
        [-1.3614e-04,  3.9315e-04, -1.2140e-03,  ..., -4.6253e-04,
         -8.3983e-05, -7.1573e-04],
        [ 1.7643e-05, -8.8072e-04, -5.3501e-04,  ...,  4.1318e-04,
         -5.8770e-05, -1.7471e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0583,  0.0153,  0.0033,  ...,  0.0005, -0.0077, -0.0084],
        [-0.0003, -0.0551,  0.0095,  ..., -0.0044,  0.0021,  0.0112],
        [ 0.0081, -0.0012, -0.0557,  ..., -0.0173,  0.0057, -0.0073],
        ...,
        [ 0.0034,  0.0031, -0.0190,  ..., -0.0506, -0.0039,  0.0009],
        [ 0.0035, -0.0105, -0.0090,  ..., -0.0047, -0.0626,  0.0074],
        [-0.0051, -0.0035, -0.0031,  ..., -0.0020,  0.0015, -0.0669]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0681e-01,  3.2730e-03,  1.4259e-02,  ..., -7.6294e-04,
         -2.9068e-03, -4.3831e-03],
        [ 4.2000e-03, -1.1560e-01,  3.1719e-03,  ..., -3.7193e-03,
         -7.0114e-03, -8.4991e-03],
        [ 1.8120e-04,  3.6964e-03, -1.1371e-01,  ...,  2.9945e-03,
          8.4839e-03,  2.5711e-03],
        ...,
        [-4.9591e-04,  1.4896e-03,  3.1776e-03,  ..., -1.0181e-01,
          1.0674e-02,  1.0223e-03],
        [-1.4534e-03,  5.7697e-05,  4.6692e-03,  ..., -4.5509e-03,
         -1.0889e-01,  6.7062e-03],
        [-2.0752e-03, -3.4904e-04, -1.0681e-03,  ..., -3.1300e-03,
          6.9923e-03, -1.0968e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:55:59 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 16:55:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2551, -1.0684, -0.8560,  ...,  0.4983, -0.0435,  0.2795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2024,  0.6421, -0.5225,  ..., -1.0605, -0.4319, -0.6372],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3870, -1.1191, -0.6807,  ...,  0.5923, -0.5605,  0.4443],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2021,  0.0928, -0.4797,  ..., -0.2505, -0.5928, -0.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:55:59 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 16:55:59 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 16:56:34 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 16:57:03 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 16:57:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0030, -0.0002,  0.0013,  ..., -0.0006,  0.0002,  0.0008],
        [ 0.0002, -0.0033,  0.0028,  ...,  0.0003,  0.0024, -0.0011],
        [-0.0010,  0.0017, -0.0043,  ..., -0.0009, -0.0005, -0.0018],
        ...,
        [ 0.0007, -0.0002,  0.0008,  ..., -0.0029,  0.0003, -0.0013],
        [ 0.0032, -0.0012,  0.0002,  ..., -0.0006, -0.0009, -0.0014],
        [ 0.0003,  0.0014,  0.0018,  ..., -0.0012, -0.0012,  0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.1177e-02,  9.8953e-03, -1.6556e-03,  ...,  5.3329e-03,
          1.3018e-03,  1.1169e-02],
        [ 1.7624e-03, -8.3923e-02,  4.0321e-03,  ..., -1.1818e-02,
         -2.2354e-03,  8.0299e-04],
        [ 1.3626e-02, -9.4414e-05, -8.3374e-02,  ...,  4.7455e-03,
          4.1656e-03, -3.2578e-03],
        ...,
        [-4.7607e-03,  2.0866e-03, -2.1076e-03,  ..., -6.5369e-02,
         -3.4504e-03, -1.1578e-03],
        [-6.1722e-03, -6.7329e-03, -1.5335e-03,  ..., -5.7030e-03,
         -7.9346e-02, -6.0959e-03],
        [-2.5082e-03,  6.7186e-04,  3.4275e-03,  ..., -1.2840e-02,
         -3.4466e-03, -8.4717e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1082,  0.0101, -0.0094,  ...,  0.0009,  0.0039, -0.0035],
        [ 0.0030, -0.1082, -0.0043,  ...,  0.0028, -0.0044,  0.0052],
        [ 0.0017,  0.0003, -0.0989,  ..., -0.0050,  0.0077, -0.0023],
        ...,
        [-0.0015, -0.0059,  0.0013,  ..., -0.1011, -0.0056, -0.0046],
        [ 0.0008,  0.0038, -0.0047,  ...,  0.0033, -0.1016, -0.0017],
        [-0.0025, -0.0024, -0.0048,  ..., -0.0088, -0.0005, -0.1021]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:57:37 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 16:57:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3069, -0.8779, -0.4390,  ...,  0.7124, -0.2377,  0.1042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0111,  0.1306, -0.2590,  ..., -0.7427, -0.3855, -0.7651],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5288, -0.8320, -0.8340,  ...,  0.2344, -0.4990,  0.6382],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2341,  0.0418, -0.6660,  ..., -1.0723, -0.6187, -0.8135],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:57:37 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 16:57:37 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 16:58:16 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 16:58:56 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 16:59:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2608e-03, -4.7874e-04, -2.9564e-05,  ...,  5.6219e-04,
         -1.3380e-03,  4.1580e-04],
        [ 3.3998e-04, -1.5125e-03, -6.4754e-04,  ..., -2.0337e-04,
          8.2684e-04, -1.0824e-03],
        [ 7.3767e-04, -8.5211e-04, -3.8433e-03,  ..., -8.8978e-04,
          5.8711e-05, -1.3485e-03],
        ...,
        [ 7.7724e-04, -1.9102e-03,  7.5674e-04,  ..., -3.6411e-03,
          1.2894e-03,  1.4782e-03],
        [ 2.1112e-04, -1.8990e-04, -1.3018e-03,  ...,  3.4976e-04,
         -1.5230e-03, -5.9319e-04],
        [ 6.3515e-04, -2.4014e-03,  9.7561e-04,  ..., -2.8038e-03,
          7.0572e-04, -2.1725e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0689,  0.0092,  0.0071,  ..., -0.0180,  0.0019,  0.0216],
        [ 0.0033, -0.0701,  0.0120,  ...,  0.0108,  0.0106, -0.0005],
        [ 0.0017, -0.0042, -0.0654,  ...,  0.0054, -0.0111,  0.0037],
        ...,
        [ 0.0031, -0.0045,  0.0148,  ..., -0.0810, -0.0061,  0.0072],
        [ 0.0035, -0.0038, -0.0050,  ..., -0.0025, -0.0810, -0.0034],
        [ 0.0142, -0.0060,  0.0036,  ..., -0.0138, -0.0043, -0.0724]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0956e-01, -3.0098e-03,  7.1831e-03,  ..., -1.5480e-02,
         -1.4824e-02,  1.5011e-03],
        [ 7.7553e-03, -9.4482e-02, -1.5091e-02,  ...,  7.8735e-03,
          5.3825e-03, -2.2602e-03],
        [-2.2259e-03, -3.0365e-03, -9.4604e-02,  ..., -2.8610e-03,
          5.7220e-05, -6.5041e-04],
        ...,
        [-1.0176e-03, -6.7024e-03,  5.6152e-03,  ..., -1.0785e-01,
          1.0483e-02, -2.0504e-03],
        [ 1.0147e-03,  1.1501e-03,  3.5405e-04,  ...,  1.3046e-02,
         -1.1090e-01, -3.3760e-03],
        [ 1.9951e-03, -5.2223e-03,  8.4839e-03,  ...,  2.8744e-03,
          1.4629e-03, -1.0187e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 16:59:38 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 16:59:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3140, -0.9429, -0.5332,  ...,  0.4380, -0.4478,  0.3408],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1959,  0.0874, -0.4597,  ..., -0.2316, -0.5747, -0.7534],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2271, -0.8096, -1.0439,  ...,  0.0570, -0.6455,  0.6675],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2590, -1.0713, -0.9517,  ..., -1.4502, -0.7490, -0.2974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 16:59:38 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 16:59:38 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 17:00:20 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 17:01:01 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 17:01:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.8280e-03, -9.0003e-05, -1.1215e-03,  ...,  7.5912e-04,
          3.5763e-04, -8.1968e-04],
        [-8.8358e-04, -1.3199e-03,  2.3329e-04,  ..., -4.0550e-03,
          8.2552e-05, -1.6174e-03],
        [-4.2319e-06,  6.3658e-04, -1.6079e-03,  ...,  1.1425e-03,
          7.8630e-04,  2.5749e-04],
        ...,
        [ 6.2466e-05,  1.8568e-03, -1.0357e-03,  ...,  1.2751e-03,
          2.4929e-03,  8.3447e-04],
        [ 4.6015e-05, -1.0929e-03, -1.3089e-04,  ...,  2.3723e-04,
         -4.9248e-03, -6.3562e-04],
        [ 9.3269e-04,  1.3828e-03,  1.9026e-04,  ...,  9.7847e-04,
          8.9264e-04, -1.1129e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0571,  0.0013, -0.0018,  ..., -0.0012, -0.0036,  0.0105],
        [-0.0082, -0.0863,  0.0008,  ..., -0.0056,  0.0047,  0.0021],
        [-0.0037,  0.0113, -0.0728,  ..., -0.0081, -0.0068,  0.0060],
        ...,
        [-0.0058,  0.0005, -0.0129,  ..., -0.0697,  0.0041, -0.0002],
        [-0.0004,  0.0073,  0.0006,  ..., -0.0003, -0.0685,  0.0242],
        [ 0.0063,  0.0105, -0.0051,  ...,  0.0007,  0.0005, -0.0784]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0983,  0.0141, -0.0046,  ..., -0.0023,  0.0062, -0.0010],
        [ 0.0052, -0.1021,  0.0016,  ..., -0.0089, -0.0110,  0.0109],
        [-0.0018, -0.0018, -0.1014,  ..., -0.0047, -0.0117,  0.0075],
        ...,
        [ 0.0036,  0.0072, -0.0100,  ..., -0.0984, -0.0060, -0.0028],
        [-0.0058,  0.0031, -0.0008,  ..., -0.0019, -0.1041,  0.0076],
        [-0.0004,  0.0033, -0.0111,  ...,  0.0019,  0.0027, -0.1027]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:01:43 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 17:01:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3682, -0.6294, -0.6382,  ...,  0.1387, -0.3735,  0.4580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2283,  0.0356, -0.6196,  ..., -0.9170, -0.5518, -0.7598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2208,  0.1875, -0.6553,  ...,  0.4883, -0.4985,  0.0625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1360, -0.4985, -0.5972,  ..., -1.5830, -0.5732, -0.2125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:01:43 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:01:43 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 17:02:31 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 17:03:21 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 17:04:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0025,  0.0011,  0.0026,  ..., -0.0047, -0.0008, -0.0033],
        [ 0.0036, -0.0032, -0.0010,  ..., -0.0010, -0.0007,  0.0049],
        [ 0.0004,  0.0020,  0.0035,  ..., -0.0030,  0.0016, -0.0030],
        ...,
        [-0.0009, -0.0027, -0.0005,  ..., -0.0014, -0.0035, -0.0036],
        [-0.0067, -0.0007,  0.0018,  ..., -0.0025, -0.0025,  0.0017],
        [-0.0016, -0.0014,  0.0017,  ..., -0.0029,  0.0008,  0.0024]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0822, -0.0149,  0.0103,  ..., -0.0239,  0.0174,  0.0062],
        [ 0.0030, -0.0920,  0.0019,  ...,  0.0019,  0.0006, -0.0043],
        [-0.0016, -0.0080, -0.0599,  ..., -0.0009,  0.0028, -0.0187],
        ...,
        [-0.0080,  0.0040,  0.0170,  ..., -0.0677, -0.0005, -0.0100],
        [ 0.0096, -0.0051,  0.0042,  ..., -0.0011, -0.0824,  0.0074],
        [-0.0011, -0.0099, -0.0023,  ..., -0.0131,  0.0100, -0.0638]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.5417e-01, -2.6321e-03,  5.3215e-03,  ...,  1.9836e-03,
         -4.2343e-03,  1.1467e-02],
        [ 4.3678e-03, -1.7310e-01, -3.9177e-03,  ...,  1.2306e-02,
         -1.2589e-04, -5.3940e-03],
        [-1.4992e-02, -6.7978e-03, -1.5979e-01,  ..., -4.7646e-03,
         -1.5907e-03,  1.8482e-03],
        ...,
        [-5.5008e-03,  1.1017e-02,  6.9313e-03,  ..., -1.5149e-01,
         -1.8463e-03,  6.3515e-03],
        [-1.0223e-03,  5.1270e-03,  4.7302e-03,  ...,  1.0395e-03,
         -1.6663e-01, -2.4281e-03],
        [-9.3231e-03, -1.0452e-03, -7.1297e-03,  ..., -1.0757e-02,
         -1.3802e-02, -1.4502e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:04:12 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 17:04:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1531, -0.5610, -0.7007,  ...,  0.0435, -0.4358,  0.4055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2074, -0.9004, -0.7798,  ..., -1.1094, -0.6133, -0.2896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7461, -0.0842, -0.5898,  ...,  0.1504, -0.5391,  0.2277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2429, -0.7134, -0.6104,  ..., -0.9204, -1.0088,  0.4360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:04:12 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:04:12 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 17:04:54 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 17:05:45 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 17:06:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5545e-03,  2.6226e-04, -3.2539e-03,  ...,  2.9354e-03,
          1.3828e-03, -2.8014e-06],
        [-5.5027e-04,  1.5030e-03,  2.5845e-04,  ..., -2.8133e-03,
          5.3549e-04,  3.4142e-04],
        [ 4.0293e-04,  2.9106e-03, -5.3444e-03,  ...,  3.2101e-03,
         -8.6594e-03,  2.8725e-03],
        ...,
        [-4.2367e-04, -3.5553e-03,  2.2278e-03,  ..., -5.6610e-03,
          1.8625e-03,  7.7963e-05],
        [ 2.7065e-03, -3.5629e-03,  6.7377e-04,  ...,  5.7831e-03,
         -9.8133e-04,  3.1738e-03],
        [-3.2616e-04,  3.3245e-03, -2.5215e-03,  ...,  3.6316e-03,
         -3.0613e-03, -2.1820e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0953, -0.0041, -0.0045,  ..., -0.0004,  0.0056,  0.0094],
        [ 0.0056, -0.0923,  0.0006,  ..., -0.0030, -0.0084,  0.0075],
        [-0.0008,  0.0067, -0.1046,  ...,  0.0026,  0.0013, -0.0088],
        ...,
        [ 0.0010,  0.0036,  0.0111,  ..., -0.1014,  0.0111,  0.0012],
        [ 0.0140, -0.0094,  0.0025,  ...,  0.0029, -0.0944,  0.0155],
        [ 0.0019,  0.0084, -0.0026,  ..., -0.0025, -0.0091, -0.1078]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1144,  0.0091,  0.0017,  ...,  0.0130, -0.0041, -0.0127],
        [ 0.0103, -0.1133,  0.0056,  ...,  0.0063, -0.0063,  0.0100],
        [-0.0012, -0.0063, -0.1226,  ...,  0.0053,  0.0043,  0.0020],
        ...,
        [-0.0060,  0.0052,  0.0046,  ..., -0.1168,  0.0148, -0.0081],
        [-0.0022, -0.0011,  0.0004,  ..., -0.0015, -0.1221,  0.0256],
        [-0.0074, -0.0015, -0.0054,  ..., -0.0038, -0.0077, -0.1061]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:06:38 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 17:06:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1197,  0.0952, -0.4287,  ...,  0.2490, -0.3218,  0.0385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1114, -0.3848, -0.4517,  ..., -1.1152, -0.4224, -0.1527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2456,  0.1047, -1.1523,  ...,  1.3086, -0.4907,  0.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8896, -0.7930, -0.6445,  ..., -1.1074, -0.7002,  0.4502],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:06:38 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:06:38 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 17:07:30 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 17:08:21 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 17:09:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0218, -0.0013,  0.0016,  ...,  0.0007,  0.0011,  0.0023],
        [-0.0017,  0.0146, -0.0002,  ...,  0.0015,  0.0018,  0.0032],
        [-0.0022, -0.0037,  0.0133,  ..., -0.0040,  0.0045, -0.0003],
        ...,
        [ 0.0005,  0.0058,  0.0071,  ...,  0.0216, -0.0098,  0.0046],
        [-0.0029, -0.0067,  0.0016,  ..., -0.0096,  0.0198, -0.0021],
        [-0.0056, -0.0016,  0.0013,  ..., -0.0003,  0.0017,  0.0140]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.3074e-01, -5.3291e-03,  3.2539e-03,  ...,  8.3466e-03,
          9.9335e-03, -1.7029e-02],
        [ 7.2861e-03, -1.4099e-01, -2.3003e-03,  ...,  7.9193e-03,
         -8.4534e-03,  6.2294e-03],
        [-4.4975e-03, -5.2490e-03, -1.2671e-01,  ...,  8.8959e-03,
         -9.1858e-03,  9.3765e-03],
        ...,
        [-4.7226e-03,  3.5305e-03,  1.2909e-02,  ..., -1.3733e-01,
         -6.0349e-03,  8.1635e-03],
        [-8.5754e-03,  1.3638e-04, -7.7438e-04,  ...,  1.2527e-02,
         -1.2262e-01, -1.2611e-02],
        [ 3.6087e-03, -1.5121e-02,  5.0316e-03,  ..., -1.3199e-02,
          1.0841e-02, -1.4172e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2417,  0.0041, -0.0034,  ..., -0.0054, -0.0035, -0.0062],
        [ 0.0009, -0.2517, -0.0017,  ..., -0.0126,  0.0063, -0.0014],
        [-0.0046,  0.0163, -0.2345,  ...,  0.0043, -0.0193, -0.0128],
        ...,
        [-0.0154, -0.0046, -0.0036,  ..., -0.2556,  0.0161,  0.0140],
        [-0.0117, -0.0054, -0.0120,  ...,  0.0090, -0.2396, -0.0080],
        [-0.0030, -0.0265, -0.0089,  ...,  0.0024,  0.0076, -0.2634]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:09:15 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 17:09:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4182, -0.0677, -0.3865,  ...,  0.0817, -0.3293,  0.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2158, -0.5664, -0.4949,  ..., -0.6968, -0.7754,  0.2913],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0576, -0.2832, -0.9043,  ...,  1.6445, -1.2217,  0.6533],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4180, -0.9150, -0.7241,  ..., -0.6768, -0.3657,  0.3171],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:09:15 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:09:15 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 17:10:10 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 17:11:06 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 17:12:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0032,  0.0014,  0.0070,  ..., -0.0031, -0.0004, -0.0054],
        [ 0.0028, -0.0072, -0.0005,  ..., -0.0020,  0.0012, -0.0006],
        [ 0.0089,  0.0030, -0.0034,  ..., -0.0025, -0.0030, -0.0020],
        ...,
        [ 0.0024,  0.0003, -0.0009,  ..., -0.0039, -0.0027,  0.0030],
        [-0.0072,  0.0007, -0.0037,  ...,  0.0017, -0.0064,  0.0042],
        [-0.0024,  0.0018, -0.0061,  ...,  0.0038,  0.0003, -0.0044]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.8196e-02,  6.6528e-03,  1.2798e-03,  ..., -2.1152e-03,
         -1.4542e-02, -1.4305e-03],
        [ 8.6670e-03, -9.0393e-02, -1.1681e-02,  ...,  8.7128e-03,
          6.3477e-03,  6.9809e-03],
        [-7.3357e-03,  9.5367e-06, -8.6609e-02,  ..., -8.4610e-03,
          8.2169e-03,  7.6981e-03],
        ...,
        [ 2.1057e-03, -2.4223e-03, -2.1420e-03,  ..., -8.0566e-02,
          3.8452e-03, -7.9498e-03],
        [ 1.1162e-02, -1.5404e-02, -3.0632e-03,  ...,  1.0014e-03,
         -9.6252e-02,  6.8474e-03],
        [ 1.3428e-03,  3.8280e-03,  7.6256e-03,  ..., -3.8376e-03,
         -2.7943e-04, -8.7158e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0897, -0.0065, -0.0032,  ...,  0.0015, -0.0122,  0.0002],
        [ 0.0083, -0.1064, -0.0035,  ..., -0.0040,  0.0089,  0.0068],
        [ 0.0049, -0.0047, -0.1054,  ..., -0.0054, -0.0063,  0.0063],
        ...,
        [ 0.0033,  0.0043,  0.0067,  ..., -0.0830,  0.0023, -0.0129],
        [ 0.0001,  0.0034, -0.0046,  ...,  0.0057, -0.0926,  0.0027],
        [-0.0040,  0.0083,  0.0060,  ...,  0.0026, -0.0100, -0.0853]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:12:04 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 17:12:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1399,  0.0221, -0.6416,  ...,  0.6992, -0.2773,  0.3079],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6631, -0.6147, -0.4546,  ..., -0.7891, -0.4990,  0.3086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0417, -0.4355, -1.1826,  ...,  1.7949, -0.7559,  0.4292],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0176, -0.9424, -1.2227,  ..., -0.5684, -0.0986,  0.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:12:04 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:12:04 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 17:13:02 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 17:13:59 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 17:14:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0236, -0.0025, -0.0035,  ...,  0.0036,  0.0016, -0.0051],
        [-0.0044,  0.0280, -0.0004,  ...,  0.0022, -0.0004, -0.0017],
        [-0.0048,  0.0008,  0.0270,  ..., -0.0013,  0.0030, -0.0016],
        ...,
        [ 0.0013,  0.0030,  0.0074,  ...,  0.0249, -0.0126,  0.0038],
        [ 0.0022, -0.0006,  0.0072,  ..., -0.0023,  0.0274,  0.0088],
        [ 0.0025, -0.0071, -0.0018,  ..., -0.0092, -0.0078,  0.0217]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.2651e-02, -1.5526e-02, -1.2856e-02,  ..., -1.0162e-02,
          7.4615e-03,  4.2229e-03],
        [ 7.0572e-05, -1.1420e-01, -1.0433e-03,  ...,  2.0905e-03,
         -1.1215e-02,  4.6997e-03],
        [ 1.9852e-02, -5.7297e-03, -1.1200e-01,  ..., -2.7237e-03,
          8.9417e-03, -1.8433e-02],
        ...,
        [-1.2962e-02,  4.1809e-03,  7.3776e-03,  ..., -1.0938e-01,
         -5.9967e-03,  1.3680e-02],
        [-6.7520e-03,  1.2520e-02, -4.5204e-03,  ..., -1.9951e-03,
         -1.0413e-01,  9.9373e-04],
        [ 1.7471e-03, -8.5602e-03, -1.0490e-02,  ...,  8.1558e-03,
         -4.1962e-03, -1.0712e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1565, -0.0069,  0.0036,  ..., -0.0191,  0.0109,  0.0051],
        [-0.0086, -0.1744,  0.0058,  ..., -0.0090, -0.0068,  0.0086],
        [ 0.0101, -0.0042, -0.1517,  ..., -0.0088,  0.0019, -0.0028],
        ...,
        [-0.0101, -0.0119, -0.0009,  ..., -0.1604,  0.0118,  0.0027],
        [-0.0048,  0.0038, -0.0021,  ...,  0.0025, -0.1581,  0.0008],
        [ 0.0037,  0.0027, -0.0076,  ..., -0.0051,  0.0068, -0.1497]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:14:59 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 17:15:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0593, -0.1666, -0.4712,  ...,  0.8179, -0.6118,  0.2881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8975, -0.5713, -0.4402,  ..., -0.4177, -0.1940,  0.1400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4050, -0.3745, -0.4609,  ...,  1.8018,  0.0000,  0.3564],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7935, -1.1689, -1.7891,  ..., -1.5566,  0.1012,  0.0914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:15:00 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:15:00 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 17:15:55 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 17:16:54 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 17:17:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8763e-03, -3.6564e-03,  3.4952e-04,  ..., -4.3726e-04,
         -7.3166e-03, -1.6432e-03],
        [-2.3308e-03,  7.4911e-04, -4.7112e-03,  ..., -4.9019e-04,
          1.2846e-03,  1.2341e-03],
        [ 1.9503e-04, -2.1896e-03, -1.6165e-03,  ..., -8.2302e-04,
         -2.8591e-03,  2.8000e-03],
        ...,
        [ 4.3755e-03, -2.7409e-03, -1.0061e-03,  ..., -5.8413e-06,
          6.5041e-04, -1.1654e-03],
        [ 3.1590e-04, -9.2602e-04, -4.0512e-03,  ...,  4.0703e-03,
          3.2597e-03,  1.4973e-03],
        [ 8.1062e-04,  3.2635e-03,  3.1071e-03,  ..., -2.4853e-03,
         -2.6665e-03, -8.2588e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0889,  0.0147, -0.0105,  ...,  0.0017, -0.0014,  0.0093],
        [ 0.0043, -0.0989,  0.0008,  ..., -0.0011,  0.0043,  0.0091],
        [-0.0090,  0.0070, -0.0962,  ..., -0.0059, -0.0079, -0.0103],
        ...,
        [ 0.0045, -0.0030, -0.0008,  ..., -0.0948,  0.0003, -0.0034],
        [ 0.0064,  0.0106,  0.0057,  ...,  0.0111, -0.0989,  0.0099],
        [ 0.0030,  0.0132, -0.0155,  ..., -0.0098,  0.0009, -0.1111]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1229,  0.0039,  0.0018,  ..., -0.0087, -0.0012,  0.0079],
        [ 0.0117, -0.1362, -0.0044,  ...,  0.0093,  0.0005,  0.0214],
        [ 0.0022, -0.0002, -0.1249,  ..., -0.0049, -0.0019, -0.0074],
        ...,
        [-0.0017, -0.0273,  0.0011,  ..., -0.1219,  0.0121,  0.0007],
        [-0.0006,  0.0109, -0.0002,  ...,  0.0058, -0.1144,  0.0004],
        [-0.0064,  0.0073, -0.0078,  ..., -0.0082,  0.0092, -0.1377]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:17:54 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 17:17:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0286, -0.2495, -0.5537,  ...,  0.8481, -0.3633,  0.1785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6216, -0.5913, -0.6846,  ..., -0.3391, -0.0516,  0.0128],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6406, -0.9204,  0.2061,  ...,  1.3379,  0.2133,  0.9331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4551, -0.9556, -2.5918,  ..., -1.6602, -0.7021,  0.7563],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:17:54 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:17:54 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 17:18:56 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 17:20:00 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 17:21:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0141, -0.0032,  0.0019,  ...,  0.0012, -0.0015,  0.0024],
        [ 0.0075,  0.0114, -0.0014,  ...,  0.0018,  0.0050, -0.0063],
        [ 0.0017, -0.0109,  0.0110,  ..., -0.0028, -0.0060,  0.0006],
        ...,
        [-0.0049, -0.0077,  0.0003,  ...,  0.0110, -0.0108, -0.0016],
        [ 0.0110,  0.0025,  0.0090,  ..., -0.0057,  0.0134, -0.0020],
        [ 0.0068, -0.0017,  0.0072,  ..., -0.0009, -0.0007,  0.0168]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0966, -0.0108,  0.0118,  ..., -0.0173, -0.0063,  0.0148],
        [-0.0198, -0.0884, -0.0077,  ..., -0.0065,  0.0213, -0.0030],
        [ 0.0152,  0.0022, -0.1022,  ..., -0.0019, -0.0016,  0.0072],
        ...,
        [-0.0080, -0.0028,  0.0002,  ..., -0.1035, -0.0131, -0.0031],
        [-0.0014, -0.0076, -0.0151,  ...,  0.0069, -0.0981,  0.0005],
        [ 0.0061,  0.0064, -0.0100,  ...,  0.0016,  0.0064, -0.1040]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3416e-01,  5.5847e-03,  7.6056e-05,  ..., -4.3335e-03,
          3.3798e-03, -6.8626e-03],
        [-3.9597e-03, -1.4331e-01,  1.5345e-03,  ..., -7.5293e-04,
          8.1558e-03, -4.1771e-03],
        [-2.8801e-03,  6.4240e-03, -1.4563e-01,  ...,  6.7949e-06,
          1.1253e-03,  1.0460e-02],
        ...,
        [ 5.3940e-03,  5.3558e-03,  1.0277e-02,  ..., -1.4709e-01,
         -6.9656e-03, -2.8038e-03],
        [ 2.7828e-03, -1.2589e-02, -1.1978e-02,  ...,  1.2032e-02,
         -1.4551e-01,  1.8707e-02],
        [ 1.6357e-02,  4.6120e-03, -6.4087e-03,  ...,  6.1531e-03,
          1.3527e-02, -1.3281e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:21:03 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 17:21:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1586, -0.1854, -0.2341,  ...,  0.8662,  0.0026,  0.1478],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4873, -0.6514, -0.9526,  ..., -0.8467,  0.0603,  0.0243],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1016, -0.7061,  0.2360,  ...,  1.3428,  0.0476,  0.9399],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2734, -1.2910, -2.4609,  ..., -0.5977, -1.0508,  1.2148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:21:03 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:21:04 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 17:22:06 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 17:23:10 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 17:24:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.0719e-03, -4.0321e-03,  2.0332e-03,  ...,  5.1346e-03,
          9.4652e-05, -7.0343e-03],
        [-6.7406e-03,  1.4671e-02,  2.9755e-03,  ...,  6.3057e-03,
          4.8141e-03,  4.1351e-03],
        [-3.6240e-03, -1.4210e-03,  5.0011e-03,  ...,  6.0272e-03,
          2.0370e-03, -5.2185e-03],
        ...,
        [ 5.2414e-03, -5.0812e-03, -3.7727e-03,  ...,  1.2543e-02,
         -1.4168e-02, -5.9204e-03],
        [-3.8300e-03,  2.2011e-03, -2.9774e-03,  ...,  6.3972e-03,
          1.2558e-02, -3.9024e-03],
        [ 5.9605e-04,  2.0809e-03,  1.7071e-03,  ..., -6.8245e-03,
          1.2207e-02, -5.1022e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.6589e-02,  1.2350e-03, -1.7290e-03,  ...,  4.0970e-03,
          6.0310e-03, -9.3002e-03],
        [-8.5907e-03, -6.3904e-02, -1.5850e-03,  ...,  1.7319e-02,
         -1.0315e-02, -7.6294e-06],
        [-4.6654e-03,  4.9362e-03, -5.4504e-02,  ...,  1.9455e-03,
         -2.1332e-02, -4.2725e-03],
        ...,
        [-1.1375e-02,  3.6087e-03, -5.7526e-03,  ..., -6.2866e-02,
         -7.8506e-03,  6.5994e-03],
        [ 1.0284e-02,  1.1375e-02, -1.4587e-02,  ...,  7.7896e-03,
         -6.4453e-02,  2.8210e-03],
        [-8.8692e-04,  1.3229e-02,  1.1818e-02,  ...,  5.4436e-03,
          2.7313e-03, -7.0740e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.8989e-02,  6.7291e-03, -1.1703e-02,  ..., -1.1768e-03,
         -6.0005e-03, -1.8341e-02],
        [ 8.5678e-03, -8.8562e-02, -8.4457e-03,  ...,  1.9913e-03,
         -1.2085e-02,  4.6005e-03],
        [ 7.5874e-03,  1.8692e-04, -8.8440e-02,  ..., -1.2177e-02,
         -1.1406e-02, -7.0152e-03],
        ...,
        [-6.1722e-03,  8.8196e-03, -6.7329e-03,  ..., -7.9407e-02,
          8.7738e-05,  4.3030e-03],
        [ 7.3929e-03,  1.0628e-02, -1.1803e-02,  ...,  7.1106e-03,
         -8.1787e-02, -3.4065e-03],
        [-6.7902e-03,  9.4528e-03,  1.4938e-02,  ...,  2.7466e-04,
         -1.3275e-02, -9.2163e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:24:16 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 17:24:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3098, -0.4275,  0.0892,  ...,  0.5791,  0.1071,  0.3823],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7085, -0.4580, -1.1660,  ..., -0.7593, -0.3157,  0.3181],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1809, -0.6016,  0.8848,  ...,  1.9785,  0.0431,  2.2695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7319, -0.7505, -2.0586,  ..., -0.7866, -0.8960, -0.1318],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:24:16 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:24:16 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 17:25:21 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 17:26:29 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 17:27:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.4196e-03, -1.0700e-03,  1.2522e-03,  ...,  7.9107e-04,
          1.2236e-03,  3.2425e-03],
        [-1.6222e-03, -5.6648e-03,  2.4438e-06,  ...,  1.2751e-03,
          1.4410e-03, -8.1921e-04],
        [-7.3099e-04,  2.1648e-03, -6.5918e-03,  ...,  4.7255e-04,
         -3.1185e-03, -1.5669e-03],
        ...,
        [ 5.0163e-04, -1.0386e-03,  1.0290e-03,  ..., -5.4665e-03,
          2.5406e-03, -3.7813e-04],
        [ 1.2379e-03,  5.2567e-03, -1.1978e-03,  ...,  1.7862e-03,
         -1.1314e-02, -2.9316e-03],
        [ 3.1352e-04,  1.7176e-03,  5.7125e-04,  ..., -1.2560e-03,
         -2.1000e-03, -6.8741e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.5876e-02, -6.1035e-05,  7.2899e-03,  ..., -5.1537e-03,
          1.1234e-03,  3.1662e-03],
        [ 7.0076e-03, -7.5928e-02,  2.2678e-03,  ..., -4.9744e-03,
          1.6357e-02, -9.6283e-03],
        [-7.7629e-04, -1.0834e-02, -7.1411e-02,  ..., -4.3602e-03,
          1.7872e-03,  4.1809e-03],
        ...,
        [ 2.6970e-03, -5.3101e-03,  1.9150e-03,  ..., -6.7505e-02,
          1.3588e-02, -1.4595e-02],
        [ 1.4275e-02, -6.5918e-03,  1.1730e-03,  ...,  4.4556e-03,
         -8.3069e-02,  1.2451e-02],
        [ 4.5242e-03,  6.5804e-05, -1.4442e-02,  ..., -3.3073e-03,
         -5.9052e-03, -5.6793e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1057,  0.0070, -0.0007,  ...,  0.0065,  0.0083,  0.0179],
        [-0.0026, -0.0901,  0.0029,  ...,  0.0030,  0.0047, -0.0256],
        [ 0.0050,  0.0021, -0.1246,  ...,  0.0029,  0.0006, -0.0102],
        ...,
        [ 0.0021, -0.0170, -0.0077,  ..., -0.1206,  0.0093, -0.0046],
        [ 0.0044,  0.0110,  0.0115,  ...,  0.0075, -0.1255,  0.0062],
        [ 0.0097,  0.0019, -0.0029,  ...,  0.0002,  0.0050, -0.0958]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:27:37 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 17:27:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0645, -0.3032,  0.0864,  ...,  0.5762,  0.0245,  0.3726],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6094, -0.5840, -1.1094,  ..., -0.2732, -0.4834,  0.5249],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7002, -1.1719,  1.1738,  ...,  1.3809, -0.3901,  2.7344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3604, -0.6719, -1.4170,  ..., -0.4556, -1.6738,  0.7041],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:27:37 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:27:37 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 17:28:46 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 17:29:52 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 17:31:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0040, -0.0002, -0.0009,  ...,  0.0011,  0.0022, -0.0009],
        [-0.0012, -0.0051,  0.0009,  ..., -0.0003,  0.0016,  0.0002],
        [ 0.0025,  0.0003, -0.0033,  ...,  0.0009,  0.0012, -0.0010],
        ...,
        [-0.0015,  0.0019,  0.0021,  ..., -0.0026, -0.0012, -0.0003],
        [-0.0010, -0.0029,  0.0013,  ..., -0.0011, -0.0050, -0.0009],
        [-0.0013,  0.0006,  0.0001,  ...,  0.0010, -0.0004, -0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0663,  0.0044, -0.0002,  ..., -0.0036, -0.0051,  0.0030],
        [-0.0042, -0.0856,  0.0062,  ..., -0.0272,  0.0056,  0.0018],
        [ 0.0122,  0.0063, -0.0630,  ...,  0.0070,  0.0159, -0.0159],
        ...,
        [-0.0088, -0.0011, -0.0109,  ..., -0.0628,  0.0098,  0.0017],
        [ 0.0091,  0.0005, -0.0088,  ...,  0.0016, -0.0539,  0.0086],
        [-0.0059,  0.0034,  0.0027,  ..., -0.0035,  0.0154, -0.0781]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1204,  0.0091, -0.0035,  ..., -0.0073, -0.0096, -0.0008],
        [-0.0022, -0.1365,  0.0018,  ..., -0.0126,  0.0086, -0.0119],
        [ 0.0120,  0.0016, -0.1179,  ..., -0.0161,  0.0107, -0.0058],
        ...,
        [-0.0025, -0.0069, -0.0172,  ..., -0.1130, -0.0067, -0.0162],
        [-0.0018, -0.0019, -0.0155,  ..., -0.0120, -0.1125, -0.0024],
        [ 0.0030, -0.0042, -0.0051,  ...,  0.0107, -0.0187, -0.1252]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:31:02 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 17:31:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0721, -0.2603,  0.3379,  ...,  0.8174,  0.0398,  0.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3535, -0.3550, -0.9473,  ..., -0.3650, -0.3945, -0.1071],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0449, -0.1890,  1.2744,  ...,  2.2715, -0.4644,  2.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7891, -1.2148,  0.1016,  ..., -1.3945, -0.9165,  1.8457],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:31:02 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:31:02 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 17:32:12 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 17:33:22 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 17:34:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0087, -0.0005,  0.0034,  ...,  0.0062, -0.0085, -0.0102],
        [ 0.0018,  0.0174, -0.0055,  ...,  0.0081,  0.0008, -0.0002],
        [-0.0013,  0.0009,  0.0164,  ..., -0.0140, -0.0004,  0.0027],
        ...,
        [ 0.0030, -0.0024, -0.0078,  ...,  0.0123,  0.0006, -0.0008],
        [ 0.0045, -0.0080, -0.0042,  ...,  0.0084,  0.0211,  0.0055],
        [-0.0034,  0.0004,  0.0061,  ..., -0.0031, -0.0069,  0.0172]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0379,  0.0031,  0.0152,  ...,  0.0100,  0.0070,  0.0129],
        [ 0.0125, -0.0139,  0.0026,  ...,  0.0124, -0.0014, -0.0023],
        [-0.0073,  0.0062, -0.0252,  ...,  0.0029, -0.0048,  0.0158],
        ...,
        [-0.0045, -0.0072, -0.0029,  ..., -0.0220,  0.0053, -0.0137],
        [-0.0009, -0.0166, -0.0065,  ...,  0.0089, -0.0341, -0.0152],
        [-0.0058, -0.0060,  0.0022,  ..., -0.0010,  0.0031, -0.0092]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0582,  0.0162,  0.0114,  ..., -0.0130,  0.0021, -0.0110],
        [-0.0008, -0.0352, -0.0068,  ...,  0.0123, -0.0062,  0.0117],
        [-0.0021,  0.0243, -0.0507,  ...,  0.0046,  0.0080,  0.0013],
        ...,
        [-0.0030,  0.0089, -0.0026,  ..., -0.0555, -0.0079, -0.0121],
        [-0.0032,  0.0167, -0.0065,  ...,  0.0090, -0.0430,  0.0141],
        [-0.0006, -0.0070,  0.0042,  ..., -0.0147,  0.0101, -0.0443]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:34:35 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 17:34:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2727, -0.4641,  0.4114,  ...,  0.5239, -0.1525,  1.0283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1531, -0.2922, -0.5820,  ..., -0.1847, -0.6885,  0.2634],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0732, -0.6699,  1.8057,  ...,  1.9922, -1.5469,  1.5996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1504, -1.4590,  0.3438,  ..., -2.0078, -0.9668,  1.9883],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:34:35 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:34:35 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 17:35:48 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 17:37:01 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 17:38:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0500e-03, -2.0065e-03, -3.9339e-04,  ...,  5.3644e-05,
         -4.2772e-04, -5.7220e-06],
        [ 1.2321e-03,  3.1185e-03, -7.3767e-04,  ..., -6.8808e-04,
         -1.0490e-03,  5.2631e-05],
        [-1.2112e-03,  4.1914e-04, -2.8467e-04,  ..., -2.3270e-04,
          6.9618e-05,  7.9966e-04],
        ...,
        [-5.9223e-04, -3.0935e-05,  2.8312e-05,  ...,  1.5202e-03,
         -6.8998e-04, -6.6221e-05],
        [-1.1435e-03,  7.5102e-05,  5.6028e-05,  ...,  2.9469e-04,
          1.8368e-03,  1.1148e-03],
        [-3.2473e-04, -3.6287e-04,  1.3905e-03,  ..., -8.4972e-04,
         -6.1035e-04,  3.3951e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0231,  0.0027,  0.0100,  ...,  0.0096,  0.0037, -0.0015],
        [-0.0094, -0.0400, -0.0040,  ...,  0.0170, -0.0096, -0.0070],
        [-0.0148,  0.0108, -0.0334,  ..., -0.0018,  0.0053, -0.0146],
        ...,
        [ 0.0027, -0.0005, -0.0067,  ..., -0.0141, -0.0139, -0.0224],
        [-0.0009,  0.0034,  0.0006,  ...,  0.0105, -0.0332,  0.0125],
        [-0.0050, -0.0115, -0.0026,  ..., -0.0135,  0.0073, -0.0443]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0558,  0.0142,  0.0081,  ...,  0.0208, -0.0051,  0.0165],
        [-0.0149, -0.0818,  0.0036,  ...,  0.0322, -0.0038,  0.0265],
        [-0.0209, -0.0097, -0.0736,  ...,  0.0050,  0.0183, -0.0155],
        ...,
        [-0.0150,  0.0050, -0.0151,  ..., -0.0474, -0.0080,  0.0047],
        [ 0.0003,  0.0100,  0.0053,  ...,  0.0097, -0.0589, -0.0115],
        [-0.0274, -0.0077, -0.0043,  ...,  0.0079,  0.0056, -0.0908]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:38:15 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 17:38:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3711, -0.0776,  0.4363,  ...,  0.7876, -0.1553,  0.7344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3186, -0.4968,  0.0289,  ..., -0.5654, -0.3555,  0.7119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6621, -0.4495,  2.0703,  ...,  1.1680, -1.8975,  1.5645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.8682, -1.3516,  0.9399,  ..., -0.8799, -3.1172,  2.3574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:38:15 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:38:15 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 17:39:34 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 17:40:56 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 17:42:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0010, -0.0059, -0.0021,  ...,  0.0041, -0.0031,  0.0049],
        [ 0.0009, -0.0044, -0.0024,  ...,  0.0032,  0.0057,  0.0025],
        [-0.0009,  0.0002,  0.0006,  ...,  0.0018, -0.0003,  0.0025],
        ...,
        [ 0.0037,  0.0009, -0.0041,  ...,  0.0013, -0.0001, -0.0004],
        [-0.0012,  0.0014,  0.0034,  ...,  0.0019, -0.0039, -0.0030],
        [-0.0025,  0.0001,  0.0017,  ..., -0.0004,  0.0063,  0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0207, -0.0191,  0.0024,  ..., -0.0049,  0.0078,  0.0239],
        [-0.0210, -0.0385, -0.0078,  ...,  0.0034,  0.0168, -0.0094],
        [ 0.0067,  0.0056, -0.0136,  ...,  0.0123, -0.0021,  0.0123],
        ...,
        [-0.0097, -0.0099, -0.0096,  ..., -0.0388,  0.0087, -0.0020],
        [-0.0103, -0.0075,  0.0040,  ...,  0.0107, -0.0381,  0.0021],
        [ 0.0167,  0.0109, -0.0125,  ..., -0.0144, -0.0070, -0.0269]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0410, -0.0078, -0.0115,  ..., -0.0107, -0.0019,  0.0120],
        [-0.0099, -0.0644, -0.0126,  ...,  0.0173,  0.0215,  0.0048],
        [-0.0114,  0.0071, -0.0667,  ..., -0.0069, -0.0043,  0.0185],
        ...,
        [-0.0091, -0.0136, -0.0086,  ..., -0.0677, -0.0015,  0.0024],
        [ 0.0143, -0.0020, -0.0141,  ...,  0.0002, -0.0693, -0.0072],
        [ 0.0034, -0.0027, -0.0057,  ..., -0.0146,  0.0027, -0.0726]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:42:17 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 17:42:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3765, -0.2281,  0.5967,  ...,  0.6782, -0.5259,  0.5342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4556, -0.5547,  0.1163,  ..., -0.7563, -0.3669,  0.7554],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.8203, -1.0508,  4.1992,  ...,  1.1445, -1.2051,  2.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.8779, -1.1074,  1.6289,  ..., -1.1250, -4.8359,  3.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:42:17 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:42:17 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 17:43:39 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 17:45:00 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 17:46:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2124e-04, -9.1791e-05, -1.7297e-04,  ..., -3.4392e-05,
          1.6117e-04, -1.0133e-05],
        [-1.0788e-04,  1.2505e-04,  3.8052e-04,  ...,  3.5572e-04,
         -1.9991e-04,  1.5402e-04],
        [-1.7548e-04,  1.8358e-04, -1.3328e-04,  ...,  3.9756e-05,
         -2.2554e-04, -9.1851e-05],
        ...,
        [ 5.1260e-05, -1.9848e-05,  3.1769e-05,  ..., -3.2377e-04,
          3.7909e-04,  4.6015e-05],
        [ 1.6987e-05,  1.4782e-04, -5.2154e-05,  ..., -1.1498e-04,
         -1.3316e-04,  2.1577e-05],
        [ 2.1219e-05,  5.5969e-05,  1.4448e-04,  ...,  6.8545e-05,
          1.3471e-04, -3.7479e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0228,  0.0190, -0.0105,  ...,  0.0183, -0.0011,  0.0043],
        [ 0.0038, -0.0365, -0.0097,  ..., -0.0087, -0.0044,  0.0015],
        [-0.0097,  0.0040, -0.0305,  ..., -0.0011,  0.0031,  0.0014],
        ...,
        [-0.0047, -0.0026, -0.0011,  ..., -0.0274, -0.0094,  0.0122],
        [ 0.0091,  0.0092,  0.0158,  ...,  0.0096, -0.0458,  0.0014],
        [-0.0024, -0.0100,  0.0032,  ..., -0.0159,  0.0028, -0.0060]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0484,  0.0223, -0.0086,  ...,  0.0155, -0.0045, -0.0017],
        [ 0.0118, -0.0278, -0.0246,  ..., -0.0118,  0.0033, -0.0003],
        [ 0.0075, -0.0058, -0.0531,  ...,  0.0068, -0.0091, -0.0004],
        ...,
        [ 0.0020, -0.0129, -0.0057,  ..., -0.0702, -0.0031,  0.0285],
        [ 0.0208, -0.0011, -0.0052,  ...,  0.0137, -0.0575, -0.0189],
        [ 0.0101, -0.0044,  0.0051,  ..., -0.0119, -0.0089, -0.0319]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:46:19 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 17:46:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5708, -0.1449,  0.6436,  ...,  0.3840, -0.6094,  0.4946],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6890, -0.4849,  0.3096,  ..., -0.3123, -1.1250,  0.8433],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2422, -1.1084,  4.0742,  ..., -0.6182, -1.1768,  1.5459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0732, -0.4927,  2.8359,  ..., -1.0264, -5.3359,  2.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:46:19 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:46:19 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 17:47:34 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 17:48:50 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 17:50:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0433e-03,  2.7728e-04,  1.4067e-04,  ..., -1.5795e-05,
         -9.2125e-04,  3.0494e-04],
        [ 4.1389e-04,  1.2064e-03,  6.1178e-04,  ...,  2.9945e-04,
          1.1373e-04, -7.7963e-04],
        [ 7.9727e-04,  1.7700e-03,  1.1253e-03,  ..., -4.2439e-05,
          1.5783e-04,  2.6393e-04],
        ...,
        [ 3.1447e-04, -1.3876e-04, -1.3769e-05,  ...,  1.2531e-03,
          5.4359e-05,  1.9801e-04],
        [ 7.4327e-05, -3.9363e-04, -5.3453e-04,  ..., -1.8179e-04,
          8.5592e-04,  2.9385e-05],
        [ 7.7820e-04,  5.1594e-04,  7.7248e-04,  ..., -3.4094e-04,
         -6.1178e-04,  3.4356e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.6922e-02,  2.5444e-03,  7.7152e-04,  ...,  1.0635e-02,
          1.0803e-02,  1.5259e-02],
        [ 3.1311e-02, -2.7725e-02, -9.6664e-03,  ...,  6.3934e-03,
          4.4098e-03, -2.2583e-02],
        [ 9.0256e-03,  8.2254e-05, -9.2545e-03,  ..., -1.2070e-02,
          2.4170e-02,  1.0483e-02],
        ...,
        [ 6.1798e-04, -3.1052e-03, -2.5463e-03,  ...,  2.2545e-03,
          7.1793e-03,  1.5526e-03],
        [-6.4735e-03, -7.5340e-03,  1.3924e-02,  ...,  7.0953e-04,
         -2.4307e-02,  9.1705e-03],
        [ 7.6981e-03, -1.4427e-02, -1.0406e-02,  ..., -6.6452e-03,
          2.3819e-02, -1.6510e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0693, -0.0011,  0.0059,  ..., -0.0067,  0.0146,  0.0025],
        [ 0.0033, -0.0742,  0.0017,  ..., -0.0072, -0.0088, -0.0003],
        [ 0.0191,  0.0094, -0.0771,  ..., -0.0128,  0.0011, -0.0110],
        ...,
        [-0.0057, -0.0203, -0.0062,  ..., -0.0728,  0.0054, -0.0126],
        [ 0.0003, -0.0044,  0.0141,  ..., -0.0116, -0.0990, -0.0177],
        [ 0.0060, -0.0075, -0.0242,  ...,  0.0001, -0.0018, -0.0759]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:50:11 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 17:50:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5977, -0.2998,  1.2891,  ...,  0.3511, -0.3801,  0.6841],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6724, -0.3545,  0.5234,  ..., -0.4014, -1.7217,  1.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.8662, -0.4985,  4.1133,  ..., -0.0361, -1.0186,  2.3535],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.0820,  0.4985,  3.1523,  ..., -0.0601, -3.8262,  2.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:50:11 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:50:11 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 17:51:29 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 17:52:48 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 17:54:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.1210e-03,  4.2081e-05,  4.9889e-05,  ...,  6.5088e-04,
         -1.0788e-04,  6.6614e-04],
        [-2.3842e-07,  1.7128e-03, -3.0994e-04,  ...,  4.1723e-05,
         -2.9027e-05,  7.0333e-05],
        [-1.3089e-04,  9.5725e-05,  2.6112e-03,  ..., -1.7762e-04,
          3.5381e-04, -1.4758e-04],
        ...,
        [-4.4703e-04, -1.1796e-04,  6.4373e-06,  ...,  2.2297e-03,
          6.5470e-04, -3.9673e-04],
        [-1.1349e-04, -3.1233e-04, -4.0126e-04,  ...,  6.7282e-04,
          2.0847e-03, -3.3569e-04],
        [ 2.1744e-04, -5.7983e-04, -2.5797e-04,  ..., -3.3760e-04,
         -1.4472e-04,  2.8076e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0255,  0.0168,  0.0172,  ...,  0.0041,  0.0064,  0.0043],
        [-0.0011, -0.0156,  0.0094,  ...,  0.0064, -0.0058,  0.0212],
        [ 0.0128, -0.0184,  0.0073,  ...,  0.0041, -0.0090, -0.0069],
        ...,
        [-0.0244,  0.0078, -0.0116,  ...,  0.0478, -0.0050, -0.0149],
        [ 0.0163, -0.0199,  0.0067,  ...,  0.0278,  0.0294,  0.0048],
        [ 0.0005,  0.0053, -0.0031,  ..., -0.0149, -0.0043,  0.0151]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0250, -0.0009,  0.0022,  ...,  0.0082, -0.0149,  0.0218],
        [-0.0098, -0.0197,  0.0220,  ...,  0.0102, -0.0064,  0.0243],
        [ 0.0019, -0.0111, -0.0097,  ...,  0.0199,  0.0041, -0.0033],
        ...,
        [-0.0123, -0.0005, -0.0142,  ..., -0.0077, -0.0117,  0.0016],
        [ 0.0074, -0.0239, -0.0036,  ..., -0.0013, -0.0129,  0.0322],
        [-0.0012,  0.0062,  0.0033,  ...,  0.0146,  0.0036, -0.0447]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:54:11 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 17:54:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7178, -0.3035,  1.1982,  ..., -0.2256, -0.3638,  0.4453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3503, -0.1410,  0.9238,  ..., -0.3889, -1.8398,  0.8193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4277, -0.0496,  3.5820,  ...,  0.0974, -0.9131,  2.5859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2715,  1.2324,  2.6875,  ..., -0.9551, -5.2383,  2.6836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:54:11 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:54:11 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 17:55:33 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 17:56:54 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 17:58:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.4529e-03, -4.2820e-04, -3.5501e-04,  ..., -1.7488e-04,
          2.3389e-04, -7.2670e-04],
        [ 4.4107e-05, -9.9182e-05,  5.2595e-04,  ...,  4.2439e-05,
         -2.1863e-04,  1.4293e-04],
        [-2.0623e-05,  5.0497e-04,  1.9188e-03,  ...,  5.6314e-04,
         -4.1008e-04, -5.9509e-04],
        ...,
        [ 4.7207e-05, -6.2132e-04, -8.7070e-04,  ...,  1.1091e-03,
         -2.7394e-04,  2.2054e-04],
        [ 5.7602e-04,  3.2711e-04, -5.7602e-04,  ...,  3.6025e-04,
          1.8511e-03, -4.8351e-04],
        [-4.8113e-04, -8.9931e-04,  1.1635e-03,  ...,  1.2922e-04,
          1.6701e-04,  2.0103e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0094, -0.0003,  0.0161,  ..., -0.0042, -0.0098,  0.0005],
        [-0.0081, -0.0227,  0.0011,  ...,  0.0019,  0.0077, -0.0123],
        [ 0.0177, -0.0037,  0.0049,  ..., -0.0072, -0.0029,  0.0083],
        ...,
        [ 0.0007, -0.0022, -0.0236,  ...,  0.0011,  0.0188, -0.0076],
        [-0.0116,  0.0061, -0.0152,  ...,  0.0022, -0.0238, -0.0010],
        [-0.0013, -0.0121, -0.0040,  ...,  0.0080, -0.0031, -0.0151]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0441e-02, -2.0325e-02,  1.4946e-02,  ..., -1.0872e-04,
         -1.5579e-02, -5.0507e-03],
        [ 3.3379e-04, -5.5542e-02,  1.6556e-02,  ...,  1.1444e-02,
          2.2324e-02, -9.2621e-03],
        [-7.5951e-03,  2.1988e-02, -9.1782e-03,  ...,  2.3041e-03,
         -3.0716e-02,  9.1171e-03],
        ...,
        [ 2.5082e-04, -8.8806e-03,  7.1526e-05,  ..., -2.8885e-02,
          1.4015e-02, -6.0272e-03],
        [ 1.2268e-02,  7.7209e-03, -4.3182e-02,  ..., -4.3678e-03,
         -4.8676e-02,  1.1803e-02],
        [ 1.2219e-04,  8.0261e-03, -8.2254e-04,  ...,  1.7670e-02,
          1.3466e-02, -6.4575e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 17:58:20 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 17:58:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5786, -0.1060,  1.0400,  ..., -0.1080, -0.3071,  0.6064],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6489,  0.1858,  0.9360,  ..., -0.1186, -1.2754,  0.8740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.7012e+00,  2.5024e-03,  1.5840e+00,  ..., -1.0801e+00,
        -1.0811e+00,  1.4570e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.2422,  1.4219,  2.1992,  ..., -0.9619, -5.1094,  1.6992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 17:58:20 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 17:58:20 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 17:59:45 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 18:01:11 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 18:02:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5518e-02, -3.2578e-03, -2.3575e-03,  ...,  3.1986e-03,
         -7.8535e-04, -2.3079e-03],
        [ 3.0613e-04, -4.2114e-03,  1.6804e-03,  ..., -1.1864e-03,
          3.2902e-03,  2.3232e-03],
        [ 7.2289e-03, -6.7673e-03, -1.2222e-02,  ...,  2.7180e-04,
         -4.9095e-03,  6.2609e-04],
        ...,
        [-2.3651e-04,  5.2929e-04,  4.3774e-04,  ..., -1.5091e-02,
          6.9332e-04,  2.2488e-03],
        [ 2.8095e-03, -6.0141e-05, -7.4506e-06,  ..., -1.4887e-03,
         -9.5673e-03, -2.0027e-03],
        [-1.8692e-03,  5.2261e-03, -2.0103e-03,  ...,  1.4372e-03,
         -5.6076e-04, -1.0368e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0388,  0.0004, -0.0015,  ...,  0.0159,  0.0023,  0.0051],
        [ 0.0020, -0.0076, -0.0060,  ..., -0.0252,  0.0172,  0.0027],
        [-0.0134, -0.0005,  0.0050,  ..., -0.0115,  0.0059,  0.0077],
        ...,
        [ 0.0093,  0.0083,  0.0072,  ...,  0.0522, -0.0128,  0.0005],
        [-0.0002, -0.0114, -0.0291,  ..., -0.0058,  0.0193,  0.0152],
        [-0.0107,  0.0173,  0.0007,  ...,  0.0134, -0.0026,  0.0236]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0236,  0.0030,  0.0103,  ...,  0.0008,  0.0178, -0.0063],
        [ 0.0307, -0.0536, -0.0017,  ..., -0.0176,  0.0224, -0.0030],
        [-0.0076,  0.0082, -0.0442,  ..., -0.0055, -0.0113,  0.0136],
        ...,
        [-0.0020, -0.0136, -0.0275,  ..., -0.0036,  0.0006,  0.0157],
        [ 0.0124, -0.0015, -0.0187,  ..., -0.0124, -0.0375,  0.0002],
        [ 0.0031,  0.0180,  0.0240,  ...,  0.0118, -0.0176, -0.0313]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:02:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The butterfly falls into the category of insect
The goat falls into the category of bovid
The allosaurus falls into the category of dinosaur
The falcon falls into the category of raptor
The gorilla falls into the category of primate
The jackal falls into the category of canine
The vulture falls into the category of raptor
The leopard falls into the category of
2024-06-30 18:02:39 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 18:02:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3516, -1.1299, -0.4834,  ...,  0.0149, -0.5518,  0.7998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4502, -0.1215, -0.5234,  ..., -0.1155, -0.9175, -0.3826],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3486, -1.1016, -0.9365,  ..., -0.2725, -0.5161,  0.3684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4719,  0.0449, -0.2664,  ..., -0.5127, -0.4263, -0.5020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:02:39 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:02:39 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 18:03:03 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 18:03:25 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 18:03:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.4216e-04,  3.1233e-05,  2.9755e-04,  ..., -3.0708e-04,
          3.4690e-05,  5.7077e-04],
        [ 2.2411e-04, -2.4581e-04, -2.3484e-05,  ...,  6.0201e-06,
          2.0885e-04,  2.3055e-04],
        [ 1.9145e-04,  1.9288e-04, -1.0080e-03,  ..., -7.5400e-05,
         -7.6962e-04,  1.2064e-04],
        ...,
        [-4.1676e-04, -4.2701e-04,  7.2122e-06,  ..., -4.1246e-04,
          4.1151e-04, -9.4593e-05],
        [ 2.7418e-06,  9.2983e-05, -4.3511e-06,  ..., -4.3631e-05,
         -7.2241e-04, -3.3045e-04],
        [-3.2187e-04, -3.3426e-04,  5.9366e-04,  ..., -4.0770e-04,
          3.1066e-04, -8.3828e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.3691e-02, -2.4185e-03, -1.0963e-02,  ...,  3.3417e-03,
          7.7105e-04, -2.3651e-03],
        [-8.2397e-03, -3.6255e-02,  2.0981e-03,  ..., -5.7125e-04,
         -2.2240e-03, -5.0545e-05],
        [-2.0580e-03,  6.3248e-03, -3.0899e-02,  ..., -4.5319e-03,
         -1.3170e-03,  4.1008e-03],
        ...,
        [-8.9455e-04, -9.8610e-04, -3.2730e-03,  ..., -3.5858e-02,
          1.8349e-03,  2.4834e-03],
        [-1.9798e-03,  3.0499e-03,  9.1324e-03,  ...,  8.2874e-04,
         -2.8946e-02,  3.8004e-04],
        [-1.0338e-02, -1.2703e-03, -4.8294e-03,  ...,  4.9934e-03,
          1.2360e-03, -3.4424e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0975e-02,  4.6158e-04,  6.3553e-03,  ..., -1.4915e-03,
         -1.9169e-03,  4.4823e-04],
        [ 6.3133e-04, -2.6276e-02, -6.1493e-03,  ..., -2.1553e-03,
          2.6817e-03,  2.6560e-04],
        [-2.9707e-04,  2.0142e-03, -2.4872e-02,  ..., -2.5654e-04,
         -2.0714e-03,  5.3406e-03],
        ...,
        [ 2.2392e-03,  3.2082e-03,  3.8862e-04,  ..., -2.2125e-02,
          3.2883e-03,  1.4992e-03],
        [-1.5163e-03,  1.7300e-03,  1.5950e-04,  ..., -5.3596e-04,
         -2.5635e-02,  9.2793e-04],
        [-7.9441e-04, -1.8291e-03, -2.7924e-03,  ...,  8.4114e-04,
         -8.6546e-05, -2.8275e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:03:50 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 18:03:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4041, -1.0908, -1.0342,  ..., -0.3518, -0.6748,  0.5630],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5923,  0.1307, -0.3574,  ..., -1.0508, -0.4602, -0.4480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3481, -1.1904, -0.8389,  ..., -0.4302, -0.4800,  0.5479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2471, -0.1691,  0.1729,  ..., -1.1338, -0.5918, -0.4912],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:03:51 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:03:51 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 18:04:13 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 18:04:37 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 18:05:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.4676e-03, -5.0783e-04, -9.0456e-04,  ..., -6.3086e-04,
         -1.9276e-04, -6.0892e-04],
        [ 1.3447e-04, -4.9973e-03,  1.0020e-04,  ...,  8.2779e-04,
         -7.9107e-04, -3.1376e-04],
        [ 1.5664e-04,  3.2568e-04, -5.2299e-03,  ...,  1.7345e-04,
         -1.9825e-04, -4.7207e-04],
        ...,
        [ 3.8528e-04,  4.7517e-04,  1.8120e-04,  ..., -4.0970e-03,
         -1.3399e-03, -5.3048e-06],
        [ 2.7418e-04,  7.3004e-04,  9.9945e-04,  ..., -4.3035e-04,
         -4.6654e-03, -1.1641e-04],
        [ 1.1766e-04, -1.5497e-05,  3.3545e-04,  ...,  6.6996e-05,
         -3.6788e-04, -3.8853e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.8981e-02,  5.7411e-04, -4.6234e-03,  ...,  3.2806e-03,
         -6.1989e-04,  3.4370e-03],
        [-7.5150e-04, -3.3691e-02, -1.1368e-02,  ...,  8.2626e-03,
          2.3804e-03,  2.6131e-03],
        [-4.1199e-03,  7.4730e-03, -4.4708e-02,  ..., -3.8981e-05,
          4.9286e-03,  1.7080e-03],
        ...,
        [ 8.2626e-03,  1.1810e-02, -5.3520e-03,  ..., -4.8340e-02,
         -1.0620e-02, -2.6703e-03],
        [-2.8629e-03, -1.3647e-03, -7.2594e-03,  ..., -3.5191e-03,
         -4.9133e-02, -5.9967e-03],
        [ 1.1818e-02, -1.6546e-03,  1.2863e-02,  ..., -6.1417e-03,
         -2.4452e-03, -6.4392e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0598, -0.0008, -0.0029,  ...,  0.0076,  0.0055,  0.0013],
        [-0.0014, -0.0641, -0.0034,  ...,  0.0003, -0.0025, -0.0036],
        [ 0.0008,  0.0030, -0.0609,  ...,  0.0032,  0.0024, -0.0003],
        ...,
        [ 0.0028, -0.0048,  0.0009,  ..., -0.0579, -0.0063, -0.0089],
        [-0.0069, -0.0064,  0.0044,  ..., -0.0067, -0.0619,  0.0038],
        [ 0.0020, -0.0129,  0.0055,  ...,  0.0026,  0.0019, -0.0545]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:05:03 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 18:05:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3989, -1.2285, -0.9995,  ..., -0.2810, -0.5469,  0.3760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7676,  0.0535, -0.4189,  ..., -0.7695, -0.6602, -0.8418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0190, -1.2559, -0.6582,  ...,  0.0234, -0.6440,  1.0381],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4395,  0.4702, -0.0283,  ..., -0.9355, -0.9077, -0.9033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:05:03 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:05:04 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 18:05:28 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 18:05:54 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 18:06:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.9591e-03,  6.0368e-04, -2.6822e-05,  ...,  1.0335e-04,
          2.8443e-04,  2.6631e-04],
        [-1.3423e-04, -2.2430e-03, -2.5451e-05,  ...,  2.7895e-04,
          7.4100e-04,  6.2370e-04],
        [ 5.4884e-04, -3.9101e-04, -3.3131e-03,  ...,  2.2829e-04,
          4.2963e-04, -6.2990e-04],
        ...,
        [ 2.3031e-04,  1.3475e-03,  3.2234e-04,  ..., -2.6970e-03,
          6.4945e-04, -9.4843e-04],
        [ 1.5938e-04, -5.9795e-04, -4.6468e-04,  ...,  1.2665e-03,
         -3.1929e-03, -6.9141e-04],
        [-1.2898e-04,  4.1175e-04, -3.3236e-04,  ...,  2.7061e-05,
          4.0770e-04, -2.3651e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.5314e-02, -1.5726e-03, -5.3253e-03,  ...,  1.0948e-02,
          1.1091e-03, -1.8239e-04],
        [-9.0332e-03, -3.7048e-02,  4.6463e-03,  ..., -3.6030e-03,
          3.3302e-03, -6.5880e-03],
        [ 1.6918e-03, -1.5678e-03, -2.8824e-02,  ..., -4.3678e-04,
         -2.3422e-03, -3.7956e-04],
        ...,
        [ 1.4420e-03, -6.8665e-05,  2.5082e-04,  ..., -2.5299e-02,
         -8.2207e-04,  2.4529e-03],
        [ 5.0354e-03, -4.3869e-03, -4.7150e-03,  ...,  2.1229e-03,
         -3.1174e-02,  3.2539e-03],
        [ 2.2144e-03,  2.0714e-03, -6.6147e-03,  ...,  1.0826e-02,
         -1.6451e-03, -3.0090e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0290,  0.0002, -0.0039,  ...,  0.0014,  0.0025,  0.0049],
        [-0.0044, -0.0325, -0.0014,  ...,  0.0062,  0.0038,  0.0008],
        [ 0.0005,  0.0003, -0.0365,  ..., -0.0021, -0.0039, -0.0044],
        ...,
        [ 0.0008,  0.0020, -0.0015,  ..., -0.0297, -0.0061,  0.0036],
        [-0.0009,  0.0024, -0.0033,  ..., -0.0052, -0.0303,  0.0096],
        [ 0.0027,  0.0062,  0.0030,  ..., -0.0062,  0.0011, -0.0307]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:06:21 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 18:06:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4185, -1.3672, -0.9077,  ..., -0.4551, -0.5410,  0.5801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3826, -0.2698,  0.2502,  ..., -1.5625, -0.8521, -0.7646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3396, -1.6465, -0.6338,  ...,  0.2566, -0.4104,  1.0674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2196,  0.7539, -0.5151,  ..., -1.0664, -0.4858, -0.3574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:06:21 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:06:21 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 18:06:50 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 18:07:19 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 18:07:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.9550e-03, -1.0061e-03, -6.6805e-04,  ...,  1.6594e-04,
         -8.2827e-04, -1.3304e-03],
        [ 5.5552e-04, -2.3327e-03, -3.6621e-04,  ...,  4.8578e-05,
          1.3602e-04, -4.7779e-04],
        [ 5.7793e-04,  7.7820e-04, -1.9703e-03,  ...,  1.9016e-03,
          1.0004e-03,  7.3910e-05],
        ...,
        [-7.3814e-04, -1.0796e-03, -2.4295e-04,  ..., -3.9291e-03,
         -2.7323e-04,  4.9114e-04],
        [-1.1911e-03, -3.7813e-04,  6.9857e-05,  ..., -1.9722e-03,
         -4.2200e-04, -6.0892e-04],
        [ 4.1723e-04, -2.6512e-04,  2.1315e-04,  ..., -1.3819e-03,
          7.2432e-04, -2.4281e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0471,  0.0057, -0.0014,  ..., -0.0024,  0.0042,  0.0039],
        [-0.0075, -0.0447, -0.0008,  ...,  0.0038,  0.0073,  0.0011],
        [-0.0005, -0.0096, -0.0327,  ...,  0.0031,  0.0005, -0.0013],
        ...,
        [-0.0020, -0.0044,  0.0019,  ..., -0.0432, -0.0087,  0.0058],
        [ 0.0033, -0.0030,  0.0035,  ..., -0.0014, -0.0402,  0.0002],
        [ 0.0102, -0.0099, -0.0010,  ..., -0.0021,  0.0031, -0.0382]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0573,  0.0023,  0.0003,  ..., -0.0041,  0.0088, -0.0067],
        [ 0.0034, -0.0470, -0.0003,  ...,  0.0023, -0.0004,  0.0010],
        [-0.0004, -0.0055, -0.0405,  ...,  0.0044, -0.0015,  0.0005],
        ...,
        [-0.0058, -0.0068,  0.0015,  ..., -0.0612,  0.0005, -0.0135],
        [-0.0012,  0.0048, -0.0122,  ..., -0.0042, -0.0392, -0.0085],
        [-0.0009, -0.0018, -0.0013,  ..., -0.0022, -0.0007, -0.0503]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:07:51 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 18:07:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0359, -1.2715, -0.5913,  ...,  0.0071, -0.5776,  0.9575],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4595,  0.4607, -0.0205,  ..., -0.9126, -0.9072, -1.0010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3113, -2.1914, -0.5059,  ...,  0.1719, -0.9854,  1.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1891,  0.3447, -0.1448,  ..., -0.8389, -0.5083, -0.6421],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:07:51 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:07:51 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 18:08:19 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 18:08:43 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 18:09:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0290e-03,  2.8629e-03, -3.2692e-03,  ...,  5.3520e-03,
         -4.0436e-04, -9.8133e-04],
        [-3.8815e-04,  2.9144e-03, -1.7138e-03,  ...,  5.9128e-04,
         -2.7823e-04, -4.7469e-04],
        [ 2.7847e-03,  1.7376e-03, -3.4180e-03,  ..., -3.7651e-03,
         -1.7433e-03,  2.0885e-03],
        ...,
        [-2.0542e-03,  5.8079e-04,  1.2350e-04,  ..., -3.1471e-03,
         -3.4657e-03,  3.2234e-03],
        [-1.5488e-03,  1.6346e-03, -1.4544e-03,  ..., -4.7731e-04,
          1.2171e-04, -6.4373e-04],
        [ 9.7752e-06, -1.0090e-03, -1.7090e-03,  ..., -7.0906e-04,
         -2.6951e-03, -2.7084e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0797,  0.0120,  0.0009,  ..., -0.0044,  0.0013, -0.0133],
        [ 0.0018, -0.0663,  0.0106,  ..., -0.0025,  0.0005, -0.0045],
        [-0.0030,  0.0071, -0.0713,  ..., -0.0016,  0.0054, -0.0052],
        ...,
        [ 0.0079, -0.0015, -0.0184,  ..., -0.0606, -0.0090,  0.0063],
        [ 0.0028, -0.0061,  0.0012,  ...,  0.0051, -0.0715,  0.0054],
        [-0.0002,  0.0041,  0.0042,  ..., -0.0079, -0.0054, -0.0791]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1050,  0.0006,  0.0130,  ..., -0.0013, -0.0023, -0.0050],
        [ 0.0021, -0.1155,  0.0040,  ..., -0.0052, -0.0091, -0.0078],
        [-0.0005,  0.0011, -0.1144,  ...,  0.0028,  0.0063,  0.0006],
        ...,
        [ 0.0004,  0.0010,  0.0048,  ..., -0.1005,  0.0116,  0.0015],
        [-0.0011, -0.0015,  0.0048,  ..., -0.0042, -0.1068,  0.0042],
        [-0.0027,  0.0007, -0.0012,  ..., -0.0035,  0.0063, -0.1100]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:09:08 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 18:09:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3008, -1.4775, -0.5366,  ...,  0.2129, -0.3711,  0.9131],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2397,  0.8306, -0.5439,  ..., -1.1084, -0.5371, -0.4175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5947, -2.4453, -0.9238,  ...,  0.1469, -1.3691,  0.9834],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3447,  0.3535, -0.3364,  ..., -0.1997, -0.9082, -0.8008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:09:08 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:09:08 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 18:09:30 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 18:09:57 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 18:10:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.4893e-03, -6.7806e-04,  2.7199e-03,  ...,  4.3607e-04,
          1.3323e-03,  2.3842e-07],
        [ 1.3459e-04, -4.8828e-03,  2.6188e-03,  ...,  3.3998e-04,
          1.4534e-03, -9.3126e-04],
        [-2.3723e-04,  8.0872e-04, -5.4054e-03,  ..., -2.6131e-04,
         -6.0797e-05, -3.3703e-03],
        ...,
        [ 2.0981e-03,  2.8515e-04, -5.3215e-04,  ..., -5.7526e-03,
          5.1641e-04, -6.6328e-04],
        [ 3.3207e-03, -1.2541e-03, -4.8423e-04,  ..., -1.1368e-03,
         -1.2684e-03, -9.4891e-04],
        [-8.7023e-05,  6.0415e-04,  4.3983e-03,  ...,  1.0645e-04,
         -2.0847e-03,  2.5787e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0897, -0.0022, -0.0007,  ...,  0.0088,  0.0069,  0.0091],
        [-0.0021, -0.0911,  0.0040,  ..., -0.0057,  0.0007,  0.0005],
        [ 0.0227,  0.0041, -0.0886,  ..., -0.0031, -0.0018,  0.0110],
        ...,
        [ 0.0039, -0.0028,  0.0104,  ..., -0.0774, -0.0003,  0.0139],
        [-0.0129,  0.0029,  0.0007,  ...,  0.0053, -0.0928, -0.0061],
        [ 0.0003, -0.0018,  0.0073,  ..., -0.0033, -0.0062, -0.0825]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0266e-01,  1.0635e-02, -1.1444e-02,  ...,  4.3259e-03,
          5.4665e-03, -5.4054e-03],
        [ 2.7752e-03, -1.0626e-01, -7.5073e-03,  ...,  1.1787e-03,
         -2.3060e-03,  6.7978e-03],
        [ 3.1872e-03,  3.1281e-04, -9.3445e-02,  ..., -2.7218e-03,
          9.9335e-03, -3.5620e-04],
        ...,
        [-3.7193e-05, -3.9673e-03,  2.8706e-03,  ..., -9.8328e-02,
         -7.6065e-03, -4.6921e-03],
        [ 8.2922e-04,  4.8637e-03, -2.8725e-03,  ..., -8.7881e-04,
         -9.6130e-02,  2.5692e-03],
        [-5.3940e-03, -1.8139e-03, -3.9825e-03,  ..., -8.8501e-03,
         -8.3780e-04, -9.9060e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:10:36 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 18:10:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2637, -1.8398, -0.4128,  ...,  0.1014, -0.8066,  1.0273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1848,  0.3579, -0.1482,  ..., -0.7881, -0.4900, -0.6724],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7334, -1.8750, -1.4424,  ...,  0.0789, -0.9854,  1.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2220,  0.2544, -0.5039,  ..., -0.9077, -0.7881, -0.9858],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:10:36 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:10:36 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 18:11:12 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 18:11:49 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 18:12:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.4708e-03,  8.6355e-04,  6.7091e-04,  ..., -8.2207e-04,
         -1.1435e-03,  6.1226e-04],
        [-1.0467e-04, -2.9984e-03, -1.4973e-03,  ..., -5.0402e-04,
          2.0638e-03, -2.1744e-04],
        [ 1.2484e-03, -4.9877e-04, -5.4054e-03,  ..., -2.6202e-04,
          1.3895e-03, -1.3676e-03],
        ...,
        [-4.3631e-04, -9.8228e-04,  2.0275e-03,  ..., -5.5008e-03,
          1.4200e-03,  5.1355e-04],
        [-1.5211e-04, -2.8658e-04, -2.4014e-03,  ...,  1.1559e-03,
         -1.6079e-03,  1.1168e-03],
        [ 1.0643e-03, -2.1172e-03, -4.0388e-04,  ..., -2.1572e-03,
         -7.9632e-05, -4.2572e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0905,  0.0050,  0.0053,  ..., -0.0010,  0.0018,  0.0128],
        [ 0.0075, -0.0811, -0.0015,  ..., -0.0006,  0.0122, -0.0064],
        [-0.0096,  0.0030, -0.0680,  ...,  0.0025, -0.0160, -0.0034],
        ...,
        [-0.0006, -0.0102, -0.0028,  ..., -0.0862, -0.0119, -0.0048],
        [ 0.0004, -0.0009, -0.0215,  ...,  0.0016, -0.0836, -0.0022],
        [ 0.0093, -0.0083,  0.0015,  ..., -0.0070, -0.0089, -0.0793]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1146, -0.0010,  0.0065,  ..., -0.0177, -0.0157,  0.0018],
        [ 0.0072, -0.0957, -0.0156,  ...,  0.0055,  0.0035, -0.0038],
        [-0.0046, -0.0032, -0.0965,  ..., -0.0031, -0.0008,  0.0015],
        ...,
        [-0.0012, -0.0039,  0.0042,  ..., -0.1094,  0.0121, -0.0029],
        [ 0.0015,  0.0015, -0.0022,  ...,  0.0140, -0.1100, -0.0061],
        [ 0.0021, -0.0061,  0.0067,  ...,  0.0020,  0.0023, -0.1069]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:12:28 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 18:12:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4756, -2.0156, -0.7100,  ...,  0.1001, -1.0645,  0.7671],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3357,  0.3521, -0.3235,  ..., -0.1837, -0.8730, -0.8237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7598, -2.4336, -1.7344,  ..., -0.0874, -0.9600,  1.5566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2152, -0.8433, -0.6890,  ..., -1.2939, -1.0020, -0.2788],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:12:28 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:12:28 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 18:13:09 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 18:13:51 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 18:14:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0057,  0.0008, -0.0011,  ...,  0.0002, -0.0005, -0.0024],
        [ 0.0001, -0.0042,  0.0007,  ..., -0.0046, -0.0002, -0.0028],
        [-0.0008,  0.0011, -0.0026,  ...,  0.0022,  0.0020, -0.0017],
        ...,
        [-0.0004,  0.0008, -0.0013,  ..., -0.0019,  0.0034,  0.0017],
        [ 0.0005, -0.0020, -0.0010,  ...,  0.0004, -0.0057, -0.0008],
        [ 0.0027,  0.0008,  0.0013,  ..., -0.0003,  0.0017, -0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.6355e-02, -2.6836e-03, -2.9926e-03,  ..., -1.1017e-02,
         -1.5869e-03,  1.1749e-02],
        [-6.2065e-03, -9.9243e-02, -3.4237e-03,  ..., -1.3557e-02,
         -5.0735e-03,  3.3760e-03],
        [-1.3000e-02,  1.2199e-02, -7.7087e-02,  ..., -1.3924e-02,
         -1.0605e-02, -7.6408e-03],
        ...,
        [-6.7368e-03,  5.8060e-03, -9.1019e-03,  ..., -7.1777e-02,
          2.0485e-03, -2.9850e-03],
        [ 2.9602e-03, -8.3923e-05, -8.6670e-03,  ...,  8.8882e-04,
         -7.3242e-02,  1.0246e-02],
        [ 2.8133e-03,  1.2390e-02,  3.5172e-03,  ..., -1.4748e-02,
          4.7989e-03, -8.6182e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0083e-01,  8.1024e-03, -3.4657e-03,  ...,  5.0259e-04,
          4.4861e-03, -5.5695e-04],
        [ 2.5387e-03, -1.0474e-01,  6.2714e-03,  ..., -1.1047e-02,
         -1.3702e-02,  1.0536e-02],
        [-7.2289e-04,  2.2240e-03, -1.0400e-01,  ..., -2.9564e-03,
         -1.0071e-02,  1.1505e-02],
        ...,
        [ 8.2016e-05,  4.8904e-03, -9.5978e-03,  ..., -9.8694e-02,
         -4.2877e-03, -7.0381e-04],
        [-5.2109e-03,  3.4256e-03, -4.1656e-03,  ..., -2.5368e-03,
         -1.0211e-01,  3.3588e-03],
        [ 1.5297e-03,  7.7972e-03, -1.4023e-02,  ...,  3.2387e-03,
          6.5155e-03, -1.0663e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:14:31 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 18:14:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5288, -1.3203, -1.0010,  ...,  0.0263, -0.6758,  0.7080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2178,  0.2303, -0.4817,  ..., -0.7808, -0.7002, -0.9189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7031, -2.1172, -1.7344,  ...,  0.2068, -0.7090,  0.9624],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0753, -0.4844, -0.4795,  ..., -1.5078, -0.9824, -0.4050],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:14:31 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:14:31 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 18:15:08 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 18:15:50 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 18:16:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0030,  0.0025,  0.0020,  ..., -0.0053, -0.0004, -0.0038],
        [ 0.0024, -0.0005, -0.0010,  ..., -0.0008, -0.0028,  0.0046],
        [ 0.0002,  0.0024,  0.0023,  ..., -0.0028,  0.0008, -0.0022],
        ...,
        [-0.0017, -0.0030, -0.0011,  ...,  0.0004, -0.0037, -0.0029],
        [-0.0044, -0.0016,  0.0027,  ..., -0.0004, -0.0012,  0.0023],
        [-0.0019, -0.0019,  0.0011,  ..., -0.0014,  0.0010,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.4177e-02, -7.0877e-03, -5.0068e-05,  ..., -4.2801e-03,
          1.7502e-02, -8.1177e-03],
        [ 2.8725e-03, -9.9243e-02,  5.4054e-03,  ..., -5.3406e-03,
          7.6714e-03,  8.5526e-03],
        [-8.9264e-03, -5.9586e-03, -9.3933e-02,  ...,  8.5754e-03,
          1.6449e-02, -1.6708e-02],
        ...,
        [-2.2659e-03,  1.0239e-02,  2.1835e-02,  ..., -8.9172e-02,
         -4.8981e-03, -6.4049e-03],
        [ 9.8495e-03,  1.8024e-03, -2.8687e-03,  ...,  5.3864e-03,
         -9.8450e-02,  1.0460e-02],
        [-9.9468e-04, -2.1720e-04, -7.2174e-03,  ..., -3.9291e-03,
          1.1353e-02, -8.0811e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.5686e-01, -3.6983e-03,  6.7444e-03,  ..., -1.5001e-03,
         -7.6675e-03,  5.6038e-03],
        [-5.7220e-06, -1.7285e-01, -5.4932e-04,  ...,  5.2910e-03,
          3.4409e-03,  5.4121e-04],
        [-1.5442e-02, -6.9046e-03, -1.6284e-01,  ..., -7.0953e-03,
         -4.5586e-04, -1.3409e-03],
        ...,
        [-4.7302e-03,  1.1551e-02,  6.2637e-03,  ..., -1.5234e-01,
         -5.4169e-03,  4.7684e-03],
        [-3.0041e-04,  4.3945e-03,  5.8632e-03,  ..., -1.1311e-03,
         -1.6992e-01, -2.3346e-03],
        [-7.7820e-03, -3.8776e-03, -7.2937e-03,  ..., -1.1551e-02,
         -1.1383e-02, -1.4954e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:16:40 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 18:16:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4700, -1.5352, -1.0625,  ..., -0.0449, -0.5977,  0.9297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1705, -0.7085, -0.5723,  ..., -0.9844, -0.8115, -0.2729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8350, -2.1211, -1.3457,  ..., -0.0530, -0.9243,  1.1191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2898, -0.7046, -0.2683,  ..., -0.4814, -1.1631,  0.4495],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:16:40 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:16:40 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 18:17:29 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 18:18:20 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 18:19:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0059,  0.0020, -0.0036,  ...,  0.0014,  0.0014,  0.0009],
        [ 0.0004, -0.0030, -0.0008,  ..., -0.0005,  0.0012,  0.0016],
        [ 0.0017,  0.0034, -0.0087,  ...,  0.0021, -0.0029,  0.0028],
        ...,
        [ 0.0018, -0.0078,  0.0024,  ..., -0.0087,  0.0046, -0.0027],
        [ 0.0006, -0.0059,  0.0013,  ...,  0.0039, -0.0062,  0.0049],
        [-0.0019, -0.0005, -0.0037,  ...,  0.0024,  0.0018, -0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1115e-01,  4.2610e-03, -1.1444e-05,  ..., -8.5220e-03,
          7.8011e-03,  6.8626e-03],
        [ 2.0493e-02, -9.6130e-02, -1.1139e-02,  ...,  4.1580e-04,
         -7.9956e-03, -7.1793e-03],
        [-1.2093e-03,  5.6458e-03, -9.5154e-02,  ...,  3.3398e-03,
         -5.9586e-03, -1.2138e-02],
        ...,
        [ 1.1185e-02, -1.9331e-03,  5.5084e-03,  ..., -1.0083e-01,
          1.4923e-02,  2.6989e-04],
        [ 1.8631e-02, -1.4694e-02,  5.1880e-03,  ...,  1.0956e-02,
         -1.0730e-01,  1.1162e-02],
        [-4.7455e-03,  4.2953e-03, -2.2736e-03,  ...,  3.6469e-03,
         -2.3556e-03, -1.0852e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1609e-01,  7.9346e-03,  3.5820e-03,  ...,  1.2680e-02,
         -8.4915e-03, -8.5983e-03],
        [ 1.0986e-02, -1.1401e-01,  9.8705e-04,  ...,  3.3073e-03,
         -5.5313e-03,  6.3477e-03],
        [-7.0000e-04, -2.5120e-03, -1.1987e-01,  ..., -3.2616e-04,
          3.5973e-03, -6.6757e-04],
        ...,
        [-6.2714e-03,  3.3379e-03,  3.1376e-03,  ..., -1.2018e-01,
          1.7212e-02, -1.1322e-02],
        [ 1.2026e-03,  3.3665e-04,  4.9210e-04,  ..., -8.7738e-05,
         -1.2103e-01,  2.1988e-02],
        [-3.2349e-03, -2.3689e-03, -5.1765e-03,  ..., -3.2864e-03,
         -1.1627e-02, -1.1304e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:19:13 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 18:19:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4209, -1.2539, -0.9844,  ...,  0.0746, -0.4189,  0.5557],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0413, -0.3721, -0.3691,  ..., -1.0566, -0.7051, -0.2917],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7090, -1.8125, -2.0215,  ...,  0.9365, -0.4543,  2.0059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3772, -0.5928, -0.0536,  ..., -0.8052, -0.8071,  0.3628],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:19:13 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:19:13 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 18:20:05 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 18:20:58 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 18:21:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.3849e-02, -1.5259e-05,  1.2293e-03,  ...,  9.8991e-04,
          4.4060e-04,  5.3864e-03],
        [-9.3994e-03,  1.7288e-02, -1.8110e-03,  ...,  1.1721e-03,
         -1.7366e-03,  2.4643e-03],
        [-4.2572e-03, -1.6279e-03,  1.6983e-02,  ..., -5.4207e-03,
          3.4447e-03,  2.3842e-03],
        ...,
        [ 2.2697e-04,  8.2321e-03,  6.9885e-03,  ...,  2.4246e-02,
         -6.7635e-03,  5.9624e-03],
        [-1.2188e-03, -7.6370e-03,  3.0460e-03,  ..., -7.5035e-03,
          1.7731e-02, -4.0817e-03],
        [-2.8419e-03, -1.3990e-03,  4.3373e-03,  ...,  2.5978e-03,
         -3.1300e-03,  1.2474e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.4490e-01, -2.6436e-03,  8.9340e-03,  ...,  1.3206e-02,
          8.6365e-03, -1.5160e-02],
        [ 2.1076e-03, -1.3196e-01, -2.8515e-04,  ..., -8.0185e-03,
         -8.2550e-03,  1.0490e-04],
        [-1.8753e-02, -3.1013e-03, -1.3855e-01,  ...,  3.9101e-03,
         -7.3929e-03,  6.8359e-03],
        ...,
        [-1.0414e-03, -4.2801e-03,  1.6998e-02,  ..., -1.3721e-01,
         -2.8553e-03,  1.2955e-02],
        [ 2.6627e-03, -3.7994e-03, -1.7151e-02,  ...,  1.9989e-03,
         -1.2231e-01, -1.9264e-03],
        [-4.8141e-03, -4.4403e-03, -1.1520e-02,  ..., -6.1150e-03,
          1.5419e-02, -1.2512e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2500,  0.0084, -0.0008,  ..., -0.0110, -0.0068, -0.0068],
        [ 0.0019, -0.2544,  0.0017,  ..., -0.0163,  0.0048,  0.0038],
        [-0.0041,  0.0109, -0.2427,  ...,  0.0039, -0.0235, -0.0080],
        ...,
        [-0.0138,  0.0006, -0.0015,  ..., -0.2605,  0.0154,  0.0090],
        [-0.0116, -0.0036, -0.0123,  ...,  0.0084, -0.2375, -0.0112],
        [-0.0087, -0.0218, -0.0098,  ..., -0.0031,  0.0005, -0.2603]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:21:52 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 18:21:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4880, -1.1777, -0.7471,  ..., -0.0361, -0.5088,  0.5674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1960, -0.5601, -0.2452,  ..., -0.3665, -0.8926,  0.3018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1338, -1.8896, -2.0078,  ...,  0.8516, -1.3086,  2.1504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.8755, -0.5107, -0.0765,  ..., -0.5430, -0.5679,  0.0269],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:21:53 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:21:53 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 18:22:46 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 18:23:38 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 18:24:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.6008e-04,  8.6427e-05,  4.4289e-03,  ..., -2.4986e-03,
          2.8248e-03, -5.2376e-03],
        [ 2.6169e-03, -3.0270e-03,  3.2568e-04,  ..., -2.3880e-03,
          6.3400e-03, -1.4820e-03],
        [ 9.6207e-03, -1.8382e-04, -6.4964e-03,  ..., -1.8148e-03,
         -6.9008e-03, -1.1320e-03],
        ...,
        [-1.0614e-03,  1.4839e-03, -5.2109e-03,  ...,  3.0804e-03,
         -3.0079e-03,  3.9673e-03],
        [-4.0970e-03,  2.1534e-03, -2.3460e-03,  ..., -1.6108e-03,
         -7.4615e-03,  4.7226e-03],
        [ 1.5640e-04,  2.7084e-04, -3.0766e-03,  ..., -2.3537e-03,
         -9.4938e-04, -4.6310e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0905,  0.0035,  0.0086,  ...,  0.0076,  0.0004, -0.0072],
        [ 0.0125, -0.1027, -0.0100,  ...,  0.0057, -0.0024,  0.0050],
        [ 0.0077, -0.0029, -0.0855,  ...,  0.0026,  0.0167,  0.0037],
        ...,
        [-0.0066, -0.0061,  0.0003,  ..., -0.0792,  0.0052,  0.0007],
        [ 0.0102, -0.0096,  0.0034,  ...,  0.0032, -0.0908,  0.0074],
        [ 0.0036,  0.0017,  0.0004,  ..., -0.0077, -0.0059, -0.0833]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0977, -0.0037, -0.0004,  ...,  0.0053, -0.0073,  0.0013],
        [ 0.0069, -0.1038, -0.0063,  ..., -0.0040,  0.0051,  0.0087],
        [ 0.0026, -0.0016, -0.1000,  ..., -0.0095, -0.0072,  0.0072],
        ...,
        [-0.0036,  0.0033,  0.0066,  ..., -0.0860,  0.0050, -0.0075],
        [-0.0002, -0.0012, -0.0062,  ...,  0.0045, -0.0966,  0.0061],
        [-0.0058,  0.0066,  0.0010,  ...,  0.0028, -0.0075, -0.0872]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:24:35 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 18:24:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3877, -0.9976, -1.0225,  ...,  0.4480, -0.2362,  1.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2800, -0.4648, -0.0473,  ..., -0.5742, -0.5708,  0.2423],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7163, -2.1250, -2.0176,  ...,  1.4766, -0.9316,  2.7109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5430, -0.7988, -0.8105,  ..., -0.1924, -0.2368, -0.1329],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:24:35 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:24:35 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 18:25:33 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 18:26:29 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 18:27:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0169, -0.0016, -0.0027,  ...,  0.0060,  0.0026,  0.0023],
        [-0.0070,  0.0275, -0.0033,  ..., -0.0001,  0.0020, -0.0045],
        [-0.0057,  0.0017,  0.0204,  ...,  0.0001,  0.0003, -0.0027],
        ...,
        [ 0.0006,  0.0027,  0.0092,  ...,  0.0222, -0.0124,  0.0032],
        [-0.0007,  0.0010,  0.0092,  ..., -0.0007,  0.0245,  0.0104],
        [ 0.0048, -0.0065, -0.0035,  ..., -0.0084, -0.0076,  0.0186]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1147, -0.0132, -0.0039,  ..., -0.0135,  0.0025,  0.0092],
        [ 0.0034, -0.1166,  0.0039,  ...,  0.0029, -0.0040,  0.0069],
        [ 0.0152, -0.0066, -0.1215,  ..., -0.0024, -0.0031, -0.0150],
        ...,
        [-0.0230,  0.0000, -0.0053,  ..., -0.1404, -0.0058, -0.0055],
        [ 0.0058,  0.0125,  0.0077,  ...,  0.0137, -0.1332,  0.0022],
        [ 0.0104, -0.0015, -0.0066,  ..., -0.0143,  0.0095, -0.1141]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6443e-01, -1.3939e-02,  4.5204e-03,  ..., -2.2003e-02,
          5.1956e-03, -1.6022e-04],
        [-1.3275e-02, -1.8689e-01,  1.0101e-02,  ..., -5.9891e-03,
         -2.7847e-04,  4.8714e-03],
        [ 1.2367e-02,  2.1763e-03, -1.5393e-01,  ..., -6.4888e-03,
          2.4529e-03, -1.3672e-02],
        ...,
        [-4.8294e-03, -8.2932e-03, -5.3253e-03,  ..., -1.6418e-01,
          4.5052e-03, -4.2534e-03],
        [ 4.1580e-03,  8.2626e-03,  3.7289e-04,  ...,  2.0084e-03,
         -1.6235e-01,  2.8276e-04],
        [ 5.5466e-03,  3.1471e-04, -7.1259e-03,  ..., -8.9188e-03,
          9.6436e-03, -1.5491e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:27:30 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 18:27:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5571, -0.8862, -0.8989,  ...,  0.3630, -0.5786,  0.9478],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5518, -0.3196, -0.0681,  ..., -0.3308, -0.3093, -0.0396],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1245, -2.0391, -1.6006,  ...,  0.8203, -0.3408,  2.1074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4551, -1.0957, -1.2842,  ..., -0.9263, -0.5605, -0.3506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:27:30 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:27:30 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 18:28:30 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 18:29:31 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 18:30:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.7122e-03, -2.1439e-03, -8.7452e-04,  ...,  5.9843e-05,
         -1.0201e-02,  1.4889e-04],
        [-2.1591e-03,  2.0771e-03, -1.7366e-03,  ..., -9.3031e-04,
         -1.2856e-03, -1.8692e-04],
        [-2.5845e-03, -9.6083e-04,  2.1791e-04,  ..., -4.1847e-03,
          4.2224e-04,  1.5373e-03],
        ...,
        [ 4.7989e-03, -1.1139e-03, -1.7815e-03,  ...,  9.4509e-04,
          2.0714e-03,  1.0986e-03],
        [ 8.8739e-04, -9.5963e-05, -9.7752e-04,  ...,  2.5139e-03,
          5.1594e-04, -1.7986e-03],
        [-7.2145e-04,  4.0321e-03, -6.5708e-04,  ...,  7.2765e-04,
         -7.7343e-04, -1.0586e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1057,  0.0122, -0.0075,  ..., -0.0087,  0.0070,  0.0074],
        [ 0.0088, -0.1091,  0.0047,  ...,  0.0020,  0.0030,  0.0089],
        [-0.0175,  0.0022, -0.0961,  ..., -0.0062,  0.0046, -0.0106],
        ...,
        [ 0.0102, -0.0118,  0.0046,  ..., -0.1021,  0.0012,  0.0064],
        [ 0.0056, -0.0068,  0.0045,  ...,  0.0158, -0.1002,  0.0024],
        [-0.0112,  0.0085, -0.0017,  ..., -0.0017,  0.0001, -0.1166]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2671e-01,  4.8714e-03, -8.4686e-04,  ..., -1.4153e-02,
          3.2043e-04,  1.5221e-03],
        [ 4.3259e-03, -1.3489e-01, -1.0315e-02,  ...,  6.7329e-03,
          1.8806e-03,  2.2705e-02],
        [-1.2169e-03,  8.0395e-04, -1.3477e-01,  ...,  4.5738e-03,
         -1.1002e-02, -2.8954e-03],
        ...,
        [-9.7198e-03, -2.5208e-02,  5.5008e-03,  ..., -1.3733e-01,
          1.1597e-02,  4.0207e-03],
        [-2.3842e-06,  3.3150e-03, -2.7924e-03,  ...,  1.1864e-03,
         -1.1920e-01, -8.4839e-03],
        [-1.4076e-02,  8.4915e-03, -6.5308e-03,  ...,  3.8681e-03,
          6.4049e-03, -1.4185e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:30:33 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 18:30:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3333, -0.9785, -0.8481,  ...,  0.6211, -0.4033,  1.1738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3289, -0.4980, -0.4456,  ..., -0.1208, -0.1296, -0.1116],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.0742, -2.2227, -1.6934,  ...,  0.5786,  0.6465,  2.3379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1272, -1.5293, -2.4141,  ..., -1.3398, -1.0605, -0.2039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:30:33 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:30:33 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 18:31:34 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 18:32:36 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 18:33:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.7515e-03,  4.6539e-03,  2.1992e-03,  ...,  3.1509e-03,
         -5.6953e-03,  1.9951e-03],
        [ 6.3858e-03,  5.6114e-03, -6.9022e-05,  ..., -7.4148e-04,
          4.6387e-03, -2.7866e-03],
        [-1.4820e-03, -5.2681e-03,  5.9967e-03,  ..., -3.9291e-03,
         -2.4529e-03,  1.9875e-03],
        ...,
        [-5.0774e-03, -4.0474e-03, -5.1498e-04,  ...,  5.3024e-03,
         -8.7891e-03,  1.2608e-03],
        [ 1.0124e-02, -3.8385e-04,  1.0834e-02,  ..., -5.2910e-03,
          6.2027e-03, -1.5488e-03],
        [ 5.0850e-03,  4.3917e-04,  7.3814e-03,  ..., -3.0899e-04,
         -2.8000e-03,  1.2215e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0565e-01, -1.6479e-03,  4.7684e-04,  ..., -8.5983e-03,
         -7.1907e-04,  1.5671e-02],
        [ 1.3176e-02, -1.1560e-01, -4.2686e-03,  ..., -2.5368e-03,
          1.6174e-02, -1.9608e-03],
        [ 2.4231e-02, -5.7220e-06, -1.1676e-01,  ...,  2.2717e-03,
         -3.4714e-04,  8.9073e-04],
        ...,
        [-6.6338e-03, -4.8065e-03, -9.3613e-03,  ..., -1.1609e-01,
         -4.8714e-03,  6.7902e-03],
        [ 3.1013e-03, -2.4986e-04, -3.9215e-03,  ...,  1.1841e-02,
         -1.2360e-01,  1.2299e-02],
        [ 1.1162e-02,  1.4587e-02,  5.2338e-03,  ..., -4.6158e-03,
          3.3092e-03, -1.2201e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1312,  0.0091,  0.0028,  ..., -0.0029,  0.0048,  0.0012],
        [ 0.0065, -0.1604,  0.0086,  ..., -0.0018,  0.0025, -0.0018],
        [-0.0032,  0.0074, -0.1499,  ..., -0.0064, -0.0008,  0.0077],
        ...,
        [ 0.0017, -0.0002, -0.0043,  ..., -0.1573,  0.0066, -0.0048],
        [ 0.0011, -0.0117, -0.0159,  ...,  0.0205, -0.1570,  0.0137],
        [ 0.0177, -0.0015,  0.0056,  ...,  0.0181,  0.0036, -0.1367]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:33:42 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 18:33:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1018, -0.9214, -0.6958,  ...,  0.3535, -0.1494,  0.9160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2097, -0.5986, -0.6763,  ..., -0.4949, -0.2964, -0.2181],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5498, -1.8740, -1.2920,  ...,  0.7944,  0.6743,  2.4648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9795, -2.0586, -1.9170,  ..., -0.5718, -1.2266,  0.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:33:42 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:33:42 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 18:34:42 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 18:35:47 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 18:36:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.9182e-05, -5.9700e-03,  8.7643e-04,  ...,  7.4806e-03,
          4.5991e-04, -4.1008e-03],
        [-3.4485e-03,  1.0803e-02,  2.6474e-03,  ...,  5.2872e-03,
          4.7226e-03,  5.4245e-03],
        [-4.9629e-03, -2.2078e-04,  4.9171e-03,  ...,  1.9302e-03,
          2.9411e-03, -1.4296e-03],
        ...,
        [ 4.6959e-03, -4.1199e-03, -2.7046e-03,  ...,  9.1248e-03,
         -1.0002e-02, -8.0185e-03],
        [-1.6451e-04,  3.1147e-03,  2.2912e-04,  ...,  6.1531e-03,
          9.8572e-03,  6.2370e-04],
        [ 4.5357e-03,  5.0659e-03,  2.0752e-03,  ..., -3.8757e-03,
          7.3204e-03,  9.0504e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0698,  0.0106, -0.0030,  ...,  0.0028, -0.0048, -0.0100],
        [-0.0118, -0.0622, -0.0050,  ...,  0.0107, -0.0091,  0.0004],
        [-0.0140, -0.0145, -0.0556,  ..., -0.0020, -0.0095,  0.0065],
        ...,
        [-0.0012, -0.0057, -0.0034,  ..., -0.0511, -0.0068,  0.0013],
        [-0.0047,  0.0005, -0.0120,  ...,  0.0129, -0.0634,  0.0010],
        [ 0.0020,  0.0067,  0.0091,  ..., -0.0084,  0.0018, -0.0704]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0787, -0.0027, -0.0122,  ...,  0.0007, -0.0062, -0.0204],
        [ 0.0096, -0.0754, -0.0072,  ...,  0.0048, -0.0048,  0.0126],
        [ 0.0020,  0.0005, -0.0912,  ..., -0.0135, -0.0142,  0.0003],
        ...,
        [ 0.0038,  0.0031, -0.0069,  ..., -0.0839,  0.0059,  0.0006],
        [ 0.0137,  0.0133, -0.0150,  ...,  0.0126, -0.0888, -0.0059],
        [-0.0066,  0.0184,  0.0040,  ..., -0.0003, -0.0060, -0.0951]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:36:50 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 18:36:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4646, -0.9292, -0.6675,  ...,  0.2211,  0.2732,  0.9160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0477, -0.7217, -1.0723,  ..., -0.6060, -0.4773, -0.1317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7183, -1.3213, -0.4077,  ...,  0.3115,  0.5469,  3.7148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.3047, -1.3652, -1.6992,  ..., -0.6855, -1.6377,  0.0210],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:36:50 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:36:50 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 18:37:54 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 18:39:00 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 18:40:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.9135e-02, -2.0618e-03,  1.9245e-03,  ...,  3.9101e-03,
          9.9087e-04,  8.3008e-03],
        [-4.3869e-03, -1.6312e-02,  1.0910e-03,  ...,  2.6207e-03,
          9.7179e-04, -7.4806e-03],
        [-1.9360e-03,  3.9215e-03, -1.7258e-02,  ...,  5.7316e-04,
         -2.7599e-03,  2.7256e-03],
        ...,
        [ 1.9455e-04, -1.9407e-03, -4.3094e-05,  ..., -1.5732e-02,
          4.6692e-03,  6.3801e-04],
        [-1.1406e-03,  7.2632e-03, -1.8206e-03,  ...,  4.4250e-03,
         -2.5192e-02, -7.2403e-03],
        [ 1.7376e-03,  1.8053e-03,  1.6880e-03,  ..., -3.2234e-03,
         -6.8970e-03, -2.0493e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1071, -0.0067,  0.0090,  ..., -0.0069,  0.0004,  0.0168],
        [ 0.0126, -0.0876,  0.0118,  ...,  0.0025,  0.0078, -0.0112],
        [-0.0084,  0.0021, -0.0904,  ..., -0.0151, -0.0066,  0.0175],
        ...,
        [ 0.0084, -0.0105,  0.0059,  ..., -0.0918,  0.0026, -0.0082],
        [ 0.0008,  0.0004,  0.0068,  ...,  0.0128, -0.1072,  0.0053],
        [ 0.0017,  0.0093, -0.0075,  ..., -0.0117, -0.0145, -0.0781]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0980,  0.0026, -0.0038,  ..., -0.0093,  0.0005,  0.0120],
        [-0.0008, -0.0941, -0.0061,  ...,  0.0015, -0.0057, -0.0169],
        [ 0.0109,  0.0023, -0.1096,  ..., -0.0015, -0.0013,  0.0116],
        ...,
        [-0.0153, -0.0203, -0.0092,  ..., -0.1028,  0.0039,  0.0037],
        [ 0.0100,  0.0119,  0.0275,  ...,  0.0087, -0.1015,  0.0152],
        [ 0.0159, -0.0013,  0.0050,  ...,  0.0070, -0.0019, -0.0922]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:40:09 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 18:40:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2463, -0.7510, -0.5225,  ...,  0.3110,  0.2771,  0.9673],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4321, -0.9233, -0.8564,  ..., -0.2583, -0.5581,  0.2537],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5723, -1.5127,  0.0825,  ..., -0.1982,  0.4453,  3.9512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1201, -1.1553, -1.9668,  ..., -0.3545, -1.0742,  0.0824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:40:09 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:40:09 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 18:41:16 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 18:42:26 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 18:43:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0009, -0.0009, -0.0030,  ...,  0.0006, -0.0010, -0.0005],
        [ 0.0004, -0.0024,  0.0017,  ...,  0.0007,  0.0004, -0.0019],
        [ 0.0003, -0.0016, -0.0013,  ...,  0.0025,  0.0005,  0.0003],
        ...,
        [-0.0006,  0.0025,  0.0019,  ...,  0.0006, -0.0016, -0.0005],
        [-0.0002, -0.0024,  0.0035,  ..., -0.0018, -0.0032,  0.0004],
        [ 0.0001, -0.0016, -0.0006,  ...,  0.0011, -0.0004, -0.0030]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0747, -0.0032, -0.0139,  ..., -0.0050, -0.0041, -0.0093],
        [ 0.0056, -0.0883,  0.0042,  ..., -0.0061,  0.0010,  0.0002],
        [ 0.0164, -0.0014, -0.0748,  ...,  0.0006,  0.0133, -0.0031],
        ...,
        [-0.0110,  0.0126, -0.0067,  ..., -0.0849,  0.0069, -0.0010],
        [ 0.0081,  0.0057,  0.0052,  ..., -0.0100, -0.0724,  0.0217],
        [-0.0051, -0.0029,  0.0121,  ...,  0.0117,  0.0223, -0.0980]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1295,  0.0129, -0.0168,  ..., -0.0126, -0.0094, -0.0005],
        [ 0.0110, -0.1558,  0.0035,  ...,  0.0133,  0.0192, -0.0064],
        [ 0.0070, -0.0126, -0.1407,  ..., -0.0084,  0.0061, -0.0130],
        ...,
        [-0.0077,  0.0072, -0.0059,  ..., -0.1359,  0.0123, -0.0156],
        [-0.0023,  0.0015, -0.0157,  ..., -0.0174, -0.1331,  0.0207],
        [ 0.0012, -0.0117, -0.0035,  ...,  0.0168, -0.0130, -0.1440]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:43:36 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 18:43:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2976, -0.5293, -0.1794,  ...,  0.1140,  0.2347,  1.4414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6143, -0.6382, -0.7817,  ..., -0.3171, -0.7363, -0.0350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1328, -0.5986,  0.1584,  ...,  0.4165,  1.4648,  2.9355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2266, -1.5527, -0.2344,  ..., -0.6338, -0.7080,  0.4658],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:43:36 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:43:36 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 18:44:43 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 18:45:52 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 18:47:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0063, -0.0007,  0.0033,  ...,  0.0032, -0.0046, -0.0061],
        [ 0.0032,  0.0090, -0.0040,  ...,  0.0061, -0.0020, -0.0021],
        [-0.0010,  0.0010,  0.0089,  ..., -0.0084,  0.0012,  0.0034],
        ...,
        [ 0.0005,  0.0003, -0.0053,  ...,  0.0097,  0.0019, -0.0012],
        [ 0.0024, -0.0028, -0.0030,  ...,  0.0043,  0.0130,  0.0026],
        [-0.0002, -0.0006,  0.0030,  ..., -0.0014, -0.0045,  0.0112]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0244,  0.0025, -0.0009,  ...,  0.0100,  0.0026,  0.0083],
        [ 0.0026, -0.0147, -0.0064,  ..., -0.0064, -0.0034, -0.0089],
        [-0.0093,  0.0041, -0.0150,  ..., -0.0007, -0.0107, -0.0005],
        ...,
        [-0.0079, -0.0182, -0.0008,  ..., -0.0237, -0.0063, -0.0103],
        [ 0.0031, -0.0101, -0.0034,  ...,  0.0078, -0.0388,  0.0033],
        [-0.0105,  0.0018, -0.0045,  ..., -0.0026,  0.0077, -0.0364]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0574,  0.0070,  0.0070,  ..., -0.0077, -0.0016, -0.0193],
        [-0.0106, -0.0350,  0.0038,  ...,  0.0159, -0.0076,  0.0051],
        [ 0.0024,  0.0195, -0.0457,  ...,  0.0002, -0.0016,  0.0003],
        ...,
        [-0.0011,  0.0021,  0.0009,  ..., -0.0403, -0.0124, -0.0004],
        [-0.0053,  0.0024, -0.0118,  ...,  0.0111, -0.0339,  0.0190],
        [-0.0058, -0.0033,  0.0029,  ..., -0.0232, -0.0025, -0.0435]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:47:04 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 18:47:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2180, -0.5747,  0.0077,  ..., -0.0726,  0.1542,  1.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4788, -0.5000, -0.8101,  ..., -0.1453, -0.4490,  0.0025],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3611, -0.8716,  0.5459,  ...,  0.2646,  0.6948,  2.3105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.4199, -1.0293, -0.4707,  ..., -0.8506, -1.0723,  0.7729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:47:04 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:47:04 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 18:48:17 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 18:49:30 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 18:50:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6279e-03, -4.9925e-04, -2.6608e-03,  ...,  1.4439e-03,
         -1.3838e-03,  1.2846e-03],
        [-2.5787e-03, -4.7989e-03,  1.1768e-03,  ..., -3.1719e-03,
         -5.0774e-03,  2.5940e-03],
        [ 2.0599e-04, -2.5368e-03, -9.8419e-03,  ..., -2.4586e-03,
          3.1242e-03,  4.9286e-03],
        ...,
        [-3.8414e-03, -4.9133e-03,  2.7275e-03,  ..., -3.5458e-03,
          3.5248e-03, -4.1199e-03],
        [-3.8414e-03,  2.8253e-05,  6.6853e-04,  ...,  4.5052e-03,
         -2.3079e-03, -3.8204e-03],
        [-1.5678e-03, -1.9920e-04, -3.7060e-03,  ..., -3.3016e-03,
         -2.9469e-03, -5.1613e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0145,  0.0026,  0.0069,  ..., -0.0028,  0.0084,  0.0052],
        [ 0.0005, -0.0246,  0.0026,  ...,  0.0283,  0.0082, -0.0044],
        [-0.0083,  0.0139, -0.0226,  ..., -0.0101,  0.0031, -0.0095],
        ...,
        [-0.0055, -0.0166, -0.0071,  ..., -0.0030, -0.0006, -0.0099],
        [ 0.0084,  0.0027, -0.0138,  ...,  0.0091, -0.0225,  0.0098],
        [-0.0130,  0.0026, -0.0043,  ...,  0.0004, -0.0019, -0.0320]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.5786e-02,  9.8572e-03,  5.8212e-03,  ...,  3.3936e-02,
          1.8883e-04,  6.2180e-03],
        [-9.8572e-03, -6.7078e-02, -5.6915e-03,  ...,  1.8204e-02,
         -5.7373e-03,  2.8900e-02],
        [-1.8341e-02, -1.2302e-04, -6.1310e-02,  ..., -3.3493e-03,
          7.7362e-03, -2.0142e-02],
        ...,
        [-8.5907e-03, -5.1689e-03, -1.7303e-02,  ..., -4.9896e-02,
         -8.8501e-03, -1.3748e-02],
        [ 2.4204e-03,  5.7983e-03, -4.2648e-03,  ...,  3.8147e-05,
         -4.0039e-02,  8.1348e-04],
        [-1.6815e-02, -1.2253e-02,  7.5340e-04,  ...,  6.0120e-03,
         -6.3057e-03, -7.7026e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:50:45 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 18:50:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0433, -0.2234,  0.0427,  ...,  0.1305,  0.5166,  1.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9004, -0.6392, -0.1043,  ..., -0.2673, -0.2764,  0.1619],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5425, -1.0078,  0.7441,  ..., -0.3179,  0.6943,  2.4355],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.3887, -0.2554, -0.0776,  ..., -0.1104, -2.1035,  0.4714],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:50:45 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:50:45 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 18:52:06 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 18:53:27 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 18:54:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0016, -0.0052, -0.0025,  ...,  0.0043, -0.0018,  0.0042],
        [ 0.0003, -0.0077, -0.0011,  ...,  0.0020,  0.0035,  0.0011],
        [-0.0024,  0.0005, -0.0004,  ...,  0.0014, -0.0023,  0.0013],
        ...,
        [ 0.0039,  0.0018,  0.0001,  ...,  0.0013, -0.0027,  0.0008],
        [ 0.0004,  0.0026,  0.0038,  ..., -0.0005, -0.0056, -0.0081],
        [-0.0009,  0.0009,  0.0009,  ...,  0.0003,  0.0055,  0.0024]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0226, -0.0192, -0.0109,  ..., -0.0085,  0.0014,  0.0220],
        [-0.0222, -0.0424,  0.0016,  ...,  0.0006,  0.0175, -0.0008],
        [ 0.0113, -0.0096,  0.0015,  ...,  0.0120, -0.0015, -0.0047],
        ...,
        [ 0.0004, -0.0033, -0.0050,  ..., -0.0272,  0.0041, -0.0117],
        [-0.0014,  0.0032,  0.0103,  ...,  0.0027, -0.0377,  0.0079],
        [-0.0038,  0.0123, -0.0038,  ..., -0.0045,  0.0021, -0.0280]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0287, -0.0025, -0.0023,  ..., -0.0085,  0.0021,  0.0118],
        [-0.0100, -0.0638, -0.0184,  ...,  0.0101,  0.0090,  0.0115],
        [ 0.0034, -0.0069, -0.0527,  ..., -0.0009,  0.0003,  0.0094],
        ...,
        [ 0.0083, -0.0135, -0.0106,  ..., -0.0443, -0.0061,  0.0037],
        [ 0.0205, -0.0038, -0.0103,  ..., -0.0025, -0.0606, -0.0052],
        [ 0.0007, -0.0055, -0.0127,  ..., -0.0116,  0.0101, -0.0525]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:54:50 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 18:54:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1235, -0.2969,  0.1691,  ...,  0.0922,  0.2484,  0.7803],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3633, -0.3975, -0.1935,  ..., -0.3220, -0.4128,  0.2771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1045, -1.6006,  2.7871,  ..., -0.8906,  1.3545,  3.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 5.2734, -0.0698,  0.8643,  ..., -0.1476, -4.5703,  1.3682],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:54:50 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:54:50 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 18:56:13 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 18:57:36 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 18:58:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.5436e-04, -1.2302e-04,  9.1016e-05,  ..., -2.1279e-05,
         -1.0091e-04, -7.4744e-05],
        [ 4.6587e-04, -8.7643e-04,  1.0163e-04,  ...,  2.0063e-04,
         -3.7014e-05,  6.7532e-05],
        [-1.6809e-04,  1.9312e-04, -7.7248e-04,  ..., -1.4794e-04,
         -7.2598e-05, -1.7524e-05],
        ...,
        [-9.9003e-05,  2.7275e-04,  3.7730e-05,  ..., -8.3065e-04,
          2.1291e-04, -3.0696e-05],
        [ 1.8287e-04,  1.6057e-04, -7.0989e-05,  ..., -2.7180e-05,
         -8.9788e-04,  6.2704e-05],
        [-1.3816e-04,  4.5133e-04,  1.0538e-04,  ..., -1.4114e-04,
          3.1590e-06, -9.0313e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0222,  0.0030, -0.0120,  ..., -0.0003,  0.0061,  0.0108],
        [-0.0049, -0.0190, -0.0047,  ..., -0.0120, -0.0027, -0.0020],
        [-0.0120, -0.0059, -0.0228,  ..., -0.0049,  0.0075,  0.0037],
        ...,
        [-0.0006,  0.0019, -0.0133,  ..., -0.0192,  0.0132,  0.0140],
        [ 0.0131,  0.0143,  0.0109,  ...,  0.0069, -0.0297, -0.0099],
        [ 0.0099, -0.0061, -0.0042,  ..., -0.0099, -0.0133, -0.0208]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0403,  0.0283, -0.0126,  ...,  0.0078,  0.0023, -0.0016],
        [ 0.0125, -0.0177, -0.0105,  ..., -0.0157,  0.0022,  0.0014],
        [-0.0051, -0.0047, -0.0568,  ...,  0.0013,  0.0068,  0.0001],
        ...,
        [ 0.0169,  0.0034, -0.0046,  ..., -0.0748, -0.0004,  0.0085],
        [ 0.0321, -0.0034, -0.0046,  ...,  0.0082, -0.0578, -0.0105],
        [ 0.0167, -0.0113,  0.0097,  ..., -0.0077, -0.0116, -0.0527]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 18:59:01 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 18:59:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1924, -0.3303,  0.2157,  ..., -0.1009,  0.2499,  0.7920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3008, -0.0945, -0.0541,  ..., -0.0368, -0.7700,  0.1466],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2578, -1.6357,  2.8477,  ..., -1.6162,  1.2793,  3.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 5.5234,  0.2009,  1.5518,  ...,  0.6401, -5.4609,  1.2578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 18:59:01 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 18:59:01 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 19:00:24 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 19:01:42 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 19:02:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.5890e-05,  3.0994e-04, -2.4557e-04,  ...,  2.9755e-04,
         -7.1049e-04,  4.5252e-04],
        [-3.0661e-04,  1.0290e-03,  2.1982e-04,  ...,  6.4230e-04,
          5.0187e-05, -1.4091e-04],
        [ 7.1478e-04,  1.2293e-03,  6.7329e-04,  ...,  4.1127e-05,
         -4.4107e-06,  3.5381e-04],
        ...,
        [ 7.4482e-04, -5.2786e-04, -1.1212e-04,  ...,  5.2023e-04,
          7.5042e-05, -2.0421e-04],
        [-4.0770e-04, -3.5214e-04, -6.9046e-04,  ...,  4.2939e-04,
          3.2806e-04,  1.0908e-05],
        [ 1.1272e-03,  7.8440e-04,  8.3828e-04,  ..., -9.6893e-04,
         -9.1076e-05,  1.5676e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0267, -0.0032, -0.0086,  ...,  0.0072,  0.0084,  0.0136],
        [ 0.0262, -0.0370,  0.0038,  ..., -0.0013,  0.0110, -0.0054],
        [ 0.0079, -0.0109, -0.0074,  ..., -0.0028,  0.0106,  0.0101],
        ...,
        [ 0.0031, -0.0148, -0.0005,  ..., -0.0082,  0.0013, -0.0032],
        [ 0.0060, -0.0183,  0.0019,  ...,  0.0073, -0.0232,  0.0084],
        [ 0.0048, -0.0055, -0.0045,  ..., -0.0248,  0.0110, -0.0126]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.6172e-02, -8.5068e-03, -2.7466e-04,  ..., -5.1193e-03,
          7.3929e-03, -7.3051e-03],
        [ 3.0255e-04, -6.9885e-02,  2.4261e-02,  ..., -1.2367e-02,
         -1.3084e-02, -1.2894e-03],
        [ 2.2873e-02,  8.5297e-03, -7.6050e-02,  ...,  1.6479e-03,
         -1.6327e-02,  1.5182e-03],
        ...,
        [ 3.5305e-03, -1.8692e-03,  3.7270e-03,  ..., -6.7932e-02,
         -2.7344e-02, -5.9509e-04],
        [ 1.0895e-02, -2.0187e-02, -1.1780e-02,  ..., -8.3923e-05,
         -1.2335e-01, -2.2995e-02],
        [ 2.3285e-02, -4.5586e-03,  3.4332e-03,  ..., -1.2665e-02,
         -5.3902e-03, -9.7595e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:03:00 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 19:03:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3601, -0.4688,  0.8325,  ..., -0.2896,  0.4443,  1.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.9365e+00, -6.2406e-05,  2.6074e-01,  ..., -6.2561e-02,
        -1.6582e+00,  4.7314e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2324, -1.2793,  3.3945,  ..., -1.0996,  1.8652,  3.6836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 5.1719,  0.6016,  3.0195,  ...,  1.2617, -3.8945,  2.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:03:00 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 19:03:00 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 19:04:13 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 19:05:34 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 19:06:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.2064e-04,  4.4727e-04,  4.5729e-04,  ...,  6.4278e-04,
          1.9586e-04,  7.9679e-04],
        [-4.7803e-05,  6.7854e-04, -3.6407e-04,  ..., -3.2711e-04,
         -1.2426e-03, -1.0099e-03],
        [ 1.1468e-04,  1.0115e-04,  8.0061e-04,  ..., -8.3494e-04,
          8.5497e-04,  1.1545e-04],
        ...,
        [-1.3161e-04, -1.2093e-03,  9.0957e-05,  ...,  8.8787e-04,
          1.3006e-04, -1.6451e-04],
        [ 2.1148e-04, -4.9829e-04, -1.8764e-04,  ...,  8.7833e-04,
          5.6934e-04, -9.3222e-04],
        [ 1.2755e-04, -7.0000e-04, -6.8283e-04,  ..., -2.1815e-04,
         -2.5320e-04,  1.2960e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0107, -0.0103, -0.0052,  ..., -0.0105,  0.0113, -0.0026],
        [-0.0119, -0.0413, -0.0006,  ...,  0.0113,  0.0080,  0.0162],
        [ 0.0038, -0.0167,  0.0131,  ...,  0.0088,  0.0171, -0.0083],
        ...,
        [-0.0133, -0.0041, -0.0049,  ...,  0.0253, -0.0053, -0.0132],
        [ 0.0048, -0.0207, -0.0012,  ...,  0.0289,  0.0010,  0.0154],
        [-0.0031, -0.0020, -0.0169,  ..., -0.0012, -0.0019,  0.0073]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0537, -0.0005,  0.0023,  ...,  0.0001, -0.0138, -0.0054],
        [ 0.0068, -0.0249,  0.0237,  ...,  0.0020, -0.0005,  0.0066],
        [-0.0002, -0.0131, -0.0249,  ...,  0.0099, -0.0077, -0.0021],
        ...,
        [-0.0072, -0.0174, -0.0276,  ..., -0.0203, -0.0007, -0.0107],
        [-0.0029, -0.0186, -0.0113,  ..., -0.0115, -0.0302,  0.0374],
        [-0.0183,  0.0215, -0.0105,  ...,  0.0238,  0.0116, -0.0450]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:06:57 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 19:06:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7188, -0.4595,  0.8159,  ..., -0.5293,  0.3855,  0.9116],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.9902,  0.0899,  0.4922,  ...,  0.1852, -1.9297,  0.4133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0996, -1.2773,  2.9414,  ..., -0.7544,  2.4844,  3.6074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 6.8125,  1.1211,  4.1562,  ...,  0.6641, -4.1094,  1.8164],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:06:57 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 19:06:57 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 19:08:16 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 19:09:37 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 19:10:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.2360e-05, -2.2292e-04, -2.5368e-04,  ..., -1.0258e-04,
          2.0051e-04, -6.2275e-04],
        [-1.0471e-03, -8.4829e-04,  2.7156e-04,  ..., -9.0981e-04,
          1.4925e-04, -1.7452e-04],
        [-1.0705e-04,  1.1986e-04, -3.3021e-04,  ..., -4.6730e-04,
          3.6311e-04, -1.4949e-04],
        ...,
        [ 3.5977e-04, -4.6778e-04, -7.4577e-04,  ...,  9.7334e-05,
          7.9989e-05, -1.9598e-04],
        [ 1.2722e-03,  2.6846e-04, -1.7071e-04,  ...,  3.8052e-04,
         -5.4836e-04, -7.6234e-05],
        [ 1.8096e-04, -5.8699e-04,  9.7847e-04,  ..., -4.5180e-04,
          2.9969e-04, -3.4750e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0100,  0.0095,  0.0162,  ..., -0.0013, -0.0101, -0.0040],
        [-0.0204, -0.0312,  0.0116,  ..., -0.0031, -0.0015, -0.0132],
        [ 0.0151, -0.0079,  0.0061,  ..., -0.0022,  0.0029,  0.0073],
        ...,
        [-0.0012, -0.0013, -0.0035,  ...,  0.0078,  0.0051, -0.0076],
        [ 0.0038,  0.0195, -0.0044,  ...,  0.0023, -0.0018,  0.0044],
        [-0.0045, -0.0072,  0.0030,  ...,  0.0065,  0.0065, -0.0058]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0252, -0.0107,  0.0279,  ...,  0.0107, -0.0113,  0.0034],
        [ 0.0044, -0.0309,  0.0274,  ...,  0.0047,  0.0093,  0.0025],
        [-0.0042,  0.0083, -0.0214,  ...,  0.0003, -0.0213,  0.0123],
        ...,
        [-0.0006, -0.0089, -0.0006,  ..., -0.0318,  0.0044, -0.0063],
        [ 0.0090,  0.0067, -0.0445,  ..., -0.0080, -0.0431,  0.0165],
        [-0.0027,  0.0119, -0.0047,  ...,  0.0251,  0.0201, -0.0643]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:10:59 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 19:10:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3965, -0.3167,  0.8389,  ..., -0.4004,  0.4829,  0.9771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.8027,  0.2205,  0.9033,  ...,  0.3147, -1.3115,  0.7417],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.4609, -0.6562,  1.2520,  ..., -1.7520,  3.2266,  2.3379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 8.3438,  1.1406,  3.8379,  ...,  0.2007, -4.1445,  1.4014],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:10:59 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 19:10:59 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 19:12:20 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 19:13:45 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 19:15:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0147e-03, -6.5804e-04, -2.8062e-04,  ...,  3.7098e-04,
         -1.5306e-04, -2.2674e-04],
        [ 5.5647e-04, -6.2644e-05,  1.7118e-04,  ..., -1.7250e-04,
          6.6280e-04,  5.2023e-04],
        [ 8.9407e-04, -1.0595e-03, -2.1219e-04,  ..., -3.3379e-05,
         -9.4938e-04,  3.4142e-04],
        ...,
        [-1.0049e-04,  1.5879e-04,  1.1694e-04,  ..., -3.9291e-04,
         -2.9659e-04,  2.6798e-04],
        [ 4.1866e-04, -3.4547e-04, -3.4809e-04,  ..., -1.2118e-04,
         -2.4796e-04, -9.7454e-05],
        [-1.8287e-04,  3.2425e-04, -2.8777e-04,  ...,  8.6308e-05,
         -3.7074e-04,  2.3794e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0545,  0.0009, -0.0014,  ..., -0.0040, -0.0005,  0.0001],
        [ 0.0023, -0.0022,  0.0021,  ..., -0.0170,  0.0075, -0.0026],
        [-0.0050,  0.0053,  0.0226,  ..., -0.0126,  0.0085,  0.0110],
        ...,
        [-0.0127,  0.0059,  0.0034,  ...,  0.0611, -0.0079, -0.0078],
        [ 0.0083,  0.0058, -0.0291,  ..., -0.0162,  0.0417,  0.0143],
        [-0.0170,  0.0318,  0.0035,  ...,  0.0135,  0.0024,  0.0546]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0211,  0.0114,  0.0247,  ..., -0.0115,  0.0094,  0.0010],
        [ 0.0353, -0.0371, -0.0091,  ..., -0.0256,  0.0081, -0.0058],
        [ 0.0088, -0.0044, -0.0366,  ..., -0.0197, -0.0063,  0.0045],
        ...,
        [ 0.0009,  0.0094, -0.0082,  ..., -0.0091,  0.0038,  0.0049],
        [ 0.0136, -0.0114, -0.0175,  ...,  0.0107, -0.0220, -0.0170],
        [-0.0067,  0.0112,  0.0290,  ...,  0.0067, -0.0258, -0.0072]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:15:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The butterfly falls into the category of insect
The goat falls into the category of bovid
The falcon falls into the category of raptor
The jackal falls into the category of canine
The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The vulture falls into the category of raptor
The gorilla falls into the category of
2024-06-30 19:15:14 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 19:15:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2129, -0.2681, -0.9995,  ..., -0.0465,  0.3621,  0.1009],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4666, -0.1047, -0.5562,  ..., -0.1688, -0.8989, -0.3855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0249, -0.5850, -0.8804,  ..., -0.8716,  0.5654,  0.3928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4812,  0.1079, -0.2520,  ..., -0.5322, -0.3818, -0.4846],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:15:14 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:15:14 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 19:15:37 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 19:16:00 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 19:16:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.3879e-04, -2.1458e-04,  8.1241e-05,  ..., -2.9373e-04,
         -1.2338e-05,  1.5187e-04],
        [ 1.0633e-04, -2.2948e-04, -2.0766e-04,  ..., -2.1040e-04,
          2.2173e-04,  1.0848e-04],
        [-4.2140e-05, -1.2010e-04, -5.7983e-04,  ..., -2.6608e-04,
         -3.9649e-04, -3.8004e-04],
        ...,
        [-5.0783e-05, -1.7643e-04,  3.3617e-05,  ..., -9.8526e-05,
          3.9673e-04, -7.7486e-05],
        [-7.2777e-05,  7.4029e-05,  3.2365e-05,  ...,  4.0650e-05,
         -5.7125e-04,  5.8591e-05],
        [ 2.1875e-04, -8.2731e-05,  3.6812e-04,  ..., -9.4533e-05,
          4.3178e-04, -5.1355e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0216,  0.0018,  0.0033,  ...,  0.0023, -0.0072,  0.0116],
        [-0.0033, -0.0288,  0.0003,  ...,  0.0005, -0.0021,  0.0002],
        [ 0.0096, -0.0029, -0.0246,  ..., -0.0031,  0.0068,  0.0016],
        ...,
        [ 0.0032,  0.0074, -0.0002,  ..., -0.0241,  0.0011,  0.0027],
        [ 0.0048,  0.0043,  0.0029,  ...,  0.0011, -0.0162,  0.0098],
        [ 0.0044, -0.0022,  0.0075,  ...,  0.0027, -0.0001, -0.0184]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0303,  0.0003,  0.0064,  ..., -0.0008, -0.0015,  0.0003],
        [ 0.0004, -0.0265, -0.0061,  ..., -0.0019,  0.0019,  0.0003],
        [-0.0003,  0.0022, -0.0252,  ...,  0.0004, -0.0020,  0.0061],
        ...,
        [ 0.0016,  0.0033,  0.0011,  ..., -0.0227,  0.0031,  0.0021],
        [-0.0015,  0.0020, -0.0003,  ..., -0.0001, -0.0251,  0.0006],
        [-0.0009, -0.0025, -0.0030,  ...,  0.0010,  0.0006, -0.0280]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:16:24 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 19:16:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2698, -1.1328, -0.9463,  ..., -1.0283,  0.4963,  0.0974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5659,  0.1594, -0.3652,  ..., -1.0586, -0.4165, -0.4790],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3276, -0.8037, -1.1250,  ..., -1.1348,  0.3325,  0.1233],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2544, -0.1034,  0.2778,  ..., -1.1680, -0.5586, -0.6025],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:16:24 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:16:24 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 19:16:48 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 19:17:12 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 19:17:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.4620e-03,  4.6015e-04, -7.6246e-04,  ..., -1.2655e-03,
         -3.0327e-04, -7.1430e-04],
        [ 1.1146e-04, -3.2215e-03, -1.8167e-04,  ...,  8.2207e-04,
         -4.1795e-04,  2.6512e-04],
        [ 9.7632e-05,  2.8372e-04, -3.0556e-03,  ..., -1.3804e-04,
         -2.0945e-04, -3.0446e-04],
        ...,
        [-2.3973e-04,  1.9526e-04, -2.9385e-05,  ..., -2.1191e-03,
         -5.9223e-04, -3.8409e-04],
        [ 1.3518e-04,  5.2261e-04,  8.2159e-04,  ...,  2.9445e-05,
         -2.7294e-03, -1.0967e-05],
        [-1.2743e-04,  8.1301e-05,  4.2629e-04,  ..., -1.1545e-04,
          2.2507e-04, -2.1954e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.7079e-02, -1.4252e-02, -2.8706e-03,  ..., -8.3618e-03,
         -1.7624e-02,  3.1166e-03],
        [ 8.4991e-03, -3.2104e-02,  1.8864e-03,  ...,  3.4142e-03,
         -4.3106e-03, -3.4571e-04],
        [ 1.1196e-03, -8.0719e-03, -2.8397e-02,  ..., -1.0071e-02,
         -4.3106e-03,  5.8060e-03],
        ...,
        [ 6.3419e-05, -4.3755e-03,  1.7233e-03,  ..., -4.9622e-02,
         -5.5809e-03, -9.7733e-03],
        [-5.7602e-03,  5.4169e-03,  2.8343e-03,  ..., -2.1172e-04,
         -4.1138e-02, -1.1398e-02],
        [ 3.6144e-03, -1.2344e-02,  5.1003e-03,  ..., -3.6964e-03,
         -1.5587e-02, -4.5349e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.0089e-02,  1.0529e-03, -3.2501e-03,  ...,  6.8970e-03,
          5.2948e-03,  2.1439e-03],
        [-1.7405e-03, -6.3965e-02, -3.7079e-03,  ..., -1.2350e-03,
         -1.4744e-03, -4.1084e-03],
        [ 4.4823e-04,  3.1395e-03, -6.0852e-02,  ...,  2.6932e-03,
          2.9316e-03, -1.9455e-04],
        ...,
        [ 3.3112e-03, -4.4250e-03,  1.2569e-03,  ..., -5.8258e-02,
         -5.5580e-03, -8.4534e-03],
        [-7.1564e-03, -5.8365e-03,  4.1161e-03,  ..., -6.4278e-03,
         -6.1676e-02,  4.5853e-03],
        [ 2.5635e-03, -1.2329e-02,  6.1836e-03,  ...,  2.3727e-03,
          6.4850e-05, -5.4169e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:17:38 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 19:17:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0109, -0.7251, -1.0312,  ..., -0.9766,  0.6519,  0.4548],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7803,  0.1552, -0.3953,  ..., -0.7964, -0.5898, -0.8110],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6582, -1.0195, -1.0127,  ..., -0.7246,  0.5117,  0.8994],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4287,  0.4019,  0.1361,  ..., -0.8545, -0.7158, -0.9224],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:17:39 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:17:39 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 19:18:04 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 19:18:29 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 19:18:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.0180e-03,  2.0325e-05, -2.2292e-05,  ...,  1.6379e-04,
         -1.8477e-05,  1.5116e-04],
        [ 5.9962e-05, -1.4524e-03,  5.5075e-05,  ...,  9.1374e-05,
         -2.2078e-04,  9.4771e-05],
        [ 4.1199e-04, -1.0949e-04, -1.4849e-03,  ...,  2.2388e-04,
          1.3208e-04, -2.4056e-04],
        ...,
        [ 1.7500e-04,  6.2656e-04,  1.4091e-04,  ..., -1.4381e-03,
          2.7943e-04, -1.9205e-04],
        [-1.7238e-04, -9.3758e-05, -1.7309e-04,  ...,  3.5858e-04,
         -1.3971e-03, -3.5906e-04],
        [ 4.2009e-04,  1.9217e-04,  5.4419e-05,  ..., -2.8801e-04,
         -2.3103e-04, -1.2989e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0345, -0.0090, -0.0083,  ...,  0.0107,  0.0057,  0.0021],
        [-0.0071, -0.0334, -0.0025,  ..., -0.0009, -0.0003, -0.0024],
        [ 0.0131,  0.0060, -0.0299,  ...,  0.0006, -0.0030,  0.0004],
        ...,
        [ 0.0063, -0.0056, -0.0149,  ..., -0.0370,  0.0135, -0.0025],
        [ 0.0017,  0.0079,  0.0050,  ...,  0.0040, -0.0287,  0.0010],
        [ 0.0020, -0.0020,  0.0002,  ..., -0.0015,  0.0132, -0.0315]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.8366e-02,  2.8753e-04, -3.6163e-03,  ...,  2.2373e-03,
          3.0117e-03,  5.6152e-03],
        [-3.3512e-03, -3.3356e-02, -9.9182e-04,  ...,  7.4997e-03,
          3.6392e-03,  1.3800e-03],
        [ 5.9319e-04,  5.1022e-05, -3.4515e-02,  ..., -2.1992e-03,
         -3.8471e-03, -4.2114e-03],
        ...,
        [ 9.0075e-04,  1.9550e-03, -9.8896e-04,  ..., -2.9907e-02,
         -5.5428e-03,  3.8166e-03],
        [-6.1035e-04,  3.2425e-03, -2.2354e-03,  ..., -4.6272e-03,
         -2.9037e-02,  8.5602e-03],
        [ 2.6836e-03,  5.4054e-03,  3.1452e-03,  ..., -4.1237e-03,
          1.4238e-03, -2.8320e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:18:56 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 19:18:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3586, -0.9604, -1.2568,  ..., -1.2383,  0.3562,  0.1102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3918, -0.1722,  0.3977,  ..., -1.6045, -0.8027, -0.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6680, -1.1221, -1.0498,  ..., -0.4141,  0.6987,  0.6206],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2666,  0.6152, -0.2734,  ..., -0.9175, -0.2732, -0.4033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:18:56 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:18:56 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 19:19:25 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 19:19:55 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 19:20:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.7942e-04, -3.5572e-04, -2.5702e-04,  ...,  1.9431e-04,
          1.9538e-04, -1.3912e-04],
        [ 2.1648e-04, -1.0214e-03,  9.7275e-04,  ..., -3.9387e-04,
         -2.2638e-04, -5.2261e-04],
        [-4.0507e-04,  3.6049e-04, -3.7169e-04,  ...,  5.5552e-04,
          1.1873e-04,  5.3549e-04],
        ...,
        [ 4.6492e-04, -4.8399e-04, -2.4509e-04,  ..., -9.2173e-04,
         -4.7779e-04, -1.8573e-04],
        [-2.6321e-04,  3.7384e-04,  2.1756e-04,  ..., -6.2323e-04,
         -5.1022e-04, -3.9434e-04],
        [ 5.1689e-04, -1.8835e-04,  8.7690e-04,  ..., -5.1856e-05,
         -2.7156e-04, -1.6661e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.3579e-02,  2.9430e-03, -1.3908e-02,  ..., -5.0011e-03,
          3.6697e-03,  1.5669e-03],
        [-4.4556e-03, -3.9612e-02, -8.5602e-03,  ..., -1.8167e-03,
          3.4332e-05, -1.7452e-03],
        [-1.5106e-02, -1.9196e-02, -4.5166e-02,  ...,  1.0395e-04,
          5.1804e-03, -1.3943e-03],
        ...,
        [-4.1695e-03, -5.4398e-03, -2.4376e-03,  ..., -3.6469e-02,
         -1.4442e-02, -1.5965e-03],
        [-1.3718e-02,  9.1248e-03, -2.7161e-03,  ...,  6.9847e-03,
         -3.9001e-02, -9.0332e-03],
        [ 3.6354e-03, -5.2795e-03,  5.1880e-03,  ...,  6.4201e-03,
         -1.9073e-03, -4.0344e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.6396e-02,  1.6270e-03,  8.8310e-04,  ..., -3.8319e-03,
          8.8425e-03, -9.4299e-03],
        [ 5.7411e-03, -4.6570e-02, -5.9128e-04,  ...,  2.6531e-03,
          5.3263e-04,  6.5279e-04],
        [ 3.8147e-06, -5.8899e-03, -4.0344e-02,  ...,  4.7798e-03,
         -2.3994e-03,  2.0981e-04],
        ...,
        [-4.9934e-03, -8.3389e-03,  1.2093e-03,  ..., -6.1676e-02,
         -8.0013e-04, -1.2138e-02],
        [-9.4032e-04,  1.7853e-03, -1.2703e-02,  ..., -4.7913e-03,
         -3.9612e-02, -6.9656e-03],
        [-1.4172e-03, -1.1997e-03, -4.3583e-04,  ..., -5.2185e-03,
         -8.2588e-04, -5.2368e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:20:28 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 19:20:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5986, -1.0381, -0.9058,  ..., -0.6450,  0.5171,  0.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4465,  0.3855,  0.1420,  ..., -0.8301, -0.7041, -1.0166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9102, -0.9897, -0.9839,  ..., -0.8364,  0.6982,  0.4067],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1918,  0.1084, -0.0734,  ..., -0.6997, -0.2394, -0.5693],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:20:28 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:20:28 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 19:20:59 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 19:21:31 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 19:22:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.6325e-04,  6.7663e-04, -1.1215e-03,  ...,  9.3412e-04,
         -7.3385e-04,  6.3658e-05],
        [-1.9431e-04,  8.8310e-04, -2.5296e-04,  ...,  6.4182e-04,
         -4.0317e-04, -4.7922e-04],
        [ 1.0481e-03,  7.8201e-04, -1.0452e-03,  ..., -1.5891e-04,
          4.0102e-04,  8.4972e-04],
        ...,
        [-4.1747e-04,  7.9489e-04, -2.6822e-04,  ..., -6.6042e-04,
         -8.6498e-04,  1.1511e-03],
        [ 6.9427e-04,  2.0385e-04, -3.4275e-03,  ..., -5.0402e-04,
          1.0195e-03, -1.0085e-04],
        [-3.6478e-05, -4.2439e-04, -6.1321e-04,  ..., -7.5054e-04,
         -1.5459e-03, -1.7385e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0854,  0.0149,  0.0137,  ..., -0.0039,  0.0060, -0.0092],
        [-0.0012, -0.0922,  0.0049,  ...,  0.0044, -0.0013,  0.0043],
        [-0.0017, -0.0109, -0.0873,  ..., -0.0016,  0.0039, -0.0064],
        ...,
        [ 0.0031, -0.0037, -0.0124,  ..., -0.0761, -0.0039,  0.0047],
        [ 0.0066, -0.0061, -0.0071,  ...,  0.0014, -0.0879,  0.0060],
        [-0.0040,  0.0021, -0.0075,  ...,  0.0032, -0.0004, -0.0931]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0724e-01,  8.9264e-04,  1.2024e-02,  ...,  2.9564e-05,
         -5.0211e-04, -4.0627e-03],
        [ 8.4257e-04, -1.1444e-01,  3.2520e-03,  ..., -4.3602e-03,
         -7.1259e-03, -5.7755e-03],
        [ 1.2302e-03,  3.5172e-03, -1.1224e-01,  ...,  4.8523e-03,
          6.1836e-03,  4.6730e-05],
        ...,
        [ 9.3460e-04,  3.1376e-03,  1.0891e-03,  ..., -9.7717e-02,
          1.0864e-02, -5.9891e-04],
        [ 8.5258e-04,  4.1199e-03,  3.5191e-03,  ..., -5.6763e-03,
         -1.0803e-01,  5.8899e-03],
        [-5.0316e-03, -7.8487e-04, -1.6212e-03,  ..., -5.4932e-03,
          6.7940e-03, -1.0962e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:22:07 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 19:22:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5879, -1.0293, -0.8926,  ..., -0.3440,  0.5908,  0.5371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2900,  0.6733, -0.2910,  ..., -0.9487, -0.3074, -0.4670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1797, -1.1621, -0.8423,  ..., -0.9219, -0.0049,  0.4834],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5405,  0.1477, -0.3071,  ...,  0.0151, -0.3589, -0.6553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:22:07 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:22:07 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 19:22:42 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 19:23:17 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 19:23:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.4332e-03, -1.2350e-03,  2.3727e-03,  ..., -1.1530e-03,
          4.8542e-04,  8.4305e-04],
        [-4.4966e-04, -2.3041e-03,  1.5469e-03,  ..., -2.6655e-04,
          1.7262e-03,  2.5272e-05],
        [ 7.6818e-04,  3.2997e-04, -4.4289e-03,  ...,  1.1806e-03,
          5.6887e-04, -5.6610e-03],
        ...,
        [-1.0943e-04,  1.0500e-03,  7.8678e-04,  ..., -4.0855e-03,
         -5.1689e-04,  8.7595e-04],
        [ 2.8000e-03, -1.9283e-03, -6.2656e-04,  ..., -1.4629e-03,
         -1.4820e-03, -1.4992e-03],
        [ 8.6880e-04, -2.5797e-04,  1.3485e-03,  ..., -2.8229e-04,
         -1.0366e-03, -4.0436e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0836, -0.0044,  0.0026,  ...,  0.0156,  0.0005, -0.0006],
        [-0.0052, -0.0913,  0.0057,  ..., -0.0027,  0.0016,  0.0022],
        [ 0.0122,  0.0086, -0.0857,  ...,  0.0050,  0.0061, -0.0003],
        ...,
        [ 0.0112,  0.0099, -0.0023,  ..., -0.0900, -0.0141, -0.0052],
        [-0.0125, -0.0004, -0.0070,  ..., -0.0141, -0.0896, -0.0107],
        [-0.0042,  0.0079,  0.0046,  ..., -0.0110, -0.0036, -0.0970]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0895e-01,  8.8730e-03, -6.3286e-03,  ..., -5.6934e-04,
          1.6317e-03, -3.4695e-03],
        [ 1.6212e-03, -1.1151e-01, -7.6904e-03,  ...,  1.5574e-03,
         -3.0499e-03,  5.1498e-03],
        [ 8.3733e-04,  1.5068e-03, -9.9487e-02,  ..., -2.7161e-03,
          1.0826e-02, -8.0109e-05],
        ...,
        [ 1.3237e-03, -4.3640e-03,  2.1381e-03,  ..., -1.0144e-01,
         -8.5449e-03, -5.3864e-03],
        [ 2.7695e-03,  5.6076e-03, -2.7847e-03,  ...,  3.1509e-03,
         -1.0278e-01,  8.9025e-04],
        [-3.7365e-03,  5.7411e-04, -2.3479e-03,  ..., -1.1932e-02,
         -4.6692e-03, -1.0065e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:23:55 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 19:23:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7568, -0.8389, -0.7915,  ..., -0.6816,  0.5698,  0.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1873,  0.1220, -0.0828,  ..., -0.6611, -0.2322, -0.5996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2412, -0.6045, -1.3984,  ..., -1.3027,  0.2856,  0.5869],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4829,  0.0878, -0.3506,  ..., -0.6387, -0.2335, -0.6797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:23:55 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:23:55 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 19:24:30 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 19:25:10 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 19:25:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.3801e-04,  1.1711e-03, -2.3460e-03,  ...,  1.8415e-03,
         -1.7223e-03, -1.6203e-03],
        [ 3.6430e-04, -1.7414e-03,  6.6280e-04,  ...,  8.1635e-04,
          9.0218e-04, -1.1568e-03],
        [-6.0034e-04, -1.2817e-03, -1.8835e-03,  ..., -2.5425e-03,
          1.2693e-03, -5.4216e-04],
        ...,
        [ 9.4128e-04, -1.3752e-03,  3.6502e-04,  ..., -1.4086e-03,
         -8.9788e-04,  8.5402e-04],
        [-1.0719e-03, -2.6226e-06, -1.8711e-03,  ...,  1.5345e-03,
         -1.8930e-03,  5.3644e-05],
        [ 7.5912e-04, -2.1343e-03,  1.2140e-03,  ..., -1.3504e-03,
          4.8709e-04, -1.8854e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.8440e-02,  7.2784e-03,  1.2903e-03,  ..., -4.8113e-04,
          8.7814e-03,  1.9836e-02],
        [-3.5439e-03, -7.1838e-02,  2.0332e-03,  ..., -1.9302e-03,
          9.4681e-03, -5.3291e-03],
        [-5.8365e-03,  4.0054e-05, -7.4707e-02,  ...,  1.6251e-03,
         -1.3962e-02, -1.8368e-03],
        ...,
        [-4.0627e-04, -5.8250e-03,  2.4109e-02,  ..., -8.3008e-02,
          2.9144e-03, -4.6463e-03],
        [ 8.2397e-03,  1.8063e-03, -9.4604e-03,  ...,  7.8354e-03,
         -8.4229e-02, -3.8757e-03],
        [ 1.4824e-02, -5.0621e-03, -5.9929e-03,  ..., -7.6828e-03,
         -3.2091e-04, -8.0017e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1116, -0.0014,  0.0058,  ..., -0.0107, -0.0190,  0.0017],
        [ 0.0080, -0.0953, -0.0128,  ...,  0.0084,  0.0052, -0.0001],
        [-0.0073, -0.0033, -0.1014,  ..., -0.0074,  0.0008, -0.0021],
        ...,
        [ 0.0038, -0.0039,  0.0070,  ..., -0.1068,  0.0116, -0.0060],
        [ 0.0004,  0.0030,  0.0009,  ...,  0.0164, -0.1097, -0.0059],
        [ 0.0024, -0.0087,  0.0079,  ...,  0.0031, -0.0017, -0.1052]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:25:50 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 19:25:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9517, -0.9712, -0.6514,  ..., -0.6890, -0.0115,  0.3726],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5273,  0.1423, -0.2949,  ...,  0.0128, -0.3467, -0.6748],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3955,  0.0254, -1.8633,  ..., -1.1592,  0.4048,  0.5654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4023, -0.4141, -0.7715,  ..., -0.8525, -0.3662, -0.2046],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:25:51 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:25:51 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 19:26:32 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 19:27:13 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 19:27:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3022e-03, -4.9019e-04, -1.3733e-03,  ...,  2.2650e-05,
         -2.4357e-03, -4.5700e-03],
        [-3.2158e-03, -5.1575e-03,  1.3990e-03,  ..., -3.4103e-03,
         -3.1853e-04, -2.5463e-03],
        [ 3.0518e-04,  5.9462e-04, -3.9291e-03,  ...,  3.2501e-03,
          4.6420e-04, -4.5090e-03],
        ...,
        [-1.0853e-03,  5.2738e-04,  6.7186e-04,  ..., -1.4248e-03,
          3.4752e-03,  3.1967e-03],
        [-1.3561e-03, -1.5764e-03,  1.1587e-04,  ..., -8.1110e-04,
         -2.5635e-03,  6.9284e-04],
        [ 1.8845e-03,  1.0624e-03,  5.4693e-04,  ..., -1.5736e-05,
         -2.4357e-03, -7.0190e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0688,  0.0077, -0.0089,  ..., -0.0110, -0.0022,  0.0099],
        [-0.0056, -0.1070,  0.0034,  ..., -0.0088, -0.0109,  0.0121],
        [-0.0041,  0.0140, -0.0912,  ...,  0.0117, -0.0029,  0.0008],
        ...,
        [-0.0038, -0.0074, -0.0112,  ..., -0.0762,  0.0037,  0.0061],
        [-0.0045,  0.0099,  0.0003,  ..., -0.0005, -0.0798,  0.0267],
        [-0.0021,  0.0111, -0.0126,  ..., -0.0082, -0.0070, -0.0947]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.9182e-02,  1.1009e-02, -1.3361e-03,  ...,  5.1212e-04,
          3.2578e-03,  1.2894e-03],
        [ 3.4409e-03, -1.0931e-01,  5.3902e-03,  ..., -6.8474e-03,
         -1.0414e-02,  1.1627e-02],
        [-8.9111e-03,  1.6279e-03, -1.0352e-01,  ..., -2.9221e-03,
         -1.0254e-02,  9.1858e-03],
        ...,
        [ 1.7662e-03,  2.5902e-03, -1.2009e-02,  ..., -9.7473e-02,
         -1.4105e-03, -2.2526e-03],
        [-5.6038e-03,  6.3896e-05, -5.1193e-03,  ...,  2.6989e-03,
         -1.0309e-01,  9.3231e-03],
        [-4.6043e-03, -1.8797e-03, -7.7591e-03,  ...,  3.3417e-03,
          3.1090e-03, -1.0284e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:27:55 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 19:27:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8472, -0.4331, -0.9805,  ..., -0.8682,  0.1763,  0.3987],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4536,  0.0782, -0.3511,  ..., -0.5562, -0.2184, -0.6401],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2871,  0.2749, -1.4570,  ..., -0.5186,  0.3445, -0.3511],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0908, -0.1475, -0.7373,  ..., -0.8438, -0.7031, -0.1558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:27:55 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:27:55 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 19:28:41 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 19:29:28 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 19:30:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0023,  0.0011,  0.0028,  ..., -0.0044, -0.0002, -0.0055],
        [ 0.0030, -0.0023,  0.0018,  ..., -0.0011, -0.0006,  0.0038],
        [-0.0016,  0.0030,  0.0009,  ..., -0.0006,  0.0029, -0.0005],
        ...,
        [-0.0041, -0.0012, -0.0005,  ..., -0.0001, -0.0028, -0.0031],
        [-0.0071, -0.0025,  0.0017,  ...,  0.0008, -0.0021,  0.0005],
        [ 0.0001, -0.0017,  0.0002,  ..., -0.0069,  0.0010,  0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1078, -0.0012,  0.0083,  ..., -0.0134,  0.0143, -0.0112],
        [-0.0006, -0.0987,  0.0008,  ..., -0.0012,  0.0028,  0.0027],
        [-0.0095,  0.0023, -0.0826,  ...,  0.0063, -0.0063, -0.0061],
        ...,
        [-0.0048,  0.0117,  0.0159,  ..., -0.0918, -0.0008, -0.0108],
        [ 0.0118, -0.0055,  0.0002,  ...,  0.0115, -0.0951, -0.0057],
        [-0.0047,  0.0062,  0.0142,  ..., -0.0070,  0.0089, -0.0804]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6150e-01, -4.2572e-03,  3.8605e-03,  ...,  3.8490e-03,
         -1.4435e-02,  5.7716e-03],
        [-4.5624e-03, -1.6943e-01, -8.0795e-03,  ..., -7.7248e-04,
         -2.1992e-03,  2.7657e-03],
        [-9.6741e-03, -1.4366e-02, -1.6052e-01,  ..., -7.6370e-03,
         -6.5765e-03, -7.7591e-03],
        ...,
        [-8.4076e-03,  1.1536e-02,  4.5967e-03,  ..., -1.5930e-01,
          5.7220e-05,  5.1193e-03],
        [-1.4286e-03,  3.5133e-03, -2.5997e-03,  ..., -5.8098e-03,
         -1.7102e-01, -5.9891e-03],
        [-9.0103e-03,  1.9360e-03, -3.9673e-03,  ..., -8.0338e-03,
         -1.3702e-02, -1.4990e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:30:12 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 19:30:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 9.1943e-01, -6.4039e-04, -1.2021e+00,  ..., -7.0703e-01,
         2.4243e-01,  3.3276e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3203, -0.3528, -0.6309,  ..., -0.6387, -0.3030, -0.2098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.7227,  0.4709, -1.2324,  ..., -0.9463, -0.1545, -0.0327],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0906, -0.1320, -0.4460,  ..., -0.4824, -0.9106,  0.7368],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:30:12 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:30:12 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 19:31:00 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 19:31:47 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 19:32:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.0556e-03, -7.9203e-04, -3.0823e-03,  ...,  2.0142e-03,
          1.2302e-03,  3.0727e-03],
        [-1.9436e-03,  3.0327e-03,  2.2812e-03,  ...,  1.9321e-03,
          2.2292e-05,  1.8492e-03],
        [ 1.4582e-03,  6.1798e-04, -4.7073e-03,  ...,  1.1711e-03,
         -1.1082e-03,  1.8368e-03],
        ...,
        [-3.6025e-04, -2.9602e-03,  2.8934e-03,  ..., -6.2180e-03,
         -8.1968e-04, -2.1076e-04],
        [ 5.9938e-04, -4.5357e-03,  9.3651e-04,  ...,  4.3297e-03,
         -2.5768e-03,  1.4839e-03],
        [ 1.0796e-03,  4.4060e-04, -2.7409e-03,  ...,  4.4966e-04,
          3.6201e-03, -1.7948e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0974, -0.0018, -0.0053,  ..., -0.0088,  0.0135,  0.0072],
        [ 0.0181, -0.0956,  0.0035,  ..., -0.0081, -0.0060, -0.0004],
        [ 0.0004, -0.0040, -0.1013,  ...,  0.0046,  0.0048,  0.0049],
        ...,
        [-0.0005, -0.0081,  0.0078,  ..., -0.1156,  0.0049,  0.0075],
        [ 0.0126, -0.0029,  0.0053,  ...,  0.0073, -0.1028,  0.0221],
        [-0.0035,  0.0136, -0.0013,  ..., -0.0053, -0.0009, -0.0998]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1143,  0.0119,  0.0017,  ...,  0.0111,  0.0006, -0.0081],
        [ 0.0140, -0.1203,  0.0079,  ...,  0.0064, -0.0091,  0.0036],
        [ 0.0100, -0.0050, -0.1290,  ...,  0.0031,  0.0048,  0.0011],
        ...,
        [-0.0072,  0.0003,  0.0052,  ..., -0.1210,  0.0127, -0.0124],
        [ 0.0009, -0.0026, -0.0039,  ...,  0.0026, -0.1213,  0.0213],
        [-0.0034,  0.0006,  0.0013,  ..., -0.0071, -0.0087, -0.1115]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:32:37 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 19:32:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.3623,  0.1473, -0.8721,  ..., -0.3291,  0.1796, -0.2129],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0778, -0.1254, -0.5396,  ..., -0.6006, -0.5063, -0.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.5293,  0.1238, -1.4424,  ..., -0.1743,  0.3188,  0.7339],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1555, -0.2661, -0.4041,  ..., -0.4238, -0.5742,  0.6636],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:32:37 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:32:37 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 19:33:30 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 19:34:22 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 19:35:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0115,  0.0002,  0.0033,  ..., -0.0012, -0.0014,  0.0036],
        [-0.0030,  0.0051,  0.0017,  ..., -0.0007,  0.0015,  0.0010],
        [-0.0043, -0.0037,  0.0067,  ..., -0.0025,  0.0041,  0.0013],
        ...,
        [ 0.0037,  0.0036,  0.0052,  ...,  0.0093, -0.0056,  0.0034],
        [-0.0043, -0.0014, -0.0023,  ..., -0.0016,  0.0083, -0.0006],
        [-0.0029, -0.0008, -0.0010,  ...,  0.0028, -0.0004,  0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1235, -0.0049,  0.0119,  ..., -0.0073,  0.0191, -0.0114],
        [ 0.0039, -0.1075,  0.0060,  ...,  0.0018,  0.0083, -0.0128],
        [ 0.0064, -0.0079, -0.1113,  ..., -0.0003,  0.0016,  0.0071],
        ...,
        [-0.0094, -0.0034,  0.0120,  ..., -0.1116, -0.0113, -0.0013],
        [-0.0010,  0.0017, -0.0065,  ..., -0.0031, -0.1190,  0.0056],
        [-0.0024, -0.0128, -0.0031,  ..., -0.0143,  0.0115, -0.1283]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2462,  0.0103, -0.0045,  ..., -0.0103, -0.0015, -0.0124],
        [ 0.0126, -0.2522, -0.0007,  ..., -0.0066,  0.0071,  0.0023],
        [ 0.0003,  0.0148, -0.2283,  ...,  0.0061, -0.0036, -0.0163],
        ...,
        [-0.0097, -0.0013, -0.0061,  ..., -0.2527,  0.0142,  0.0172],
        [-0.0052,  0.0003, -0.0049,  ...,  0.0025, -0.2401, -0.0032],
        [-0.0101, -0.0126, -0.0035,  ..., -0.0088, -0.0059, -0.2583]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:35:17 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 19:35:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.5713,  0.2615, -0.7339,  ..., -0.5464, -0.0986, -0.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0414, -0.1162, -0.3726,  ..., -0.3645, -0.6958,  0.5244],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3457, -0.5967, -1.4502,  ..., -0.1396,  0.3342,  0.5317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3301, -0.6270, -0.5845,  ..., -0.2273,  0.0474,  0.1929],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:35:17 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:35:17 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 19:36:13 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 19:37:08 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 19:38:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.2673e-03,  1.3695e-03,  1.6756e-03,  ..., -5.9700e-04,
          2.9230e-04, -1.0319e-03],
        [ 5.8317e-04, -2.9335e-03, -2.4929e-03,  ...,  1.9228e-04,
          1.5755e-03, -9.2697e-04],
        [ 4.4518e-03,  1.1196e-03, -6.8474e-03,  ..., -2.2411e-05,
         -2.0351e-03, -2.0158e-04],
        ...,
        [ 3.0193e-03,  2.7542e-03, -1.8120e-03,  ..., -2.4300e-03,
         -1.5306e-03,  4.0283e-03],
        [-7.0667e-04, -1.6804e-03,  1.5326e-03,  ..., -2.1191e-03,
         -4.3068e-03,  6.9427e-04],
        [-4.8256e-04, -1.3888e-05, -2.0275e-03,  ...,  1.3514e-03,
          1.4305e-03, -4.3297e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0956,  0.0009, -0.0009,  ..., -0.0001, -0.0104, -0.0023],
        [ 0.0006, -0.0905, -0.0130,  ...,  0.0027, -0.0071,  0.0052],
        [-0.0040, -0.0091, -0.0872,  ...,  0.0021,  0.0015, -0.0015],
        ...,
        [ 0.0040,  0.0052,  0.0048,  ..., -0.0792,  0.0107,  0.0002],
        [ 0.0101, -0.0052, -0.0048,  ...,  0.0085, -0.0891,  0.0063],
        [ 0.0087,  0.0030, -0.0035,  ..., -0.0013, -0.0087, -0.0939]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.4788e-02,  2.0313e-03,  1.6031e-03,  ...,  9.1782e-03,
         -9.7580e-03, -4.5776e-04],
        [ 2.7771e-03, -1.1041e-01, -1.2970e-04,  ..., -6.1798e-03,
          1.9073e-04,  8.8120e-03],
        [-2.3804e-03, -1.0178e-02, -1.0065e-01,  ..., -5.1422e-03,
         -7.9575e-03,  1.4320e-02],
        ...,
        [-2.3270e-03,  2.9430e-03,  3.9864e-03,  ..., -8.9783e-02,
          7.6714e-03, -8.8348e-03],
        [-4.1885e-03,  3.1948e-05, -3.3112e-03,  ...,  8.3466e-03,
         -9.2773e-02, -7.3433e-04],
        [-2.7771e-03,  5.2223e-03,  1.2802e-02,  ...,  8.4534e-03,
         -3.9406e-03, -8.1421e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:38:05 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 19:38:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.4443,  0.0326, -0.7773,  ..., -0.1137,  0.1796,  0.3931],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1202, -0.2340, -0.2939,  ..., -0.3193, -0.4158,  0.4741],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3242, -0.7437, -1.4268,  ..., -0.0077,  1.0088,  0.4136],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1417, -0.5146, -1.4004,  ..., -0.1357,  0.5679,  0.4385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:38:06 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:38:06 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 19:39:03 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 19:40:00 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 19:40:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7914e-02, -1.0462e-03, -7.5698e-06,  ...,  5.5237e-03,
         -7.1764e-05, -1.6537e-03],
        [-2.6073e-03,  1.7105e-02,  4.0770e-05,  ...,  2.0084e-03,
          1.5628e-04,  3.4547e-04],
        [-4.2229e-03,  1.0529e-03,  1.9012e-02,  ..., -5.3978e-04,
          1.1101e-03, -6.6757e-04],
        ...,
        [ 1.4210e-03,  4.2000e-03,  6.3629e-03,  ...,  2.0370e-02,
         -1.0658e-02,  5.5618e-03],
        [-1.0262e-03,  9.4795e-04,  5.5122e-03,  ..., -8.8215e-04,
          1.9897e-02,  6.5880e-03],
        [ 8.4782e-04, -4.8752e-03, -1.1406e-03,  ..., -9.4757e-03,
         -2.6360e-03,  1.4191e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0960, -0.0100, -0.0062,  ..., -0.0119,  0.0032,  0.0029],
        [ 0.0066, -0.1136, -0.0162,  ...,  0.0013, -0.0123, -0.0087],
        [ 0.0083, -0.0103, -0.0966,  ..., -0.0102,  0.0060, -0.0087],
        ...,
        [-0.0117, -0.0014,  0.0066,  ..., -0.0995,  0.0019,  0.0019],
        [ 0.0031,  0.0169,  0.0037,  ...,  0.0031, -0.1013,  0.0084],
        [ 0.0085, -0.0115,  0.0011,  ..., -0.0113,  0.0183, -0.0997]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6589e-01, -7.1640e-03,  4.9400e-03,  ..., -2.8107e-02,
          9.9030e-03,  1.5488e-03],
        [-4.8141e-03, -1.7542e-01,  7.1526e-03,  ..., -2.3251e-03,
          9.1400e-03,  1.0132e-02],
        [ 1.9302e-03,  3.5934e-03, -1.6589e-01,  ..., -9.7809e-03,
          1.6470e-03, -3.8872e-03],
        ...,
        [-6.7406e-03, -7.7667e-03, -7.1411e-03,  ..., -1.6553e-01,
          7.2784e-03, -5.9700e-03],
        [ 4.7836e-03,  1.6785e-04,  2.2144e-03,  ...,  2.2087e-03,
         -1.6406e-01, -4.4727e-04],
        [ 7.4768e-03,  1.2627e-02, -2.7351e-03,  ..., -2.1782e-03,
          1.9363e-02, -1.5540e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:40:59 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 19:40:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1709, -0.3191, -0.7173,  ..., -0.0861,  0.1978,  0.2166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2341, -0.4055, -0.3677,  ..., -0.1541,  0.0586,  0.0657],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.8359, -0.7222, -1.1836,  ..., -0.3784,  1.7773,  0.1411],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2233, -0.6392, -1.8428,  ..., -0.6924,  0.8857,  1.0107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:40:59 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:40:59 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 19:41:55 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 19:42:53 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 19:43:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.7643e-04, -3.0136e-03, -1.6708e-03,  ...,  1.5759e-04,
         -7.4692e-03, -5.4741e-04],
        [ 8.5688e-04,  4.8409e-03, -6.3629e-03,  ...,  2.2662e-04,
          3.4657e-03, -8.3113e-04],
        [ 4.1556e-04, -1.5697e-03,  8.1787e-03,  ..., -5.4359e-03,
         -1.9588e-03,  3.4943e-03],
        ...,
        [ 3.6392e-03, -6.7806e-04, -5.0583e-03,  ...,  6.9923e-03,
         -8.9836e-04,  1.5173e-03],
        [-2.8968e-05, -3.1986e-03, -4.5319e-03,  ...,  5.2261e-03,
          5.9776e-03,  1.9722e-03],
        [-8.2874e-04,  2.8934e-03, -2.1935e-04,  ..., -3.4561e-03,
          2.8658e-04,  5.0240e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.4778e-02, -6.8188e-04, -8.2474e-03,  ..., -1.2100e-02,
         -5.4855e-03, -7.0572e-05],
        [-5.8174e-05, -1.0852e-01,  3.2310e-03,  ...,  8.0338e-03,
          2.4658e-02,  1.6602e-02],
        [-8.8577e-03, -3.9024e-03, -8.5083e-02,  ...,  3.1776e-03,
          1.1444e-02, -1.2657e-02],
        ...,
        [-1.5402e-03, -7.0000e-03,  1.2459e-02,  ..., -7.7942e-02,
          6.5231e-04,  1.5671e-02],
        [ 1.2856e-03,  9.2087e-03,  7.0038e-03,  ...,  1.8311e-02,
         -9.4299e-02,  3.7918e-03],
        [-9.0103e-03,  1.3885e-02, -1.1002e-02,  ..., -1.0071e-02,
         -1.2751e-03, -9.8022e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0529e-01, -5.4703e-03,  4.7913e-03,  ..., -1.1559e-02,
          1.5583e-03,  2.4223e-03],
        [-1.3542e-03, -1.0785e-01, -4.0531e-04,  ...,  1.2497e-02,
         -2.6474e-03,  1.9547e-02],
        [-2.1877e-03, -5.3406e-05, -1.1145e-01,  ..., -2.7885e-03,
         -2.1362e-04, -8.9417e-03],
        ...,
        [-5.1727e-03, -2.2476e-02,  3.7079e-03,  ..., -1.0773e-01,
          1.2787e-02,  7.6218e-03],
        [-2.4204e-03,  1.1269e-02,  8.9722e-03,  ...,  4.5013e-03,
         -1.0059e-01,  5.4474e-03],
        [-7.5035e-03, -4.3893e-04, -8.0185e-03,  ..., -6.0654e-03,
          5.3291e-03, -1.2042e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:43:50 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 19:43:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1514, -0.3965, -0.6587,  ..., -0.0165,  0.4895,  0.1687],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0918, -0.3381, -0.7856,  ..., -0.0903,  0.3376,  0.2286],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.9355, -1.3174, -0.1064,  ..., -0.9312,  1.8574,  0.4875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1969, -0.8047, -2.6738,  ..., -1.0586,  0.7598,  0.9482],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:43:50 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:43:50 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 19:44:52 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 19:45:53 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 19:46:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0058,  0.0015,  0.0020,  ...,  0.0027, -0.0043,  0.0013],
        [ 0.0071,  0.0052,  0.0003,  ...,  0.0003,  0.0041, -0.0028],
        [ 0.0005, -0.0045,  0.0053,  ...,  0.0002, -0.0042, -0.0002],
        ...,
        [-0.0051, -0.0041,  0.0004,  ...,  0.0028, -0.0099,  0.0008],
        [ 0.0069, -0.0010,  0.0053,  ..., -0.0032,  0.0087, -0.0043],
        [ 0.0023, -0.0002,  0.0022,  ...,  0.0003, -0.0010,  0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.4585e-02, -2.0552e-04, -6.2466e-05,  ..., -1.6083e-02,
         -4.7112e-03,  9.9411e-03],
        [ 5.9128e-03, -8.6548e-02, -2.0657e-03,  ...,  2.2659e-03,
          5.6076e-03, -5.0926e-03],
        [ 7.1678e-03,  8.3542e-03, -7.8430e-02,  ..., -6.7902e-03,
         -1.5602e-03,  7.7152e-04],
        ...,
        [-4.3373e-03,  2.8000e-03, -3.1872e-03,  ..., -9.6436e-02,
         -4.8561e-03,  8.9111e-03],
        [-1.8177e-03, -2.0508e-02, -9.9182e-03,  ...,  2.4090e-03,
         -8.2825e-02,  8.1787e-03],
        [ 2.5558e-03,  5.3253e-03,  6.5994e-04,  ..., -3.8414e-03,
          1.1993e-02, -9.3018e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1511e-01,  4.3411e-03,  2.0599e-03,  ..., -2.4185e-03,
          8.3008e-03,  2.3766e-03],
        [ 1.3351e-05, -1.4062e-01,  6.9885e-03,  ..., -7.6389e-04,
         -4.6501e-03, -6.8970e-03],
        [ 2.0065e-03,  1.8875e-02, -1.3525e-01,  ..., -1.1841e-02,
         -6.4945e-04,  6.6109e-03],
        ...,
        [ 1.0719e-03,  3.9139e-03, -6.6757e-03,  ..., -1.4722e-01,
         -5.4932e-03, -6.1760e-03],
        [ 4.7684e-03, -1.0132e-02, -1.5671e-02,  ...,  6.3438e-03,
         -1.2964e-01,  1.2886e-02],
        [ 1.6647e-02, -3.2597e-03,  2.2850e-03,  ...,  5.3253e-03,
          1.2573e-02, -1.1890e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:46:52 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 19:46:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.3662, -0.3562, -0.5669,  ..., -0.1851,  0.8647,  0.0412],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0842, -0.3542, -0.9810,  ..., -0.3772,  0.4905,  0.5371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0488, -1.3652, -0.4670,  ..., -1.1270,  1.3037,  0.4473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3782, -1.0508, -2.8730,  ..., -0.2261,  0.8760,  1.8516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:46:52 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:46:52 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 19:47:51 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 19:48:55 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 19:49:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0038, -0.0030,  0.0027,  ...,  0.0032,  0.0034, -0.0037],
        [-0.0017,  0.0090,  0.0007,  ...,  0.0027, -0.0005,  0.0002],
        [-0.0051, -0.0011,  0.0008,  ...,  0.0023,  0.0005, -0.0012],
        ...,
        [ 0.0059, -0.0022, -0.0025,  ...,  0.0038, -0.0105, -0.0062],
        [-0.0046,  0.0002, -0.0049,  ...,  0.0056,  0.0051,  0.0020],
        [ 0.0018, -0.0001,  0.0048,  ..., -0.0044,  0.0096, -0.0021]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0474, -0.0075, -0.0018,  ..., -0.0034,  0.0073, -0.0063],
        [-0.0080, -0.0548, -0.0057,  ...,  0.0112, -0.0124, -0.0007],
        [-0.0150, -0.0070, -0.0472,  ..., -0.0043, -0.0125, -0.0075],
        ...,
        [-0.0003, -0.0031, -0.0066,  ..., -0.0495, -0.0013, -0.0078],
        [ 0.0040,  0.0027, -0.0158,  ...,  0.0060, -0.0587,  0.0114],
        [ 0.0075,  0.0014,  0.0130,  ...,  0.0001, -0.0011, -0.0601]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.8013e-02,  3.4370e-03, -1.3870e-02,  ...,  1.1215e-03,
          5.6982e-05, -1.6083e-02],
        [ 1.0414e-02, -8.3740e-02, -3.9215e-03,  ...,  4.6635e-04,
         -9.7198e-03,  1.2426e-03],
        [ 1.0201e-02, -4.9305e-04, -7.4585e-02,  ..., -1.2604e-02,
         -9.4223e-03, -1.7071e-03],
        ...,
        [ 2.3079e-03,  5.9700e-03, -8.1024e-03,  ..., -7.8247e-02,
          3.9101e-03,  1.0643e-03],
        [ 2.2217e-02,  4.8218e-03, -3.7460e-03,  ...,  5.1346e-03,
         -9.0454e-02,  7.1526e-04],
        [-5.8861e-03,  2.1866e-02,  7.7171e-03,  ...,  6.1798e-03,
         -1.5297e-03, -8.5510e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:50:01 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 19:50:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8574, -0.5952, -0.0448,  ..., -0.4045,  0.8311,  0.1766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1100, -0.4011, -1.2510,  ..., -0.5044,  0.3835,  0.4260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5254, -1.8652,  0.5312,  ..., -0.7803,  1.0723,  1.4434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2021, -0.7705, -2.0742,  ..., -0.1584,  0.4082,  0.6709],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:50:01 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:50:01 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 19:51:06 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 19:52:12 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 19:53:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.9659e-03, -2.1038e-03,  6.1512e-04,  ...,  1.3790e-03,
          1.3304e-03,  1.8454e-03],
        [-8.6546e-04, -4.1771e-03,  5.8842e-04,  ...,  3.2663e-04,
          1.1861e-05, -1.8826e-03],
        [-1.4699e-04, -6.0368e-04, -3.0937e-03,  ..., -9.0647e-04,
         -9.6321e-04, -3.0651e-03],
        ...,
        [-7.8201e-04, -1.6298e-03,  1.2865e-03,  ..., -2.8057e-03,
          1.8902e-03,  2.0397e-04],
        [ 6.6662e-04,  2.5539e-03, -3.2687e-04,  ..., -1.0567e-03,
         -4.9477e-03, -1.0595e-03],
        [ 2.2340e-04, -2.9135e-04, -6.1512e-04,  ..., -1.2779e-03,
         -1.3800e-03, -4.6272e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.7646e-02,  6.5155e-03,  9.3384e-03,  ..., -9.3536e-03,
          7.2250e-03,  6.8665e-05],
        [ 5.3253e-03, -7.0740e-02,  1.1703e-02,  ...,  2.8687e-03,
          1.1948e-02, -8.8959e-03],
        [ 2.1439e-03, -4.8828e-03, -6.5979e-02,  ..., -4.7913e-03,
          4.9591e-03, -2.1935e-04],
        ...,
        [ 3.8490e-03, -1.7670e-02,  2.6226e-03,  ..., -6.2927e-02,
          4.4975e-03, -1.9669e-02],
        [ 2.2125e-03,  3.8757e-03,  5.2643e-03,  ...,  1.4496e-04,
         -7.8247e-02, -4.4823e-03],
        [ 1.1124e-02,  7.0763e-03, -2.7313e-03,  ..., -1.1459e-02,
         -7.6981e-03, -5.6793e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0828,  0.0052,  0.0062,  ...,  0.0043,  0.0040,  0.0058],
        [ 0.0017, -0.0898, -0.0002,  ..., -0.0051,  0.0022, -0.0209],
        [ 0.0097,  0.0008, -0.1033,  ...,  0.0051,  0.0111, -0.0080],
        ...,
        [-0.0062, -0.0244, -0.0097,  ..., -0.0989,  0.0070, -0.0062],
        [ 0.0073,  0.0074,  0.0229,  ..., -0.0016, -0.1122,  0.0042],
        [-0.0036, -0.0001, -0.0034,  ..., -0.0036,  0.0043, -0.0835]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:53:21 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 19:53:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8716, -0.5786, -0.2079,  ..., -0.4817,  0.5713,  0.1498],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1959, -0.4824, -1.3164,  ..., -0.1059,  0.4211,  0.8398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.9609, -2.0762,  0.5254,  ..., -1.6680,  0.4644,  1.9014],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3064, -0.5332, -1.8027,  ..., -0.6660,  0.2729,  0.4622],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:53:21 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:53:21 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 19:54:30 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 19:55:40 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 19:56:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1237e-03, -5.0735e-04, -8.8167e-04,  ..., -2.4843e-04,
         -1.3351e-04,  4.2057e-04],
        [-5.8889e-05, -5.0621e-03,  2.2125e-03,  ..., -2.7180e-04,
         -6.1226e-04, -1.6384e-03],
        [ 1.9531e-03, -1.7996e-03, -4.3488e-03,  ..., -6.4564e-04,
         -8.5068e-04, -1.9722e-03],
        ...,
        [-1.5202e-03,  1.3056e-03,  2.3155e-03,  ..., -3.1185e-03,
         -1.6375e-03, -7.6866e-04],
        [ 1.9665e-03,  2.0456e-04, -2.5082e-04,  ..., -8.0109e-04,
         -6.1188e-03,  2.5868e-04],
        [-4.7922e-04, -2.6166e-05, -9.1457e-04,  ...,  1.2197e-03,
         -4.3392e-05, -5.1994e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0599,  0.0084, -0.0116,  ..., -0.0070, -0.0114,  0.0014],
        [ 0.0137, -0.0755, -0.0096,  ..., -0.0118,  0.0013, -0.0011],
        [ 0.0161,  0.0076, -0.0664,  ..., -0.0103,  0.0113, -0.0033],
        ...,
        [-0.0059,  0.0057,  0.0027,  ..., -0.0726, -0.0006,  0.0076],
        [-0.0079,  0.0145, -0.0059,  ...,  0.0021, -0.0718,  0.0008],
        [-0.0076, -0.0007, -0.0093,  ..., -0.0033,  0.0058, -0.0719]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1068,  0.0188, -0.0120,  ..., -0.0056, -0.0144, -0.0006],
        [ 0.0099, -0.1285,  0.0060,  ..., -0.0076,  0.0045,  0.0066],
        [ 0.0090, -0.0084, -0.1113,  ..., -0.0083,  0.0095, -0.0069],
        ...,
        [ 0.0018, -0.0116,  0.0095,  ..., -0.1021, -0.0029, -0.0006],
        [-0.0128,  0.0003, -0.0254,  ..., -0.0066, -0.1153, -0.0057],
        [-0.0011,  0.0155, -0.0249,  ...,  0.0006, -0.0054, -0.1104]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 19:56:52 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 19:56:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6406, -0.7778,  0.1907,  ..., -0.3230,  0.4658,  0.5630],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1013, -0.3672, -0.9624,  ..., -0.0766,  0.2153,  0.2771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.8574, -1.4707,  0.9165,  ..., -0.9175,  0.4365,  1.4316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1064, -0.7017, -0.6445,  ..., -1.2559,  1.2734,  0.9668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 19:56:52 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 19:56:52 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 19:58:03 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 19:59:16 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 20:00:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0089, -0.0008,  0.0042,  ...,  0.0047, -0.0061, -0.0098],
        [ 0.0018,  0.0102, -0.0078,  ...,  0.0061, -0.0010,  0.0018],
        [ 0.0008,  0.0012,  0.0141,  ..., -0.0113, -0.0001,  0.0031],
        ...,
        [ 0.0001, -0.0009, -0.0066,  ...,  0.0137,  0.0005, -0.0010],
        [ 0.0048, -0.0075, -0.0048,  ...,  0.0081,  0.0185,  0.0042],
        [-0.0030, -0.0008,  0.0049,  ..., -0.0038, -0.0031,  0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0316,  0.0014,  0.0039,  ...,  0.0051,  0.0150,  0.0025],
        [ 0.0042, -0.0138,  0.0007,  ..., -0.0038,  0.0086,  0.0037],
        [-0.0137,  0.0065, -0.0188,  ..., -0.0045, -0.0069,  0.0140],
        ...,
        [-0.0164, -0.0013, -0.0051,  ..., -0.0163, -0.0019, -0.0037],
        [ 0.0045, -0.0072, -0.0049,  ..., -0.0075, -0.0358,  0.0005],
        [-0.0049,  0.0004,  0.0195,  ...,  0.0028, -0.0017, -0.0223]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.0161e-02,  9.2773e-03,  1.0689e-02,  ..., -2.2141e-02,
         -5.1041e-03, -1.1597e-02],
        [ 2.5120e-03, -4.3762e-02,  2.6646e-03,  ...,  9.5901e-03,
          5.9605e-05,  1.6708e-03],
        [-4.7913e-03,  2.2614e-02, -5.2063e-02,  ..., -7.3357e-03,
          2.9278e-03,  1.2711e-02],
        ...,
        [-7.0572e-03,  2.1194e-02, -1.3947e-02,  ..., -4.8096e-02,
         -9.5825e-03, -1.3481e-02],
        [-1.2535e-02, -1.4400e-03, -1.5488e-02,  ...,  5.9052e-03,
         -3.0960e-02,  1.4954e-02],
        [-1.8826e-03, -5.5008e-03,  2.2202e-02,  ..., -1.8280e-02,
          1.5541e-02, -3.6224e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:00:26 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 20:00:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7583, -0.8042,  0.1719,  ..., -0.6226,  0.1685,  0.6987],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1317, -0.2373, -0.7461,  ..., -0.2747,  0.1087,  0.1654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.9883, -1.7539,  0.7178,  ..., -1.3906, -0.6689,  0.3350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2500, -0.3774, -2.0938,  ..., -1.8379,  0.6260,  0.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:00:27 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 20:00:27 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 20:01:40 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 20:02:51 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 20:04:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.7663e-04, -1.0614e-03, -2.9027e-05,  ...,  7.0190e-04,
         -1.3142e-03,  3.2377e-04],
        [ 4.3964e-04,  7.0190e-04, -4.9162e-04,  ..., -1.8873e-03,
         -8.5163e-04,  1.0014e-04],
        [-7.3051e-04, -1.0872e-03,  2.3854e-04,  ..., -7.4863e-04,
         -5.6744e-04, -8.4829e-04],
        ...,
        [ 2.6274e-04, -9.9945e-04, -6.3705e-04,  ...,  7.6675e-04,
          2.5392e-04, -4.3094e-05],
        [-8.7214e-04,  7.5150e-04,  3.3522e-04,  ...,  5.3549e-04,
          7.6962e-04,  9.2125e-04],
        [-8.5306e-04,  4.4632e-04,  1.4126e-04,  ..., -4.3368e-04,
         -6.0177e-04,  1.0691e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.2125e-02,  1.1625e-03,  2.4910e-03,  ...,  1.2083e-03,
         -8.8272e-03,  4.0894e-03],
        [-4.3488e-03, -3.8574e-02, -9.3689e-03,  ...,  1.6098e-02,
          3.0327e-03, -9.7656e-03],
        [ 4.0741e-03,  2.1149e-02, -4.1016e-02,  ..., -7.6637e-03,
          9.9258e-03, -1.1703e-02],
        ...,
        [-1.2405e-02, -2.3899e-03, -1.3733e-02,  ..., -5.1346e-03,
         -9.0942e-03, -2.2293e-02],
        [ 3.3607e-03,  5.4588e-03, -2.7466e-03,  ..., -9.8991e-04,
         -1.7944e-02,  7.3433e-03],
        [-7.8354e-03, -1.1444e-05,  7.9193e-03,  ..., -5.5389e-03,
          4.8714e-03, -3.2562e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0498,  0.0067,  0.0068,  ...,  0.0252, -0.0156,  0.0078],
        [-0.0161, -0.0616, -0.0080,  ...,  0.0217, -0.0008,  0.0159],
        [-0.0031, -0.0092, -0.0527,  ...,  0.0030,  0.0049, -0.0209],
        ...,
        [-0.0137,  0.0055, -0.0147,  ..., -0.0363, -0.0023,  0.0004],
        [ 0.0108,  0.0009, -0.0107,  ...,  0.0224, -0.0418,  0.0085],
        [-0.0077,  0.0012, -0.0037,  ...,  0.0043,  0.0088, -0.0715]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:04:05 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 20:04:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0264, -0.5381,  0.3137,  ..., -0.3384,  0.1633,  0.4890],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4561, -0.2981, -0.2703,  ..., -0.5225,  0.5249,  0.3708],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.6836, -0.7852,  0.8120,  ..., -1.1328, -0.8311,  0.4424],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1035,  0.3506, -2.1484,  ..., -0.4033,  0.0449, -0.2295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:04:05 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 20:04:05 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 20:05:26 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 20:06:46 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 20:08:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0108, -0.0007,  0.0005,  ..., -0.0015, -0.0018,  0.0006],
        [-0.0028,  0.0097,  0.0008,  ...,  0.0071,  0.0020, -0.0001],
        [-0.0015, -0.0026,  0.0177,  ...,  0.0025,  0.0029, -0.0022],
        ...,
        [-0.0058,  0.0033, -0.0033,  ...,  0.0156,  0.0041,  0.0028],
        [-0.0032, -0.0027,  0.0058,  ...,  0.0012,  0.0105,  0.0023],
        [-0.0078,  0.0025, -0.0004,  ..., -0.0024,  0.0118,  0.0103]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0100, -0.0032,  0.0055,  ..., -0.0011,  0.0099,  0.0120],
        [-0.0164, -0.0121, -0.0077,  ...,  0.0018,  0.0128,  0.0004],
        [ 0.0165, -0.0055,  0.0031,  ...,  0.0080, -0.0019,  0.0066],
        ...,
        [-0.0015, -0.0100,  0.0063,  ..., -0.0127,  0.0059, -0.0055],
        [-0.0085, -0.0067,  0.0020,  ...,  0.0096, -0.0146, -0.0003],
        [ 0.0059, -0.0039,  0.0072,  ..., -0.0072, -0.0048, -0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0553, -0.0020,  0.0104,  ..., -0.0137,  0.0181, -0.0080],
        [-0.0037, -0.0429, -0.0137,  ...,  0.0058,  0.0062,  0.0051],
        [ 0.0081,  0.0022, -0.0560,  ...,  0.0023, -0.0137,  0.0082],
        ...,
        [ 0.0153, -0.0126, -0.0141,  ..., -0.0443, -0.0061,  0.0071],
        [ 0.0144, -0.0060, -0.0282,  ..., -0.0004, -0.0714, -0.0054],
        [-0.0037, -0.0064,  0.0010,  ..., -0.0104, -0.0043, -0.0534]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:08:08 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 20:08:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0537, -0.5952,  0.2310,  ..., -0.4658, -0.2220,  0.0870],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0984, -0.1476, -0.8140,  ..., -0.7002,  0.2566,  0.0998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.7539, -1.1465,  2.6855,  ..., -1.5625, -0.0068,  1.4336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.5947,  0.3901, -2.1191,  ..., -0.5688, -0.6426,  1.8623],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:08:08 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 20:08:08 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 20:09:29 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 20:10:50 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 20:12:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.6286e-05, -3.9363e-04, -3.6597e-05,  ..., -1.9073e-04,
          3.4189e-04, -7.1764e-05],
        [-3.9530e-04,  5.9843e-04,  1.6487e-04,  ...,  5.8413e-04,
         -3.3319e-05,  5.4407e-04],
        [-3.4261e-04,  5.4789e-04, -2.4652e-04,  ...,  5.0259e-04,
          4.9531e-05,  4.8041e-04],
        ...,
        [-2.2793e-04, -7.0155e-05,  1.8191e-04,  ..., -3.8648e-04,
          6.6578e-05,  1.8597e-05],
        [-2.9945e-04,  2.1958e-04, -1.3566e-04,  ..., -1.1051e-04,
         -1.3781e-04,  1.7262e-04],
        [ 5.9545e-05, -2.8968e-05,  3.2449e-04,  ..., -1.2469e-04,
          8.8751e-05, -3.4618e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0170,  0.0231,  0.0012,  ...,  0.0090, -0.0034, -0.0043],
        [-0.0038, -0.0319, -0.0071,  ..., -0.0142, -0.0004,  0.0015],
        [-0.0041,  0.0031, -0.0323,  ...,  0.0003, -0.0055,  0.0109],
        ...,
        [-0.0006,  0.0037, -0.0020,  ..., -0.0301, -0.0005,  0.0173],
        [ 0.0028,  0.0100, -0.0106,  ...,  0.0142, -0.0363,  0.0019],
        [-0.0043, -0.0193,  0.0046,  ..., -0.0211, -0.0129, -0.0131]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.0507e-02,  2.3254e-02,  1.9464e-03,  ...,  1.9388e-03,
         -1.1192e-02,  7.3471e-03],
        [ 2.2064e-02, -4.9133e-02, -2.4963e-02,  ...,  4.5509e-03,
          4.4136e-03,  9.8114e-03],
        [ 3.7994e-03, -4.1962e-05, -7.5317e-02,  ..., -1.3062e-02,
          1.5068e-02,  1.1314e-02],
        ...,
        [ 1.0071e-02,  3.0231e-04, -1.3779e-02,  ..., -7.3730e-02,
         -1.1986e-02,  1.7303e-02],
        [ 9.6817e-03, -7.5378e-03, -1.9455e-02,  ...,  4.9934e-03,
         -4.9011e-02, -1.1345e-02],
        [-8.3771e-03,  4.1580e-03, -7.9823e-04,  ..., -9.6359e-03,
         -1.9104e-02, -4.0161e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:12:14 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 20:12:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2529, -0.2532,  0.2378,  ..., -0.3618, -0.2554,  0.1180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4106,  0.1272, -0.8062,  ..., -0.1432,  0.0356, -0.1187],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.9238, -1.6133,  2.6699,  ..., -3.4980, -0.4290,  0.8984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.8486,  0.3816, -1.3145,  ...,  0.5571, -0.7197,  2.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:12:14 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 20:12:14 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 20:13:38 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 20:15:01 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 20:16:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.3213e-05,  1.2922e-04, -3.7730e-05,  ...,  2.9862e-05,
         -1.4019e-03,  2.8753e-04],
        [-3.2353e-04, -5.9271e-04,  3.5381e-04,  ...,  3.9887e-04,
         -7.7307e-05, -2.7442e-04],
        [-1.0842e-04,  8.7357e-04, -9.8038e-04,  ..., -1.2922e-04,
         -9.1982e-04,  5.4264e-04],
        ...,
        [ 2.3961e-05,  3.0041e-04,  3.0637e-04,  ...,  1.2803e-04,
          1.0452e-03,  7.7426e-05],
        [ 3.1996e-04,  5.9843e-05,  3.8481e-04,  ..., -6.2466e-05,
          2.0766e-04, -3.3474e-04],
        [ 5.5122e-04,  1.7142e-04,  6.6519e-04,  ..., -2.9147e-05,
         -4.9591e-04, -1.5888e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.2794e-02, -1.3599e-03, -6.2943e-03,  ...,  4.6501e-03,
         -6.4888e-03,  5.5923e-03],
        [ 2.0874e-02, -3.2440e-02,  1.6968e-02,  ..., -5.7220e-03,
          1.1520e-02, -1.4359e-02],
        [-4.5891e-03,  4.3154e-05, -7.7744e-03,  ..., -2.3651e-02,
          1.6968e-02, -8.9188e-03],
        ...,
        [ 9.8724e-03, -1.7838e-02, -4.4975e-03,  ..., -2.6505e-02,
         -8.0490e-04, -3.1128e-03],
        [-9.0942e-03, -1.6708e-02, -3.6850e-03,  ..., -6.8512e-03,
         -1.4397e-02,  4.9286e-03],
        [ 2.9106e-03, -2.1286e-02,  2.3537e-03,  ..., -1.2154e-02,
          2.0111e-02, -2.3804e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0356, -0.0225, -0.0103,  ..., -0.0205, -0.0134, -0.0220],
        [ 0.0036, -0.0655,  0.0004,  ...,  0.0029, -0.0017,  0.0179],
        [ 0.0058,  0.0155, -0.0576,  ..., -0.0066, -0.0044,  0.0063],
        ...,
        [-0.0013, -0.0074, -0.0062,  ..., -0.0651, -0.0094,  0.0025],
        [-0.0157, -0.0045,  0.0024,  ..., -0.0053, -0.0863,  0.0039],
        [-0.0012, -0.0108, -0.0040,  ..., -0.0122, -0.0055, -0.0822]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:16:19 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 20:16:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2158, -0.3257,  0.7993,  ..., -0.4958,  0.0083,  0.4353],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5801,  0.1604, -0.8076,  ..., -0.2111, -0.2246,  0.6553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.1641, -1.3379,  3.0000,  ..., -3.0234,  0.0129,  0.7627],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-3.4199,  0.5073, -1.8408,  ...,  0.3364, -0.0083,  1.4951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:16:19 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 20:16:19 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 20:17:36 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 20:18:50 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 20:20:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7414e-03, -5.0354e-04, -3.4714e-04,  ...,  1.0262e-03,
          2.1958e-04,  1.1692e-03],
        [ 1.4219e-03,  1.3571e-03,  4.0340e-04,  ..., -7.6652e-05,
         -1.6394e-03, -1.4162e-03],
        [ 8.4829e-04,  8.5533e-05,  2.4948e-03,  ..., -6.0463e-04,
          1.1444e-03,  4.2582e-04],
        ...,
        [ 2.0275e-03,  1.0576e-03,  4.1938e-04,  ...,  3.2692e-03,
          3.2926e-04, -4.2295e-04],
        [-3.5524e-04,  2.2781e-04, -8.7690e-04,  ...,  1.4734e-03,
          2.0218e-03, -7.1383e-04],
        [-1.5020e-03, -2.4529e-03, -2.4586e-03,  ...,  2.2030e-04,
         -1.0996e-03,  4.0550e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0279,  0.0056,  0.0073,  ...,  0.0013, -0.0012,  0.0158],
        [-0.0033, -0.0304,  0.0164,  ...,  0.0131, -0.0017,  0.0042],
        [ 0.0190, -0.0141,  0.0124,  ...,  0.0157, -0.0091, -0.0112],
        ...,
        [-0.0146,  0.0035, -0.0052,  ...,  0.0402,  0.0149, -0.0130],
        [ 0.0101, -0.0138, -0.0138,  ...,  0.0225,  0.0262,  0.0199],
        [ 0.0143,  0.0156, -0.0179,  ..., -0.0094,  0.0147,  0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0055,  0.0102, -0.0073,  ...,  0.0133, -0.0055,  0.0348],
        [ 0.0060, -0.0539,  0.0040,  ...,  0.0080, -0.0020,  0.0158],
        [-0.0131, -0.0082, -0.0307,  ...,  0.0026,  0.0042,  0.0036],
        ...,
        [-0.0316,  0.0094, -0.0250,  ...,  0.0049,  0.0123, -0.0094],
        [ 0.0231, -0.0136, -0.0124,  ..., -0.0173, -0.0200,  0.0256],
        [ 0.0114,  0.0317, -0.0053,  ...,  0.0139,  0.0272, -0.0184]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:20:11 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 20:20:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2256, -0.4468,  0.7573,  ..., -1.0889, -0.1331,  0.2388],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6348,  0.1515, -0.5234,  ...,  0.1566, -0.2573,  0.7871],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3574, -0.8262,  1.9717,  ..., -3.4355,  0.3420,  1.6279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.8457,  0.9956, -2.8516,  ...,  0.2642,  0.5005,  1.7246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:20:11 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 20:20:11 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 20:21:27 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 20:22:47 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 20:24:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2526e-03, -4.1509e-04,  1.8048e-04,  ..., -8.5592e-05,
          5.2261e-04,  9.0420e-05],
        [-3.5095e-04,  5.6601e-04,  4.7421e-04,  ..., -2.9230e-04,
         -1.6868e-04,  5.4419e-05],
        [-3.4904e-04, -9.3877e-05,  1.8940e-03,  ..., -2.8610e-06,
          2.0409e-04, -1.3542e-04],
        ...,
        [ 1.2958e-04, -3.4690e-04, -6.6710e-04,  ...,  2.4738e-03,
          1.2445e-04,  2.5451e-05],
        [ 1.9312e-04,  5.4598e-04, -4.0317e-04,  ...,  5.6624e-05,
          1.9436e-03, -3.0875e-05],
        [ 2.8181e-04, -8.1110e-04,  6.4278e-04,  ..., -2.9278e-04,
          4.2343e-04,  2.2297e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0006,  0.0137,  0.0170,  ..., -0.0087, -0.0049,  0.0074],
        [-0.0241, -0.0226,  0.0080,  ...,  0.0120,  0.0039, -0.0165],
        [ 0.0121, -0.0011, -0.0016,  ..., -0.0012, -0.0095,  0.0022],
        ...,
        [ 0.0013,  0.0015, -0.0192,  ..., -0.0009,  0.0071, -0.0006],
        [-0.0065,  0.0153, -0.0188,  ..., -0.0157, -0.0167,  0.0034],
        [-0.0069, -0.0029, -0.0026,  ...,  0.0162, -0.0110, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0215, -0.0105,  0.0062,  ..., -0.0078, -0.0174, -0.0003],
        [-0.0002, -0.0347,  0.0017,  ..., -0.0041,  0.0085,  0.0155],
        [ 0.0035, -0.0248, -0.0185,  ..., -0.0066, -0.0089,  0.0058],
        ...,
        [-0.0093, -0.0161, -0.0024,  ..., -0.0387,  0.0258, -0.0074],
        [ 0.0040,  0.0304, -0.0246,  ..., -0.0139, -0.0468,  0.0356],
        [ 0.0098, -0.0144, -0.0117,  ...,  0.0135,  0.0176, -0.0217]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:24:10 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 20:24:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9194, -0.3203,  0.7104,  ..., -0.9009, -0.0232,  0.1512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-1.1025,  0.1896, -0.6885,  ...,  0.0109, -0.0303,  0.4438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.5801,  0.0249, -0.7607,  ..., -4.9766,  0.1935,  0.1709],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2402,  1.0996, -4.4688,  ...,  0.1831,  0.0886,  1.2285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:24:10 root INFO     [order_1_approx] starting weight calculation for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 20:24:10 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 20:25:30 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 20:26:51 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 20:28:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0710e-03, -1.0443e-03, -1.1921e-05,  ...,  8.9169e-05,
         -2.7609e-04,  1.1009e-04],
        [-1.2684e-04, -1.4901e-05,  4.3416e-04,  ...,  4.5896e-05,
          3.5191e-04,  5.7507e-04],
        [ 9.3365e-04, -8.9407e-04, -7.8201e-04,  ..., -2.8968e-04,
         -2.7823e-04, -1.4722e-05],
        ...,
        [-5.7030e-04,  9.3174e-04,  3.4428e-04,  ..., -1.1742e-05,
         -2.8312e-05, -9.2149e-05],
        [ 2.0409e-04, -6.4802e-04, -5.4896e-05,  ..., -4.3368e-04,
         -5.8985e-04, -2.0802e-04],
        [-5.0735e-04,  8.2970e-04,  1.1504e-04,  ...,  4.3464e-04,
         -3.7456e-04, -2.4056e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0409,  0.0083, -0.0032,  ...,  0.0036, -0.0089,  0.0013],
        [ 0.0007, -0.0110, -0.0092,  ..., -0.0358,  0.0066, -0.0008],
        [-0.0181, -0.0129,  0.0085,  ..., -0.0085, -0.0088,  0.0057],
        ...,
        [ 0.0169,  0.0031,  0.0118,  ...,  0.0597, -0.0076, -0.0151],
        [ 0.0013,  0.0037, -0.0333,  ..., -0.0106,  0.0089,  0.0151],
        [-0.0125,  0.0286,  0.0131,  ..., -0.0066, -0.0021,  0.0356]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0513, -0.0099,  0.0047,  ..., -0.0143,  0.0177, -0.0072],
        [ 0.0297, -0.0341, -0.0011,  ..., -0.0259,  0.0318,  0.0010],
        [-0.0253, -0.0034, -0.0356,  ..., -0.0337, -0.0059,  0.0231],
        ...,
        [ 0.0084,  0.0027, -0.0227,  ..., -0.0218,  0.0083,  0.0048],
        [ 0.0012,  0.0110, -0.0205,  ..., -0.0073, -0.0189, -0.0054],
        [ 0.0058,  0.0103,  0.0319,  ...,  0.0074,  0.0050, -0.0359]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:28:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leopard falls into the category of feline
The allosaurus falls into the category of dinosaur
The goat falls into the category of bovid
The jackal falls into the category of canine
The gorilla falls into the category of primate
The vulture falls into the category of raptor
The butterfly falls into the category of insect
The falcon falls into the category of
2024-06-30 20:28:17 root INFO     total operator prediction time: 35108.50892186165 seconds
2024-06-30 20:28:17 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-06-30 20:28:19 root INFO     building operator verb+tion_irreg
2024-06-30 20:28:19 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 20:28:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6602,  0.0141, -0.5464,  ..., -0.7646, -0.2695, -0.1265],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0333,  0.2471, -0.3145,  ..., -0.3523, -0.2349, -0.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0283, -0.0461, -0.6099,  ..., -0.7026, -0.6260, -0.1729],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0732,  0.5713,  0.1039,  ...,  0.1804, -0.3157,  0.3169],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:28:19 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:28:19 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 20:28:42 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 20:29:05 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 20:29:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5869e-02,  2.0447e-03, -1.7538e-03,  ..., -1.5545e-03,
         -6.7186e-04, -1.3065e-03],
        [ 1.6651e-03, -1.4542e-02, -4.1866e-04,  ..., -8.6665e-05,
         -2.9411e-03,  4.5242e-03],
        [-4.7159e-04,  1.1313e-04, -1.5717e-02,  ..., -4.8637e-04,
         -3.9597e-03,  4.1199e-03],
        ...,
        [ 5.6744e-05, -1.1644e-03,  9.7275e-04,  ..., -1.5236e-02,
         -2.2812e-03, -1.1516e-04],
        [-5.6171e-04, -1.7929e-03,  8.8406e-04,  ..., -1.9588e-03,
         -1.7242e-02,  9.0170e-04],
        [ 3.6240e-04,  1.1978e-03,  1.1024e-03,  ...,  9.0885e-04,
          4.1885e-03, -1.7792e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0456, -0.0044,  0.0009,  ...,  0.0007, -0.0068, -0.0024],
        [ 0.0004, -0.0381,  0.0004,  ...,  0.0042, -0.0032, -0.0044],
        [ 0.0030,  0.0023, -0.0418,  ..., -0.0067, -0.0007,  0.0067],
        ...,
        [-0.0015,  0.0004, -0.0012,  ..., -0.0342,  0.0031, -0.0032],
        [-0.0067,  0.0070, -0.0010,  ..., -0.0045, -0.0364,  0.0066],
        [-0.0035,  0.0038, -0.0015,  ...,  0.0031,  0.0016, -0.0381]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.4485e-02,  3.7270e-03, -8.3008e-03,  ..., -1.5497e-03,
         -3.5744e-03,  2.7809e-03],
        [ 2.5177e-03, -4.2542e-02,  6.1035e-05,  ...,  5.5771e-03,
          1.5659e-03, -2.3098e-03],
        [-1.6766e-03,  4.9973e-04, -4.6082e-02,  ...,  5.7507e-04,
          5.1765e-03, -4.6921e-04],
        ...,
        [-1.4467e-03,  3.9978e-03,  3.2902e-04,  ..., -4.0375e-02,
         -6.5708e-04, -7.2575e-04],
        [-1.2569e-03, -1.0147e-03,  8.5831e-04,  ..., -5.2452e-04,
         -3.9215e-02,  3.6507e-03],
        [-1.7204e-03, -4.8141e-03, -1.7490e-03,  ...,  2.1286e-03,
          3.6087e-03, -3.5950e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:29:31 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 20:29:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8091,  0.1215, -0.7085,  ..., -0.7495, -0.3645, -0.3640],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1620,  0.3076,  0.0199,  ..., -0.2448, -0.2222, -0.1150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3652,  0.0601, -0.5391,  ..., -0.7979, -0.2754, -0.2881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1626,  0.6274,  0.0937,  ..., -0.2590, -0.3975,  0.5767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:29:31 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:29:31 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 20:29:55 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 20:30:19 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 20:30:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.4139e-02,  2.1820e-03, -8.4341e-05,  ...,  1.3733e-03,
          9.4604e-04,  9.7656e-04],
        [-1.3742e-03, -3.0914e-02,  1.4868e-03,  ..., -1.1301e-04,
         -4.2701e-04, -2.8133e-03],
        [-2.9926e-03,  3.2063e-03, -2.7695e-02,  ..., -1.3847e-03,
          3.1528e-03,  8.5258e-04],
        ...,
        [ 2.7103e-03,  6.0081e-03, -4.6468e-04,  ..., -2.7771e-02,
         -5.6458e-03,  1.1282e-03],
        [-8.7690e-04, -9.6321e-04, -2.7905e-03,  ...,  1.8129e-03,
         -2.4200e-02, -3.3226e-03],
        [-2.0924e-03, -2.8591e-03, -3.6964e-03,  ..., -1.1473e-03,
          5.0278e-03, -3.1494e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0602,  0.0082, -0.0057,  ...,  0.0034,  0.0050,  0.0074],
        [ 0.0080, -0.0637, -0.0033,  ...,  0.0018,  0.0026, -0.0042],
        [-0.0086, -0.0085, -0.0640,  ..., -0.0059, -0.0019, -0.0055],
        ...,
        [-0.0027, -0.0036,  0.0004,  ..., -0.0667, -0.0048,  0.0113],
        [-0.0031, -0.0169,  0.0059,  ...,  0.0026, -0.0703,  0.0009],
        [-0.0088, -0.0074,  0.0034,  ..., -0.0021, -0.0009, -0.0751]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.4829e-02,  5.9853e-03, -4.2572e-03,  ...,  1.8864e-03,
         -4.1924e-03,  2.3518e-03],
        [ 7.1068e-03, -7.3303e-02, -1.4048e-03,  ...,  4.4250e-04,
          3.8719e-04, -1.0834e-03],
        [-1.6041e-03, -9.2163e-03, -6.7261e-02,  ..., -3.3798e-03,
          4.8828e-03, -3.8147e-06],
        ...,
        [ 5.5237e-03, -3.3302e-03,  5.5428e-03,  ..., -7.3914e-02,
         -6.7329e-04,  3.4733e-03],
        [-5.7182e-03,  6.0940e-04,  6.4087e-03,  ...,  3.6621e-03,
         -6.2500e-02, -3.2997e-03],
        [ 1.2064e-03,  1.8501e-03,  8.0795e-03,  ..., -1.0509e-03,
         -2.6131e-04, -7.4341e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:30:45 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 20:30:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.3467, -0.0938, -0.8174,  ..., -0.8989, -0.8276, -0.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1014,  0.9434,  0.1659,  ...,  0.2847, -0.5132,  0.5156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1328, -0.0536, -0.4836,  ..., -0.5488, -0.7402, -0.1919],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1802,  0.4443, -0.2349,  ..., -0.1639, -0.9121,  0.7798],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:30:45 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:30:45 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 20:31:10 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 20:31:36 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 20:32:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0803e-02, -1.5240e-03,  1.9467e-04,  ...,  7.3373e-05,
         -2.1133e-03, -2.8114e-03],
        [-4.8256e-04, -8.4763e-03, -1.5793e-03,  ...,  1.2798e-03,
          1.4629e-03,  1.0862e-03],
        [ 2.3270e-03, -1.6727e-03, -8.7967e-03,  ..., -1.5488e-03,
          1.0805e-03, -3.6263e-04],
        ...,
        [ 2.0390e-03,  5.8174e-05, -2.3155e-03,  ..., -8.5068e-03,
          1.9550e-03,  1.1206e-03],
        [ 5.4932e-04, -1.9493e-03,  3.2520e-03,  ..., -1.9627e-03,
         -8.6060e-03, -8.1253e-04],
        [-9.0551e-04, -7.5579e-04,  2.2774e-03,  ..., -5.3072e-04,
         -3.5238e-04, -7.7858e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0347, -0.0055, -0.0026,  ..., -0.0012, -0.0008, -0.0110],
        [-0.0028, -0.0334, -0.0024,  ...,  0.0056,  0.0035, -0.0004],
        [-0.0021, -0.0043, -0.0330,  ..., -0.0020,  0.0027,  0.0023],
        ...,
        [-0.0018,  0.0071, -0.0037,  ..., -0.0282, -0.0053,  0.0042],
        [-0.0040,  0.0037,  0.0037,  ..., -0.0039, -0.0311, -0.0008],
        [-0.0046, -0.0055,  0.0051,  ...,  0.0026,  0.0011, -0.0256]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.2990e-02,  1.8387e-03, -4.1389e-04,  ..., -5.6267e-04,
          1.7328e-03, -4.1199e-03],
        [-1.7586e-03, -4.0100e-02,  1.1124e-02,  ...,  1.3885e-03,
         -3.5820e-03, -3.5000e-04],
        [ 7.1030e-03,  1.1253e-04, -3.2745e-02,  ...,  2.2888e-03,
         -1.6260e-03, -8.7547e-04],
        ...,
        [-6.1874e-03,  7.0953e-04, -2.4719e-03,  ..., -3.6285e-02,
         -4.3526e-03, -3.9635e-03],
        [ 3.2845e-03,  3.7384e-03, -8.2302e-04,  ...,  7.6370e-03,
         -3.2043e-02, -7.9393e-05],
        [-1.6851e-03, -5.6534e-03, -2.0123e-04,  ..., -6.6986e-03,
          5.1346e-03, -3.6316e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:32:03 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 20:32:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.7793,  0.0473, -0.6958,  ..., -1.0039, -0.3792, -0.4338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2329,  0.9688,  0.1449,  ..., -0.3804, -0.6211,  0.8857],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0391, -0.0938,  0.4485,  ..., -0.1504, -0.5146,  0.1594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1543,  0.2603,  0.1152,  ..., -0.3586, -0.5542,  0.7148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:32:03 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:32:03 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 20:32:30 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 20:33:00 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 20:33:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.8512e-03, -1.0786e-03,  1.9455e-03,  ...,  7.0715e-04,
          1.1396e-03, -2.7885e-03],
        [-3.8528e-04, -7.2899e-03, -1.3275e-03,  ...,  8.1873e-04,
         -4.0293e-05,  9.4414e-04],
        [-2.8095e-03,  9.4604e-04, -6.8283e-03,  ...,  1.5688e-04,
          4.0388e-04, -8.0109e-04],
        ...,
        [-1.3847e-03, -1.9503e-03,  1.0414e-03,  ..., -8.2779e-03,
          1.6956e-03,  5.3167e-05],
        [-5.3310e-04, -2.6054e-03, -1.6708e-03,  ..., -2.3575e-03,
         -8.6365e-03, -6.7234e-04],
        [ 1.3714e-03, -3.2854e-04, -1.5411e-03,  ..., -2.1954e-03,
         -1.1482e-03, -7.1335e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.1147e-02,  3.2902e-03, -2.2697e-03,  ...,  9.5367e-03,
          2.9221e-03, -8.1482e-03],
        [ 5.3177e-03, -5.1514e-02,  3.7289e-03,  ..., -2.9373e-03,
          2.5978e-03, -1.7338e-03],
        [ 8.9264e-03, -1.2154e-02, -4.9774e-02,  ...,  4.7607e-03,
         -9.6130e-03,  9.5367e-06],
        ...,
        [ 2.1458e-03, -1.0681e-03, -5.5838e-04,  ..., -4.9347e-02,
         -4.1199e-03, -6.8626e-03],
        [-2.3880e-03, -5.3253e-03, -3.6755e-03,  ..., -3.7155e-03,
         -4.4250e-02, -1.0109e-03],
        [-2.5597e-03, -4.2992e-03, -2.3308e-03,  ..., -4.5052e-03,
         -6.7711e-03, -5.5298e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.3365e-02, -2.1000e-03, -1.0586e-03,  ..., -8.5297e-03,
          1.3180e-03,  5.1918e-03],
        [ 1.0712e-02, -4.6356e-02, -8.7738e-05,  ...,  7.1640e-03,
          6.6147e-03, -5.4550e-03],
        [-4.0817e-03, -1.0597e-02, -4.5319e-02,  ...,  9.5272e-04,
         -1.8320e-03, -3.4771e-03],
        ...,
        [-1.0738e-03, -4.2248e-04,  7.0190e-03,  ..., -5.3894e-02,
          4.7073e-03, -6.6414e-03],
        [-5.1994e-03, -3.1376e-03, -3.7041e-03,  ..., -8.2731e-04,
         -4.7852e-02,  7.6637e-03],
        [-8.1482e-03,  1.1778e-03, -5.6915e-03,  ...,  2.5501e-03,
          9.0790e-04, -5.0049e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:33:33 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 20:33:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1855, -0.1146, -0.5015,  ..., -0.5688, -0.7744, -0.2603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2288,  0.5117, -0.2681,  ..., -0.1946, -1.0771,  0.9360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2344, -0.1497,  0.6025,  ..., -0.5996, -0.6870, -0.2961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1971,  0.1798,  0.5229,  ..., -0.3701, -0.6689,  0.0342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:33:33 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:33:33 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 20:34:06 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 20:34:38 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 20:35:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.9128e-04,  9.9087e-04, -5.1641e-04,  ..., -1.5221e-03,
          2.1896e-03, -4.3488e-04],
        [ 4.0703e-03,  7.8726e-04,  1.4591e-03,  ..., -1.6332e-05,
          6.8188e-04,  3.3016e-03],
        [ 1.8826e-03, -1.9093e-03, -1.2946e-04,  ...,  1.3800e-03,
          1.9073e-04,  1.6108e-03],
        ...,
        [-2.3746e-03, -4.8757e-05,  1.4400e-03,  ...,  3.6106e-03,
          1.4458e-03,  1.1930e-03],
        [ 1.1897e-04, -2.0313e-03, -4.5609e-04,  ...,  9.5081e-04,
          2.9659e-03,  1.0653e-03],
        [ 2.7704e-04,  6.6042e-05, -1.1225e-03,  ...,  2.2640e-03,
          1.8167e-03, -1.3342e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0834, -0.0011,  0.0032,  ..., -0.0090, -0.0060,  0.0014],
        [-0.0028, -0.0820, -0.0084,  ...,  0.0047, -0.0019,  0.0100],
        [ 0.0016, -0.0030, -0.0775,  ...,  0.0057,  0.0075, -0.0076],
        ...,
        [ 0.0012,  0.0022, -0.0058,  ..., -0.0750,  0.0060, -0.0035],
        [ 0.0061, -0.0033, -0.0058,  ...,  0.0015, -0.0800,  0.0094],
        [-0.0018,  0.0074, -0.0077,  ...,  0.0049,  0.0112, -0.0855]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.3994e-02, -3.9864e-03, -1.5640e-04,  ..., -4.5052e-03,
         -6.9122e-03, -3.5400e-03],
        [-8.1940e-03, -9.0698e-02,  4.7722e-03,  ...,  5.5542e-03,
         -5.5923e-03,  8.5373e-03],
        [-1.9836e-03,  1.4553e-03, -8.6304e-02,  ...,  5.3227e-05,
          2.4242e-03,  3.6602e-03],
        ...,
        [-1.6232e-03, -2.0523e-03, -4.3373e-03,  ..., -9.0576e-02,
         -2.6436e-03,  8.8348e-03],
        [-5.3596e-03, -5.9166e-03,  4.5319e-03,  ..., -3.6669e-04,
         -8.6487e-02,  1.2505e-02],
        [ 7.8735e-03,  6.0883e-03, -8.3351e-04,  ..., -1.0323e-02,
          4.3106e-03, -1.0522e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:35:12 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 20:35:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0771, -0.1238,  0.4297,  ..., -0.1526, -0.5547,  0.1399],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1903,  0.3076,  0.1232,  ..., -0.4121, -0.6802,  0.8628],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1240, -0.0643,  0.4033,  ..., -0.2153, -0.5288, -0.4749],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2389,  0.2386, -0.3853,  ..., -0.4509, -0.6465, -0.6870],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:35:12 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:35:12 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 20:35:49 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 20:36:26 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 20:37:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.5662e-03, -1.0757e-03,  1.4925e-03,  ...,  2.7657e-03,
          5.5361e-04,  1.1950e-03],
        [ 1.2922e-03, -7.9498e-03,  1.6699e-03,  ..., -6.6185e-04,
         -5.2929e-04, -2.8610e-05],
        [-1.0147e-03,  4.1046e-03, -7.6370e-03,  ..., -7.1859e-04,
          2.8019e-03, -1.4181e-03],
        ...,
        [ 6.7234e-05, -3.1528e-03,  3.4828e-03,  ..., -5.0087e-03,
         -1.1253e-03, -1.0529e-03],
        [ 9.4461e-04,  3.1066e-04,  8.5688e-04,  ...,  2.3317e-04,
         -5.2071e-03,  3.8195e-04],
        [ 1.1311e-03, -3.1114e-04, -2.8157e-04,  ...,  7.0381e-04,
         -4.7951e-03, -3.9940e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0896, -0.0006, -0.0006,  ...,  0.0068,  0.0062, -0.0101],
        [-0.0037, -0.1031,  0.0061,  ...,  0.0064, -0.0056, -0.0044],
        [ 0.0102,  0.0023, -0.0952,  ...,  0.0048,  0.0020, -0.0013],
        ...,
        [ 0.0094,  0.0061,  0.0135,  ..., -0.0880, -0.0086,  0.0042],
        [-0.0027,  0.0090,  0.0013,  ..., -0.0013, -0.0926,  0.0056],
        [ 0.0008,  0.0013, -0.0085,  ..., -0.0125, -0.0106, -0.0948]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0907, -0.0083,  0.0027,  ...,  0.0034, -0.0025, -0.0072],
        [ 0.0037, -0.1000, -0.0015,  ...,  0.0017,  0.0002, -0.0033],
        [-0.0089, -0.0035, -0.0852,  ...,  0.0048,  0.0017, -0.0043],
        ...,
        [ 0.0074,  0.0047,  0.0065,  ..., -0.0854, -0.0109, -0.0019],
        [ 0.0049,  0.0052, -0.0108,  ..., -0.0024, -0.0916,  0.0008],
        [-0.0101, -0.0023, -0.0084,  ..., -0.0027, -0.0051, -0.0948]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:37:04 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 20:37:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1982, -0.1473,  0.5298,  ..., -0.5840, -0.6763, -0.3406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2157,  0.2096,  0.5103,  ..., -0.3994, -0.7148,  0.0018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0645, -0.0145,  0.2625,  ..., -0.1901, -0.2615, -0.1963],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5684, -0.1725, -0.2803,  ..., -0.0342, -0.2444, -1.3184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:37:04 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:37:04 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 20:37:43 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 20:38:17 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 20:38:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0104,  0.0030, -0.0040,  ...,  0.0034, -0.0027, -0.0035],
        [ 0.0012, -0.0013,  0.0009,  ...,  0.0019,  0.0007, -0.0012],
        [ 0.0020,  0.0011, -0.0006,  ..., -0.0009,  0.0007, -0.0033],
        ...,
        [ 0.0037,  0.0011,  0.0008,  ..., -0.0045,  0.0020,  0.0083],
        [-0.0027, -0.0005, -0.0034,  ...,  0.0019,  0.0047, -0.0026],
        [ 0.0045, -0.0038,  0.0039,  ..., -0.0002,  0.0119, -0.0063]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.1421e-02,  4.8637e-03,  5.7945e-03,  ..., -5.8517e-03,
         -2.0409e-03,  1.2302e-03],
        [ 3.5820e-03, -7.8674e-02, -2.7054e-02,  ...,  8.9645e-03,
         -1.2722e-03, -7.9498e-03],
        [ 1.8682e-03, -1.4854e-02, -7.8247e-02,  ..., -4.2915e-03,
         -3.0422e-04, -4.2191e-03],
        ...,
        [-3.6659e-03,  8.1778e-05,  4.4861e-03,  ..., -8.3069e-02,
         -4.2267e-03, -5.6534e-03],
        [ 7.5035e-03, -8.6517e-03, -3.5305e-03,  ...,  5.7983e-03,
         -7.6233e-02,  7.7782e-03],
        [-2.3880e-03, -3.4924e-03,  3.9101e-03,  ..., -6.4850e-03,
          3.0365e-03, -8.1848e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.2590e-02,  5.0774e-03,  6.8588e-03,  ..., -3.5686e-03,
         -9.9792e-03, -3.3798e-03],
        [ 6.7902e-04, -8.1909e-02, -8.9874e-03,  ..., -8.0061e-04,
          4.5166e-03,  3.5839e-03],
        [ 7.5073e-03, -4.2953e-03, -7.9529e-02,  ...,  7.4921e-03,
         -3.8147e-06,  5.5237e-03],
        ...,
        [-1.1864e-03, -4.7379e-03, -1.2100e-02,  ..., -8.4900e-02,
          1.1505e-02, -2.0943e-03],
        [ 9.6588e-03,  2.1172e-03,  3.9101e-03,  ...,  9.4604e-04,
         -8.3252e-02, -1.0574e-02],
        [-3.9558e-03,  1.8644e-03,  8.7280e-03,  ...,  5.7945e-03,
          1.8997e-03, -8.1848e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:38:51 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 20:38:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0430, -0.0787,  0.3357,  ..., -0.1953, -0.4902, -0.4783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2366,  0.2302, -0.3655,  ..., -0.4092, -0.6157, -0.7012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7637,  0.1917,  0.4355,  ..., -0.5337, -0.3394,  0.2856],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8867, -0.5972, -0.8086,  ..., -0.8525, -1.0244, -0.4502],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:38:51 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:38:51 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 20:39:33 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 20:40:15 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 20:40:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0037, -0.0012, -0.0013,  ...,  0.0017,  0.0005, -0.0019],
        [-0.0017, -0.0060,  0.0022,  ..., -0.0045,  0.0020, -0.0015],
        [-0.0027,  0.0019, -0.0013,  ...,  0.0012,  0.0022, -0.0010],
        ...,
        [-0.0031,  0.0005, -0.0030,  ..., -0.0041,  0.0021,  0.0005],
        [ 0.0014, -0.0004,  0.0002,  ..., -0.0002, -0.0072, -0.0017],
        [ 0.0039, -0.0013,  0.0024,  ...,  0.0021,  0.0004, -0.0029]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.9346e-02,  3.7746e-03, -1.0824e-03,  ..., -4.6082e-03,
         -1.2722e-03,  2.8229e-04],
        [-3.5896e-03, -9.7534e-02,  9.8801e-03,  ...,  7.0076e-03,
          5.7220e-03,  9.7351e-03],
        [ 1.2865e-03, -3.1948e-03, -8.0811e-02,  ...,  7.8735e-03,
         -1.5961e-02, -9.2926e-03],
        ...,
        [-9.5367e-06, -1.2560e-03, -4.2915e-03,  ..., -9.6313e-02,
          2.7695e-03, -1.3664e-02],
        [ 5.1689e-04,  5.1308e-03,  7.2098e-03,  ..., -5.4436e-03,
         -9.5703e-02,  4.8447e-03],
        [ 1.1513e-02, -1.2064e-03, -1.2665e-02,  ..., -9.7351e-03,
          9.1743e-04, -8.2703e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1102,  0.0197, -0.0069,  ..., -0.0200,  0.0039,  0.0012],
        [-0.0057, -0.0964,  0.0105,  ..., -0.0094, -0.0058,  0.0110],
        [ 0.0085, -0.0052, -0.1038,  ..., -0.0041,  0.0061,  0.0110],
        ...,
        [ 0.0034,  0.0041, -0.0044,  ..., -0.1005, -0.0041, -0.0009],
        [-0.0100,  0.0149, -0.0104,  ..., -0.0075, -0.0969,  0.0182],
        [ 0.0081, -0.0076, -0.0162,  ..., -0.0117,  0.0165, -0.1083]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:41:00 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 20:41:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.6621, -0.0231,  0.1464,  ..., -0.1716, -0.2296, -0.1882],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4592, -0.1512, -0.2756,  ..., -0.0468, -0.2147, -1.1465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7363,  0.1536,  0.6338,  ..., -1.2764, -0.1893, -0.2471],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4307, -0.7607, -0.6699,  ..., -0.1963, -1.0195, -0.3257],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:41:00 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:41:00 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 20:41:48 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 20:42:32 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 20:43:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.4210e-03,  5.1498e-03,  5.1308e-04,  ..., -6.2799e-04,
          3.6955e-04,  3.9196e-04],
        [ 3.1929e-03,  2.1782e-03, -1.2112e-03,  ..., -6.1750e-05,
         -4.8447e-03,  4.4098e-03],
        [-3.1877e-04, -2.0676e-03,  7.9803e-03,  ..., -2.7142e-03,
          2.0218e-03, -1.5240e-03],
        ...,
        [ 2.6569e-03, -3.3264e-03, -8.2135e-05,  ...,  4.9591e-03,
         -1.2302e-03,  5.0831e-04],
        [-3.1338e-03,  1.6689e-05,  1.8978e-03,  ..., -7.8869e-04,
          8.0204e-04,  1.6661e-03],
        [-2.1019e-03, -2.6207e-03, -2.3518e-03,  ..., -2.4281e-03,
         -2.4967e-03,  4.7531e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0950, -0.0068, -0.0014,  ...,  0.0158,  0.0200, -0.0134],
        [ 0.0011, -0.1138, -0.0110,  ...,  0.0018,  0.0032, -0.0024],
        [-0.0119,  0.0105, -0.1101,  ..., -0.0002,  0.0053,  0.0031],
        ...,
        [ 0.0002,  0.0073,  0.0003,  ..., -0.1119, -0.0072, -0.0017],
        [-0.0052,  0.0074,  0.0036,  ..., -0.0149, -0.1161,  0.0042],
        [ 0.0093,  0.0061, -0.0017,  ...,  0.0041,  0.0118, -0.1169]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6589e-01, -9.8343e-03,  1.6373e-02,  ...,  6.8817e-03,
          3.9215e-03, -1.0319e-03],
        [-4.2496e-03, -1.8616e-01, -2.4757e-03,  ..., -5.9357e-03,
         -9.5062e-03, -3.3264e-03],
        [-8.5068e-03, -6.1111e-03, -1.4709e-01,  ...,  3.9291e-03,
         -2.5139e-03, -9.8648e-03],
        ...,
        [-7.9193e-03,  8.5373e-03,  2.6951e-03,  ..., -1.6785e-01,
          3.6240e-03,  4.8485e-03],
        [ 1.1177e-02, -5.6076e-03,  1.1719e-02,  ..., -9.3460e-05,
         -1.6504e-01, -2.6760e-03],
        [-4.3869e-03,  5.6686e-03, -7.2479e-03,  ..., -1.7624e-02,
         -1.3016e-02, -1.7737e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:43:22 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 20:43:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.3457,  0.1234,  0.2720,  ..., -0.3811, -0.2754,  0.1711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6865, -0.4785, -0.6294,  ..., -0.6069, -0.7822, -0.3943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.8350,  0.3047,  0.2351,  ..., -1.3701,  0.6475,  0.1665],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8115, -0.1567, -0.4995,  ..., -0.6465, -0.8281,  0.4604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:43:22 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:43:22 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 20:44:12 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 20:45:03 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 20:45:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.1564e-03, -9.8228e-04,  2.8648e-03,  ...,  3.2368e-03,
          1.4668e-03,  5.9032e-04],
        [-4.3535e-04, -2.8496e-03,  3.4733e-03,  ...,  2.7504e-03,
         -6.7949e-05,  4.4861e-03],
        [ 2.0733e-03, -4.2992e-03, -9.8801e-03,  ..., -1.3571e-03,
         -2.2030e-03, -2.1629e-03],
        ...,
        [-1.4038e-03, -8.1587e-04,  2.6798e-04,  ..., -1.0315e-02,
         -5.6419e-03, -6.1512e-04],
        [ 3.9244e-04, -1.4553e-03, -8.5211e-04,  ...,  2.9716e-03,
         -3.1548e-03,  1.9989e-03],
        [ 1.4439e-03,  3.5362e-03, -1.5717e-03,  ...,  2.3346e-03,
          8.2159e-04, -5.0926e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1804e-01,  1.6861e-02,  3.9024e-03,  ...,  2.2831e-03,
         -9.2773e-03, -7.1335e-03],
        [-1.2331e-03, -1.3257e-01,  1.0628e-02,  ...,  1.7303e-02,
          2.6665e-03, -6.3782e-03],
        [ 5.1308e-03,  2.3556e-03, -1.2219e-01,  ...,  2.2459e-04,
         -3.7651e-03,  2.0790e-03],
        ...,
        [-1.0109e-04, -1.5678e-03,  6.9389e-03,  ..., -9.7168e-02,
          1.1734e-02, -1.5541e-02],
        [ 1.6693e-02,  5.4588e-03,  1.0109e-02,  ...,  1.7242e-02,
         -1.1426e-01,  6.6757e-03],
        [ 6.5231e-03,  5.5847e-03, -3.7689e-03,  ...,  6.8703e-03,
         -5.9662e-03, -1.0931e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1132,  0.0199,  0.0059,  ..., -0.0070, -0.0098,  0.0090],
        [-0.0016, -0.1008,  0.0018,  ..., -0.0007, -0.0041, -0.0101],
        [ 0.0059,  0.0116, -0.1166,  ...,  0.0024, -0.0062,  0.0080],
        ...,
        [ 0.0025, -0.0140, -0.0039,  ..., -0.1011,  0.0093, -0.0066],
        [-0.0063, -0.0050, -0.0023,  ...,  0.0055, -0.1278,  0.0156],
        [ 0.0076, -0.0003, -0.0031,  ...,  0.0033, -0.0030, -0.1122]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:45:54 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 20:45:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1992,  0.0826,  0.3665,  ..., -0.8877, -0.1569, -0.1809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9858, -0.5596, -0.4866,  ..., -0.1630, -0.7124, -0.2284],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5137, -0.1450,  0.2468,  ..., -0.8555,  0.7070,  0.5884],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4160, -0.2671, -0.7607,  ..., -0.8530, -0.4282,  0.2114],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:45:54 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:45:54 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 20:46:48 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 20:47:41 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 20:48:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0029, -0.0003,  0.0020,  ..., -0.0019, -0.0010,  0.0008],
        [ 0.0028,  0.0047, -0.0005,  ...,  0.0009,  0.0015,  0.0013],
        [-0.0026, -0.0009,  0.0041,  ..., -0.0005,  0.0016, -0.0017],
        ...,
        [-0.0010,  0.0029,  0.0058,  ...,  0.0060, -0.0035,  0.0036],
        [-0.0043, -0.0034, -0.0001,  ..., -0.0026,  0.0057,  0.0042],
        [-0.0022,  0.0003, -0.0002,  ..., -0.0009, -0.0007,  0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1519,  0.0024,  0.0045,  ..., -0.0081, -0.0018, -0.0094],
        [ 0.0064, -0.1451, -0.0072,  ..., -0.0159, -0.0089, -0.0068],
        [ 0.0035, -0.0044, -0.1436,  ..., -0.0062,  0.0137, -0.0046],
        ...,
        [-0.0170,  0.0042,  0.0064,  ..., -0.1498,  0.0031,  0.0035],
        [-0.0135,  0.0074,  0.0037,  ..., -0.0167, -0.1381, -0.0071],
        [-0.0055, -0.0078, -0.0190,  ..., -0.0137,  0.0107, -0.1349]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.4695e-01,  2.3346e-02,  8.0185e-03,  ..., -1.8234e-02,
         -1.1101e-02, -2.6608e-04],
        [ 9.8572e-03, -2.6050e-01, -8.4305e-03,  ..., -1.2848e-02,
          1.2772e-02,  4.2229e-03],
        [ 1.8101e-03,  6.8617e-04, -2.4023e-01,  ...,  4.0359e-03,
          6.7825e-03,  1.6823e-03],
        ...,
        [-1.2817e-02,  1.4664e-02, -3.7155e-03,  ..., -2.7051e-01,
          1.3206e-02, -4.5471e-03],
        [-9.8724e-03, -5.2223e-03,  2.2984e-03,  ...,  2.3842e-03,
         -2.3792e-01,  7.5798e-03],
        [ 4.5891e-03, -4.6501e-03, -9.7809e-03,  ..., -8.2207e-04,
          3.2883e-03, -2.5293e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:48:21 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 20:48:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2520,  0.1918,  0.0993,  ..., -0.9468,  0.4312,  0.0583],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.4385, -0.1437, -0.4333,  ..., -0.5161, -0.6704,  0.3264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7959,  0.1206,  0.1858,  ..., -0.9561, -0.2031,  1.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1211, -0.6812, -0.8721,  ..., -0.9458,  0.0239,  0.4600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:48:21 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:48:22 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 20:49:16 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 20:50:11 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 20:51:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.9629e-03,  9.4318e-04, -1.1265e-05,  ...,  6.7616e-04,
         -2.3270e-03, -6.3086e-04],
        [-1.0262e-03, -3.0842e-03,  8.2016e-04,  ..., -1.1778e-03,
         -1.7910e-03, -6.6471e-04],
        [ 2.8591e-03, -3.6716e-05, -3.7308e-03,  ...,  1.2445e-03,
         -1.9341e-03, -7.4482e-04],
        ...,
        [ 2.2850e-03, -2.5024e-03, -2.0523e-03,  ..., -3.1834e-03,
         -1.3800e-03,  4.9353e-04],
        [-5.1403e-04,  2.7542e-03, -1.8606e-03,  ..., -9.8228e-04,
         -5.3329e-03,  1.2550e-03],
        [ 2.0638e-03,  1.7939e-03,  1.0252e-03,  ...,  2.1458e-03,
          5.1308e-04, -2.4605e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1000,  0.0112,  0.0121,  ...,  0.0021, -0.0028, -0.0029],
        [ 0.0101, -0.0916,  0.0051,  ..., -0.0042,  0.0059,  0.0122],
        [-0.0149, -0.0069, -0.0920,  ..., -0.0064,  0.0018,  0.0027],
        ...,
        [ 0.0047,  0.0005,  0.0033,  ..., -0.0726,  0.0073, -0.0067],
        [-0.0060,  0.0078, -0.0052,  ...,  0.0061, -0.1042,  0.0099],
        [ 0.0082, -0.0026, -0.0078,  ...,  0.0022,  0.0047, -0.0836]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0878, -0.0029,  0.0040,  ..., -0.0023, -0.0029, -0.0076],
        [ 0.0012, -0.1011, -0.0040,  ..., -0.0046,  0.0085,  0.0235],
        [-0.0030, -0.0135, -0.1007,  ..., -0.0083,  0.0010,  0.0073],
        ...,
        [-0.0014, -0.0025,  0.0052,  ..., -0.0815,  0.0020, -0.0029],
        [ 0.0029,  0.0101, -0.0003,  ...,  0.0155, -0.0942,  0.0149],
        [ 0.0010, -0.0006, -0.0067,  ...,  0.0064, -0.0002, -0.0933]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:51:02 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 20:51:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9790, -0.1353,  0.1328,  ..., -0.5479,  0.4441,  0.3521],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1357, -0.2500, -0.5811,  ..., -0.6650, -0.3320,  0.1437],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3613,  1.2441, -0.1570,  ..., -0.9624,  0.5078,  1.4150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9863, -1.5859, -0.8740,  ..., -0.6304,  0.9531,  0.6201],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:51:02 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:51:02 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 20:51:49 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 20:52:47 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 20:53:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2535e-02,  5.6505e-04,  1.1892e-03,  ..., -3.0975e-03,
          3.4447e-03, -6.8283e-03],
        [-4.0359e-03, -5.2571e-05,  7.7343e-04,  ...,  3.1967e-03,
         -2.5539e-03, -3.6163e-03],
        [-2.8820e-03, -2.0580e-03,  3.0212e-03,  ..., -4.2343e-03,
         -2.9516e-04, -4.5853e-03],
        ...,
        [-2.7466e-03,  5.8699e-04,  2.3899e-03,  ...,  2.3232e-03,
         -2.5520e-03,  7.5760e-03],
        [ 6.8932e-03,  1.9360e-03,  3.2215e-03,  ...,  2.5654e-04,
         -7.3586e-03, -6.0310e-03],
        [ 8.2207e-04,  6.3057e-03,  1.7967e-03,  ..., -4.0627e-03,
         -4.2391e-04, -1.1040e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1260,  0.0007, -0.0125,  ..., -0.0122,  0.0173,  0.0146],
        [-0.0020, -0.1120, -0.0022,  ...,  0.0069, -0.0050, -0.0028],
        [ 0.0005,  0.0124, -0.1119,  ..., -0.0092,  0.0174, -0.0043],
        ...,
        [-0.0051, -0.0002,  0.0023,  ..., -0.1114, -0.0034,  0.0055],
        [ 0.0155,  0.0100,  0.0012,  ...,  0.0036, -0.1191, -0.0048],
        [ 0.0002, -0.0081, -0.0091,  ..., -0.0075, -0.0054, -0.1084]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1155,  0.0071, -0.0043,  ..., -0.0024,  0.0275, -0.0091],
        [-0.0018, -0.1316, -0.0011,  ..., -0.0040, -0.0061,  0.0026],
        [ 0.0033,  0.0065, -0.1292,  ..., -0.0022, -0.0075, -0.0154],
        ...,
        [-0.0048, -0.0036, -0.0060,  ..., -0.1355, -0.0008,  0.0046],
        [ 0.0085, -0.0037,  0.0043,  ...,  0.0017, -0.1418,  0.0110],
        [-0.0046,  0.0070,  0.0025,  ..., -0.0053,  0.0066, -0.1349]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:53:47 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 20:53:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9736,  0.0435,  0.0665,  ..., -0.5391, -0.0893,  0.7422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7212, -0.4683, -0.5708,  ..., -0.6289,  0.0434,  0.2520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.7695,  1.6553,  0.1326,  ..., -1.4160,  0.1472,  1.6055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.0117, -2.1113, -0.9102,  ..., -0.3694,  0.9531,  0.5913],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:53:47 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:53:47 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 20:54:44 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 20:55:43 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 20:56:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0019, -0.0055,  0.0023,  ..., -0.0013, -0.0170, -0.0058],
        [-0.0080,  0.0029, -0.0031,  ..., -0.0032,  0.0039, -0.0101],
        [-0.0062, -0.0055,  0.0007,  ...,  0.0037, -0.0025,  0.0012],
        ...,
        [ 0.0054,  0.0058, -0.0144,  ..., -0.0019,  0.0013, -0.0040],
        [-0.0024,  0.0032,  0.0076,  ...,  0.0023,  0.0093,  0.0055],
        [-0.0089,  0.0033,  0.0009,  ..., -0.0021, -0.0032, -0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1074,  0.0208,  0.0076,  ..., -0.0103,  0.0014, -0.0060],
        [-0.0041, -0.1005, -0.0039,  ...,  0.0072,  0.0040, -0.0005],
        [-0.0015, -0.0132, -0.0927,  ..., -0.0139,  0.0087, -0.0127],
        ...,
        [-0.0060, -0.0048, -0.0257,  ..., -0.1049,  0.0098,  0.0104],
        [-0.0145, -0.0016,  0.0084,  ..., -0.0018, -0.0974, -0.0026],
        [-0.0077,  0.0056, -0.0070,  ..., -0.0103,  0.0036, -0.0943]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1075, -0.0065,  0.0009,  ..., -0.0170, -0.0022, -0.0033],
        [-0.0057, -0.0972,  0.0066,  ...,  0.0058,  0.0092,  0.0038],
        [-0.0047, -0.0091, -0.1023,  ..., -0.0096,  0.0083, -0.0062],
        ...,
        [-0.0092, -0.0091,  0.0051,  ..., -0.1094,  0.0137, -0.0151],
        [-0.0122,  0.0093, -0.0057,  ...,  0.0097, -0.1079,  0.0108],
        [-0.0023,  0.0068,  0.0005,  ..., -0.0184,  0.0013, -0.0942]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:56:44 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 20:56:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2617,  0.6201, -0.0818,  ..., -0.5103,  0.2649,  0.7139],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5942, -0.9805, -0.4929,  ..., -0.3782,  0.5645,  0.3381],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2695,  1.7373, -0.1448,  ..., -1.2695, -0.1575,  2.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6250, -1.8125, -2.3711,  ..., -0.1392,  0.3574,  0.5708],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:56:45 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:56:45 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 20:57:46 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 20:58:47 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 20:59:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0696e-02,  4.4403e-03, -2.5702e-04,  ..., -1.0090e-03,
         -3.1853e-03, -1.2434e-04],
        [ 6.3057e-03,  1.1246e-02,  3.1586e-03,  ...,  1.0014e-03,
          6.0959e-03, -4.6921e-03],
        [-3.4485e-03, -3.5725e-03,  1.1086e-02,  ..., -1.3285e-03,
          5.7602e-04,  8.6975e-04],
        ...,
        [-4.4250e-03, -1.1539e-03, -2.2430e-03,  ...,  1.2619e-02,
         -7.4768e-03,  3.2825e-03],
        [ 7.7486e-04, -1.5020e-03,  2.7046e-03,  ..., -5.8289e-03,
          1.5854e-02, -1.9207e-03],
        [-6.2943e-04,  3.6354e-03,  3.5725e-03,  ...,  6.9380e-04,
         -6.8903e-05,  1.8585e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0833,  0.0036, -0.0059,  ..., -0.0011,  0.0119,  0.0075],
        [-0.0134, -0.1040, -0.0069,  ..., -0.0226, -0.0063, -0.0071],
        [-0.0072, -0.0016, -0.1008,  ..., -0.0068, -0.0110,  0.0090],
        ...,
        [-0.0050,  0.0090, -0.0022,  ..., -0.0986, -0.0188, -0.0009],
        [ 0.0033, -0.0046,  0.0055,  ..., -0.0082, -0.1094,  0.0112],
        [ 0.0016,  0.0073,  0.0047,  ..., -0.0012, -0.0011, -0.0909]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1313,  0.0103, -0.0045,  ..., -0.0076,  0.0033,  0.0131],
        [ 0.0032, -0.1371, -0.0103,  ..., -0.0129, -0.0033, -0.0026],
        [-0.0039,  0.0096, -0.1332,  ...,  0.0087, -0.0027,  0.0053],
        ...,
        [ 0.0105,  0.0020,  0.0068,  ..., -0.1267, -0.0081, -0.0043],
        [-0.0082, -0.0048, -0.0065,  ..., -0.0059, -0.1311,  0.0085],
        [ 0.0136,  0.0098,  0.0002,  ..., -0.0039,  0.0073, -0.1292]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 20:59:53 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 20:59:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.4531,  0.8926,  0.0435,  ..., -0.7490,  0.0767,  0.8306],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.0977, -1.1904, -0.4983,  ..., -0.2046,  0.5308,  0.3049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.8721,  2.3438,  0.0208,  ..., -1.2363, -0.1763,  2.8672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8145, -2.2441, -1.9707,  ..., -0.7227, -0.0251,  0.0239],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 20:59:53 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 20:59:53 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 21:00:56 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 21:02:00 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 21:03:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0209, -0.0036,  0.0054,  ..., -0.0077, -0.0021,  0.0009],
        [-0.0039, -0.0120,  0.0071,  ...,  0.0031,  0.0004, -0.0027],
        [ 0.0050, -0.0011, -0.0200,  ...,  0.0028, -0.0047,  0.0040],
        ...,
        [ 0.0121, -0.0034, -0.0019,  ..., -0.0124, -0.0034, -0.0033],
        [ 0.0042,  0.0047, -0.0028,  ...,  0.0019, -0.0230,  0.0038],
        [ 0.0015,  0.0059, -0.0059,  ..., -0.0009,  0.0059, -0.0221]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0649, -0.0025,  0.0169,  ..., -0.0058,  0.0080, -0.0175],
        [ 0.0062, -0.0518, -0.0087,  ...,  0.0168,  0.0082,  0.0080],
        [-0.0035,  0.0036, -0.0623,  ..., -0.0024,  0.0065, -0.0115],
        ...,
        [-0.0125,  0.0118, -0.0005,  ..., -0.0516, -0.0094,  0.0022],
        [ 0.0054,  0.0005,  0.0031,  ...,  0.0203, -0.0500,  0.0022],
        [-0.0085,  0.0053,  0.0012,  ..., -0.0020,  0.0062, -0.0656]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0796,  0.0023,  0.0065,  ..., -0.0096,  0.0029, -0.0006],
        [ 0.0059, -0.0670, -0.0076,  ...,  0.0059,  0.0029,  0.0087],
        [ 0.0151,  0.0215, -0.0717,  ..., -0.0146, -0.0128, -0.0083],
        ...,
        [-0.0117, -0.0043, -0.0194,  ..., -0.0788, -0.0054, -0.0050],
        [ 0.0054,  0.0084, -0.0148,  ...,  0.0051, -0.0743, -0.0041],
        [-0.0091,  0.0077,  0.0083,  ..., -0.0035, -0.0072, -0.0785]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:03:05 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 21:03:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1113,  0.8496, -0.0710,  ..., -0.6104, -0.0689,  1.1104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8081, -0.9150, -1.1279,  ..., -0.0718,  0.1896,  0.2455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5645,  2.4199,  0.4402,  ..., -1.3008, -0.1796,  4.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8887, -2.0020, -1.8555,  ..., -0.1758, -0.3594,  0.2522],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:03:05 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:03:06 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 21:04:11 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 21:05:20 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 21:06:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0147, -0.0175,  0.0015,  ...,  0.0033, -0.0019, -0.0076],
        [-0.0032,  0.0122,  0.0014,  ...,  0.0007, -0.0002, -0.0011],
        [-0.0060,  0.0009,  0.0070,  ..., -0.0042,  0.0084, -0.0050],
        ...,
        [-0.0035, -0.0068,  0.0054,  ...,  0.0102,  0.0072, -0.0017],
        [ 0.0103,  0.0070, -0.0032,  ..., -0.0164, -0.0018, -0.0004],
        [ 0.0026, -0.0007, -0.0092,  ..., -0.0058, -0.0004, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0671,  0.0029,  0.0071,  ...,  0.0013, -0.0019,  0.0035],
        [-0.0053, -0.0879,  0.0102,  ..., -0.0021,  0.0173, -0.0066],
        [-0.0025, -0.0061, -0.0815,  ..., -0.0159, -0.0068,  0.0043],
        ...,
        [ 0.0125, -0.0168,  0.0173,  ..., -0.0835,  0.0028, -0.0109],
        [ 0.0224,  0.0041,  0.0131,  ..., -0.0051, -0.0707,  0.0016],
        [-0.0135, -0.0072, -0.0039,  ..., -0.0122,  0.0129, -0.0787]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.9773e-02, -2.1439e-03, -4.9210e-03,  ..., -5.2948e-03,
          1.5850e-03,  1.9970e-03],
        [ 3.1281e-04, -1.0699e-01, -5.1498e-03,  ..., -1.3199e-02,
          1.2611e-02,  1.2779e-04],
        [ 5.8212e-03, -1.2222e-02, -1.0486e-01,  ..., -9.5673e-03,
         -5.3139e-03, -7.3166e-03],
        ...,
        [ 1.3069e-02, -2.2449e-03,  1.7303e-02,  ..., -8.3191e-02,
          1.9913e-03, -7.4196e-03],
        [ 3.2539e-03,  3.6240e-05,  5.3482e-03,  ...,  2.9564e-03,
         -1.1957e-01, -4.3068e-03],
        [-1.6312e-02,  1.8187e-03, -9.1095e-03,  ..., -2.6035e-03,
          1.2688e-02, -1.0022e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:06:31 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 21:06:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8672,  1.0957, -0.0068,  ..., -0.5801, -0.0830,  1.3252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8335, -1.0283, -0.8984,  ..., -0.3328, -0.0061, -0.0333],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8721,  2.4688,  0.5962,  ..., -1.2295,  0.0312,  4.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8926, -1.6484, -2.6953,  ..., -0.4482, -0.4438,  0.8154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:06:31 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:06:31 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 21:07:39 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 21:08:48 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 21:09:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.3482e-03, -3.4332e-03,  3.2444e-03,  ..., -9.8648e-03,
         -9.1028e-04, -9.7885e-03],
        [-4.4289e-03,  2.7313e-03,  4.5242e-03,  ..., -2.3727e-03,
          2.1515e-03, -4.3907e-03],
        [-1.2093e-03, -6.2408e-03,  6.7177e-03,  ...,  1.0429e-02,
         -3.7456e-04,  2.9507e-03],
        ...,
        [ 2.2717e-03,  1.9312e-03, -5.8174e-03,  ...,  1.7834e-03,
         -5.0850e-03, -7.4005e-03],
        [ 4.1008e-03,  1.6041e-03,  5.6534e-03,  ...,  1.9588e-03,
          8.6594e-03,  5.9700e-03],
        [ 1.6937e-03, -4.8332e-03, -6.7234e-05,  ...,  1.4206e-02,
          3.6621e-03,  1.3031e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.3894e-02, -8.3313e-03,  9.1934e-04,  ..., -3.9597e-03,
         -6.5804e-03, -1.1818e-02],
        [-3.3035e-03, -6.6040e-02,  2.6264e-03,  ...,  1.9073e-06,
          1.2980e-03,  1.2634e-02],
        [-1.3626e-02, -3.5000e-03, -4.9774e-02,  ...,  6.3133e-03,
          7.1869e-03,  1.6342e-02],
        ...,
        [-7.6904e-03,  1.3718e-02, -3.2349e-03,  ..., -7.1716e-02,
          8.8043e-03,  1.8265e-02],
        [-5.5466e-03,  3.2082e-03, -1.0010e-02,  ...,  6.6490e-03,
         -4.9713e-02,  6.1493e-03],
        [-5.3749e-03,  2.2125e-03, -1.4679e-02,  ..., -5.0888e-03,
          1.5717e-02, -5.7861e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0623,  0.0147, -0.0055,  ...,  0.0147, -0.0105, -0.0079],
        [-0.0064, -0.0704,  0.0005,  ..., -0.0132, -0.0033,  0.0127],
        [-0.0011, -0.0018, -0.0663,  ..., -0.0095,  0.0202, -0.0137],
        ...,
        [-0.0086,  0.0084, -0.0102,  ..., -0.0671, -0.0029,  0.0096],
        [ 0.0105, -0.0231, -0.0243,  ..., -0.0204, -0.0571, -0.0028],
        [-0.0050, -0.0053, -0.0244,  ..., -0.0099,  0.0049, -0.0664]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:09:55 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 21:09:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7119,  1.0791,  0.1669,  ..., -0.5845, -0.0617,  1.8848],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8267, -0.8643, -0.7900,  ..., -0.0773, -0.1307,  0.0665],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7822,  2.4785,  0.1436,  ..., -0.6831,  0.4429,  3.3574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.6816, -2.5391, -3.0781,  ..., -0.8496, -0.5537,  0.3979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:09:55 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:09:55 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 21:11:05 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 21:12:17 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 21:13:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5783e-04,  2.7895e-05,  9.4509e-04,  ...,  3.2673e-03,
         -1.0958e-03, -3.8986e-03],
        [ 6.2103e-03,  2.7370e-03, -4.1122e-03,  ..., -4.4746e-03,
          7.0992e-03,  1.3990e-03],
        [-2.8362e-03, -4.1008e-03, -3.1986e-03,  ..., -4.3640e-03,
          5.8632e-03,  3.0727e-03],
        ...,
        [-3.0613e-03, -5.1346e-03, -1.4162e-03,  ..., -4.4632e-03,
         -4.7207e-04,  1.9684e-03],
        [ 4.0855e-03, -2.3460e-03,  3.1986e-03,  ...,  3.3436e-03,
         -2.0046e-03,  9.2077e-04],
        [-1.3647e-03,  5.3139e-03, -1.9531e-03,  ..., -8.9798e-03,
          2.1152e-03,  2.7695e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0166, -0.0064, -0.0018,  ..., -0.0194,  0.0043,  0.0050],
        [ 0.0009, -0.0134,  0.0050,  ..., -0.0020, -0.0078, -0.0155],
        [-0.0107,  0.0239, -0.0180,  ..., -0.0072, -0.0086,  0.0026],
        ...,
        [-0.0019, -0.0152, -0.0193,  ..., -0.0276,  0.0074, -0.0086],
        [ 0.0020, -0.0002, -0.0027,  ..., -0.0113, -0.0375,  0.0081],
        [-0.0036,  0.0015,  0.0041,  ...,  0.0059,  0.0102, -0.0302]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0419,  0.0021,  0.0097,  ..., -0.0281,  0.0125,  0.0041],
        [ 0.0033, -0.0375,  0.0006,  ..., -0.0235,  0.0038, -0.0188],
        [ 0.0104, -0.0008, -0.0553,  ..., -0.0111,  0.0019, -0.0007],
        ...,
        [-0.0071,  0.0023, -0.0194,  ..., -0.0506,  0.0009, -0.0027],
        [ 0.0151, -0.0119, -0.0187,  ...,  0.0031, -0.0528,  0.0276],
        [-0.0031, -0.0033,  0.0106,  ..., -0.0040,  0.0283, -0.0538]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:13:29 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 21:13:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3674,  1.0205,  0.2166,  ..., -0.5059,  0.0056,  1.7148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7222, -0.6284, -0.9800,  ..., -0.1608, -0.1655,  0.2783],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7422,  2.7148,  0.5957,  ..., -0.4138,  0.6948,  3.1465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.6855, -2.4668, -3.6211,  ..., -0.3496,  0.0811,  0.0869],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:13:29 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:13:29 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 21:14:38 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 21:15:49 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 21:17:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0268, -0.0033,  0.0002,  ...,  0.0064, -0.0005,  0.0028],
        [-0.0064,  0.0243,  0.0020,  ...,  0.0015, -0.0024, -0.0009],
        [ 0.0002,  0.0007,  0.0250,  ..., -0.0022, -0.0017,  0.0037],
        ...,
        [ 0.0040, -0.0019, -0.0010,  ...,  0.0219, -0.0035,  0.0025],
        [-0.0033, -0.0012, -0.0005,  ..., -0.0044,  0.0204,  0.0008],
        [-0.0002, -0.0014,  0.0021,  ..., -0.0018,  0.0060,  0.0273]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0261,  0.0096, -0.0078,  ..., -0.0015, -0.0116,  0.0073],
        [ 0.0221, -0.0126,  0.0057,  ...,  0.0060, -0.0034, -0.0076],
        [-0.0120, -0.0016, -0.0216,  ...,  0.0180, -0.0054, -0.0002],
        ...,
        [ 0.0071, -0.0052, -0.0016,  ..., -0.0141,  0.0062, -0.0013],
        [-0.0003,  0.0042,  0.0009,  ..., -0.0129, -0.0149,  0.0083],
        [ 0.0064, -0.0041, -0.0003,  ..., -0.0019,  0.0030, -0.0307]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0296,  0.0113, -0.0020,  ..., -0.0198,  0.0113, -0.0028],
        [ 0.0155, -0.0239, -0.0063,  ...,  0.0079,  0.0185,  0.0185],
        [ 0.0068, -0.0067, -0.0322,  ..., -0.0028,  0.0182,  0.0117],
        ...,
        [-0.0006, -0.0036, -0.0071,  ..., -0.0227,  0.0142,  0.0121],
        [-0.0145,  0.0104,  0.0075,  ..., -0.0113, -0.0479,  0.0053],
        [-0.0030,  0.0057, -0.0033,  ...,  0.0024, -0.0074, -0.0419]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:17:04 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 21:17:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6924,  0.9526,  0.0431,  ..., -0.2781,  0.1771,  1.2832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9473, -0.9023, -1.0752,  ..., -0.3066, -0.1829,  0.1165],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7002,  2.7207,  0.5996,  ..., -0.2974,  0.7583,  3.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.8633, -2.3359, -3.1953,  ...,  0.2124, -0.7485, -0.1785],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:17:04 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:17:04 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 21:18:23 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 21:19:45 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 21:21:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2945e-03, -4.9353e-04,  8.4019e-04,  ..., -5.6953e-03,
         -3.6488e-03, -2.7537e-05],
        [-8.2684e-04,  2.3861e-03, -2.6131e-04,  ..., -2.7132e-04,
          2.6932e-03,  2.6760e-03],
        [ 3.6812e-03,  3.3927e-04,  2.4490e-03,  ...,  2.0428e-03,
         -2.3708e-03, -2.3098e-03],
        ...,
        [-6.7406e-03,  1.2817e-03,  4.6806e-03,  ..., -3.2282e-04,
         -1.7548e-03, -3.9978e-03],
        [ 1.4582e-03,  3.9558e-03, -6.3553e-03,  ...,  2.2240e-03,
          1.7881e-04,  6.7186e-04],
        [-7.7820e-04,  4.8828e-04, -1.9436e-03,  ..., -1.7748e-03,
          4.6997e-03,  4.8676e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.5839e-03,  7.9041e-03, -1.8951e-02,  ..., -2.2797e-02,
          6.1493e-03,  4.2763e-03],
        [-8.1177e-03, -1.7136e-02, -5.5275e-03,  ..., -6.4926e-03,
          3.0174e-03,  9.7198e-03],
        [-1.0208e-02, -6.7596e-03, -2.6749e-02,  ..., -1.5190e-02,
          1.1349e-04, -1.4366e-02],
        ...,
        [-3.0308e-03,  1.1391e-02, -2.2011e-03,  ..., -2.7496e-02,
         -1.3905e-03, -7.0572e-05],
        [-4.2992e-03,  9.5367e-03,  3.2310e-03,  ...,  1.9007e-03,
         -2.2049e-02,  6.0272e-03],
        [-1.0300e-02,  4.7989e-03, -2.4090e-03,  ..., -4.0894e-03,
         -5.6610e-03, -1.6678e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0599,  0.0104, -0.0128,  ..., -0.0037,  0.0007, -0.0057],
        [-0.0003, -0.0612, -0.0130,  ..., -0.0075, -0.0027, -0.0027],
        [ 0.0129, -0.0130, -0.0412,  ..., -0.0068, -0.0086, -0.0204],
        ...,
        [ 0.0126,  0.0136, -0.0034,  ..., -0.0488, -0.0083, -0.0014],
        [ 0.0007,  0.0053, -0.0031,  ..., -0.0124, -0.0349, -0.0137],
        [-0.0004, -0.0008, -0.0057,  ..., -0.0106,  0.0086, -0.0554]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:21:07 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 21:21:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6729,  1.0039,  0.2075,  ..., -0.1505,  0.2744,  1.1943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2910e+00, -8.2715e-01, -1.2246e+00,  ..., -1.1005e-01,
         4.0802e-02,  6.6376e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.4121,  2.7773,  2.1641,  ..., -0.3875,  0.8428,  3.3320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.9492, -2.2949, -2.1680,  ...,  0.0856, -1.0752, -0.0188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:21:07 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:21:07 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 21:22:28 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 21:23:50 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 21:25:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0262e-03, -2.1338e-04, -6.8378e-04,  ...,  5.6934e-04,
         -1.4629e-03, -1.9817e-03],
        [ 6.4707e-04, -3.5515e-03,  3.3617e-05,  ...,  1.3847e-03,
          7.3767e-04, -1.9608e-03],
        [-1.0376e-03,  2.7122e-03, -1.0557e-03,  ..., -2.2469e-03,
          1.9684e-03,  4.5395e-04],
        ...,
        [-3.8338e-03,  8.5068e-04, -7.3910e-04,  ..., -5.0659e-03,
          1.8883e-03,  1.8301e-03],
        [ 9.4712e-05,  3.6550e-04,  1.6670e-03,  ..., -3.2558e-03,
         -1.3895e-03,  2.6741e-03],
        [ 1.0567e-03, -3.2425e-03,  1.1683e-03,  ..., -2.9683e-05,
         -1.2150e-03, -1.7338e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0214, -0.0201,  0.0145,  ..., -0.0027, -0.0090,  0.0086],
        [-0.0131, -0.0210,  0.0030,  ..., -0.0055, -0.0002, -0.0074],
        [-0.0019, -0.0133, -0.0066,  ...,  0.0133, -0.0085, -0.0035],
        ...,
        [-0.0057,  0.0135, -0.0104,  ..., -0.0181, -0.0104,  0.0055],
        [ 0.0055, -0.0044, -0.0052,  ...,  0.0048, -0.0067,  0.0021],
        [-0.0002, -0.0125, -0.0022,  ...,  0.0006,  0.0151, -0.0100]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0484, -0.0012,  0.0143,  ..., -0.0033,  0.0130,  0.0134],
        [ 0.0038, -0.0556, -0.0038,  ...,  0.0099,  0.0135, -0.0005],
        [-0.0037,  0.0079, -0.0728,  ..., -0.0163, -0.0054,  0.0055],
        ...,
        [ 0.0131,  0.0063, -0.0032,  ..., -0.0469, -0.0118,  0.0077],
        [ 0.0077,  0.0084, -0.0135,  ...,  0.0003, -0.0524, -0.0120],
        [-0.0116,  0.0028,  0.0197,  ..., -0.0172,  0.0162, -0.0501]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:25:11 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 21:25:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6460,  0.9771,  0.1891,  ..., -0.1036,  0.2976,  1.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3184, -0.7549, -1.0547,  ...,  0.0761, -0.2271, -0.0889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([2.1621, 3.1777, 2.2930,  ..., 0.3259, 0.7842, 3.3535], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.8105, -1.6680, -2.6699,  ...,  0.5991, -0.6846,  0.5342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:25:11 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:25:11 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 21:26:33 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 21:27:55 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 21:29:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.4883e-03,  2.8610e-04,  1.2165e-04,  ..., -2.4509e-03,
         -7.5006e-04,  1.9350e-03],
        [-1.8368e-03,  1.1192e-02,  1.1015e-03,  ...,  3.2768e-03,
         -7.7152e-04,  4.2038e-03],
        [-8.9312e-04,  6.3972e-03,  1.7731e-02,  ..., -2.0790e-03,
          3.1662e-03,  1.7986e-03],
        ...,
        [-1.6708e-03, -1.3351e-04,  2.9564e-03,  ...,  1.2093e-02,
          1.1897e-04, -3.2959e-03],
        [ 1.3256e-03,  1.1742e-05,  1.6918e-03,  ..., -1.5259e-04,
          7.6256e-03,  1.4486e-03],
        [-2.8229e-03,  7.7772e-04,  2.1477e-03,  ...,  8.0633e-04,
          2.0485e-03,  1.0475e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0109,  0.0077, -0.0078,  ..., -0.0173, -0.0011, -0.0104],
        [ 0.0074,  0.0053,  0.0129,  ...,  0.0012,  0.0117,  0.0055],
        [ 0.0016,  0.0084,  0.0188,  ...,  0.0003,  0.0019,  0.0145],
        ...,
        [-0.0084, -0.0039, -0.0014,  ..., -0.0021,  0.0021, -0.0161],
        [ 0.0050, -0.0096, -0.0068,  ..., -0.0008,  0.0114,  0.0172],
        [ 0.0202,  0.0015,  0.0065,  ..., -0.0113,  0.0106, -0.0200]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.0171e-02, -1.3115e-02,  9.0063e-05,  ..., -3.8357e-03,
          8.7738e-03,  7.5607e-03],
        [ 2.0142e-03, -5.2551e-02,  8.8196e-03,  ..., -5.2338e-03,
         -9.5673e-03, -7.8735e-03],
        [-2.1240e-02,  1.3725e-02, -4.2511e-02,  ...,  1.2665e-02,
         -2.7588e-02,  3.7003e-03],
        ...,
        [ 7.1106e-03,  5.4092e-03, -1.2222e-02,  ..., -4.4678e-02,
         -5.1689e-03, -8.8730e-03],
        [ 1.1475e-02,  5.6992e-03, -1.2466e-02,  ...,  1.4877e-04,
         -6.0486e-02,  2.2812e-03],
        [ 9.5177e-04, -3.9558e-03,  2.2659e-02,  ..., -8.9645e-03,
          1.7624e-02, -4.6417e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:29:18 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 21:29:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8569,  0.9580,  0.6997,  ..., -0.1427,  0.3057,  1.1553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2773, -0.6738, -0.7280,  ...,  0.0197, -0.3315, -0.0342],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.9561, 3.0527, 3.0742,  ..., 0.3000, 0.9761, 3.6016], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4902, -2.1738, -2.6895,  ...,  1.2959, -1.0010,  1.2900],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:29:18 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:29:18 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 21:30:35 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 21:31:53 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 21:33:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.9973e-03, -6.6423e-04,  5.3072e-04,  ...,  1.6260e-04,
          2.8157e-04,  2.6569e-03],
        [ 4.1723e-04,  2.2888e-03, -3.4022e-04,  ..., -2.7275e-04,
         -8.4019e-04, -1.1854e-03],
        [-2.7919e-04,  2.2471e-04,  4.8370e-03,  ..., -1.0719e-03,
          5.8794e-04, -4.7350e-04],
        ...,
        [-1.0118e-03,  5.8174e-04,  1.1940e-03,  ...,  3.7308e-03,
          4.3344e-04,  1.2665e-03],
        [ 9.4295e-05,  9.5320e-04, -9.0837e-04,  ...,  5.5552e-04,
          5.9967e-03,  4.7469e-04],
        [-8.9347e-05, -1.6108e-03,  7.7128e-05,  ..., -1.8799e-04,
          8.2016e-04,  7.6904e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0231, -0.0109, -0.0053,  ..., -0.0027, -0.0040,  0.0005],
        [ 0.0032,  0.0067, -0.0022,  ..., -0.0045, -0.0040, -0.0061],
        [-0.0051,  0.0062,  0.0198,  ...,  0.0058, -0.0052,  0.0044],
        ...,
        [-0.0046,  0.0135,  0.0042,  ...,  0.0052, -0.0034, -0.0032],
        [-0.0035, -0.0085, -0.0007,  ...,  0.0038,  0.0136,  0.0096],
        [-0.0173,  0.0197, -0.0019,  ..., -0.0056,  0.0103,  0.0289]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0492, -0.0209,  0.0111,  ..., -0.0090, -0.0043,  0.0557],
        [-0.0154, -0.0080,  0.0050,  ..., -0.0163, -0.0117,  0.0313],
        [ 0.0080,  0.0210,  0.0596,  ..., -0.0258,  0.0073,  0.0032],
        ...,
        [-0.0002, -0.0058, -0.0071,  ...,  0.0643, -0.0052,  0.0143],
        [ 0.0101, -0.0166,  0.0139,  ...,  0.0041,  0.0357, -0.0037],
        [-0.0079,  0.0345,  0.0123,  ...,  0.0160,  0.0079,  0.0646]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:33:15 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 21:33:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.7373, 1.0205, 0.6963,  ..., 0.0673, 0.2522, 1.0840], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8833, -0.4590, -0.8657,  ...,  0.1438, -0.2078,  0.1266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.7314, 3.7617, 2.4961,  ..., 0.5361, 0.1460, 4.3750], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1914, -1.5049, -3.0215,  ...,  0.3730, -1.1289,  3.4648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:33:15 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:33:15 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 21:34:33 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 21:35:53 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 21:37:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.2635e-03, -9.6035e-04,  1.3332e-03,  ..., -8.4543e-04,
          9.3889e-04,  1.2283e-03],
        [-7.6294e-04,  1.0242e-03,  1.0166e-03,  ..., -1.9798e-03,
          7.3147e-04, -4.7874e-04],
        [-5.8126e-04, -7.6103e-04,  3.2578e-03,  ..., -8.4400e-04,
         -3.0565e-04,  7.9215e-05],
        ...,
        [ 5.3978e-04, -9.9087e-04,  4.9543e-04,  ...,  3.2787e-03,
          9.6607e-04, -3.8171e-04],
        [ 4.4632e-04,  1.7967e-03, -7.8011e-04,  ...,  9.0313e-04,
          1.0700e-03, -6.8474e-04],
        [ 1.2627e-03, -3.8862e-04,  2.8305e-03,  ..., -1.0824e-03,
         -1.0788e-05,  3.4676e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0045,  0.0018,  0.0045,  ..., -0.0159, -0.0036,  0.0039],
        [ 0.0062,  0.0091, -0.0048,  ...,  0.0147, -0.0086,  0.0152],
        [ 0.0005,  0.0101,  0.0060,  ..., -0.0175,  0.0014, -0.0098],
        ...,
        [-0.0025,  0.0112,  0.0003,  ...,  0.0060, -0.0008, -0.0031],
        [-0.0015,  0.0134, -0.0094,  ..., -0.0077,  0.0084, -0.0014],
        [-0.0014,  0.0059, -0.0128,  ...,  0.0121,  0.0163,  0.0194]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0457,  0.0004,  0.0065,  ..., -0.0131, -0.0156,  0.0135],
        [-0.0131, -0.0442, -0.0008,  ...,  0.0209,  0.0077, -0.0170],
        [ 0.0160,  0.0075, -0.0410,  ..., -0.0063, -0.0086, -0.0160],
        ...,
        [ 0.0015,  0.0208, -0.0121,  ..., -0.0602,  0.0066, -0.0031],
        [ 0.0256, -0.0138, -0.0224,  ..., -0.0040, -0.0311,  0.0094],
        [ 0.0090,  0.0160, -0.0258,  ...,  0.0201, -0.0027, -0.0267]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:37:15 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 21:37:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6577,  0.9282,  0.8379,  ..., -0.0093,  0.2668,  1.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4922, -0.5815, -0.8569,  ...,  0.2737, -0.3140,  0.3235],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.1914,  3.5840,  1.1943,  ..., -0.3916, -1.0430,  3.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2229, -0.8320, -4.5273,  ..., -0.2720, -0.5039,  2.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:37:15 root INFO     [order_1_approx] starting weight calculation for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:37:15 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 21:38:38 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 21:40:01 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 21:41:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.0163e-03, -9.3603e-04,  1.5759e-04,  ...,  2.6917e-04,
         -3.3283e-04, -4.1270e-04],
        [ 5.3310e-04,  3.1414e-03, -2.0099e-04,  ...,  2.4033e-04,
          8.8513e-05,  7.1669e-04],
        [ 8.2445e-04, -6.7139e-04,  4.6387e-03,  ..., -6.7234e-04,
         -1.3046e-03,  6.6400e-05],
        ...,
        [-9.4271e-04,  6.8951e-04, -3.4213e-04,  ...,  5.5733e-03,
          6.7890e-05, -1.0033e-03],
        [-7.9155e-05, -2.2316e-04,  1.1683e-04,  ...,  8.4937e-05,
          6.8321e-03, -3.3140e-04],
        [-8.2076e-05,  6.5088e-04, -1.6689e-05,  ..., -4.7874e-04,
          3.5024e-04,  7.5455e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0169,  0.0021, -0.0115,  ..., -0.0005,  0.0068, -0.0006],
        [ 0.0144,  0.0036,  0.0015,  ..., -0.0089,  0.0046,  0.0011],
        [-0.0169, -0.0114,  0.0170,  ...,  0.0168, -0.0012,  0.0046],
        ...,
        [-0.0029,  0.0033, -0.0048,  ...,  0.0212, -0.0096,  0.0118],
        [-0.0092, -0.0190, -0.0051,  ..., -0.0049,  0.0094,  0.0165],
        [ 0.0082,  0.0297,  0.0145,  ..., -0.0002,  0.0058,  0.0188]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0061, -0.0256,  0.0103,  ..., -0.0111,  0.0049, -0.0129],
        [ 0.0396, -0.0359, -0.0133,  ..., -0.0163, -0.0084,  0.0263],
        [-0.0179,  0.0096,  0.0080,  ..., -0.0057,  0.0054, -0.0118],
        ...,
        [-0.0150, -0.0126, -0.0095,  ...,  0.0078,  0.0049,  0.0013],
        [-0.0021, -0.0097, -0.0113,  ..., -0.0204,  0.0027,  0.0088],
        [ 0.0101,  0.0079,  0.0068,  ..., -0.0113,  0.0086,  0.0235]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:41:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To standardize results in standardization
To optimize results in optimization
To restore results in restoration
To illumine results in illumination
To randomize results in randomization
To minimize results in minimization
To aspire results in aspiration
To characterize results in
2024-06-30 21:41:27 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 21:41:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0796, -0.8589,  0.1296,  ..., -1.3135, -0.8135, -0.4517],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1125,  0.2849, -0.3613,  ..., -0.4124, -0.2581, -0.0801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5742, -0.7939, -0.0884,  ..., -1.1748, -0.6968, -0.2319],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0333,  0.5488, -0.0798,  ...,  0.1648, -0.0477,  0.3081],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:41:27 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:41:27 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 21:41:50 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 21:42:13 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 21:42:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.8082e-02,  2.4052e-03, -2.8114e-03,  ..., -3.3450e-04,
         -2.5344e-04, -3.0079e-03],
        [ 7.8583e-04, -1.7303e-02, -2.6798e-03,  ..., -4.3011e-04,
         -3.4199e-03,  3.8929e-03],
        [-1.7443e-03,  2.5272e-04, -1.8646e-02,  ...,  2.7990e-04,
         -4.9400e-03,  6.4564e-04],
        ...,
        [-1.1988e-03, -1.7958e-03, -1.7166e-03,  ..., -1.5480e-02,
         -3.0117e-03, -3.3474e-04],
        [-1.1845e-03,  2.0289e-04,  1.4524e-03,  ..., -3.9940e-03,
         -1.8616e-02,  1.0099e-03],
        [-8.9169e-04,  8.0681e-04, -1.9855e-03,  ...,  6.1870e-05,
          1.8921e-03, -1.9318e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0391, -0.0009,  0.0015,  ..., -0.0102, -0.0030, -0.0017],
        [-0.0013, -0.0387,  0.0033,  ...,  0.0014, -0.0026, -0.0012],
        [-0.0023,  0.0031, -0.0448,  ...,  0.0055,  0.0056,  0.0108],
        ...,
        [-0.0061,  0.0018,  0.0068,  ..., -0.0371,  0.0053, -0.0046],
        [-0.0096, -0.0036,  0.0049,  ..., -0.0004, -0.0365,  0.0054],
        [ 0.0054,  0.0042,  0.0019,  ...,  0.0040,  0.0068, -0.0338]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0357,  0.0046, -0.0059,  ..., -0.0029, -0.0045,  0.0033],
        [ 0.0029, -0.0422, -0.0007,  ...,  0.0057,  0.0013, -0.0008],
        [-0.0043,  0.0007, -0.0433,  ...,  0.0003,  0.0050,  0.0026],
        ...,
        [-0.0030,  0.0059,  0.0017,  ..., -0.0406, -0.0010, -0.0005],
        [-0.0027,  0.0005,  0.0013,  ..., -0.0005, -0.0375,  0.0041],
        [-0.0008, -0.0033, -0.0029,  ...,  0.0016,  0.0043, -0.0352]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:42:38 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 21:42:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2362, -0.5332, -0.0945,  ..., -1.5557, -0.4697, -0.6914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2349,  0.2732, -0.0753,  ..., -0.1514, -0.0734, -0.1781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8281, -0.6074, -0.2419,  ..., -1.4727, -0.4978, -0.8936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 5.1880e-04,  4.9976e-01, -1.3916e-02,  ..., -2.5684e-01,
        -7.6233e-02,  5.2832e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:42:39 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:42:39 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 21:43:03 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 21:43:27 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 21:43:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3605e-02,  3.1185e-03,  1.7524e-04,  ..., -5.0306e-05,
         -2.0123e-03,  2.4776e-03],
        [-9.5558e-04, -2.5665e-02,  1.7986e-03,  ...,  2.1439e-03,
          4.5681e-04, -1.4820e-03],
        [-2.3022e-03,  2.0332e-03, -2.6260e-02,  ..., -1.4639e-03,
          1.2341e-03,  2.0504e-04],
        ...,
        [ 2.9202e-03,  4.8752e-03,  1.2474e-03,  ..., -2.2903e-02,
         -4.0321e-03,  3.0732e-04],
        [-2.3975e-03,  4.0579e-04, -1.5755e-03,  ...,  2.8191e-03,
         -2.2980e-02, -3.9215e-03],
        [-1.0815e-03, -2.6207e-03, -3.0117e-03,  ...,  3.4904e-03,
          3.9253e-03, -2.5589e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.0444e-02,  6.5384e-03, -1.8082e-03,  ..., -1.7471e-03,
         -7.0648e-03,  8.8644e-04],
        [ 9.3460e-03, -7.3059e-02, -7.2403e-03,  ...,  7.0534e-03,
          8.7280e-03,  2.5120e-03],
        [-1.2016e-04, -4.2877e-03, -7.4402e-02,  ..., -3.7918e-03,
         -1.1253e-02,  3.1738e-03],
        ...,
        [ 7.6942e-03,  5.6648e-04, -3.4485e-03,  ..., -7.2266e-02,
         -7.6199e-04,  1.2913e-03],
        [-5.3596e-03, -9.5367e-03, -2.3556e-03,  ..., -4.1246e-05,
         -7.4036e-02,  3.2024e-03],
        [-3.4180e-03,  4.8218e-03,  5.9433e-03,  ..., -1.4565e-02,
          3.3455e-03, -8.2275e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0770,  0.0049, -0.0011,  ...,  0.0047, -0.0060, -0.0001],
        [ 0.0070, -0.0723, -0.0012,  ...,  0.0010,  0.0049, -0.0032],
        [-0.0037, -0.0070, -0.0687,  ..., -0.0014,  0.0049, -0.0022],
        ...,
        [ 0.0058, -0.0042,  0.0036,  ..., -0.0723, -0.0031,  0.0024],
        [-0.0040, -0.0006,  0.0089,  ...,  0.0054, -0.0675,  0.0008],
        [ 0.0033, -0.0004,  0.0079,  ..., -0.0016, -0.0025, -0.0758]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:43:53 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 21:43:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7158, -1.0752, -0.1243,  ..., -1.4482, -0.8887, -0.3406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0754,  0.9058, -0.1346,  ...,  0.2605, -0.0797,  0.5010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4668, -1.2363,  0.0247,  ..., -1.2285, -0.4778, -0.6660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3862,  0.3462, -0.1936,  ..., -0.1750, -0.3889,  0.8096],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:43:53 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:43:53 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 21:44:18 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 21:44:42 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 21:45:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.8190e-03,  1.4043e-04, -1.8978e-03,  ...,  1.0347e-03,
         -1.6975e-03, -3.0975e-03],
        [-6.4659e-04, -7.8506e-03, -1.3094e-03,  ...,  2.4021e-05,
          4.9496e-04,  1.5326e-03],
        [ 3.3398e-03, -3.9043e-03, -5.3215e-03,  ..., -2.9011e-03,
          1.6365e-03,  1.4591e-04],
        ...,
        [ 1.8711e-03,  2.8610e-04, -3.5248e-03,  ..., -7.0572e-03,
          2.3098e-03,  9.3746e-04],
        [ 9.5367e-05, -1.4801e-03,  7.1096e-04,  ...,  6.1417e-04,
         -4.9400e-03, -4.7374e-04],
        [-2.2686e-04,  1.4620e-03,  1.8463e-03,  ...,  8.9169e-04,
          8.0109e-04, -5.7716e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0385, -0.0111, -0.0074,  ..., -0.0042,  0.0001,  0.0080],
        [-0.0087, -0.0392, -0.0011,  ..., -0.0088, -0.0014, -0.0077],
        [-0.0020, -0.0014, -0.0404,  ..., -0.0081,  0.0069,  0.0006],
        ...,
        [ 0.0023,  0.0023, -0.0091,  ..., -0.0417, -0.0053, -0.0061],
        [-0.0012,  0.0040, -0.0011,  ...,  0.0042, -0.0426,  0.0012],
        [-0.0015, -0.0128,  0.0042,  ...,  0.0078,  0.0055, -0.0332]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.1555e-02,  1.9512e-03, -2.7542e-03,  ...,  1.4496e-04,
          1.2636e-03, -1.3256e-03],
        [-4.6387e-03, -3.7415e-02,  8.5449e-03,  ..., -3.7823e-03,
         -7.0877e-03,  1.3733e-03],
        [ 5.1346e-03,  4.6921e-03, -3.3234e-02,  ...,  4.1885e-03,
          2.3956e-03,  1.8854e-03],
        ...,
        [-2.6340e-03,  2.7180e-05, -4.1351e-03,  ..., -3.7170e-02,
         -7.0343e-03, -1.8072e-04],
        [ 5.2452e-03,  1.9646e-03, -2.5749e-03,  ...,  2.1057e-03,
         -3.2928e-02,  3.7613e-03],
        [ 5.3120e-04, -2.0523e-03, -7.4005e-04,  ..., -2.7676e-03,
          5.4512e-03, -3.5156e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:45:11 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 21:45:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9858, -0.7798, -0.2905,  ..., -1.7080, -0.6138, -1.1572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0224,  0.7954, -0.0193,  ..., -0.3911, -0.1377,  0.8389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1052, -1.1865,  0.2422,  ..., -1.2725, -0.5034, -0.4326],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6719,  0.4438,  0.0134,  ..., -0.2321, -0.0554,  0.6646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:45:11 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:45:11 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 21:45:41 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 21:46:11 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 21:46:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.0430e-03,  2.9230e-04,  1.0567e-03,  ...,  1.2341e-03,
          5.3406e-04, -1.5869e-03],
        [ 8.9836e-04, -6.7482e-03, -1.9503e-03,  ...,  1.4853e-04,
          1.4734e-04, -5.9128e-04],
        [-2.3804e-03, -8.6880e-04, -4.0550e-03,  ..., -3.9005e-04,
          7.3719e-04, -1.3380e-03],
        ...,
        [ 6.3133e-04, -2.4719e-03,  4.0746e-04,  ..., -8.4000e-03,
          1.1883e-03, -2.7657e-04],
        [-2.1992e-03, -3.4785e-04,  4.0340e-04,  ..., -3.3779e-03,
         -5.1117e-03, -1.8787e-03],
        [ 1.5106e-03,  1.4353e-04,  3.0875e-05,  ..., -2.2240e-03,
         -1.7605e-03, -4.7646e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0522, -0.0089, -0.0041,  ..., -0.0054,  0.0020,  0.0008],
        [ 0.0014, -0.0506, -0.0059,  ..., -0.0013,  0.0071,  0.0022],
        [ 0.0040, -0.0040, -0.0451,  ...,  0.0086,  0.0038,  0.0050],
        ...,
        [-0.0139,  0.0008,  0.0056,  ..., -0.0541, -0.0063,  0.0035],
        [ 0.0024, -0.0133, -0.0060,  ..., -0.0078, -0.0352,  0.0083],
        [ 0.0027,  0.0045, -0.0040,  ..., -0.0001, -0.0035, -0.0435]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0459, -0.0041, -0.0034,  ..., -0.0077,  0.0006,  0.0039],
        [ 0.0075, -0.0447, -0.0010,  ...,  0.0093,  0.0119, -0.0079],
        [-0.0014, -0.0126, -0.0518,  ...,  0.0035, -0.0047, -0.0042],
        ...,
        [-0.0068,  0.0045,  0.0054,  ..., -0.0579, -0.0019, -0.0068],
        [-0.0019, -0.0035,  0.0010,  ..., -0.0036, -0.0458,  0.0037],
        [-0.0091,  0.0009, -0.0078,  ...,  0.0005,  0.0001, -0.0493]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:46:43 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 21:46:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4290, -1.2959,  0.0222,  ..., -1.1299, -0.4373, -0.7114],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4897,  0.4016, -0.2271,  ..., -0.2131, -0.4541,  1.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2385, -1.0410,  0.3489,  ..., -1.5107, -0.3010, -0.6250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4631,  0.0688,  0.3525,  ...,  0.0619,  0.1882,  0.2124],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:46:43 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:46:43 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 21:47:16 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 21:47:49 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 21:48:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.0975e-03,  1.2350e-04, -8.7500e-05,  ..., -9.1743e-04,
          1.9817e-03,  4.3917e-04],
        [ 6.5041e-04,  1.6117e-03,  2.4605e-04,  ...,  1.9722e-03,
          1.3304e-03, -5.3787e-04],
        [ 5.2929e-04, -2.4624e-03,  4.5300e-04,  ..., -1.0033e-03,
         -1.2703e-03, -1.2417e-03],
        ...,
        [-1.5659e-03,  1.3695e-03, -1.0319e-03,  ...,  1.5230e-03,
          1.2589e-03,  1.3809e-03],
        [ 1.4811e-03,  1.5182e-03, -1.0796e-03,  ...,  5.2214e-04,
          2.1515e-03,  1.3790e-03],
        [-5.5885e-04, -2.1088e-04,  3.4380e-04,  ...,  2.1744e-03,
         -8.0967e-04, -2.1782e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.7158e-02,  2.6112e-03,  5.5389e-03,  ..., -4.7989e-03,
         -5.7640e-03,  3.1128e-03],
        [ 2.8629e-03, -9.0515e-02, -1.4524e-03,  ...,  9.5367e-03,
         -2.2316e-03,  9.8267e-03],
        [-5.3787e-04,  1.1420e-04, -8.8379e-02,  ..., -1.6346e-03,
         -3.5629e-03,  1.1627e-02],
        ...,
        [-6.5804e-05, -1.7357e-04, -1.8112e-02,  ..., -8.1177e-02,
          2.8439e-03, -5.3329e-03],
        [ 8.5831e-03, -3.7041e-03,  1.4315e-03,  ...,  1.0204e-03,
         -8.4900e-02,  6.2904e-03],
        [-4.5395e-03, -1.8644e-04,  6.7062e-03,  ..., -3.3722e-03,
          1.3000e-02, -1.0376e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.4421e-02, -7.7915e-04,  5.0316e-03,  ..., -2.9697e-03,
         -4.3221e-03,  2.4815e-03],
        [-7.5684e-03, -8.8135e-02,  7.9193e-03,  ...,  1.0586e-03,
         -2.1133e-03,  5.8174e-03],
        [ 5.2643e-04, -3.6583e-03, -8.2214e-02,  ..., -4.7684e-03,
          6.8550e-03,  5.1765e-03],
        ...,
        [ 1.0090e-03, -5.6190e-03, -3.9062e-03,  ..., -8.2520e-02,
         -8.6784e-05,  7.4539e-03],
        [-2.9392e-03, -5.8823e-03,  5.2719e-03,  ...,  4.2305e-03,
         -8.3740e-02,  2.9716e-03],
        [-6.1913e-03,  1.0010e-02,  9.1400e-03,  ..., -4.1504e-03,
          1.4038e-03, -1.0468e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:48:22 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 21:48:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0953, -1.2188,  0.2119,  ..., -1.2012, -0.5112, -0.4626],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8159,  0.5337,  0.0052,  ..., -0.2639, -0.0836,  0.7969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2681, -0.7227, -0.0857,  ..., -1.3018,  0.0540, -1.2969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1057, -0.2212, -0.3149,  ...,  0.3125, -0.1187, -0.8345],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:48:22 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:48:22 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 21:48:57 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 21:49:34 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 21:50:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.6305e-03, -1.2531e-03, -1.0681e-03,  ..., -9.9540e-06,
          7.5817e-04, -3.5286e-04],
        [ 4.2496e-03, -1.2260e-02,  3.1147e-03,  ..., -1.0748e-03,
         -5.5885e-04,  2.0313e-04],
        [-4.7264e-03,  6.2752e-03, -9.1400e-03,  ..., -1.0834e-03,
         -1.7490e-03, -3.6030e-03],
        ...,
        [ 3.9253e-03, -4.4365e-03,  1.3485e-03,  ..., -7.2479e-03,
         -1.5621e-03,  3.4027e-03],
        [ 2.7885e-03, -2.6932e-03,  2.9831e-03,  ..., -6.0959e-03,
         -2.3403e-03, -1.9855e-03],
        [ 1.9474e-03,  3.9635e-03, -1.8234e-03,  ...,  2.6417e-04,
         -9.7809e-03, -2.5940e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.2825e-02,  1.1230e-02,  5.2986e-03,  ...,  6.7635e-03,
          1.3065e-03, -5.8136e-03],
        [ 5.1765e-03, -1.0852e-01,  1.4359e-02,  ...,  3.1128e-03,
         -1.7338e-03,  6.3667e-03],
        [-1.9093e-03, -2.3022e-03, -9.2346e-02,  ..., -4.1885e-03,
         -9.6798e-05, -4.7417e-03],
        ...,
        [ 9.6130e-03,  4.9324e-03,  6.7978e-03,  ..., -9.4910e-02,
         -2.1591e-03,  1.0929e-03],
        [-6.3972e-03, -6.6681e-03, -3.3531e-03,  ..., -6.9427e-04,
         -8.6853e-02,  1.8864e-03],
        [-1.1627e-02, -2.2526e-03, -1.5381e-02,  ..., -2.0172e-02,
         -3.2616e-03, -9.3994e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0945, -0.0056, -0.0045,  ..., -0.0024, -0.0026,  0.0011],
        [ 0.0033, -0.0863,  0.0016,  ..., -0.0018, -0.0004,  0.0006],
        [-0.0008, -0.0020, -0.0839,  ...,  0.0005,  0.0019, -0.0080],
        ...,
        [ 0.0107,  0.0072,  0.0073,  ..., -0.0895, -0.0053, -0.0033],
        [-0.0041,  0.0010, -0.0049,  ..., -0.0102, -0.0938, -0.0021],
        [-0.0104,  0.0019, -0.0182,  ...,  0.0035, -0.0013, -0.0895]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:50:09 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 21:50:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2130, -0.9927,  0.2822,  ..., -1.3525, -0.2881, -0.6387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4871,  0.0853,  0.3284,  ...,  0.0348,  0.1885,  0.1919],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4768, -0.9053, -0.5508,  ..., -1.0342,  0.1584, -1.0674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4397, -0.8042, -0.7510,  ...,  0.0452,  0.2888, -0.9214],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:50:09 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:50:09 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 21:50:40 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 21:51:18 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 21:51:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0070,  0.0038, -0.0017,  ..., -0.0006, -0.0009,  0.0010],
        [ 0.0029, -0.0033, -0.0070,  ...,  0.0030,  0.0012, -0.0012],
        [ 0.0035,  0.0010, -0.0039,  ...,  0.0011, -0.0010, -0.0009],
        ...,
        [ 0.0007,  0.0008,  0.0022,  ..., -0.0029,  0.0038,  0.0012],
        [-0.0027,  0.0014, -0.0029,  ...,  0.0036,  0.0008, -0.0023],
        [ 0.0016, -0.0005,  0.0038,  ...,  0.0026,  0.0088, -0.0039]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.9294e-02,  4.6997e-03,  1.1703e-02,  ..., -9.0332e-03,
          4.9477e-03, -2.7714e-03],
        [ 8.3923e-03, -7.8491e-02, -8.1406e-03,  ...,  1.2634e-02,
         -7.9575e-03,  2.7809e-03],
        [-3.5000e-03,  8.3160e-04, -8.2214e-02,  ...,  2.3365e-05,
         -9.8877e-03,  2.5101e-03],
        ...,
        [-9.5215e-03, -1.2123e-02,  5.8403e-03,  ..., -8.1482e-02,
         -3.5324e-03, -3.2902e-03],
        [-3.5896e-03,  3.0289e-03,  6.7139e-03,  ...,  1.8127e-02,
         -7.9163e-02, -6.1302e-03],
        [ 1.8539e-03, -6.4659e-04,  9.9106e-03,  ...,  1.4366e-02,
          7.2021e-03, -8.3069e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1002,  0.0057,  0.0113,  ..., -0.0025, -0.0111,  0.0005],
        [ 0.0075, -0.0830, -0.0110,  ...,  0.0064,  0.0065, -0.0018],
        [-0.0091, -0.0051, -0.0805,  ...,  0.0055, -0.0031,  0.0086],
        ...,
        [-0.0043,  0.0006, -0.0040,  ..., -0.0923,  0.0181,  0.0024],
        [ 0.0133,  0.0060,  0.0055,  ...,  0.0035, -0.0846, -0.0056],
        [ 0.0012, -0.0016,  0.0052,  ...,  0.0123,  0.0051, -0.0925]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:52:00 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 21:52:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2424, -0.6958, -0.0914,  ..., -1.1104,  0.0345, -1.2324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0987, -0.2292, -0.2988,  ...,  0.2773, -0.1179, -0.8418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 9.5801e-01, -5.6152e-01, -3.7622e-01,  ..., -2.0039e+00,
        -1.8311e-03, -8.9258e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4333, -1.1719, -1.2520,  ..., -0.4324,  0.0215, -0.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:52:00 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:52:00 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 21:52:43 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 21:53:24 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 21:54:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0051, -0.0021, -0.0007,  ..., -0.0008, -0.0019, -0.0051],
        [-0.0007, -0.0040,  0.0010,  ..., -0.0021,  0.0029, -0.0045],
        [-0.0011,  0.0010, -0.0042,  ...,  0.0020, -0.0005,  0.0008],
        ...,
        [-0.0024, -0.0003, -0.0038,  ..., -0.0049,  0.0028,  0.0015],
        [ 0.0062,  0.0005, -0.0012,  ..., -0.0016, -0.0088, -0.0030],
        [ 0.0038,  0.0025,  0.0011,  ...,  0.0008,  0.0029, -0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0861,  0.0026, -0.0048,  ..., -0.0037, -0.0161,  0.0082],
        [ 0.0003, -0.1052,  0.0166,  ...,  0.0058, -0.0041,  0.0047],
        [ 0.0080,  0.0107, -0.0878,  ...,  0.0010, -0.0091, -0.0139],
        ...,
        [ 0.0019,  0.0058, -0.0038,  ..., -0.0837,  0.0022, -0.0017],
        [-0.0041, -0.0014, -0.0002,  ..., -0.0077, -0.0938,  0.0014],
        [ 0.0027, -0.0005, -0.0154,  ..., -0.0051, -0.0021, -0.0924]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1227,  0.0183, -0.0035,  ..., -0.0182,  0.0060, -0.0071],
        [-0.0036, -0.1144,  0.0057,  ...,  0.0010,  0.0022,  0.0127],
        [ 0.0104,  0.0023, -0.1136,  ..., -0.0047, -0.0056,  0.0241],
        ...,
        [ 0.0022,  0.0018, -0.0060,  ..., -0.1056, -0.0024,  0.0047],
        [-0.0093,  0.0170, -0.0094,  ...,  0.0062, -0.1194,  0.0195],
        [ 0.0080, -0.0079, -0.0121,  ..., -0.0057,  0.0061, -0.1179]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:54:09 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 21:54:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3503, -0.7329, -0.4685,  ..., -0.7832,  0.0991, -0.8770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3435, -0.6772, -0.6401,  ...,  0.0149,  0.2142, -0.7896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8760, -0.2485,  0.0579,  ..., -2.1543,  0.3892, -1.3867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.3262, -1.1396, -1.0322,  ..., -0.1340,  0.1343,  0.0154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:54:10 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:54:10 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 21:54:59 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 21:55:47 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 21:56:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.0746e-03,  4.8943e-03,  3.6125e-03,  ..., -2.3384e-03,
          1.8473e-03,  2.5959e-03],
        [ 2.4433e-03, -5.3310e-04, -3.4485e-03,  ...,  4.2152e-04,
         -5.9319e-03,  4.4022e-03],
        [-1.6060e-03, -1.6479e-03,  7.9575e-03,  ..., -1.2589e-03,
          4.4136e-03, -6.3400e-03],
        ...,
        [-1.3790e-03, -3.3092e-03, -3.6125e-03,  ...,  3.4161e-03,
          9.9659e-05, -6.5231e-04],
        [-7.4615e-03, -7.2479e-05, -8.9598e-04,  ..., -5.5218e-04,
          3.0518e-04,  1.4629e-03],
        [-5.5351e-03, -4.4537e-04, -4.7989e-03,  ..., -2.6588e-03,
         -3.5858e-03,  2.5520e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1798e-01, -2.3941e-02,  1.4019e-04,  ...,  1.4694e-02,
          1.4977e-02, -6.0997e-03],
        [-1.9779e-03, -1.1108e-01, -1.3763e-02,  ..., -6.5651e-03,
         -5.8517e-03,  1.1780e-02],
        [-1.0338e-02, -9.4414e-05, -1.0651e-01,  ...,  7.5073e-03,
          1.6346e-03, -3.7460e-03],
        ...,
        [-8.4686e-03,  1.2856e-02,  1.0040e-02,  ..., -1.1914e-01,
         -3.7136e-03, -3.1624e-03],
        [-3.1757e-03, -6.7902e-03,  5.6763e-03,  ..., -1.0880e-02,
         -1.1890e-01,  1.2711e-02],
        [-3.2692e-03,  9.5062e-03, -7.3509e-03,  ..., -6.7902e-03,
          1.4839e-02, -1.1646e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1519, -0.0177, -0.0006,  ...,  0.0164,  0.0043,  0.0076],
        [-0.0036, -0.1696, -0.0063,  ...,  0.0065, -0.0130, -0.0048],
        [-0.0112, -0.0077, -0.1401,  ...,  0.0108, -0.0019, -0.0111],
        ...,
        [-0.0062,  0.0138,  0.0030,  ..., -0.1680,  0.0058,  0.0075],
        [ 0.0129,  0.0025,  0.0030,  ..., -0.0068, -0.1564, -0.0054],
        [-0.0093,  0.0051,  0.0034,  ..., -0.0150, -0.0051, -0.1549]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:56:39 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 21:56:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6914, -0.4299, -0.3013,  ..., -1.3574, -0.0218, -0.7026],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3433, -0.9380, -0.9683,  ..., -0.3079,  0.0011, -0.1234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9644, -0.1248,  0.2153,  ..., -2.9023,  0.6279, -1.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.7637, -0.5176, -0.6357,  ..., -0.4109,  0.1516,  0.5459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:56:39 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:56:39 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 21:57:28 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 21:58:17 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 21:59:01 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0139,  0.0052,  0.0035,  ...,  0.0035, -0.0003,  0.0003],
        [ 0.0004, -0.0029,  0.0085,  ...,  0.0042,  0.0018,  0.0050],
        [ 0.0011, -0.0054, -0.0108,  ..., -0.0014,  0.0004, -0.0047],
        ...,
        [ 0.0021, -0.0034,  0.0058,  ..., -0.0098, -0.0025, -0.0023],
        [ 0.0020, -0.0059, -0.0032,  ...,  0.0025, -0.0049,  0.0028],
        [ 0.0011,  0.0002, -0.0022,  ...,  0.0009, -0.0008, -0.0074]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1304,  0.0234,  0.0108,  ..., -0.0063, -0.0099, -0.0067],
        [ 0.0067, -0.1362, -0.0027,  ..., -0.0006,  0.0028, -0.0103],
        [ 0.0003, -0.0056, -0.1263,  ..., -0.0100, -0.0006,  0.0138],
        ...,
        [ 0.0111, -0.0035, -0.0200,  ..., -0.1182,  0.0075, -0.0305],
        [ 0.0027,  0.0178, -0.0012,  ...,  0.0144, -0.1119,  0.0063],
        [ 0.0134,  0.0009, -0.0045,  ...,  0.0062, -0.0056, -0.1111]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1177,  0.0287,  0.0027,  ..., -0.0108, -0.0141,  0.0094],
        [ 0.0049, -0.0964, -0.0026,  ...,  0.0003, -0.0091, -0.0108],
        [-0.0042,  0.0173, -0.1092,  ...,  0.0023, -0.0068,  0.0055],
        ...,
        [-0.0020, -0.0071, -0.0025,  ..., -0.0895,  0.0086, -0.0012],
        [-0.0089, -0.0093, -0.0087,  ...,  0.0021, -0.1100,  0.0160],
        [ 0.0043,  0.0033,  0.0091,  ...,  0.0108,  0.0028, -0.1065]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 21:59:04 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 21:59:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5688, -0.1937, -0.0139,  ..., -1.4043,  0.2279, -0.9448],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9292, -0.8423, -0.7363,  ..., -0.1233,  0.0718,  0.0131],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3579, -0.2399,  0.6738,  ..., -3.1172,  0.6201, -0.7314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9937, -0.6743, -0.7715,  ..., -0.5894,  0.5635,  0.3904],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 21:59:04 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 21:59:04 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 21:59:53 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 22:00:46 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 22:01:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.2065e-03, -3.7766e-04,  6.6614e-04,  ..., -2.0161e-03,
          5.2261e-04,  1.6966e-03],
        [ 1.4439e-03,  1.0582e-02, -1.8682e-03,  ...,  1.9798e-03,
         -1.9150e-03,  5.1155e-03],
        [-5.2261e-03, -3.9444e-03,  8.6212e-03,  ..., -9.9468e-04,
          3.0670e-03,  8.8882e-04],
        ...,
        [ 3.7432e-05,  5.2376e-03,  6.1073e-03,  ...,  1.0506e-02,
         -4.3144e-03,  5.0392e-03],
        [-4.6692e-03, -5.5199e-03,  2.7347e-04,  ..., -4.1542e-03,
          1.0620e-02,  6.5384e-03],
        [-1.5831e-03, -4.8180e-03,  3.6774e-03,  ..., -1.4858e-03,
          1.3828e-03,  1.6508e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1392,  0.0041, -0.0038,  ..., -0.0064,  0.0071, -0.0053],
        [ 0.0101, -0.1411,  0.0008,  ..., -0.0037, -0.0164,  0.0011],
        [-0.0059,  0.0047, -0.1469,  ..., -0.0092,  0.0015, -0.0178],
        ...,
        [-0.0202,  0.0088,  0.0020,  ..., -0.1724,  0.0032,  0.0011],
        [ 0.0068, -0.0081, -0.0014,  ..., -0.0029, -0.1464, -0.0107],
        [-0.0032,  0.0070, -0.0102,  ..., -0.0178,  0.0117, -0.1522]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2233,  0.0140,  0.0089,  ..., -0.0106, -0.0097, -0.0016],
        [ 0.0093, -0.2471, -0.0110,  ..., -0.0093,  0.0067,  0.0017],
        [-0.0008,  0.0026, -0.2191,  ..., -0.0017,  0.0082, -0.0006],
        ...,
        [-0.0072,  0.0079, -0.0046,  ..., -0.2588,  0.0107, -0.0053],
        [-0.0137, -0.0021, -0.0033,  ...,  0.0044, -0.2412,  0.0017],
        [-0.0047, -0.0057, -0.0086,  ...,  0.0026,  0.0070, -0.2317]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:01:42 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 22:01:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6250, -0.1054,  0.0841,  ..., -1.9385,  0.4077, -1.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3730, -0.4280, -0.5278,  ..., -0.3235,  0.1086,  0.3887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7393, -0.0546,  1.2490,  ..., -3.0195,  0.0972,  0.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8525, -0.4404, -0.7861,  ..., -1.4258,  1.1777,  0.4229],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:01:43 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:01:43 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 22:02:38 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 22:03:32 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 22:04:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.9449e-03, -1.3828e-03,  1.6518e-03,  ...,  8.6069e-04,
         -4.5395e-03, -3.3646e-03],
        [-1.2913e-03, -5.9891e-03,  9.7275e-05,  ..., -5.0888e-03,
         -1.4820e-03, -2.0332e-03],
        [ 2.4414e-03,  2.0981e-03, -6.3324e-03,  ...,  1.8082e-03,
         -7.5245e-04, -4.2868e-04],
        ...,
        [ 2.3994e-03, -3.5954e-03, -7.3242e-04,  ..., -3.1452e-03,
         -3.4189e-04, -1.1473e-03],
        [-9.4557e-04,  4.3182e-03, -3.6888e-03,  ...,  2.6913e-03,
         -7.9880e-03, -7.8011e-04],
        [-5.4407e-04,  4.1890e-04,  1.7195e-03,  ..., -2.1954e-03,
          1.9369e-03, -4.2725e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.0942e-02,  3.2501e-03,  1.5961e-02,  ..., -2.6741e-03,
         -5.7259e-03, -9.0103e-03],
        [ 5.2032e-03, -8.8318e-02, -3.3226e-03,  ..., -1.2321e-02,
         -1.4477e-03, -7.0343e-03],
        [-1.0414e-02, -5.6496e-03, -8.1055e-02,  ..., -5.4588e-03,
          1.0929e-03, -2.0027e-05],
        ...,
        [ 6.9261e-05, -7.0343e-03,  4.0245e-03,  ..., -8.7708e-02,
          1.2680e-02, -7.6599e-03],
        [-1.1253e-03,  8.8806e-03, -1.1124e-02,  ...,  1.2543e-02,
         -9.4910e-02,  1.0330e-02],
        [-7.3957e-04,  2.5444e-03, -9.4604e-03,  ...,  8.6365e-03,
          2.3613e-03, -7.2205e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0752, -0.0031, -0.0100,  ...,  0.0010, -0.0011, -0.0008],
        [ 0.0074, -0.0880, -0.0047,  ..., -0.0004,  0.0088,  0.0162],
        [-0.0091, -0.0068, -0.0921,  ..., -0.0016, -0.0010, -0.0015],
        ...,
        [-0.0068, -0.0082, -0.0016,  ..., -0.0792,  0.0143, -0.0011],
        [-0.0005,  0.0013, -0.0006,  ...,  0.0121, -0.0818,  0.0089],
        [-0.0015,  0.0044, -0.0026,  ...,  0.0025,  0.0091, -0.0891]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:04:30 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 22:04:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2200, -0.1901,  0.3809,  ..., -1.8730,  0.3796, -0.4873],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7681, -0.5537, -0.5693,  ..., -0.4507,  0.4255,  0.2761],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5879,  0.7100,  0.4404,  ..., -3.1152,  0.9595,  0.4802],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9902, -0.2345, -0.5898,  ..., -1.2969,  1.9824,  0.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:04:30 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:04:30 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 22:05:25 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 22:06:22 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 22:07:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1618e-03,  2.1343e-03,  5.1022e-05,  ..., -3.3188e-03,
          1.2207e-03, -4.7646e-03],
        [-3.8509e-03,  3.0441e-03, -2.9087e-03,  ..., -4.8981e-03,
         -1.4410e-03, -2.5940e-03],
        [-6.6376e-03, -1.0157e-04,  7.4387e-04,  ...,  8.0156e-04,
         -1.0204e-03, -5.3902e-03],
        ...,
        [ 3.4122e-03, -6.0654e-04,  1.8024e-03,  ..., -8.8835e-04,
         -2.4681e-03,  6.4087e-03],
        [ 7.1030e-03, -6.6519e-04,  8.2874e-04,  ..., -3.8910e-03,
         -6.1340e-03, -2.8133e-04],
        [-6.5327e-04,  7.5264e-03,  4.7264e-03,  ..., -4.5357e-03,
         -3.4866e-03, -1.0704e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1083,  0.0053, -0.0020,  ..., -0.0050,  0.0085,  0.0161],
        [-0.0039, -0.1111, -0.0066,  ...,  0.0026,  0.0096,  0.0091],
        [-0.0031, -0.0031, -0.1105,  ..., -0.0135,  0.0019,  0.0068],
        ...,
        [ 0.0016, -0.0023, -0.0101,  ..., -0.1242, -0.0080,  0.0054],
        [ 0.0161,  0.0091,  0.0072,  ...,  0.0099, -0.1230, -0.0031],
        [ 0.0009, -0.0042, -0.0017,  ..., -0.0097, -0.0100, -0.1078]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1287,  0.0047, -0.0042,  ..., -0.0126,  0.0207,  0.0043],
        [-0.0134, -0.1420, -0.0024,  ...,  0.0097, -0.0087,  0.0037],
        [ 0.0128,  0.0040, -0.1580,  ..., -0.0016, -0.0152, -0.0211],
        ...,
        [-0.0084,  0.0088, -0.0030,  ..., -0.1484, -0.0062,  0.0066],
        [ 0.0130, -0.0081,  0.0013,  ...,  0.0046, -0.1576,  0.0042],
        [-0.0011,  0.0081,  0.0048,  ..., -0.0026,  0.0112, -0.1427]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:07:23 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 22:07:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3882, -0.0528,  0.6318,  ..., -1.6768,  0.0794,  0.1023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5293, -0.3037, -0.5073,  ..., -0.9199,  0.7935,  0.2208],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7246,  0.6035,  1.0791,  ..., -4.0781,  1.0566,  0.9072],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4805, -0.4849, -1.4746,  ..., -0.9053,  1.5166,  0.2949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:07:23 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:07:23 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 22:08:21 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 22:09:22 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 22:10:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0020, -0.0066,  0.0013,  ..., -0.0005, -0.0106, -0.0068],
        [-0.0051, -0.0002, -0.0058,  ...,  0.0014,  0.0042, -0.0072],
        [-0.0025, -0.0032, -0.0028,  ...,  0.0056, -0.0057,  0.0033],
        ...,
        [ 0.0020,  0.0050, -0.0093,  ..., -0.0039,  0.0031, -0.0005],
        [-0.0032, -0.0019,  0.0020,  ...,  0.0023,  0.0031,  0.0086],
        [-0.0045,  0.0042,  0.0016,  ..., -0.0024, -0.0010, -0.0100]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0876e-01,  6.3858e-03, -1.4717e-02,  ..., -6.4926e-03,
          4.6921e-03,  2.5864e-03],
        [ 1.9436e-03, -1.0785e-01,  1.1158e-03,  ...,  5.6610e-03,
         -4.1962e-05,  8.2092e-03],
        [-2.9602e-03, -1.3863e-02, -1.0547e-01,  ...,  1.5392e-03,
          7.4081e-03, -9.6436e-03],
        ...,
        [-8.3313e-03,  3.2825e-03, -1.3191e-02,  ..., -1.0974e-01,
          1.2802e-02,  3.7575e-03],
        [-1.1810e-02, -1.3914e-03, -3.8624e-04,  ..., -6.6376e-04,
         -9.4360e-02,  2.1229e-03],
        [-2.8229e-04,  9.4070e-03, -6.4926e-03,  ...,  7.8964e-03,
          3.1204e-03, -1.0150e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1115,  0.0106,  0.0012,  ..., -0.0118, -0.0031, -0.0089],
        [ 0.0062, -0.0968,  0.0101,  ..., -0.0005,  0.0074,  0.0048],
        [-0.0141, -0.0060, -0.0980,  ..., -0.0062,  0.0194, -0.0102],
        ...,
        [-0.0021, -0.0140, -0.0005,  ..., -0.1066,  0.0124, -0.0098],
        [-0.0140,  0.0094, -0.0105,  ...,  0.0053, -0.1138,  0.0032],
        [-0.0030,  0.0106, -0.0023,  ..., -0.0146,  0.0049, -0.1050]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:10:24 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 22:10:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8647,  0.3469,  0.2222,  ..., -1.6484,  0.5112,  0.2230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5923, -0.1726, -0.3308,  ..., -0.7598,  1.1611,  0.1320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3477,  1.0566,  1.5781,  ..., -3.9395,  1.0039,  2.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4336, -0.4893, -2.9688,  ..., -0.6665,  1.6738,  0.7412],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:10:24 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:10:24 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 22:11:26 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 22:12:26 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 22:13:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.9455e-02,  1.4181e-03,  3.3798e-03,  ...,  1.6224e-04,
         -5.2986e-03, -7.0429e-04],
        [ 9.6588e-03,  1.7197e-02,  5.8556e-03,  ...,  1.3294e-03,
          3.0327e-03, -7.0648e-03],
        [ 3.1519e-04, -7.7629e-03,  1.5869e-02,  ..., -1.6270e-03,
         -2.2411e-04, -1.5521e-04],
        ...,
        [-5.7907e-03, -3.0670e-03, -2.7256e-03,  ...,  1.3298e-02,
         -8.5373e-03,  3.1948e-03],
        [ 6.1226e-03, -3.2501e-03,  3.7594e-03,  ..., -4.4346e-05,
          1.6022e-02, -2.9449e-03],
        [-3.4142e-03,  1.2484e-03,  7.8964e-03,  ..., -6.8665e-04,
          2.4471e-03,  2.1408e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.8604e-02, -9.0332e-03, -4.0894e-03,  ..., -2.0065e-03,
          9.2316e-04,  2.7871e-04],
        [ 2.9526e-03, -8.2214e-02, -1.1063e-04,  ...,  1.0071e-02,
         -9.7198e-03, -5.7793e-04],
        [ 5.7220e-05, -8.6288e-03, -8.3435e-02,  ..., -1.5907e-03,
         -1.8234e-03, -1.1005e-03],
        ...,
        [ 2.6340e-03,  8.5449e-03, -8.1062e-05,  ..., -7.6538e-02,
         -2.9144e-03,  1.8524e-02],
        [ 1.4038e-03, -1.2917e-02,  4.9400e-03,  ..., -1.6449e-02,
         -8.5815e-02, -8.7166e-04],
        [ 4.0359e-03,  3.9673e-03,  2.0027e-04,  ..., -3.8147e-06,
          3.7212e-03, -7.6416e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1181,  0.0078, -0.0174,  ..., -0.0087, -0.0019,  0.0082],
        [-0.0061, -0.1383, -0.0157,  ..., -0.0137, -0.0095, -0.0062],
        [-0.0186,  0.0069, -0.1220,  ...,  0.0072,  0.0052,  0.0031],
        ...,
        [ 0.0153,  0.0025,  0.0132,  ..., -0.1187, -0.0053, -0.0080],
        [-0.0092, -0.0114, -0.0051,  ...,  0.0085, -0.1138, -0.0069],
        [ 0.0084,  0.0099, -0.0048,  ..., -0.0035,  0.0060, -0.1355]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:13:30 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 22:13:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8984,  0.3286,  0.5278,  ..., -2.1660,  0.5645,  0.4617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3535, -0.2695, -0.7905,  ..., -0.4946,  0.8359,  0.1370],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4927,  1.2949,  1.8135,  ..., -4.4961,  1.8779,  2.1953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4023, -1.1055, -3.3477,  ..., -1.0977,  1.9863,  0.6040],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:13:30 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:13:31 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 22:14:33 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 22:15:38 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 22:16:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0083, -0.0069,  0.0057,  ..., -0.0061,  0.0005, -0.0065],
        [ 0.0021,  0.0007,  0.0035,  ...,  0.0038,  0.0020,  0.0013],
        [-0.0011, -0.0007, -0.0097,  ..., -0.0008,  0.0031, -0.0015],
        ...,
        [ 0.0077, -0.0022, -0.0046,  ..., -0.0030, -0.0019, -0.0056],
        [-0.0028, -0.0012, -0.0046,  ..., -0.0016, -0.0063,  0.0030],
        [-0.0002,  0.0058,  0.0002,  ..., -0.0057, -0.0007, -0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.1045e-02,  1.4565e-02,  8.2779e-04,  ..., -1.6922e-02,
          1.3039e-02, -1.2054e-02],
        [-1.0933e-02, -6.8909e-02, -1.6678e-02,  ...,  5.2643e-04,
          8.7128e-03,  7.5874e-03],
        [-1.7166e-02, -6.0272e-04, -6.2347e-02,  ..., -5.6190e-03,
          2.7905e-03, -1.2573e-02],
        ...,
        [-1.4412e-02, -4.5204e-04, -5.9662e-03,  ..., -6.4087e-02,
         -1.1787e-02,  4.2305e-03],
        [ 6.7520e-03,  6.0043e-03,  2.2049e-03,  ...,  5.9433e-03,
         -6.7932e-02,  8.3084e-03],
        [-7.2479e-03, -2.1095e-03, -7.6294e-06,  ..., -6.2752e-03,
         -7.8430e-03, -6.3904e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0668, -0.0051,  0.0225,  ..., -0.0050, -0.0062,  0.0071],
        [ 0.0030, -0.0698, -0.0171,  ...,  0.0105,  0.0001,  0.0046],
        [ 0.0214,  0.0266, -0.0840,  ..., -0.0215, -0.0043, -0.0122],
        ...,
        [-0.0177,  0.0024, -0.0190,  ..., -0.0873, -0.0143,  0.0055],
        [ 0.0143,  0.0081, -0.0055,  ...,  0.0031, -0.0655, -0.0051],
        [-0.0151,  0.0028,  0.0004,  ...,  0.0007, -0.0008, -0.0773]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:16:45 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 22:16:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6729,  0.5288,  0.7593,  ..., -1.9277,  0.5122,  1.0703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1963, -0.2462, -1.3887,  ..., -0.3198,  0.8271,  0.3240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0562,  1.3135,  1.9902,  ..., -4.5000,  2.6934,  2.4277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.7266, -0.9883, -2.9160,  ..., -1.4561,  2.0566,  0.6113],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:16:45 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:16:45 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 22:17:53 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 22:19:00 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 22:20:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.3876e-03, -6.9618e-03,  5.3024e-03,  ...,  2.1820e-03,
          1.3809e-03, -6.9237e-04],
        [ 5.8830e-05,  7.3471e-03,  3.2234e-03,  ...,  1.8287e-04,
          3.7613e-03, -4.4937e-03],
        [-6.5536e-03, -1.9684e-03, -5.6534e-03,  ...,  3.0518e-04,
         -2.2430e-03, -3.7479e-03],
        ...,
        [-4.4861e-03,  5.2309e-04, -1.6470e-03,  ...,  7.4425e-03,
          4.5433e-03,  2.0943e-03],
        [ 4.6616e-03,  6.0692e-03,  2.3079e-03,  ..., -9.8801e-03,
         -1.4706e-03, -4.4060e-03],
        [ 2.1381e-03,  2.8896e-04, -4.7150e-03,  ..., -2.3003e-03,
          1.7576e-03, -7.9880e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0541,  0.0063,  0.0123,  ...,  0.0003, -0.0008, -0.0043],
        [-0.0065, -0.0856,  0.0036,  ..., -0.0056, -0.0017,  0.0117],
        [ 0.0002, -0.0043, -0.0743,  ..., -0.0151,  0.0041, -0.0050],
        ...,
        [ 0.0185, -0.0134,  0.0055,  ..., -0.0670,  0.0011, -0.0035],
        [ 0.0071,  0.0022,  0.0145,  ..., -0.0049, -0.0566,  0.0116],
        [-0.0083, -0.0009,  0.0015,  ..., -0.0063, -0.0042, -0.0605]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.8430e-02,  2.6360e-03,  8.8959e-03,  ..., -7.0572e-03,
          8.0414e-03, -1.0681e-04],
        [-2.9030e-03, -1.0474e-01,  1.9522e-03,  ..., -2.6207e-03,
         -7.0419e-03, -4.4708e-03],
        [ 1.2794e-02, -1.0681e-02, -1.0431e-01,  ..., -2.0386e-02,
          8.4076e-03, -6.6414e-03],
        ...,
        [ 1.7883e-02, -2.8915e-03,  1.4534e-02,  ..., -8.3191e-02,
          1.2543e-02,  8.0299e-04],
        [ 2.5520e-03, -1.0109e-04,  1.4511e-02,  ...,  1.8520e-03,
         -1.0345e-01,  6.5193e-03],
        [-8.2855e-03,  5.4817e-03, -6.2027e-03,  ..., -9.8648e-03,
          1.2276e-02, -1.0248e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:20:08 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 22:20:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2197,  0.6255,  0.8369,  ..., -2.1582,  0.9229,  1.0361],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1123, -0.5049, -1.5225,  ..., -0.5059,  0.9404,  0.2417],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7939,  1.4404,  2.0703,  ..., -3.7539,  2.7656,  2.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.0098, -1.2051, -3.1738,  ..., -1.7021,  1.4414,  0.9502],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:20:08 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:20:09 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 22:21:15 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 22:22:25 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 22:23:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.5297e-02, -1.1311e-03, -5.0545e-04,  ...,  9.8419e-04,
         -2.3460e-03, -6.7949e-04],
        [ 3.7694e-04,  7.6141e-03,  2.7580e-03,  ..., -1.8396e-03,
          2.9778e-04, -3.2368e-03],
        [ 4.3831e-03, -1.6308e-03,  1.0101e-02,  ...,  6.7139e-03,
          2.8372e-05, -2.6488e-04],
        ...,
        [ 5.5542e-03,  1.3113e-03,  2.7618e-03,  ...,  1.0513e-02,
          1.1272e-03, -5.4398e-03],
        [-1.9121e-04,  9.7322e-04,  5.4626e-03,  ..., -2.8944e-04,
          8.5526e-03,  8.3256e-04],
        [ 2.5272e-05,  9.8896e-04, -1.2034e-04,  ...,  7.5989e-03,
         -5.7602e-04,  9.9106e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0401, -0.0044,  0.0044,  ..., -0.0123, -0.0077, -0.0032],
        [ 0.0066, -0.0581, -0.0023,  ...,  0.0045,  0.0155,  0.0041],
        [ 0.0025, -0.0061, -0.0585,  ...,  0.0003,  0.0013,  0.0021],
        ...,
        [-0.0149,  0.0047, -0.0002,  ..., -0.0544,  0.0051,  0.0324],
        [-0.0215, -0.0077, -0.0153,  ...,  0.0095, -0.0437, -0.0043],
        [-0.0066,  0.0078, -0.0070,  ..., -0.0027,  0.0084, -0.0578]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0941,  0.0112, -0.0011,  ...,  0.0013, -0.0024, -0.0118],
        [-0.0154, -0.1046,  0.0060,  ..., -0.0166,  0.0174,  0.0154],
        [ 0.0039, -0.0074, -0.1057,  ..., -0.0108,  0.0163, -0.0034],
        ...,
        [-0.0015,  0.0089,  0.0079,  ..., -0.1000, -0.0021,  0.0157],
        [-0.0050, -0.0099, -0.0087,  ..., -0.0207, -0.0905,  0.0017],
        [-0.0076,  0.0027, -0.0162,  ..., -0.0125,  0.0057, -0.1077]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:23:37 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 22:23:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0344,  0.5947,  0.8604,  ..., -2.0488,  1.2588,  1.0889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2637, -0.4548, -1.3018,  ..., -0.6567,  0.9575,  0.2382],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2559,  1.6416,  2.1113,  ..., -3.4883,  2.8750,  2.5781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.2578, -1.4355, -3.6055,  ..., -1.3818,  0.9727,  0.2417],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:23:37 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:23:37 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 22:24:48 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 22:25:59 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 22:27:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0010, -0.0007, -0.0007,  ..., -0.0028, -0.0036, -0.0068],
        [ 0.0055,  0.0037, -0.0039,  ...,  0.0063, -0.0025,  0.0006],
        [-0.0039,  0.0038,  0.0038,  ..., -0.0020, -0.0015,  0.0012],
        ...,
        [-0.0030, -0.0021, -0.0046,  ...,  0.0017, -0.0019, -0.0008],
        [ 0.0011, -0.0027, -0.0002,  ...,  0.0031,  0.0007,  0.0017],
        [-0.0032,  0.0057,  0.0041,  ..., -0.0074, -0.0018,  0.0034]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0288, -0.0032,  0.0078,  ..., -0.0036, -0.0012, -0.0160],
        [ 0.0101, -0.0321, -0.0044,  ..., -0.0150,  0.0076, -0.0081],
        [ 0.0057,  0.0078, -0.0344,  ...,  0.0005, -0.0037, -0.0031],
        ...,
        [-0.0224, -0.0043, -0.0160,  ..., -0.0219,  0.0189,  0.0089],
        [ 0.0128,  0.0153, -0.0113,  ...,  0.0031, -0.0276,  0.0163],
        [-0.0136, -0.0183, -0.0012,  ..., -0.0013,  0.0188, -0.0397]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.0253e-02, -9.2926e-03,  1.0941e-02,  ..., -2.0538e-02,
         -1.4515e-03,  6.1836e-03],
        [ 1.0635e-02, -3.2776e-02,  2.7199e-03,  ..., -2.0889e-02,
          1.9699e-02, -1.5572e-02],
        [ 8.1940e-03, -3.0842e-03, -5.8105e-02,  ..., -8.2703e-03,
          1.3138e-02, -9.6512e-04],
        ...,
        [-3.8090e-03, -7.7724e-05, -1.0117e-02,  ..., -6.0425e-02,
          3.0785e-03,  9.5367e-06],
        [ 8.0414e-03,  8.5735e-04, -4.7607e-03,  ...,  3.8300e-03,
         -5.3375e-02,  3.1647e-02],
        [-1.4206e-02, -5.0087e-03,  2.9564e-03,  ..., -2.8782e-03,
          1.7838e-02, -5.9326e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:27:12 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 22:27:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3457,  0.6006,  0.8198,  ..., -1.5703,  1.1465,  1.1953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2412, -0.5005, -1.2471,  ..., -0.6763,  0.5698,  0.3579],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5908,  2.3516,  1.9668,  ..., -3.2070,  3.1992,  2.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.0625, -1.1982, -4.0156,  ..., -0.7593,  2.0117,  1.2402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:27:12 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:27:12 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 22:28:25 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 22:29:38 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 22:30:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8860e-02, -2.6684e-03, -9.8038e-04,  ...,  1.0872e-03,
         -2.6932e-03,  2.2163e-03],
        [-3.8052e-03,  1.9180e-02,  1.6088e-03,  ..., -1.5140e-04,
         -2.6131e-04,  2.4319e-03],
        [ 4.0197e-04,  4.1127e-04,  1.9318e-02,  ..., -3.2496e-04,
         -2.1191e-03, -2.4629e-04],
        ...,
        [ 5.5733e-03,  1.4496e-04, -3.7918e-03,  ...,  1.5778e-02,
         -2.2316e-03,  1.3933e-03],
        [-8.3876e-04, -3.5744e-03, -1.1473e-03,  ..., -1.6756e-03,
          1.6754e-02,  8.1360e-05],
        [ 3.4142e-03,  1.9913e-03,  3.2349e-03,  ...,  4.3640e-03,
          7.8430e-03,  1.5732e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0196,  0.0145,  0.0040,  ...,  0.0124, -0.0228,  0.0020],
        [ 0.0165, -0.0212,  0.0042,  ..., -0.0129, -0.0112,  0.0052],
        [-0.0058, -0.0028, -0.0569,  ..., -0.0009, -0.0017, -0.0053],
        ...,
        [ 0.0015, -0.0146, -0.0058,  ..., -0.0319, -0.0184, -0.0066],
        [ 0.0044, -0.0108, -0.0009,  ..., -0.0019, -0.0294, -0.0065],
        [ 0.0077,  0.0073, -0.0069,  ...,  0.0051, -0.0010, -0.0423]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.5940e-02,  1.6003e-03,  1.2337e-02,  ..., -1.2489e-02,
         -1.0880e-02,  1.0624e-03],
        [-2.9564e-05, -3.5736e-02,  4.2915e-03,  ...,  4.3449e-03,
         -1.8177e-03,  1.1391e-02],
        [-1.9646e-03, -3.2234e-03, -3.1128e-02,  ..., -6.9466e-03,
          1.0712e-02,  1.8539e-03],
        ...,
        [ 8.0566e-03, -5.1842e-03, -1.7776e-02,  ..., -3.3417e-02,
          2.2793e-03,  1.9321e-03],
        [-1.0815e-03, -1.3905e-03,  1.1635e-02,  ..., -2.3712e-02,
         -5.6274e-02, -1.1467e-02],
        [-8.2245e-03,  9.3155e-03, -6.7329e-03,  ...,  6.9847e-03,
          9.3994e-03, -3.6804e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:30:51 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 22:30:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1005,  0.6514,  0.8286,  ..., -1.4111,  1.1572,  1.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2529, -0.5601, -1.3711,  ..., -0.5366,  0.3787,  0.0679],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1836,  3.2461,  1.7959,  ..., -3.1992,  3.4785,  1.9297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.9922, -0.6289, -4.8398,  ..., -0.5762,  2.1211,  1.9570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:30:51 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:30:51 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 22:32:11 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 22:33:32 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 22:34:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8402e-02, -3.7346e-03, -1.0099e-03,  ..., -2.8915e-03,
         -2.3117e-03, -5.4626e-03],
        [ 7.2718e-04,  1.7166e-02,  6.4754e-04,  ...,  3.9444e-03,
          2.6970e-03,  1.3828e-04],
        [ 4.5586e-03, -1.3962e-03,  2.3270e-02,  ..., -1.5163e-03,
          3.2711e-03, -5.8022e-03],
        ...,
        [-6.1569e-03,  5.5008e-03, -3.9597e-03,  ...,  1.8433e-02,
         -3.6259e-03,  2.8229e-03],
        [-1.8892e-03, -3.4761e-04, -1.4009e-03,  ...,  2.8992e-03,
          1.6983e-02, -2.6047e-05],
        [-1.1665e-02, -4.9896e-03,  4.7722e-03,  ..., -1.0391e-02,
          6.0577e-03,  2.0386e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.7715e-02,  9.8801e-03, -1.4229e-02,  ..., -1.0292e-02,
          5.2071e-03, -4.9553e-03],
        [ 7.1182e-03, -3.6621e-02, -1.6464e-02,  ..., -1.0651e-02,
          1.6241e-03,  1.5488e-02],
        [ 6.2332e-03, -2.5063e-03, -2.8381e-02,  ..., -2.1744e-03,
          5.9090e-03, -3.8757e-03],
        ...,
        [-1.3023e-02,  1.8326e-02, -1.3641e-02,  ..., -2.5909e-02,
          1.8930e-03,  2.7466e-03],
        [ 8.3008e-03,  5.8708e-03,  8.4877e-05,  ...,  1.0948e-02,
         -2.1347e-02,  7.3242e-04],
        [-1.9791e-02,  1.3977e-02,  1.3252e-02,  ..., -2.6264e-03,
         -9.8419e-03, -2.0081e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0503,  0.0059, -0.0038,  ..., -0.0069, -0.0152, -0.0042],
        [ 0.0166, -0.0825, -0.0050,  ..., -0.0130, -0.0079, -0.0034],
        [ 0.0137,  0.0060, -0.0323,  ..., -0.0175,  0.0012, -0.0102],
        ...,
        [ 0.0151,  0.0158, -0.0195,  ..., -0.0468,  0.0065, -0.0006],
        [-0.0052, -0.0023, -0.0174,  ..., -0.0107, -0.0320, -0.0032],
        [-0.0113,  0.0169,  0.0020,  ...,  0.0017, -0.0151, -0.0388]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:34:56 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 22:34:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2375,  0.9106,  0.7524,  ..., -1.2480,  1.2910,  0.9600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.5420, -0.4370, -1.4717,  ..., -0.2703,  0.7646,  0.4429],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3281,  3.2793,  3.5898,  ..., -2.6367,  3.5078,  1.9736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.2656, -1.0703, -3.8789,  ..., -0.2048,  1.8984,  2.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:34:56 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:34:56 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 22:36:18 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 22:37:40 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 22:39:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7223e-03,  3.4618e-04,  6.3515e-04,  ..., -1.4734e-04,
         -6.4754e-04,  3.8147e-04],
        [ 7.7152e-04, -5.1641e-04,  3.5787e-04,  ...,  6.9714e-04,
         -7.0000e-04,  1.3423e-04],
        [ 1.4725e-03,  6.8474e-04, -2.4834e-03,  ...,  5.6505e-04,
         -1.6336e-03, -5.0640e-04],
        ...,
        [ 2.8014e-06,  8.9645e-04, -1.8144e-04,  ..., -8.5115e-04,
         -4.0650e-04,  2.1136e-04],
        [-1.0319e-03, -1.6820e-04,  1.0099e-03,  ..., -7.4577e-04,
          3.2616e-04, -1.7345e-05],
        [ 1.3885e-03, -4.3106e-04,  6.4182e-04,  ...,  7.3957e-04,
         -1.4997e-04, -1.3571e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0306, -0.0177,  0.0097,  ..., -0.0126, -0.0087,  0.0103],
        [-0.0150, -0.0396, -0.0092,  ..., -0.0018,  0.0119,  0.0134],
        [ 0.0065, -0.0047, -0.0199,  ...,  0.0117, -0.0104,  0.0212],
        ...,
        [-0.0104, -0.0002, -0.0083,  ..., -0.0543, -0.0011, -0.0066],
        [-0.0055,  0.0037, -0.0133,  ..., -0.0227, -0.0044, -0.0099],
        [ 0.0050, -0.0158,  0.0004,  ...,  0.0036,  0.0045, -0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0427, -0.0047,  0.0096,  ..., -0.0163,  0.0118,  0.0027],
        [ 0.0008, -0.0454,  0.0108,  ..., -0.0038,  0.0168,  0.0061],
        [-0.0157, -0.0023, -0.0578,  ..., -0.0082, -0.0112,  0.0062],
        ...,
        [ 0.0103,  0.0149, -0.0117,  ..., -0.0627, -0.0215,  0.0158],
        [ 0.0018,  0.0242, -0.0268,  ..., -0.0167, -0.0518, -0.0057],
        [ 0.0014, -0.0082,  0.0103,  ..., -0.0219,  0.0124, -0.0646]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:39:05 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 22:39:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4709,  1.2148,  0.6450,  ..., -1.1982,  1.3545,  0.7183],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.4658, -0.2183, -1.7090,  ..., -0.1956,  0.7803,  0.6802],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3613,  4.2500,  3.5977,  ..., -2.4023,  4.0352,  2.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 5.0391,  0.0088, -3.5566,  ...,  0.1272,  1.9268,  1.9512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:39:06 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:39:06 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 22:40:31 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 22:41:53 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 22:43:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2331e-03,  3.6755e-03,  1.5831e-03,  ...,  1.1358e-03,
         -2.0695e-03, -1.7738e-03],
        [-8.0681e-04,  3.2101e-03,  3.4618e-03,  ...,  4.0169e-03,
         -5.5361e-04,  2.2087e-03],
        [ 1.0538e-04,  2.0943e-03,  4.5204e-03,  ...,  6.4182e-04,
          1.7548e-03,  2.0237e-03],
        ...,
        [-2.6741e-03,  3.3617e-04,  5.5008e-03,  ...,  1.6174e-03,
          5.1260e-05, -4.7646e-03],
        [-1.1368e-03,  2.4033e-03, -1.7490e-03,  ...,  8.8692e-04,
         -2.5921e-03,  1.4267e-03],
        [-1.4410e-03, -2.2182e-03,  2.0695e-03,  ..., -1.7614e-03,
          1.2484e-03,  6.3229e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0264,  0.0020,  0.0102,  ..., -0.0197, -0.0187, -0.0160],
        [ 0.0133, -0.0322,  0.0061,  ...,  0.0168,  0.0091, -0.0056],
        [ 0.0127,  0.0168, -0.0250,  ...,  0.0001,  0.0091,  0.0192],
        ...,
        [ 0.0062,  0.0007,  0.0075,  ..., -0.0228, -0.0120, -0.0115],
        [ 0.0086, -0.0101, -0.0177,  ...,  0.0226, -0.0281, -0.0101],
        [ 0.0234, -0.0098,  0.0117,  ..., -0.0105,  0.0044, -0.0311]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0508, -0.0001, -0.0026,  ...,  0.0033, -0.0046, -0.0022],
        [-0.0034, -0.0538,  0.0145,  ...,  0.0154, -0.0034,  0.0038],
        [-0.0096, -0.0020, -0.0374,  ...,  0.0057, -0.0154, -0.0015],
        ...,
        [ 0.0181,  0.0132, -0.0071,  ..., -0.0464, -0.0059, -0.0067],
        [ 0.0136,  0.0120, -0.0008,  ...,  0.0103, -0.0675, -0.0078],
        [ 0.0288,  0.0059,  0.0151,  ..., -0.0219,  0.0198, -0.0418]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:43:18 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 22:43:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4885,  1.1631,  1.2334,  ..., -0.9409,  1.2842,  0.6938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.4727, -0.3230, -1.3506,  ..., -0.0759,  0.6611,  0.7793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9722,  4.4375,  3.9414,  ..., -2.1328,  4.1641,  2.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.4023,  0.0196, -4.6406,  ...,  1.3857,  2.0566,  2.3652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:43:18 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:43:18 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 22:44:36 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 22:45:54 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 22:47:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.9913e-02,  4.0483e-04, -1.4610e-03,  ...,  3.7365e-03,
          2.4223e-03,  5.3444e-03],
        [ 7.8058e-04,  7.8049e-03,  1.7023e-03,  ..., -1.4601e-03,
         -1.5650e-03, -3.0537e-03],
        [-8.7166e-04, -1.0843e-03,  2.1652e-02,  ..., -1.5278e-03,
          3.5172e-03, -1.2264e-03],
        ...,
        [ 1.8291e-03,  3.8624e-03, -1.9550e-05,  ...,  2.3849e-02,
         -1.9622e-04, -5.7364e-04],
        [-3.4261e-04,  1.9398e-03,  1.2693e-03,  ...,  8.2350e-04,
          2.5055e-02, -2.7084e-03],
        [ 4.2000e-03, -4.9782e-03, -4.7035e-03,  ...,  3.7994e-03,
         -2.3746e-04,  2.4750e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 1.7929e-02, -1.8066e-02, -7.8278e-03,  ...,  3.4637e-03,
         -7.9193e-03,  1.4143e-03],
        [ 7.8812e-03, -1.9180e-02,  6.7215e-03,  ...,  6.2370e-04,
         -5.8861e-03,  9.4318e-04],
        [-4.0169e-03,  6.5880e-03, -3.7766e-04,  ...,  3.9711e-03,
          1.4488e-02,  1.3256e-04],
        ...,
        [-1.2878e-02, -1.7700e-03, -2.2598e-02,  ...,  2.2873e-02,
         -4.7684e-03,  1.2360e-02],
        [ 2.5368e-04,  1.1368e-03,  1.4946e-02,  ..., -1.9913e-03,
          2.7115e-02, -8.1100e-03],
        [ 5.1994e-03,  1.7593e-02, -2.3544e-02,  ...,  8.9111e-03,
         -8.0109e-05,  2.3529e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0144, -0.0140,  0.0135,  ...,  0.0075,  0.0118,  0.0210],
        [-0.0066, -0.0378,  0.0118,  ..., -0.0216, -0.0131,  0.0139],
        [ 0.0022,  0.0027, -0.0245,  ..., -0.0183,  0.0078,  0.0045],
        ...,
        [-0.0111, -0.0196, -0.0113,  ...,  0.0160,  0.0006,  0.0034],
        [ 0.0059, -0.0053,  0.0135,  ...,  0.0024, -0.0124,  0.0145],
        [-0.0264,  0.0331, -0.0017,  ...,  0.0113, -0.0035, -0.0082]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:47:11 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-06-30 22:47:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4878,  1.4023,  1.1650,  ..., -0.8438,  1.3594,  0.7935],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.6621,  0.0267, -1.2061,  ...,  0.0042,  0.6177,  0.6045],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8257,  4.2422,  3.6582,  ..., -2.2227,  3.6152,  2.8438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 5.1367,  0.0800, -5.1484,  ...,  1.1523,  2.0566,  4.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:47:12 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:47:12 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 22:48:30 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 22:49:49 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-06-30 22:51:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.1809e-03, -5.8031e-04,  1.9312e-05,  ..., -3.5954e-04,
          1.1215e-03,  6.1750e-04],
        [-4.9114e-04,  2.1095e-03,  4.4823e-04,  ..., -1.6336e-03,
          1.6713e-04,  1.2314e-04],
        [ 1.2922e-04, -3.0637e-04,  3.0193e-03,  ..., -1.4198e-04,
         -9.2316e-04,  5.2023e-04],
        ...,
        [-1.1134e-04, -1.0958e-03, -5.5456e-04,  ...,  4.7569e-03,
         -3.3212e-04, -3.6383e-04],
        [ 3.0470e-04,  4.4370e-04, -7.0953e-04,  ...,  3.6907e-04,
          3.8643e-03,  2.0432e-04],
        [ 3.4094e-04, -2.2709e-04,  1.2255e-03,  ..., -1.6534e-04,
         -3.1173e-05,  4.3297e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0173, -0.0015, -0.0040,  ..., -0.0071, -0.0016,  0.0107],
        [ 0.0041, -0.0106,  0.0019,  ...,  0.0189, -0.0090,  0.0087],
        [ 0.0064,  0.0220, -0.0253,  ..., -0.0079,  0.0015, -0.0051],
        ...,
        [-0.0060,  0.0098, -0.0058,  ..., -0.0308, -0.0036, -0.0138],
        [-0.0045,  0.0255,  0.0004,  ..., -0.0059, -0.0102,  0.0018],
        [ 0.0029, -0.0014, -0.0006,  ..., -0.0025, -0.0061, -0.0008]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0466, -0.0097,  0.0066,  ...,  0.0030,  0.0067,  0.0066],
        [-0.0109, -0.0314,  0.0041,  ...,  0.0018, -0.0048, -0.0078],
        [ 0.0041,  0.0120, -0.0320,  ..., -0.0028, -0.0178, -0.0083],
        ...,
        [-0.0052,  0.0081, -0.0097,  ..., -0.0624, -0.0016, -0.0166],
        [ 0.0222,  0.0017,  0.0009,  ...,  0.0123, -0.0334, -0.0041],
        [ 0.0019,  0.0184, -0.0059,  ...,  0.0095, -0.0193, -0.0235]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:51:13 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-06-30 22:51:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3613,  1.3799,  1.1377,  ..., -0.7627,  1.2725,  0.6465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.4287,  0.0341, -1.4932,  ...,  0.3220,  0.5991,  0.6807],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.8848,  4.3672,  2.5469,  ..., -2.3926,  2.9746,  2.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 6.2422,  1.0098, -5.5352,  ...,  1.3330,  2.1094,  3.4980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:51:13 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:51:13 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 22:52:35 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 22:53:59 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-06-30 22:55:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.8201e-03, -6.6090e-04, -1.6761e-04,  ..., -6.9284e-04,
          5.4789e-04, -9.6130e-04],
        [ 6.9046e-04,  4.5509e-03,  1.1158e-04,  ...,  3.0565e-04,
         -1.6856e-04,  1.0033e-03],
        [ 8.6498e-04, -8.2302e-04,  6.8970e-03,  ..., -5.5695e-04,
         -1.8921e-03,  2.9564e-04],
        ...,
        [-7.3910e-04,  3.9196e-04, -4.2725e-04,  ...,  7.8812e-03,
          2.6822e-05, -1.5602e-03],
        [-1.4794e-04, -1.4901e-04,  5.2214e-04,  ..., -3.3188e-04,
          8.8348e-03, -2.3723e-04],
        [ 2.8396e-04,  9.2936e-04,  7.5698e-05,  ..., -2.4557e-04,
          1.1861e-04,  1.0727e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0031,  0.0156, -0.0009,  ..., -0.0088, -0.0056, -0.0207],
        [ 0.0060, -0.0355, -0.0075,  ..., -0.0139,  0.0196, -0.0145],
        [-0.0231, -0.0092, -0.0045,  ...,  0.0064, -0.0013, -0.0019],
        ...,
        [ 0.0035, -0.0075, -0.0019,  ..., -0.0013, -0.0308,  0.0085],
        [ 0.0004, -0.0127, -0.0153,  ..., -0.0143, -0.0175,  0.0091],
        [-0.0162,  0.0292,  0.0075,  ...,  0.0006,  0.0189, -0.0182]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3447e-03,  1.4133e-03,  2.9869e-03,  ..., -2.7267e-02,
          4.1389e-03, -6.5041e-03],
        [-5.1460e-03, -3.8055e-02, -1.3023e-02,  ..., -7.8659e-03,
          3.4256e-03,  1.9440e-02],
        [-2.1301e-02,  1.1200e-02,  1.1414e-02,  ..., -2.6588e-03,
         -3.6716e-03, -6.3286e-03],
        ...,
        [-1.7746e-02,  1.3908e-02, -1.9028e-02,  ..., -6.5269e-03,
          1.8635e-03,  1.3222e-02],
        [ 9.2850e-03, -1.2993e-02, -1.7502e-02,  ..., -1.5404e-02,
         -1.6312e-02,  1.5350e-02],
        [-4.5776e-03,  3.3234e-02,  7.6294e-06,  ..., -3.0003e-03,
          1.7685e-02, -1.8784e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:55:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To aspire results in aspiration
To randomize results in randomization
To optimize results in optimization
To characterize results in characterization
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To minimize results in
2024-06-30 22:55:25 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-06-30 22:55:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5190, -0.4009, -0.5474,  ..., -0.3816, -0.3608, -0.0816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1077,  0.2935, -0.3557,  ..., -0.3955, -0.2156, -0.0767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3242, -0.4902, -0.7466,  ...,  0.3784, -0.8633,  0.1439],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0549,  0.3894, -0.0433,  ...,  0.3103, -0.3042,  0.1044],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:55:25 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 22:55:25 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 22:55:48 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 22:56:11 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-06-30 22:56:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0757e-02,  1.6661e-03, -1.5593e-03,  ..., -9.3746e-04,
         -7.7486e-04,  6.5994e-04],
        [-1.8406e-04, -7.6447e-03, -5.1498e-04,  ...,  7.7248e-05,
         -2.7695e-03,  2.1172e-03],
        [-2.4128e-03,  6.6757e-04, -9.7198e-03,  ...,  8.2970e-05,
         -1.2035e-03,  2.3365e-04],
        ...,
        [ 1.6136e-03,  9.5367e-04,  6.6185e-04,  ..., -1.0048e-02,
          5.3835e-04,  1.2646e-03],
        [-1.6222e-03, -4.1699e-04,  1.1177e-03,  ..., -1.0815e-03,
         -8.5602e-03, -1.6212e-04],
        [-2.1529e-04, -1.8167e-03,  3.8266e-05,  ..., -4.5776e-05,
          9.2888e-04, -7.5951e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0260, -0.0042, -0.0041,  ..., -0.0008, -0.0005,  0.0057],
        [-0.0100, -0.0436, -0.0074,  ...,  0.0148, -0.0018,  0.0062],
        [ 0.0050,  0.0007, -0.0248,  ...,  0.0054,  0.0010,  0.0003],
        ...,
        [-0.0044,  0.0047,  0.0029,  ..., -0.0278, -0.0170, -0.0039],
        [ 0.0013,  0.0057, -0.0035,  ...,  0.0029, -0.0239, -0.0018],
        [-0.0003, -0.0063, -0.0021,  ...,  0.0029, -0.0002, -0.0312]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0353,  0.0040, -0.0084,  ..., -0.0043, -0.0029,  0.0017],
        [ 0.0026, -0.0411,  0.0011,  ...,  0.0079,  0.0027, -0.0024],
        [-0.0032, -0.0003, -0.0441,  ...,  0.0026,  0.0054,  0.0022],
        ...,
        [-0.0035,  0.0057,  0.0005,  ..., -0.0383, -0.0007, -0.0001],
        [-0.0029,  0.0014, -0.0001,  ..., -0.0023, -0.0376,  0.0050],
        [-0.0016, -0.0022, -0.0013,  ...,  0.0014,  0.0053, -0.0352]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:56:36 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-06-30 22:56:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3477, -0.1761, -0.9116,  ..., -0.3350, -0.1830, -0.1061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1697,  0.2405,  0.0010,  ..., -0.1776, -0.1235, -0.1464],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2939, -0.4600, -0.9082,  ..., -0.4565, -1.0928, -0.0981],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1202,  0.4341,  0.0886,  ..., -0.3411, -0.3926,  0.4331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:56:36 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 22:56:36 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 22:57:00 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 22:57:23 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-06-30 22:57:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7853e-02,  4.3893e-04, -6.6805e-04,  ..., -5.2929e-05,
         -1.1406e-03,  1.2589e-03],
        [ 1.2302e-03, -2.3407e-02,  6.3992e-04,  ...,  2.7580e-03,
         -9.5797e-04,  4.6301e-04],
        [-9.9373e-04,  2.2869e-03, -1.9516e-02,  ...,  9.9373e-04,
         -3.2043e-04,  1.2369e-03],
        ...,
        [ 7.8678e-04,  3.9482e-03,  6.0511e-04,  ..., -1.8356e-02,
         -2.4052e-03,  1.8620e-04],
        [-1.0357e-03,  2.0866e-03,  4.2498e-05,  ...,  5.7554e-04,
         -1.5305e-02, -4.0817e-03],
        [-1.0023e-03, -2.6798e-03, -2.9106e-03,  ...,  1.4458e-03,
          8.6069e-04, -1.9867e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.0781e-02, -4.7922e-04, -1.9455e-04,  ...,  7.7896e-03,
          2.7657e-05,  2.3651e-03],
        [-3.8319e-03, -4.6631e-02, -3.2272e-03,  ...,  2.3823e-03,
          4.7112e-03, -4.7226e-03],
        [-1.2955e-02,  3.0098e-03, -5.0476e-02,  ..., -1.4153e-03,
         -4.6577e-03, -1.0086e-02],
        ...,
        [ 1.2756e-02,  1.3802e-02,  8.9340e-03,  ..., -5.0781e-02,
          2.7828e-03,  1.9379e-02],
        [-1.7653e-03, -1.4252e-02,  7.1335e-03,  ..., -1.2917e-02,
         -4.9438e-02,  4.5662e-03],
        [-1.1871e-02, -4.5624e-03,  2.2030e-03,  ...,  9.0942e-03,
          9.8801e-03, -4.7943e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0762,  0.0036, -0.0037,  ...,  0.0030, -0.0003,  0.0029],
        [ 0.0051, -0.0729, -0.0064,  ...,  0.0014,  0.0016, -0.0072],
        [ 0.0005, -0.0024, -0.0718,  ..., -0.0017,  0.0021, -0.0018],
        ...,
        [ 0.0078, -0.0028,  0.0046,  ..., -0.0752, -0.0038,  0.0027],
        [-0.0056, -0.0028,  0.0112,  ...,  0.0036, -0.0669,  0.0006],
        [ 0.0029,  0.0022,  0.0069,  ...,  0.0003,  0.0020, -0.0757]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:57:49 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-06-30 22:57:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4106, -0.6230, -0.8921,  ...,  0.4348, -1.0176,  0.1545],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1115,  0.6436, -0.0750,  ...,  0.4951, -0.4990,  0.1561],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5430, -0.4177, -0.8091,  ..., -0.3909, -1.0264,  0.1389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2734,  0.2720, -0.2058,  ..., -0.3828, -0.9351,  0.6553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:57:49 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 22:57:49 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 22:58:14 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 22:58:41 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-06-30 22:59:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0067, -0.0009, -0.0004,  ...,  0.0003, -0.0017, -0.0024],
        [ 0.0004, -0.0059, -0.0009,  ...,  0.0001, -0.0003,  0.0003],
        [ 0.0015, -0.0008, -0.0051,  ..., -0.0001,  0.0009, -0.0005],
        ...,
        [ 0.0004,  0.0010, -0.0010,  ..., -0.0068,  0.0019,  0.0019],
        [-0.0006,  0.0004,  0.0004,  ...,  0.0001, -0.0041, -0.0002],
        [ 0.0003,  0.0010,  0.0014,  ..., -0.0003, -0.0004, -0.0039]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0336, -0.0076, -0.0028,  ...,  0.0014,  0.0044, -0.0026],
        [-0.0020, -0.0397,  0.0019,  ..., -0.0049, -0.0063, -0.0027],
        [-0.0077, -0.0082, -0.0419,  ...,  0.0036,  0.0026,  0.0081],
        ...,
        [-0.0023,  0.0103,  0.0079,  ..., -0.0444,  0.0003,  0.0041],
        [-0.0031,  0.0082, -0.0058,  ...,  0.0059, -0.0471, -0.0050],
        [-0.0072,  0.0053,  0.0032,  ..., -0.0034,  0.0190, -0.0417]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.0670e-02,  4.3678e-03, -3.5667e-03,  ...,  1.4706e-03,
         -2.4939e-04, -4.0016e-03],
        [-5.0392e-03, -3.4973e-02,  8.3466e-03,  ..., -3.0060e-03,
         -5.0468e-03, -2.1553e-04],
        [ 2.7409e-03,  2.8744e-03, -2.8656e-02,  ...,  3.0594e-03,
         -6.1512e-04, -4.6253e-04],
        ...,
        [-6.7940e-03,  4.1103e-04, -5.2643e-04,  ..., -3.8727e-02,
         -3.9291e-03, -2.6112e-03],
        [ 3.0479e-03,  2.0351e-03, -1.4753e-03,  ...,  5.3139e-03,
         -3.2776e-02,  1.7128e-03],
        [-1.0061e-03, -5.0163e-03,  3.1948e-05,  ..., -4.0665e-03,
          9.7809e-03, -3.1342e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 22:59:08 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-06-30 22:59:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3799, -0.5845, -1.0605,  ..., -0.5186, -1.2969, -0.1571],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1782,  0.7051,  0.1460,  ..., -0.5322, -0.6489,  0.6982],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5107, -0.2761, -0.2290,  ..., -0.6650, -0.6899,  0.2925],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4492,  0.3706, -0.0131,  ..., -0.5693, -0.5000,  0.5605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 22:59:08 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 22:59:08 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 22:59:39 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 23:00:09 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-06-30 23:00:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.9864e-03,  4.0221e-04,  2.3770e-04,  ..., -6.7949e-05,
          3.3545e-04, -1.0538e-03],
        [ 8.6164e-04, -2.2793e-03, -2.2202e-03,  ...,  1.4973e-04,
         -1.4172e-03, -1.6785e-03],
        [-9.4318e-04, -4.6229e-04, -2.5463e-03,  ...,  2.2888e-05,
          2.7442e-04, -6.1750e-04],
        ...,
        [-2.7323e-04, -1.9894e-03,  2.1362e-04,  ..., -3.5248e-03,
          1.6212e-03,  2.9564e-04],
        [-2.6207e-03, -9.3031e-04,  1.6794e-03,  ..., -2.0103e-03,
         -2.6741e-03, -9.7275e-04],
        [-1.5795e-04, -1.9531e-03,  2.8062e-04,  ..., -1.4400e-03,
         -1.6909e-03, -3.0193e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.1971e-02,  5.5695e-03,  2.8400e-03,  ...,  4.4556e-03,
          3.5324e-03, -1.3857e-03],
        [-4.9095e-03, -3.3630e-02, -6.1760e-03,  ...,  1.0443e-03,
         -3.1710e-05, -6.3782e-03],
        [ 4.1485e-04, -6.4468e-03, -4.2480e-02,  ...,  5.8098e-03,
          8.7509e-03,  7.4959e-03],
        ...,
        [ 8.2207e-04,  7.1669e-04,  3.2501e-03,  ..., -4.9988e-02,
         -8.8692e-04, -4.9133e-03],
        [-4.0741e-03, -1.9836e-03, -2.3746e-04,  ..., -7.9536e-04,
         -4.1168e-02, -6.2523e-03],
        [-5.5027e-04, -3.0212e-03, -8.4925e-04,  ...,  7.8430e-03,
         -3.8490e-03, -5.1666e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0435, -0.0059, -0.0020,  ..., -0.0086,  0.0030,  0.0014],
        [ 0.0121, -0.0467, -0.0047,  ...,  0.0053,  0.0091, -0.0061],
        [-0.0033, -0.0135, -0.0473,  ...,  0.0015,  0.0015, -0.0032],
        ...,
        [-0.0061,  0.0021,  0.0078,  ..., -0.0515, -0.0020, -0.0074],
        [-0.0014,  0.0008, -0.0031,  ..., -0.0015, -0.0436,  0.0076],
        [-0.0064, -0.0019, -0.0094,  ...,  0.0044, -0.0012, -0.0541]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:00:43 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-06-30 23:00:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5615, -0.4893, -0.7876,  ..., -0.3826, -1.0195,  0.1069],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3552,  0.3118, -0.2450,  ..., -0.4629, -1.1582,  0.8193],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1372, -0.5928, -0.1375,  ..., -0.9155,  0.2563,  0.5688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2715, -0.2617,  0.2230,  ..., -0.4478, -0.4575, -0.0908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:00:43 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:00:43 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 23:01:16 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 23:01:48 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-06-30 23:02:20 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.9293e-03,  4.6730e-04, -7.8201e-04,  ...,  5.4073e-04,
         -1.4579e-04, -1.0796e-03],
        [ 2.6073e-03,  3.1319e-03,  7.3338e-04,  ..., -3.2997e-04,
          5.8556e-04,  2.4109e-03],
        [ 1.1978e-03, -7.1001e-04,  7.4196e-04,  ...,  3.4904e-04,
         -7.6437e-04, -2.3842e-06],
        ...,
        [-9.7752e-04,  1.8692e-03, -2.1133e-03,  ...,  3.7785e-03,
          6.6137e-04,  8.5926e-04],
        [-5.9795e-04, -6.2895e-04, -6.1560e-04,  ...,  1.0147e-03,
          6.4125e-03, -3.7766e-04],
        [ 5.6934e-04,  1.1140e-04, -1.3132e-03,  ...,  2.4509e-04,
          2.6727e-04,  6.9046e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0707,  0.0109, -0.0099,  ..., -0.0066,  0.0112,  0.0022],
        [-0.0075, -0.0907,  0.0032,  ...,  0.0068, -0.0044,  0.0111],
        [-0.0029, -0.0082, -0.0838,  ...,  0.0135,  0.0059,  0.0096],
        ...,
        [ 0.0064,  0.0049,  0.0064,  ..., -0.0717, -0.0042,  0.0095],
        [ 0.0056, -0.0073,  0.0087,  ..., -0.0035, -0.0844,  0.0136],
        [-0.0041,  0.0023, -0.0083,  ..., -0.0073,  0.0009, -0.0950]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.2590e-02,  1.7929e-03,  4.4823e-03,  ..., -1.9646e-03,
         -1.4534e-03, -9.5749e-04],
        [-5.8136e-03, -8.9539e-02,  1.9970e-03,  ...,  9.3460e-05,
         -8.8644e-04,  6.9618e-04],
        [-3.0651e-03,  2.0111e-04, -8.1848e-02,  ..., -3.4485e-03,
          1.0384e-02,  1.4400e-03],
        ...,
        [-3.2120e-03, -4.9629e-03, -2.9755e-04,  ..., -8.6060e-02,
         -4.4441e-04, -5.2834e-04],
        [-1.3275e-03, -2.3823e-03,  5.7793e-04,  ..., -1.2932e-03,
         -8.2092e-02,  4.4098e-03],
        [-2.5368e-03,  3.9101e-03, -5.6171e-04,  ..., -1.3260e-02,
          1.7490e-03, -9.7412e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:02:23 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-06-30 23:02:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5137, -0.2988, -0.2286,  ..., -0.6313, -0.6963,  0.2749],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5522,  0.4490, -0.0248,  ..., -0.6616, -0.6191,  0.6772],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3909, -0.9395, -0.2510,  ..., -0.5601, -0.0886, -0.1172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0447, -0.3054, -0.3540,  ..., -0.3442, -0.6650, -0.7627],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:02:23 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:02:23 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 23:02:58 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 23:03:29 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-06-30 23:03:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.4174e-03,  5.8079e-04,  9.8991e-04,  ...,  1.2980e-03,
          2.1324e-03, -2.2259e-03],
        [-4.1246e-04, -8.0795e-03,  2.1362e-04,  ...,  1.8501e-03,
          3.9721e-04, -1.1730e-03],
        [ 1.0118e-03,  2.1000e-03, -5.4932e-03,  ...,  1.7524e-04,
         -9.5749e-04, -1.1311e-03],
        ...,
        [-7.1526e-05, -2.6817e-03,  1.0757e-03,  ..., -1.9302e-03,
         -4.9591e-04, -8.1110e-04],
        [ 7.2670e-04, -8.9169e-05,  2.6932e-03,  ..., -2.0313e-03,
         -7.7009e-04,  1.2455e-03],
        [-2.5451e-05, -2.8253e-04,  2.2812e-03,  ..., -9.7370e-04,
         -2.9583e-03, -1.7071e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0714,  0.0003, -0.0079,  ...,  0.0107,  0.0140, -0.0172],
        [ 0.0020, -0.0944,  0.0016,  ...,  0.0012, -0.0049, -0.0002],
        [-0.0016,  0.0082, -0.0974,  ..., -0.0054,  0.0027, -0.0024],
        ...,
        [ 0.0046, -0.0063,  0.0076,  ..., -0.0972,  0.0073,  0.0113],
        [-0.0079, -0.0135, -0.0035,  ..., -0.0027, -0.0876,  0.0040],
        [-0.0111,  0.0115, -0.0034,  ..., -0.0068, -0.0073, -0.0754]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0842, -0.0016,  0.0030,  ..., -0.0049, -0.0040,  0.0047],
        [ 0.0029, -0.0908, -0.0029,  ..., -0.0067, -0.0108,  0.0053],
        [-0.0066, -0.0030, -0.0862,  ..., -0.0040,  0.0016, -0.0072],
        ...,
        [ 0.0055,  0.0052,  0.0067,  ..., -0.0872, -0.0050, -0.0076],
        [ 0.0025,  0.0002, -0.0070,  ..., -0.0007, -0.0841,  0.0040],
        [-0.0069,  0.0032, -0.0147,  ..., -0.0032, -0.0035, -0.0914]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:03:55 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-06-30 23:03:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1235, -0.5581, -0.1396,  ..., -0.8276,  0.2294,  0.5068],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2908, -0.2734,  0.2051,  ..., -0.4709, -0.4834, -0.1335],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3555, -0.8218, -0.3970,  ..., -0.3105,  0.0277,  0.3442],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5801, -1.0869, -0.8398,  ...,  0.0742,  0.0723, -1.1006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:03:55 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:03:55 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 23:04:33 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 23:05:11 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-06-30 23:05:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.4855e-03,  2.5253e-03, -2.4796e-04,  ...,  1.4257e-04,
         -1.9197e-03,  7.2861e-04],
        [ 4.5180e-05, -2.9507e-03, -4.0359e-03,  ...,  1.4610e-03,
         -1.0967e-04, -4.4727e-04],
        [ 2.7466e-03, -1.9951e-03, -1.2274e-03,  ..., -1.4963e-03,
         -5.7745e-04, -6.7711e-04],
        ...,
        [ 4.1008e-04, -3.2043e-04, -6.7902e-04,  ..., -2.0676e-03,
          1.5631e-03,  1.6248e-04],
        [-2.8477e-03, -3.6192e-04, -1.8370e-04,  ...,  1.0147e-03,
         -1.7138e-03, -7.0429e-04],
        [ 3.3264e-03,  2.4319e-05,  1.1721e-03,  ...,  1.8072e-04,
          6.1302e-03, -3.5973e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0734,  0.0136,  0.0005,  ..., -0.0092, -0.0072,  0.0011],
        [ 0.0033, -0.0724, -0.0140,  ...,  0.0059,  0.0094,  0.0037],
        [-0.0011, -0.0113, -0.0767,  ...,  0.0039, -0.0087,  0.0119],
        ...,
        [-0.0012, -0.0035,  0.0029,  ..., -0.0690, -0.0062, -0.0008],
        [ 0.0056, -0.0026, -0.0050,  ...,  0.0091, -0.0814,  0.0096],
        [ 0.0017,  0.0028,  0.0160,  ...,  0.0002,  0.0006, -0.0743]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1003, -0.0073,  0.0136,  ..., -0.0025, -0.0124, -0.0013],
        [ 0.0056, -0.0787, -0.0119,  ...,  0.0004,  0.0062, -0.0003],
        [ 0.0027, -0.0037, -0.0845,  ...,  0.0093,  0.0006,  0.0146],
        ...,
        [ 0.0009, -0.0070, -0.0060,  ..., -0.0871,  0.0163, -0.0014],
        [ 0.0132,  0.0075,  0.0041,  ...,  0.0055, -0.0859, -0.0028],
        [-0.0038, -0.0014,  0.0086,  ...,  0.0035,  0.0061, -0.0850]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:05:50 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-06-30 23:05:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3413, -0.8477, -0.2177,  ..., -0.4529, -0.0823, -0.1257],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0397, -0.3174, -0.3391,  ..., -0.3152, -0.6387, -0.7827],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1848, -0.9072, -0.3521,  ..., -1.2207,  0.6797,  0.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5742, -1.2666, -1.9941,  ..., -0.4182, -0.2993, -0.3994],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:05:50 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:05:50 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 23:06:33 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 23:07:15 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-06-30 23:07:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.4479e-03, -1.1482e-03, -1.6670e-03,  ...,  1.7900e-03,
         -4.5466e-04, -5.7793e-04],
        [ 2.1219e-05, -3.1471e-03,  1.9760e-03,  ..., -1.6136e-03,
         -2.2531e-04, -1.9836e-03],
        [-3.4218e-03, -1.1578e-03, -4.5013e-03,  ...,  2.4338e-03,
          2.3842e-06,  7.7200e-04],
        ...,
        [-1.0262e-03, -7.6199e-04, -1.0805e-03,  ..., -3.7994e-03,
          1.3580e-03,  3.0458e-05],
        [ 9.1791e-05,  1.3828e-05, -1.1390e-04,  ..., -2.2185e-04,
         -4.3106e-03, -7.4005e-04],
        [ 3.7727e-03,  2.3632e-03,  1.4725e-03,  ..., -9.9564e-04,
          9.6750e-04, -3.2692e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1056, -0.0043, -0.0040,  ...,  0.0031, -0.0024,  0.0107],
        [ 0.0038, -0.1071,  0.0094,  ...,  0.0022, -0.0099,  0.0057],
        [ 0.0047,  0.0021, -0.0954,  ..., -0.0039, -0.0017, -0.0136],
        ...,
        [-0.0111,  0.0012, -0.0037,  ..., -0.0944,  0.0097,  0.0097],
        [ 0.0025, -0.0072,  0.0053,  ...,  0.0036, -0.0919,  0.0039],
        [ 0.0027,  0.0007, -0.0071,  ..., -0.0075,  0.0060, -0.1108]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1185,  0.0210, -0.0073,  ..., -0.0185,  0.0004, -0.0054],
        [-0.0006, -0.1157,  0.0049,  ...,  0.0042, -0.0085,  0.0168],
        [ 0.0023, -0.0007, -0.1140,  ..., -0.0063, -0.0076,  0.0194],
        ...,
        [ 0.0031,  0.0057, -0.0013,  ..., -0.0983, -0.0053,  0.0086],
        [-0.0069,  0.0030, -0.0070,  ...,  0.0047, -0.1089,  0.0189],
        [ 0.0030,  0.0010, -0.0086,  ...,  0.0031,  0.0088, -0.1166]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:08:00 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-06-30 23:08:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2520, -0.6445, -0.3416,  ..., -0.2429,  0.0033,  0.2493],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4685, -0.9302, -0.7212,  ...,  0.0388,  0.0434, -0.9561],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3867, -0.4619,  0.0269,  ..., -1.4980,  1.2129, -0.1753],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4111, -0.7451, -1.1797,  ...,  0.0295, -0.5195, -0.0881],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:08:00 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:08:00 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 23:08:48 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 23:09:37 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-06-30 23:10:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7986e-03,  3.2921e-03,  3.0231e-04,  ..., -3.0594e-03,
         -1.3816e-04, -1.0700e-03],
        [ 2.4185e-03,  1.6375e-03, -9.4700e-04,  ...,  2.2144e-03,
         -3.2177e-03,  3.0060e-03],
        [ 3.3307e-04,  4.9734e-04,  6.4240e-03,  ..., -1.8940e-03,
          3.4599e-03, -3.0251e-03],
        ...,
        [-9.9182e-04, -1.5593e-03, -1.3371e-03,  ...,  3.1700e-03,
         -2.9049e-03,  1.0519e-03],
        [-1.2150e-03, -5.8317e-04,  2.6569e-03,  ...,  1.0532e-04,
          7.4911e-04,  4.8780e-04],
        [ 5.5313e-05, -1.6918e-03, -8.7929e-04,  ..., -3.1137e-04,
         -7.6580e-04,  2.2621e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0911, -0.0105, -0.0110,  ...,  0.0024,  0.0084, -0.0013],
        [-0.0096, -0.1074,  0.0028,  ..., -0.0046,  0.0024,  0.0164],
        [-0.0075,  0.0036, -0.1013,  ...,  0.0218,  0.0062,  0.0048],
        ...,
        [ 0.0042,  0.0087,  0.0136,  ..., -0.0997, -0.0012, -0.0057],
        [ 0.0037,  0.0014,  0.0083,  ..., -0.0068, -0.1161,  0.0107],
        [ 0.0096, -0.0018, -0.0014,  ..., -0.0077,  0.0102, -0.0927]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1573, -0.0127, -0.0075,  ...,  0.0194,  0.0101,  0.0027],
        [-0.0053, -0.1714, -0.0013,  ...,  0.0061, -0.0152,  0.0007],
        [-0.0014, -0.0099, -0.1343,  ...,  0.0099, -0.0005, -0.0117],
        ...,
        [-0.0134,  0.0112,  0.0079,  ..., -0.1625, -0.0030,  0.0029],
        [ 0.0115, -0.0020,  0.0060,  ...,  0.0008, -0.1639, -0.0079],
        [-0.0150,  0.0055, -0.0095,  ..., -0.0193, -0.0081, -0.1605]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:10:25 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-06-30 23:10:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1377, -0.6870, -0.2849,  ..., -0.8335,  0.4673,  0.1567],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4497, -1.0029, -1.5059,  ..., -0.2942, -0.2405, -0.3562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2915,  0.0249, -0.5039,  ..., -1.9297,  0.7715, -0.0498],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8184, -0.2817, -0.8184,  ..., -0.3960, -0.5459,  0.6143],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:10:25 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:10:25 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 23:11:08 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 23:11:55 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-06-30 23:12:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0085, -0.0010, -0.0005,  ...,  0.0009,  0.0002,  0.0007],
        [-0.0004, -0.0049,  0.0019,  ...,  0.0022,  0.0007,  0.0013],
        [ 0.0016, -0.0009, -0.0060,  ..., -0.0013, -0.0022, -0.0018],
        ...,
        [ 0.0014, -0.0019,  0.0022,  ..., -0.0040, -0.0018, -0.0009],
        [ 0.0010, -0.0026, -0.0006,  ...,  0.0011, -0.0066,  0.0013],
        [ 0.0005, -0.0011, -0.0012,  ...,  0.0010, -0.0002, -0.0049]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1047,  0.0169, -0.0005,  ..., -0.0023, -0.0030,  0.0065],
        [ 0.0076, -0.1020,  0.0087,  ..., -0.0017, -0.0083, -0.0055],
        [-0.0029,  0.0024, -0.1005,  ..., -0.0047,  0.0022,  0.0103],
        ...,
        [ 0.0085, -0.0101,  0.0042,  ..., -0.0863,  0.0002, -0.0179],
        [ 0.0074, -0.0055, -0.0002,  ...,  0.0090, -0.0995, -0.0046],
        [ 0.0051, -0.0055, -0.0058,  ...,  0.0016,  0.0015, -0.0952]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1185,  0.0264,  0.0186,  ..., -0.0150, -0.0139,  0.0101],
        [ 0.0008, -0.0951, -0.0017,  ..., -0.0032, -0.0093, -0.0097],
        [-0.0007,  0.0112, -0.1163,  ...,  0.0018, -0.0008,  0.0038],
        ...,
        [-0.0027, -0.0061, -0.0084,  ..., -0.0992,  0.0024,  0.0023],
        [-0.0125, -0.0151, -0.0060,  ...,  0.0041, -0.1132,  0.0134],
        [ 0.0041,  0.0016, -0.0048,  ...,  0.0108, -0.0013, -0.1092]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:12:36 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-06-30 23:12:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2527, -0.3496, -0.0310,  ..., -1.0234,  0.7969, -0.1246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9888, -0.5566, -0.8340,  ..., -0.0131, -0.3787, -0.0610],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3838,  0.5513, -0.2090,  ..., -1.8154,  0.7939,  0.7588],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4746, -0.1199, -0.8975,  ..., -0.6504, -0.1836,  0.2764],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:12:36 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:12:36 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 23:13:29 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 23:14:23 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-06-30 23:15:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0020, -0.0016,  0.0004,  ..., -0.0015, -0.0024,  0.0012],
        [ 0.0010,  0.0048,  0.0005,  ...,  0.0017, -0.0008,  0.0020],
        [-0.0041, -0.0020,  0.0047,  ..., -0.0027,  0.0014,  0.0008],
        ...,
        [-0.0007,  0.0011,  0.0039,  ...,  0.0040,  0.0009,  0.0015],
        [-0.0026, -0.0035, -0.0010,  ..., -0.0011,  0.0039,  0.0041],
        [-0.0020, -0.0008,  0.0011,  ..., -0.0030,  0.0015,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.4978e-01, -3.9177e-03, -8.5831e-05,  ...,  3.5038e-03,
          1.7014e-03,  3.2196e-03],
        [ 3.1242e-03, -1.4539e-01, -8.1253e-03,  ..., -5.2795e-03,
         -9.2163e-03, -4.7073e-03],
        [ 9.8190e-03,  2.2507e-04, -1.5479e-01,  ..., -1.0040e-02,
         -7.6599e-03, -5.2872e-03],
        ...,
        [-1.2817e-02, -1.4198e-02,  7.0190e-04,  ..., -1.5857e-01,
          2.3003e-03,  7.3471e-03],
        [ 1.0529e-02,  7.1793e-03, -1.2455e-03,  ..., -1.1826e-02,
         -1.4893e-01, -1.2215e-02],
        [-6.1035e-03, -9.8114e-03, -1.5388e-02,  ..., -1.0330e-02,
          1.1169e-02, -1.5540e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2178,  0.0169,  0.0043,  ..., -0.0057, -0.0089, -0.0003],
        [ 0.0052, -0.2367, -0.0160,  ..., -0.0133,  0.0094,  0.0021],
        [ 0.0056,  0.0030, -0.2083,  ...,  0.0040,  0.0046,  0.0055],
        ...,
        [-0.0055,  0.0039,  0.0027,  ..., -0.2424,  0.0179, -0.0048],
        [-0.0051,  0.0048, -0.0053,  ...,  0.0071, -0.2216,  0.0087],
        [-0.0006, -0.0161, -0.0031,  ..., -0.0014, -0.0006, -0.2239]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:15:17 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-06-30 23:15:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.6980e-01, -3.1972e-04, -3.7915e-01,  ..., -1.2988e+00,
         5.1074e-01, -9.1431e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.4404, -0.2439, -0.6753,  ..., -0.3169, -0.4436,  0.4529],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1775,  0.9521, -0.7188,  ..., -1.7061,  0.2676,  1.5508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0859, -0.5786, -1.7715,  ..., -1.1982,  1.2246,  1.3525],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:15:17 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:15:17 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 23:16:09 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 23:17:01 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-06-30 23:17:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.3700e-03,  4.7607e-03,  2.8152e-03,  ..., -5.5885e-04,
         -2.5539e-03, -1.2779e-03],
        [-1.3962e-03, -5.9967e-03,  3.9577e-04,  ..., -5.1689e-04,
         -8.8978e-04,  5.7697e-04],
        [ 1.2703e-03, -2.5344e-04, -4.6883e-03,  ...,  1.4353e-03,
          1.6117e-03, -1.0424e-03],
        ...,
        [ 1.8215e-03, -2.2049e-03,  1.5583e-03,  ..., -3.9825e-03,
          4.3082e-04, -2.4307e-04],
        [-1.4372e-03,  3.2997e-04, -1.8668e-04,  ..., -2.0866e-03,
         -7.7896e-03, -1.8430e-04],
        [ 1.8702e-03,  2.8858e-03, -4.8733e-04,  ...,  1.4515e-03,
         -9.5367e-07, -2.5730e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0874,  0.0049,  0.0020,  ..., -0.0038, -0.0148, -0.0070],
        [ 0.0040, -0.0773,  0.0024,  ..., -0.0071,  0.0145,  0.0106],
        [-0.0157, -0.0021, -0.0845,  ...,  0.0019,  0.0105,  0.0153],
        ...,
        [ 0.0024,  0.0035,  0.0078,  ..., -0.0625,  0.0078, -0.0074],
        [-0.0078,  0.0051, -0.0075,  ...,  0.0036, -0.0919,  0.0106],
        [ 0.0003,  0.0101, -0.0063,  ...,  0.0045, -0.0073, -0.0635]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.1665e-02, -4.2839e-03, -2.4624e-03,  ..., -5.2071e-04,
         -8.1787e-03, -1.3084e-03],
        [ 2.3937e-04, -9.6191e-02, -5.1155e-03,  ...,  5.3978e-04,
          1.1520e-02,  2.3743e-02],
        [-7.0000e-03, -8.3542e-03, -9.1980e-02,  ..., -9.8267e-03,
         -1.0101e-02,  1.2465e-03],
        ...,
        [-8.4229e-03, -7.7782e-03,  7.4310e-03,  ..., -8.0017e-02,
          1.2154e-02, -4.3488e-03],
        [-3.2425e-05,  2.6588e-03,  1.6098e-03,  ...,  8.9188e-03,
         -9.4421e-02,  8.2855e-03],
        [-1.9894e-03,  1.2161e-02, -1.7452e-03,  ...,  4.1275e-03,
          3.7842e-03, -8.3740e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:17:55 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-06-30 23:17:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2441,  0.3127, -0.1387,  ..., -1.1240,  0.4998,  0.4631],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1758, -0.1326, -0.6787,  ..., -0.5088, -0.1403,  0.1945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2810,  1.8164, -0.2363,  ..., -1.0156,  1.2500,  1.4277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0898, -0.8770, -1.4053,  ..., -0.5776,  2.2344,  1.2314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:17:55 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:17:55 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 23:18:50 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 23:19:45 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-06-30 23:20:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.2839e-03, -1.6012e-03,  2.8305e-03,  ...,  5.7268e-04,
         -1.0767e-03, -4.8447e-03],
        [-3.2043e-03,  1.1055e-02, -6.1750e-05,  ...,  2.2945e-03,
          1.0958e-03, -1.9951e-03],
        [ 3.7193e-05,  5.2261e-04,  3.0537e-03,  ..., -4.3068e-03,
          5.6410e-04, -3.6278e-03],
        ...,
        [ 3.2067e-04, -1.9348e-04,  2.3327e-03,  ...,  5.0735e-03,
         -4.7379e-03,  5.2528e-03],
        [ 7.0000e-03, -2.0580e-03,  1.1711e-03,  ..., -4.3602e-03,
          2.5063e-03,  2.1207e-04],
        [ 1.9970e-03,  5.0735e-03,  9.4414e-04,  ..., -4.1428e-03,
         -2.8286e-03, -1.3094e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1117, -0.0113,  0.0030,  ...,  0.0019,  0.0149, -0.0047],
        [-0.0027, -0.1120, -0.0041,  ...,  0.0043,  0.0049, -0.0108],
        [ 0.0057,  0.0096, -0.1135,  ..., -0.0028,  0.0149, -0.0155],
        ...,
        [ 0.0051, -0.0037, -0.0078,  ..., -0.1193, -0.0007,  0.0066],
        [-0.0014,  0.0155,  0.0033,  ...,  0.0117, -0.1171, -0.0132],
        [-0.0021, -0.0201,  0.0023,  ..., -0.0132,  0.0159, -0.1061]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1359e-01,  1.3924e-04, -9.8801e-04,  ..., -6.5842e-03,
          2.9831e-02, -4.0131e-03],
        [-1.2825e-02, -1.3049e-01, -6.3629e-03,  ...,  8.2245e-03,
         -1.5167e-02,  1.0330e-02],
        [ 3.7689e-03,  9.3994e-03, -1.4185e-01,  ..., -1.8311e-03,
         -1.1292e-02, -1.1269e-02],
        ...,
        [-9.2545e-03, -6.8588e-03, -5.6648e-03,  ..., -1.4697e-01,
         -7.2784e-03,  6.1951e-03],
        [ 6.3934e-03, -3.8147e-06,  1.5717e-03,  ...,  8.1482e-03,
         -1.4807e-01,  4.5547e-03],
        [-1.2741e-02, -1.3399e-03, -2.2144e-03,  ..., -4.6768e-03,
          1.3382e-02, -1.3477e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:20:45 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-06-30 23:20:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0722,  0.5161, -0.4106,  ..., -0.9604,  0.1787,  0.8345],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6665, -0.3838, -1.0840,  ..., -0.7583,  0.8066,  0.8145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8623,  1.5215, -0.0846,  ..., -1.5039,  1.6719,  1.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.7178, -0.5942, -1.6934,  ..., -0.6162,  2.1328,  1.4443],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:20:46 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:20:46 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 23:21:43 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 23:22:43 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-06-30 23:23:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0042, -0.0013,  0.0006,  ..., -0.0027, -0.0047, -0.0004],
        [-0.0038, -0.0008, -0.0004,  ...,  0.0001,  0.0014, -0.0016],
        [-0.0037,  0.0009,  0.0003,  ...,  0.0016, -0.0017,  0.0003],
        ...,
        [ 0.0055,  0.0014, -0.0027,  ..., -0.0002,  0.0008, -0.0008],
        [-0.0010, -0.0014, -0.0009,  ...,  0.0036,  0.0026, -0.0024],
        [-0.0045,  0.0016, -0.0017,  ...,  0.0002,  0.0013, -0.0002]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0934,  0.0207, -0.0003,  ..., -0.0246,  0.0055,  0.0083],
        [ 0.0142, -0.0759,  0.0010,  ...,  0.0025,  0.0060,  0.0121],
        [-0.0048, -0.0028, -0.0892,  ..., -0.0070,  0.0200, -0.0090],
        ...,
        [-0.0177, -0.0121, -0.0035,  ..., -0.0865,  0.0126,  0.0111],
        [-0.0092, -0.0002,  0.0134,  ...,  0.0109, -0.0804, -0.0027],
        [ 0.0006,  0.0136, -0.0060,  ...,  0.0051,  0.0052, -0.0843]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0956e-01,  3.2883e-03, -1.0307e-02,  ..., -7.8659e-03,
          4.1695e-03,  1.2159e-05],
        [ 7.7972e-03, -1.0822e-01,  5.8136e-03,  ...,  9.2239e-03,
          8.6975e-03,  4.6654e-03],
        [-1.3206e-02, -1.4473e-02, -1.1127e-01,  ...,  3.7823e-03,
          2.1042e-02, -1.0368e-02],
        ...,
        [-5.2834e-03, -1.2474e-02,  9.2239e-03,  ..., -1.0608e-01,
          1.6449e-02, -1.0704e-02],
        [-8.5449e-03,  7.1640e-03,  5.9814e-03,  ...,  9.0866e-03,
         -1.1597e-01, -2.4509e-03],
        [ 2.3804e-03,  1.0315e-02, -3.3760e-03,  ..., -1.5488e-02,
         -5.4359e-05, -1.0901e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:23:44 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-06-30 23:23:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1489,  0.9624, -0.1237,  ..., -0.5552,  0.6777,  0.7524],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6582, -0.5586, -0.7949,  ..., -0.3486,  1.3184,  0.7065],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3706,  1.6396,  0.2915,  ..., -1.4902,  2.0176,  2.2891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4521, -0.3848, -2.8418,  ...,  0.1060,  2.3887,  2.1309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:23:45 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:23:45 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 23:24:48 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 23:25:52 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-06-30 23:26:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.6681e-03, -4.6730e-04, -9.4509e-04,  ..., -2.4738e-03,
         -1.8158e-03, -1.0185e-03],
        [ 3.8891e-03,  9.9869e-03, -1.0242e-03,  ...,  1.6336e-03,
          2.9716e-03, -2.3994e-03],
        [-9.5940e-04, -4.5853e-03,  8.5449e-03,  ..., -4.2677e-05,
         -1.2302e-03, -1.8740e-04],
        ...,
        [-1.0586e-03,  1.5392e-03, -4.7607e-03,  ...,  9.4299e-03,
         -4.6310e-03,  4.1962e-03],
        [ 4.9744e-03,  5.6982e-04,  2.2769e-04,  ...,  3.5048e-04,
          8.8425e-03, -2.6817e-03],
        [ 1.3161e-03,  1.9550e-03,  3.0651e-03,  ...,  2.8458e-03,
          1.2274e-03,  1.0399e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0786,  0.0006, -0.0154,  ...,  0.0066,  0.0074, -0.0023],
        [-0.0202, -0.0818,  0.0116,  ..., -0.0117,  0.0003, -0.0052],
        [-0.0074,  0.0008, -0.0695,  ...,  0.0028,  0.0044,  0.0086],
        ...,
        [-0.0047,  0.0017, -0.0087,  ..., -0.0632,  0.0012,  0.0062],
        [-0.0106, -0.0072, -0.0090,  ...,  0.0044, -0.0827,  0.0095],
        [-0.0074, -0.0063,  0.0007,  ...,  0.0021, -0.0008, -0.0800]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0754e-01,  5.9128e-03, -1.9302e-02,  ..., -4.8904e-03,
         -1.7118e-03,  8.4076e-03],
        [-3.7384e-04, -1.0956e-01, -1.7548e-02,  ..., -1.3161e-02,
         -4.1223e-04,  5.6267e-04],
        [-1.0796e-02, -3.5954e-04, -1.2451e-01,  ...,  7.7553e-03,
          3.5496e-03, -1.4706e-03],
        ...,
        [ 1.0101e-02, -1.3189e-03,  7.8583e-04,  ..., -9.8022e-02,
         -1.4214e-02, -1.0422e-02],
        [ 5.2185e-03, -9.3002e-03, -8.0795e-03,  ...,  2.5673e-03,
         -1.1188e-01,  4.8661e-04],
        [ 1.6281e-02,  1.6584e-03, -8.3923e-05,  ..., -4.6577e-03,
          2.3632e-03, -1.1139e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:26:59 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-06-30 23:26:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4429,  0.8594, -0.0655,  ..., -0.8276,  0.9243,  0.7695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9365, -0.3357, -0.9170,  ..., -0.3423,  1.1895,  0.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0938,  1.5000,  0.2527,  ..., -1.6494,  1.3574,  2.6699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.2041, -0.7549, -2.9238,  ..., -0.1665,  2.6992,  1.9102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:26:59 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:26:59 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 23:28:03 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 23:29:08 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-06-30 23:30:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.9280e-03, -6.3019e-03,  3.3150e-03,  ..., -2.3499e-03,
          6.8951e-04, -4.1771e-03],
        [-4.5586e-04,  1.9503e-03,  1.6451e-03,  ...,  5.6648e-03,
          2.1684e-04, -7.4148e-04],
        [ 6.9737e-05, -1.8024e-03, -7.3433e-03,  ..., -1.7185e-03,
          3.5572e-03, -2.4166e-03],
        ...,
        [ 2.4586e-03, -6.8331e-04, -5.5122e-03,  ...,  1.1845e-03,
         -2.9297e-03, -3.3588e-03],
        [ 4.3654e-04, -2.6894e-04, -2.2030e-03,  ..., -6.9237e-04,
         -1.8072e-03,  3.5629e-03],
        [ 4.5419e-04,  7.2861e-03, -2.2011e-03,  ..., -4.1885e-03,
         -1.5373e-03, -1.1185e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.7220e-02, -4.2419e-03, -3.9215e-03,  ..., -1.0971e-02,
          8.3389e-03, -1.5869e-02],
        [-7.5912e-03, -4.5441e-02, -2.8954e-03,  ...,  6.8054e-03,
          8.3389e-03,  7.7477e-03],
        [ 3.8242e-03,  1.0433e-03, -5.0110e-02,  ..., -1.9760e-03,
          1.3184e-02, -6.5918e-03],
        ...,
        [-1.7273e-02,  1.7273e-02,  1.4095e-03,  ..., -6.5430e-02,
         -8.2169e-03,  2.6093e-03],
        [ 1.4450e-02,  9.0866e-03, -7.8678e-05,  ...,  9.5520e-03,
         -5.4871e-02,  1.1917e-02],
        [-1.5686e-02,  2.2507e-03, -9.8114e-03,  ..., -2.0866e-03,
         -8.6594e-03, -4.5593e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.6660e-02,  1.3390e-03,  1.6663e-02,  ..., -9.2316e-04,
         -3.9721e-04,  9.8877e-03],
        [ 7.1068e-03, -8.4656e-02, -1.0544e-02,  ...,  1.2833e-02,
         -2.2717e-03,  3.0823e-03],
        [ 1.1536e-02,  1.7471e-02, -8.3313e-02,  ..., -3.5362e-03,
         -1.3268e-02, -7.7400e-03],
        ...,
        [-1.5686e-02,  2.2430e-03,  4.5776e-04,  ..., -8.8196e-02,
         -1.5274e-02,  4.5662e-03],
        [ 1.2886e-02,  4.2381e-03, -9.1019e-03,  ...,  1.0269e-02,
         -7.8186e-02,  5.5084e-03],
        [-1.2337e-02, -2.2697e-04,  1.4069e-02,  ...,  9.4414e-05,
         -8.8882e-03, -8.3679e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:30:12 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-06-30 23:30:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1801,  0.8545,  0.1440,  ..., -0.7578,  1.0557,  1.1494],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7207, -0.1985, -1.3535,  ...,  0.0456,  1.1953,  1.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1289,  2.1367,  0.0996,  ..., -1.8799,  1.1553,  4.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.3594, -0.6875, -2.8027,  ...,  0.1597,  1.7598,  2.6914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:30:12 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:30:13 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 23:31:16 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 23:32:20 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-06-30 23:33:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.0156e-04, -6.1607e-03, -1.4381e-03,  ...,  2.1629e-03,
         -8.0442e-04, -7.7629e-04],
        [ 4.4870e-04,  8.1177e-03,  3.6383e-04,  ...,  3.0460e-03,
          1.6432e-03,  4.1695e-03],
        [ 6.4659e-04, -2.4395e-03,  5.7459e-04,  ..., -4.2038e-03,
          1.9312e-03, -7.4883e-03],
        ...,
        [-2.3365e-03, -6.6948e-03, -2.3127e-05,  ...,  1.1091e-03,
          1.3161e-04, -1.6994e-03],
        [ 2.7370e-03,  6.6452e-03,  2.6932e-03,  ..., -6.9962e-03,
         -3.6869e-03, -1.6298e-03],
        [ 3.4065e-03, -1.1787e-03, -6.0081e-03,  ..., -2.5105e-04,
          2.4128e-03, -6.9313e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0516,  0.0062,  0.0031,  ...,  0.0010, -0.0106,  0.0012],
        [-0.0128, -0.0515,  0.0018,  ...,  0.0061, -0.0003, -0.0071],
        [-0.0080,  0.0015, -0.0671,  ..., -0.0124,  0.0040,  0.0058],
        ...,
        [ 0.0163, -0.0136, -0.0059,  ..., -0.0616,  0.0164, -0.0081],
        [-0.0022,  0.0027,  0.0143,  ..., -0.0008, -0.0541, -0.0054],
        [-0.0107, -0.0179, -0.0018,  ..., -0.0100, -0.0054, -0.0556]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.5623e-02, -1.6537e-03, -9.6817e-03,  ..., -1.3275e-02,
          3.9482e-03, -2.5501e-03],
        [-6.5269e-03, -9.6863e-02, -2.0275e-03,  ..., -8.4610e-03,
          4.8676e-03, -5.5361e-04],
        [-1.3676e-03, -1.0895e-02, -8.9966e-02,  ..., -7.6370e-03,
          6.5117e-03, -9.6741e-03],
        ...,
        [ 2.7359e-02, -3.3875e-03,  1.4359e-02,  ..., -7.2388e-02,
          2.3331e-02,  5.2185e-03],
        [-9.9182e-05,  5.4054e-03,  1.4582e-03,  ...,  7.0419e-03,
         -1.0394e-01,  7.4997e-03],
        [-7.0839e-03,  4.0207e-03, -1.9665e-03,  ..., -1.1734e-02,
          3.9444e-03, -9.8267e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:33:27 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-06-30 23:33:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0271,  0.7490,  0.1082,  ..., -0.8198,  0.6899,  1.3154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5527, -0.3459, -1.3418,  ..., -0.0793,  1.2861,  0.8682],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0211,  2.0625,  0.5361,  ..., -1.4541,  1.0762,  4.4453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.5059, -0.4409, -3.0059,  ...,  0.3450,  1.8516,  3.5410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:33:27 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:33:27 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 23:34:35 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 23:35:45 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-06-30 23:36:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.1787e-03, -6.5346e-03,  3.5706e-03,  ..., -5.6725e-03,
         -8.7452e-04, -1.1575e-04],
        [ 7.9060e-04,  4.8447e-03,  7.9966e-04,  ...,  3.1738e-03,
          3.0613e-03, -3.7384e-03],
        [-2.8114e-03, -8.4457e-03,  2.5291e-03,  ..., -3.0994e-03,
         -5.0128e-05, -1.4772e-03],
        ...,
        [ 2.2430e-03,  3.8624e-03, -6.2180e-03,  ...,  9.1705e-03,
          3.0270e-03, -8.1711e-03],
        [ 5.6114e-03, -2.0905e-03,  7.3242e-03,  ..., -3.6573e-04,
          6.1798e-03,  3.1738e-03],
        [-4.1847e-03,  2.8419e-03, -1.5869e-03,  ...,  1.9970e-03,
         -3.2768e-03,  3.2005e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.4087e-02, -3.2482e-03,  1.2331e-03,  ..., -1.9043e-02,
         -6.9847e-03, -9.2840e-04],
        [ 1.8215e-03, -5.9296e-02,  8.2474e-03,  ...,  4.7951e-03,
          6.5460e-03,  6.3019e-03],
        [-6.8932e-03,  9.6130e-04, -4.3335e-02,  ...,  9.2888e-04,
          4.0207e-03, -6.8283e-03],
        ...,
        [-1.4748e-02,  7.1716e-03, -4.5128e-03,  ..., -4.6448e-02,
         -1.8417e-02,  1.1856e-02],
        [-8.1329e-03, -5.9319e-03,  2.0027e-03,  ..., -4.9019e-03,
         -4.9469e-02, -1.6586e-02],
        [-1.0643e-02, -9.5367e-05, -5.2643e-04,  ..., -9.1934e-03,
          6.0387e-03, -2.7374e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0890,  0.0010,  0.0029,  ..., -0.0032, -0.0012, -0.0172],
        [ 0.0007, -0.0903,  0.0056,  ..., -0.0188,  0.0002,  0.0113],
        [ 0.0033, -0.0118, -0.0829,  ..., -0.0035,  0.0136,  0.0011],
        ...,
        [-0.0039,  0.0090, -0.0079,  ..., -0.0837, -0.0042,  0.0080],
        [-0.0062, -0.0157, -0.0135,  ..., -0.0160, -0.0834, -0.0066],
        [-0.0091,  0.0057, -0.0160,  ..., -0.0047,  0.0049, -0.0903]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:36:56 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-06-30 23:36:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0555,  0.9937,  0.0226,  ..., -0.8750,  0.5630,  1.9111],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6138, -0.3110, -1.2246,  ...,  0.0665,  0.8052,  1.1738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7266,  2.4922, -0.3418,  ..., -1.3643,  1.2207,  3.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6084, -0.2576, -3.2676,  ...,  0.5854,  1.6016,  3.4746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:36:56 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:36:56 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 23:38:02 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 23:39:11 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-06-30 23:40:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.6234e-03, -2.2674e-04,  1.9140e-03,  ...,  2.0447e-03,
         -1.9703e-03, -1.3123e-03],
        [ 2.3975e-03,  3.1052e-03, -2.5444e-03,  ..., -8.0919e-04,
          3.2463e-03,  8.4400e-04],
        [ 7.9393e-04, -3.5038e-03,  4.9591e-04,  ...,  1.8034e-03,
          1.8663e-03, -4.5300e-04],
        ...,
        [-6.0692e-03,  6.8378e-04, -1.7090e-03,  ..., -2.4104e-04,
          1.1940e-03, -1.1978e-03],
        [-1.7462e-03,  1.6332e-05,  7.8869e-04,  ...,  2.2507e-03,
          7.3814e-04,  4.0114e-05],
        [-7.9679e-04,  3.1853e-03, -2.6560e-04,  ..., -2.7657e-03,
          4.4403e-03,  3.8338e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1887e-02, -6.9427e-03, -3.3607e-03,  ...,  2.8133e-03,
          9.8343e-03, -9.6283e-03],
        [ 1.4450e-02, -8.6021e-04, -9.5444e-03,  ...,  1.0405e-03,
         -1.8120e-05,  3.1681e-03],
        [ 1.5230e-03,  1.2352e-02, -4.2542e-02,  ...,  5.1575e-03,
          1.2100e-02,  1.1436e-02],
        ...,
        [-7.1793e-03, -1.8661e-02, -1.4442e-02,  ..., -1.5419e-02,
          1.8597e-03,  3.7098e-03],
        [ 1.5129e-02,  1.0544e-02, -1.1543e-02,  ...,  3.2539e-03,
         -3.4882e-02,  7.1831e-03],
        [-3.3836e-03, -1.3657e-02,  5.9738e-03,  ..., -9.5291e-03,
          9.7198e-03, -2.1820e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0334, -0.0037,  0.0037,  ..., -0.0179,  0.0157,  0.0155],
        [ 0.0096, -0.0219, -0.0057,  ..., -0.0053, -0.0030, -0.0098],
        [ 0.0168,  0.0189, -0.0669,  ..., -0.0095,  0.0136, -0.0051],
        ...,
        [-0.0211, -0.0092, -0.0018,  ..., -0.0467, -0.0126,  0.0045],
        [ 0.0012,  0.0063, -0.0138,  ...,  0.0038, -0.0510,  0.0265],
        [-0.0084, -0.0097,  0.0136,  ..., -0.0029,  0.0167, -0.0480]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:40:23 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-06-30 23:40:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0084,  0.8662,  0.1980,  ..., -0.6055,  0.4431,  1.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5884, -0.1799, -1.1191,  ...,  0.1337,  0.6938,  1.3408],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3623,  2.3457, -0.8032,  ..., -1.3379,  1.0146,  3.2520],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4043,  0.4387, -3.0527,  ...,  1.4297,  2.5215,  3.8945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:40:23 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:40:23 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 23:41:34 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 23:42:48 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-06-30 23:44:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.0692e-03, -1.2646e-03, -1.5068e-03,  ...,  1.4582e-03,
         -2.0142e-03,  8.5878e-04],
        [-2.0885e-03,  8.4000e-03,  1.0061e-03,  ...,  2.0199e-03,
          1.9288e-04,  5.4836e-05],
        [ 1.2493e-03,  8.9073e-04,  8.4839e-03,  ..., -6.3515e-04,
          2.5773e-04,  1.7548e-03],
        ...,
        [ 1.8530e-03, -2.8753e-04, -5.4789e-04,  ...,  6.7520e-03,
         -1.9178e-03,  1.5364e-03],
        [ 3.2158e-03, -8.8644e-04,  6.0511e-04,  ...,  1.9932e-03,
          9.8038e-03, -2.4700e-03],
        [ 5.2109e-03, -8.2874e-04,  2.9545e-03,  ...,  3.7842e-03,
          3.5496e-03,  6.4964e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0109e-02,  4.3869e-05, -7.8812e-03,  ..., -5.6534e-03,
         -1.1063e-02, -4.1161e-03],
        [ 1.2733e-02, -8.6975e-03,  1.1505e-02,  ...,  1.4400e-03,
         -1.4963e-03,  4.6234e-03],
        [-4.5166e-03,  1.4095e-03, -2.3148e-02,  ...,  6.4163e-03,
         -1.1658e-02,  1.8387e-03],
        ...,
        [ 1.5402e-03, -5.5027e-04,  9.6054e-03,  ..., -1.3580e-02,
          1.5087e-03, -1.3687e-02],
        [-1.3435e-02, -4.2648e-03, -2.9106e-03,  ...,  5.5161e-03,
         -8.6746e-03,  8.1015e-04],
        [ 8.6441e-03,  1.1337e-02,  1.0366e-03,  ..., -6.3972e-03,
          6.3324e-03, -8.2474e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0259,  0.0094,  0.0170,  ..., -0.0091,  0.0029, -0.0036],
        [ 0.0035, -0.0424, -0.0148,  ...,  0.0048,  0.0094,  0.0058],
        [ 0.0129, -0.0067, -0.0343,  ..., -0.0064,  0.0083,  0.0149],
        ...,
        [-0.0073, -0.0149, -0.0082,  ..., -0.0455,  0.0100, -0.0025],
        [ 0.0112, -0.0023, -0.0176,  ...,  0.0080, -0.0463, -0.0165],
        [ 0.0185,  0.0132,  0.0041,  ...,  0.0124,  0.0060, -0.0392]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:44:02 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-06-30 23:44:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2869,  0.9756, -0.1432,  ..., -0.5469,  0.4866,  1.3730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5820, -0.1021, -1.1709,  ...,  0.1981,  0.5825,  1.2334],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7129,  2.2090, -0.6689,  ..., -1.2549,  0.9048,  3.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.3076,  1.4707, -3.4336,  ...,  1.9678,  2.5703,  4.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:44:02 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:44:02 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 23:45:15 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 23:46:32 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-06-30 23:47:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.9389e-03,  1.5936e-03,  6.0463e-04,  ..., -1.0300e-03,
         -2.4738e-03, -4.7302e-03],
        [-3.9558e-03,  5.3024e-03,  1.9913e-03,  ..., -1.1331e-04,
         -1.7667e-04,  1.6947e-03],
        [-1.7271e-03,  6.3992e-04,  7.6447e-03,  ..., -3.1433e-03,
         -4.1161e-03, -1.6632e-03],
        ...,
        [-5.4817e-03,  3.2444e-03, -2.9240e-03,  ...,  8.6212e-03,
         -5.0688e-04,  2.9030e-03],
        [-2.8591e-03,  6.0201e-05,  7.9012e-04,  ..., -3.5229e-03,
          1.3208e-03,  2.1219e-04],
        [-6.2523e-03, -1.0786e-03, -1.5173e-03,  ..., -4.5242e-03,
          4.0627e-03,  7.9727e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.2291e-02,  3.7041e-03, -4.9782e-04,  ..., -1.0551e-02,
          4.6196e-03,  9.2468e-03],
        [-9.1019e-03, -1.1971e-02,  1.8349e-03,  ..., -3.2425e-03,
         -1.4029e-03,  9.3460e-03],
        [-1.9817e-03, -9.5062e-03, -4.7798e-03,  ...,  9.6416e-04,
          6.3553e-03,  1.0729e-03],
        ...,
        [-6.2561e-03,  4.5128e-03,  8.2855e-03,  ..., -1.4313e-02,
         -7.3547e-03, -7.4863e-05],
        [ 5.4359e-03,  1.0437e-02,  4.4403e-03,  ...,  4.8561e-03,
         -2.4147e-03,  3.5973e-03],
        [-9.5978e-03, -5.4512e-03, -1.4839e-03,  ...,  1.3916e-02,
         -5.7526e-03, -1.4984e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0461, -0.0003,  0.0012,  ..., -0.0160, -0.0123, -0.0004],
        [-0.0080, -0.0675, -0.0079,  ..., -0.0127, -0.0052, -0.0049],
        [ 0.0069, -0.0127, -0.0345,  ..., -0.0169,  0.0043, -0.0084],
        ...,
        [ 0.0066,  0.0125, -0.0098,  ..., -0.0735,  0.0024, -0.0091],
        [ 0.0107, -0.0168, -0.0029,  ...,  0.0015, -0.0348, -0.0189],
        [-0.0022, -0.0067,  0.0215,  ..., -0.0131,  0.0021, -0.0542]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:47:54 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-06-30 23:47:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5317,  0.8755, -0.3123,  ..., -0.4961,  0.4021,  1.2471],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8564,  0.1484, -1.0518,  ...,  0.4956,  0.8975,  1.3652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2363,  2.1602,  1.1494,  ..., -1.2510,  1.2051,  3.9414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.1797,  1.5225, -2.1719,  ...,  1.1387,  3.1738,  5.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:47:54 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:47:54 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 23:49:15 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 23:50:37 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-06-30 23:51:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5330e-04, -1.1644e-03,  5.6326e-05,  ...,  6.8903e-04,
         -1.3256e-03, -4.0054e-04],
        [-2.1970e-04, -3.9756e-05, -2.4748e-04,  ...,  1.9608e-03,
          1.0103e-04, -1.4839e-03],
        [ 1.8826e-03,  2.1648e-03, -3.7265e-04,  ...,  1.1902e-03,
         -1.3933e-03, -1.2779e-03],
        ...,
        [-6.2141e-03, -2.2602e-04, -1.1635e-04,  ..., -2.8152e-03,
          3.7079e-03,  2.6932e-03],
        [ 1.7576e-03,  8.7643e-04,  1.3065e-03,  ...,  3.1066e-04,
         -1.1501e-03,  6.1941e-04],
        [-1.4029e-03, -1.2884e-03, -1.7815e-03,  ..., -1.7524e-04,
         -4.4823e-05, -3.3522e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0161, -0.0045,  0.0063,  ..., -0.0121, -0.0098, -0.0018],
        [-0.0013, -0.0169, -0.0033,  ...,  0.0015,  0.0030, -0.0067],
        [-0.0023, -0.0083, -0.0044,  ...,  0.0084, -0.0174,  0.0053],
        ...,
        [ 0.0050, -0.0047, -0.0049,  ..., -0.0156,  0.0090,  0.0118],
        [-0.0081,  0.0004,  0.0087,  ...,  0.0044, -0.0060,  0.0028],
        [ 0.0024, -0.0010, -0.0027,  ...,  0.0105,  0.0112,  0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0392,  0.0071,  0.0060,  ..., -0.0015,  0.0117,  0.0030],
        [-0.0079, -0.0479,  0.0036,  ...,  0.0051,  0.0153,  0.0153],
        [-0.0200,  0.0011, -0.0847,  ..., -0.0162,  0.0064,  0.0060],
        ...,
        [ 0.0072,  0.0085,  0.0021,  ..., -0.0767, -0.0048,  0.0017],
        [-0.0036,  0.0234, -0.0169,  ..., -0.0153, -0.0653, -0.0061],
        [-0.0011, -0.0085,  0.0088,  ..., -0.0139,  0.0148, -0.0607]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:51:59 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-06-30 23:51:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6484,  0.7896, -0.2617,  ..., -0.4434,  0.3516,  1.2705],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4565,  0.4817, -1.1406,  ...,  0.6509,  0.8813,  1.4688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0371,  2.3906,  1.5430,  ..., -0.9937,  1.7930,  3.8008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.3535,  2.1582, -2.1445,  ...,  1.9795,  3.4766,  5.3359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:51:59 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:51:59 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 23:53:20 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 23:54:42 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-06-30 23:56:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.5347e-04, -2.3842e-06, -5.8413e-04,  ..., -2.6131e-04,
         -7.9107e-04, -6.7651e-05],
        [-1.2770e-03,  3.1543e-04,  6.7711e-04,  ..., -6.0081e-05,
         -4.8828e-04,  5.0688e-04],
        [-8.8453e-04,  1.5278e-03,  2.7847e-03,  ..., -5.0247e-05,
         -2.5630e-04,  3.4451e-04],
        ...,
        [-2.2054e-04, -1.2817e-03,  4.6444e-04,  ...,  8.8549e-04,
          1.7476e-04, -5.9271e-04],
        [-1.0691e-03,  3.6287e-04,  4.8614e-04,  ..., -4.3964e-04,
         -1.8418e-04,  7.9536e-04],
        [-1.1997e-03,  1.3089e-04,  8.4686e-04,  ..., -3.3855e-04,
          2.6345e-04, -2.5988e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0011,  0.0033, -0.0090,  ..., -0.0100, -0.0053, -0.0029],
        [ 0.0174, -0.0019,  0.0110,  ...,  0.0088, -0.0025,  0.0026],
        [ 0.0019,  0.0111,  0.0056,  ..., -0.0098,  0.0157, -0.0005],
        ...,
        [ 0.0010, -0.0055, -0.0103,  ...,  0.0037,  0.0073, -0.0109],
        [ 0.0020, -0.0212,  0.0010,  ..., -0.0021,  0.0015,  0.0016],
        [ 0.0183, -0.0084,  0.0007,  ..., -0.0149,  0.0085, -0.0134]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0520,  0.0013,  0.0043,  ...,  0.0025,  0.0283,  0.0088],
        [-0.0052, -0.0458, -0.0062,  ...,  0.0163, -0.0141,  0.0015],
        [-0.0053,  0.0187, -0.0575,  ..., -0.0016, -0.0092,  0.0050],
        ...,
        [ 0.0248,  0.0050,  0.0014,  ..., -0.0421, -0.0092, -0.0138],
        [-0.0006,  0.0050,  0.0040,  ..., -0.0113, -0.0704, -0.0046],
        [ 0.0026,  0.0016,  0.0028,  ..., -0.0264,  0.0271, -0.0448]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-06-30 23:56:02 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-06-30 23:56:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7837,  0.7407,  0.3440,  ..., -0.4287,  0.4285,  1.3506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7080,  0.4927, -0.7300,  ...,  0.3467,  1.0283,  1.6035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5879,  2.2012,  2.0273,  ..., -0.6655,  1.7969,  3.9512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6953,  1.7422, -2.4473,  ...,  2.6562,  4.6523,  6.2734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-06-30 23:56:02 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-06-30 23:56:02 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 23:57:27 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-06-30 23:58:51 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 00:00:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.7629e-03, -2.0838e-04, -7.0333e-04,  ...,  5.6267e-04,
          7.8964e-04,  2.2526e-03],
        [ 2.8467e-04,  5.2719e-03, -7.7486e-06,  ..., -1.0719e-03,
         -6.7353e-05, -1.5869e-03],
        [ 3.9339e-04, -1.9789e-05,  7.5836e-03,  ..., -1.0624e-03,
          6.4993e-04,  2.3186e-05],
        ...,
        [ 3.8362e-04,  4.7183e-04,  6.1274e-04,  ...,  1.0063e-02,
         -2.4676e-04, -9.5654e-04],
        [ 4.6992e-04,  7.9441e-04, -4.8256e-04,  ...,  1.8730e-03,
          9.6054e-03, -2.0142e-03],
        [ 7.7486e-04, -2.6073e-03, -5.5885e-04,  ...,  1.1492e-03,
         -3.9935e-04,  1.0666e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0298, -0.0157, -0.0088,  ...,  0.0005, -0.0046, -0.0020],
        [-0.0032,  0.0094,  0.0047,  ..., -0.0033,  0.0009,  0.0096],
        [ 0.0005, -0.0061,  0.0476,  ..., -0.0097, -0.0028, -0.0044],
        ...,
        [-0.0115, -0.0017, -0.0081,  ...,  0.0390, -0.0032, -0.0053],
        [ 0.0003, -0.0074, -0.0094,  ...,  0.0119,  0.0376, -0.0122],
        [-0.0206,  0.0063, -0.0017,  ..., -0.0021, -0.0036,  0.0495]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0161, -0.0231,  0.0014,  ...,  0.0077, -0.0121,  0.0136],
        [-0.0059, -0.0083,  0.0148,  ..., -0.0011,  0.0029,  0.0129],
        [-0.0004,  0.0135,  0.0493,  ..., -0.0055, -0.0023, -0.0013],
        ...,
        [-0.0148, -0.0135, -0.0382,  ...,  0.0280,  0.0011, -0.0005],
        [ 0.0206, -0.0101, -0.0005,  ...,  0.0102,  0.0263, -0.0114],
        [-0.0061,  0.0240,  0.0056,  ...,  0.0104,  0.0013,  0.0115]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:00:08 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 00:00:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6875,  0.7632,  0.4436,  ..., -0.3535,  0.5747,  1.2158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7524,  0.6582, -0.7153,  ...,  0.5640,  1.0605,  1.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4316,  2.3906,  1.3232,  ..., -0.4355,  1.3291,  4.7266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0293,  2.9805, -1.7119,  ...,  2.3320,  5.1836,  7.5742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:00:08 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-07-01 00:00:08 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 00:01:26 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 00:02:44 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 00:04:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.1357e-03, -8.6164e-04,  2.4891e-04,  ..., -2.0814e-04,
          8.3303e-04,  3.1567e-04],
        [-3.5119e-04,  1.3504e-03,  9.4938e-04,  ..., -1.9226e-03,
          3.5286e-04, -2.9230e-04],
        [-2.9588e-04, -4.1914e-04,  2.9335e-03,  ..., -7.6890e-05,
          2.8014e-04, -1.6689e-04],
        ...,
        [ 1.9383e-04, -5.9080e-04, -4.7016e-04,  ...,  2.8362e-03,
          5.4836e-04, -2.8014e-06],
        [ 5.7030e-04,  3.0327e-04,  2.0742e-05,  ...,  2.2101e-04,
          2.3308e-03,  1.0777e-04],
        [ 8.7643e-04,  3.1114e-04,  5.3596e-04,  ...,  4.3094e-05,
         -9.0003e-05,  3.3226e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0051, -0.0121,  0.0077,  ..., -0.0146, -0.0026,  0.0026],
        [ 0.0048,  0.0132, -0.0026,  ...,  0.0052, -0.0009, -0.0009],
        [ 0.0054,  0.0018,  0.0115,  ..., -0.0183,  0.0035, -0.0025],
        ...,
        [ 0.0109,  0.0200,  0.0026,  ...,  0.0229,  0.0024, -0.0057],
        [ 0.0058,  0.0113,  0.0010,  ..., -0.0063, -0.0037,  0.0082],
        [-0.0088,  0.0085, -0.0060,  ...,  0.0057,  0.0028,  0.0077]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.6978e-02, -7.3586e-03,  2.1801e-03,  ...,  9.9411e-03,
         -2.3987e-02,  5.5046e-03],
        [-8.7547e-04, -4.4281e-02,  1.3046e-02,  ..., -5.3253e-03,
          1.4198e-02, -1.2314e-02],
        [ 5.9242e-03, -4.7836e-03, -2.6245e-02,  ..., -5.8594e-03,
         -1.4603e-02,  7.7286e-03],
        ...,
        [-9.9716e-03,  1.9882e-02, -4.3716e-03,  ..., -4.2419e-02,
         -1.8677e-02,  5.1880e-04],
        [ 1.0574e-02,  1.8478e-02,  2.6703e-05,  ..., -9.3536e-03,
         -3.6987e-02,  9.1629e-03],
        [ 2.2293e-02,  4.5319e-03, -4.5700e-03,  ..., -2.8229e-03,
         -4.3297e-03, -2.5345e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:04:06 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 00:04:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5347,  0.6650,  0.5117,  ..., -0.2939,  0.5059,  1.1436],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5635,  0.5283, -0.8037,  ...,  0.6797,  1.3408,  1.8350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.9453,  2.3730,  0.1025,  ..., -0.9736,  0.8188,  3.9434],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2825,  3.3809, -2.5273,  ...,  1.7012,  5.2461,  6.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:04:07 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-07-01 00:04:07 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 00:05:26 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 00:06:45 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 00:08:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.7215e-03, -1.9026e-04, -3.3140e-04,  ..., -2.4772e-04,
         -2.0111e-04, -5.3549e-04],
        [ 1.2016e-03,  4.3297e-03,  2.4307e-04,  ...,  3.9649e-04,
          7.1192e-04,  2.2829e-04],
        [ 6.7234e-04, -1.0242e-03,  5.6534e-03,  ..., -2.9492e-04,
         -1.3676e-03,  3.3379e-04],
        ...,
        [-4.9925e-04, -4.0472e-05, -2.3246e-04,  ...,  8.2169e-03,
         -2.5249e-04, -1.4219e-03],
        [-1.5616e-04, -3.1710e-04, -2.0409e-04,  ...,  2.5964e-04,
          7.6218e-03, -5.6028e-04],
        [ 8.9169e-04,  4.9543e-04, -5.8222e-04,  ..., -3.9196e-04,
          3.2902e-04,  7.7553e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0316, -0.0067, -0.0150,  ..., -0.0015, -0.0081, -0.0135],
        [ 0.0113, -0.0025, -0.0023,  ..., -0.0151,  0.0104, -0.0088],
        [-0.0112, -0.0101,  0.0191,  ...,  0.0061, -0.0045, -0.0075],
        ...,
        [-0.0040,  0.0045, -0.0052,  ...,  0.0472, -0.0164,  0.0086],
        [-0.0061, -0.0180, -0.0014,  ..., -0.0204,  0.0268,  0.0200],
        [-0.0008,  0.0360,  0.0029,  ..., -0.0087,  0.0169,  0.0394]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.7487e-03,  5.1765e-03,  2.5597e-03,  ..., -1.3817e-02,
          4.9515e-03, -1.8951e-02],
        [ 1.5121e-02, -2.0508e-02, -2.4094e-02,  ..., -9.2010e-03,
          1.1650e-02, -4.2343e-03],
        [-3.5522e-02,  5.9509e-03,  4.7379e-03,  ...,  4.9210e-03,
          2.8793e-02,  1.4420e-03],
        ...,
        [ 3.0193e-03, -8.1406e-03,  1.1826e-03,  ...,  9.3918e-03,
          9.8724e-03,  5.5847e-03],
        [-1.0651e-02, -8.4229e-03,  1.3084e-03,  ..., -1.7227e-02,
         -8.3160e-03,  2.5482e-02],
        [-8.5068e-03,  1.6663e-02,  1.4282e-02,  ..., -6.0501e-03,
          8.1062e-05, -2.9907e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:08:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To aspire results in aspiration
To restore results in restoration
To illumine results in illumination
To standardize results in standardization
To optimize results in optimization
To minimize results in minimization
To randomize results in
2024-07-01 00:08:09 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 00:08:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0823, -0.2101,  0.1987,  ..., -0.5952, -0.5669,  0.5122],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1023,  0.2698, -0.3508,  ..., -0.3977, -0.2305, -0.0891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1610, -0.3748, -0.2231,  ..., -0.0847, -0.5933,  0.3296],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0046e-01,  5.3809e-01, -6.1035e-05,  ...,  2.3096e-01,
        -2.4487e-01,  1.7261e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:08:09 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:08:09 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 00:08:32 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 00:08:55 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 00:09:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0121,  0.0028, -0.0006,  ..., -0.0016,  0.0023, -0.0010],
        [-0.0004, -0.0117, -0.0012,  ...,  0.0009, -0.0031,  0.0021],
        [-0.0015,  0.0007, -0.0119,  ...,  0.0021, -0.0011, -0.0004],
        ...,
        [ 0.0007, -0.0008, -0.0007,  ..., -0.0102,  0.0010,  0.0018],
        [-0.0019, -0.0010,  0.0005,  ..., -0.0011, -0.0117,  0.0020],
        [-0.0009, -0.0008, -0.0011,  ..., -0.0005,  0.0018, -0.0120]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0342,  0.0028,  0.0030,  ..., -0.0103, -0.0093,  0.0023],
        [-0.0104, -0.0303, -0.0026,  ...,  0.0073,  0.0054, -0.0001],
        [ 0.0037,  0.0055, -0.0190,  ..., -0.0078,  0.0055, -0.0003],
        ...,
        [-0.0018, -0.0020, -0.0081,  ..., -0.0314, -0.0085, -0.0097],
        [-0.0031, -0.0038, -0.0016,  ..., -0.0082, -0.0220,  0.0107],
        [-0.0054,  0.0014,  0.0006,  ..., -0.0033, -0.0012, -0.0227]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0354,  0.0035, -0.0060,  ..., -0.0030, -0.0023,  0.0027],
        [ 0.0028, -0.0412, -0.0009,  ...,  0.0070,  0.0019, -0.0029],
        [-0.0027,  0.0005, -0.0418,  ...,  0.0023,  0.0037,  0.0019],
        ...,
        [-0.0019,  0.0056,  0.0005,  ..., -0.0397, -0.0011,  0.0002],
        [-0.0027,  0.0011,  0.0012,  ..., -0.0011, -0.0380,  0.0049],
        [-0.0010, -0.0026, -0.0016,  ...,  0.0009,  0.0047, -0.0352]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:09:20 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 00:09:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0442, -0.0152, -0.0569,  ..., -0.1843, -0.2983,  0.4846],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1147,  0.2788, -0.0211,  ..., -0.2396, -0.1674, -0.1622],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1946, -0.0144, -0.2681,  ..., -0.2124, -0.6284,  0.1594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2603,  0.5161,  0.0172,  ..., -0.2935, -0.3074,  0.3936],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:09:20 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:09:20 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 00:09:44 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 00:10:08 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 00:10:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6617e-02, -1.1692e-03, -1.7643e-04,  ..., -7.1430e-04,
         -1.2255e-03,  8.1682e-04],
        [ 8.0967e-04, -2.1927e-02,  3.6645e-04,  ...,  1.9798e-03,
         -8.2588e-04,  1.0672e-03],
        [ 4.0770e-04,  2.4357e-03, -1.9501e-02,  ..., -1.5330e-04,
         -4.6611e-05,  7.3814e-04],
        ...,
        [ 1.2379e-03,  4.7493e-03, -5.3596e-04,  ..., -1.8005e-02,
         -3.2787e-03, -2.3150e-04],
        [-1.2798e-03,  1.7285e-04, -1.0252e-03,  ...,  4.7970e-04,
         -1.4641e-02, -4.1351e-03],
        [-2.0266e-05, -2.4033e-03, -1.8063e-03,  ...,  2.5129e-04,
          1.2188e-03, -1.9516e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0517,  0.0059, -0.0063,  ...,  0.0031,  0.0070,  0.0021],
        [ 0.0038, -0.0628, -0.0066,  ...,  0.0021, -0.0035,  0.0005],
        [-0.0058, -0.0033, -0.0548,  ..., -0.0035, -0.0081, -0.0126],
        ...,
        [ 0.0122,  0.0079, -0.0054,  ..., -0.0492, -0.0023,  0.0071],
        [-0.0018, -0.0094,  0.0096,  ...,  0.0005, -0.0501, -0.0080],
        [-0.0045,  0.0033,  0.0053,  ...,  0.0014,  0.0025, -0.0608]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0730,  0.0052,  0.0002,  ...,  0.0039, -0.0033,  0.0040],
        [ 0.0069, -0.0738, -0.0026,  ...,  0.0020,  0.0020, -0.0046],
        [-0.0030, -0.0039, -0.0685,  ..., -0.0039,  0.0038, -0.0004],
        ...,
        [ 0.0041, -0.0019,  0.0033,  ..., -0.0736, -0.0030,  0.0007],
        [-0.0059, -0.0027,  0.0076,  ...,  0.0039, -0.0649, -0.0011],
        [ 0.0005,  0.0002,  0.0055,  ...,  0.0034, -0.0024, -0.0771]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:10:34 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 00:10:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1921, -0.5249, -0.2947,  ..., -0.1053, -0.7656,  0.4219],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1495,  0.8999, -0.0037,  ...,  0.3699, -0.4036,  0.2744],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0974,  0.0633,  0.2205,  ...,  0.0264, -0.8789,  0.4480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0417,  0.3684, -0.2986,  ..., -0.3369, -0.8984,  0.6865],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:10:34 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:10:34 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 00:10:59 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 00:11:22 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 00:11:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.5613e-03, -1.4896e-03, -4.4990e-04,  ...,  3.9101e-04,
         -1.0672e-03, -2.6646e-03],
        [-5.2691e-04, -6.0272e-03, -9.9087e-04,  ..., -1.2946e-04,
         -1.2550e-03,  7.1812e-04],
        [ 1.2779e-03, -7.7534e-04, -4.2534e-03,  ..., -2.6107e-04,
          1.6689e-03,  5.5361e-04],
        ...,
        [ 1.0042e-03,  3.8218e-04, -1.1368e-03,  ..., -6.5880e-03,
          1.3094e-03,  2.3956e-03],
        [-4.1342e-04, -9.1219e-04,  2.0351e-03,  ..., -4.1866e-04,
         -5.0354e-03, -5.3704e-05],
        [ 2.7418e-04,  1.2331e-03,  1.4305e-03,  ..., -1.2922e-04,
         -1.5593e-04, -5.1270e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0265, -0.0082,  0.0023,  ...,  0.0031,  0.0005, -0.0044],
        [-0.0059, -0.0343,  0.0076,  ...,  0.0069,  0.0050, -0.0042],
        [-0.0072,  0.0035, -0.0370,  ..., -0.0054,  0.0133,  0.0018],
        ...,
        [-0.0067, -0.0048,  0.0014,  ..., -0.0450, -0.0040,  0.0084],
        [ 0.0106,  0.0004,  0.0014,  ..., -0.0041, -0.0403, -0.0013],
        [-0.0008, -0.0060,  0.0044,  ..., -0.0050,  0.0078, -0.0293]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0304,  0.0026, -0.0021,  ..., -0.0026,  0.0004, -0.0046],
        [-0.0065, -0.0375,  0.0084,  ...,  0.0027, -0.0030,  0.0021],
        [ 0.0036,  0.0027, -0.0300,  ...,  0.0022, -0.0027,  0.0017],
        ...,
        [-0.0070,  0.0010, -0.0022,  ..., -0.0370, -0.0054, -0.0042],
        [ 0.0019,  0.0010,  0.0027,  ...,  0.0043, -0.0320,  0.0027],
        [ 0.0005, -0.0037, -0.0015,  ..., -0.0042,  0.0076, -0.0346]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:11:49 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 00:11:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2267, -0.0428, -0.3303,  ..., -0.2539, -0.7979,  0.1714],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4058,  0.8306,  0.0306,  ..., -0.4504, -0.5049,  0.6221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0148,  0.1173,  0.5771,  ...,  0.2004, -0.9268,  0.6338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1123,  0.2266, -0.2285,  ..., -0.3777, -0.3809,  0.6274],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:11:49 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:11:49 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 00:12:18 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 00:12:48 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 00:13:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.9526e-03,  1.6718e-03,  9.9564e-04,  ...,  1.8654e-03,
         -1.0891e-03,  3.4118e-04],
        [-5.7936e-04, -2.8152e-03, -2.9659e-03,  ...,  1.6899e-03,
          6.0749e-04, -1.6365e-03],
        [-6.4802e-04, -1.9989e-03, -3.1967e-03,  ..., -1.5240e-03,
          2.0885e-03, -1.4706e-03],
        ...,
        [ 6.2943e-05, -1.2951e-03,  3.0518e-04,  ..., -2.8610e-03,
          8.1062e-04,  1.1969e-03],
        [-8.4925e-04, -1.0910e-03,  6.8951e-04,  ..., -1.3266e-03,
         -1.7929e-03, -3.9601e-04],
        [-6.7186e-04, -2.2087e-03,  1.0085e-04,  ..., -1.2913e-03,
         -1.8997e-03, -3.0556e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.0171e-02,  9.0942e-03,  3.0785e-03,  ...,  6.0959e-03,
         -4.4022e-03, -3.2425e-04],
        [-1.0300e-03, -4.8187e-02, -8.2321e-03,  ...,  2.2030e-03,
          4.3225e-04,  1.9159e-03],
        [ 2.6245e-03,  1.7138e-03, -4.6509e-02,  ...,  6.4697e-03,
         -3.0937e-03,  1.0223e-02],
        ...,
        [ 4.9133e-03,  1.9073e-05,  1.4553e-03,  ..., -5.4016e-02,
         -8.3771e-03, -7.2594e-03],
        [-1.3107e-02, -1.6815e-02, -8.8959e-03,  ..., -6.4316e-03,
         -3.3142e-02, -3.5915e-03],
        [ 1.1759e-03, -1.0242e-03, -1.1721e-03,  ...,  5.3291e-03,
         -3.7308e-03, -5.1605e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0450, -0.0047, -0.0009,  ..., -0.0064, -0.0002,  0.0034],
        [ 0.0114, -0.0393, -0.0050,  ...,  0.0049,  0.0061, -0.0061],
        [-0.0009, -0.0105, -0.0465,  ...,  0.0029, -0.0021, -0.0023],
        ...,
        [-0.0059,  0.0008,  0.0066,  ..., -0.0519, -0.0020, -0.0103],
        [-0.0024, -0.0008, -0.0005,  ...,  0.0006, -0.0446,  0.0018],
        [-0.0098, -0.0023, -0.0092,  ...,  0.0069,  0.0014, -0.0524]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:13:20 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 00:13:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1128,  0.0200,  0.2217,  ...,  0.0164, -0.8770,  0.4363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0638,  0.4304, -0.3521,  ..., -0.4019, -1.0928,  0.8452],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4819,  0.2812,  0.4448,  ..., -0.2166, -0.4536,  0.1863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0865,  0.0085,  0.3813,  ..., -0.3889, -0.3958,  0.1870],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:13:20 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:13:20 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 00:13:54 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 00:14:28 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 00:14:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8597e-03,  5.2214e-04, -8.0490e-04,  ...,  9.6512e-04,
          6.9714e-04, -6.7806e-04],
        [ 1.8854e-03,  1.4963e-03,  8.9312e-04,  ..., -1.1501e-03,
         -3.6192e-04,  1.6546e-03],
        [ 1.9512e-03, -1.6041e-03,  1.1520e-03,  ..., -1.3418e-03,
          6.2561e-04,  7.5150e-04],
        ...,
        [-7.6294e-04,  3.8910e-04,  1.6093e-05,  ...,  2.9793e-03,
          1.0157e-03, -7.2956e-04],
        [-1.7433e-03, -9.0361e-04, -7.2670e-04,  ..., -2.5296e-04,
          4.7188e-03, -4.8137e-04],
        [-2.7418e-04, -1.2779e-04, -1.6336e-03,  ...,  4.0793e-04,
          1.0118e-03,  2.3901e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0884, -0.0027, -0.0013,  ..., -0.0059, -0.0069,  0.0046],
        [-0.0069, -0.0917, -0.0062,  ...,  0.0063,  0.0110,  0.0177],
        [-0.0110, -0.0149, -0.0953,  ...,  0.0060,  0.0079,  0.0069],
        ...,
        [-0.0056, -0.0034, -0.0142,  ..., -0.0854, -0.0056,  0.0109],
        [ 0.0086,  0.0009,  0.0135,  ...,  0.0058, -0.0862,  0.0111],
        [-0.0147,  0.0104, -0.0073,  ...,  0.0048,  0.0054, -0.1100]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.3506e-02, -1.3638e-03,  3.3264e-03,  ..., -1.5755e-03,
         -5.2948e-03, -3.0403e-03],
        [-8.6288e-03, -8.5571e-02,  3.4447e-03,  ...,  5.7449e-03,
          1.2388e-03,  2.3232e-03],
        [-3.2043e-03,  5.2490e-03, -8.0139e-02,  ...,  3.0403e-03,
          1.0139e-02,  2.7866e-03],
        ...,
        [-8.5831e-05, -4.7493e-03, -4.7493e-03,  ..., -8.7524e-02,
         -3.1109e-03,  4.2877e-03],
        [-2.8381e-03, -3.9253e-03,  5.3787e-03,  ..., -6.6299e-03,
         -8.2458e-02,  7.4539e-03],
        [ 2.8400e-03,  5.3253e-03,  2.1076e-04,  ..., -1.0254e-02,
          3.2806e-03, -1.0291e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:15:01 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 00:15:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0175,  0.1014,  0.5283,  ...,  0.1927, -0.9116,  0.6104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1362,  0.2610, -0.2693,  ..., -0.4255, -0.4641,  0.7402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8174,  0.0927,  0.2310,  ...,  0.1624, -0.0405, -0.5332],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2081, -0.0498, -0.1904,  ..., -0.0906, -0.4961, -0.7349],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:15:01 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:15:01 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 00:15:38 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 00:16:15 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 00:16:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.8092e-03, -1.0357e-03,  1.6623e-03,  ...,  1.2646e-03,
          1.2093e-03,  6.5804e-04],
        [ 1.6060e-03, -7.1907e-03,  1.2302e-03,  ...,  3.3398e-03,
          4.3750e-04, -8.9359e-04],
        [ 6.5756e-04,  5.3062e-03, -6.7902e-03,  ..., -9.6130e-04,
         -5.3406e-05, -2.4700e-03],
        ...,
        [ 1.9550e-04, -1.2016e-03,  2.8038e-03,  ..., -4.5204e-03,
         -2.4891e-03, -6.7139e-04],
        [ 3.4065e-03,  1.3638e-03, -6.5899e-04,  ..., -4.0054e-03,
         -2.1858e-03,  1.9445e-03],
        [ 2.1858e-03,  1.1129e-03,  6.0797e-05,  ...,  2.3317e-04,
         -5.2567e-03, -2.9945e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1032,  0.0191,  0.0038,  ...,  0.0027,  0.0169, -0.0036],
        [-0.0056, -0.1242,  0.0101,  ...,  0.0090, -0.0024,  0.0020],
        [ 0.0032,  0.0211, -0.1169,  ..., -0.0010, -0.0008, -0.0038],
        ...,
        [ 0.0177,  0.0002,  0.0107,  ..., -0.1055,  0.0079,  0.0008],
        [-0.0028, -0.0113,  0.0041,  ...,  0.0037, -0.0969, -0.0027],
        [ 0.0026,  0.0019, -0.0147,  ..., -0.0083, -0.0040, -0.1043]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0923, -0.0007,  0.0029,  ..., -0.0064, -0.0048, -0.0007],
        [-0.0004, -0.0924, -0.0022,  ..., -0.0033, -0.0059,  0.0036],
        [-0.0118,  0.0007, -0.0844,  ..., -0.0046, -0.0005, -0.0107],
        ...,
        [ 0.0092,  0.0070,  0.0072,  ..., -0.0906, -0.0050, -0.0058],
        [ 0.0003, -0.0009, -0.0135,  ..., -0.0031, -0.0820,  0.0053],
        [-0.0054,  0.0052, -0.0136,  ..., -0.0039, -0.0009, -0.0953]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:16:47 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 00:16:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4463,  0.2805,  0.3723,  ..., -0.2172, -0.4250,  0.1418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0922,  0.0208,  0.3523,  ..., -0.4016, -0.4072,  0.1626],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2158, -0.2064, -0.0671,  ..., -0.0385, -0.1821, -0.5908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.3247, -0.4646, -0.4189,  ...,  0.0601, -0.2827, -1.1758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:16:48 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:16:48 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 00:17:23 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 00:18:00 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 00:18:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.0648e-03,  4.6310e-03, -2.4147e-03,  ..., -1.1930e-03,
         -1.1015e-03, -2.7218e-03],
        [-1.2803e-04, -1.3332e-03, -3.1071e-03,  ...,  4.5300e-04,
         -7.5197e-04,  3.9518e-05],
        [ 5.2338e-03, -1.1597e-03, -2.4548e-03,  ..., -1.9073e-03,
         -6.7949e-04, -1.6356e-03],
        ...,
        [ 7.4863e-04, -1.5140e-04, -4.1485e-04,  ..., -3.5095e-03,
          2.4223e-03,  3.0708e-03],
        [-1.7147e-03, -1.8902e-03, -1.5020e-03,  ...,  1.2350e-04,
         -2.1267e-04, -7.6771e-05],
        [ 5.1880e-03, -1.0033e-03, -8.4352e-04,  ...,  1.1005e-03,
          8.5068e-03, -5.6229e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0829, -0.0035, -0.0106,  ..., -0.0148, -0.0115, -0.0019],
        [-0.0004, -0.0851, -0.0121,  ...,  0.0060,  0.0049,  0.0087],
        [-0.0073, -0.0045, -0.0959,  ..., -0.0045, -0.0035,  0.0080],
        ...,
        [-0.0106,  0.0037,  0.0095,  ..., -0.0916, -0.0009, -0.0003],
        [ 0.0053, -0.0035,  0.0028,  ...,  0.0100, -0.0894,  0.0019],
        [-0.0028, -0.0022,  0.0091,  ...,  0.0123,  0.0043, -0.0934]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1025, -0.0003,  0.0128,  ..., -0.0051, -0.0029,  0.0047],
        [ 0.0095, -0.0920, -0.0091,  ...,  0.0033,  0.0019,  0.0050],
        [ 0.0060, -0.0063, -0.0902,  ...,  0.0098, -0.0010,  0.0134],
        ...,
        [ 0.0046,  0.0017, -0.0031,  ..., -0.0967,  0.0168, -0.0046],
        [ 0.0058,  0.0091,  0.0019,  ..., -0.0002, -0.0949, -0.0079],
        [-0.0043, -0.0058,  0.0094,  ..., -0.0032, -0.0002, -0.1007]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:18:41 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 00:18:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7056,  0.0714,  0.1748,  ...,  0.1252, -0.0420, -0.4885],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2021, -0.0570, -0.1813,  ..., -0.0815, -0.4617, -0.7295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4785,  0.0978,  0.2842,  ..., -0.3159,  0.0186, -0.4521],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7500, -0.9629, -1.1221,  ..., -0.1938, -1.0625, -0.6704],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:18:41 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:18:41 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 00:19:21 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 00:19:59 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 00:20:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0049, -0.0016, -0.0023,  ...,  0.0015,  0.0011, -0.0022],
        [-0.0023, -0.0052,  0.0009,  ..., -0.0038,  0.0003, -0.0005],
        [-0.0017,  0.0003, -0.0060,  ...,  0.0031,  0.0017, -0.0001],
        ...,
        [-0.0010, -0.0004, -0.0014,  ..., -0.0052,  0.0022,  0.0007],
        [ 0.0002, -0.0016,  0.0025,  ...,  0.0006, -0.0063, -0.0033],
        [ 0.0033,  0.0027,  0.0011,  ...,  0.0011, -0.0003, -0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1111,  0.0044, -0.0140,  ..., -0.0015,  0.0022,  0.0059],
        [ 0.0024, -0.1268,  0.0103,  ...,  0.0217, -0.0083,  0.0036],
        [ 0.0050, -0.0029, -0.1036,  ...,  0.0062, -0.0040, -0.0183],
        ...,
        [-0.0042,  0.0056,  0.0026,  ..., -0.1072, -0.0065, -0.0068],
        [-0.0111,  0.0053,  0.0043,  ..., -0.0012, -0.1102, -0.0007],
        [ 0.0159,  0.0088, -0.0136,  ..., -0.0069, -0.0048, -0.1092]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1194,  0.0203, -0.0086,  ..., -0.0177,  0.0072, -0.0063],
        [-0.0053, -0.1108,  0.0116,  ..., -0.0030, -0.0066,  0.0079],
        [ 0.0045, -0.0062, -0.1125,  ..., -0.0020, -0.0017,  0.0162],
        ...,
        [ 0.0012,  0.0001, -0.0023,  ..., -0.0972, -0.0080, -0.0007],
        [-0.0118,  0.0073, -0.0050,  ...,  0.0003, -0.1027,  0.0079],
        [ 0.0007, -0.0076, -0.0112,  ..., -0.0082,  0.0058, -0.1190]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:20:42 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 00:20:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9082, -0.1652, -0.1011,  ..., -0.0485, -0.1515, -0.4778],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2522, -0.3972, -0.3833,  ...,  0.0271, -0.2434, -1.0146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2764,  0.7847,  0.3562,  ..., -0.0366,  0.4932, -0.8784],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0986, -0.8970, -0.8750,  ...,  0.2136, -0.8154, -0.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:20:42 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:20:42 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 00:21:29 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 00:22:17 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 00:23:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.3151e-03,  5.1422e-03, -1.2074e-03,  ..., -2.8343e-03,
         -1.2894e-03, -1.1921e-05],
        [ 3.7804e-03,  1.8730e-03, -3.1967e-03,  ...,  1.4763e-03,
         -5.2948e-03,  4.1847e-03],
        [-2.0752e-03,  9.6321e-05,  7.8506e-03,  ..., -2.0142e-03,
          1.8663e-03, -3.0708e-03],
        ...,
        [ 1.0223e-03, -1.5259e-03, -4.0588e-03,  ...,  5.8022e-03,
         -1.5621e-03,  6.8331e-04],
        [-2.9907e-03,  1.3247e-03,  4.9934e-03,  ..., -6.1512e-04,
          1.0643e-03,  2.1076e-03],
        [ 3.0231e-03, -2.7084e-03,  3.4428e-04,  ..., -2.6245e-03,
         -1.0133e-04,  3.8719e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1208, -0.0150, -0.0097,  ...,  0.0051,  0.0100, -0.0063],
        [ 0.0006, -0.1134, -0.0081,  ..., -0.0042, -0.0048,  0.0074],
        [-0.0024,  0.0153, -0.1250,  ...,  0.0080,  0.0123,  0.0027],
        ...,
        [-0.0031,  0.0016,  0.0172,  ..., -0.1166,  0.0028, -0.0005],
        [ 0.0048, -0.0035,  0.0065,  ..., -0.0133, -0.1338,  0.0191],
        [-0.0033, -0.0099,  0.0016,  ...,  0.0026,  0.0184, -0.1179]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.4465e-01, -1.8646e-02, -2.0742e-04,  ...,  1.2329e-02,
          1.0086e-02,  1.2245e-03],
        [-4.3297e-04, -1.7261e-01,  1.2589e-03,  ...,  4.4289e-03,
         -1.9241e-02,  5.5885e-04],
        [-5.2719e-03,  1.4687e-04, -1.3318e-01,  ...,  1.3161e-02,
          1.9445e-03, -1.0826e-02],
        ...,
        [-1.8066e-02,  1.2863e-02,  6.1340e-03,  ..., -1.6028e-01,
         -3.2864e-03,  6.8130e-03],
        [ 1.1337e-02, -2.0733e-03,  2.0714e-03,  ...,  7.7629e-03,
         -1.5662e-01, -5.2948e-03],
        [-1.0582e-02,  1.0178e-02, -1.2932e-02,  ..., -1.2421e-02,
         -8.3008e-03, -1.5662e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:23:02 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 00:23:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0684,  0.0529,  0.1555,  ..., -0.2056, -0.0038, -0.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5796, -0.7583, -0.8550,  ..., -0.1294, -0.8076, -0.5640],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7832,  0.4607,  0.0967,  ..., -0.2437,  0.6919, -0.3638],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6328, -0.5039, -0.1558,  ..., -0.3635, -0.7207,  0.5938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:23:02 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:23:02 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 00:23:53 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 00:24:44 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 00:25:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1024e-02, -2.8849e-04,  2.9163e-03,  ...,  1.2779e-03,
          4.0398e-03,  1.7729e-03],
        [ 1.7500e-03, -7.8125e-03,  2.9106e-03,  ...,  3.4046e-03,
          2.0084e-03,  3.8586e-03],
        [ 1.2722e-03, -5.1308e-03, -8.1406e-03,  ..., -3.8948e-03,
         -4.6120e-03, -2.9068e-03],
        ...,
        [ 1.0481e-03, -1.3828e-03,  1.1902e-03,  ..., -6.2256e-03,
         -2.7905e-03, -7.2360e-05],
        [ 1.8616e-03, -4.6539e-03,  1.3685e-04,  ...,  2.7008e-03,
         -6.5193e-03,  2.8610e-03],
        [-1.4696e-03,  2.3022e-03, -1.9245e-03,  ...,  1.9236e-03,
         -2.6894e-03, -5.5656e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1115,  0.0110, -0.0008,  ...,  0.0086, -0.0125, -0.0100],
        [-0.0021, -0.1174,  0.0024,  ..., -0.0069, -0.0065, -0.0037],
        [ 0.0004, -0.0018, -0.0980,  ..., -0.0019, -0.0011,  0.0076],
        ...,
        [ 0.0021, -0.0002, -0.0058,  ..., -0.0951,  0.0026, -0.0133],
        [-0.0016,  0.0091,  0.0038,  ...,  0.0154, -0.1053,  0.0026],
        [ 0.0058, -0.0014,  0.0003,  ..., -0.0057, -0.0064, -0.0978]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1215,  0.0278,  0.0066,  ..., -0.0053, -0.0116,  0.0065],
        [ 0.0031, -0.1074, -0.0052,  ...,  0.0034, -0.0047, -0.0116],
        [-0.0046,  0.0095, -0.1116,  ...,  0.0056, -0.0071,  0.0047],
        ...,
        [-0.0004, -0.0071, -0.0085,  ..., -0.1021,  0.0034, -0.0107],
        [-0.0085, -0.0069, -0.0035,  ...,  0.0009, -0.1217,  0.0161],
        [ 0.0060,  0.0007,  0.0058,  ...,  0.0088, -0.0061, -0.1201]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:25:35 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 00:25:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8247,  0.5034,  0.1732,  ..., -0.0576,  0.2927, -0.5854],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7534, -0.6553, -0.6206,  ...,  0.1080, -0.5732, -0.1772],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.7256e-01,  1.2246e+00,  5.9204e-02,  ..., -4.3286e-01,
         6.2891e-01,  7.3242e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0908, -0.4021, -0.5151,  ..., -0.5400, -0.3315,  0.0581],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:25:35 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:25:35 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 00:26:28 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 00:27:22 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 00:28:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.5763e-06, -3.4618e-03, -1.6403e-03,  ..., -2.6093e-03,
          6.1512e-04,  1.5669e-03],
        [ 2.3270e-03,  2.9583e-03,  4.0770e-05,  ...,  8.8882e-04,
          4.5180e-04,  1.0290e-03],
        [-2.2335e-03,  2.0623e-04,  3.1948e-03,  ..., -8.0872e-04,
          1.6356e-03,  5.9605e-05],
        ...,
        [-6.6280e-04,  1.8177e-03,  4.3602e-03,  ...,  1.6937e-03,
         -6.8283e-04,  1.9608e-03],
        [-3.8319e-03, -2.7733e-03,  3.8195e-04,  ..., -1.9026e-04,
          2.5120e-03,  4.3564e-03],
        [-2.9964e-03, -1.2074e-03, -3.2234e-04,  ..., -2.0599e-03,
          1.5240e-03,  2.3174e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1715,  0.0114,  0.0029,  ...,  0.0023, -0.0149, -0.0104],
        [-0.0003, -0.1821, -0.0074,  ..., -0.0064, -0.0037,  0.0016],
        [-0.0040,  0.0036, -0.1895,  ..., -0.0029, -0.0010, -0.0224],
        ...,
        [-0.0106, -0.0007,  0.0106,  ..., -0.1981,  0.0022, -0.0064],
        [-0.0094,  0.0091,  0.0036,  ..., -0.0056, -0.1825, -0.0145],
        [-0.0117, -0.0109, -0.0174,  ..., -0.0133,  0.0111, -0.1766]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2219,  0.0194,  0.0014,  ..., -0.0121, -0.0153,  0.0026],
        [ 0.0090, -0.2405, -0.0028,  ..., -0.0117,  0.0128,  0.0044],
        [-0.0014,  0.0019, -0.2242,  ...,  0.0059,  0.0017,  0.0073],
        ...,
        [-0.0071,  0.0111,  0.0031,  ..., -0.2490,  0.0141, -0.0070],
        [-0.0087, -0.0057,  0.0024,  ..., -0.0035, -0.2258,  0.0059],
        [ 0.0036, -0.0091, -0.0095,  ..., -0.0055,  0.0036, -0.2367]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:28:17 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 00:28:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4951,  0.2925,  0.0101,  ..., -0.1646,  0.4458, -0.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2578, -0.4133, -0.1664,  ..., -0.2842, -0.5684,  0.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.2344, 1.6436, 0.0756,  ..., 0.1052, 0.6440, 1.0977], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8281, -0.7959, -0.3625,  ..., -0.4395,  0.2725,  0.8462],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:28:18 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:28:18 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 00:29:14 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 00:30:08 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 00:31:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.6152e-03,  1.8444e-03,  8.2970e-04,  ..., -1.1997e-03,
         -3.2444e-03, -1.8835e-03],
        [-1.5554e-03, -1.8730e-03,  1.0748e-03,  ...,  2.3603e-04,
         -3.5496e-03,  3.3474e-04],
        [ 2.9316e-03, -1.2140e-03, -5.2376e-03,  ...,  6.3133e-04,
         -4.1151e-04, -6.4135e-04],
        ...,
        [ 3.7422e-03, -1.0300e-03, -1.5144e-03,  ..., -1.7033e-03,
         -1.2188e-03,  3.4761e-04],
        [-1.4858e-03, -1.5879e-03, -9.0837e-04,  ..., -1.9054e-03,
         -5.0659e-03,  3.7432e-04],
        [ 1.8158e-03,  3.1776e-03,  1.0586e-03,  ...,  1.4687e-04,
         -2.1935e-05, -1.1587e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1030,  0.0107,  0.0101,  ..., -0.0019, -0.0102, -0.0059],
        [ 0.0065, -0.1016,  0.0001,  ..., -0.0050,  0.0021,  0.0054],
        [-0.0056, -0.0157, -0.0955,  ...,  0.0023,  0.0014,  0.0076],
        ...,
        [ 0.0028,  0.0023, -0.0047,  ..., -0.0789,  0.0023, -0.0007],
        [-0.0070,  0.0112, -0.0111,  ...,  0.0058, -0.1058, -0.0033],
        [-0.0065, -0.0007, -0.0055,  ..., -0.0049,  0.0054, -0.0922]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.9163e-02, -7.4463e-03, -1.3857e-03,  ...,  3.2940e-03,
         -2.8248e-03, -2.2812e-03],
        [ 4.8485e-03, -1.0028e-01, -1.9779e-03,  ...,  8.0643e-03,
          1.1330e-02,  2.1423e-02],
        [-5.4741e-03, -5.6190e-03, -9.3445e-02,  ..., -9.6436e-03,
         -8.7585e-03,  2.6512e-03],
        ...,
        [-6.9046e-03, -3.2005e-03,  8.2626e-03,  ..., -8.4229e-02,
          2.6245e-03,  8.2970e-05],
        [ 2.8687e-03,  1.2268e-02,  6.8512e-03,  ...,  1.8036e-02,
         -9.4727e-02,  1.3367e-02],
        [ 3.8567e-03,  2.8515e-03, -2.3861e-03,  ...,  3.9330e-03,
          4.2534e-03, -8.2397e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:31:06 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 00:31:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2314,  0.7222,  0.0225,  ..., -0.2766,  0.3865, -0.0237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8423, -0.3445, -0.3831,  ..., -0.4133, -0.2466,  0.0202],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.5327, 2.4102, 0.3496,  ..., 0.1956, 1.5820, 1.4814], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8765, -1.1260, -0.2104,  ..., -0.1631,  1.2676,  0.6128],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:31:06 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:31:06 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 00:32:03 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 00:32:55 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 00:33:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0948e-02, -1.4138e-04,  3.6297e-03,  ...,  1.8001e-04,
          6.7902e-04, -4.3640e-03],
        [-3.9902e-03, -3.3665e-03, -3.0494e-04,  ..., -1.8520e-03,
         -2.4071e-03, -2.4242e-03],
        [-1.2226e-03,  9.8419e-04, -4.8714e-03,  ..., -9.0790e-04,
         -1.0195e-03, -2.5215e-03],
        ...,
        [ 7.8678e-05, -6.1512e-04,  2.5425e-03,  ..., -1.2894e-03,
         -9.7847e-04,  4.1542e-03],
        [ 4.3678e-03, -6.8378e-04,  3.8338e-03,  ..., -2.0313e-03,
         -9.0408e-03, -1.4896e-03],
        [ 2.0981e-04,  4.6997e-03,  2.5177e-03,  ..., -2.2736e-03,
         -1.4763e-03, -1.0834e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1211, -0.0079, -0.0031,  ..., -0.0046,  0.0229,  0.0069],
        [-0.0034, -0.1223, -0.0055,  ..., -0.0068, -0.0012,  0.0020],
        [ 0.0078,  0.0089, -0.1270,  ..., -0.0045,  0.0140, -0.0023],
        ...,
        [-0.0049, -0.0059, -0.0028,  ..., -0.1326, -0.0040,  0.0091],
        [ 0.0045,  0.0109,  0.0033,  ...,  0.0060, -0.1254, -0.0039],
        [ 0.0058, -0.0088, -0.0085,  ..., -0.0080,  0.0100, -0.1099]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1232,  0.0030, -0.0002,  ..., -0.0140,  0.0358, -0.0091],
        [-0.0039, -0.1387, -0.0010,  ...,  0.0143, -0.0111,  0.0053],
        [ 0.0149,  0.0040, -0.1497,  ..., -0.0060, -0.0003, -0.0229],
        ...,
        [-0.0047, -0.0036, -0.0020,  ..., -0.1372, -0.0008,  0.0057],
        [ 0.0116, -0.0089, -0.0023,  ..., -0.0030, -0.1414,  0.0004],
        [-0.0123,  0.0077, -0.0060,  ..., -0.0013,  0.0165, -0.1356]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:33:50 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-07-01 00:33:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.1034, 0.8926, 0.0126,  ..., 0.0395, 0.3879, 0.5649], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5142, -0.5332, -0.2485,  ..., -0.2959,  0.2051,  0.5010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6152,  2.1719,  0.7422,  ..., -0.1440,  1.9980,  1.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.3037, -1.4170, -0.9136,  ..., -0.1313,  1.2559,  0.7163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:33:50 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:33:50 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 00:34:49 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 00:35:48 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 00:36:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8787e-03, -2.4700e-03,  3.2520e-03,  ..., -3.1853e-03,
         -8.9722e-03, -3.4657e-03],
        [ 2.4414e-03,  3.7079e-03, -2.3232e-03,  ..., -1.8358e-03,
          3.9253e-03, -6.3610e-04],
        [-2.8954e-03,  9.6512e-04,  1.9741e-04,  ...,  3.3913e-03,
         -8.4734e-04,  4.7207e-05],
        ...,
        [ 4.3335e-03,  4.0932e-03, -9.8801e-03,  ...,  4.0436e-03,
         -1.7824e-03, -1.3237e-03],
        [-1.8635e-03,  1.6861e-03,  9.6035e-04,  ...,  3.5820e-03,
          8.6594e-03,  1.7738e-03],
        [-3.2978e-03,  2.6150e-03,  1.6642e-04,  ..., -1.8940e-03,
          5.8079e-04,  2.1439e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1016,  0.0255, -0.0107,  ..., -0.0240,  0.0056,  0.0007],
        [ 0.0050, -0.0966,  0.0001,  ...,  0.0100,  0.0096,  0.0054],
        [-0.0093, -0.0098, -0.0840,  ..., -0.0075,  0.0220, -0.0120],
        ...,
        [-0.0021, -0.0027, -0.0103,  ..., -0.0875,  0.0086, -0.0035],
        [-0.0071,  0.0001,  0.0172,  ..., -0.0002, -0.0876, -0.0094],
        [ 0.0012,  0.0112, -0.0032,  ..., -0.0024,  0.0010, -0.0845]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1023,  0.0028, -0.0035,  ..., -0.0128,  0.0009, -0.0049],
        [ 0.0022, -0.0987,  0.0067,  ...,  0.0080,  0.0009, -0.0032],
        [-0.0149, -0.0081, -0.1028,  ..., -0.0042,  0.0174, -0.0044],
        ...,
        [-0.0086, -0.0053, -0.0001,  ..., -0.1044,  0.0169, -0.0119],
        [-0.0075,  0.0066,  0.0055,  ...,  0.0109, -0.1013,  0.0043],
        [-0.0035,  0.0081,  0.0064,  ..., -0.0117, -0.0010, -0.0980]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:36:45 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-07-01 00:36:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.2825, 1.2539, 0.1760,  ..., 0.0875, 0.8345, 0.7607], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5254, -0.7031, -0.1180,  ..., -0.1071,  0.7466,  0.3323],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.1648, 2.7344, 0.7212,  ..., 0.1216, 2.2871, 2.0176], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8633, -0.9473, -1.8438,  ...,  0.7749,  1.5117,  1.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:36:45 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:36:45 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 00:37:48 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 00:38:49 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 00:39:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0128, -0.0004,  0.0003,  ..., -0.0013, -0.0041, -0.0022],
        [ 0.0045,  0.0163,  0.0037,  ...,  0.0004,  0.0044, -0.0033],
        [-0.0059, -0.0049,  0.0110,  ..., -0.0010, -0.0034,  0.0010],
        ...,
        [-0.0042, -0.0045,  0.0005,  ...,  0.0142, -0.0080,  0.0006],
        [ 0.0082, -0.0019,  0.0051,  ..., -0.0031,  0.0166, -0.0045],
        [-0.0012,  0.0004,  0.0054,  ..., -0.0012,  0.0036,  0.0173]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0822,  0.0027, -0.0137,  ...,  0.0020,  0.0013,  0.0020],
        [-0.0050, -0.0925,  0.0107,  ..., -0.0090, -0.0152, -0.0125],
        [-0.0144, -0.0076, -0.0896,  ...,  0.0030, -0.0093, -0.0020],
        ...,
        [-0.0001,  0.0012, -0.0035,  ..., -0.0956, -0.0083,  0.0122],
        [-0.0046,  0.0016,  0.0115,  ...,  0.0027, -0.1000,  0.0175],
        [-0.0087, -0.0027, -0.0010,  ..., -0.0116, -0.0024, -0.0922]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1246,  0.0116, -0.0138,  ..., -0.0084, -0.0018,  0.0157],
        [-0.0035, -0.1289, -0.0113,  ..., -0.0171, -0.0020,  0.0009],
        [-0.0104,  0.0081, -0.1388,  ..., -0.0042, -0.0036, -0.0026],
        ...,
        [ 0.0201, -0.0036, -0.0021,  ..., -0.1076, -0.0064, -0.0160],
        [ 0.0018, -0.0074, -0.0076,  ...,  0.0005, -0.1187,  0.0088],
        [ 0.0124,  0.0105, -0.0117,  ..., -0.0042,  0.0142, -0.1274]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:39:53 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-07-01 00:39:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2954,  1.1982,  0.3613,  ..., -0.0817,  1.0791,  0.8101],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6943, -0.7959, -0.4988,  ..., -0.0742,  0.6958,  0.3740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3806,  2.6562,  0.9072,  ..., -0.1804,  2.0879,  2.2754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8745, -1.2441, -1.8691,  ...,  0.1240,  1.9473,  1.5371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:39:53 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:39:53 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 00:40:56 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 00:41:58 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 00:43:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0074, -0.0043,  0.0033,  ..., -0.0015, -0.0003, -0.0044],
        [-0.0012, -0.0029,  0.0036,  ...,  0.0042,  0.0018, -0.0015],
        [ 0.0030, -0.0005, -0.0068,  ...,  0.0009,  0.0011, -0.0009],
        ...,
        [ 0.0037, -0.0038, -0.0050,  ..., -0.0029,  0.0010, -0.0040],
        [ 0.0012, -0.0010, -0.0050,  ..., -0.0022, -0.0075,  0.0032],
        [ 0.0028,  0.0051, -0.0015,  ..., -0.0034, -0.0019, -0.0119]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0682,  0.0009,  0.0025,  ..., -0.0071,  0.0100,  0.0038],
        [-0.0071, -0.0703, -0.0203,  ...,  0.0064,  0.0090,  0.0176],
        [ 0.0021,  0.0002, -0.0680,  ...,  0.0046,  0.0045, -0.0078],
        ...,
        [-0.0169,  0.0042, -0.0148,  ..., -0.0600, -0.0085, -0.0036],
        [ 0.0105,  0.0024, -0.0037,  ...,  0.0077, -0.0526,  0.0058],
        [-0.0083,  0.0096, -0.0095,  ...,  0.0070, -0.0100, -0.0594]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0784, -0.0008,  0.0169,  ..., -0.0020,  0.0019,  0.0127],
        [ 0.0079, -0.0786, -0.0222,  ...,  0.0131, -0.0002,  0.0105],
        [ 0.0150,  0.0150, -0.0750,  ..., -0.0038, -0.0059, -0.0058],
        ...,
        [-0.0162, -0.0058, -0.0085,  ..., -0.0769, -0.0048,  0.0049],
        [ 0.0110,  0.0059, -0.0096,  ...,  0.0093, -0.0815,  0.0057],
        [-0.0133,  0.0072,  0.0151,  ...,  0.0053,  0.0025, -0.0690]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:43:06 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-07-01 00:43:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.0702, 1.4170, 0.3550,  ..., 0.0527, 1.1846, 0.9980], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4241, -0.4819, -0.8794,  ...,  0.3682,  0.7627,  0.5947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0208,  3.1680,  1.3838,  ...,  0.2366,  1.8145,  3.2539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1758, -1.6533, -1.5254,  ...,  0.3809,  2.4980,  2.0664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:43:06 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:43:06 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 00:44:12 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 00:45:18 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 00:46:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0016, -0.0028,  0.0005,  ...,  0.0001, -0.0027, -0.0002],
        [-0.0021,  0.0039,  0.0010,  ...,  0.0002, -0.0010, -0.0012],
        [ 0.0026, -0.0035,  0.0043,  ...,  0.0004, -0.0003, -0.0073],
        ...,
        [ 0.0008, -0.0018,  0.0013,  ...,  0.0009,  0.0033, -0.0020],
        [ 0.0040,  0.0074,  0.0005,  ..., -0.0004,  0.0029,  0.0017],
        [ 0.0003, -0.0021, -0.0013,  ..., -0.0009,  0.0031, -0.0038]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.1615e-02,  4.2114e-03,  7.0839e-03,  ...,  8.6784e-05,
          1.4954e-03, -3.0518e-05],
        [-8.7891e-03, -5.5176e-02,  9.2163e-03,  ..., -9.6416e-04,
          3.5362e-03, -1.6928e-03],
        [-1.1200e-02,  6.5880e-03, -6.0303e-02,  ..., -1.1627e-02,
          5.6305e-03,  7.9727e-03],
        ...,
        [ 1.7242e-02, -2.3209e-02,  8.4686e-03,  ..., -6.1584e-02,
          1.6975e-04, -1.4168e-02],
        [ 7.4463e-03,  1.2619e-02,  1.8127e-02,  ..., -4.9438e-03,
         -5.5939e-02,  7.5340e-05],
        [-5.6190e-03, -5.5885e-03, -1.0910e-02,  ...,  2.1362e-03,
          6.0196e-03, -5.9998e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0864, -0.0015,  0.0060,  ..., -0.0073,  0.0093,  0.0056],
        [-0.0070, -0.1097,  0.0010,  ..., -0.0036,  0.0046,  0.0011],
        [ 0.0047, -0.0082, -0.1105,  ..., -0.0094,  0.0046, -0.0102],
        ...,
        [ 0.0138,  0.0045,  0.0233,  ..., -0.0828,  0.0071,  0.0023],
        [ 0.0117,  0.0146,  0.0059,  ...,  0.0008, -0.1033,  0.0031],
        [-0.0088, -0.0013, -0.0053,  ..., -0.0066,  0.0112, -0.1023]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:46:27 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-07-01 00:46:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2196,  1.3633,  0.4385,  ..., -0.0974,  1.0908,  1.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4062, -0.5874, -0.8818,  ...,  0.0565,  0.9507,  0.7070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5000,  2.8594,  1.5908,  ...,  0.8545,  1.9590,  3.1660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.5879, -1.7383, -1.8848,  ...,  0.1272,  2.1797,  2.6016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:46:27 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:46:27 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 00:47:36 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 00:48:45 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 00:49:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0113, -0.0050,  0.0042,  ...,  0.0023,  0.0002,  0.0035],
        [-0.0010,  0.0060,  0.0029,  ...,  0.0017,  0.0015, -0.0027],
        [-0.0012, -0.0056,  0.0071,  ..., -0.0018, -0.0002,  0.0008],
        ...,
        [ 0.0040,  0.0012, -0.0008,  ...,  0.0100, -0.0028, -0.0052],
        [ 0.0009,  0.0027,  0.0056,  ..., -0.0026,  0.0062,  0.0052],
        [-0.0039, -0.0010, -0.0019,  ...,  0.0075, -0.0023,  0.0116]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.2358e-02, -1.1673e-02,  7.7915e-04,  ..., -1.0056e-02,
         -2.4605e-03,  9.7656e-03],
        [-4.1695e-03, -4.5380e-02,  9.2697e-03,  ..., -9.5367e-06,
          1.0681e-02,  1.1284e-02],
        [-6.9733e-03,  1.6546e-04, -3.8452e-02,  ..., -2.9926e-03,
         -1.5335e-03,  1.9436e-03],
        ...,
        [-1.6418e-02,  5.5313e-03,  5.5580e-03,  ..., -3.8849e-02,
         -8.2245e-03,  8.8272e-03],
        [-1.1703e-02, -8.2626e-03, -1.5839e-02,  ...,  9.9182e-03,
         -3.6591e-02,  5.5771e-03],
        [-1.9714e-02,  1.8005e-03,  7.5188e-03,  ..., -5.1956e-03,
          1.7776e-02, -2.9465e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0728,  0.0038, -0.0069,  ..., -0.0010, -0.0071, -0.0080],
        [ 0.0008, -0.0807,  0.0082,  ..., -0.0210,  0.0072,  0.0081],
        [-0.0071,  0.0020, -0.0605,  ..., -0.0022,  0.0101, -0.0081],
        ...,
        [ 0.0021,  0.0077, -0.0087,  ..., -0.0646, -0.0024,  0.0214],
        [-0.0064, -0.0112, -0.0088,  ..., -0.0098, -0.0620,  0.0055],
        [-0.0246,  0.0025, -0.0152,  ..., -0.0106,  0.0053, -0.0672]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:49:56 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-07-01 00:49:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0178,  1.5430,  0.6318,  ...,  0.1081,  0.9097,  1.5771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5205, -0.7251, -0.6626,  ...,  0.1606,  1.1123,  0.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.4521, 2.9395, 1.3633,  ..., 1.1680, 2.5156, 2.5605], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8350, -1.5137, -2.8789,  ...,  0.0276,  2.2793,  2.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:49:56 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:49:56 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 00:51:07 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 00:52:19 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 00:53:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.9024e-03,  3.3021e-05,  2.9621e-03,  ..., -2.8248e-03,
          2.9612e-04, -3.0403e-03],
        [ 3.6182e-03,  1.4687e-04, -2.1248e-03,  ..., -6.5899e-04,
          9.6750e-04,  2.3384e-03],
        [-2.4033e-03, -2.3727e-03, -3.0918e-03,  ..., -2.0866e-03,
          1.9608e-03,  6.0654e-04],
        ...,
        [-4.8447e-03, -2.6112e-03, -8.5831e-04,  ..., -5.8441e-03,
         -7.2002e-05, -1.0653e-03],
        [-1.5316e-03, -1.0939e-03,  3.0499e-03,  ..., -1.2321e-03,
         -2.2621e-03,  9.9957e-05],
        [-1.7338e-03,  3.8795e-03, -1.2054e-03,  ..., -6.1874e-03,
          2.6283e-03,  2.0428e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0048, -0.0193, -0.0014,  ..., -0.0154, -0.0018, -0.0046],
        [ 0.0172, -0.0096, -0.0038,  ...,  0.0044, -0.0039, -0.0023],
        [-0.0023,  0.0176, -0.0192,  ...,  0.0015,  0.0161, -0.0001],
        ...,
        [-0.0064, -0.0206, -0.0106,  ..., -0.0102,  0.0080, -0.0007],
        [ 0.0088,  0.0156, -0.0095,  ...,  0.0042, -0.0339,  0.0143],
        [-0.0016, -0.0075, -0.0047,  ...,  0.0102,  0.0068, -0.0260]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0522, -0.0118,  0.0180,  ..., -0.0204, -0.0041,  0.0118],
        [-0.0019, -0.0322, -0.0007,  ..., -0.0115, -0.0018, -0.0084],
        [-0.0023,  0.0094, -0.0544,  ..., -0.0046,  0.0021, -0.0021],
        ...,
        [-0.0019,  0.0165, -0.0075,  ..., -0.0531,  0.0069, -0.0079],
        [ 0.0036, -0.0013, -0.0227,  ...,  0.0106, -0.0631,  0.0327],
        [-0.0040, -0.0021,  0.0109,  ...,  0.0015,  0.0119, -0.0605]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:53:33 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-07-01 00:53:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2277,  1.2617,  0.6553,  ...,  0.3745,  0.8481,  1.3877],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6064, -0.6631, -0.6914,  ...,  0.0510,  0.7988,  0.9546],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.1992, 3.1016, 1.2539,  ..., 1.4902, 2.5527, 1.7949], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.7988, -1.2500, -3.5664,  ...,  0.3247,  3.2676,  1.8555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:53:33 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:53:33 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 00:54:47 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 00:56:00 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 00:57:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0201, -0.0017, -0.0013,  ...,  0.0060, -0.0047,  0.0003],
        [-0.0055,  0.0196,  0.0016,  ...,  0.0013, -0.0009,  0.0003],
        [-0.0018,  0.0007,  0.0185,  ..., -0.0028, -0.0016,  0.0051],
        ...,
        [ 0.0032, -0.0008, -0.0009,  ...,  0.0154, -0.0021,  0.0029],
        [-0.0008, -0.0015,  0.0002,  ..., -0.0014,  0.0179, -0.0018],
        [-0.0009, -0.0023,  0.0021,  ..., -0.0009,  0.0034,  0.0207]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0065,  0.0055, -0.0091,  ...,  0.0035, -0.0055, -0.0061],
        [ 0.0020, -0.0204, -0.0010,  ...,  0.0021, -0.0025,  0.0051],
        [-0.0117,  0.0062, -0.0217,  ...,  0.0093, -0.0054,  0.0018],
        ...,
        [ 0.0046, -0.0034, -0.0019,  ..., -0.0051,  0.0011,  0.0024],
        [-0.0086, -0.0008,  0.0005,  ..., -0.0047, -0.0100, -0.0028],
        [ 0.0105,  0.0079, -0.0124,  ..., -0.0021,  0.0042, -0.0287]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0179, -0.0027, -0.0033,  ...,  0.0082, -0.0056,  0.0007],
        [ 0.0024, -0.0217, -0.0143,  ..., -0.0022,  0.0093,  0.0020],
        [ 0.0229, -0.0057, -0.0248,  ..., -0.0103,  0.0018,  0.0049],
        ...,
        [ 0.0114, -0.0080, -0.0038,  ..., -0.0270, -0.0001,  0.0063],
        [-0.0021, -0.0008, -0.0008,  ...,  0.0022, -0.0365, -0.0012],
        [ 0.0085,  0.0049, -0.0049,  ..., -0.0041,  0.0073, -0.0487]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 00:57:13 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-07-01 00:57:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.1852, 1.2041, 0.5444,  ..., 0.4651, 1.0381, 1.0352], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 6.3965e-01, -5.3418e-01, -9.9268e-01,  ..., -9.5892e-04,
         7.9443e-01,  6.8066e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.3262, 2.8828, 1.1514,  ..., 1.7275, 2.8320, 1.8496], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.9355, -0.9258, -4.0938,  ...,  0.8291,  3.6133,  1.8896],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 00:57:13 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 00:57:14 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 00:58:37 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 00:59:59 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 01:01:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.5226e-03,  9.2506e-04,  1.1148e-03,  ..., -1.5268e-03,
         -1.8835e-03, -9.6083e-04],
        [-2.2674e-04,  4.1847e-03,  1.1396e-03,  ...,  1.5230e-03,
         -6.9523e-04, -1.1616e-03],
        [ 1.3647e-03, -7.4530e-04,  6.7673e-03,  ..., -1.5898e-03,
         -5.6934e-04, -2.5730e-03],
        ...,
        [-1.4334e-03,  6.8760e-04, -1.4410e-03,  ...,  8.8043e-03,
         -8.5831e-04, -3.0041e-04],
        [-1.3990e-03, -3.1352e-04,  3.4988e-05,  ..., -1.0169e-04,
          4.5128e-03,  1.2455e-03],
        [-1.0719e-03, -1.3542e-03, -7.4148e-04,  ..., -2.9259e-03,
          5.0125e-03,  7.6752e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.9775e-02, -3.0756e-04, -1.3870e-02,  ..., -1.7853e-02,
          1.1497e-02, -2.0943e-03],
        [-2.4567e-03, -1.3367e-02, -1.7700e-03,  ..., -8.4763e-03,
         -5.2490e-03,  9.1095e-03],
        [ 1.3256e-03, -1.2169e-03, -3.8853e-03,  ..., -1.2459e-02,
         -7.4654e-03, -1.2932e-02],
        ...,
        [-4.9973e-03,  1.1826e-02, -4.2686e-03,  ..., -1.9623e-02,
         -6.6681e-03, -1.0742e-02],
        [-1.6785e-04,  1.5213e-02, -1.3351e-05,  ..., -1.4477e-03,
         -3.4008e-03, -3.4885e-03],
        [-1.2787e-02,  8.2626e-03, -6.9733e-03,  ...,  3.5858e-03,
         -3.1662e-03, -7.0381e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0533, -0.0012,  0.0061,  ..., -0.0027, -0.0068,  0.0012],
        [ 0.0133, -0.0639, -0.0073,  ..., -0.0178, -0.0238, -0.0070],
        [ 0.0019, -0.0023, -0.0330,  ..., -0.0092, -0.0039, -0.0204],
        ...,
        [ 0.0168,  0.0082, -0.0202,  ..., -0.0427, -0.0008, -0.0027],
        [-0.0039,  0.0059,  0.0036,  ..., -0.0038, -0.0163, -0.0112],
        [-0.0047,  0.0135, -0.0022,  ...,  0.0040,  0.0065, -0.0464]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:01:19 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-07-01 01:01:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.4854, 1.2021, 0.4753,  ..., 0.5859, 1.0322, 0.7007], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9653, -0.4128, -1.1875,  ...,  0.1149,  1.1230,  0.6138],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([2.0156, 3.0078, 2.7578,  ..., 1.4707, 3.0391, 2.4297], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.5391, -1.0840, -3.2207,  ...,  1.0557,  3.4824,  1.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:01:19 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 01:01:20 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 01:02:40 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 01:04:02 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 01:05:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.1737e-04, -1.1981e-04,  2.9325e-04,  ...,  9.9838e-05,
         -1.2798e-03, -1.2617e-03],
        [-5.1975e-04, -1.4677e-03, -6.1607e-04,  ...,  1.2951e-03,
         -2.3627e-04, -2.0370e-03],
        [-6.9332e-04,  1.9312e-03, -1.5965e-03,  ..., -6.0225e-04,
          1.2188e-03, -8.1682e-04],
        ...,
        [-6.3133e-03, -9.3269e-04, -2.2907e-03,  ..., -2.9488e-03,
          2.6150e-03,  1.1692e-03],
        [ 5.1737e-04,  1.9550e-03,  1.7815e-03,  ..., -3.6120e-04,
         -9.8228e-04,  2.4433e-03],
        [-3.9506e-04, -5.0306e-04,  1.9169e-04,  ..., -2.8467e-04,
         -6.4087e-04, -1.3943e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0091, -0.0214,  0.0107,  ..., -0.0105, -0.0043,  0.0125],
        [-0.0089, -0.0229, -0.0007,  ...,  0.0062,  0.0057,  0.0004],
        [-0.0028, -0.0178, -0.0169,  ...,  0.0206, -0.0096,  0.0151],
        ...,
        [ 0.0056,  0.0020, -0.0050,  ..., -0.0289, -0.0043,  0.0079],
        [-0.0002,  0.0013, -0.0073,  ..., -0.0007, -0.0151,  0.0011],
        [ 0.0043, -0.0006, -0.0040,  ...,  0.0051,  0.0137, -0.0130]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0471, -0.0073, -0.0020,  ..., -0.0062,  0.0078, -0.0050],
        [ 0.0093, -0.0429, -0.0021,  ...,  0.0029,  0.0050, -0.0019],
        [-0.0084,  0.0072, -0.0636,  ..., -0.0186, -0.0052,  0.0115],
        ...,
        [ 0.0192,  0.0232, -0.0176,  ..., -0.0485, -0.0108,  0.0164],
        [ 0.0067,  0.0179, -0.0218,  ..., -0.0187, -0.0610, -0.0190],
        [ 0.0062,  0.0040,  0.0026,  ..., -0.0136,  0.0187, -0.0522]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:05:27 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-07-01 01:05:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.5225, 1.0684, 0.4011,  ..., 0.6470, 1.0957, 0.6807], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9883, -0.2927, -1.3232,  ...,  0.2722,  1.2031,  0.5967],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.9883, 3.4609, 2.6934,  ..., 1.8047, 3.2949, 2.4902], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.4570, -0.7314, -3.0098,  ...,  0.6396,  4.5781,  2.1699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:05:27 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 01:05:27 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 01:06:50 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 01:08:14 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 01:09:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.1003e-03, -5.4073e-04,  5.1355e-04,  ..., -4.5395e-04,
         -3.5644e-04,  4.1366e-04],
        [ 4.3035e-04,  5.8212e-03,  2.1815e-04,  ...,  1.7195e-03,
         -1.1492e-03,  1.7624e-03],
        [ 2.5654e-04,  2.7370e-03,  9.7580e-03,  ..., -6.1035e-04,
          4.7469e-04, -1.9145e-04],
        ...,
        [ 6.1691e-05, -9.8610e-04,  6.0844e-04,  ...,  7.1411e-03,
          1.1673e-03, -8.4209e-04],
        [ 1.0138e-03, -4.1604e-04, -2.6727e-04,  ..., -2.2316e-04,
          3.3073e-03,  9.7752e-04],
        [-1.4734e-03,  5.5432e-06,  4.6253e-04,  ...,  2.5678e-04,
          1.0691e-03,  5.4054e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0048,  0.0040, -0.0018,  ..., -0.0161, -0.0045, -0.0198],
        [ 0.0070, -0.0074,  0.0082,  ..., -0.0034,  0.0062, -0.0003],
        [-0.0012,  0.0249,  0.0070,  ..., -0.0011,  0.0024,  0.0084],
        ...,
        [ 0.0012, -0.0116, -0.0100,  ...,  0.0127, -0.0016, -0.0228],
        [ 0.0069, -0.0101, -0.0082,  ...,  0.0029,  0.0004,  0.0095],
        [ 0.0118, -0.0093,  0.0126,  ..., -0.0169,  0.0093, -0.0296]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.9343e-02, -5.1155e-03,  1.7433e-03,  ..., -9.3613e-03,
          1.3985e-02,  2.2697e-04],
        [-6.1722e-03, -5.1666e-02,  8.4610e-03,  ...,  8.5754e-03,
         -1.1497e-02, -1.6068e-02],
        [-7.6828e-03, -2.1095e-03, -4.2206e-02,  ...,  1.6479e-02,
         -2.0844e-02, -4.4823e-05],
        ...,
        [ 1.6922e-02,  6.4621e-03, -1.1932e-02,  ..., -3.9276e-02,
          2.2831e-03, -1.2726e-02],
        [ 1.2177e-02,  1.0742e-02, -4.3907e-03,  ...,  5.3368e-03,
         -4.7821e-02, -1.3008e-03],
        [-4.1656e-03,  5.4855e-03,  1.8646e-02,  ..., -1.3115e-02,
          2.5055e-02, -6.1920e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:09:40 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-07-01 01:09:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.7363, 1.0635, 0.9312,  ..., 0.5068, 1.1074, 0.8574], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1250, -0.2976, -1.0400,  ...,  0.3154,  1.1064,  0.6060],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.1240, 3.4277, 2.9492,  ..., 2.2871, 3.2109, 2.7910], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.6797, -1.0967, -3.5391,  ...,  1.8213,  4.6250,  3.3008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:09:40 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 01:09:40 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 01:11:05 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 01:12:31 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 01:13:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0099,  0.0001, -0.0007,  ...,  0.0005,  0.0013,  0.0012],
        [ 0.0005,  0.0059, -0.0007,  ..., -0.0007, -0.0001, -0.0006],
        [-0.0005,  0.0008,  0.0113,  ..., -0.0001, -0.0002, -0.0007],
        ...,
        [-0.0003,  0.0003, -0.0008,  ...,  0.0123,  0.0014, -0.0009],
        [-0.0003, -0.0005, -0.0019,  ...,  0.0022,  0.0130, -0.0018],
        [ 0.0007, -0.0016, -0.0003,  ..., -0.0004, -0.0002,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0395, -0.0176, -0.0090,  ..., -0.0037, -0.0017,  0.0130],
        [-0.0035,  0.0032,  0.0101,  ..., -0.0104, -0.0154, -0.0026],
        [-0.0165, -0.0040,  0.0437,  ..., -0.0042, -0.0057, -0.0047],
        ...,
        [-0.0095, -0.0080, -0.0111,  ...,  0.0435, -0.0143,  0.0054],
        [-0.0026,  0.0021, -0.0111,  ...,  0.0089,  0.0319, -0.0010],
        [-0.0136,  0.0020, -0.0001,  ...,  0.0041,  0.0131,  0.0733]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0033, -0.0167,  0.0146,  ...,  0.0017,  0.0108,  0.0321],
        [ 0.0027, -0.0236,  0.0033,  ..., -0.0214, -0.0227,  0.0241],
        [-0.0024,  0.0085,  0.0013,  ..., -0.0280,  0.0033,  0.0106],
        ...,
        [-0.0208,  0.0002,  0.0020,  ...,  0.0238,  0.0046, -0.0028],
        [-0.0052, -0.0107,  0.0102,  ...,  0.0039, -0.0056, -0.0052],
        [-0.0302,  0.0178,  0.0077,  ...,  0.0136,  0.0063,  0.0206]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:13:58 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 01:13:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.6914, 1.1270, 0.8433,  ..., 0.5571, 1.0908, 0.8086], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.0596, -0.1831, -0.9512,  ...,  0.1522,  1.3535,  0.6206],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.4648, 4.0000, 2.0195,  ..., 2.0996, 2.7383, 3.9922], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.3887, -0.1104, -3.1055,  ...,  1.3555,  4.1680,  4.8242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:13:58 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 01:13:58 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 01:15:17 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 01:16:33 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 01:17:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.7180e-03, -9.1410e-04,  5.1975e-04,  ...,  1.4305e-04,
          6.6948e-04,  4.4346e-04],
        [-4.6039e-04,  1.1377e-03,  1.0099e-03,  ..., -1.1196e-03,
          3.2234e-04, -5.4955e-05],
        [-3.3855e-05,  3.3045e-04,  2.1267e-03,  ..., -5.3501e-04,
         -1.1599e-04,  3.0935e-05],
        ...,
        [ 2.4462e-04, -2.5177e-04, -3.7575e-04,  ...,  2.3365e-03,
          6.4611e-04, -1.0639e-04],
        [ 3.3402e-04,  2.1505e-04, -1.6749e-05,  ...,  2.2280e-04,
          2.3689e-03,  6.1214e-05],
        [ 5.4979e-04,  9.0027e-04,  6.0749e-04,  ...,  2.0957e-04,
         -4.5824e-04,  2.2850e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0031, -0.0105,  0.0051,  ..., -0.0026, -0.0003,  0.0109],
        [ 0.0089,  0.0018, -0.0046,  ...,  0.0148, -0.0050,  0.0049],
        [ 0.0095, -0.0011, -0.0070,  ..., -0.0121, -0.0075,  0.0036],
        ...,
        [ 0.0127,  0.0185,  0.0054,  ...,  0.0119,  0.0017, -0.0133],
        [ 0.0002,  0.0013, -0.0051,  ...,  0.0020, -0.0015,  0.0048],
        [ 0.0041, -0.0015, -0.0199,  ...,  0.0076,  0.0032,  0.0031]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0225, -0.0107,  0.0038,  ..., -0.0030, -0.0072,  0.0249],
        [-0.0042, -0.0168,  0.0201,  ...,  0.0211,  0.0020, -0.0169],
        [ 0.0132, -0.0078, -0.0139,  ...,  0.0056, -0.0070, -0.0168],
        ...,
        [ 0.0026,  0.0094, -0.0132,  ..., -0.0440, -0.0001, -0.0103],
        [ 0.0110, -0.0039, -0.0177,  ...,  0.0055, -0.0146,  0.0015],
        [ 0.0066,  0.0035, -0.0082,  ...,  0.0015, -0.0115, -0.0001]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:17:54 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 01:17:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.4048, 1.0537, 0.8130,  ..., 0.5996, 0.9565, 0.8193], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8223, -0.2703, -1.0713,  ...,  0.4097,  1.2666,  0.8901],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.1543, 4.1445, 0.2891,  ..., 1.3691, 1.9844, 3.0117], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.9922,  0.4272, -3.5332,  ...,  0.7695,  4.1523,  3.8242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:17:54 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 01:17:54 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 01:19:14 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 01:20:36 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 01:21:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.4692e-03, -3.6335e-04, -1.3256e-04,  ..., -4.7398e-04,
         -4.1544e-05, -5.6028e-04],
        [ 7.1001e-04,  4.3488e-03, -8.5592e-05,  ...,  8.0466e-05,
          3.9625e-04,  4.8280e-04],
        [ 9.4604e-04, -1.1683e-03,  6.3896e-03,  ..., -7.0620e-04,
         -9.4986e-04, -5.3358e-04],
        ...,
        [-5.6648e-04,  2.4843e-04, -2.3925e-04,  ...,  8.6136e-03,
         -2.4176e-04, -1.2817e-03],
        [ 4.9591e-05,  7.2360e-05, -2.4176e-04,  ..., -3.1948e-04,
          9.2468e-03, -2.2125e-04],
        [ 3.6263e-04,  2.4271e-04, -4.6921e-04,  ..., -3.7193e-04,
          2.9874e-04,  9.0408e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 3.0853e-02,  2.6703e-03, -8.3313e-03,  ...,  1.4858e-03,
          2.8286e-03, -1.4969e-02],
        [ 1.4854e-02, -1.7929e-03,  6.9275e-03,  ..., -1.5480e-02,
          1.1299e-02, -9.3842e-03],
        [-2.5726e-02, -5.0354e-03,  3.5431e-02,  ..., -4.4250e-04,
         -5.2261e-04,  2.2335e-03],
        ...,
        [-9.6741e-03, -7.9727e-04,  1.4618e-02,  ...,  4.3671e-02,
         -1.4740e-02,  8.9798e-03],
        [ 2.1381e-03, -1.0368e-02, -1.5839e-02,  ..., -1.4809e-02,
          2.6917e-02,  8.7128e-03],
        [-3.2845e-03,  3.6285e-02,  9.7275e-05,  ..., -2.8763e-03,
          1.6281e-02,  2.7313e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0148,  0.0096,  0.0066,  ..., -0.0107,  0.0089, -0.0131],
        [ 0.0176, -0.0223, -0.0024,  ..., -0.0082, -0.0011,  0.0146],
        [-0.0276,  0.0005,  0.0193,  ..., -0.0072, -0.0114,  0.0049],
        ...,
        [-0.0029, -0.0047,  0.0028,  ...,  0.0314,  0.0012, -0.0044],
        [ 0.0089, -0.0130,  0.0054,  ..., -0.0033,  0.0172,  0.0169],
        [-0.0090,  0.0289,  0.0229,  ..., -0.0066,  0.0036,  0.0276]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:22:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To randomize results in randomization
To restore results in restoration
To optimize results in optimization
To minimize results in minimization
To illumine results in illumination
To aspire results in aspiration
To standardize results in
2024-07-01 01:22:00 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 01:22:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6357, -0.1322,  0.0104,  ..., -0.4175, -0.6274, -0.2202],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0967,  0.2039, -0.3223,  ..., -0.4126, -0.1962, -0.0944],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1005, -0.1033, -0.1204,  ...,  0.1367, -0.7847,  0.0631],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2803,  0.3804, -0.1582,  ...,  0.4355, -0.1460,  0.0442],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:22:00 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:22:00 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 01:22:24 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 01:22:47 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 01:23:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1009e-02,  7.5865e-04, -1.2207e-03,  ..., -9.2411e-04,
         -8.6498e-04, -5.6744e-04],
        [ 1.8682e-03, -1.1658e-02, -4.5538e-04,  ..., -3.0375e-04,
         -3.0518e-03,  4.7379e-03],
        [-1.6832e-03,  4.3797e-04, -1.2718e-02,  ..., -1.1816e-03,
         -2.6951e-03, -4.0364e-04],
        ...,
        [-6.1893e-04,  4.0054e-05, -3.5381e-03,  ..., -1.1711e-02,
         -4.3178e-04, -2.5368e-04],
        [-4.5633e-04, -5.3763e-05, -7.5579e-04,  ..., -3.0384e-03,
         -1.0544e-02, -7.4959e-04],
        [-8.3113e-04, -2.1315e-04,  1.3466e-03,  ..., -1.0166e-03,
          1.5593e-03, -1.2321e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.6438e-02,  1.0323e-02, -2.3270e-03,  ..., -4.4861e-03,
          4.2343e-03,  6.0120e-03],
        [ 1.2264e-03, -3.1189e-02,  5.8327e-03,  ...,  3.3150e-03,
         -4.5853e-03,  1.9989e-03],
        [ 1.3399e-03,  8.9951e-03, -3.7659e-02,  ...,  7.4425e-03,
         -6.6137e-04,  6.4392e-03],
        ...,
        [-1.1322e-02,  7.8278e-03,  7.9117e-03,  ..., -2.6215e-02,
          8.6212e-03, -4.6349e-03],
        [-1.5579e-02,  1.8396e-03,  4.6501e-03,  ..., -1.1246e-02,
         -2.9251e-02,  1.1749e-03],
        [-4.2801e-03, -3.4199e-03,  5.7068e-03,  ...,  5.5027e-04,
         -5.9128e-05, -2.4750e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.7537e-02,  3.3340e-03, -8.8882e-03,  ..., -2.5978e-03,
         -3.4866e-03,  4.4250e-03],
        [ 3.9558e-03, -4.4128e-02,  1.3065e-04,  ...,  6.0081e-03,
          2.2945e-03, -3.1776e-03],
        [-3.3455e-03,  8.5831e-05, -4.5410e-02,  ...,  2.5311e-03,
          4.9820e-03,  2.8172e-03],
        ...,
        [-2.4891e-03,  5.9662e-03,  1.3294e-03,  ..., -4.1626e-02,
         -2.1954e-03,  8.5974e-04],
        [-2.4586e-03, -6.9141e-04,  1.2970e-03,  ..., -1.2379e-03,
         -4.0314e-02,  5.1651e-03],
        [-2.1725e-03, -2.9488e-03, -2.7561e-04,  ...,  2.1057e-03,
          3.6907e-03, -3.5797e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:23:12 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 01:23:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3928, -0.0402, -0.3701,  ..., -0.0891, -0.4734, -0.1610],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1569,  0.2322, -0.2412,  ..., -0.1257, -0.1835, -0.2417],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0108,  0.1260, -0.0545,  ..., -0.0696, -0.5293, -0.1874],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5068,  0.3428, -0.2195,  ..., -0.0762, -0.0851,  0.2996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:23:12 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:23:12 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 01:23:34 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 01:23:57 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 01:24:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.0096e-02,  8.2111e-04, -1.7238e-04,  ..., -3.8004e-04,
         -1.0004e-03,  1.0567e-03],
        [-8.9836e-04, -2.4536e-02,  9.6035e-04,  ...,  2.2945e-03,
         -1.0836e-04,  2.5725e-04],
        [-1.9779e-03,  2.0771e-03, -2.0920e-02,  ...,  1.7929e-04,
          3.9959e-04,  1.3456e-03],
        ...,
        [ 2.5635e-03,  4.6844e-03,  7.7128e-05,  ..., -2.0096e-02,
         -3.9711e-03,  1.6451e-03],
        [-1.9026e-03,  1.2627e-03, -7.5340e-04,  ...,  1.3819e-03,
         -1.9913e-02, -1.3428e-03],
        [ 9.4223e-04, -2.7905e-03, -3.6278e-03,  ...,  3.9196e-04,
          1.2455e-03, -2.2812e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.4158e-02,  6.2637e-03, -1.8711e-03,  ...,  2.5024e-03,
          1.6632e-03,  3.5210e-03],
        [ 5.5981e-04, -5.8289e-02, -1.2222e-02,  ...,  9.8801e-03,
          6.2561e-03,  1.1730e-04],
        [-9.7198e-03, -1.6994e-03, -6.7078e-02,  ...,  2.3031e-04,
         -3.2501e-03, -4.5242e-03],
        ...,
        [-7.6370e-03, -6.1340e-03, -2.6779e-03,  ..., -6.3171e-02,
          6.3419e-05,  6.7215e-03],
        [ 2.0409e-03, -5.3253e-03,  5.5695e-03,  ...,  1.1749e-03,
         -5.9387e-02,  3.5381e-03],
        [-3.7403e-03,  3.2787e-03,  4.6616e-03,  ..., -1.3763e-02,
          8.3160e-03, -7.0984e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0741,  0.0030,  0.0024,  ...,  0.0033, -0.0049,  0.0053],
        [ 0.0063, -0.0733, -0.0048,  ...,  0.0004,  0.0042, -0.0023],
        [-0.0017, -0.0076, -0.0712,  ..., -0.0014,  0.0037, -0.0009],
        ...,
        [ 0.0099, -0.0039,  0.0044,  ..., -0.0734, -0.0038,  0.0002],
        [-0.0052, -0.0038,  0.0098,  ...,  0.0029, -0.0645,  0.0002],
        [ 0.0024,  0.0034,  0.0056,  ...,  0.0007,  0.0001, -0.0770]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:24:23 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 01:24:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1506, -0.1582, -0.1573,  ...,  0.1564, -0.9580,  0.0500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4453,  0.6206, -0.2627,  ...,  0.6865, -0.2383,  0.0510],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3967,  0.1891,  0.0335,  ...,  0.0728, -1.1270, -0.0026],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.5122e-01,  7.6904e-02, -3.3936e-01,  ..., -2.4414e-04,
        -5.4443e-01,  5.1660e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:24:23 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:24:23 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 01:24:48 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 01:25:14 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 01:25:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.7585e-03, -1.0223e-03, -6.4611e-04,  ..., -5.3740e-04,
         -1.5650e-03, -1.8091e-03],
        [-5.7125e-04, -8.6212e-03, -5.9509e-04,  ...,  6.3479e-05,
         -3.0947e-04,  1.3170e-03],
        [ 1.9264e-03, -1.3447e-03, -5.2834e-03,  ..., -5.8937e-04,
          1.8959e-03, -3.6383e-04],
        ...,
        [ 8.6498e-04, -1.4186e-05, -2.2373e-03,  ..., -6.1493e-03,
          1.1959e-03,  1.5202e-03],
        [-1.4937e-04, -9.7275e-04,  5.6171e-04,  ..., -4.6635e-04,
         -5.3406e-03, -3.7193e-04],
        [ 6.4993e-04,  9.7561e-04, -1.0645e-04,  ...,  2.7370e-04,
          9.2268e-04, -6.1798e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.2196e-02, -8.0185e-03, -3.8643e-03,  ...,  2.7828e-03,
          3.5133e-03, -6.6757e-03],
        [-2.4509e-03, -4.6326e-02,  4.5776e-04,  ..., -4.5700e-03,
         -7.8888e-03, -2.5635e-03],
        [ 5.9929e-03,  1.7166e-03, -3.9246e-02,  ..., -6.9504e-03,
          8.3389e-03,  6.3324e-04],
        ...,
        [ 4.4365e-03,  5.7755e-03, -2.1687e-03,  ..., -3.7628e-02,
          5.7220e-06, -3.5954e-03],
        [-3.2768e-03, -4.2458e-03, -4.8714e-03,  ..., -1.0338e-03,
         -3.8147e-02,  4.7455e-03],
        [-3.4695e-03, -9.5901e-03, -5.1880e-03,  ..., -5.4626e-03,
          7.7934e-03, -3.0609e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.9160e-02,  1.5020e-04, -7.3528e-04,  ..., -3.7193e-05,
         -7.8678e-05, -4.3182e-03],
        [-6.6223e-03, -3.9368e-02,  7.4997e-03,  ..., -2.1672e-04,
         -6.0539e-03,  4.8161e-04],
        [ 5.5084e-03,  6.3858e-03, -3.0487e-02,  ...,  2.7771e-03,
          9.7179e-04,  3.6888e-03],
        ...,
        [-5.3558e-03, -1.1616e-03, -3.9368e-03,  ..., -3.5522e-02,
         -4.6310e-03, -8.4352e-04],
        [ 2.8648e-03,  1.7319e-03, -3.3264e-03,  ...,  4.6234e-03,
         -3.5736e-02, -1.1349e-03],
        [-1.7099e-03, -3.2806e-03, -2.6855e-03,  ..., -7.0496e-03,
          8.9645e-03, -3.1464e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:25:41 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 01:25:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0161,  0.1234, -0.0668,  ..., -0.0806, -0.6411, -0.2727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8032,  0.5376, -0.3420,  ..., -0.1125, -0.1512,  0.4597],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5244, -0.0878,  0.3137,  ..., -0.1176, -1.3037,  0.0049],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.3777,  0.1663, -0.0715,  ...,  0.0746, -0.2402,  0.3079],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:25:41 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:25:41 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 01:26:11 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 01:26:40 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 01:27:10 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8172e-03,  5.7936e-05,  1.1339e-03,  ..., -1.0896e-04,
          2.1496e-03, -1.1959e-03],
        [-3.4690e-04, -3.9062e-03, -6.9618e-04,  ...,  6.1417e-04,
         -5.1689e-04,  6.7472e-05],
        [-1.8740e-03, -4.6968e-05, -3.9177e-03,  ...,  4.1366e-04,
         -3.2544e-05, -7.4053e-04],
        ...,
        [-3.7932e-04, -1.7424e-03,  3.2330e-04,  ..., -5.8784e-03,
         -2.6321e-04,  1.1978e-03],
        [-1.5211e-03, -5.0831e-04, -8.5783e-04,  ..., -1.9779e-03,
         -5.1956e-03, -1.1520e-03],
        [ 3.3617e-04, -1.3762e-03, -8.5068e-04,  ..., -3.1638e-04,
         -8.3733e-04, -5.0964e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.9845e-02,  1.0063e-02, -1.5221e-03,  ..., -7.9041e-03,
         -2.9259e-03,  2.1534e-03],
        [ 2.6588e-03, -5.1239e-02, -5.8060e-03,  ..., -4.4937e-03,
          3.6488e-03,  2.3499e-03],
        [ 1.0391e-02, -6.2294e-03, -5.1331e-02,  ...,  1.0788e-02,
         -7.3738e-03,  4.2572e-03],
        ...,
        [-7.0572e-03,  4.8637e-05, -1.5440e-03,  ..., -5.9937e-02,
         -3.4924e-03, -6.2485e-03],
        [-6.9389e-03, -8.5545e-04, -7.5302e-03,  ..., -6.8817e-03,
         -3.3752e-02,  4.0741e-03],
        [ 4.6768e-03,  1.4954e-03,  1.1574e-02,  ...,  9.8648e-03,
         -5.0068e-04, -5.3497e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.6112e-02, -3.2063e-03, -1.7118e-03,  ..., -1.0468e-02,
          5.8174e-05,  2.0218e-03],
        [ 1.1963e-02, -4.1748e-02, -4.1199e-03,  ...,  5.9052e-03,
          1.2215e-02, -6.3477e-03],
        [-2.1439e-03, -9.9335e-03, -4.6692e-02,  ...,  1.9588e-03,
          2.9659e-03, -6.8741e-03],
        ...,
        [-7.3280e-03,  5.1765e-03,  6.6833e-03,  ..., -5.2216e-02,
         -3.4847e-03, -9.4757e-03],
        [-3.0899e-03, -8.8596e-04,  3.3236e-04,  ..., -5.3644e-04,
         -4.2816e-02,  6.4621e-03],
        [-6.7635e-03, -4.4861e-03, -5.8670e-03,  ...,  4.6082e-03,
         -1.9722e-03, -5.1544e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:27:12 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 01:27:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4004,  0.1390,  0.0311,  ...,  0.0533, -1.0752, -0.0471],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3008,  0.0540, -0.4055,  ..., -0.0084, -0.6562,  0.6333],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5771,  0.1051, -0.1699,  ..., -0.2864, -1.1992, -0.4211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4944, -0.1621,  0.1729,  ...,  0.0818, -0.1482,  0.0251],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:27:13 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:27:13 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 01:27:45 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 01:28:17 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 01:28:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2970e-03,  1.9569e-03,  2.8431e-05,  ...,  1.3371e-03,
          2.0123e-03, -6.4278e-04],
        [ 2.3823e-03,  1.4162e-03,  8.4734e-04,  ..., -5.4789e-04,
         -2.4772e-04, -6.6948e-04],
        [ 1.2283e-03,  8.5735e-04,  1.4639e-04,  ...,  4.7779e-04,
         -4.7731e-04, -1.7023e-03],
        ...,
        [-3.2902e-03,  1.1644e-03, -1.6403e-03,  ...,  3.9444e-03,
          1.7405e-03, -4.9400e-04],
        [ 1.7815e-03,  6.7902e-04,  7.0095e-04,  ...,  4.1580e-04,
          5.0812e-03,  1.3914e-03],
        [-7.6485e-04,  4.8614e-04, -5.2691e-04,  ...,  1.0548e-03,
         -3.8624e-04,  1.5199e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0795, -0.0072,  0.0065,  ...,  0.0033, -0.0015,  0.0119],
        [-0.0067, -0.0833, -0.0021,  ..., -0.0063,  0.0004,  0.0077],
        [-0.0011,  0.0027, -0.0818,  ..., -0.0042,  0.0024,  0.0038],
        ...,
        [-0.0047,  0.0036, -0.0075,  ..., -0.0869,  0.0003,  0.0006],
        [ 0.0073, -0.0031, -0.0042,  ..., -0.0078, -0.0916,  0.0075],
        [-0.0055,  0.0127,  0.0016,  ...,  0.0035,  0.0090, -0.0988]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.6558e-02, -6.2704e-05,  1.2159e-03,  ..., -5.2872e-03,
         -7.0572e-04,  4.5624e-03],
        [-1.1337e-02, -8.6792e-02,  6.2866e-03,  ...,  3.6354e-03,
         -3.1166e-03,  7.7171e-03],
        [-3.7975e-03,  2.9039e-04, -8.5144e-02,  ..., -1.1740e-03,
          7.8278e-03, -1.7166e-04],
        ...,
        [-2.4662e-03,  1.0643e-03, -2.3575e-03,  ..., -8.5632e-02,
          2.2793e-03,  1.7948e-03],
        [-2.2507e-04, -3.9864e-03,  3.1662e-04,  ...,  4.3535e-04,
         -8.8257e-02,  4.0588e-03],
        [-3.5057e-03,  6.4583e-03,  5.6381e-03,  ..., -9.2163e-03,
          1.3218e-03, -1.0413e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:28:51 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 01:28:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5137, -0.1078,  0.2732,  ..., -0.1084, -1.2598, -0.0229],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4644,  0.1946, -0.0943,  ...,  0.0934, -0.3098,  0.3655],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4409,  0.0496, -0.6514,  ..., -0.2190, -1.3027, -0.8931],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5283, -0.1251, -0.6138,  ...,  0.6338, -0.4734, -1.2324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:28:51 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:28:51 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 01:29:26 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 01:30:01 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 01:30:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.3008e-03,  1.5759e-04,  1.6727e-03,  ...,  2.0504e-05,
          1.7862e-03,  1.2617e-03],
        [ 3.8128e-03, -8.5678e-03,  8.5211e-04,  ...,  1.7834e-03,
         -2.5043e-03, -4.2391e-04],
        [-2.2221e-03,  5.4779e-03, -7.7400e-03,  ..., -5.5599e-04,
         -1.4019e-04, -1.9569e-03],
        ...,
        [ 2.5253e-03, -4.3564e-03,  7.2861e-04,  ..., -6.8512e-03,
         -1.6193e-03,  4.1122e-03],
        [ 5.1651e-03, -2.0199e-03,  4.6730e-05,  ..., -3.5744e-03,
         -2.7485e-03,  1.2283e-03],
        [ 2.0046e-03,  1.1787e-03,  1.7376e-03,  ..., -7.2479e-05,
         -5.9662e-03, -3.9902e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0939,  0.0157,  0.0068,  ...,  0.0107,  0.0096, -0.0002],
        [ 0.0079, -0.1003, -0.0082,  ...,  0.0098, -0.0103,  0.0135],
        [ 0.0011,  0.0020, -0.1028,  ..., -0.0030,  0.0046,  0.0041],
        ...,
        [ 0.0060,  0.0031,  0.0056,  ..., -0.1001, -0.0007, -0.0043],
        [-0.0137, -0.0011, -0.0012,  ...,  0.0074, -0.1038,  0.0041],
        [-0.0034, -0.0022, -0.0034,  ..., -0.0172,  0.0018, -0.1033]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0814, -0.0019, -0.0013,  ..., -0.0088, -0.0022,  0.0007],
        [ 0.0049, -0.0908,  0.0007,  ..., -0.0060, -0.0053,  0.0048],
        [-0.0058, -0.0042, -0.0847,  ...,  0.0002,  0.0036, -0.0048],
        ...,
        [ 0.0065, -0.0022,  0.0069,  ..., -0.0880, -0.0070, -0.0100],
        [-0.0012,  0.0036, -0.0057,  ..., -0.0036, -0.0825,  0.0054],
        [-0.0119,  0.0028, -0.0091,  ...,  0.0022, -0.0069, -0.0906]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:30:39 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 01:30:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5352,  0.1039, -0.1691,  ..., -0.2761, -1.0889, -0.4346],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5161, -0.1635,  0.1530,  ...,  0.0549, -0.1586, -0.0082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4214, -0.3237, -1.0908,  ..., -0.3010, -1.1064, -0.4399],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7798, -0.7256, -0.7188,  ...,  0.6768, -0.2046, -1.4141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:30:39 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:30:39 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 01:31:15 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 01:31:55 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 01:32:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0048,  0.0051, -0.0015,  ...,  0.0034, -0.0020, -0.0008],
        [ 0.0036, -0.0007, -0.0056,  ...,  0.0042,  0.0012, -0.0025],
        [ 0.0030,  0.0004, -0.0020,  ..., -0.0034, -0.0033,  0.0026],
        ...,
        [-0.0008,  0.0013,  0.0010,  ..., -0.0039,  0.0039,  0.0050],
        [-0.0035,  0.0009, -0.0054,  ...,  0.0027, -0.0004, -0.0021],
        [ 0.0048, -0.0036,  0.0032,  ..., -0.0027,  0.0097, -0.0046]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0856,  0.0013, -0.0069,  ..., -0.0057,  0.0014,  0.0065],
        [-0.0014, -0.0706, -0.0044,  ...,  0.0049,  0.0019,  0.0043],
        [-0.0016, -0.0101, -0.0756,  ...,  0.0042, -0.0083, -0.0044],
        ...,
        [-0.0067,  0.0057, -0.0071,  ..., -0.0826, -0.0023, -0.0012],
        [ 0.0106,  0.0108, -0.0008,  ...,  0.0065, -0.0563, -0.0019],
        [ 0.0071,  0.0063,  0.0100,  ...,  0.0082, -0.0007, -0.0820]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0991,  0.0062,  0.0091,  ...,  0.0008, -0.0116,  0.0040],
        [ 0.0051, -0.0812, -0.0103,  ...,  0.0090,  0.0023,  0.0017],
        [ 0.0035, -0.0016, -0.0825,  ...,  0.0044, -0.0002,  0.0062],
        ...,
        [ 0.0023, -0.0041, -0.0083,  ..., -0.0952,  0.0092,  0.0091],
        [ 0.0099,  0.0050, -0.0011,  ..., -0.0015, -0.0859, -0.0118],
        [-0.0019, -0.0008,  0.0063,  ...,  0.0089,  0.0061, -0.0838]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:32:36 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 01:32:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3916,  0.0295, -0.5591,  ..., -0.1870, -1.1230, -0.8276],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5015, -0.1292, -0.5547,  ...,  0.5493, -0.4360, -1.1963],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8882, -0.4504, -0.9878,  ..., -0.7832, -0.8574, -0.6787],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8096, -1.5791, -1.5596,  ..., -0.0044, -0.5869, -0.6250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:32:36 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:32:36 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 01:33:16 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 01:34:00 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 01:34:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0024, -0.0027, -0.0008,  ..., -0.0001,  0.0015, -0.0002],
        [ 0.0006, -0.0031,  0.0016,  ..., -0.0043,  0.0041, -0.0029],
        [-0.0020,  0.0012, -0.0068,  ...,  0.0009,  0.0028, -0.0014],
        ...,
        [-0.0024,  0.0018, -0.0008,  ..., -0.0022,  0.0029, -0.0007],
        [ 0.0025,  0.0002,  0.0003,  ..., -0.0017, -0.0077, -0.0013],
        [ 0.0014,  0.0005,  0.0025,  ...,  0.0014, -0.0013, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0920,  0.0030,  0.0118,  ..., -0.0062,  0.0021,  0.0065],
        [ 0.0049, -0.0953, -0.0012,  ...,  0.0016,  0.0008,  0.0023],
        [-0.0058,  0.0088, -0.0917,  ..., -0.0030, -0.0080, -0.0096],
        ...,
        [-0.0012,  0.0110, -0.0007,  ..., -0.0884,  0.0022,  0.0005],
        [-0.0011, -0.0071, -0.0053,  ..., -0.0077, -0.0806, -0.0107],
        [ 0.0035,  0.0123, -0.0096,  ..., -0.0210,  0.0018, -0.0972]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2512e-01,  1.7166e-02, -1.0300e-02,  ..., -1.2741e-02,
          6.8855e-04, -4.9591e-05],
        [-3.3855e-05, -1.1176e-01,  3.1719e-03,  ..., -3.5782e-03,
         -4.6806e-03,  1.4076e-02],
        [ 6.6528e-03,  2.0199e-03, -1.0895e-01,  ..., -9.6588e-03,
         -3.1891e-03,  1.7731e-02],
        ...,
        [ 3.1781e-04,  4.3526e-03, -3.4981e-03,  ..., -1.0736e-01,
          3.3760e-04, -1.1749e-03],
        [-3.7022e-03,  1.3817e-02, -5.6381e-03,  ..., -4.3392e-04,
         -1.1285e-01,  1.7471e-02],
        [ 1.1078e-02, -5.9433e-03, -1.4450e-02,  ..., -6.6490e-03,
          9.0103e-03, -1.2280e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:34:41 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 01:34:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3662, -0.2761, -0.8975,  ..., -0.2527, -0.8872, -0.3860],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6221, -0.6089, -0.6123,  ...,  0.4990, -0.1776, -1.1982],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6221, -0.1658, -0.7690,  ..., -0.7012, -0.8862, -0.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6768, -1.3027, -1.3428,  ...,  0.5322, -0.4336, -0.6553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:34:42 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:34:42 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 01:35:30 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 01:36:13 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 01:36:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.9455e-03,  3.1033e-03,  2.7523e-03,  ..., -1.2112e-03,
         -1.0576e-03, -7.3624e-04],
        [ 2.3823e-03,  1.8921e-03, -6.5947e-04,  ...,  2.1858e-03,
         -2.2202e-03,  4.1275e-03],
        [ 7.9775e-04, -1.0157e-03,  7.7782e-03,  ..., -3.0994e-03,
          1.9197e-03,  4.5061e-05],
        ...,
        [-2.2202e-03, -3.4790e-03, -2.3727e-03,  ...,  6.0272e-03,
         -7.8201e-04, -1.1053e-03],
        [-4.5547e-03,  1.1902e-03,  2.8849e-04,  ..., -9.6130e-04,
          5.4932e-04,  3.1242e-03],
        [-6.4993e-04,  6.0511e-04, -4.2839e-03,  ..., -7.7629e-04,
         -1.4839e-03,  3.3169e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.5825e-02, -8.3008e-03, -9.5749e-03,  ...,  1.1307e-02,
          5.6610e-03, -7.2365e-03],
        [ 5.1346e-03, -1.1993e-01, -5.2032e-03,  ..., -1.2939e-02,
         -5.6229e-03,  5.9128e-03],
        [-6.2065e-03,  6.6566e-03, -1.0779e-01,  ...,  4.3411e-03,
         -7.5493e-03,  4.6844e-03],
        ...,
        [-1.5521e-04,  9.7046e-03,  2.2461e-02,  ..., -1.0077e-01,
          4.7112e-03, -3.7537e-03],
        [ 5.5008e-03, -3.0289e-03,  1.3939e-02,  ...,  1.2207e-04,
         -1.2482e-01,  2.0355e-02],
        [-2.3441e-03,  1.3142e-03,  2.3937e-03,  ...,  4.5433e-03,
          6.9542e-03, -1.0724e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3135e-01, -1.4572e-02,  4.9248e-03,  ...,  1.7838e-02,
          1.0002e-02,  8.0872e-03],
        [-4.0932e-03, -1.6248e-01, -8.2493e-04,  ...,  9.9640e-03,
         -9.9640e-03, -6.5384e-03],
        [-1.4038e-02, -8.1253e-03, -1.2769e-01,  ...,  1.1261e-02,
         -5.8098e-03, -1.5038e-02],
        ...,
        [-8.0566e-03,  1.5869e-02,  6.3782e-03,  ..., -1.5222e-01,
          2.7065e-03, -1.1444e-04],
        [ 4.0627e-03, -7.5874e-03,  6.9046e-03,  ...,  4.7989e-03,
         -1.3855e-01, -3.6049e-03],
        [-6.4201e-03,  5.8136e-03, -5.1537e-03,  ..., -1.1520e-02,
         -7.0496e-03, -1.4502e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:36:58 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 01:36:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6606, -0.3586, -0.7402,  ..., -0.5425, -0.6406, -0.5601],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6133, -1.2070, -1.1494,  ...,  0.0080, -0.4429, -0.5176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3220,  0.8750, -1.1191,  ..., -0.9185, -0.2183, -1.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.5361, -0.5781, -1.2031,  ..., -0.1421, -0.5918,  0.4082],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:36:58 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:36:58 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 01:37:48 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 01:38:38 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 01:39:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.2218e-03,  4.0550e-03, -1.2457e-04,  ...,  2.6855e-03,
          3.5477e-03, -6.3992e-04],
        [ 1.7366e-03, -2.7008e-03,  7.1144e-03,  ...,  3.1242e-03,
          9.4271e-04,  4.1962e-03],
        [ 3.5496e-03, -5.7945e-03, -8.0414e-03,  ..., -1.5259e-03,
         -2.8133e-03, -3.6812e-03],
        ...,
        [ 4.6997e-03, -6.2408e-03,  3.5076e-03,  ..., -6.0158e-03,
         -3.4389e-03, -2.7561e-04],
        [-5.9605e-05, -1.0900e-03,  1.1387e-03,  ...,  6.6948e-04,
         -3.2711e-03,  7.0095e-05],
        [ 2.2831e-03, -1.1740e-03, -1.9007e-03,  ...,  1.3294e-03,
         -4.6396e-04, -6.3419e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1078,  0.0092,  0.0048,  ...,  0.0060, -0.0104,  0.0060],
        [ 0.0021, -0.1086,  0.0096,  ...,  0.0162,  0.0102, -0.0095],
        [ 0.0100, -0.0032, -0.1108,  ...,  0.0054,  0.0083,  0.0104],
        ...,
        [-0.0065, -0.0008, -0.0012,  ..., -0.0959,  0.0090, -0.0085],
        [ 0.0051,  0.0061,  0.0044,  ...,  0.0150, -0.0980,  0.0113],
        [-0.0074,  0.0108,  0.0015,  ..., -0.0012, -0.0022, -0.0912]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1218,  0.0245,  0.0050,  ..., -0.0074, -0.0133,  0.0069],
        [ 0.0076, -0.0936,  0.0008,  ...,  0.0022, -0.0044, -0.0081],
        [ 0.0007,  0.0163, -0.1121,  ..., -0.0005, -0.0041,  0.0119],
        ...,
        [ 0.0014, -0.0042, -0.0059,  ..., -0.0961,  0.0065, -0.0019],
        [-0.0066, -0.0133, -0.0048,  ...,  0.0043, -0.1185,  0.0182],
        [ 0.0091,  0.0056,  0.0021,  ...,  0.0083, -0.0014, -0.1107]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:39:30 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 01:39:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4414, -0.1395, -0.5420,  ..., -0.4880, -0.6094, -0.5562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1416, -0.9287, -0.9146,  ...,  0.3140, -0.3096, -0.4536],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6387,  0.7197, -1.5410,  ..., -0.7539, -0.3022, -0.6816],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1133, -0.0605, -1.4404,  ..., -0.3892, -0.5649,  0.4773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:39:30 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:39:30 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 01:40:23 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 01:41:04 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 01:41:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0013, -0.0023,  0.0031,  ...,  0.0004,  0.0001, -0.0007],
        [ 0.0014,  0.0023,  0.0004,  ..., -0.0011, -0.0008,  0.0025],
        [-0.0033, -0.0067,  0.0011,  ...,  0.0004,  0.0032, -0.0004],
        ...,
        [ 0.0016,  0.0046,  0.0044,  ...,  0.0025, -0.0052,  0.0029],
        [-0.0011, -0.0055,  0.0015,  ...,  0.0010,  0.0029,  0.0030],
        [-0.0040, -0.0014,  0.0019,  ..., -0.0049, -0.0004, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1567,  0.0048, -0.0079,  ..., -0.0054, -0.0028, -0.0077],
        [ 0.0067, -0.1624, -0.0103,  ..., -0.0072, -0.0049,  0.0056],
        [ 0.0075, -0.0009, -0.1566,  ..., -0.0152, -0.0071, -0.0015],
        ...,
        [-0.0022,  0.0012,  0.0014,  ..., -0.1798,  0.0012,  0.0012],
        [ 0.0054,  0.0006, -0.0062,  ...,  0.0087, -0.1660, -0.0064],
        [ 0.0100, -0.0042, -0.0037,  ..., -0.0135, -0.0100, -0.1490]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.3279e-01,  1.6922e-02,  6.5765e-03,  ..., -1.4160e-02,
         -1.0284e-02, -2.9488e-03],
        [ 7.3433e-03, -2.4951e-01, -8.5831e-03,  ..., -1.1627e-02,
          4.3716e-03, -1.0233e-03],
        [ 6.6948e-04, -2.0218e-04, -2.2900e-01,  ...,  2.0027e-04,
          1.3687e-02,  2.1057e-03],
        ...,
        [-1.6190e-02,  1.0811e-02, -4.5738e-03,  ..., -2.6587e-01,
          1.0460e-02, -7.2403e-03],
        [-1.4107e-02, -9.8801e-04, -4.8294e-03,  ..., -6.2943e-05,
         -2.4097e-01,  4.1924e-03],
        [ 6.0005e-03, -9.2697e-03, -6.5308e-03,  ..., -3.1681e-03,
          5.2948e-03, -2.3999e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:41:57 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 01:41:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2559,  0.5815, -0.7822,  ..., -0.6255, -0.1622, -0.8945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1777, -0.4695, -0.9419,  ..., -0.1132, -0.4661,  0.2737],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6714,  0.9697, -1.4199,  ..., -0.1802, -0.1672, -0.0303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6758,  0.0950, -1.5029,  ..., -0.9590, -0.4407,  0.7334],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:41:57 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:41:57 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 01:42:48 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 01:43:43 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 01:44:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.7746e-03,  4.5848e-04,  1.7147e-03,  ...,  1.0958e-03,
         -1.0538e-03, -2.0981e-03],
        [-2.2717e-03, -2.9736e-03,  3.2940e-03,  ..., -1.5173e-03,
          3.0780e-04, -1.2646e-03],
        [ 1.8282e-03,  3.7575e-03, -6.3896e-03,  ..., -7.1716e-04,
         -3.0556e-03,  9.6798e-04],
        ...,
        [ 2.2888e-03, -3.4485e-03, -3.5763e-04,  ..., -1.9569e-03,
          5.7125e-04, -2.4109e-03],
        [ 6.4135e-04,  1.8501e-03, -1.8196e-03,  ..., -1.1873e-04,
         -9.6588e-03, -7.9727e-04],
        [-1.6174e-03,  8.8072e-04,  1.3103e-03,  ..., -3.4952e-04,
          1.1563e-04, -9.9897e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.7219e-02,  1.7262e-03,  1.6922e-02,  ..., -3.7308e-03,
         -3.4637e-03,  3.9787e-03],
        [ 1.3847e-03, -1.0162e-01,  1.4267e-02,  ..., -8.8024e-04,
         -8.3694e-03,  7.0877e-03],
        [-5.4588e-03, -9.6893e-03, -7.9407e-02,  ..., -8.8501e-04,
         -1.6136e-03,  9.7198e-03],
        ...,
        [ 2.4242e-03, -1.0109e-04,  5.4550e-04,  ..., -7.0312e-02,
          5.1842e-03,  2.5272e-03],
        [-7.0496e-03,  1.4565e-02, -9.6054e-03,  ..., -6.7291e-03,
         -9.3018e-02,  7.8583e-03],
        [-8.9359e-04,  6.2256e-03, -2.5253e-03,  ..., -2.9144e-03,
          1.4832e-02, -7.7026e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0818, -0.0045, -0.0046,  ...,  0.0027,  0.0003, -0.0053],
        [ 0.0061, -0.0897, -0.0068,  ...,  0.0008,  0.0100,  0.0179],
        [-0.0033,  0.0029, -0.0845,  ..., -0.0088, -0.0106,  0.0013],
        ...,
        [-0.0061, -0.0050,  0.0074,  ..., -0.0735,  0.0156,  0.0003],
        [-0.0017,  0.0007,  0.0071,  ...,  0.0159, -0.0916,  0.0131],
        [-0.0077,  0.0096, -0.0013,  ...,  0.0013,  0.0015, -0.0780]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:44:39 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 01:44:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4146,  0.4089, -0.9253,  ..., -0.4739, -0.1874, -0.4587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8589, -0.0834, -1.0459,  ..., -0.3027, -0.4204,  0.3428],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7656,  1.7695, -1.7861,  ...,  0.4131,  0.6445, -0.2542],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7837, -0.2444, -1.8770,  ..., -0.5176,  0.4988,  0.9131],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:44:39 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:44:39 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 01:45:33 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 01:46:33 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 01:47:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.9426e-03,  1.7433e-03, -1.0061e-03,  ..., -2.7733e-03,
          8.1301e-05, -4.9057e-03],
        [-3.9101e-03,  4.3678e-03, -2.7695e-03,  ...,  9.5940e-04,
         -2.5978e-03, -2.4910e-03],
        [-4.5433e-03, -4.1885e-03,  4.6539e-04,  ...,  2.0313e-03,
         -1.0185e-03, -4.4556e-03],
        ...,
        [ 1.4095e-03, -5.1022e-04,  3.0479e-03,  ..., -3.0875e-04,
         -4.0054e-05,  5.2719e-03],
        [ 5.0011e-03,  1.3781e-03,  9.0599e-04,  ..., -4.8370e-03,
         -3.9520e-03, -4.6802e-04],
        [-2.4624e-03,  5.6953e-03,  7.4577e-04,  ..., -1.5516e-03,
         -4.2229e-03, -7.7438e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.9854e-02,  8.8272e-03, -6.6528e-03,  ..., -1.1505e-02,
         -2.3537e-03,  1.1044e-03],
        [-5.4054e-03, -1.0480e-01,  1.9119e-02,  ...,  2.3079e-03,
         -8.4839e-03,  1.1887e-02],
        [-9.0942e-03,  1.4343e-03, -1.0876e-01,  ..., -8.4457e-03,
          2.1332e-02, -1.3130e-02],
        ...,
        [-1.7639e-02, -2.1458e-03, -1.0025e-02,  ..., -1.2280e-01,
         -8.1482e-03,  5.0163e-03],
        [-1.2088e-04,  1.1055e-02, -1.3676e-03,  ...,  1.4214e-02,
         -1.2671e-01,  2.1243e-04],
        [-3.6926e-03, -7.2746e-03, -8.5144e-03,  ...,  1.3142e-03,
         -4.3678e-04, -8.9478e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2469e-01,  5.4893e-03, -6.4850e-04,  ..., -8.0185e-03,
          2.3499e-02, -2.6836e-03],
        [-8.4686e-03, -1.4124e-01, -5.4436e-03,  ...,  9.8419e-03,
         -1.3069e-02,  5.4169e-03],
        [ 6.8970e-03,  8.8501e-03, -1.5698e-01,  ..., -3.7689e-03,
         -7.3662e-03, -1.7029e-02],
        ...,
        [-4.3449e-03,  9.8953e-03, -5.2490e-03,  ..., -1.5222e-01,
         -3.8490e-03,  4.9095e-03],
        [ 8.1482e-03,  1.8082e-03,  9.9373e-04,  ...,  3.5839e-03,
         -1.5234e-01,  5.1422e-03],
        [ 5.3406e-05,  1.7700e-03,  1.5469e-03,  ..., -8.5449e-04,
          2.1774e-02, -1.4600e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:47:26 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-07-01 01:47:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4226,  0.5322, -0.8003,  ..., -0.1227, -0.0730, -0.0796],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4187,  0.0430, -0.9531,  ..., -0.6299, -0.2615,  0.4312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3145,  1.5059, -1.4473,  ...,  0.4663,  0.6631, -0.5469],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.9746, -0.3606, -1.9766,  ..., -0.3704,  0.2219,  0.8921],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:47:26 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:47:26 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 01:48:26 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 01:49:26 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 01:50:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0019, -0.0033,  0.0054,  ..., -0.0012, -0.0109, -0.0017],
        [-0.0060, -0.0037, -0.0036,  ..., -0.0004,  0.0051, -0.0084],
        [ 0.0003, -0.0077,  0.0005,  ...,  0.0013, -0.0008,  0.0054],
        ...,
        [-0.0002,  0.0017, -0.0110,  ..., -0.0031,  0.0019, -0.0029],
        [-0.0044, -0.0024,  0.0033,  ...,  0.0007,  0.0027,  0.0044],
        [-0.0007,  0.0023,  0.0038,  ..., -0.0006, -0.0019, -0.0095]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0907e-01,  1.0567e-02, -1.6022e-04,  ..., -3.9024e-03,
          6.4430e-03, -1.7929e-04],
        [ 2.2774e-03, -1.0193e-01, -5.7335e-03,  ..., -6.5231e-03,
          4.2801e-03, -5.8270e-04],
        [ 7.8011e-04, -3.5400e-03, -1.0382e-01,  ..., -1.5812e-03,
          8.1253e-03, -8.5449e-03],
        ...,
        [-3.1719e-03, -4.9305e-04, -1.9165e-02,  ..., -1.0352e-01,
          2.1912e-02, -6.8665e-05],
        [-1.4801e-02, -1.5259e-05,  7.7705e-03,  ...,  1.2848e-02,
         -9.3018e-02, -8.2932e-03],
        [-1.5602e-03,  1.1810e-02,  4.7874e-03,  ..., -1.6289e-03,
          9.4414e-04, -1.0046e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1006,  0.0083, -0.0066,  ..., -0.0072, -0.0002, -0.0207],
        [ 0.0052, -0.0932,  0.0044,  ...,  0.0027,  0.0110,  0.0031],
        [ 0.0008, -0.0055, -0.0983,  ..., -0.0038,  0.0121, -0.0135],
        ...,
        [-0.0145, -0.0117, -0.0023,  ..., -0.1006,  0.0190, -0.0029],
        [-0.0146,  0.0096, -0.0020,  ...,  0.0201, -0.1016, -0.0027],
        [-0.0055,  0.0142, -0.0065,  ..., -0.0204, -0.0072, -0.1055]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:50:30 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-07-01 01:50:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4414,  0.9375, -0.9336,  ...,  0.2037,  0.3499, -0.1798],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4812, -0.1821, -1.0820,  ..., -0.3191,  0.3044,  0.5264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.3730,  1.6855, -1.2109,  ...,  0.5923,  0.3828,  0.0576],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6221e+00, -7.5781e-01, -3.2246e+00,  ...,  1.7090e-03,
         9.4360e-02,  1.8438e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:50:30 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:50:30 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 01:51:31 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 01:52:33 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 01:53:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.3008e-03, -1.7338e-03,  2.0123e-04,  ...,  1.1539e-03,
         -3.0575e-03, -1.9350e-03],
        [ 1.1005e-03,  5.6534e-03,  1.4305e-03,  ..., -1.2846e-03,
          5.0468e-03, -2.3766e-03],
        [-2.5501e-03, -5.2929e-04,  3.7937e-03,  ..., -4.5662e-03,
          1.4534e-03,  1.4286e-03],
        ...,
        [-4.9934e-03, -2.9678e-03, -2.7466e-03,  ...,  5.2567e-03,
         -2.4700e-03, -2.7561e-04],
        [ 3.0251e-03,  2.4354e-04,  3.4237e-03,  ...,  2.2449e-03,
          7.5417e-03,  1.0271e-03],
        [ 4.2915e-05,  2.6569e-03,  2.3708e-03,  ...,  1.0395e-03,
          1.1415e-03,  1.1986e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0866, -0.0077, -0.0016,  ..., -0.0047, -0.0021,  0.0206],
        [ 0.0029, -0.1021,  0.0041,  ...,  0.0054, -0.0136, -0.0097],
        [-0.0044,  0.0071, -0.0959,  ..., -0.0032, -0.0126, -0.0096],
        ...,
        [ 0.0083, -0.0025, -0.0062,  ..., -0.0956, -0.0076,  0.0045],
        [-0.0098, -0.0005, -0.0003,  ..., -0.0131, -0.0810,  0.0104],
        [ 0.0042,  0.0041,  0.0062,  ...,  0.0020, -0.0069, -0.1017]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1252,  0.0022, -0.0142,  ..., -0.0163, -0.0038,  0.0058],
        [-0.0092, -0.1323, -0.0093,  ..., -0.0196, -0.0057,  0.0056],
        [-0.0197,  0.0109, -0.1194,  ...,  0.0048,  0.0008,  0.0047],
        ...,
        [ 0.0090, -0.0033,  0.0123,  ..., -0.1119, -0.0095, -0.0096],
        [-0.0005, -0.0061, -0.0082,  ...,  0.0013, -0.1111,  0.0057],
        [ 0.0134,  0.0084, -0.0096,  ..., -0.0017,  0.0056, -0.1241]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:53:35 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-07-01 01:53:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2222,  0.8330, -0.7715,  ...,  0.2433,  0.3586, -0.3340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1211, -0.2091, -1.1016,  ..., -0.2133,  0.1315,  0.4939],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1328,  0.9170, -1.1172,  ...,  0.2969,  0.6260,  0.3774],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.5410, -0.6885, -3.5977,  ..., -0.3145,  0.2881,  2.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:53:35 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:53:35 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 01:54:38 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 01:55:42 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 01:56:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0064,  0.0001,  0.0066,  ..., -0.0048, -0.0035, -0.0041],
        [-0.0005,  0.0010,  0.0009,  ...,  0.0028,  0.0023, -0.0006],
        [-0.0008, -0.0036, -0.0084,  ...,  0.0003,  0.0036, -0.0045],
        ...,
        [ 0.0050, -0.0019, -0.0055,  ...,  0.0008, -0.0022, -0.0036],
        [-0.0001, -0.0002, -0.0060,  ..., -0.0018,  0.0010,  0.0032],
        [ 0.0015,  0.0058,  0.0012,  ..., -0.0034,  0.0004, -0.0095]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0670,  0.0103,  0.0134,  ...,  0.0048, -0.0016, -0.0182],
        [ 0.0037, -0.0589, -0.0115,  ...,  0.0086,  0.0049,  0.0021],
        [ 0.0066, -0.0033, -0.0630,  ..., -0.0039,  0.0139, -0.0107],
        ...,
        [-0.0086,  0.0072, -0.0087,  ..., -0.0627, -0.0128,  0.0035],
        [ 0.0069, -0.0010,  0.0033,  ...,  0.0025, -0.0538,  0.0069],
        [-0.0159,  0.0083,  0.0028,  ..., -0.0114,  0.0026, -0.0537]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0690,  0.0009,  0.0026,  ..., -0.0012, -0.0077, -0.0054],
        [ 0.0082, -0.0740, -0.0138,  ...,  0.0143, -0.0009,  0.0062],
        [ 0.0199,  0.0271, -0.0803,  ..., -0.0079, -0.0041, -0.0045],
        ...,
        [-0.0086, -0.0079, -0.0137,  ..., -0.0834, -0.0072, -0.0038],
        [ 0.0015,  0.0051, -0.0022,  ...,  0.0089, -0.0790,  0.0005],
        [-0.0137, -0.0015,  0.0124,  ..., -0.0060, -0.0091, -0.0715]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 01:56:49 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-07-01 01:56:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2074,  0.8423, -0.5830,  ...,  0.2771,  0.1987, -0.0136],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8535, -0.4072, -1.6230,  ..., -0.0042,  0.0619,  0.9297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1445,  0.9639, -1.0234,  ...,  0.4507,  0.4446,  0.7393],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.9854, -0.5933, -3.5605,  ...,  0.1157,  0.3308,  2.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 01:56:49 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 01:56:49 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 01:57:54 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 01:59:01 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 02:00:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0020, -0.0068, -0.0020,  ...,  0.0010,  0.0007, -0.0009],
        [-0.0034,  0.0092, -0.0019,  ...,  0.0013,  0.0008, -0.0002],
        [-0.0012, -0.0031,  0.0013,  ..., -0.0015,  0.0017, -0.0106],
        ...,
        [-0.0004,  0.0001, -0.0004,  ...,  0.0077,  0.0013,  0.0011],
        [ 0.0038,  0.0068,  0.0064,  ..., -0.0073,  0.0003, -0.0006],
        [ 0.0027,  0.0002,  0.0014,  ..., -0.0021,  0.0056, -0.0053]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-6.6711e-02,  1.0849e-02, -6.6471e-04,  ..., -9.7809e-03,
         -7.8201e-03, -3.3779e-03],
        [ 1.5068e-03, -5.0323e-02, -1.2627e-03,  ...,  9.5367e-07,
          1.8902e-03,  3.5629e-03],
        [ 5.3177e-03,  1.0025e-02, -6.4270e-02,  ..., -1.2032e-02,
          1.4229e-02, -3.1414e-03],
        ...,
        [ 6.4507e-03, -5.6410e-04,  7.2365e-03,  ..., -5.9082e-02,
         -1.6289e-03, -6.4545e-03],
        [ 6.5613e-03,  1.3428e-02,  2.4704e-02,  ...,  5.8098e-03,
         -7.0007e-02, -5.8594e-03],
        [-1.4542e-02, -6.2332e-03,  1.0651e-02,  ..., -7.9346e-03,
          2.7370e-03, -5.6030e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.7688e-02,  8.7738e-05,  3.6011e-03,  ..., -1.0101e-02,
          8.5449e-03, -1.1482e-03],
        [-2.7256e-03, -7.4890e-02, -2.6073e-03,  ..., -4.3869e-03,
          3.0594e-03, -9.1705e-03],
        [ 6.8245e-03, -9.2010e-03, -8.1543e-02,  ..., -1.1070e-02,
          1.7242e-02,  3.3569e-04],
        ...,
        [ 1.4839e-02,  3.7117e-03,  1.7883e-02,  ..., -6.1981e-02,
          1.0910e-02,  2.3842e-05],
        [ 1.8341e-02, -3.1948e-04,  3.7880e-03,  ..., -1.8826e-03,
         -1.0333e-01,  3.6869e-03],
        [-3.8700e-03, -7.6389e-04, -1.0437e-02,  ..., -9.2468e-03,
          1.5991e-02, -8.2703e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:00:09 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-07-01 02:00:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5474,  0.4214, -0.5132,  ...,  0.1295,  0.2932,  0.1287],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7559, -0.3335, -1.7441,  ..., -0.1558,  0.1504,  0.9800],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.0430,  0.8755, -1.1670,  ...,  0.5459,  0.4929,  0.9028],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8711, -0.3999, -3.6816,  ..., -0.5845,  0.0996,  2.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:00:09 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:00:09 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 02:01:16 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 02:02:25 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 02:03:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0057, -0.0022, -0.0006,  ..., -0.0012, -0.0027, -0.0035],
        [-0.0025,  0.0052,  0.0014,  ..., -0.0008, -0.0029,  0.0014],
        [-0.0023, -0.0051,  0.0037,  ...,  0.0026,  0.0051,  0.0019],
        ...,
        [ 0.0004, -0.0006, -0.0037,  ..., -0.0008, -0.0069, -0.0023],
        [-0.0014,  0.0007,  0.0005,  ..., -0.0019, -0.0017,  0.0004],
        [-0.0020, -0.0011, -0.0011,  ...,  0.0036,  0.0028, -0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0638, -0.0163, -0.0016,  ..., -0.0162, -0.0048, -0.0060],
        [ 0.0042, -0.0767,  0.0089,  ..., -0.0215,  0.0044,  0.0063],
        [-0.0038,  0.0141, -0.0612,  ..., -0.0041,  0.0108,  0.0058],
        ...,
        [-0.0121,  0.0040, -0.0012,  ..., -0.0565, -0.0020,  0.0167],
        [-0.0106, -0.0022, -0.0096,  ...,  0.0012, -0.0496, -0.0100],
        [ 0.0037, -0.0109, -0.0066,  ...,  0.0048,  0.0165, -0.0417]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0605,  0.0104,  0.0008,  ...,  0.0038,  0.0070, -0.0155],
        [-0.0085, -0.0765,  0.0027,  ..., -0.0046,  0.0080,  0.0182],
        [ 0.0019, -0.0089, -0.0761,  ..., -0.0039,  0.0039, -0.0148],
        ...,
        [-0.0074,  0.0061, -0.0025,  ..., -0.0660, -0.0006,  0.0140],
        [-0.0007, -0.0052, -0.0090,  ..., -0.0091, -0.0598,  0.0096],
        [-0.0192,  0.0034, -0.0194,  ..., -0.0177, -0.0066, -0.0721]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:03:37 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-07-01 02:03:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5254,  0.4180, -0.4607,  ...,  0.1907,  0.2172,  0.2859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9419, -0.2808, -1.6211,  ...,  0.0505,  0.1779,  1.1191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.4502,  0.7241, -1.5996,  ...,  0.9023,  0.4382,  0.9951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.5742, -0.5229, -3.9766,  ..., -1.1641,  0.2139,  1.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:03:37 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:03:37 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 02:04:46 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 02:05:57 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 02:07:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0028, -0.0024, -0.0022,  ..., -0.0044, -0.0085, -0.0076],
        [ 0.0022,  0.0108, -0.0030,  ..., -0.0031,  0.0018, -0.0030],
        [-0.0022, -0.0040,  0.0054,  ...,  0.0014, -0.0019,  0.0047],
        ...,
        [-0.0043, -0.0029, -0.0006,  ...,  0.0012, -0.0012,  0.0028],
        [-0.0007, -0.0030,  0.0017,  ...,  0.0048,  0.0018, -0.0008],
        [-0.0004,  0.0031, -0.0022,  ...,  0.0006,  0.0003,  0.0154]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0250, -0.0109,  0.0034,  ..., -0.0132, -0.0107, -0.0090],
        [ 0.0099, -0.0269, -0.0077,  ...,  0.0023, -0.0043,  0.0046],
        [-0.0014,  0.0024, -0.0305,  ..., -0.0005,  0.0090,  0.0067],
        ...,
        [-0.0095, -0.0097, -0.0179,  ..., -0.0216,  0.0112, -0.0025],
        [ 0.0152,  0.0108, -0.0036,  ..., -0.0135, -0.0308,  0.0101],
        [-0.0064,  0.0150, -0.0016,  ..., -0.0040,  0.0107, -0.0198]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0440, -0.0019,  0.0232,  ..., -0.0185,  0.0049,  0.0009],
        [ 0.0140, -0.0275,  0.0088,  ..., -0.0007,  0.0035, -0.0114],
        [ 0.0058, -0.0070, -0.0677,  ..., -0.0064,  0.0062,  0.0003],
        ...,
        [-0.0095,  0.0252, -0.0159,  ..., -0.0504,  0.0014, -0.0053],
        [ 0.0111, -0.0016, -0.0199,  ...,  0.0107, -0.0545,  0.0353],
        [-0.0063,  0.0014,  0.0154,  ..., -0.0113,  0.0193, -0.0668]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:07:10 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-07-01 02:07:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8491,  0.3452, -0.4749,  ...,  0.2198,  0.1912,  0.3384],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7764, -0.1729, -1.4482,  ..., -0.2301,  0.0371,  0.8374],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7676,  1.3271, -2.1680,  ...,  1.3652,  0.0500,  0.8696],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4863, -0.9150, -3.8691,  ..., -1.0703,  0.7729,  1.6611],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:07:10 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:07:10 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 02:08:22 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 02:09:33 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 02:10:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0152, -0.0012, -0.0018,  ...,  0.0044, -0.0065,  0.0035],
        [-0.0082,  0.0146,  0.0017,  ..., -0.0016, -0.0050,  0.0035],
        [-0.0006,  0.0023,  0.0168,  ..., -0.0016,  0.0030,  0.0024],
        ...,
        [ 0.0002, -0.0029, -0.0035,  ...,  0.0147, -0.0047,  0.0037],
        [ 0.0001, -0.0041,  0.0010,  ..., -0.0012,  0.0122, -0.0025],
        [-0.0006, -0.0019,  0.0025,  ...,  0.0004,  0.0054,  0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0291,  0.0086,  0.0018,  ...,  0.0033, -0.0164, -0.0053],
        [ 0.0111, -0.0194,  0.0046,  ..., -0.0064, -0.0091,  0.0050],
        [-0.0023, -0.0027, -0.0116,  ..., -0.0021,  0.0064,  0.0045],
        ...,
        [-0.0041, -0.0163, -0.0007,  ..., -0.0139, -0.0028, -0.0104],
        [ 0.0020,  0.0101, -0.0012,  ..., -0.0140, -0.0293,  0.0061],
        [-0.0049, -0.0027, -0.0091,  ..., -0.0095, -0.0047, -0.0341]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.8492e-02, -1.3077e-02,  1.3069e-02,  ..., -6.3248e-03,
         -2.8534e-03, -8.3084e-03],
        [ 5.9319e-04, -3.5706e-02,  5.0664e-05,  ...,  5.5656e-03,
          7.4768e-04,  5.1270e-03],
        [ 1.4557e-02, -1.6508e-03, -3.3173e-02,  ...,  6.0196e-03,
          1.0391e-02,  4.6921e-03],
        ...,
        [-5.3558e-03, -6.3324e-03, -1.1696e-02,  ..., -5.2765e-02,
          1.5335e-03, -6.3057e-03],
        [-1.7471e-02,  8.0872e-03,  1.0519e-03,  ..., -3.1097e-02,
         -4.0863e-02, -6.0844e-04],
        [ 5.1270e-03, -2.1553e-04,  2.2736e-03,  ...,  5.1994e-03,
          1.3733e-02, -4.0466e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:10:47 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-07-01 02:10:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5630,  0.2673, -0.6182,  ...,  0.3306,  0.1742,  0.3572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.0049, -0.2120, -1.5322,  ..., -0.4595,  0.0927,  0.5752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.0625,  1.5342, -2.7070,  ...,  1.6406, -0.0069,  1.1953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4033, -0.2666, -4.2617,  ..., -0.8438,  0.0283,  1.9912],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:10:47 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:10:47 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 02:12:09 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 02:13:30 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 02:14:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.3512e-02, -3.6373e-03, -4.0936e-04,  ..., -2.4986e-04,
         -4.0317e-04, -6.3324e-03],
        [-3.6144e-04,  1.2756e-02,  2.3937e-03,  ...,  2.5997e-03,
          6.1646e-03, -4.0627e-03],
        [-1.8330e-03, -3.9043e-03,  2.0477e-02,  ..., -7.5245e-04,
          5.2032e-03, -4.0970e-03],
        ...,
        [ 2.1019e-03,  4.9744e-03, -6.3248e-03,  ...,  1.9196e-02,
          2.0008e-03, -1.0824e-03],
        [ 3.7813e-04,  1.4648e-03,  6.2523e-03,  ...,  9.6798e-04,
          1.2589e-02, -5.3644e-07],
        [-5.6572e-03, -5.1403e-04, -3.3226e-03,  ..., -3.7766e-03,
          1.0246e-02,  1.5274e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0227,  0.0056, -0.0176,  ..., -0.0200, -0.0011,  0.0036],
        [-0.0012, -0.0126, -0.0035,  ..., -0.0112,  0.0074, -0.0082],
        [-0.0060, -0.0104, -0.0148,  ..., -0.0094,  0.0101, -0.0194],
        ...,
        [ 0.0078, -0.0034, -0.0041,  ..., -0.0175, -0.0148, -0.0007],
        [ 0.0219, -0.0069, -0.0012,  ...,  0.0070, -0.0161, -0.0089],
        [-0.0010,  0.0129, -0.0079,  ...,  0.0042, -0.0016, -0.0291]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0443,  0.0208, -0.0058,  ..., -0.0050, -0.0064, -0.0020],
        [ 0.0159, -0.0545, -0.0196,  ..., -0.0211,  0.0090, -0.0022],
        [ 0.0023, -0.0006, -0.0334,  ..., -0.0086,  0.0024, -0.0125],
        ...,
        [ 0.0152,  0.0127, -0.0181,  ..., -0.0552, -0.0010,  0.0075],
        [ 0.0256, -0.0043, -0.0107,  ..., -0.0101, -0.0390, -0.0115],
        [ 0.0013,  0.0124,  0.0051,  ..., -0.0050, -0.0035, -0.0409]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:14:53 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-07-01 02:14:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2935,  0.4797, -0.8032,  ...,  0.5029,  0.0284,  0.2998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9492, -0.3345, -1.4238,  ..., -0.3843,  0.3037,  0.6079],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6665,  1.1279, -1.3154,  ...,  1.2246, -0.0241,  1.1699],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6973, -1.4248, -3.0938,  ..., -1.0420,  0.1812,  2.8105],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:14:53 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:14:53 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 02:16:16 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 02:17:39 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 02:18:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1885e-03,  1.3351e-03, -3.5667e-04,  ...,  9.9945e-04,
         -1.7347e-03, -2.9349e-04],
        [ 7.9107e-04, -4.4785e-03,  3.5310e-04,  ...,  8.9645e-04,
         -4.8447e-04, -2.1763e-03],
        [-1.4849e-03,  4.9210e-04, -5.3749e-03,  ..., -1.5373e-03,
          1.4772e-03,  1.7509e-03],
        ...,
        [-3.2310e-03,  8.3148e-05, -1.3423e-04,  ..., -6.2218e-03,
         -9.0837e-04,  2.0428e-03],
        [ 1.1959e-03, -2.3854e-04,  4.5013e-04,  ..., -9.3985e-04,
         -5.8441e-03, -3.9983e-04],
        [-3.9983e-04,  9.9087e-04, -7.8583e-04,  ...,  1.4341e-04,
         -5.9366e-04, -3.1185e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0460, -0.0101,  0.0139,  ...,  0.0014, -0.0045,  0.0023],
        [-0.0116, -0.0352, -0.0025,  ..., -0.0006, -0.0062, -0.0123],
        [ 0.0077, -0.0155, -0.0152,  ...,  0.0043, -0.0126, -0.0062],
        ...,
        [ 0.0051,  0.0059,  0.0046,  ..., -0.0457, -0.0005,  0.0075],
        [-0.0007,  0.0024,  0.0118,  ..., -0.0117, -0.0228,  0.0108],
        [ 0.0031, -0.0078,  0.0031,  ...,  0.0069,  0.0073, -0.0193]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0665, -0.0005,  0.0150,  ..., -0.0061,  0.0170,  0.0150],
        [-0.0068, -0.0664,  0.0154,  ..., -0.0097, -0.0028, -0.0010],
        [ 0.0023,  0.0008, -0.0677,  ...,  0.0080, -0.0210, -0.0102],
        ...,
        [ 0.0050, -0.0088,  0.0118,  ..., -0.0901, -0.0142, -0.0034],
        [-0.0037,  0.0173, -0.0048,  ..., -0.0146, -0.0517,  0.0020],
        [ 0.0005, -0.0077,  0.0077,  ..., -0.0016,  0.0139, -0.0738]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:19:01 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-07-01 02:19:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3757,  0.5322, -0.9619,  ...,  0.5757,  0.0165,  0.3992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5293, -0.0918, -1.5234,  ..., -0.2917,  0.0322,  0.7021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.9346,  1.5332, -1.0977,  ...,  1.1875,  0.2014,  1.1133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2949, -0.9307, -1.9053,  ..., -0.7637,  0.4680,  2.9199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:19:01 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:19:01 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 02:20:26 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 02:21:50 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 02:23:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0069, -0.0004,  0.0018,  ..., -0.0001, -0.0015, -0.0005],
        [-0.0024,  0.0069,  0.0017,  ...,  0.0029,  0.0011,  0.0033],
        [-0.0003,  0.0040,  0.0099,  ..., -0.0005, -0.0011, -0.0024],
        ...,
        [-0.0006, -0.0025,  0.0029,  ...,  0.0067, -0.0010, -0.0009],
        [ 0.0006,  0.0009,  0.0005,  ...,  0.0016,  0.0070,  0.0048],
        [-0.0036,  0.0008,  0.0044,  ..., -0.0017,  0.0025,  0.0106]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0431,  0.0113,  0.0086,  ..., -0.0112,  0.0004, -0.0076],
        [ 0.0138, -0.0286,  0.0179,  ..., -0.0039, -0.0060, -0.0122],
        [-0.0059,  0.0170, -0.0136,  ..., -0.0012,  0.0003, -0.0035],
        ...,
        [ 0.0005, -0.0150, -0.0075,  ..., -0.0203,  0.0015, -0.0054],
        [-0.0003,  0.0031, -0.0049,  ...,  0.0039, -0.0295,  0.0067],
        [ 0.0291,  0.0027,  0.0024,  ..., -0.0220,  0.0048, -0.0354]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0627, -0.0008, -0.0031,  ...,  0.0062, -0.0062,  0.0288],
        [ 0.0165, -0.0709,  0.0154,  ...,  0.0104, -0.0063, -0.0070],
        [ 0.0003,  0.0029, -0.0406,  ...,  0.0024, -0.0219,  0.0040],
        ...,
        [ 0.0048,  0.0129, -0.0249,  ..., -0.0477,  0.0035, -0.0087],
        [ 0.0038,  0.0013, -0.0033,  ...,  0.0192, -0.0774,  0.0069],
        [-0.0013,  0.0072,  0.0171,  ..., -0.0158,  0.0341, -0.0606]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:23:15 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-07-01 02:23:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2261,  0.3945, -0.4924,  ...,  0.3987,  0.0013,  0.3752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6016, -0.4468, -1.1055,  ..., -0.3596,  0.0756,  0.9629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.3457,  1.3115, -0.7549,  ...,  0.9951, -0.0806,  1.3906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8623, -1.8184, -1.7568,  ..., -0.4214,  0.2358,  5.0820],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:23:15 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:23:15 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 02:24:40 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 02:26:05 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 02:27:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0123, -0.0009, -0.0004,  ...,  0.0041,  0.0021,  0.0045],
        [-0.0005,  0.0039, -0.0007,  ..., -0.0055, -0.0042, -0.0005],
        [ 0.0021, -0.0006,  0.0104,  ..., -0.0025,  0.0032,  0.0008],
        ...,
        [-0.0005,  0.0036,  0.0028,  ...,  0.0140, -0.0021, -0.0010],
        [ 0.0006,  0.0009, -0.0004,  ...,  0.0026,  0.0144, -0.0002],
        [ 0.0024, -0.0037, -0.0026,  ...,  0.0040,  0.0019,  0.0188]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0014, -0.0090, -0.0010,  ...,  0.0094,  0.0184, -0.0079],
        [-0.0044, -0.0104, -0.0054,  ..., -0.0173, -0.0035,  0.0063],
        [ 0.0021, -0.0127,  0.0114,  ..., -0.0111, -0.0098,  0.0109],
        ...,
        [-0.0231,  0.0066, -0.0248,  ...,  0.0085,  0.0041,  0.0044],
        [-0.0097, -0.0138, -0.0028,  ...,  0.0053, -0.0086,  0.0011],
        [-0.0132,  0.0156,  0.0011,  ..., -0.0035, -0.0003,  0.0166]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0335, -0.0243,  0.0037,  ...,  0.0004, -0.0074,  0.0241],
        [-0.0134, -0.0005,  0.0018,  ..., -0.0311,  0.0105,  0.0199],
        [-0.0083,  0.0198,  0.0426,  ..., -0.0037,  0.0031,  0.0111],
        ...,
        [-0.0128, -0.0008, -0.0234,  ...,  0.0248,  0.0113,  0.0075],
        [-0.0147, -0.0131,  0.0004,  ...,  0.0247,  0.0315,  0.0038],
        [-0.0042,  0.0138, -0.0145,  ...,  0.0165,  0.0065,  0.0366]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:27:32 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 02:27:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2793,  0.4946, -0.4116,  ...,  0.3396,  0.0609,  0.3252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7900, -0.2703, -0.6870,  ..., -0.2854,  0.1528,  0.9497],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1406,  1.5908, -1.2754,  ...,  1.8086, -0.2969,  2.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9692, -0.1406, -1.1768,  ..., -1.3770, -0.2896,  6.9141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:27:32 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:27:32 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 02:28:56 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 02:30:13 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 02:31:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.6136e-03, -7.1812e-04,  1.1435e-03,  ..., -8.2827e-04,
          1.3695e-03,  1.0920e-03],
        [-1.4896e-03,  4.2534e-03,  1.7757e-03,  ..., -2.3556e-03,
         -1.1879e-04,  5.6267e-04],
        [-1.7328e-03, -3.8767e-04,  8.1863e-03,  ..., -4.6134e-04,
         -7.5245e-04,  4.3559e-04],
        ...,
        [-4.8113e-04, -1.2503e-03, -2.1534e-03,  ...,  9.6893e-03,
         -5.5027e-04, -5.4598e-04],
        [ 1.9073e-03,  1.6232e-03, -4.5443e-04,  ..., -3.1018e-04,
          7.9193e-03, -1.7881e-05],
        [ 2.2469e-03,  1.9157e-04,  2.3918e-03,  ...,  5.0926e-04,
         -4.9543e-04,  8.4457e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.5587e-02,  6.6299e-03,  4.3488e-03,  ..., -1.2131e-02,
         -8.7433e-03,  8.9111e-03],
        [-5.3329e-03, -6.9695e-03, -2.5692e-03,  ...,  8.1024e-03,
         -1.9608e-02,  9.5749e-03],
        [-8.1062e-04,  1.4618e-02, -1.1322e-02,  ..., -7.0877e-03,
          1.0651e-02, -7.5073e-03],
        ...,
        [-5.9853e-03, -4.9591e-03,  3.4943e-03,  ..., -6.0921e-03,
          8.2254e-04,  6.9122e-03],
        [ 1.9522e-03, -7.2975e-03,  3.9139e-03,  ..., -2.6245e-03,
         -1.5244e-02,  1.3329e-02],
        [-1.0193e-02,  9.3994e-03, -1.8005e-02,  ...,  3.8395e-03,
         -6.7115e-05,  3.6316e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0365, -0.0173,  0.0287,  ...,  0.0007, -0.0003,  0.0031],
        [ 0.0029, -0.0631,  0.0090,  ...,  0.0064, -0.0011, -0.0157],
        [ 0.0158,  0.0036, -0.0229,  ..., -0.0127, -0.0088, -0.0180],
        ...,
        [-0.0116,  0.0228,  0.0020,  ..., -0.0668, -0.0091, -0.0055],
        [ 0.0201, -0.0037, -0.0156,  ...,  0.0004, -0.0480,  0.0138],
        [ 0.0194,  0.0286, -0.0126,  ..., -0.0129,  0.0001, -0.0253]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:31:31 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 02:31:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3604,  0.4060, -0.3108,  ...,  0.1941, -0.0518,  0.3635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6558, -0.5322, -0.6392,  ..., -0.2301,  0.0480,  1.5889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6318,  1.5742, -2.2480,  ...,  1.2734, -1.2207,  1.3740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4941,  0.2690, -2.3613,  ..., -2.2246, -0.2625,  5.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:31:31 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:31:31 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 02:32:50 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 02:34:11 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 02:35:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.1940e-03, -5.2929e-04, -3.6430e-04,  ..., -8.5354e-04,
          2.8205e-04, -8.8930e-04],
        [ 1.0338e-03,  5.1498e-03,  8.3447e-05,  ..., -2.2519e-04,
          2.8610e-04,  5.1165e-04],
        [ 1.1950e-03, -1.2512e-03,  7.2708e-03,  ..., -5.3883e-04,
         -1.5068e-03,  8.8274e-05],
        ...,
        [-1.8196e-03, -4.5252e-04, -7.5626e-04,  ...,  9.5139e-03,
         -1.1015e-03, -1.1225e-03],
        [-6.7592e-05, -1.5545e-04, -1.0908e-05,  ..., -7.8773e-04,
          1.0643e-02, -1.0452e-03],
        [ 1.4520e-04,  1.2484e-03, -9.5224e-04,  ..., -8.5354e-04,
         -4.2009e-04,  1.2428e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0127,  0.0111, -0.0210,  ..., -0.0095, -0.0073, -0.0204],
        [ 0.0186,  0.0043, -0.0101,  ..., -0.0185,  0.0055, -0.0069],
        [-0.0238, -0.0259,  0.0023,  ...,  0.0095,  0.0116, -0.0164],
        ...,
        [ 0.0011,  0.0075, -0.0172,  ...,  0.0033, -0.0026,  0.0081],
        [ 0.0052, -0.0218, -0.0212,  ...,  0.0016,  0.0020,  0.0076],
        [-0.0087,  0.0233,  0.0014,  ..., -0.0103,  0.0079,  0.0135]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0334,  0.0077,  0.0162,  ..., -0.0192,  0.0111, -0.0194],
        [ 0.0374, -0.0303, -0.0065,  ..., -0.0047, -0.0057, -0.0044],
        [-0.0178,  0.0135, -0.0123,  ..., -0.0128, -0.0194, -0.0003],
        ...,
        [ 0.0020,  0.0069, -0.0088,  ..., -0.0123,  0.0066, -0.0115],
        [-0.0019, -0.0251, -0.0125,  ..., -0.0068, -0.0176,  0.0165],
        [-0.0052,  0.0189,  0.0247,  ..., -0.0149,  0.0242, -0.0037]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:35:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To aspire results in aspiration
To optimize results in optimization
To illumine results in illumination
To minimize results in minimization
To characterize results in characterization
To randomize results in randomization
To standardize results in standardization
To restore results in
2024-07-01 02:35:35 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 02:35:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2438, -0.3992, -0.7354,  ..., -0.8179,  0.2135, -0.9292],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0664,  0.1282, -0.4036,  ..., -0.5015, -0.2722, -0.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4722, -0.4326, -1.1162,  ..., -0.7793,  0.1045, -0.8516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0037,  0.4495, -0.1904,  ...,  0.2681, -0.3125,  0.1017],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:35:35 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:35:35 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 02:35:58 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 02:36:21 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 02:36:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.4147e-03,  3.8290e-04, -1.3857e-03,  ..., -4.3344e-04,
         -3.2425e-04, -1.8177e-03],
        [ 9.6941e-04, -1.1024e-02,  4.8161e-04,  ...,  1.4668e-03,
         -2.6817e-03,  3.3264e-03],
        [-6.4564e-04,  4.0150e-04, -1.1642e-02,  ..., -3.6335e-04,
         -2.8477e-03,  5.8794e-04],
        ...,
        [-2.4204e-03,  6.7234e-04, -1.2951e-03,  ..., -9.3536e-03,
         -9.2936e-04,  7.3814e-04],
        [-1.0624e-03, -7.7391e-04, -3.3903e-04,  ..., -1.7385e-03,
         -9.3002e-03, -5.3692e-04],
        [ 2.1338e-05, -9.7132e-04, -1.1978e-03,  ...,  9.3937e-04,
          1.6212e-03, -1.0635e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.6855e-02,  7.2556e-03, -4.1809e-03,  ..., -4.7951e-03,
         -4.3449e-03,  2.6703e-03],
        [-4.3259e-03, -2.5757e-02,  9.6512e-04,  ...,  1.7262e-04,
         -9.6283e-03, -1.1368e-02],
        [-7.6599e-03, -7.4005e-04, -1.8539e-02,  ...,  1.0567e-02,
          8.8692e-05,  5.7945e-03],
        ...,
        [-4.6134e-04,  1.0757e-03, -6.0501e-03,  ..., -1.6617e-02,
          4.5891e-03, -3.1567e-03],
        [-4.7302e-03,  5.8823e-03, -1.0895e-02,  ...,  2.7580e-03,
         -2.2217e-02, -3.4790e-03],
        [-4.7493e-03, -2.1973e-03,  7.5417e-03,  ...,  3.9253e-03,
          6.0730e-03, -1.9485e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0333,  0.0042, -0.0057,  ..., -0.0015, -0.0035,  0.0027],
        [ 0.0006, -0.0416,  0.0001,  ...,  0.0069,  0.0011, -0.0022],
        [-0.0027, -0.0003, -0.0412,  ...,  0.0019,  0.0042,  0.0015],
        ...,
        [-0.0027,  0.0051,  0.0012,  ..., -0.0394, -0.0013,  0.0004],
        [-0.0017,  0.0007,  0.0018,  ..., -0.0003, -0.0389,  0.0029],
        [-0.0004, -0.0028, -0.0002,  ...,  0.0014,  0.0039, -0.0343]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:36:47 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 02:36:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5190, -0.2874, -1.4385,  ..., -0.5820,  0.4519, -1.0830],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1671,  0.2255, -0.2439,  ..., -0.2318, -0.2352, -0.3110],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6875, -0.1871, -1.1182,  ..., -0.5342,  0.0459, -0.8857],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0432,  0.3213, -0.2489,  ..., -0.2847, -0.2227,  0.2651],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:36:47 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:36:47 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 02:37:11 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 02:37:35 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 02:37:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2039e-02,  1.2436e-03, -1.8787e-04,  ..., -6.0678e-05,
         -1.9455e-03,  1.7204e-03],
        [ 1.8349e-03, -1.7410e-02, -1.1330e-03,  ...,  8.7929e-04,
          8.2397e-04,  2.2869e-03],
        [ 8.9741e-04, -1.5850e-03, -1.4977e-02,  ...,  1.7715e-04,
         -2.9635e-04,  1.6613e-03],
        ...,
        [ 8.1205e-04,  1.5011e-03,  5.6553e-04,  ..., -1.6388e-02,
         -3.4332e-03,  1.7729e-03],
        [-9.6703e-04, -3.2330e-04,  5.8472e-05,  ...,  5.1880e-04,
         -1.4061e-02, -9.1887e-04],
        [-8.3017e-04, -3.6812e-03, -3.1395e-03,  ...,  1.2124e-04,
          8.0967e-04, -1.3237e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.9011e-02,  8.2626e-03, -9.2316e-03,  ...,  1.4694e-02,
          8.2397e-03, -9.2163e-03],
        [-7.6103e-04, -3.7720e-02,  2.6741e-03,  ..., -3.0193e-03,
         -4.7226e-03, -1.9550e-05],
        [-8.9798e-03, -4.2114e-03, -2.8641e-02,  ..., -4.9210e-03,
         -1.5808e-02,  3.2978e-03],
        ...,
        [ 4.9400e-03, -6.9580e-03, -8.0490e-03,  ..., -3.0014e-02,
          2.0409e-03,  3.1548e-03],
        [-8.4152e-03, -3.1700e-03,  1.7395e-02,  ...,  7.7744e-03,
         -3.2959e-02,  7.7400e-03],
        [-4.0665e-03,  5.7068e-03,  1.8921e-02,  ..., -2.9716e-03,
         -2.2469e-03, -3.5034e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0763,  0.0052, -0.0024,  ...,  0.0033, -0.0016,  0.0028],
        [ 0.0045, -0.0721, -0.0060,  ...,  0.0023,  0.0027, -0.0045],
        [-0.0026, -0.0043, -0.0727,  ..., -0.0033,  0.0020, -0.0010],
        ...,
        [ 0.0071, -0.0016,  0.0026,  ..., -0.0756, -0.0021, -0.0013],
        [-0.0053, -0.0049,  0.0106,  ...,  0.0034, -0.0676,  0.0017],
        [ 0.0016,  0.0006,  0.0027,  ..., -0.0002,  0.0012, -0.0790]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:38:01 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 02:38:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4949, -0.5137, -1.2246,  ..., -0.8203,  0.1041, -0.9961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0138,  0.7490, -0.3203,  ...,  0.4292, -0.5156,  0.1515],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8926, -0.1212, -1.0498,  ..., -0.1633, -0.2102, -0.6855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2458, -0.0706, -0.4009,  ..., -0.1641, -0.8247,  0.5928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:38:01 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:38:01 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 02:38:26 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 02:38:51 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 02:39:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.8801e-03,  1.5240e-03, -3.5820e-03,  ...,  5.5909e-05,
         -1.8311e-03, -1.2512e-03],
        [ 2.5153e-05, -9.9182e-03, -1.2493e-03,  ...,  1.9760e-03,
         -6.0368e-04,  1.6069e-03],
        [ 2.0657e-03, -1.7433e-03, -5.6496e-03,  ...,  1.5736e-05,
          2.8191e-03, -1.1978e-03],
        ...,
        [ 1.5812e-03, -1.8001e-04, -1.3733e-03,  ..., -7.5874e-03,
          2.3193e-03,  1.7853e-03],
        [ 6.0797e-04, -2.6436e-03,  3.5763e-03,  ..., -5.6934e-04,
         -8.3618e-03, -3.9215e-03],
        [ 2.7418e-04,  1.7548e-03,  8.6975e-04,  ...,  2.0742e-05,
          1.0605e-03, -7.5417e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.9556e-02, -1.0395e-03, -9.7351e-03,  ..., -2.0237e-03,
          2.1114e-03, -1.3496e-02],
        [-7.8354e-03, -2.5574e-02, -4.5395e-03,  ..., -1.0338e-02,
          8.1329e-03, -2.6340e-03],
        [ 2.8763e-03,  8.5602e-03, -2.1927e-02,  ..., -4.6844e-03,
          9.9640e-03,  5.7793e-04],
        ...,
        [ 7.9966e-04, -7.3280e-03,  4.7607e-03,  ..., -3.7720e-02,
         -2.8343e-03,  1.7090e-03],
        [-5.2567e-03,  2.4052e-03,  1.0910e-03,  ...,  5.1727e-03,
         -3.8300e-02, -6.1989e-05],
        [ 3.7098e-03, -5.6610e-03, -6.1760e-03,  ..., -8.0948e-03,
          1.4900e-02, -2.4292e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0305,  0.0048, -0.0053,  ..., -0.0007,  0.0018, -0.0036],
        [-0.0054, -0.0362,  0.0099,  ...,  0.0011, -0.0041,  0.0018],
        [ 0.0045,  0.0056, -0.0302,  ...,  0.0045,  0.0022,  0.0019],
        ...,
        [-0.0010,  0.0029, -0.0038,  ..., -0.0365, -0.0069, -0.0014],
        [ 0.0040,  0.0016, -0.0042,  ...,  0.0020, -0.0329,  0.0018],
        [-0.0035, -0.0033,  0.0025,  ..., -0.0009,  0.0085, -0.0336]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:39:19 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 02:39:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7266, -0.2372, -1.1904,  ..., -0.5562,  0.0248, -1.0322],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0507,  0.5254, -0.4050,  ..., -0.4519, -0.3826,  0.4216],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6255, -0.1812, -0.4248,  ..., -0.5591,  0.1008, -0.3459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2979,  0.0901, -0.1448,  ..., -0.2036, -0.4355,  0.2612],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:39:19 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:39:19 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 02:39:49 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 02:40:20 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 02:40:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.6425e-03,  4.4465e-04, -7.0190e-04,  ..., -1.1644e-03,
          1.2226e-03, -5.0545e-05],
        [-8.3828e-04, -3.2024e-03,  9.2268e-04,  ...,  1.1053e-03,
         -2.1029e-04, -3.6716e-04],
        [-2.5654e-03,  1.2445e-04, -2.8114e-03,  ...,  1.4248e-03,
          1.4915e-03, -4.4799e-04],
        ...,
        [-3.7241e-04, -1.8158e-03,  8.9073e-04,  ..., -4.5700e-03,
          5.6696e-04, -1.1024e-03],
        [-7.5531e-04, -1.5240e-03, -6.8998e-04,  ..., -1.9860e-04,
         -3.1986e-03,  1.0509e-03],
        [ 8.7261e-04, -1.2264e-03, -1.2188e-03,  ...,  4.3535e-04,
         -1.3008e-03, -3.4428e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0474,  0.0104, -0.0097,  ...,  0.0078,  0.0066,  0.0058],
        [ 0.0096, -0.0475,  0.0118,  ...,  0.0057,  0.0009, -0.0074],
        [ 0.0097, -0.0010, -0.0524,  ...,  0.0058, -0.0158,  0.0019],
        ...,
        [ 0.0003,  0.0044,  0.0004,  ..., -0.0414, -0.0034, -0.0174],
        [ 0.0002,  0.0010, -0.0119,  ..., -0.0028, -0.0411, -0.0058],
        [ 0.0138, -0.0047, -0.0041,  ..., -0.0059, -0.0071, -0.0462]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0468, -0.0028,  0.0002,  ..., -0.0037,  0.0039, -0.0006],
        [ 0.0095, -0.0445,  0.0003,  ...,  0.0069,  0.0087, -0.0052],
        [-0.0058, -0.0101, -0.0504,  ...,  0.0017, -0.0038, -0.0006],
        ...,
        [-0.0106, -0.0005,  0.0073,  ..., -0.0543, -0.0002, -0.0120],
        [-0.0049,  0.0005, -0.0048,  ..., -0.0011, -0.0453,  0.0083],
        [-0.0113, -0.0026, -0.0116,  ...,  0.0020, -0.0017, -0.0560]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:40:52 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 02:40:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8008, -0.1696, -0.9346,  ..., -0.1559, -0.1681, -0.7017],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3198, -0.1390, -0.4805,  ..., -0.2024, -1.0127,  0.7334],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7217,  0.3125, -0.6880,  ..., -0.7617,  0.3682, -0.4543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2219, -0.1814,  0.7949,  ..., -0.1365, -0.4434, -0.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:40:52 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:40:52 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 02:41:26 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 02:41:58 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 02:42:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0019,  0.0023,  0.0011,  ..., -0.0018, -0.0004, -0.0010],
        [ 0.0025, -0.0018,  0.0005,  ..., -0.0015, -0.0001,  0.0012],
        [ 0.0010, -0.0018, -0.0015,  ...,  0.0020,  0.0025,  0.0005],
        ...,
        [-0.0015,  0.0012, -0.0002,  ...,  0.0027,  0.0015, -0.0004],
        [-0.0011, -0.0024,  0.0017,  ..., -0.0019,  0.0002, -0.0001],
        [ 0.0005,  0.0013,  0.0011,  ..., -0.0011, -0.0017, -0.0020]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0700,  0.0152,  0.0065,  ..., -0.0019, -0.0206,  0.0051],
        [-0.0077, -0.0891, -0.0062,  ...,  0.0024, -0.0005,  0.0148],
        [-0.0028, -0.0067, -0.0657,  ...,  0.0030,  0.0069,  0.0032],
        ...,
        [-0.0058,  0.0050, -0.0032,  ..., -0.0724,  0.0005, -0.0134],
        [-0.0024, -0.0051, -0.0029,  ...,  0.0030, -0.0905,  0.0154],
        [-0.0016,  0.0068,  0.0123,  ...,  0.0098,  0.0120, -0.0972]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.0210e-02,  2.1439e-03,  3.7308e-03,  ..., -3.5858e-03,
         -1.1740e-03, -3.8719e-04],
        [-7.5798e-03, -8.1543e-02,  6.1417e-03,  ...,  4.9362e-03,
         -9.4128e-04,  2.3270e-03],
        [-1.3420e-02,  3.4504e-03, -7.7026e-02,  ..., -1.2407e-03,
          9.5673e-03, -5.8823e-03],
        ...,
        [-3.5324e-03,  7.3738e-03, -4.0588e-03,  ..., -7.9895e-02,
          3.0746e-03,  1.8835e-03],
        [-5.6839e-04,  8.0633e-04,  5.0812e-03,  ..., -1.2457e-05,
         -8.8806e-02,  4.7569e-03],
        [ 5.1003e-03,  8.0109e-03,  1.2093e-03,  ..., -1.3206e-02,
         -2.4166e-03, -1.0571e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:42:33 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 02:42:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5474, -0.1858, -0.3745,  ..., -0.4749,  0.0654, -0.3406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3618,  0.0959, -0.1763,  ..., -0.2299, -0.5347,  0.2996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4160, -0.1541, -1.4629,  ...,  0.0410,  0.4683, -0.4565],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2673,  0.2881, -0.0244,  ...,  0.2820, -0.7681, -1.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:42:33 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:42:33 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 02:43:09 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 02:43:44 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 02:44:21 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0042, -0.0011,  0.0003,  ..., -0.0005,  0.0021, -0.0003],
        [ 0.0012, -0.0041, -0.0014,  ...,  0.0012, -0.0033,  0.0004],
        [ 0.0004,  0.0026, -0.0043,  ...,  0.0009,  0.0012, -0.0009],
        ...,
        [-0.0005, -0.0022, -0.0007,  ..., -0.0021, -0.0002,  0.0015],
        [ 0.0031,  0.0011,  0.0007,  ..., -0.0016, -0.0037, -0.0007],
        [ 0.0002,  0.0012,  0.0012,  ...,  0.0038, -0.0024, -0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0825,  0.0060,  0.0075,  ...,  0.0140,  0.0055, -0.0025],
        [ 0.0099, -0.0834, -0.0126,  ..., -0.0084,  0.0001, -0.0054],
        [ 0.0074,  0.0023, -0.0894,  ..., -0.0059,  0.0061,  0.0025],
        ...,
        [ 0.0068, -0.0074,  0.0130,  ..., -0.0782,  0.0033,  0.0140],
        [ 0.0086,  0.0089, -0.0020,  ..., -0.0007, -0.0903, -0.0125],
        [ 0.0004, -0.0038, -0.0041,  ..., -0.0087,  0.0056, -0.0920]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0900, -0.0073,  0.0048,  ...,  0.0008, -0.0046,  0.0033],
        [ 0.0038, -0.0986, -0.0041,  ..., -0.0026, -0.0025, -0.0004],
        [-0.0140, -0.0056, -0.0901,  ...,  0.0034, -0.0006, -0.0041],
        ...,
        [ 0.0098,  0.0030,  0.0076,  ..., -0.0899, -0.0064, -0.0009],
        [ 0.0031, -0.0002, -0.0124,  ..., -0.0057, -0.0867,  0.0003],
        [-0.0073,  0.0007, -0.0107,  ..., -0.0043, -0.0041, -0.1010]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:44:23 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 02:44:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6138,  0.2825, -0.5830,  ..., -0.6489,  0.3022, -0.4438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2377, -0.1854,  0.7734,  ..., -0.1609, -0.4673, -0.3376],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5664,  0.0621, -1.7188,  ...,  0.0757,  0.7837, -0.4019],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5908, -0.1655, -0.5679,  ...,  0.5107, -0.3074, -1.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:44:24 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:44:24 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 02:45:02 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 02:45:40 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 02:46:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.8948e-03,  3.7632e-03, -1.2565e-04,  ...,  1.2121e-03,
         -6.9320e-05, -8.1348e-04],
        [ 1.8282e-03, -2.2984e-04, -3.2272e-03,  ...,  2.6054e-03,
          1.2026e-03, -7.5006e-04],
        [ 2.2182e-03,  2.7256e-03, -2.6455e-03,  ..., -2.4967e-03,
         -7.2145e-04, -5.3644e-05],
        ...,
        [-3.1567e-04, -4.3845e-04, -1.2070e-04,  ..., -3.7041e-03,
          2.8839e-03,  4.1313e-03],
        [-2.8133e-03,  1.8358e-05, -7.5102e-04,  ...,  3.7556e-03,
          3.8261e-03, -4.0932e-03],
        [ 2.1706e-03, -1.1578e-03,  6.7806e-04,  ...,  2.2430e-03,
          7.8278e-03, -4.0054e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0695, -0.0071,  0.0054,  ..., -0.0086, -0.0064,  0.0055],
        [-0.0024, -0.0602, -0.0033,  ...,  0.0055, -0.0030,  0.0093],
        [-0.0092,  0.0012, -0.0748,  ..., -0.0076, -0.0051,  0.0011],
        ...,
        [-0.0101,  0.0047, -0.0048,  ..., -0.0615,  0.0028, -0.0127],
        [-0.0008, -0.0004, -0.0047,  ...,  0.0100, -0.0681,  0.0017],
        [-0.0131, -0.0007,  0.0083,  ...,  0.0030,  0.0025, -0.0960]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0961,  0.0021,  0.0111,  ..., -0.0049, -0.0136, -0.0005],
        [ 0.0122, -0.0822, -0.0156,  ...,  0.0080,  0.0030,  0.0021],
        [-0.0049, -0.0030, -0.0863,  ...,  0.0037, -0.0004,  0.0056],
        ...,
        [-0.0006,  0.0038, -0.0059,  ..., -0.0953,  0.0124,  0.0039],
        [ 0.0081,  0.0054,  0.0024,  ..., -0.0034, -0.0889, -0.0106],
        [ 0.0025, -0.0038,  0.0064,  ...,  0.0086, -0.0027, -0.0885]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:46:06 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 02:46:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1416, -0.1434, -1.1318,  ...,  0.0223,  0.3528, -0.4021],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2646,  0.2800, -0.0328,  ...,  0.2520, -0.7280, -1.2549],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2949,  0.6011, -1.0039,  ..., -0.4810,  0.4104, -0.2114],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5522, -0.4739, -1.4590,  ...,  0.0474, -1.0029, -0.3389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:46:06 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:46:06 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 02:46:46 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 02:47:23 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 02:48:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.1575e-03, -8.2397e-04, -1.8311e-03,  ...,  3.1090e-04,
         -4.1151e-04, -6.5498e-03],
        [ 2.9945e-04, -3.9902e-03,  1.2951e-03,  ..., -4.6234e-03,
          3.1948e-03, -4.4670e-03],
        [ 7.3433e-05,  9.6917e-05, -2.5597e-03,  ...,  2.6016e-03,
          2.0466e-03, -8.6260e-04],
        ...,
        [-2.3079e-03, -5.9319e-04, -2.1248e-03,  ..., -1.9112e-03,
          4.8065e-03, -4.5347e-04],
        [ 5.1804e-03, -3.6621e-03, -1.8511e-03,  ..., -3.1853e-03,
         -8.7433e-03,  3.0208e-04],
        [ 1.8778e-03,  1.3313e-03,  1.7204e-03,  ..., -1.6203e-03,
          1.9255e-03, -2.4529e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.5642e-02,  3.4790e-03,  7.9880e-03,  ...,  8.4114e-04,
         -1.2383e-02,  1.9188e-03],
        [ 2.6550e-03, -1.1920e-01,  2.3270e-02,  ...,  8.9111e-03,
          9.6893e-03,  8.0109e-03],
        [ 6.2904e-03,  6.2256e-03, -8.1360e-02,  ...,  1.1887e-02,
          3.3913e-03, -1.5640e-03],
        ...,
        [-1.4496e-03, -7.0190e-03,  1.6670e-03,  ..., -1.0968e-01,
          9.8877e-03, -2.2945e-03],
        [ 6.0201e-06,  1.6174e-02,  1.5297e-02,  ..., -5.3101e-03,
         -1.0535e-01,  7.3471e-03],
        [ 3.8376e-03,  5.6686e-03, -1.7746e-02,  ..., -6.2065e-03,
         -7.9193e-03, -1.1017e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1201,  0.0204, -0.0082,  ..., -0.0193,  0.0062, -0.0007],
        [-0.0062, -0.1084,  0.0037,  ..., -0.0063, -0.0021,  0.0213],
        [ 0.0060, -0.0010, -0.1110,  ...,  0.0033,  0.0027,  0.0113],
        ...,
        [ 0.0061,  0.0008,  0.0024,  ..., -0.0998, -0.0021,  0.0067],
        [-0.0088,  0.0111, -0.0144,  ..., -0.0031, -0.1042,  0.0233],
        [ 0.0021, -0.0039, -0.0081,  ..., -0.0057,  0.0067, -0.1177]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:48:06 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 02:48:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0986,  0.0361, -1.2295,  ...,  0.0255,  0.5215, -0.3162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4746, -0.1428, -0.5005,  ...,  0.3779, -0.2625, -1.1689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5527,  1.0371, -0.9360,  ..., -0.8584,  0.9844, -0.1362],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9712, -0.2827, -1.1855,  ...,  0.5879, -0.8691,  0.0752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:48:06 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:48:06 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 02:48:54 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 02:49:40 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 02:50:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.2913e-03,  5.6648e-03,  5.0068e-04,  ..., -5.9471e-03,
         -1.8473e-03, -1.0324e-04],
        [ 4.6992e-04, -1.0700e-03, -3.3054e-03,  ...,  5.6496e-03,
         -4.2076e-03,  6.8932e-03],
        [-1.3895e-03,  2.5635e-03,  4.6577e-03,  ..., -3.5000e-03,
          2.1648e-03, -1.8044e-03],
        ...,
        [-3.0079e-03, -4.5776e-03, -1.0986e-03,  ...,  5.2872e-03,
         -1.3847e-03,  6.7234e-05],
        [-6.0577e-03, -2.0123e-04,  1.4858e-03,  ...,  1.1454e-03,
         -1.6212e-03, -2.4548e-03],
        [ 1.7071e-04,  1.7281e-03,  5.4502e-04,  ...,  1.3599e-03,
         -1.8425e-03,  5.0507e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1255e-01, -1.0208e-02, -7.8964e-03,  ...,  1.0300e-02,
          6.6872e-03, -1.5976e-02],
        [-4.0674e-04, -1.1584e-01, -1.6499e-03,  ..., -7.9060e-04,
         -3.8338e-03, -1.3542e-04],
        [-8.3237e-03,  4.6005e-03, -1.1188e-01,  ...,  3.5667e-03,
         -5.5428e-03, -3.1319e-03],
        ...,
        [-3.8071e-03,  1.2350e-03,  1.6129e-02,  ..., -9.9792e-02,
         -6.3705e-03, -3.0842e-03],
        [ 7.2975e-03,  5.4312e-04,  1.8358e-03,  ..., -6.0310e-03,
         -1.3562e-01,  8.7280e-03],
        [ 7.1716e-03, -2.6245e-03,  3.7365e-03,  ..., -3.8624e-04,
          9.6512e-03, -1.1365e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1541, -0.0145,  0.0053,  ...,  0.0137,  0.0084,  0.0037],
        [-0.0012, -0.1719, -0.0020,  ..., -0.0020, -0.0137, -0.0018],
        [-0.0118, -0.0041, -0.1453,  ...,  0.0045, -0.0121, -0.0088],
        ...,
        [-0.0010,  0.0091,  0.0079,  ..., -0.1729, -0.0009,  0.0048],
        [ 0.0139,  0.0007,  0.0059,  ..., -0.0031, -0.1652,  0.0054],
        [-0.0112,  0.0029, -0.0113,  ..., -0.0024, -0.0062, -0.1594]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:50:31 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 02:50:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8789,  0.3887, -0.6919,  ..., -0.3030,  0.2507, -0.1945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4368, -0.3882, -1.1211,  ...,  0.0457, -0.7773, -0.3108],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6426,  1.1123, -1.3809,  ..., -0.5527,  1.9424,  0.1038],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4287, -0.0383, -1.0098,  ...,  0.3398, -0.9590,  0.9326],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:50:31 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:50:31 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 02:51:22 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 02:52:09 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 02:53:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0089,  0.0017,  0.0030,  ...,  0.0022,  0.0021,  0.0023],
        [-0.0006,  0.0004,  0.0048,  ...,  0.0010,  0.0002,  0.0021],
        [ 0.0017, -0.0049, -0.0089,  ...,  0.0003, -0.0007, -0.0031],
        ...,
        [ 0.0026, -0.0030,  0.0049,  ..., -0.0071, -0.0044, -0.0011],
        [-0.0019, -0.0008,  0.0013,  ...,  0.0014, -0.0041,  0.0029],
        [-0.0005,  0.0002, -0.0028,  ...,  0.0034, -0.0027, -0.0036]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0718e-01,  8.4305e-03,  1.1276e-02,  ...,  1.9779e-03,
         -8.9569e-03, -1.7654e-02],
        [ 3.2425e-05, -1.1017e-01, -5.0125e-03,  ...,  1.3527e-02,
         -4.3564e-03, -1.0880e-02],
        [ 6.2408e-03, -1.1826e-03, -1.0663e-01,  ..., -3.7212e-03,
         -1.5078e-03, -3.7670e-03],
        ...,
        [ 9.9258e-03, -2.3079e-03, -6.2637e-03,  ..., -8.1726e-02,
          1.0498e-02, -9.4147e-03],
        [ 9.0485e-03, -1.1921e-03,  5.7220e-03,  ...,  1.1078e-02,
         -9.4360e-02,  1.2184e-02],
        [-1.0262e-03, -1.9684e-03,  6.8398e-03,  ...,  6.4611e-04,
         -7.8201e-03, -1.0236e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1193,  0.0275,  0.0056,  ..., -0.0068, -0.0123,  0.0075],
        [ 0.0037, -0.0872, -0.0030,  ..., -0.0002, -0.0120, -0.0144],
        [-0.0034,  0.0095, -0.1116,  ...,  0.0040,  0.0019,  0.0065],
        ...,
        [ 0.0012, -0.0135, -0.0042,  ..., -0.0917,  0.0102,  0.0049],
        [-0.0098, -0.0126, -0.0077,  ...,  0.0030, -0.1137,  0.0165],
        [ 0.0032, -0.0081,  0.0006,  ...,  0.0075,  0.0076, -0.0977]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:53:03 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 02:53:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9214,  0.6128, -0.5840,  ..., -0.5293,  0.5527, -0.0864],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6719, -0.2212, -0.8320,  ...,  0.3596, -0.6152,  0.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5137,  1.0420, -1.6523,  ..., -0.5967,  2.2305, -0.1064],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8521,  0.0918, -1.3594,  ..., -0.0291, -0.4272,  0.5181],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:53:03 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:53:03 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 02:53:56 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 02:54:48 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 02:55:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.3723e-04,  1.1444e-03, -1.3762e-03,  ..., -3.1242e-03,
         -6.5041e-04, -6.7520e-04],
        [ 1.9760e-03,  3.6469e-03, -1.5640e-04,  ...,  2.4738e-03,
         -6.0654e-04,  3.1185e-03],
        [-6.8855e-03, -3.2597e-03,  2.7294e-03,  ..., -4.9515e-03,
          1.6479e-03,  2.4343e-04],
        ...,
        [-1.3914e-03,  5.0697e-03,  4.6654e-03,  ...,  5.5122e-03,
         -3.4828e-03,  3.4542e-03],
        [-1.3838e-03, -3.7804e-03,  1.3037e-03,  ..., -9.0408e-04,
          4.6997e-03,  2.9259e-03],
        [-3.9005e-03,  6.0797e-06,  1.1313e-04,  ..., -3.1319e-03,
          1.5936e-03, -7.3767e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.6980e-01,  9.0714e-03, -1.1530e-03,  ..., -5.4626e-03,
         -3.4771e-03, -7.4959e-03],
        [ 3.7823e-03, -1.6602e-01,  2.0733e-03,  ...,  3.0594e-03,
         -6.3934e-03, -1.1539e-04],
        [ 1.6037e-02, -8.1558e-03, -1.6565e-01,  ..., -7.5150e-03,
         -4.0150e-04, -1.0246e-02],
        ...,
        [ 7.1449e-03, -1.1726e-02,  5.4893e-03,  ..., -1.9336e-01,
          8.6517e-03, -5.5199e-03],
        [ 3.0708e-04,  8.1253e-03, -2.9392e-03,  ...,  2.8458e-03,
         -1.6699e-01, -8.0032e-03],
        [ 7.3738e-03,  1.9875e-03, -1.6846e-02,  ..., -1.2360e-02,
          8.2474e-03, -1.5747e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.3462e-01,  1.7212e-02,  6.1874e-03,  ..., -1.0124e-02,
         -2.0569e-02,  1.2217e-03],
        [ 5.6267e-03, -2.5146e-01, -7.4692e-03,  ..., -1.2802e-02,
          8.2684e-04,  2.0123e-04],
        [-2.7313e-03,  7.6332e-03, -2.3560e-01,  ..., -7.0953e-04,
          8.2626e-03,  2.2125e-04],
        ...,
        [-5.6534e-03,  9.0561e-03, -4.0512e-03,  ..., -2.7124e-01,
          1.7700e-02, -5.2299e-03],
        [-1.6479e-02, -2.2335e-03, -2.9755e-03,  ...,  1.3332e-03,
         -2.4890e-01,  7.6141e-03],
        [-1.1330e-03, -7.5607e-03, -7.7782e-03,  ..., -7.3624e-03,
          1.3323e-03, -2.5513e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:55:43 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 02:55:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9614,  0.6538, -0.8438,  ..., -0.3350,  1.1426,  0.0052],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.0928, -0.0450, -0.7974,  ...,  0.2554, -0.7480,  0.6943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9609,  1.7314, -1.7871,  ..., -1.2715,  1.5371,  0.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.9648, -0.1111, -1.1855,  ..., -0.9082,  0.2935,  0.3594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:55:43 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:55:43 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 02:56:38 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 02:57:33 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 02:58:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.0885e-04, -1.6904e-04,  1.3695e-03,  ..., -5.2834e-04,
         -5.3177e-03, -3.6983e-03],
        [ 4.2129e-04, -5.7716e-03,  2.2507e-03,  ..., -1.6136e-03,
         -1.6766e-03,  5.1689e-04],
        [ 2.4757e-03,  7.4482e-04, -4.3106e-03,  ..., -1.8239e-05,
         -1.7033e-03, -2.8229e-03],
        ...,
        [ 1.8444e-03, -2.3613e-03, -4.2629e-04,  ..., -4.1389e-03,
          1.3733e-04, -1.8167e-03],
        [-3.2368e-03,  2.2373e-03, -4.0550e-03,  ..., -4.4823e-04,
         -6.9618e-03,  2.2373e-03],
        [-3.6564e-03,  4.9019e-03,  1.8177e-03,  ..., -1.5688e-03,
          4.2419e-03, -2.1381e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0820,  0.0037,  0.0054,  ..., -0.0077, -0.0049,  0.0047],
        [ 0.0195, -0.0975,  0.0078,  ..., -0.0079, -0.0071,  0.0066],
        [-0.0115, -0.0158, -0.0965,  ...,  0.0001, -0.0032,  0.0086],
        ...,
        [-0.0080, -0.0142, -0.0067,  ..., -0.0819, -0.0007, -0.0003],
        [ 0.0014, -0.0030, -0.0161,  ...,  0.0038, -0.1188,  0.0034],
        [-0.0034,  0.0122,  0.0068,  ...,  0.0083,  0.0077, -0.0893]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.0027e-02, -5.4359e-04, -5.7602e-03,  ...,  1.1539e-03,
          3.7422e-03, -4.6921e-03],
        [ 6.6566e-03, -1.0425e-01, -8.1635e-03,  ...,  7.8726e-04,
          9.0103e-03,  1.5129e-02],
        [-3.9558e-03, -2.3136e-03, -9.7473e-02,  ..., -4.0512e-03,
          1.6117e-04,  1.5030e-03],
        ...,
        [-1.0880e-02, -6.5308e-03,  7.4921e-03,  ..., -8.0444e-02,
          8.5144e-03, -5.2795e-03],
        [ 2.9488e-03,  3.7918e-03, -1.2398e-05,  ...,  8.7261e-04,
         -1.0040e-01,  1.1887e-02],
        [-2.5253e-03,  8.7051e-03,  5.6419e-03,  ...,  3.6964e-03,
          1.9684e-03, -9.0820e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 02:58:31 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 02:58:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8472,  0.5371, -0.8794,  ..., -0.3389,  1.2168, -0.0870],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6606,  0.0333, -0.9937,  ..., -0.0414, -0.3188,  0.3767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1172,  2.5215, -2.3789,  ..., -0.7134,  2.9375,  0.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4912, -0.4397, -1.3662,  ..., -0.8301,  1.1543, -0.2974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 02:58:31 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 02:58:31 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 02:59:27 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 03:00:23 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 03:01:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.5804e-05,  2.3079e-03,  9.6989e-04,  ..., -3.2330e-03,
          8.5735e-04, -5.1994e-03],
        [-5.5122e-03,  4.2915e-03, -1.9245e-03,  ...,  4.3602e-03,
         -3.1052e-03, -4.6539e-03],
        [-2.9659e-03, -1.2093e-03,  3.9711e-03,  ..., -6.9237e-04,
         -1.1711e-03, -2.1858e-03],
        ...,
        [-2.3537e-03,  1.1101e-03,  4.1237e-03,  ...,  7.5607e-03,
         -3.5496e-03,  4.5891e-03],
        [ 4.3068e-03, -2.7294e-03,  3.1948e-03,  ..., -6.7787e-03,
         -2.8629e-03,  2.4109e-03],
        [-1.1864e-03,  5.5389e-03,  5.7936e-04,  ..., -7.2136e-03,
         -3.8033e-03, -5.3787e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1176,  0.0035, -0.0032,  ..., -0.0204, -0.0005,  0.0157],
        [-0.0046, -0.1130,  0.0035,  ..., -0.0014, -0.0068, -0.0058],
        [ 0.0065,  0.0038, -0.0988,  ..., -0.0068, -0.0094, -0.0145],
        ...,
        [ 0.0051,  0.0095,  0.0088,  ..., -0.1107,  0.0051,  0.0082],
        [ 0.0012,  0.0084,  0.0048,  ...,  0.0077, -0.0984,  0.0096],
        [-0.0009, -0.0133, -0.0150,  ..., -0.0043,  0.0003, -0.0983]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.3403e-01,  8.2169e-03, -1.0262e-03,  ..., -1.3786e-02,
          1.7502e-02, -7.7019e-03],
        [-2.8610e-04, -1.4551e-01, -1.0941e-02,  ..., -1.6022e-03,
         -7.7057e-04,  2.9526e-03],
        [ 6.7291e-03,  5.6534e-03, -1.5161e-01,  ..., -5.2834e-03,
         -1.3359e-02, -8.4381e-03],
        ...,
        [-2.0771e-03,  9.7084e-04, -7.8812e-03,  ..., -1.4526e-01,
         -1.2589e-04,  1.7059e-02],
        [ 6.5613e-03,  1.1780e-02,  6.6757e-04,  ...,  1.3580e-02,
         -1.5271e-01,  1.1322e-02],
        [ 1.4877e-03, -2.3651e-03, -7.7782e-03,  ..., -1.1726e-02,
          1.8585e-02, -1.4575e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:01:19 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-07-01 03:01:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4509,  0.8340, -0.8662,  ..., -0.6372,  0.7915,  0.1685],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5903, -0.0881, -0.7339,  ..., -0.5781,  0.2155,  0.1753],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0156,  2.6035, -2.1562,  ..., -1.6465,  3.1973,  0.4824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.5273, -1.3945, -1.1572,  ..., -0.7515,  1.0938, -0.1128],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:01:19 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:01:19 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 03:02:18 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 03:03:16 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 03:04:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.6474e-03, -3.7270e-03,  2.5902e-03,  ...,  3.4504e-03,
         -9.4223e-03, -3.0975e-03],
        [-5.3215e-03, -2.0027e-03, -3.2482e-03,  ..., -3.7432e-05,
          6.1874e-03, -9.3842e-03],
        [-1.9550e-03, -5.3902e-03, -3.3817e-03,  ...,  7.7972e-03,
         -2.7199e-03,  3.9635e-03],
        ...,
        [ 3.4771e-03,  1.4381e-03, -1.0818e-02,  ..., -2.1629e-03,
          4.1962e-04, -4.2796e-04],
        [-3.2711e-04, -2.6741e-03,  4.7340e-03,  ..., -2.7256e-03,
          3.7098e-03,  6.1684e-03],
        [-4.8065e-03,  3.4351e-03,  4.1847e-03,  ..., -8.9979e-04,
         -4.2877e-03, -7.8354e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0878,  0.0116, -0.0021,  ..., -0.0068, -0.0005,  0.0085],
        [ 0.0084, -0.1025, -0.0079,  ...,  0.0091,  0.0029, -0.0088],
        [ 0.0073, -0.0191, -0.0934,  ..., -0.0076,  0.0125, -0.0168],
        ...,
        [-0.0050, -0.0032, -0.0250,  ..., -0.0934,  0.0200, -0.0047],
        [-0.0156,  0.0019,  0.0068,  ...,  0.0114, -0.0894, -0.0151],
        [ 0.0048,  0.0093, -0.0049,  ..., -0.0087,  0.0004, -0.0966]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1022,  0.0072,  0.0003,  ..., -0.0080, -0.0041, -0.0097],
        [ 0.0059, -0.1047,  0.0045,  ..., -0.0014,  0.0035,  0.0088],
        [-0.0068, -0.0093, -0.0967,  ..., -0.0142,  0.0233, -0.0139],
        ...,
        [-0.0086, -0.0080, -0.0080,  ..., -0.1057,  0.0156, -0.0226],
        [-0.0101,  0.0088,  0.0006,  ...,  0.0104, -0.1050,  0.0038],
        [ 0.0067,  0.0137, -0.0029,  ..., -0.0225,  0.0050, -0.1053]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:04:19 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-07-01 03:04:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5234,  1.1436, -1.0547,  ..., -0.3396,  1.3535,  0.1179],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8901, -0.2913, -0.7598,  ..., -0.4863,  0.6743, -0.2101],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5703,  3.3516, -1.6348,  ..., -1.7520,  2.8965,  0.9990],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.0352, -1.0918, -2.2500,  ..., -0.2656,  0.9873,  0.0593],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:04:19 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:04:19 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 03:05:20 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 03:06:22 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 03:07:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.8648e-03,  1.5554e-03,  4.1151e-04,  ..., -1.5621e-03,
         -4.3297e-03, -5.9414e-04],
        [ 5.0507e-03,  6.0730e-03,  2.0638e-03,  ..., -2.0752e-03,
          2.7618e-03, -3.5000e-03],
        [ 1.1480e-04, -8.7261e-05,  5.4092e-03,  ...,  1.4133e-03,
         -2.4147e-03,  5.7364e-04],
        ...,
        [-3.7136e-03, -1.8654e-03,  4.9973e-04,  ...,  4.2877e-03,
         -2.7046e-03, -1.0147e-03],
        [ 3.5610e-03, -1.9569e-03,  4.9210e-03,  ...,  3.0556e-03,
          4.7684e-03, -1.8196e-03],
        [-1.7262e-03,  1.3809e-03,  2.1496e-03,  ...,  8.0156e-04,
          2.6035e-04,  7.8888e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1057,  0.0022, -0.0073,  ..., -0.0231, -0.0051,  0.0117],
        [-0.0079, -0.1136, -0.0132,  ..., -0.0022, -0.0036, -0.0102],
        [ 0.0020,  0.0062, -0.0951,  ...,  0.0007, -0.0121,  0.0110],
        ...,
        [ 0.0038,  0.0018,  0.0066,  ..., -0.1070, -0.0017,  0.0172],
        [ 0.0006, -0.0160, -0.0056,  ..., -0.0104, -0.1047,  0.0033],
        [ 0.0065,  0.0176,  0.0007,  ..., -0.0064,  0.0053, -0.0875]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1201,  0.0098, -0.0155,  ..., -0.0167, -0.0015,  0.0029],
        [ 0.0003, -0.1129, -0.0147,  ..., -0.0180, -0.0057, -0.0024],
        [-0.0061,  0.0121, -0.1130,  ...,  0.0112, -0.0047,  0.0013],
        ...,
        [ 0.0132, -0.0102,  0.0016,  ..., -0.1057, -0.0015, -0.0095],
        [-0.0069, -0.0182, -0.0174,  ..., -0.0021, -0.1133,  0.0109],
        [ 0.0112,  0.0034, -0.0043,  ...,  0.0010,  0.0029, -0.1153]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:07:25 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-07-01 03:07:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9043,  1.2236, -0.9683,  ..., -0.7563,  1.4707,  0.1945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3760, -0.7769, -0.6216,  ..., -0.4089,  0.6030, -0.0895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8691,  2.6602, -2.0059,  ..., -1.4414,  3.4082,  0.7725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8662, -1.3594, -2.4883,  ..., -0.3406,  1.2607, -0.2000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:07:25 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:07:25 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 03:08:29 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 03:09:35 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 03:10:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.1150e-03, -4.4098e-03,  5.7449e-03,  ..., -3.6011e-03,
          2.9039e-04, -6.4049e-03],
        [-2.1191e-03, -1.9836e-03,  9.7046e-03,  ...,  1.5268e-03,
         -4.1246e-04, -5.0306e-04],
        [-2.7065e-03, -8.3017e-04, -1.7605e-03,  ..., -2.8934e-03,
          3.2425e-05, -5.2338e-03],
        ...,
        [ 3.4161e-03, -5.1270e-03, -8.3160e-03,  ..., -1.8978e-04,
          1.0300e-03, -3.2692e-03],
        [-8.6069e-04, -2.1954e-03, -1.2306e-02,  ..., -3.7599e-04,
         -1.3275e-03, -1.9312e-03],
        [ 5.0507e-03,  5.4398e-03, -1.8682e-03,  ..., -4.5204e-03,
         -1.3423e-04, -2.0294e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0692,  0.0013,  0.0055,  ..., -0.0105,  0.0041, -0.0106],
        [-0.0149, -0.0607, -0.0063,  ...,  0.0012,  0.0041,  0.0023],
        [-0.0073, -0.0001, -0.0706,  ...,  0.0059,  0.0025, -0.0009],
        ...,
        [-0.0136,  0.0104, -0.0052,  ..., -0.0533, -0.0075,  0.0036],
        [ 0.0057,  0.0191, -0.0067,  ...,  0.0148, -0.0634, -0.0018],
        [-0.0120, -0.0063,  0.0036,  ..., -0.0041, -0.0109, -0.0634]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0826, -0.0024,  0.0125,  ..., -0.0014, -0.0040,  0.0065],
        [ 0.0044, -0.0809, -0.0110,  ...,  0.0078, -0.0002,  0.0115],
        [ 0.0160,  0.0173, -0.0743,  ..., -0.0067, -0.0116, -0.0078],
        ...,
        [-0.0068,  0.0011, -0.0098,  ..., -0.0793, -0.0082,  0.0109],
        [ 0.0035,  0.0201, -0.0123,  ...,  0.0170, -0.0844, -0.0003],
        [-0.0172,  0.0008,  0.0053,  ...,  0.0014, -0.0021, -0.0801]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:10:42 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-07-01 03:10:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6875,  1.4863, -0.6948,  ..., -0.7573,  1.2822,  0.3982],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.0098, -0.5493, -1.0635,  ..., -0.1313,  0.4990, -0.0081],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7158,  2.1836, -2.0723,  ..., -1.0137,  3.0293,  1.8750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2637, -1.1094, -2.1387,  ...,  0.2141,  1.4043,  0.1047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:10:42 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:10:42 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 03:11:50 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 03:12:55 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 03:14:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.2082e-03, -7.7896e-03,  1.3218e-03,  ...,  4.1695e-03,
          1.0958e-03, -6.3801e-04],
        [ 3.0689e-03, -2.3975e-03, -3.5000e-04,  ...,  2.9125e-03,
          1.0910e-03,  5.7030e-04],
        [-1.9455e-03, -1.5068e-03, -4.3411e-03,  ..., -2.9526e-03,
         -8.4114e-04,  3.9244e-04],
        ...,
        [-4.4136e-03, -4.1389e-03,  9.1553e-04,  ...,  2.9888e-03,
          7.7057e-04, -8.2064e-04],
        [ 2.8458e-03,  3.8471e-03,  2.9564e-05,  ..., -6.3362e-03,
         -3.0785e-03, -2.7676e-03],
        [ 2.8362e-03,  2.6894e-03, -1.0529e-03,  ..., -5.1308e-03,
          2.6474e-03, -9.1476e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0841,  0.0027,  0.0050,  ...,  0.0007,  0.0092,  0.0006],
        [-0.0100, -0.0786, -0.0005,  ..., -0.0125,  0.0071, -0.0040],
        [ 0.0069,  0.0022, -0.0973,  ..., -0.0144,  0.0056, -0.0039],
        ...,
        [-0.0024, -0.0242,  0.0040,  ..., -0.0654,  0.0078, -0.0160],
        [ 0.0023,  0.0062,  0.0002,  ...,  0.0030, -0.0864,  0.0072],
        [-0.0148,  0.0030, -0.0050,  ...,  0.0081,  0.0024, -0.0825]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.5632e-02,  3.4332e-05,  9.2392e-03,  ..., -2.7561e-03,
          6.8092e-03,  5.1498e-03],
        [ 1.3676e-03, -1.0205e-01, -4.9248e-03,  ..., -1.3847e-02,
          4.8828e-03, -1.2856e-02],
        [ 7.5874e-03, -1.6388e-02, -1.0706e-01,  ..., -3.7026e-04,
          8.8882e-03, -1.2680e-02],
        ...,
        [ 1.7059e-02, -6.0987e-04,  7.2632e-03,  ..., -8.2764e-02,
          1.0620e-02,  2.7370e-04],
        [ 1.2962e-02,  1.5812e-03, -4.2534e-04,  ..., -6.3324e-03,
         -1.1621e-01,  5.7449e-03],
        [-1.9379e-02,  1.1131e-02, -5.4817e-03,  ..., -2.0676e-03,
          2.9945e-03, -9.9609e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:14:05 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-07-01 03:14:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3518,  1.1260, -0.8442,  ..., -0.6123,  1.4688,  0.2859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8848, -0.6396, -1.1650,  ..., -0.1624,  0.6157, -0.1420],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6626,  2.0430, -1.9814,  ..., -0.9727,  2.8789,  1.9561],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.9531, -0.6934, -2.1270,  ..., -1.3252,  0.6445, -0.3516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:14:05 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:14:05 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 03:15:14 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 03:16:24 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 03:17:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0141, -0.0014,  0.0027,  ..., -0.0058, -0.0019, -0.0072],
        [ 0.0007,  0.0093, -0.0064,  ..., -0.0070, -0.0033, -0.0094],
        [-0.0017, -0.0093,  0.0128,  ...,  0.0108,  0.0011, -0.0031],
        ...,
        [ 0.0071,  0.0033, -0.0026,  ...,  0.0056, -0.0017, -0.0047],
        [ 0.0051, -0.0023,  0.0079,  ...,  0.0003,  0.0127, -0.0005],
        [-0.0051,  0.0008,  0.0051,  ...,  0.0106, -0.0031,  0.0084]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0671,  0.0044,  0.0029,  ..., -0.0201, -0.0114, -0.0004],
        [ 0.0054, -0.0646,  0.0064,  ..., -0.0008, -0.0001,  0.0138],
        [-0.0053,  0.0041, -0.0641,  ..., -0.0063, -0.0026,  0.0160],
        ...,
        [-0.0099,  0.0196,  0.0085,  ..., -0.0623,  0.0079,  0.0083],
        [-0.0117,  0.0046, -0.0011,  ...,  0.0033, -0.0626, -0.0143],
        [-0.0015, -0.0071, -0.0039,  ...,  0.0161,  0.0278, -0.0630]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.9834e-02,  1.8433e-02,  5.0659e-03,  ...,  5.3883e-04,
         -1.8188e-02, -5.7259e-03],
        [-6.2561e-03, -7.8064e-02,  9.0942e-03,  ...,  2.2984e-03,
         -9.6054e-03,  1.8509e-02],
        [-6.3667e-03,  5.5695e-03, -8.2520e-02,  ..., -4.5967e-03,
          3.1815e-03, -5.1117e-03],
        ...,
        [-6.3858e-03,  4.1237e-03,  1.9073e-03,  ..., -7.4585e-02,
          5.1498e-05,  9.5978e-03],
        [-1.3342e-03, -1.2283e-02, -2.3438e-02,  ..., -2.9083e-02,
         -6.2500e-02, -1.3000e-02],
        [-9.8190e-03, -1.8110e-03, -1.7639e-02,  ..., -1.6083e-02,
          1.8738e-02, -7.6172e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:17:34 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-07-01 03:17:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2986,  0.9058, -0.8652,  ..., -0.4275,  1.2900,  0.7524],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.0293, -0.4990, -0.9414,  ...,  0.0916,  0.6504,  0.0040],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6719,  1.7334, -2.6387,  ..., -0.6074,  3.5371,  0.9688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.7354, -0.7871, -2.7988,  ..., -1.7959,  0.5039, -0.7832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:17:34 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:17:34 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 03:18:43 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 03:19:53 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 03:21:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0046, -0.0009,  0.0005,  ...,  0.0036, -0.0040, -0.0125],
        [ 0.0030,  0.0046, -0.0049,  ..., -0.0020,  0.0028, -0.0060],
        [-0.0040, -0.0088, -0.0033,  ...,  0.0058, -0.0098, -0.0022],
        ...,
        [-0.0053, -0.0028,  0.0007,  ..., -0.0110,  0.0052,  0.0064],
        [ 0.0059, -0.0038, -0.0007,  ...,  0.0108, -0.0029,  0.0013],
        [ 0.0046,  0.0008, -0.0040,  ..., -0.0016,  0.0036,  0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.2104e-02, -1.5015e-02,  2.5139e-03,  ..., -2.5772e-02,
          8.9645e-05, -1.9379e-02],
        [-1.6956e-03, -3.1311e-02,  2.7199e-03,  ..., -4.9591e-03,
          1.7899e-02, -3.2673e-03],
        [ 6.6719e-03,  8.3637e-04, -4.0375e-02,  ...,  6.8893e-03,
          1.7868e-02, -3.3703e-03],
        ...,
        [-2.3254e-02,  3.4771e-03, -1.1971e-02,  ..., -4.2847e-02,
         -5.3864e-03,  1.1551e-02],
        [ 1.8265e-02,  5.4550e-03, -3.0136e-03,  ..., -1.2566e-02,
         -3.8818e-02,  2.9846e-02],
        [-2.0020e-02, -1.0849e-02, -1.6289e-03,  ..., -1.1063e-02,
          8.6060e-03, -4.8859e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.8248e-02, -8.6517e-03,  1.4816e-02,  ..., -2.0859e-02,
          1.3931e-02,  3.4485e-03],
        [-1.9073e-06, -4.3213e-02,  2.4078e-02,  ..., -9.0866e-03,
         -3.2997e-04, -2.0981e-02],
        [-7.4768e-03,  2.1420e-03, -3.8452e-02,  ..., -7.4959e-03,
         -8.1024e-03,  8.1558e-03],
        ...,
        [-1.1730e-04,  1.6159e-02, -1.5778e-02,  ..., -5.4779e-02,
         -4.5662e-03, -1.1475e-02],
        [-3.3112e-03,  7.9269e-03, -1.5335e-02,  ..., -6.8703e-03,
         -4.1473e-02,  2.0584e-02],
        [-5.1956e-03, -2.8610e-03, -5.2910e-03,  ..., -4.6921e-03,
          2.3010e-02, -7.1045e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:21:06 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-07-01 03:21:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2654,  0.8042, -0.7788,  ..., -0.3840,  1.1211,  0.7544],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7739, -0.2798, -0.8062,  ..., -0.5029,  0.2433, -0.1680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.4141,  1.5361, -2.6699,  ..., -0.4658,  4.1914,  0.0850],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8525, -0.0903, -3.3906,  ..., -1.1641,  0.9355, -0.7891],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:21:06 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:21:06 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 03:22:19 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 03:23:32 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 03:24:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0076, -0.0018, -0.0049,  ...,  0.0059, -0.0049,  0.0023],
        [-0.0075,  0.0126,  0.0045,  ...,  0.0036, -0.0014, -0.0011],
        [-0.0023,  0.0049,  0.0182,  ..., -0.0047,  0.0044,  0.0042],
        ...,
        [ 0.0016, -0.0039, -0.0038,  ...,  0.0101, -0.0060,  0.0026],
        [-0.0047,  0.0004,  0.0002,  ..., -0.0038,  0.0158, -0.0011],
        [-0.0076, -0.0071, -0.0002,  ..., -0.0027,  0.0022,  0.0208]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0347,  0.0057,  0.0092,  ...,  0.0128, -0.0132,  0.0083],
        [ 0.0023, -0.0430, -0.0013,  ..., -0.0040, -0.0017,  0.0120],
        [ 0.0067, -0.0046, -0.0468,  ...,  0.0110, -0.0061, -0.0129],
        ...,
        [ 0.0045,  0.0065, -0.0031,  ..., -0.0321, -0.0054,  0.0058],
        [ 0.0053,  0.0098,  0.0027,  ..., -0.0148, -0.0209, -0.0035],
        [ 0.0066, -0.0014, -0.0157,  ...,  0.0139, -0.0071, -0.0422]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0296,  0.0075,  0.0130,  ..., -0.0096,  0.0042,  0.0166],
        [-0.0052, -0.0350, -0.0048,  ...,  0.0081, -0.0117,  0.0121],
        [ 0.0026, -0.0086, -0.0462,  ...,  0.0199, -0.0011,  0.0169],
        ...,
        [-0.0041, -0.0013, -0.0088,  ..., -0.0403,  0.0052,  0.0069],
        [ 0.0078,  0.0266, -0.0067,  ...,  0.0031, -0.0528, -0.0025],
        [-0.0019, -0.0042, -0.0091,  ...,  0.0152,  0.0111, -0.0524]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:24:48 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-07-01 03:24:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6431,  0.6562, -1.0186,  ..., -0.2485,  1.3594,  0.3459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6470, -0.3008, -1.0322,  ..., -0.6714,  0.1956, -0.3159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2402,  1.5107, -2.5586,  ..., -0.2039,  4.6992,  0.3386],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6738,  0.4253, -4.0352,  ..., -0.8633,  1.0098, -0.3330],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:24:48 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:24:48 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 03:26:09 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 03:27:30 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 03:28:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0106, -0.0044,  0.0008,  ...,  0.0030, -0.0051, -0.0075],
        [-0.0010,  0.0068, -0.0018,  ...,  0.0043,  0.0087,  0.0015],
        [-0.0026, -0.0019,  0.0146,  ..., -0.0021,  0.0015, -0.0051],
        ...,
        [-0.0061,  0.0057, -0.0079,  ...,  0.0087,  0.0003,  0.0043],
        [ 0.0083,  0.0026,  0.0043,  ...,  0.0126,  0.0031, -0.0058],
        [-0.0099, -0.0022, -0.0007,  ..., -0.0076,  0.0133,  0.0102]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0167,  0.0050, -0.0025,  ..., -0.0017, -0.0025,  0.0042],
        [-0.0212, -0.0210, -0.0059,  ...,  0.0069,  0.0028, -0.0070],
        [ 0.0168, -0.0028,  0.0075,  ..., -0.0070,  0.0100, -0.0118],
        ...,
        [ 0.0002,  0.0082,  0.0073,  ..., -0.0279, -0.0006, -0.0053],
        [-0.0013,  0.0156, -0.0175,  ...,  0.0046, -0.0181, -0.0093],
        [-0.0089, -0.0088,  0.0093,  ...,  0.0022,  0.0031, -0.0069]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0551,  0.0077, -0.0050,  ..., -0.0032, -0.0031, -0.0047],
        [ 0.0043, -0.0722, -0.0069,  ..., -0.0103, -0.0005,  0.0178],
        [ 0.0170, -0.0029, -0.0140,  ..., -0.0066,  0.0055, -0.0298],
        ...,
        [ 0.0256,  0.0045, -0.0042,  ..., -0.0591, -0.0116, -0.0014],
        [ 0.0113, -0.0024, -0.0055,  ..., -0.0152, -0.0295, -0.0108],
        [ 0.0136,  0.0049,  0.0122,  ..., -0.0022, -0.0051, -0.0464]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:28:53 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-07-01 03:28:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9312,  0.5645, -1.0068,  ..., -0.1713,  1.6094, -0.0024],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6787, -0.0324, -1.1992,  ..., -0.4019,  0.3501, -0.3210],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.6992,  0.9414, -0.6387,  ...,  0.3049,  4.1953,  0.3801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.0039,  1.0410, -3.1250,  ..., -0.6279,  0.9731, -0.5117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:28:53 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:28:53 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 03:30:15 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 03:31:36 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 03:32:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0012,  0.0005,  0.0006,  ...,  0.0019, -0.0059, -0.0012],
        [-0.0036, -0.0032,  0.0008,  ..., -0.0018,  0.0037,  0.0001],
        [ 0.0023,  0.0031, -0.0045,  ...,  0.0008, -0.0036, -0.0005],
        ...,
        [-0.0010,  0.0004, -0.0010,  ..., -0.0039, -0.0010,  0.0006],
        [-0.0016, -0.0014,  0.0009,  ..., -0.0029,  0.0004, -0.0001],
        [-0.0028, -0.0012, -0.0014,  ..., -0.0044,  0.0046, -0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0292, -0.0169,  0.0031,  ..., -0.0044, -0.0065,  0.0262],
        [ 0.0034, -0.0227, -0.0118,  ...,  0.0052, -0.0063, -0.0089],
        [ 0.0051, -0.0079, -0.0165,  ...,  0.0061, -0.0085,  0.0151],
        ...,
        [-0.0121,  0.0071,  0.0106,  ..., -0.0197,  0.0046,  0.0062],
        [ 0.0023,  0.0002, -0.0088,  ..., -0.0172, -0.0284,  0.0112],
        [-0.0005,  0.0080, -0.0089,  ..., -0.0047,  0.0160, -0.0189]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0480,  0.0011,  0.0144,  ..., -0.0274,  0.0070, -0.0007],
        [ 0.0030, -0.0553,  0.0110,  ..., -0.0013,  0.0097,  0.0098],
        [-0.0066, -0.0008, -0.0566,  ..., -0.0039, -0.0030,  0.0085],
        ...,
        [ 0.0047,  0.0259, -0.0046,  ..., -0.0620, -0.0049,  0.0112],
        [ 0.0043,  0.0197, -0.0389,  ..., -0.0092, -0.0564, -0.0202],
        [-0.0075, -0.0037,  0.0055,  ..., -0.0197,  0.0135, -0.0780]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:33:02 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-07-01 03:33:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8394,  0.5356, -0.9360,  ..., -0.0705,  1.7334,  0.0914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6011,  0.1456, -1.3809,  ..., -0.2854,  0.3711, -0.1459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.4492,  0.6099, -0.4922,  ...,  0.3291,  4.8320,  0.1130],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.3652,  1.4561, -2.6758,  ..., -0.7578,  0.9521,  0.3325],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:33:02 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:33:02 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 03:34:24 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 03:35:47 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 03:37:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0064, -0.0031,  0.0019,  ..., -0.0014, -0.0003, -0.0022],
        [-0.0040,  0.0094,  0.0008,  ...,  0.0063,  0.0034,  0.0042],
        [ 0.0020,  0.0054,  0.0133,  ...,  0.0033,  0.0007, -0.0047],
        ...,
        [-0.0034,  0.0011,  0.0026,  ...,  0.0100, -0.0032, -0.0048],
        [ 0.0028, -0.0021, -0.0030,  ...,  0.0017,  0.0038,  0.0020],
        [-0.0019,  0.0022,  0.0016,  ...,  0.0079,  0.0008,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0298,  0.0067, -0.0145,  ..., -0.0240,  0.0108,  0.0036],
        [ 0.0208, -0.0137, -0.0009,  ...,  0.0073, -0.0013, -0.0154],
        [ 0.0002,  0.0183,  0.0127,  ...,  0.0024, -0.0173,  0.0006],
        ...,
        [ 0.0005, -0.0035, -0.0096,  ..., -0.0085,  0.0097, -0.0350],
        [-0.0107, -0.0070, -0.0238,  ...,  0.0174, -0.0162,  0.0049],
        [ 0.0079,  0.0070,  0.0036,  ..., -0.0094,  0.0128, -0.0385]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0611, -0.0051, -0.0013,  ..., -0.0027,  0.0085, -0.0034],
        [ 0.0064, -0.0558, -0.0077,  ...,  0.0113, -0.0100, -0.0120],
        [ 0.0089, -0.0042, -0.0652,  ...,  0.0271, -0.0122, -0.0074],
        ...,
        [ 0.0131,  0.0154, -0.0161,  ..., -0.0440,  0.0168,  0.0155],
        [ 0.0054,  0.0017, -0.0127,  ...,  0.0220, -0.0620,  0.0099],
        [ 0.0072,  0.0072,  0.0367,  ..., -0.0180,  0.0285, -0.0870]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:37:14 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-07-01 03:37:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9448,  0.3354, -0.2686,  ...,  0.0914,  1.4648,  0.1008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6899,  0.3643, -1.0889,  ..., -0.2146,  0.3420, -0.2043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3340,  0.4634, -0.2469,  ...,  0.1875,  4.5664,  0.4385],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.1660,  1.4580, -2.4609,  ...,  0.0762,  0.9253,  1.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:37:14 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:37:14 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 03:38:39 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 03:40:04 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 03:41:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.9798e-03, -1.0223e-03, -2.0847e-03,  ...,  4.6196e-03,
          1.9131e-03,  4.3945e-03],
        [ 1.2589e-03,  2.3479e-03,  3.9935e-04,  ..., -2.7609e-04,
         -6.6338e-03, -5.4016e-03],
        [ 2.2469e-03, -9.4032e-04,  4.9133e-03,  ..., -1.4629e-03,
          1.9779e-03, -1.1539e-04],
        ...,
        [ 3.6449e-03,  3.9520e-03,  1.6146e-03,  ...,  1.1528e-02,
         -2.7637e-03, -1.9741e-03],
        [ 4.3144e-03,  5.7068e-03, -4.7541e-04,  ...,  5.2185e-03,
          1.0590e-02, -4.0092e-03],
        [ 7.9536e-04, -7.2899e-03, -4.5166e-03,  ...,  6.7472e-04,
         -2.2411e-05,  1.7654e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0276, -0.0072, -0.0228,  ...,  0.0088,  0.0088,  0.0174],
        [-0.0023, -0.0067, -0.0164,  ..., -0.0027, -0.0023,  0.0077],
        [ 0.0011, -0.0039,  0.0202,  ...,  0.0077, -0.0019,  0.0156],
        ...,
        [-0.0102,  0.0046,  0.0002,  ...,  0.0290, -0.0075,  0.0074],
        [ 0.0207, -0.0080,  0.0077,  ...,  0.0128,  0.0098, -0.0056],
        [-0.0199, -0.0017,  0.0010,  ...,  0.0188, -0.0137,  0.0463]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0094, -0.0198,  0.0030,  ..., -0.0036,  0.0116,  0.0223],
        [ 0.0015, -0.0440,  0.0104,  ..., -0.0184, -0.0253,  0.0225],
        [-0.0006,  0.0146,  0.0133,  ..., -0.0052, -0.0032,  0.0052],
        ...,
        [-0.0187, -0.0203, -0.0259,  ...,  0.0078,  0.0127, -0.0084],
        [ 0.0166, -0.0112, -0.0069,  ...,  0.0162, -0.0061,  0.0006],
        [ 0.0036,  0.0205,  0.0028,  ...,  0.0150, -0.0022, -0.0064]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:41:30 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 03:41:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8208,  0.2102, -0.2186,  ...,  0.0660,  1.5537, -0.0055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8115,  0.4844, -0.9414,  ..., -0.2837,  0.3113,  0.0726],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2109,  0.8345, -0.4927,  ...,  0.5186,  4.7070,  1.1182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.9307,  2.2910, -3.0059,  ..., -0.6870,  0.2769,  1.1045],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:41:30 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:41:30 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 03:42:55 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 03:44:17 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 03:45:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8835e-03,  1.5557e-04,  6.6900e-04,  ..., -1.1957e-04,
          4.8113e-04,  4.2129e-04],
        [-4.9639e-04,  8.7452e-04, -1.2245e-03,  ...,  8.2254e-04,
         -3.7718e-04, -8.5115e-04],
        [-8.5306e-04,  3.7456e-04,  1.6432e-03,  ...,  5.0402e-04,
         -1.0843e-03,  2.0194e-04],
        ...,
        [ 1.2751e-03, -8.6021e-04, -1.0967e-03,  ...,  3.7746e-03,
          6.1750e-05, -7.4577e-04],
        [ 1.0214e-03,  1.0290e-03, -4.7874e-04,  ...,  1.9894e-03,
          2.9850e-04, -5.6124e-04],
        [ 1.0042e-03,  1.9991e-04,  5.8222e-04,  ...,  1.3304e-03,
         -1.0335e-04,  1.8320e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0125, -0.0056,  0.0099,  ..., -0.0188,  0.0085,  0.0105],
        [ 0.0055,  0.0003, -0.0019,  ...,  0.0135, -0.0116, -0.0123],
        [-0.0011,  0.0154,  0.0003,  ..., -0.0025, -0.0017, -0.0043],
        ...,
        [ 0.0014,  0.0152,  0.0026,  ..., -0.0061, -0.0041, -0.0092],
        [-0.0131,  0.0070, -0.0030,  ...,  0.0007, -0.0049, -0.0068],
        [ 0.0115,  0.0104, -0.0003,  ...,  0.0010,  0.0064, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0465,  0.0010,  0.0019,  ..., -0.0080,  0.0242,  0.0103],
        [-0.0039, -0.0505, -0.0023,  ..., -0.0081,  0.0115, -0.0028],
        [ 0.0196, -0.0176, -0.0486,  ...,  0.0146, -0.0231,  0.0102],
        ...,
        [ 0.0204,  0.0042, -0.0239,  ..., -0.0894, -0.0120,  0.0008],
        [ 0.0222,  0.0266, -0.0125,  ..., -0.0064, -0.0498, -0.0126],
        [ 0.0247,  0.0043, -0.0006,  ...,  0.0233,  0.0069, -0.0416]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:45:38 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 03:45:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4565,  0.1604, -0.1626,  ..., -0.0449,  1.3301,  0.0737],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7554,  0.4788, -0.8608,  ..., -0.0733,  0.2664,  0.2944],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.0977,  1.1094, -1.9180,  ..., -0.3813,  4.7578,  0.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2578,  3.0234, -4.4062,  ..., -0.5459,  0.9233, -0.5127],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:45:38 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:45:38 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 03:46:57 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 03:48:15 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 03:49:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.3256e-04,  2.4092e-04, -3.0231e-04,  ..., -9.8610e-04,
          6.8808e-04,  5.1022e-04],
        [ 7.5626e-04,  8.9550e-04,  3.2139e-04,  ..., -4.3035e-05,
          3.8314e-04,  5.9247e-05],
        [ 1.1120e-03, -9.9182e-04,  1.6327e-03,  ...,  1.4353e-04,
         -1.1396e-03, -3.0851e-04],
        ...,
        [-3.0327e-04, -1.1027e-05, -5.1260e-06,  ...,  1.9722e-03,
         -3.5191e-04, -3.8743e-04],
        [ 3.7169e-04, -6.0701e-04,  5.4169e-04,  ...,  2.3460e-04,
          1.4973e-03, -6.4421e-04],
        [ 5.7399e-05,  1.2293e-03, -6.2370e-04,  ..., -2.4939e-04,
          5.1594e-04,  3.2692e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0106, -0.0051, -0.0128,  ..., -0.0031,  0.0044,  0.0068],
        [ 0.0121,  0.0048,  0.0069,  ..., -0.0035,  0.0107, -0.0115],
        [-0.0221,  0.0078,  0.0061,  ...,  0.0095, -0.0011, -0.0018],
        ...,
        [ 0.0028,  0.0022, -0.0200,  ...,  0.0083, -0.0016,  0.0167],
        [ 0.0017, -0.0148, -0.0109,  ...,  0.0020,  0.0144, -0.0042],
        [ 0.0064,  0.0400,  0.0082,  ...,  0.0099,  0.0038,  0.0208]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0339,  0.0106,  0.0174,  ...,  0.0032, -0.0123,  0.0057],
        [ 0.0364, -0.0611, -0.0072,  ..., -0.0016, -0.0099,  0.0058],
        [-0.0161,  0.0272, -0.0115,  ..., -0.0045, -0.0112,  0.0020],
        ...,
        [-0.0041,  0.0130, -0.0009,  ..., -0.0249,  0.0127, -0.0077],
        [ 0.0118, -0.0174, -0.0173,  ..., -0.0040, -0.0231,  0.0116],
        [-0.0095,  0.0115,  0.0086,  ..., -0.0025, -0.0030, -0.0089]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:49:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To randomize results in randomization
To minimize results in minimization
To restore results in restoration
To illumine results in illumination
To characterize results in characterization
To optimize results in optimization
To standardize results in standardization
To aspire results in
2024-07-01 03:49:30 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 03:49:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.8081, -0.2480, -0.0288,  ..., -0.7388, -0.0884, -0.2125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0724,  0.2427, -0.3611,  ..., -0.4517, -0.2798, -0.1174],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5034,  0.2788,  0.0660,  ..., -0.6021, -0.1935,  0.2145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0616,  0.3589, -0.2261,  ...,  0.2300, -0.0988,  0.1782],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:49:30 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 03:49:30 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 03:49:53 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 03:50:16 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 03:50:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-9.6664e-03, -1.2608e-03, -6.5422e-04,  ..., -1.4091e-04,
         -1.0195e-03, -9.3460e-04],
        [-6.5899e-04, -8.1177e-03, -1.9951e-03,  ...,  1.3123e-03,
         -6.1035e-04,  7.8726e-04],
        [-1.0395e-03,  3.8071e-03, -1.0544e-02,  ...,  1.2579e-03,
          1.1482e-03, -2.0809e-03],
        ...,
        [-1.2131e-03,  6.5327e-05, -1.4400e-04,  ..., -6.9618e-03,
         -7.2765e-04,  2.2469e-03],
        [-2.0046e-03, -4.1676e-04, -4.2415e-04,  ..., -2.1935e-03,
         -6.9695e-03,  1.1215e-03],
        [-9.6035e-04,  3.6478e-05, -4.1771e-04,  ..., -2.1267e-03,
          3.8147e-04, -8.3466e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0242, -0.0020, -0.0015,  ..., -0.0029, -0.0028,  0.0163],
        [ 0.0036, -0.0298, -0.0059,  ..., -0.0058,  0.0055, -0.0026],
        [-0.0030,  0.0040, -0.0250,  ...,  0.0145, -0.0067,  0.0056],
        ...,
        [ 0.0009, -0.0079,  0.0014,  ..., -0.0304, -0.0012,  0.0014],
        [ 0.0020, -0.0034, -0.0046,  ..., -0.0048, -0.0272, -0.0107],
        [-0.0031,  0.0067,  0.0005,  ...,  0.0149,  0.0024, -0.0226]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0326,  0.0042, -0.0066,  ..., -0.0023, -0.0030,  0.0028],
        [ 0.0033, -0.0416,  0.0020,  ...,  0.0064,  0.0013, -0.0024],
        [-0.0033, -0.0004, -0.0408,  ...,  0.0024,  0.0045,  0.0043],
        ...,
        [-0.0038,  0.0056,  0.0012,  ..., -0.0389, -0.0026,  0.0004],
        [-0.0027, -0.0002, -0.0003,  ..., -0.0007, -0.0366,  0.0055],
        [-0.0044, -0.0011, -0.0004,  ...,  0.0037,  0.0035, -0.0352]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:50:41 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 03:50:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4741,  0.2460, -0.2017,  ..., -0.8867, -0.0329, -0.3499],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1917,  0.2267, -0.1619,  ..., -0.1821, -0.1199, -0.0196],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3064,  0.4131,  0.2103,  ..., -0.5146,  0.2106,  0.0023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1559,  0.2749, -0.2230,  ..., -0.2104, -0.1948,  0.3701],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:50:41 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 03:50:41 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 03:51:06 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 03:51:30 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 03:51:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0173,  0.0022, -0.0003,  ..., -0.0009, -0.0015, -0.0010],
        [ 0.0003, -0.0205,  0.0007,  ...,  0.0012,  0.0012,  0.0020],
        [-0.0016,  0.0014, -0.0175,  ..., -0.0002, -0.0016,  0.0017],
        ...,
        [ 0.0020,  0.0033,  0.0004,  ..., -0.0185, -0.0026,  0.0012],
        [-0.0008, -0.0001,  0.0001,  ...,  0.0013, -0.0158, -0.0013],
        [-0.0014, -0.0021, -0.0048,  ..., -0.0010,  0.0008, -0.0204]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.7333e-02,  1.5297e-03, -3.1605e-03,  ...,  3.5553e-03,
          1.8291e-03, -1.8597e-04],
        [-1.8167e-03, -6.1493e-02, -1.3031e-02,  ...,  3.9673e-03,
          9.7733e-03, -8.2016e-05],
        [-7.6294e-06, -9.6893e-03, -3.7994e-02,  ..., -5.0592e-04,
         -7.0801e-03, -2.2049e-03],
        ...,
        [ 2.9159e-04,  2.8763e-03,  2.0943e-03,  ..., -5.0842e-02,
         -2.7733e-03, -7.4387e-03],
        [-4.5013e-03, -5.0926e-04,  4.0588e-03,  ...,  3.7689e-03,
         -4.7119e-02, -4.0817e-04],
        [-8.4991e-03,  3.9520e-03,  7.6180e-03,  ..., -2.7676e-03,
         -2.1801e-03, -5.8167e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.4646e-02,  5.5847e-03, -1.6985e-03,  ...,  2.3346e-03,
         -4.4785e-03,  4.2953e-03],
        [ 3.9673e-03, -7.1228e-02, -4.7073e-03,  ..., -1.0014e-04,
          3.5629e-03, -6.9084e-03],
        [-2.1648e-03, -4.5395e-03, -7.1228e-02,  ..., -4.6425e-03,
          4.3030e-03, -9.9945e-04],
        ...,
        [ 7.6027e-03, -3.2959e-03,  3.6297e-03,  ..., -7.5378e-02,
          1.4782e-04, -9.1136e-05],
        [-5.4817e-03, -3.2578e-03,  7.3204e-03,  ..., -1.4257e-04,
         -6.7383e-02, -5.7602e-04],
        [ 2.9221e-03,  2.1839e-03,  4.5967e-03,  ...,  2.3842e-04,
          1.5888e-03, -7.3730e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:51:56 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 03:51:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7173,  0.3936,  0.0909,  ..., -0.8364, -0.2793,  0.2979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1241,  0.5977, -0.3816,  ...,  0.3708, -0.1650,  0.2861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1300,  0.1661,  0.1846,  ..., -0.5439,  0.1233,  0.2905],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1295, -0.0273, -0.4775,  ..., -0.1316, -0.7817,  0.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:51:56 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 03:51:56 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 03:52:21 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 03:52:46 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 03:53:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.3891e-03, -2.0313e-03, -2.1210e-03,  ..., -2.6345e-05,
         -1.4133e-03, -1.5965e-03],
        [ 9.3269e-04, -5.5847e-03, -1.4153e-03,  ...,  1.4973e-03,
          7.1621e-04,  1.2913e-03],
        [ 5.7697e-04,  1.3590e-04, -5.1079e-03,  ...,  7.4863e-04,
          2.1400e-03, -1.1337e-04],
        ...,
        [ 6.6280e-04,  7.7915e-04, -1.6422e-03,  ..., -4.5242e-03,
          2.8725e-03,  8.2874e-04],
        [ 6.0320e-05, -9.0122e-04, -5.0545e-04,  ...,  5.6076e-04,
         -5.8556e-03, -8.4066e-04],
        [ 3.9816e-04, -1.2894e-03,  1.7586e-03,  ..., -1.0881e-03,
          1.2922e-04, -5.0926e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.4519e-02, -8.1711e-03, -8.8272e-03,  ..., -7.8630e-04,
          2.1439e-03,  3.6144e-03],
        [-1.2909e-02, -2.1896e-02,  1.2596e-02,  ..., -7.7896e-03,
         -1.2035e-03, -5.3253e-03],
        [-3.4466e-03,  5.8136e-03, -2.2125e-02,  ..., -7.7972e-03,
         -8.3971e-04, -3.1376e-03],
        ...,
        [-1.0017e-02,  3.3760e-03, -1.7967e-03,  ..., -3.2898e-02,
         -1.1024e-02,  1.4587e-02],
        [-5.7259e-03, -8.9111e-03, -1.3573e-02,  ...,  6.8817e-03,
         -2.1759e-02,  1.3523e-03],
        [-4.6492e-05, -5.6171e-04,  1.3447e-03,  ..., -1.6136e-03,
         -9.0179e-03, -2.9831e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0299,  0.0042, -0.0012,  ..., -0.0014,  0.0023, -0.0027],
        [-0.0050, -0.0353,  0.0085,  ...,  0.0042, -0.0029,  0.0011],
        [ 0.0062,  0.0025, -0.0276,  ..., -0.0004, -0.0009,  0.0049],
        ...,
        [-0.0057,  0.0030, -0.0037,  ..., -0.0362, -0.0067, -0.0024],
        [ 0.0016,  0.0029, -0.0019,  ...,  0.0052, -0.0299,  0.0011],
        [-0.0002, -0.0040,  0.0019,  ..., -0.0021,  0.0095, -0.0323]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:53:16 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 03:53:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4233,  0.5815,  0.2979,  ..., -0.7056,  0.2781, -0.0338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2427,  0.4468, -0.3630,  ..., -0.3333, -0.3372,  0.6040],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2039,  0.0199,  0.7061,  ..., -0.5273, -0.0220,  0.6489],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1923,  0.2346, -0.1533,  ..., -0.0166, -0.3594,  0.4614],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:53:16 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 03:53:16 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 03:53:46 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 03:54:16 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 03:54:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.3640e-03,  2.4967e-03,  6.1750e-05,  ...,  1.9608e-03,
          4.1275e-03, -6.3610e-04],
        [-7.8630e-04, -5.4054e-03, -3.0875e-05,  ...,  8.9455e-04,
         -2.1231e-04, -1.4610e-03],
        [-1.1053e-03, -1.3313e-03, -4.8409e-03,  ...,  1.3733e-03,
         -2.7990e-04, -1.0710e-03],
        ...,
        [ 7.0286e-04, -2.9316e-03,  7.6818e-04,  ..., -6.7291e-03,
         -9.3699e-04,  6.9237e-04],
        [-2.0962e-03,  3.0327e-04,  7.1526e-04,  ..., -5.1260e-04,
         -5.6534e-03,  8.4114e-04],
        [ 1.2026e-03, -5.4932e-04, -1.7643e-03,  ..., -3.9816e-04,
         -2.2316e-03, -5.6725e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0318, -0.0005, -0.0051,  ..., -0.0003, -0.0012,  0.0012],
        [ 0.0056, -0.0386,  0.0050,  ...,  0.0036,  0.0107,  0.0017],
        [ 0.0005,  0.0010, -0.0356,  ...,  0.0062, -0.0149, -0.0047],
        ...,
        [-0.0014, -0.0054,  0.0005,  ..., -0.0447, -0.0088, -0.0103],
        [-0.0120,  0.0011, -0.0010,  ..., -0.0172, -0.0388, -0.0034],
        [ 0.0128, -0.0002,  0.0013,  ..., -0.0029,  0.0135, -0.0435]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0469, -0.0068, -0.0055,  ..., -0.0071,  0.0033, -0.0018],
        [ 0.0133, -0.0449, -0.0015,  ...,  0.0048,  0.0128, -0.0065],
        [-0.0051, -0.0111, -0.0515,  ...,  0.0027,  0.0020, -0.0065],
        ...,
        [-0.0068, -0.0021,  0.0095,  ..., -0.0497,  0.0006, -0.0064],
        [-0.0034,  0.0028, -0.0022,  ..., -0.0029, -0.0463,  0.0102],
        [-0.0103, -0.0026, -0.0130,  ...,  0.0035, -0.0013, -0.0545]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:54:48 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 03:54:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1384,  0.1562,  0.2134,  ..., -0.6143,  0.1796,  0.3149],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1724, -0.0816, -0.5674,  ..., -0.1620, -0.9482,  1.0879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5542,  0.1351,  0.2725,  ..., -0.6104, -0.1121,  0.3608],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2408, -0.0781,  0.3228,  ..., -0.1647, -0.4175, -0.1509],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:54:48 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 03:54:48 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 03:55:21 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 03:55:52 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 03:56:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.3689e-03,  4.1199e-04,  2.5034e-04,  ...,  6.2943e-04,
          5.2547e-04, -1.1797e-03],
        [ 1.5955e-03,  4.1199e-04,  1.1940e-03,  ..., -1.1778e-03,
          1.1091e-03,  9.4128e-04],
        [ 1.9968e-05,  5.6839e-04, -1.1265e-05,  ...,  7.6771e-04,
          9.1553e-04,  1.5078e-03],
        ...,
        [-6.2895e-04,  2.0962e-03, -5.2166e-04,  ...,  3.0384e-03,
          4.3917e-04,  7.9489e-04],
        [-9.0981e-04, -2.0504e-03,  3.6526e-04,  ...,  2.7466e-04,
          3.3722e-03, -2.2423e-04],
        [ 7.3338e-04, -9.3555e-04,  8.7166e-04,  ...,  1.8845e-03,
         -9.2387e-05, -3.7718e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0580,  0.0073, -0.0063,  ..., -0.0120, -0.0018,  0.0026],
        [-0.0037, -0.0789,  0.0090,  ...,  0.0010,  0.0039, -0.0067],
        [-0.0051, -0.0123, -0.0671,  ..., -0.0012,  0.0188,  0.0101],
        ...,
        [-0.0014,  0.0103,  0.0088,  ..., -0.0532,  0.0075, -0.0025],
        [ 0.0065, -0.0118, -0.0011,  ..., -0.0002, -0.0809,  0.0062],
        [ 0.0030,  0.0213, -0.0057,  ..., -0.0018,  0.0005, -0.0698]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0878, -0.0012,  0.0050,  ..., -0.0088, -0.0098, -0.0020],
        [-0.0087, -0.0840,  0.0030,  ..., -0.0008, -0.0119,  0.0039],
        [-0.0079, -0.0022, -0.0829,  ...,  0.0005,  0.0087, -0.0010],
        ...,
        [-0.0074, -0.0021, -0.0040,  ..., -0.0847,  0.0070,  0.0004],
        [-0.0019, -0.0036,  0.0065,  ...,  0.0002, -0.0813,  0.0070],
        [-0.0064,  0.0062,  0.0071,  ..., -0.0133,  0.0022, -0.1000]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:56:27 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 03:56:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2064,  0.0041,  0.6821,  ..., -0.5161, -0.0407,  0.6577],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2317,  0.2715, -0.1840,  ..., -0.0133, -0.4392,  0.5400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1406,  0.2903,  0.2168,  ..., -0.3301, -0.1589,  0.8599],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1698, -0.1650, -0.2847,  ...,  0.3813, -0.5088, -0.7124],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:56:27 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 03:56:27 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 03:57:02 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 03:57:36 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 03:58:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0058, -0.0002,  0.0029,  ..., -0.0030,  0.0040,  0.0019],
        [ 0.0004, -0.0078,  0.0028,  ...,  0.0018,  0.0008,  0.0014],
        [ 0.0015,  0.0012, -0.0065,  ..., -0.0004,  0.0007, -0.0013],
        ...,
        [ 0.0008, -0.0031,  0.0010,  ..., -0.0031, -0.0005,  0.0013],
        [ 0.0007,  0.0003, -0.0014,  ..., -0.0008, -0.0074, -0.0004],
        [-0.0005,  0.0011, -0.0013,  ...,  0.0011, -0.0016, -0.0038]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0839,  0.0165, -0.0018,  ..., -0.0034,  0.0114,  0.0053],
        [ 0.0182, -0.0964,  0.0064,  ...,  0.0018, -0.0061, -0.0015],
        [ 0.0069,  0.0042, -0.1039,  ..., -0.0042, -0.0079, -0.0036],
        ...,
        [-0.0101,  0.0038,  0.0027,  ..., -0.0977, -0.0006,  0.0113],
        [-0.0077,  0.0084,  0.0058,  ...,  0.0051, -0.0938, -0.0065],
        [ 0.0040,  0.0047, -0.0060,  ..., -0.0025,  0.0027, -0.0945]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.6619e-02, -2.3346e-03, -2.5024e-03,  ...,  3.0289e-03,
          4.3221e-03,  6.8970e-03],
        [ 6.0997e-03, -1.0468e-01, -9.2506e-05,  ..., -2.8000e-03,
          1.9445e-03,  2.5797e-04],
        [-4.3449e-03, -3.2997e-03, -9.4543e-02,  ...,  3.5610e-03,
         -4.6463e-03, -3.2196e-03],
        ...,
        [ 9.0790e-03,  2.8744e-03,  9.2163e-03,  ..., -1.0168e-01,
         -6.4926e-03, -2.8572e-03],
        [ 2.2526e-03,  6.0606e-04, -1.1940e-02,  ..., -5.3673e-03,
         -9.5032e-02,  7.4768e-04],
        [-4.1389e-03, -1.5373e-03, -1.5976e-02,  ..., -6.0234e-03,
         -1.7185e-03, -1.0425e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 03:58:16 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 03:58:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4976,  0.1356,  0.2129,  ..., -0.5464, -0.1071,  0.2981],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2585, -0.0735,  0.3047,  ..., -0.1895, -0.4419, -0.1991],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0166,  0.2917, -0.9814,  ...,  0.1580,  0.2986,  0.8110],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6875, -0.7715, -0.6943,  ...,  0.8726,  0.3052, -0.9819],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 03:58:16 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 03:58:16 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 03:58:54 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 03:59:33 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 04:00:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.6959e-03,  2.4548e-03, -5.4693e-04,  ..., -1.0462e-03,
         -5.4121e-04, -9.5272e-04],
        [ 7.2384e-04, -1.0281e-03, -2.7122e-03,  ...,  1.8282e-03,
          1.8060e-05, -2.7580e-03],
        [ 4.5624e-03, -2.1439e-03,  1.3208e-03,  ..., -1.7576e-03,
         -1.4791e-03,  3.6764e-04],
        ...,
        [-2.0828e-03,  8.2588e-04,  3.0518e-04,  ..., -2.8419e-03,
          1.5860e-03,  2.3532e-04],
        [-1.9360e-03,  8.1921e-04, -6.8307e-05,  ...,  1.1797e-03,
          2.8896e-04, -4.1080e-04],
        [ 2.7962e-03, -1.8511e-03,  3.3646e-03,  ...,  1.5535e-03,
          8.6212e-03, -3.5019e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0893,  0.0055, -0.0025,  ..., -0.0099, -0.0017,  0.0019],
        [ 0.0033, -0.0851,  0.0089,  ..., -0.0018, -0.0023, -0.0041],
        [-0.0154, -0.0048, -0.0882,  ..., -0.0120, -0.0005,  0.0050],
        ...,
        [-0.0075,  0.0013,  0.0087,  ..., -0.0876,  0.0018, -0.0064],
        [ 0.0016,  0.0036, -0.0011,  ...,  0.0081, -0.0880, -0.0038],
        [ 0.0092,  0.0019,  0.0031,  ...,  0.0027,  0.0013, -0.0809]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0999,  0.0018,  0.0129,  ..., -0.0040, -0.0094,  0.0004],
        [ 0.0088, -0.0813, -0.0092,  ...,  0.0066,  0.0054,  0.0028],
        [ 0.0082, -0.0093, -0.0786,  ...,  0.0027,  0.0064,  0.0043],
        ...,
        [ 0.0048, -0.0082, -0.0031,  ..., -0.0946,  0.0103, -0.0047],
        [ 0.0116,  0.0012,  0.0061,  ...,  0.0025, -0.0833, -0.0044],
        [ 0.0015,  0.0019,  0.0113,  ...,  0.0062,  0.0007, -0.0905]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:00:14 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 04:00:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9507,  0.2373,  0.1571,  ..., -0.2583, -0.1365,  0.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1702, -0.1747, -0.2737,  ...,  0.3428, -0.4875, -0.7285],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5469, -0.2556, -0.3657,  ...,  0.3450,  1.3145,  1.1973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8125, -1.2988, -1.4258,  ...,  0.1841, -0.2769, -0.1255],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:00:14 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:00:14 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 04:00:55 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 04:01:37 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 04:02:15 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.0738e-03,  4.9973e-04,  1.3649e-04,  ..., -1.4257e-03,
         -6.4945e-04, -4.5943e-04],
        [ 9.2268e-04, -2.3441e-03,  2.3031e-04,  ..., -6.8569e-04,
          5.3644e-06, -9.2936e-04],
        [ 8.0252e-04, -2.2280e-04, -1.9741e-03,  ..., -8.1420e-05,
          1.3962e-03,  1.5211e-04],
        ...,
        [ 1.4234e-04, -2.1219e-04, -8.7738e-04,  ..., -1.5984e-03,
          7.2718e-05,  2.0218e-03],
        [ 4.9114e-05, -1.7548e-04, -3.8815e-04,  ...,  1.8156e-04,
         -2.5501e-03, -1.6747e-03],
        [ 6.2132e-04,  8.0061e-04,  1.8835e-03,  ..., -4.0674e-04,
          1.1940e-03, -1.7862e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.2468e-02,  2.3556e-03, -8.0719e-03,  ...,  2.1992e-03,
         -6.5308e-03,  9.1248e-03],
        [ 5.8746e-04, -1.1871e-01,  7.7782e-03,  ..., -5.0850e-03,
          4.1771e-03,  6.7902e-03],
        [-3.6411e-03,  3.0308e-03, -9.8572e-02,  ...,  8.0490e-03,
         -6.9904e-04, -1.0872e-04],
        ...,
        [-2.2545e-03,  1.8978e-04, -5.2719e-03,  ..., -1.0480e-01,
          5.1117e-03,  6.2561e-04],
        [ 6.6566e-04,  1.0048e-02, -1.8959e-03,  ..., -3.2272e-03,
         -9.7290e-02,  5.1918e-03],
        [ 1.1368e-02,  2.7828e-03,  1.0292e-02,  ...,  2.1095e-03,
          9.4299e-03, -1.1816e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1755e-01,  1.7212e-02, -6.5689e-03,  ..., -2.0569e-02,
          4.2381e-03,  3.2673e-03],
        [-3.5439e-03, -9.9731e-02,  1.0780e-02,  ...,  7.6866e-04,
         -8.0490e-03,  1.5091e-02],
        [ 4.2267e-03,  6.1989e-05, -1.0742e-01,  ...,  2.2793e-04,
         -5.2490e-03,  2.1194e-02],
        ...,
        [-1.3895e-03,  4.4594e-03, -3.4466e-03,  ..., -9.9426e-02,
         -4.3411e-03,  3.0727e-03],
        [-5.9929e-03,  9.6207e-03, -1.5625e-02,  ...,  8.9741e-04,
         -1.0596e-01,  1.4954e-02],
        [ 2.1439e-03, -6.0387e-03, -1.1948e-02,  ..., -5.2910e-03,
          1.1261e-02, -1.0962e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:02:18 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 04:02:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7241,  0.2119, -0.7373,  ...,  0.0863,  0.1937,  0.5850],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5703, -0.6753, -0.6172,  ...,  0.6772,  0.2371, -0.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.9570,  0.2058, -0.2932,  ..., -0.5664,  1.9561,  0.5239],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6240, -0.7246, -1.5986,  ...,  0.4380, -0.5537,  0.2791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:02:18 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:02:18 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 04:02:57 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 04:03:45 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 04:04:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0015,  0.0015, -0.0016,  ...,  0.0017,  0.0008, -0.0010],
        [-0.0015,  0.0019, -0.0037,  ...,  0.0004, -0.0015,  0.0032],
        [-0.0023,  0.0025,  0.0037,  ..., -0.0018,  0.0042, -0.0015],
        ...,
        [-0.0042, -0.0019, -0.0062,  ...,  0.0030,  0.0008, -0.0002],
        [-0.0037,  0.0024,  0.0012,  ..., -0.0004, -0.0011, -0.0006],
        [ 0.0012, -0.0007,  0.0015,  ..., -0.0047, -0.0015,  0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.4050e-01, -7.0877e-03, -4.1084e-03,  ...,  8.6136e-03,
          1.1284e-02, -3.3455e-03],
        [ 2.6855e-03, -1.4539e-01, -6.3171e-03,  ...,  5.8441e-03,
         -1.2009e-02, -3.8986e-03],
        [ 1.8196e-03,  1.0767e-03, -1.2634e-01,  ...,  1.2833e-02,
          1.1492e-03, -9.8648e-03],
        ...,
        [-1.4343e-02,  4.6768e-03,  6.2256e-03,  ..., -1.3220e-01,
         -1.3885e-03, -7.3433e-04],
        [-2.0981e-05, -1.4854e-02, -1.1024e-03,  ...,  8.4686e-03,
         -1.5344e-01, -7.8821e-04],
        [-3.5725e-03, -1.8600e-02, -2.3689e-03,  ..., -5.5733e-03,
          2.4872e-03, -1.3745e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6174e-01, -1.6617e-02,  2.0943e-03,  ...,  1.0727e-02,
          3.0918e-03,  9.1705e-03],
        [-7.3433e-04, -1.8860e-01, -4.2381e-03,  ...,  1.2102e-03,
         -1.5381e-02,  1.7834e-03],
        [-1.1063e-04, -1.0185e-02, -1.4966e-01,  ...,  2.7428e-03,
         -9.8495e-03, -3.5629e-03],
        ...,
        [ 5.3310e-04,  5.9128e-03,  3.1300e-03,  ..., -1.7236e-01,
          1.1806e-03,  3.6392e-03],
        [ 1.2054e-02, -2.1744e-03,  1.1688e-02,  ..., -4.8923e-04,
         -1.7102e-01, -4.1809e-03],
        [-1.8585e-02, -3.0327e-04, -1.0315e-02,  ..., -8.9111e-03,
         -3.5324e-03, -1.7273e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:04:34 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 04:04:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1045, -0.2028, -0.2886,  ...,  0.2389,  0.8945,  0.8208],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6650, -1.0791, -1.1406,  ...,  0.1510, -0.2344, -0.1464],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.1680,  0.4822, -0.9160,  ..., -0.6997,  1.5801,  0.9258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.7441, -0.3921, -1.0957,  ...,  0.0645, -0.8037,  0.8154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:04:34 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:04:34 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 04:05:21 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 04:06:03 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 04:06:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6479e-02,  5.7945e-03,  1.2360e-03,  ...,  5.7602e-04,
          6.1321e-04,  1.9875e-03],
        [ 3.0499e-03, -1.1269e-02,  6.8092e-03,  ...,  2.5139e-03,
          3.0174e-03,  2.2564e-03],
        [ 6.8331e-04, -1.0500e-03, -1.3733e-02,  ..., -1.5221e-03,
         -5.3310e-04, -2.0790e-03],
        ...,
        [ 5.2986e-03, -3.7022e-03,  2.7294e-03,  ..., -1.2253e-02,
         -2.9678e-03,  9.6381e-05],
        [ 2.4414e-03, -4.0779e-03,  1.4725e-03,  ...,  2.9793e-03,
         -1.2566e-02,  2.5826e-03],
        [-1.6270e-03,  1.2379e-03, -5.2872e-03,  ...,  3.9558e-03,
         -1.7385e-03, -1.3687e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1188,  0.0247,  0.0070,  ...,  0.0033, -0.0096,  0.0072],
        [-0.0010, -0.1230,  0.0053,  ...,  0.0123, -0.0050, -0.0072],
        [ 0.0008,  0.0014, -0.1152,  ...,  0.0039,  0.0009,  0.0022],
        ...,
        [ 0.0182, -0.0095,  0.0098,  ..., -0.0930,  0.0071, -0.0204],
        [ 0.0050,  0.0111, -0.0056,  ...,  0.0126, -0.1161,  0.0083],
        [ 0.0028,  0.0063,  0.0003,  ...,  0.0030, -0.0021, -0.1069]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1353e-01,  2.6428e-02,  2.9984e-03,  ..., -7.2708e-03,
         -1.8982e-02,  5.5733e-03],
        [ 2.4204e-03, -9.6375e-02, -4.9477e-03,  ...,  4.7684e-03,
          6.6757e-05, -1.5610e-02],
        [ 5.1041e-03,  1.3718e-02, -1.1420e-01,  ...,  5.2261e-03,
         -3.9673e-04,  2.2507e-04],
        ...,
        [-1.3113e-03, -4.0131e-03, -8.4763e-03,  ..., -9.6802e-02,
          7.5073e-03, -2.4281e-03],
        [-1.0780e-02, -1.4000e-02, -9.4376e-03,  ..., -3.2978e-03,
         -1.0925e-01,  1.0765e-02],
        [ 1.5812e-03, -2.0790e-03, -6.3133e-04,  ...,  6.7444e-03,
          1.5669e-03, -1.0413e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:06:56 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 04:06:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2822,  0.1160, -0.2319,  ..., -0.3916,  1.2363,  0.3511],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1670, -0.5542, -1.1396,  ...,  0.2678, -0.4114,  0.2074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.9609,  0.1807, -0.9995,  ..., -0.4092,  0.7505,  1.7988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.2803, -0.1143, -1.3174,  ..., -0.2373, -0.6973,  0.4229],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:06:56 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:06:56 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 04:07:48 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 04:08:34 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 04:09:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0013, -0.0006,  0.0009,  ..., -0.0016, -0.0010,  0.0014],
        [-0.0011,  0.0021, -0.0006,  ...,  0.0013, -0.0002,  0.0026],
        [-0.0057, -0.0021,  0.0034,  ..., -0.0031,  0.0010,  0.0016],
        ...,
        [-0.0009,  0.0011,  0.0048,  ...,  0.0032, -0.0001,  0.0029],
        [-0.0042, -0.0032, -0.0014,  ..., -0.0033,  0.0039,  0.0043],
        [-0.0009, -0.0006,  0.0022,  ..., -0.0036,  0.0012, -0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.7419e-01, -3.4714e-03,  3.8471e-03,  ..., -7.3471e-03,
         -2.4319e-03, -1.8402e-02],
        [-1.4114e-03, -1.8738e-01, -2.0630e-02,  ...,  7.9803e-03,
         -4.3793e-03, -3.0613e-03],
        [ 1.7151e-02, -1.5430e-03, -1.7590e-01,  ..., -5.6648e-03,
          1.3161e-04, -1.5518e-02],
        ...,
        [-2.7527e-02, -1.5354e-03,  2.1133e-03,  ..., -2.0386e-01,
          1.8967e-02,  1.2770e-03],
        [-1.2154e-02,  5.8784e-03, -1.4782e-03,  ...,  9.8953e-03,
         -1.8127e-01, -5.9891e-03],
        [ 4.0283e-03, -2.8076e-03, -8.1940e-03,  ..., -1.9531e-02,
          1.6891e-02, -1.9482e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2078,  0.0099,  0.0147,  ..., -0.0135, -0.0036,  0.0036],
        [ 0.0127, -0.2286, -0.0012,  ..., -0.0158,  0.0073, -0.0098],
        [ 0.0094,  0.0017, -0.1965,  ...,  0.0041,  0.0113,  0.0010],
        ...,
        [-0.0045,  0.0029,  0.0033,  ..., -0.2375,  0.0093, -0.0013],
        [-0.0088,  0.0051, -0.0054,  ...,  0.0072, -0.2211,  0.0053],
        [ 0.0037, -0.0083, -0.0103,  ...,  0.0015,  0.0141, -0.2195]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:09:24 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 04:09:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.3721,  0.2944, -0.6123,  ..., -0.4482,  0.9946,  0.5562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3750, -0.3315, -0.8833,  ...,  0.0453, -0.6455,  0.6167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3828, -0.2732, -0.7158,  ...,  0.0493, -0.3921,  2.3965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1484, -0.2603, -1.5166,  ..., -0.6323, -0.5566,  0.5430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:09:24 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:09:24 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 04:10:18 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 04:11:06 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 04:11:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.8654e-03, -4.8351e-04,  3.1090e-04,  ..., -1.2338e-04,
          8.5354e-05, -1.4820e-03],
        [-1.9064e-03, -3.4294e-03,  8.6784e-04,  ..., -3.4666e-04,
         -1.1101e-03,  1.1711e-03],
        [ 2.0332e-03, -4.7255e-04, -4.6768e-03,  ...,  3.1018e-04,
         -8.5163e-04,  5.5742e-04],
        ...,
        [ 8.8930e-04, -6.9189e-04, -3.8481e-04,  ..., -2.6150e-03,
          2.5024e-03, -1.0490e-03],
        [-3.2253e-03,  1.6079e-03, -1.3266e-03,  ..., -3.2449e-04,
         -5.4359e-03,  1.9064e-03],
        [ 4.4441e-04,  2.3193e-03,  9.0361e-04,  ...,  4.9400e-04,
          3.2768e-03, -2.3975e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0956,  0.0085, -0.0057,  ..., -0.0107, -0.0047, -0.0073],
        [ 0.0002, -0.1050, -0.0039,  ..., -0.0104, -0.0040,  0.0153],
        [-0.0100, -0.0097, -0.0955,  ..., -0.0052, -0.0049,  0.0071],
        ...,
        [-0.0011,  0.0019, -0.0030,  ..., -0.0925,  0.0134, -0.0007],
        [ 0.0015, -0.0031, -0.0037,  ...,  0.0028, -0.1089,  0.0181],
        [-0.0004,  0.0063,  0.0065,  ..., -0.0034, -0.0031, -0.0867]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.5876e-02,  6.8092e-03,  1.2827e-03,  ..., -8.0252e-04,
         -2.8534e-03, -6.2180e-03],
        [ 2.6073e-03, -9.5276e-02, -3.6182e-03,  ..., -1.7128e-03,
          1.0590e-02,  2.6855e-02],
        [-1.5030e-03, -4.9286e-03, -9.4666e-02,  ..., -1.0777e-03,
         -2.6665e-03, -1.9908e-05],
        ...,
        [-9.4452e-03, -3.7594e-03,  6.1646e-03,  ..., -7.5256e-02,
          6.7978e-03, -7.8201e-04],
        [ 2.2583e-03, -5.2032e-03, -3.5400e-03,  ...,  4.9591e-03,
         -8.9050e-02,  1.1208e-02],
        [-2.6455e-03,  1.9245e-03, -9.6941e-04,  ...,  8.2550e-03,
          3.3264e-03, -9.0881e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:11:55 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 04:11:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2080,  0.0706, -0.5869,  ..., -0.2593,  0.4500,  1.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.0059, -0.1265, -0.9756,  ..., -0.1963, -0.5293,  0.3062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.7988,  0.4661, -0.3167,  ...,  0.2334,  0.1567,  2.0488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4658, -0.1064, -1.7559,  ..., -0.0049,  0.3467,  0.4932],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:11:56 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:11:56 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 04:12:52 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 04:13:50 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 04:14:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3603e-02,  3.0823e-03,  1.5097e-03,  ...,  7.3195e-04,
         -2.0714e-03, -5.1727e-03],
        [-4.3068e-03, -8.4114e-04, -1.4076e-03,  ..., -1.2058e-04,
         -2.2106e-03, -3.4199e-03],
        [-2.8057e-03,  2.8849e-05, -6.5842e-03,  ..., -5.6744e-05,
         -1.6642e-04, -3.1624e-03],
        ...,
        [ 2.1839e-03, -7.0286e-04,  9.2602e-04,  ..., -3.4409e-03,
          2.4080e-05,  3.6583e-03],
        [ 7.3242e-03, -1.6823e-03,  2.9087e-03,  ..., -4.0817e-03,
         -8.3237e-03, -2.8191e-03],
        [-5.0735e-04,  6.1073e-03,  2.8934e-03,  ..., -1.3762e-03,
         -2.6531e-03, -1.0254e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1229, -0.0070, -0.0089,  ..., -0.0052, -0.0047,  0.0031],
        [-0.0045, -0.1150, -0.0150,  ...,  0.0004, -0.0018, -0.0076],
        [-0.0053, -0.0093, -0.1069,  ..., -0.0115,  0.0101, -0.0212],
        ...,
        [-0.0040,  0.0017, -0.0033,  ..., -0.1190, -0.0046,  0.0061],
        [ 0.0162,  0.0096,  0.0052,  ...,  0.0041, -0.1122,  0.0029],
        [-0.0057, -0.0036, -0.0068,  ..., -0.0179,  0.0130, -0.1076]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1284, -0.0013, -0.0061,  ..., -0.0107,  0.0155, -0.0070],
        [-0.0108, -0.1451, -0.0060,  ...,  0.0090, -0.0081,  0.0045],
        [ 0.0018,  0.0029, -0.1594,  ...,  0.0019, -0.0098, -0.0188],
        ...,
        [-0.0074,  0.0095, -0.0098,  ..., -0.1482, -0.0038,  0.0136],
        [ 0.0037,  0.0049, -0.0040,  ...,  0.0062, -0.1481,  0.0110],
        [-0.0089,  0.0002,  0.0040,  ..., -0.0021,  0.0174, -0.1432]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:14:50 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-07-01 04:14:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2812, -0.1688, -0.3955,  ...,  0.0071, -0.1882,  1.2695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7256, -0.1875, -0.9556,  ..., -0.4187, -0.3354,  0.3015],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.9922,  0.1143, -0.1403,  ..., -0.0957, -0.0447,  2.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4473, -0.4521, -1.7373,  ...,  0.2234,  0.1055,  0.6001],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:14:50 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:14:50 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 04:15:48 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 04:16:46 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 04:17:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8482e-03, -5.4121e-04, -2.2087e-03,  ..., -2.6369e-04,
         -1.1360e-02, -5.2452e-05],
        [ 7.0047e-04,  8.1711e-03, -1.4267e-03,  ..., -1.8950e-03,
          3.3817e-03, -2.8381e-03],
        [ 3.4213e-05, -2.9449e-03,  1.0971e-02,  ..., -6.8283e-04,
          3.6907e-04,  2.0237e-03],
        ...,
        [ 3.5152e-03,  2.3880e-03, -6.6872e-03,  ...,  8.8959e-03,
         -1.5926e-03,  4.6086e-04],
        [-2.7704e-04, -2.6836e-03,  5.9795e-04,  ...,  1.8778e-03,
          1.0277e-02,  2.1420e-03],
        [-7.0763e-04,  4.0665e-03,  4.8637e-04,  ..., -3.1567e-03,
          2.1076e-03,  8.1177e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0997,  0.0130, -0.0032,  ..., -0.0137,  0.0060, -0.0040],
        [-0.0018, -0.1028, -0.0028,  ...,  0.0136,  0.0019, -0.0034],
        [-0.0006, -0.0099, -0.0791,  ..., -0.0051,  0.0093, -0.0002],
        ...,
        [-0.0123, -0.0052, -0.0074,  ..., -0.0916,  0.0100,  0.0025],
        [-0.0031,  0.0190,  0.0112,  ...,  0.0130, -0.0825, -0.0016],
        [-0.0074,  0.0084,  0.0097,  ..., -0.0074, -0.0006, -0.0840]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1029,  0.0158,  0.0076,  ..., -0.0068,  0.0009,  0.0002],
        [ 0.0061, -0.0956,  0.0071,  ...,  0.0074,  0.0095,  0.0091],
        [-0.0034, -0.0059, -0.1016,  ..., -0.0061,  0.0142, -0.0096],
        ...,
        [-0.0028, -0.0087,  0.0034,  ..., -0.1068,  0.0213, -0.0100],
        [-0.0135, -0.0027, -0.0021,  ...,  0.0165, -0.1057,  0.0047],
        [-0.0040,  0.0103, -0.0068,  ..., -0.0074, -0.0028, -0.1077]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:17:47 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-07-01 04:17:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.4824,  0.2087, -0.1575,  ...,  0.1039,  0.0840,  1.0410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8926, -0.0972, -0.9980,  ..., -0.0157,  0.2101,  0.2639],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.4668,  0.4417, -0.1792,  ...,  0.0884, -0.0670,  3.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8877, -0.3730, -3.5234,  ...,  0.9756, -0.5752,  1.1797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:17:47 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:17:47 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 04:18:46 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 04:19:48 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 04:20:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0028, -0.0008,  0.0012,  ..., -0.0007, -0.0034, -0.0013],
        [ 0.0038,  0.0020, -0.0002,  ...,  0.0002,  0.0026, -0.0007],
        [ 0.0010, -0.0023, -0.0008,  ...,  0.0016, -0.0015, -0.0022],
        ...,
        [-0.0022, -0.0035, -0.0042,  ...,  0.0010, -0.0029,  0.0020],
        [ 0.0037, -0.0004,  0.0036,  ..., -0.0008,  0.0004, -0.0031],
        [-0.0012,  0.0012,  0.0031,  ..., -0.0016, -0.0002,  0.0014]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0897, -0.0014, -0.0010,  ..., -0.0105, -0.0022,  0.0090],
        [ 0.0034, -0.1014, -0.0014,  ..., -0.0036, -0.0049, -0.0119],
        [-0.0045,  0.0033, -0.0956,  ...,  0.0004, -0.0086, -0.0019],
        ...,
        [ 0.0013, -0.0016, -0.0051,  ..., -0.0899,  0.0022,  0.0084],
        [-0.0157, -0.0056,  0.0027,  ..., -0.0112, -0.0950, -0.0025],
        [ 0.0184,  0.0120,  0.0004,  ..., -0.0045, -0.0010, -0.0864]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1396, -0.0057, -0.0274,  ..., -0.0209, -0.0134, -0.0016],
        [-0.0022, -0.1272, -0.0148,  ..., -0.0236,  0.0013, -0.0072],
        [-0.0331,  0.0122, -0.1322,  ..., -0.0044,  0.0049,  0.0166],
        ...,
        [ 0.0188, -0.0008,  0.0022,  ..., -0.1195, -0.0019, -0.0132],
        [-0.0118, -0.0086, -0.0059,  ..., -0.0068, -0.1138,  0.0096],
        [ 0.0157, -0.0006, -0.0109,  ..., -0.0052,  0.0070, -0.1174]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:20:52 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-07-01 04:20:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.5645,  0.0615, -0.0911,  ..., -0.0547, -0.0220,  1.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3926, -0.2625, -0.9678,  ...,  0.1237,  0.0638,  0.3213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.9551,  0.6128,  0.0879,  ...,  0.1184, -0.0605,  3.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4004, -0.1655, -3.5879,  ...,  0.9795, -0.0186,  1.0107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:20:52 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:20:52 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 04:21:54 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 04:22:59 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 04:24:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.9121e-04, -5.6610e-03,  4.7379e-03,  ..., -7.4654e-03,
          1.2589e-03, -6.5002e-03],
        [ 1.0729e-03,  1.6665e-04,  4.0283e-03,  ...,  1.6537e-03,
          3.4943e-03,  2.5921e-03],
        [-3.0041e-03,  1.4439e-03, -4.6349e-03,  ..., -3.4869e-05,
          6.4659e-04, -3.5686e-03],
        ...,
        [-4.5204e-03, -7.2384e-04, -3.0994e-03,  ...,  6.1417e-03,
         -2.3937e-03,  4.4327e-03],
        [ 3.0308e-03, -3.4924e-03, -1.0796e-02,  ..., -2.6798e-03,
          3.8719e-03,  5.7817e-05],
        [ 4.4327e-03,  3.7556e-03,  6.3610e-04,  ..., -5.1804e-03,
          2.6245e-03, -1.7807e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0650,  0.0058,  0.0130,  ..., -0.0028,  0.0036, -0.0180],
        [-0.0041, -0.0542, -0.0045,  ..., -0.0006,  0.0012,  0.0115],
        [-0.0030, -0.0074, -0.0661,  ..., -0.0035, -0.0149, -0.0147],
        ...,
        [-0.0118,  0.0099,  0.0028,  ..., -0.0515, -0.0060,  0.0044],
        [ 0.0090,  0.0076, -0.0094,  ...,  0.0017, -0.0515,  0.0118],
        [-0.0048,  0.0123, -0.0047,  ..., -0.0005, -0.0192, -0.0690]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0842,  0.0159,  0.0047,  ...,  0.0023, -0.0050,  0.0008],
        [ 0.0030, -0.0975, -0.0108,  ...,  0.0180, -0.0002,  0.0098],
        [ 0.0231,  0.0224, -0.0965,  ..., -0.0044, -0.0141, -0.0083],
        ...,
        [-0.0162, -0.0017, -0.0082,  ..., -0.0898, -0.0131,  0.0051],
        [ 0.0127,  0.0139, -0.0120,  ...,  0.0212, -0.1007, -0.0018],
        [ 0.0031,  0.0006,  0.0189,  ..., -0.0009, -0.0113, -0.0861]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:24:06 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-07-01 04:24:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2197,  0.2124, -0.0858,  ...,  0.0345, -0.0230,  1.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9692, -0.1985, -1.7285,  ...,  0.4773, -0.2815,  0.5645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5049,  1.0000,  0.1914,  ..., -0.1100, -0.2998,  4.4023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1992,  0.1042, -3.4102,  ...,  0.9644,  0.0900,  2.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:24:06 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:24:06 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 04:25:11 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 04:26:18 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 04:27:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0007, -0.0070, -0.0015,  ...,  0.0049,  0.0014, -0.0007],
        [-0.0010,  0.0027,  0.0002,  ..., -0.0014,  0.0003, -0.0014],
        [-0.0005, -0.0038, -0.0025,  ..., -0.0021,  0.0036, -0.0023],
        ...,
        [-0.0055, -0.0023,  0.0037,  ...,  0.0008,  0.0025, -0.0006],
        [ 0.0028,  0.0050,  0.0006,  ..., -0.0071, -0.0034,  0.0007],
        [ 0.0033, -0.0002, -0.0020,  ..., -0.0006,  0.0040, -0.0070]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0784, -0.0074,  0.0005,  ..., -0.0009,  0.0123,  0.0050],
        [-0.0075, -0.0793,  0.0108,  ..., -0.0068,  0.0064, -0.0048],
        [ 0.0113,  0.0016, -0.0871,  ..., -0.0040,  0.0094, -0.0040],
        ...,
        [ 0.0111, -0.0177,  0.0099,  ..., -0.0670,  0.0012, -0.0011],
        [-0.0021,  0.0062,  0.0054,  ..., -0.0026, -0.0698,  0.0027],
        [-0.0140,  0.0027,  0.0005,  ..., -0.0066,  0.0046, -0.0654]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.1064e-02, -1.4244e-02,  1.4130e-02,  ..., -2.8744e-03,
          7.3624e-03,  2.5964e-04],
        [ 2.6321e-04, -1.0791e-01, -3.7766e-04,  ..., -4.4322e-04,
         -9.5272e-04,  3.5286e-04],
        [ 1.5045e-02, -4.2915e-03, -1.0864e-01,  ..., -4.4556e-03,
          9.0637e-03,  6.4087e-04],
        ...,
        [ 1.9379e-02, -4.5052e-03,  1.5388e-02,  ..., -8.9844e-02,
          5.4779e-03, -5.8174e-05],
        [ 1.2756e-02,  9.2239e-03,  3.4943e-03,  ..., -3.8414e-03,
         -1.1890e-01, -3.9444e-03],
        [-1.3474e-02,  2.2793e-04,  2.3317e-04,  ..., -7.5836e-03,
          6.9466e-03, -1.0199e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:27:26 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-07-01 04:27:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9414,  0.2988,  0.0265,  ...,  0.0517, -0.0277,  1.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7026, -0.0792, -1.7871,  ...,  0.4897, -0.0053,  0.4795],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5166,  0.5327,  0.0399,  ..., -0.2852, -0.4585,  4.4180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2070,  0.1790, -5.0859,  ...,  0.6729,  0.6675,  2.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:27:26 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:27:26 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 04:28:35 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 04:29:45 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 04:30:51 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0003, -0.0006, -0.0002,  ..., -0.0041, -0.0115, -0.0104],
        [-0.0039,  0.0047, -0.0040,  ..., -0.0022, -0.0012, -0.0052],
        [-0.0011, -0.0061,  0.0077,  ...,  0.0021,  0.0004,  0.0013],
        ...,
        [-0.0001, -0.0009, -0.0008,  ...,  0.0027, -0.0019, -0.0030],
        [ 0.0036,  0.0006,  0.0045,  ..., -0.0021,  0.0061,  0.0050],
        [-0.0073,  0.0001, -0.0024,  ...,  0.0025, -0.0046,  0.0005]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.3894e-02,  1.1276e-02, -1.7136e-02,  ..., -5.9738e-03,
         -8.5526e-03,  3.9062e-03],
        [-3.9673e-04, -7.2571e-02,  4.5319e-03,  ..., -1.4353e-04,
          2.9411e-03,  4.3259e-03],
        [-5.9853e-03, -1.5182e-03, -4.4769e-02,  ..., -5.2109e-03,
          2.6970e-03,  2.0905e-02],
        ...,
        [-1.2321e-02,  8.0414e-03, -1.1284e-02,  ..., -5.7770e-02,
         -4.0207e-03,  7.1716e-03],
        [ 9.1171e-04, -1.4458e-03, -1.1627e-02,  ..., -4.5052e-03,
         -5.3070e-02,  3.8147e-05],
        [-5.9128e-04, -2.6703e-03, -1.1559e-03,  ...,  6.3095e-03,
          1.6663e-02, -4.8492e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0969,  0.0048,  0.0033,  ...,  0.0084, -0.0056, -0.0074],
        [-0.0140, -0.1191,  0.0138,  ..., -0.0211,  0.0042,  0.0027],
        [-0.0032, -0.0075, -0.1383,  ..., -0.0165,  0.0136, -0.0045],
        ...,
        [-0.0072,  0.0114, -0.0080,  ..., -0.1159,  0.0141,  0.0087],
        [-0.0007, -0.0146,  0.0001,  ..., -0.0193, -0.1032,  0.0107],
        [-0.0006,  0.0106, -0.0154,  ..., -0.0084, -0.0063, -0.1222]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:30:53 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-07-01 04:30:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6987,  0.4500,  0.0619,  ..., -0.0553, -0.1165,  2.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5913,  0.0442, -1.6230,  ...,  0.4583,  0.0659,  0.9819],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.9922,  0.5581, -0.7358,  ..., -0.0930, -0.1660,  4.1328],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6426, -0.4260, -6.2891,  ...,  0.1313, -0.1987,  1.1465],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:30:53 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:30:53 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 04:32:03 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 04:33:13 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 04:34:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.5335e-03,  2.6665e-03,  8.2159e-04,  ..., -2.9659e-03,
         -2.6131e-03, -4.0283e-03],
        [ 2.1210e-03,  4.7607e-03, -1.8492e-03,  ..., -1.0376e-03,
          5.6915e-03, -1.6232e-03],
        [-4.7035e-03,  8.8310e-04,  9.7656e-04,  ..., -1.3742e-03,
         -2.5692e-03,  1.2608e-03],
        ...,
        [-2.3289e-03, -2.4090e-03,  4.1485e-04,  ...,  9.2649e-04,
         -2.7370e-03,  9.2697e-04],
        [ 1.7967e-03, -1.6880e-03,  2.1343e-03,  ...,  2.7924e-03,
          3.1509e-03, -6.3372e-04],
        [ 2.3499e-03,  3.8683e-05,  2.2602e-04,  ..., -2.8515e-03,
          3.7498e-03,  2.3556e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0323, -0.0147,  0.0090,  ..., -0.0176,  0.0133, -0.0144],
        [ 0.0069, -0.0252,  0.0022,  ...,  0.0076,  0.0193,  0.0021],
        [ 0.0093,  0.0126, -0.0133,  ...,  0.0053,  0.0101,  0.0084],
        ...,
        [-0.0133, -0.0165, -0.0075,  ...,  0.0063,  0.0065, -0.0029],
        [ 0.0075,  0.0022, -0.0061,  ..., -0.0143, -0.0365,  0.0020],
        [-0.0161,  0.0165, -0.0002,  ..., -0.0120,  0.0037, -0.0240]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.0699e-02,  1.4305e-03,  2.0706e-02,  ..., -2.2247e-02,
          1.3977e-02, -3.4523e-03],
        [-4.5929e-03, -4.3701e-02,  1.1398e-02,  ...,  1.5396e-02,
          4.1580e-03, -2.8610e-05],
        [ 2.2980e-02, -1.1330e-02, -5.7312e-02,  ..., -2.3499e-02,
          1.0193e-02,  8.7585e-03],
        ...,
        [-5.7487e-03,  1.1368e-02, -1.5068e-03,  ..., -4.5593e-02,
         -4.4022e-03, -2.2995e-02],
        [ 9.1248e-03,  4.5242e-03, -2.3918e-03,  ...,  5.1804e-03,
         -6.5918e-02,  4.1565e-02],
        [-3.8452e-03,  1.2138e-02,  2.7466e-02,  ...,  8.7204e-03,
          9.3307e-03, -6.0730e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:34:25 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-07-01 04:34:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6436,  0.2111, -0.0036,  ..., -0.1158, -0.1935,  1.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9380,  0.0643, -2.0469,  ...,  0.2798,  0.2698,  0.9980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.7500,  0.3442, -0.7891,  ...,  0.2974, -0.2034,  3.8457],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.9922, -0.2424, -6.3008,  ...,  0.4734, -0.0847,  0.3203],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:34:25 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:34:25 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 04:35:38 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 04:36:51 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 04:38:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0103, -0.0015, -0.0003,  ...,  0.0018, -0.0012,  0.0003],
        [-0.0020,  0.0108,  0.0006,  ..., -0.0010,  0.0001,  0.0028],
        [-0.0009,  0.0025,  0.0090,  ...,  0.0005,  0.0013,  0.0030],
        ...,
        [ 0.0014,  0.0010, -0.0005,  ...,  0.0079, -0.0005,  0.0027],
        [-0.0014, -0.0026, -0.0006,  ...,  0.0017,  0.0084, -0.0013],
        [-0.0011, -0.0012,  0.0026,  ..., -0.0011,  0.0039,  0.0071]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0239, -0.0049, -0.0008,  ..., -0.0072, -0.0193,  0.0025],
        [ 0.0156, -0.0087,  0.0004,  ..., -0.0042, -0.0044, -0.0028],
        [-0.0095,  0.0125, -0.0270,  ..., -0.0022, -0.0146, -0.0065],
        ...,
        [-0.0017, -0.0009,  0.0065,  ..., -0.0153,  0.0004, -0.0138],
        [-0.0121, -0.0025,  0.0149,  ...,  0.0100, -0.0076,  0.0016],
        [-0.0086, -0.0037, -0.0111,  ..., -0.0062,  0.0019, -0.0297]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0333,  0.0056,  0.0080,  ..., -0.0140, -0.0129, -0.0003],
        [-0.0002, -0.0322, -0.0084,  ...,  0.0139, -0.0153,  0.0272],
        [ 0.0090, -0.0080, -0.0275,  ..., -0.0010,  0.0114,  0.0089],
        ...,
        [-0.0035, -0.0004, -0.0064,  ..., -0.0523,  0.0055, -0.0060],
        [-0.0117,  0.0051, -0.0070,  ..., -0.0141, -0.0372,  0.0071],
        [-0.0059, -0.0028, -0.0002,  ...,  0.0140,  0.0148, -0.0468]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:38:06 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-07-01 04:38:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7773,  0.2069, -0.2932,  ..., -0.0488, -0.0563,  1.5898],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6426, -0.1758, -2.4277,  ...,  0.0392, -0.0677,  0.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.7441,  0.2465, -1.0137,  ...,  0.3179,  0.1011,  3.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.0234,  0.9824, -5.8789,  ...,  0.4810, -0.3345, -0.2856],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:38:06 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:38:06 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 04:39:26 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 04:40:48 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 04:42:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.0741e-03, -7.1049e-04,  1.9073e-03,  ...,  6.1393e-05,
         -3.2082e-03, -7.7133e-03],
        [-5.1918e-03,  9.2773e-03,  2.7637e-03,  ...,  2.4376e-03,
          3.8776e-03,  6.1369e-04],
        [-3.6049e-03,  8.6260e-04,  8.3847e-03,  ..., -1.6088e-03,
          2.9697e-03, -1.6918e-03],
        ...,
        [-8.0185e-03,  6.2294e-03, -5.8250e-03,  ...,  6.8741e-03,
         -3.6182e-03,  5.7831e-03],
        [ 1.2755e-04,  1.2436e-03,  1.2803e-04,  ...,  3.4370e-03,
          5.3062e-03, -1.8826e-03],
        [-2.1248e-03, -4.6005e-03, -2.6665e-03,  ..., -7.3204e-03,
          9.5062e-03,  6.6872e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0148, -0.0008,  0.0040,  ..., -0.0042,  0.0013,  0.0060],
        [-0.0229, -0.0105, -0.0104,  ...,  0.0031, -0.0014, -0.0021],
        [ 0.0031, -0.0004, -0.0269,  ..., -0.0139, -0.0083,  0.0019],
        ...,
        [-0.0019,  0.0100, -0.0049,  ..., -0.0179, -0.0126, -0.0050],
        [ 0.0017,  0.0124, -0.0107,  ...,  0.0040, -0.0252, -0.0079],
        [-0.0029, -0.0035, -0.0001,  ..., -0.0085,  0.0022, -0.0241]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0423, -0.0047,  0.0092,  ...,  0.0059, -0.0165, -0.0120],
        [-0.0019, -0.0578, -0.0170,  ..., -0.0059,  0.0123,  0.0130],
        [ 0.0034,  0.0060, -0.0329,  ..., -0.0116,  0.0006, -0.0070],
        ...,
        [ 0.0135,  0.0049, -0.0036,  ..., -0.0555, -0.0172,  0.0043],
        [ 0.0156, -0.0133,  0.0071,  ..., -0.0112, -0.0465, -0.0157],
        [ 0.0240,  0.0052, -0.0136,  ...,  0.0091,  0.0007, -0.0367]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:42:09 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-07-01 04:42:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0518,  0.1237, -0.3015,  ...,  0.1147, -0.0661,  1.4512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7749, -0.0917, -2.3594,  ...,  0.1832, -0.0206,  0.0944],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([3.0820, 0.0502, 0.8652,  ..., 0.1884, 0.3066, 3.8438], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.1133,  0.3218, -4.5977,  ..., -0.0215, -0.9780,  0.8628],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:42:10 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:42:10 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 04:43:27 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 04:44:47 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 04:46:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-8.1873e-04, -4.7779e-04,  1.1845e-03,  ..., -4.2415e-04,
         -1.0471e-03,  7.8869e-04],
        [-1.7662e-03,  7.4387e-05,  3.7456e-04,  ...,  1.0376e-03,
          4.8447e-04, -8.1253e-04],
        [ 1.0462e-03,  2.7275e-03, -2.2774e-03,  ...,  3.1352e-05,
         -1.7395e-03,  2.2087e-03],
        ...,
        [-2.1305e-03,  5.0640e-04, -1.5564e-03,  ..., -3.1071e-03,
         -3.4153e-05,  1.7605e-03],
        [-2.3556e-04, -4.8828e-04,  1.0782e-04,  ..., -1.3647e-03,
         -1.0586e-03,  1.3151e-03],
        [ 4.5395e-04, -1.7109e-03,  3.3879e-04,  ..., -1.8673e-03,
          1.4007e-04, -1.2798e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.6815e-02, -1.9217e-03,  7.4959e-03,  ..., -1.3885e-02,
         -5.0735e-03,  2.6367e-02],
        [-8.0109e-05, -1.5732e-02,  1.4000e-02,  ...,  1.3710e-02,
          1.1406e-03, -1.6003e-03],
        [-1.0155e-02, -2.9697e-03, -1.3802e-02,  ...,  1.4496e-03,
         -1.7166e-02,  4.4098e-03],
        ...,
        [-1.3855e-02, -5.5466e-03,  3.6640e-03,  ..., -1.6571e-02,
         -1.0681e-02,  1.9531e-02],
        [-4.9858e-03,  4.7913e-03,  4.0512e-03,  ...,  3.1872e-03,
         -1.4549e-02,  5.1651e-03],
        [-8.1024e-03, -1.0071e-03, -1.4297e-02,  ...,  5.4626e-03,
          1.2840e-02,  1.7061e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0598, -0.0235, -0.0015,  ..., -0.0132, -0.0088,  0.0139],
        [-0.0160, -0.0445,  0.0143,  ..., -0.0165,  0.0095, -0.0125],
        [-0.0047,  0.0079, -0.0760,  ...,  0.0023, -0.0013, -0.0013],
        ...,
        [ 0.0216,  0.0071,  0.0172,  ..., -0.0513,  0.0100,  0.0125],
        [-0.0182,  0.0145, -0.0195,  ..., -0.0312, -0.0525, -0.0006],
        [-0.0112, -0.0085, -0.0081,  ..., -0.0122, -0.0001, -0.0601]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:46:11 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-07-01 04:46:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0156,  0.0871, -0.3789,  ...,  0.1173,  0.0564,  1.2656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7676,  0.3535, -2.1250,  ...,  0.1791, -0.1022, -0.1361],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([2.6680, 0.1439, 0.6562,  ..., 0.6660, 0.8149, 3.5977], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.3711,  0.1360, -4.7500,  ...,  0.2490, -2.4434,  2.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:46:11 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:46:11 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 04:47:35 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 04:48:59 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 04:50:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0157, -0.0033, -0.0004,  ..., -0.0034, -0.0005,  0.0004],
        [-0.0025,  0.0150,  0.0010,  ...,  0.0052,  0.0023,  0.0064],
        [-0.0015,  0.0031,  0.0190,  ..., -0.0023,  0.0001, -0.0018],
        ...,
        [-0.0052, -0.0024,  0.0023,  ...,  0.0154,  0.0019, -0.0015],
        [ 0.0056, -0.0036, -0.0032,  ...,  0.0024,  0.0084,  0.0007],
        [ 0.0051, -0.0019, -0.0022,  ..., -0.0009,  0.0027,  0.0137]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0186,  0.0201,  0.0119,  ..., -0.0125, -0.0038, -0.0008],
        [ 0.0157,  0.0032,  0.0155,  ..., -0.0041, -0.0048, -0.0069],
        [-0.0034,  0.0157,  0.0046,  ..., -0.0034,  0.0211,  0.0046],
        ...,
        [ 0.0005, -0.0088, -0.0091,  ...,  0.0041,  0.0012, -0.0148],
        [-0.0068, -0.0079, -0.0040,  ...,  0.0208, -0.0049,  0.0012],
        [-0.0069,  0.0033,  0.0030,  ..., -0.0100,  0.0113, -0.0146]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.2998e-02, -4.0512e-03,  9.9640e-03,  ..., -9.5978e-03,
         -8.2550e-03,  2.3697e-02],
        [ 1.8127e-02, -6.2866e-02, -1.2764e-02,  ..., -7.6008e-04,
         -3.2997e-03, -2.0493e-02],
        [ 4.7264e-03,  4.9515e-03, -5.5054e-02,  ...,  9.6130e-04,
         -5.6686e-03, -1.3161e-04],
        ...,
        [-9.2773e-03, -2.3384e-03, -2.1072e-02,  ..., -3.6987e-02,
         -1.0204e-03, -1.6479e-02],
        [ 4.6730e-05, -5.4970e-03, -6.7253e-03,  ..., -2.1744e-04,
         -9.3018e-02, -1.3519e-02],
        [ 5.3864e-03, -2.9373e-03,  2.6123e-02,  ..., -1.0834e-03,
          3.6068e-03, -7.0068e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:50:24 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-07-01 04:50:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([1.0664, 0.0423, 0.2439,  ..., 0.0541, 0.1158, 1.3027], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7617,  0.1362, -1.6543,  ..., -0.0151, -0.3362,  0.2817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.2949, -0.2837,  0.6465,  ...,  0.7036,  0.9346,  3.8301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8223, -0.5264, -4.8672,  ...,  1.1191, -2.6406,  3.5020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:50:24 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:50:24 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 04:51:48 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 04:53:12 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 04:54:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.4468e-03, -4.3583e-04, -3.4785e-04,  ...,  1.6861e-03,
          7.6771e-04,  1.2197e-03],
        [-4.5562e-04,  3.2291e-03, -3.8624e-04,  ..., -2.1040e-05,
         -1.4842e-04, -3.7503e-04],
        [-6.1274e-04, -3.2258e-04,  6.6223e-03,  ..., -6.1035e-04,
         -2.1183e-04, -6.0368e-04],
        ...,
        [-2.1398e-05,  7.5626e-04,  2.5415e-04,  ...,  7.5226e-03,
          8.0490e-04, -4.8780e-04],
        [-8.3208e-04, -3.9279e-05, -7.7724e-05,  ...,  1.0157e-03,
          7.2136e-03, -1.4648e-03],
        [ 1.7607e-04, -1.9407e-03,  7.5150e-04,  ...,  8.4758e-05,
          8.7404e-04,  8.6746e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0202,  0.0033, -0.0075,  ...,  0.0087,  0.0012,  0.0025],
        [-0.0053,  0.0031, -0.0062,  ..., -0.0146, -0.0051, -0.0053],
        [-0.0010, -0.0072,  0.0059,  ...,  0.0002, -0.0217, -0.0003],
        ...,
        [-0.0146, -0.0067, -0.0254,  ...,  0.0169, -0.0013,  0.0184],
        [-0.0138, -0.0058, -0.0038,  ...,  0.0021,  0.0143,  0.0017],
        [-0.0062,  0.0103, -0.0086,  ...,  0.0016,  0.0088,  0.0418]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0079, -0.0302, -0.0058,  ...,  0.0005,  0.0074,  0.0381],
        [-0.0062, -0.0263, -0.0037,  ..., -0.0171, -0.0148,  0.0077],
        [ 0.0106,  0.0206,  0.0390,  ..., -0.0057, -0.0003, -0.0039],
        ...,
        [-0.0096,  0.0011, -0.0270,  ...,  0.0263, -0.0015,  0.0018],
        [-0.0121, -0.0206,  0.0059,  ...,  0.0295,  0.0266, -0.0071],
        [-0.0028,  0.0088, -0.0273,  ...,  0.0114,  0.0052,  0.0314]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:54:37 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 04:54:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.8853, 0.0676, 0.1544,  ..., 0.1740, 0.2576, 1.1396], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8394,  0.0685, -1.6787,  ...,  0.0476, -0.8320,  0.6948],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.8691, -0.4934,  0.2822,  ...,  0.8765,  0.5430,  5.4375],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8779, -0.5854, -4.9883,  ..., -0.3369, -1.5010,  3.9590],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:54:37 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:54:37 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 04:56:03 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 04:57:27 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 04:58:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.1874e-03, -9.0837e-04,  4.6849e-04,  ..., -2.5392e-05,
          4.7112e-04, -4.8018e-04],
        [ 6.7472e-04,  3.6831e-03,  1.4086e-03,  ..., -1.1654e-03,
         -2.3365e-04, -5.5170e-04],
        [-1.1816e-03,  2.5809e-05,  6.6071e-03,  ...,  4.4823e-05,
         -2.9254e-04,  2.2531e-04],
        ...,
        [-6.9237e-04, -9.7179e-04, -7.8344e-04,  ...,  7.0114e-03,
          3.1233e-04,  1.9646e-04],
        [ 2.5582e-04,  5.1546e-04, -4.3273e-04,  ...,  1.4079e-04,
          5.5466e-03,  4.7803e-04],
        [ 3.6025e-04, -4.5204e-04,  8.3387e-05,  ...,  1.1504e-04,
          6.2764e-05,  6.0349e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0103, -0.0070,  0.0163,  ..., -0.0046, -0.0018,  0.0147],
        [-0.0011, -0.0094,  0.0053,  ...,  0.0065, -0.0095,  0.0016],
        [ 0.0099,  0.0125,  0.0110,  ..., -0.0151,  0.0089, -0.0256],
        ...,
        [-0.0089,  0.0143, -0.0009,  ...,  0.0044,  0.0116, -0.0078],
        [-0.0123,  0.0065,  0.0015,  ..., -0.0078, -0.0050,  0.0007],
        [ 0.0055, -0.0075, -0.0108,  ...,  0.0166,  0.0059,  0.0173]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.9938e-02, -2.0187e-02,  3.8513e-02,  ...,  1.0651e-02,
          2.7527e-02,  6.1531e-03],
        [ 2.0885e-03, -5.6030e-02,  4.2305e-03,  ...,  6.5689e-03,
          9.1171e-03, -1.8143e-02],
        [ 2.1942e-02, -2.7924e-03, -1.6403e-02,  ..., -4.4670e-03,
          6.6528e-03, -6.9885e-03],
        ...,
        [-1.8320e-03,  6.6948e-03, -2.6207e-03,  ..., -5.4352e-02,
         -2.0493e-02,  4.2915e-06],
        [ 1.9867e-02,  1.4442e-02, -1.4029e-03,  ..., -1.4687e-04,
         -4.3060e-02,  4.2610e-03],
        [ 6.3858e-03, -6.7825e-03,  3.1967e-03,  ...,  1.5114e-02,
          1.4633e-02, -9.2621e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 04:58:51 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 04:58:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7432, -0.0533,  0.1019,  ...,  0.1074,  0.2472,  1.0947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6558, -0.1368, -1.6494,  ...,  0.2620, -0.8770,  1.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.8535, -0.4202, -1.4004,  ...,  0.1304, -0.1807,  4.8320],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.5293,  0.6431, -6.2188,  ..., -0.9683, -1.0215,  1.1934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 04:58:52 root INFO     [order_1_approx] starting weight calculation for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 04:58:52 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 05:00:11 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 05:01:30 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 05:02:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.1458e-03,  5.5194e-05,  3.6621e-04,  ..., -5.8413e-04,
          3.3116e-04, -2.6155e-04],
        [ 7.5531e-04,  1.8272e-03,  1.8120e-05,  ...,  2.3770e-04,
         -3.0947e-04,  2.3532e-04],
        [ 1.0328e-03,  7.4923e-05,  2.2640e-03,  ..., -8.3876e-04,
         -6.6137e-04,  8.0287e-05],
        ...,
        [-5.2309e-04, -4.6968e-04, -3.7408e-04,  ...,  2.6474e-03,
         -2.4438e-04, -1.0699e-04],
        [ 1.3304e-04, -3.0470e-04,  8.6021e-04,  ..., -6.6817e-05,
          3.4256e-03, -1.2045e-03],
        [-2.0838e-04,  1.4400e-03, -5.6553e-04,  ..., -2.6536e-04,
          2.6894e-04,  5.3177e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 1.4603e-02,  2.0599e-04, -1.1978e-02,  ..., -6.1913e-03,
          1.3641e-02, -1.4519e-02],
        [ 2.1477e-03, -1.3031e-02,  1.1749e-03,  ...,  1.1787e-03,
          9.4070e-03, -4.2038e-03],
        [-1.3756e-02, -1.7643e-03,  2.8061e-02,  ...,  1.9775e-02,
          4.3640e-03, -8.1406e-03],
        ...,
        [ 1.5259e-05, -3.3836e-03,  1.6899e-03,  ...,  2.9312e-02,
         -2.3575e-02,  1.0078e-02],
        [-3.8719e-03, -1.4137e-02, -6.5804e-03,  ..., -1.5594e-02,
          1.2619e-02, -1.3542e-04],
        [ 1.6327e-03,  2.1606e-02, -1.1406e-02,  ...,  5.5428e-03,
          1.6266e-02,  3.5492e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0015, -0.0056,  0.0018,  ..., -0.0088, -0.0117, -0.0146],
        [ 0.0308, -0.0630,  0.0005,  ..., -0.0029,  0.0021, -0.0052],
        [ 0.0056, -0.0028, -0.0053,  ..., -0.0034,  0.0235, -0.0109],
        ...,
        [-0.0105, -0.0024, -0.0109,  ..., -0.0028,  0.0069, -0.0072],
        [ 0.0059, -0.0065, -0.0340,  ..., -0.0186, -0.0013,  0.0066],
        [-0.0168,  0.0147,  0.0219,  ..., -0.0068,  0.0221,  0.0140]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:02:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To minimize results in minimization
To aspire results in aspiration
To standardize results in standardization
To characterize results in characterization
To restore results in restoration
To randomize results in randomization
To optimize results in optimization
To illumine results in
2024-07-01 05:02:50 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 05:02:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2605, -0.3696, -0.2396,  ..., -0.5605, -0.2922, -0.2277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1642,  0.2966, -0.4021,  ..., -0.4741, -0.3735, -0.1356],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3743, -0.1058, -0.5332,  ..., -0.1772, -0.5464, -0.1788],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0686,  0.3364, -0.2144,  ...,  0.0096, -0.1987,  0.1121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:02:50 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:02:50 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 05:03:13 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 05:03:36 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 05:03:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3412e-02,  3.0499e-03, -2.1935e-03,  ..., -3.6240e-04,
          8.8072e-04, -1.2159e-03],
        [-2.1911e-04, -1.3649e-02,  6.8760e-04,  ...,  2.3308e-03,
         -3.7632e-03,  4.5853e-03],
        [-7.7343e-04,  1.1024e-03, -1.3290e-02,  ...,  2.0981e-05,
         -2.5711e-03,  3.9825e-03],
        ...,
        [-1.1759e-03, -1.1244e-03, -4.0174e-05,  ..., -1.1169e-02,
         -2.9716e-03, -1.8525e-04],
        [-3.8481e-04,  3.8958e-04,  1.2350e-03,  ..., -1.9245e-03,
         -1.3222e-02,  9.2030e-04],
        [ 2.9898e-04,  1.3199e-03, -3.9244e-04,  ...,  2.0542e-03,
          2.9202e-03, -1.4320e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0468, -0.0004, -0.0068,  ..., -0.0112, -0.0002,  0.0016],
        [ 0.0023, -0.0377, -0.0041,  ...,  0.0048,  0.0029, -0.0008],
        [ 0.0016,  0.0032, -0.0495,  ...,  0.0014,  0.0028,  0.0074],
        ...,
        [-0.0025,  0.0064,  0.0043,  ..., -0.0289, -0.0026, -0.0055],
        [-0.0058, -0.0084,  0.0013,  ..., -0.0112, -0.0462,  0.0103],
        [ 0.0003,  0.0003,  0.0063,  ..., -0.0008, -0.0004, -0.0356]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.5339e-02,  3.7937e-03, -7.1182e-03,  ..., -1.2808e-03,
         -4.3144e-03,  2.9716e-03],
        [ 3.6354e-03, -4.1840e-02, -1.2493e-03,  ...,  4.9896e-03,
          3.7956e-03, -1.0166e-03],
        [-4.1046e-03, -1.2484e-03, -4.5807e-02,  ...,  7.7057e-04,
          4.7798e-03,  2.7447e-03],
        ...,
        [-2.4834e-03,  6.2943e-03,  1.0824e-04,  ..., -4.1595e-02,
          5.3883e-05,  9.8228e-05],
        [-1.9350e-03, -2.2721e-04,  2.5272e-04,  ..., -1.0748e-03,
         -3.7354e-02,  3.5725e-03],
        [-2.6340e-03, -3.0994e-03, -5.4884e-04,  ...,  3.4103e-03,
          4.2076e-03, -3.6316e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:04:01 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 05:04:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0812,  0.1538, -0.8062,  ..., -0.7651, -0.0265, -0.4165],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2537,  0.2374, -0.2261,  ..., -0.2798, -0.2250, -0.2057],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3984,  0.0278, -0.2651,  ..., -0.3035, -0.1919, -0.6851],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2778,  0.3108, -0.2415,  ..., -0.4629, -0.3223,  0.4016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:04:01 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:04:01 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 05:04:25 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 05:04:49 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 05:05:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3453e-02,  1.8196e-03, -9.9754e-04,  ...,  2.0528e-04,
         -1.2131e-03, -1.8048e-04],
        [-1.1671e-04, -2.4261e-02,  1.6952e-04,  ...,  2.0351e-03,
         -2.8133e-04, -4.2892e-04],
        [-3.7909e-04,  2.8267e-03, -2.3621e-02,  ...,  3.3927e-04,
         -1.0462e-03,  1.4229e-03],
        ...,
        [ 2.8343e-03,  4.9362e-03,  7.1573e-04,  ..., -2.2888e-02,
         -2.6302e-03,  2.9266e-05],
        [-1.7395e-03,  1.2274e-03, -8.7690e-04,  ...,  8.5449e-04,
         -2.0340e-02, -4.6158e-03],
        [ 3.5191e-04, -3.6163e-03, -3.1929e-03,  ...,  2.0266e-06,
          2.9736e-03, -2.4246e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0700,  0.0111,  0.0021,  ...,  0.0001, -0.0134, -0.0032],
        [ 0.0013, -0.0692, -0.0013,  ...,  0.0001,  0.0063, -0.0049],
        [-0.0024, -0.0011, -0.0576,  ...,  0.0012, -0.0141, -0.0013],
        ...,
        [ 0.0076,  0.0018, -0.0065,  ..., -0.0688, -0.0077, -0.0006],
        [-0.0006, -0.0114,  0.0058,  ...,  0.0051, -0.0564,  0.0028],
        [-0.0042,  0.0073,  0.0026,  ..., -0.0081,  0.0099, -0.0820]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0779,  0.0046,  0.0009,  ...,  0.0033, -0.0032,  0.0029],
        [ 0.0053, -0.0756, -0.0021,  ...,  0.0006,  0.0052, -0.0034],
        [ 0.0007, -0.0059, -0.0717,  ..., -0.0047,  0.0059, -0.0003],
        ...,
        [ 0.0070, -0.0046,  0.0017,  ..., -0.0739, -0.0032,  0.0016],
        [-0.0048, -0.0018,  0.0089,  ...,  0.0030, -0.0674, -0.0003],
        [ 0.0003,  0.0029,  0.0074,  ...,  0.0017, -0.0021, -0.0780]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:05:16 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 05:05:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4348, -0.1606, -0.6577,  ..., -0.2120, -0.6646, -0.2573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0942,  0.5483, -0.3560,  ...,  0.0161, -0.3247,  0.1671],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2671, -0.2720, -0.0175,  ..., -0.1298, -0.5459, -0.6924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0829,  0.3633, -0.2754,  ..., -0.3796, -0.9507,  0.5713],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:05:16 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:05:16 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 05:05:43 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 05:06:08 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 05:06:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.9803e-03, -1.3905e-03, -5.0545e-04,  ...,  3.9530e-04,
         -1.5545e-03, -3.0231e-03],
        [-1.1129e-03, -8.2703e-03, -1.1759e-03,  ..., -2.4247e-04,
         -4.3058e-04,  6.2609e-04],
        [ 1.6613e-03, -1.7691e-03, -5.3787e-03,  ..., -1.7080e-03,
          1.1806e-03,  5.9700e-04],
        ...,
        [ 3.2711e-04,  2.7227e-04, -1.7614e-03,  ..., -7.9117e-03,
          2.0142e-03,  9.6369e-04],
        [ 9.1016e-05, -5.8508e-04,  1.8644e-03,  ..., -7.9536e-04,
         -5.8403e-03, -1.3649e-04],
        [ 4.3082e-04,  8.0109e-04,  1.1892e-03,  ..., -9.2173e-04,
          4.1199e-04, -5.9280e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.1311e-02, -9.0408e-03, -1.3199e-03,  ...,  3.2616e-03,
          7.0906e-04, -5.3864e-03],
        [-3.6507e-03, -4.0436e-02, -7.4921e-03,  ..., -4.2877e-03,
          5.0831e-04, -3.3855e-04],
        [ 1.1787e-03,  2.7752e-04, -4.2053e-02,  ..., -9.3460e-03,
          1.0468e-02,  4.1275e-03],
        ...,
        [ 4.8828e-03,  1.4210e-03, -9.7809e-03,  ..., -4.0924e-02,
          1.8444e-03, -3.7956e-04],
        [-6.4087e-03, -5.3062e-03,  7.5626e-04,  ...,  8.2016e-05,
         -4.4220e-02,  3.9215e-03],
        [-2.1687e-03, -5.5161e-03, -1.0281e-03,  ..., -3.3054e-03,
          5.8823e-03, -3.5889e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0323,  0.0028, -0.0062,  ..., -0.0024,  0.0018, -0.0032],
        [-0.0061, -0.0341,  0.0075,  ...,  0.0008, -0.0048,  0.0023],
        [ 0.0077,  0.0042, -0.0316,  ...,  0.0012,  0.0038,  0.0037],
        ...,
        [-0.0036,  0.0012, -0.0056,  ..., -0.0380, -0.0088,  0.0007],
        [ 0.0016,  0.0036, -0.0030,  ...,  0.0052, -0.0323, -0.0007],
        [-0.0007, -0.0030,  0.0002,  ..., -0.0049,  0.0114, -0.0340]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:06:36 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 05:06:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4512,  0.0036, -0.3120,  ..., -0.3472, -0.2472, -0.8823],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4331,  0.4890, -0.3796,  ..., -0.7129, -0.5278,  0.6333],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4902, -0.5332,  0.2491,  ..., -0.2905, -0.7329, -0.4573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1637,  0.5293, -0.0164,  ..., -0.3943, -0.4458,  0.4575],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:06:36 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:06:36 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 05:07:05 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 05:07:35 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 05:08:06 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.9635e-03,  1.6010e-04,  3.9625e-04,  ...,  1.0109e-03,
          7.6580e-04, -1.7443e-03],
        [-9.0027e-04, -3.5210e-03, -2.2869e-03,  ...,  2.8253e-05,
         -7.9679e-04, -1.7846e-04],
        [-1.2112e-03, -6.2847e-04, -3.0689e-03,  ..., -8.7166e-04,
          5.3883e-04, -2.3508e-04],
        ...,
        [-5.6982e-04, -2.9640e-03, -5.7578e-05,  ..., -3.5686e-03,
          1.9312e-04,  1.8537e-05],
        [-4.1866e-04, -1.2159e-03,  7.5054e-04,  ..., -2.1343e-03,
         -3.9520e-03, -5.2357e-04],
        [ 1.1134e-04,  9.9659e-04, -8.2970e-05,  ..., -1.6251e-03,
         -1.1787e-03, -3.9749e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0552, -0.0096, -0.0059,  ...,  0.0019,  0.0031, -0.0091],
        [ 0.0026, -0.0551, -0.0013,  ..., -0.0017,  0.0048,  0.0015],
        [ 0.0017, -0.0079, -0.0453,  ...,  0.0091, -0.0102,  0.0046],
        ...,
        [-0.0064,  0.0020,  0.0117,  ..., -0.0538, -0.0032,  0.0035],
        [-0.0015, -0.0089, -0.0073,  ..., -0.0116, -0.0341,  0.0045],
        [ 0.0038, -0.0022,  0.0014,  ...,  0.0006,  0.0009, -0.0474]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.7150e-02, -5.4779e-03, -1.1845e-03,  ..., -1.0529e-02,
          1.2197e-03,  3.4828e-03],
        [ 1.4427e-02, -4.2358e-02, -3.7613e-03,  ...,  7.2670e-03,
          9.7275e-03, -8.4763e-03],
        [-6.6376e-03, -8.2245e-03, -4.7241e-02,  ...,  4.6730e-03,
         -1.4496e-04, -7.1869e-03],
        ...,
        [-5.3864e-03,  1.7700e-03,  6.4316e-03,  ..., -5.3040e-02,
         -1.1196e-03, -7.8125e-03],
        [-4.3869e-05, -1.5497e-03, -9.6321e-04,  ...,  3.8385e-04,
         -4.5258e-02,  5.3520e-03],
        [-1.1765e-02, -7.2289e-04, -6.9618e-03,  ...,  8.5373e-03,
         -4.1962e-05, -4.9835e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:08:08 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 05:08:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2439, -0.3328, -0.0173,  ..., -0.1344, -0.5166, -0.7544],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0894,  0.4224, -0.3237,  ..., -0.4512, -1.1553,  0.6948],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.7173, -0.1714,  0.4224,  ..., -0.4521, -0.8032, -1.0283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1547,  0.3247,  0.3923,  ..., -0.2681, -0.3062, -0.0247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:08:08 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:08:08 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 05:08:41 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 05:09:13 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 05:09:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0022, -0.0001, -0.0010,  ..., -0.0005,  0.0009,  0.0005],
        [ 0.0018,  0.0010,  0.0004,  ..., -0.0002, -0.0002,  0.0008],
        [ 0.0002, -0.0023, -0.0011,  ..., -0.0002, -0.0004, -0.0004],
        ...,
        [-0.0019,  0.0010, -0.0007,  ...,  0.0013,  0.0012,  0.0009],
        [ 0.0003,  0.0001, -0.0004,  ...,  0.0011,  0.0023,  0.0002],
        [ 0.0018, -0.0004, -0.0010,  ..., -0.0006, -0.0014, -0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0759,  0.0065, -0.0018,  ..., -0.0118, -0.0006,  0.0075],
        [ 0.0023, -0.0851, -0.0066,  ...,  0.0087,  0.0011,  0.0114],
        [-0.0029, -0.0026, -0.0910,  ...,  0.0019, -0.0051,  0.0039],
        ...,
        [-0.0037,  0.0005, -0.0118,  ..., -0.0774,  0.0014, -0.0017],
        [ 0.0152,  0.0071,  0.0090,  ..., -0.0050, -0.0839,  0.0188],
        [-0.0018,  0.0144,  0.0045,  ...,  0.0059,  0.0094, -0.0959]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0895,  0.0026,  0.0044,  ..., -0.0034, -0.0048,  0.0007],
        [-0.0100, -0.0845,  0.0072,  ...,  0.0075, -0.0019,  0.0011],
        [-0.0056,  0.0010, -0.0786,  ..., -0.0010,  0.0064,  0.0049],
        ...,
        [ 0.0002, -0.0012, -0.0040,  ..., -0.0817, -0.0013,  0.0046],
        [-0.0030, -0.0040,  0.0017,  ..., -0.0005, -0.0848,  0.0066],
        [-0.0010,  0.0054,  0.0053,  ..., -0.0108,  0.0003, -0.1053]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:09:48 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 05:09:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4695, -0.5527,  0.2159,  ..., -0.2710, -0.7256, -0.4817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2009,  0.6406, -0.0290,  ..., -0.4521, -0.5493,  0.5425],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5947, -0.0729, -0.0598,  ..., -0.3032, -0.6152, -1.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0529,  0.3469, -0.3069,  ..., -0.0811, -0.5967, -0.9648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:09:48 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:09:48 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 05:10:23 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 05:10:57 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 05:11:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.5302e-03, -4.0817e-03,  1.1177e-03,  ..., -2.6436e-03,
          3.8052e-03,  1.5182e-03],
        [ 2.5597e-03, -1.2772e-02,  4.9133e-03,  ...,  4.7493e-04,
          1.6346e-03, -1.4400e-03],
        [-3.4733e-03,  6.1722e-03, -8.7585e-03,  ...,  6.4564e-04,
         -1.8206e-03, -4.7722e-03],
        ...,
        [ 2.2736e-03, -5.3406e-03,  2.2392e-03,  ..., -6.0234e-03,
         -9.4986e-04, -5.5552e-05],
        [ 3.6697e-03,  1.0157e-04,  1.5106e-03,  ..., -5.0011e-03,
         -3.9062e-03, -1.4668e-03],
        [ 2.1915e-03,  2.2774e-03, -7.1812e-04,  ...,  2.5215e-03,
         -5.2643e-03, -4.4174e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0845,  0.0048, -0.0039,  ...,  0.0073, -0.0011, -0.0037],
        [-0.0026, -0.1116,  0.0068,  ...,  0.0051, -0.0010,  0.0053],
        [ 0.0075, -0.0014, -0.1000,  ..., -0.0042, -0.0031,  0.0032],
        ...,
        [ 0.0074,  0.0010,  0.0067,  ..., -0.0982,  0.0035, -0.0010],
        [-0.0065, -0.0038, -0.0061,  ...,  0.0033, -0.0946, -0.0011],
        [-0.0077,  0.0053, -0.0075,  ..., -0.0163,  0.0006, -0.0980]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.5449e-02, -6.6032e-03, -1.6127e-03,  ..., -2.3651e-03,
         -3.7861e-03, -6.4373e-05],
        [ 2.4223e-03, -8.8440e-02,  3.5858e-04,  ..., -4.6616e-03,
         -6.9122e-03, -1.2770e-03],
        [-2.5043e-03, -1.7128e-03, -8.0444e-02,  ...,  3.7498e-03,
         -1.0967e-03, -6.2637e-03],
        ...,
        [ 9.6054e-03,  3.3522e-04,  6.3705e-03,  ..., -9.0576e-02,
         -7.5417e-03, -7.4959e-03],
        [ 8.1921e-04, -1.5717e-03, -9.2392e-03,  ..., -1.0176e-03,
         -8.6243e-02,  3.5477e-03],
        [-8.9417e-03,  4.7264e-03, -1.4557e-02,  ..., -3.7155e-03,
         -3.4847e-03, -9.0393e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:11:34 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 05:11:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6602, -0.1591,  0.3472,  ..., -0.4270, -0.7500, -1.0244],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1638,  0.3586,  0.3660,  ..., -0.2869, -0.3188, -0.0613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8086, -0.3103, -0.1179,  ..., -0.4089, -0.3293, -1.5098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1924, -0.2917, -0.1477,  ...,  0.1558,  0.0869, -1.2207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:11:34 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:11:34 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 05:12:12 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 05:12:49 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 05:13:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.0501e-03,  3.0346e-03,  4.2129e-04,  ...,  7.2145e-04,
          8.6308e-05, -1.2779e-03],
        [ 2.0065e-03, -4.0054e-03, -4.4060e-03,  ...,  1.4839e-03,
         -1.5574e-03, -2.8362e-03],
        [ 2.2812e-03, -1.6212e-03,  4.8923e-04,  ..., -1.6747e-03,
         -1.1272e-03, -6.8903e-05],
        ...,
        [ 1.3819e-03,  1.1406e-03,  1.7891e-03,  ..., -3.5915e-03,
          2.3365e-03,  3.9978e-03],
        [-2.3098e-03,  4.5133e-04, -2.0714e-03,  ...,  1.0738e-03,
          1.0166e-03, -2.0278e-04],
        [ 5.0545e-03,  6.2084e-04,  9.8228e-04,  ...,  2.1610e-03,
          1.0498e-02, -7.5073e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.5562e-02,  8.0109e-03, -9.2983e-04,  ..., -9.2125e-04,
         -4.3640e-03,  7.2136e-03],
        [ 3.4218e-03, -6.9336e-02, -1.2909e-02,  ..., -3.5896e-03,
         -5.7526e-03,  6.8169e-03],
        [-3.6945e-03, -2.5387e-03, -7.8491e-02,  ...,  8.1558e-03,
          3.5610e-03, -4.6730e-05],
        ...,
        [-6.0921e-03, -9.4557e-04,  7.0038e-03,  ..., -7.7454e-02,
         -3.1338e-03, -5.9662e-03],
        [ 3.6240e-03,  3.6392e-03,  1.3189e-03,  ...,  1.2192e-02,
         -8.3679e-02, -1.4601e-03],
        [ 3.6011e-03,  5.9795e-04,  6.9046e-03,  ...,  7.9422e-03,
          5.8985e-04, -7.8857e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1072,  0.0037,  0.0126,  ..., -0.0043, -0.0117,  0.0060],
        [ 0.0068, -0.0832, -0.0091,  ...,  0.0036,  0.0041,  0.0041],
        [ 0.0014, -0.0058, -0.0880,  ...,  0.0048, -0.0018,  0.0065],
        ...,
        [ 0.0020, -0.0002, -0.0040,  ..., -0.0874,  0.0179, -0.0002],
        [ 0.0075,  0.0043,  0.0046,  ...,  0.0054, -0.0870, -0.0078],
        [-0.0005, -0.0019,  0.0063,  ...,  0.0048,  0.0034, -0.0906]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:13:30 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 05:13:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5239, -0.0816, -0.0668,  ..., -0.2563, -0.5386, -1.4277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0472,  0.3384, -0.2922,  ..., -0.0750, -0.5669, -0.9731],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9053, -0.5259, -0.4402,  ..., -0.5537, -0.3606, -1.1299],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2291, -1.0684, -0.8037,  ..., -0.2825, -0.1511, -0.3242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:13:30 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:13:30 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 05:14:12 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 05:14:54 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 05:15:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0008, -0.0015, -0.0023,  ..., -0.0033, -0.0006, -0.0022],
        [-0.0018, -0.0055,  0.0008,  ..., -0.0022,  0.0004, -0.0023],
        [-0.0020,  0.0013, -0.0059,  ...,  0.0002,  0.0002,  0.0001],
        ...,
        [-0.0025, -0.0007, -0.0034,  ..., -0.0045,  0.0016,  0.0010],
        [ 0.0030, -0.0009,  0.0009,  ..., -0.0015, -0.0084, -0.0009],
        [ 0.0021,  0.0028,  0.0031,  ..., -0.0002,  0.0026, -0.0028]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0931, -0.0022, -0.0001,  ..., -0.0048, -0.0181,  0.0099],
        [-0.0100, -0.1006,  0.0271,  ...,  0.0111, -0.0088,  0.0091],
        [ 0.0078,  0.0087, -0.0816,  ..., -0.0011, -0.0120, -0.0033],
        ...,
        [-0.0057,  0.0018,  0.0007,  ..., -0.0828, -0.0036, -0.0080],
        [-0.0037,  0.0003,  0.0049,  ..., -0.0092, -0.0793,  0.0079],
        [ 0.0056,  0.0026, -0.0099,  ...,  0.0008, -0.0057, -0.0841]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1166,  0.0194, -0.0052,  ..., -0.0172,  0.0017, -0.0084],
        [-0.0040, -0.1083,  0.0086,  ..., -0.0005, -0.0057,  0.0108],
        [ 0.0092,  0.0014, -0.1099,  ..., -0.0062, -0.0001,  0.0161],
        ...,
        [-0.0032,  0.0006, -0.0077,  ..., -0.1058, -0.0042,  0.0024],
        [-0.0074,  0.0137, -0.0029,  ..., -0.0011, -0.1097,  0.0179],
        [ 0.0110, -0.0087, -0.0151,  ...,  0.0004,  0.0051, -0.1141]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:15:37 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 05:15:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5854, -0.2466, -0.1404,  ..., -0.3120, -0.2607, -1.1807],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1426, -0.2515, -0.1682,  ...,  0.1021,  0.0549, -1.0566],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0723,  0.0215,  0.3186,  ..., -0.7202, -0.1836, -1.1562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1318, -1.1055, -0.7871,  ...,  0.0037,  0.0774, -0.2224],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:15:37 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:15:37 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 05:16:17 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 05:16:54 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 05:17:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.4181e-03,  3.9749e-03,  2.2888e-03,  ..., -1.3199e-03,
          1.7891e-03, -1.0052e-03],
        [ 3.1624e-03, -1.6985e-03, -2.7237e-03,  ..., -2.5215e-03,
         -3.7823e-03,  6.0425e-03],
        [-1.5974e-03, -5.0449e-04,  8.1711e-03,  ..., -1.6747e-03,
          4.4937e-03, -3.2158e-03],
        ...,
        [ 2.3460e-03, -2.5997e-03, -2.4281e-03,  ..., -4.3440e-04,
         -8.7881e-04,  2.4796e-05],
        [-4.5090e-03,  1.8644e-03, -7.1526e-04,  ...,  4.0054e-04,
         -2.5692e-03,  6.2513e-04],
        [-3.7193e-04, -1.5182e-03, -1.4696e-03,  ..., -2.6150e-03,
         -3.4034e-05,  2.5692e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1098, -0.0180, -0.0064,  ...,  0.0138,  0.0055, -0.0073],
        [-0.0110, -0.1181, -0.0088,  ...,  0.0035, -0.0021,  0.0107],
        [-0.0183,  0.0114, -0.1051,  ...,  0.0192, -0.0024, -0.0089],
        ...,
        [-0.0125,  0.0090,  0.0114,  ..., -0.1226, -0.0099, -0.0128],
        [-0.0004,  0.0013,  0.0028,  ..., -0.0046, -0.1223,  0.0083],
        [ 0.0050,  0.0020, -0.0058,  ...,  0.0006,  0.0079, -0.1196]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.4758e-01, -1.8524e-02, -9.4795e-04,  ...,  9.6893e-03,
          3.1052e-03,  6.1226e-03],
        [-1.0891e-03, -1.6919e-01, -5.4359e-03,  ..., -7.4387e-05,
         -9.9640e-03, -2.7046e-03],
        [-8.8272e-03, -1.0933e-02, -1.3330e-01,  ...,  1.4427e-02,
         -4.4250e-03, -9.2239e-03],
        ...,
        [-1.3763e-02,  9.6359e-03,  7.5798e-03,  ..., -1.5967e-01,
          2.1801e-03,  7.2021e-03],
        [ 9.6588e-03,  2.7962e-03,  5.7220e-03,  ..., -5.1422e-03,
         -1.5527e-01, -1.6403e-03],
        [-1.2840e-02,  5.3101e-03, -7.5722e-03,  ..., -1.2932e-02,
         -7.5989e-03, -1.5149e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:17:42 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 05:17:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6240, -0.3857, -0.3308,  ..., -0.3535, -0.2620, -0.8379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1809, -0.8403, -0.6235,  ..., -0.1932, -0.1276, -0.2947],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8018,  0.4136,  0.4526,  ..., -0.9956, -0.0107, -1.3525],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6133, -0.2222, -0.3760,  ..., -0.5635, -0.0380,  0.6738],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:17:42 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:17:42 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 05:18:30 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 05:19:20 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 05:20:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1551e-02,  3.6716e-03, -1.8539e-03,  ...,  9.5510e-04,
         -8.8692e-05,  3.9864e-04],
        [-5.9724e-05, -1.5354e-03,  6.2103e-03,  ...,  4.0092e-03,
          2.1820e-03,  4.8370e-03],
        [ 7.7486e-04, -2.9850e-03, -5.5656e-03,  ..., -4.7731e-04,
         -1.1168e-03, -3.6201e-03],
        ...,
        [-1.3456e-03, -1.9684e-03,  2.1458e-03,  ..., -6.2065e-03,
         -3.9215e-03,  1.3018e-04],
        [ 3.2949e-04, -4.1695e-03,  3.0804e-04,  ...,  9.3889e-04,
         -5.9433e-03,  7.1573e-04],
        [ 2.1191e-03,  1.2608e-03, -6.0749e-04,  ...,  2.0924e-03,
          3.0160e-04, -4.3030e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1312,  0.0211,  0.0045,  ...,  0.0081, -0.0123,  0.0055],
        [ 0.0029, -0.1099,  0.0027,  ...,  0.0027,  0.0059,  0.0013],
        [ 0.0036, -0.0099, -0.1025,  ..., -0.0055, -0.0064,  0.0140],
        ...,
        [ 0.0009, -0.0023, -0.0079,  ..., -0.0967,  0.0019, -0.0165],
        [ 0.0031,  0.0082, -0.0010,  ...,  0.0104, -0.0995,  0.0076],
        [ 0.0060,  0.0105, -0.0034,  ...,  0.0084, -0.0039, -0.0989]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1232,  0.0275,  0.0029,  ..., -0.0041, -0.0110,  0.0087],
        [ 0.0077, -0.1063,  0.0008,  ...,  0.0074, -0.0025, -0.0132],
        [-0.0009,  0.0191, -0.1181,  ...,  0.0011, -0.0088,  0.0027],
        ...,
        [ 0.0018, -0.0087, -0.0083,  ..., -0.0986,  0.0027, -0.0087],
        [-0.0107, -0.0069, -0.0083,  ..., -0.0018, -0.1250,  0.0175],
        [ 0.0053, -0.0007,  0.0022,  ...,  0.0084, -0.0030, -0.1159]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:20:13 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 05:20:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6758, -0.0101,  0.1439,  ..., -0.4783, -0.1406, -0.7603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7754, -0.8013, -0.5615,  ..., -0.0302,  0.0321, -0.1543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8545,  0.3320,  0.5000,  ..., -0.9980, -0.3416, -1.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0273,  0.0281, -0.7295,  ..., -0.7183,  0.0299,  0.3643],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:20:13 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:20:13 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 05:21:02 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 05:21:54 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 05:22:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0021, -0.0020,  0.0010,  ..., -0.0022,  0.0013, -0.0017],
        [ 0.0018,  0.0005,  0.0001,  ...,  0.0002,  0.0005,  0.0037],
        [-0.0063, -0.0021,  0.0011,  ..., -0.0023,  0.0053,  0.0003],
        ...,
        [ 0.0004,  0.0026,  0.0059,  ...,  0.0020, -0.0032,  0.0061],
        [-0.0045, -0.0044,  0.0007,  ..., -0.0039,  0.0049,  0.0049],
        [-0.0031, -0.0023,  0.0037,  ..., -0.0019, -0.0010, -0.0041]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1428,  0.0003, -0.0101,  ..., -0.0035,  0.0069, -0.0174],
        [ 0.0090, -0.1565, -0.0081,  ...,  0.0022, -0.0047, -0.0055],
        [-0.0014, -0.0014, -0.1538,  ..., -0.0099,  0.0056, -0.0121],
        ...,
        [-0.0223, -0.0034,  0.0070,  ..., -0.1659,  0.0082,  0.0005],
        [-0.0008,  0.0018,  0.0007,  ..., -0.0023, -0.1495, -0.0087],
        [-0.0026, -0.0014, -0.0155,  ..., -0.0134,  0.0086, -0.1450]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2341,  0.0235,  0.0135,  ..., -0.0067, -0.0111, -0.0042],
        [ 0.0087, -0.2573, -0.0088,  ..., -0.0158,  0.0042,  0.0028],
        [ 0.0015,  0.0088, -0.2279,  ...,  0.0059,  0.0084,  0.0038],
        ...,
        [-0.0140,  0.0105, -0.0060,  ..., -0.2703,  0.0126, -0.0031],
        [-0.0170, -0.0036, -0.0033,  ...,  0.0062, -0.2429,  0.0006],
        [ 0.0043, -0.0119, -0.0103,  ...,  0.0019,  0.0127, -0.2473]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:22:49 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 05:22:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4951,  0.2529,  0.2274,  ..., -0.6475, -0.0202, -0.9697],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2627, -0.1938, -0.3347,  ..., -0.4443, -0.0394,  0.4971],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8730,  0.5137,  0.6943,  ..., -0.4995, -0.4807, -0.5059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8062,  0.0808, -0.3811,  ..., -1.0938,  0.7363,  0.5298],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:22:49 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:22:49 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 05:23:43 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 05:24:36 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 05:25:31 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.0539e-03,  1.3313e-03, -8.3685e-05,  ...,  1.6785e-03,
         -6.4659e-03, -1.7395e-03],
        [-1.8797e-03, -5.8327e-03,  1.9646e-03,  ..., -2.2068e-03,
         -2.8629e-03, -4.7946e-04],
        [ 2.0676e-03,  1.4763e-03, -5.0583e-03,  ..., -9.5963e-05,
         -1.5469e-03, -3.6812e-03],
        ...,
        [ 1.2445e-03, -2.4014e-03, -1.8177e-03,  ..., -6.6757e-03,
         -7.9441e-04, -2.5845e-03],
        [ 9.7132e-04,  1.4009e-03, -3.3150e-03,  ..., -3.9253e-03,
         -5.7259e-03,  2.6569e-03],
        [ 1.2245e-03,  2.9697e-03,  7.9298e-04,  ..., -1.1301e-03,
          1.7452e-04, -5.2147e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0895,  0.0048,  0.0168,  ..., -0.0016, -0.0174, -0.0113],
        [-0.0023, -0.0813, -0.0035,  ..., -0.0093,  0.0006, -0.0012],
        [-0.0119, -0.0034, -0.0874,  ...,  0.0051, -0.0064,  0.0085],
        ...,
        [ 0.0050,  0.0037, -0.0010,  ..., -0.0790,  0.0031,  0.0022],
        [ 0.0024,  0.0006, -0.0027,  ...,  0.0033, -0.0957,  0.0029],
        [ 0.0042,  0.0025, -0.0079,  ...,  0.0034,  0.0032, -0.0729]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0769, -0.0026, -0.0007,  ...,  0.0012,  0.0008, -0.0023],
        [ 0.0046, -0.0851, -0.0049,  ...,  0.0023,  0.0028,  0.0175],
        [-0.0057, -0.0131, -0.0849,  ..., -0.0077, -0.0062, -0.0038],
        ...,
        [-0.0054, -0.0031,  0.0034,  ..., -0.0740,  0.0035,  0.0006],
        [-0.0028,  0.0011,  0.0003,  ...,  0.0056, -0.0885,  0.0165],
        [-0.0041,  0.0104, -0.0021,  ...,  0.0070,  0.0065, -0.0807]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:25:33 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 05:25:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5410,  0.1685,  0.2822,  ..., -0.6235, -0.2126, -0.6865],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8052, -0.0162, -0.5454,  ..., -0.5508,  0.0250,  0.2603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.7373,  1.0723,  0.1157,  ..., -0.3149,  0.5166, -0.3088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5000, -0.1205, -0.7715,  ..., -0.6250,  1.2734,  0.7812],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:25:33 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:25:33 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 05:26:27 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 05:27:24 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 05:28:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0110,  0.0017,  0.0039,  ..., -0.0030,  0.0005, -0.0086],
        [-0.0048, -0.0011, -0.0024,  ...,  0.0002, -0.0033, -0.0051],
        [-0.0041, -0.0011, -0.0061,  ..., -0.0023, -0.0002, -0.0050],
        ...,
        [ 0.0003,  0.0007,  0.0012,  ..., -0.0009, -0.0019,  0.0076],
        [ 0.0056, -0.0018,  0.0010,  ..., -0.0012, -0.0135, -0.0004],
        [-0.0012,  0.0092,  0.0024,  ..., -0.0067, -0.0029, -0.0163]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1146,  0.0088, -0.0188,  ..., -0.0059,  0.0059,  0.0045],
        [ 0.0012, -0.1125,  0.0024,  ...,  0.0040,  0.0094,  0.0089],
        [ 0.0004,  0.0034, -0.1046,  ..., -0.0043,  0.0003, -0.0008],
        ...,
        [-0.0023, -0.0029, -0.0101,  ..., -0.1270, -0.0013,  0.0078],
        [ 0.0095,  0.0138,  0.0022,  ...,  0.0111, -0.1095, -0.0036],
        [-0.0096, -0.0005, -0.0104,  ..., -0.0059,  0.0023, -0.1064]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1234,  0.0077, -0.0069,  ..., -0.0116,  0.0199, -0.0042],
        [-0.0058, -0.1427, -0.0064,  ...,  0.0091, -0.0109,  0.0064],
        [ 0.0181,  0.0014, -0.1532,  ...,  0.0036, -0.0059, -0.0200],
        ...,
        [-0.0032, -0.0004, -0.0077,  ..., -0.1509,  0.0006,  0.0045],
        [ 0.0036, -0.0025, -0.0025,  ..., -0.0010, -0.1478,  0.0099],
        [-0.0082,  0.0079, -0.0011,  ...,  0.0034,  0.0148, -0.1432]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:28:14 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-07-01 05:28:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4697,  0.2683,  0.3418,  ..., -0.2981, -0.2500, -0.3540],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5068,  0.0335, -0.2632,  ..., -0.7197,  0.5132,  0.2966],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.1133,  1.0498,  0.3997,  ..., -0.6763,  0.2397, -0.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2695, -0.4971, -0.8643,  ..., -0.5474,  0.9595,  0.9849],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:28:14 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:28:14 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 05:29:11 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 05:30:05 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 05:31:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0023, -0.0057, -0.0001,  ..., -0.0002, -0.0133, -0.0046],
        [-0.0047,  0.0021, -0.0046,  ..., -0.0016,  0.0053, -0.0060],
        [-0.0030, -0.0043,  0.0007,  ...,  0.0038, -0.0039,  0.0057],
        ...,
        [ 0.0049,  0.0062, -0.0135,  ...,  0.0020,  0.0031, -0.0054],
        [-0.0028, -0.0028,  0.0036,  ...,  0.0015,  0.0076,  0.0085],
        [-0.0046,  0.0045,  0.0065,  ..., -0.0031, -0.0026, -0.0023]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0970,  0.0114, -0.0113,  ..., -0.0141, -0.0043, -0.0005],
        [-0.0053, -0.0944, -0.0020,  ...,  0.0040,  0.0052,  0.0065],
        [ 0.0031, -0.0021, -0.0931,  ..., -0.0003,  0.0086, -0.0119],
        ...,
        [-0.0006, -0.0085, -0.0180,  ..., -0.0942,  0.0038,  0.0127],
        [-0.0116,  0.0018,  0.0006,  ..., -0.0007, -0.0825, -0.0003],
        [ 0.0025,  0.0063, -0.0018,  ...,  0.0055, -0.0029, -0.0862]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0997,  0.0082,  0.0014,  ..., -0.0082, -0.0010, -0.0072],
        [ 0.0021, -0.0956,  0.0032,  ...,  0.0015,  0.0052,  0.0025],
        [-0.0104, -0.0121, -0.1019,  ..., -0.0114,  0.0143, -0.0092],
        ...,
        [-0.0142, -0.0127, -0.0041,  ..., -0.1046,  0.0199, -0.0083],
        [-0.0088,  0.0116, -0.0050,  ...,  0.0079, -0.1083,  0.0013],
        [-0.0017,  0.0101, -0.0035,  ..., -0.0131, -0.0009, -0.1033]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:31:07 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-07-01 05:31:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9521,  0.5459,  0.0565,  ..., -0.1824,  0.2773, -0.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3062, -0.1076, -0.4482,  ..., -0.3860,  0.7739,  0.4480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.8496,  1.3369,  0.4922,  ..., -0.3735,  0.1011,  0.2759],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.5234,  0.0781, -2.5312,  ...,  0.7427,  0.8350,  2.0957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:31:07 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:31:07 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 05:32:08 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 05:33:09 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 05:34:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.8190e-03,  5.6505e-04,  1.6766e-03,  ..., -2.7847e-04,
         -2.4853e-03,  6.0749e-04],
        [ 5.7068e-03,  9.9030e-03,  5.6648e-03,  ..., -1.3666e-03,
          5.0049e-03, -6.5041e-03],
        [-3.8700e-03, -3.3646e-03,  6.0539e-03,  ..., -3.6411e-03,
          1.0281e-03, -2.4719e-03],
        ...,
        [-4.4060e-03, -4.0817e-03,  7.0572e-05,  ...,  5.7106e-03,
         -6.3362e-03,  7.7248e-04],
        [ 8.5068e-03, -3.7689e-03,  2.0466e-03,  ...,  3.9253e-03,
          7.5684e-03, -1.3351e-03],
        [ 6.4707e-04,  3.2959e-03,  4.6768e-03,  ...,  1.5869e-03,
          1.0824e-03,  1.3100e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0747, -0.0012, -0.0056,  ...,  0.0035,  0.0014, -0.0016],
        [-0.0022, -0.0826, -0.0053,  ...,  0.0026, -0.0041, -0.0031],
        [-0.0038, -0.0033, -0.0732,  ...,  0.0066, -0.0157, -0.0007],
        ...,
        [ 0.0012, -0.0024,  0.0079,  ..., -0.0820, -0.0045,  0.0134],
        [-0.0013, -0.0047, -0.0003,  ..., -0.0113, -0.0886,  0.0085],
        [ 0.0002,  0.0084,  0.0022,  ..., -0.0088,  0.0048, -0.0785]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1141,  0.0087, -0.0166,  ..., -0.0128, -0.0038,  0.0039],
        [-0.0030, -0.1279, -0.0087,  ..., -0.0128,  0.0008, -0.0042],
        [-0.0128,  0.0117, -0.1096,  ...,  0.0036, -0.0005,  0.0065],
        ...,
        [ 0.0242, -0.0025, -0.0061,  ..., -0.1104, -0.0061, -0.0167],
        [-0.0012, -0.0136, -0.0061,  ...,  0.0040, -0.1144,  0.0009],
        [ 0.0077,  0.0184, -0.0079,  ..., -0.0037,  0.0036, -0.1208]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:34:12 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-07-01 05:34:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1182,  0.5752,  0.1824,  ..., -0.3667,  0.1285, -0.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3027, -0.2917, -0.4956,  ..., -0.3164,  0.5581,  0.5513],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4873,  1.3701,  0.9824,  ..., -0.8950,  0.4307,  0.8003],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2891, -0.3721, -2.8262,  ...,  0.1631,  0.6240,  1.8613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:34:12 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:34:12 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 05:35:14 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 05:36:13 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 05:37:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0107, -0.0045,  0.0113,  ..., -0.0102, -0.0014, -0.0089],
        [-0.0031, -0.0097,  0.0066,  ...,  0.0013,  0.0018,  0.0015],
        [ 0.0003,  0.0020, -0.0209,  ...,  0.0002, -0.0026,  0.0030],
        ...,
        [ 0.0058, -0.0085,  0.0003,  ..., -0.0073, -0.0016, -0.0026],
        [-0.0028,  0.0024, -0.0069,  ..., -0.0106, -0.0154,  0.0049],
        [ 0.0009,  0.0076, -0.0005,  ..., -0.0075,  0.0031, -0.0325]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0624,  0.0033,  0.0061,  ..., -0.0077,  0.0047, -0.0061],
        [-0.0079, -0.0578, -0.0155,  ...,  0.0081,  0.0169,  0.0129],
        [-0.0027,  0.0127, -0.0471,  ...,  0.0017,  0.0058, -0.0100],
        ...,
        [-0.0132,  0.0015, -0.0116,  ..., -0.0530, -0.0120, -0.0008],
        [-0.0023,  0.0094, -0.0051,  ...,  0.0088, -0.0489,  0.0097],
        [-0.0019,  0.0077, -0.0003,  ...,  0.0021, -0.0049, -0.0657]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.2998e-02, -3.2654e-03,  1.5579e-02,  ..., -3.6011e-03,
         -1.8139e-03,  1.4275e-02],
        [-1.0996e-03, -7.0190e-02, -1.1612e-02,  ...,  1.1871e-02,
         -2.2049e-03, -1.2083e-03],
        [ 1.8326e-02,  1.9272e-02, -6.6223e-02,  ..., -9.8267e-03,
          1.7948e-03, -8.7738e-03],
        ...,
        [-1.6312e-02, -3.0937e-03, -3.0518e-05,  ..., -7.9163e-02,
         -8.5144e-03,  2.9945e-04],
        [ 1.2085e-02,  1.7197e-02, -8.6212e-03,  ...,  6.6910e-03,
         -6.2805e-02, -2.1915e-03],
        [-8.2321e-03, -8.9169e-04,  9.0332e-03,  ..., -1.7042e-03,
         -6.0463e-03, -6.8604e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:37:19 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-07-01 05:37:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.9292,  0.6709,  0.2349,  ..., -0.1907,  0.0592,  0.0967],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2402,  0.0338, -1.1836,  ...,  0.3459,  0.4189,  0.9849],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9644,  2.2324,  1.4688,  ..., -0.7046,  1.1504,  1.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.0449, -0.5557, -2.3770,  ..., -0.1101,  1.0645,  2.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:37:20 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:37:20 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 05:38:24 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 05:39:29 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 05:40:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0028, -0.0175,  0.0092,  ..., -0.0033, -0.0028, -0.0039],
        [ 0.0010,  0.0085, -0.0016,  ...,  0.0007,  0.0030, -0.0043],
        [-0.0023,  0.0060, -0.0061,  ...,  0.0029,  0.0054, -0.0074],
        ...,
        [-0.0038, -0.0037, -0.0016,  ...,  0.0004, -0.0023, -0.0015],
        [ 0.0085,  0.0109, -0.0006,  ..., -0.0069, -0.0048, -0.0099],
        [ 0.0004,  0.0061, -0.0042,  ..., -0.0053,  0.0043, -0.0062]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0537,  0.0057,  0.0043,  ..., -0.0027,  0.0060,  0.0054],
        [ 0.0050, -0.0737,  0.0008,  ..., -0.0056,  0.0073,  0.0116],
        [-0.0074,  0.0091, -0.0580,  ..., -0.0099,  0.0056, -0.0058],
        ...,
        [ 0.0152, -0.0126, -0.0091,  ..., -0.0542, -0.0089, -0.0083],
        [ 0.0067,  0.0022,  0.0064,  ..., -0.0053, -0.0547,  0.0029],
        [-0.0060, -0.0015, -0.0064,  ...,  0.0020, -0.0033, -0.0565]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0957, -0.0008,  0.0136,  ...,  0.0069,  0.0097,  0.0025],
        [ 0.0082, -0.1235, -0.0015,  ..., -0.0128, -0.0005, -0.0073],
        [ 0.0193, -0.0076, -0.1505,  ..., -0.0130,  0.0079, -0.0110],
        ...,
        [ 0.0195, -0.0020,  0.0104,  ..., -0.0976,  0.0087, -0.0020],
        [ 0.0194, -0.0040,  0.0105,  ...,  0.0056, -0.1324, -0.0077],
        [-0.0177, -0.0034, -0.0090,  ..., -0.0151,  0.0076, -0.1210]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:40:37 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-07-01 05:40:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6968,  0.6519,  0.4397,  ..., -0.4275,  0.2098,  0.3411],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1094, -0.1748, -1.3486,  ...,  0.0760,  0.3127,  0.8799],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0518,  2.1680,  1.2979,  ..., -0.9028,  1.1260,  1.4717],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.9707, -0.5283, -2.7734,  ..., -0.0076,  0.7417,  1.8613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:40:37 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:40:37 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 05:41:44 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 05:42:52 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 05:44:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0009, -0.0062, -0.0060,  ..., -0.0092, -0.0053, -0.0071],
        [ 0.0034,  0.0049, -0.0004,  ...,  0.0097,  0.0024, -0.0032],
        [ 0.0004, -0.0075, -0.0026,  ..., -0.0044, -0.0042, -0.0040],
        ...,
        [ 0.0060,  0.0006,  0.0023,  ...,  0.0030,  0.0066, -0.0026],
        [-0.0010, -0.0036,  0.0053,  ..., -0.0066, -0.0028,  0.0023],
        [-0.0054, -0.0016,  0.0006,  ..., -0.0012, -0.0078, -0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0521,  0.0070,  0.0061,  ...,  0.0041,  0.0019,  0.0031],
        [ 0.0013, -0.0607, -0.0014,  ..., -0.0098,  0.0176,  0.0159],
        [ 0.0007,  0.0019, -0.0508,  ...,  0.0007, -0.0133,  0.0056],
        ...,
        [-0.0103,  0.0091,  0.0064,  ..., -0.0524,  0.0060,  0.0234],
        [-0.0252, -0.0224, -0.0101,  ...,  0.0082, -0.0505,  0.0041],
        [-0.0093, -0.0061, -0.0076,  ...,  0.0012,  0.0172, -0.0542]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0949,  0.0281, -0.0013,  ...,  0.0107, -0.0139, -0.0015],
        [-0.0014, -0.1215,  0.0047,  ..., -0.0143,  0.0101,  0.0162],
        [-0.0016, -0.0026, -0.1017,  ..., -0.0069,  0.0161, -0.0112],
        ...,
        [-0.0016, -0.0026,  0.0023,  ..., -0.1135, -0.0009,  0.0171],
        [-0.0049, -0.0050, -0.0048,  ..., -0.0222, -0.0899,  0.0048],
        [-0.0084, -0.0005, -0.0229,  ..., -0.0068, -0.0014, -0.1153]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:44:03 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-07-01 05:44:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4380,  0.9980,  0.6167,  ..., -0.3196,  0.5396,  0.6094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.4766, -0.2703, -1.1133,  ..., -0.0558,  0.5283,  0.9336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.9629,  2.1680,  0.4961,  ..., -0.6230,  1.8799,  0.8921],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.2852, -0.9790, -3.7383,  ...,  0.0334,  0.8643,  0.9800],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:44:03 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:44:03 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 05:45:12 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 05:46:22 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 05:47:33 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0052,  0.0052,  0.0035,  ...,  0.0010, -0.0068,  0.0006],
        [-0.0009,  0.0041, -0.0010,  ...,  0.0012,  0.0015,  0.0006],
        [ 0.0039,  0.0025, -0.0039,  ...,  0.0009,  0.0032,  0.0062],
        ...,
        [-0.0060, -0.0072, -0.0029,  ..., -0.0025,  0.0003, -0.0003],
        [-0.0010, -0.0019,  0.0019,  ...,  0.0006, -0.0015, -0.0001],
        [ 0.0034,  0.0101,  0.0032,  ..., -0.0018, -0.0025,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0265, -0.0027,  0.0051,  ..., -0.0136,  0.0058, -0.0119],
        [ 0.0081, -0.0216, -0.0015,  ..., -0.0018,  0.0059,  0.0031],
        [ 0.0054,  0.0156, -0.0339,  ...,  0.0145,  0.0100, -0.0066],
        ...,
        [-0.0067, -0.0086, -0.0100,  ..., -0.0146,  0.0028,  0.0102],
        [ 0.0134,  0.0071, -0.0131,  ...,  0.0039, -0.0390,  0.0116],
        [-0.0098, -0.0116, -0.0063,  ...,  0.0030,  0.0068, -0.0284]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0451, -0.0025,  0.0107,  ..., -0.0297,  0.0152,  0.0103],
        [ 0.0133, -0.0329,  0.0132,  ..., -0.0098,  0.0100, -0.0049],
        [ 0.0098,  0.0100, -0.0625,  ..., -0.0149,  0.0161,  0.0014],
        ...,
        [ 0.0060,  0.0101, -0.0134,  ..., -0.0593, -0.0031,  0.0002],
        [ 0.0196,  0.0003, -0.0044,  ...,  0.0131, -0.0559,  0.0211],
        [-0.0090,  0.0039, -0.0027,  ..., -0.0059,  0.0202, -0.0618]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:47:35 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-07-01 05:47:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4509,  0.9077,  0.5044,  ..., -0.3757,  0.4617,  0.5957],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2734e+00, -2.3413e-01, -1.1348e+00,  ..., -2.0552e-04,
         3.0298e-01,  7.6123e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.5488,  2.5918,  0.4797,  ..., -0.3447,  1.6973,  0.4070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.9961, -1.1748, -4.3398,  ...,  0.3840,  1.3301,  1.4336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:47:35 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:47:35 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 05:48:47 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 05:50:00 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 05:51:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0269, -0.0019, -0.0023,  ...,  0.0059, -0.0010,  0.0001],
        [-0.0059,  0.0216,  0.0015,  ..., -0.0061,  0.0003,  0.0026],
        [-0.0022,  0.0047,  0.0221,  ...,  0.0028, -0.0021,  0.0007],
        ...,
        [ 0.0064,  0.0022, -0.0030,  ...,  0.0242, -0.0017,  0.0005],
        [-0.0017, -0.0035, -0.0013,  ..., -0.0002,  0.0214,  0.0004],
        [-0.0013,  0.0034,  0.0017,  ...,  0.0001,  0.0059,  0.0195]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0155,  0.0154, -0.0088,  ..., -0.0119, -0.0196,  0.0028],
        [ 0.0158, -0.0099,  0.0085,  ...,  0.0051, -0.0084,  0.0016],
        [ 0.0016, -0.0075, -0.0300,  ...,  0.0137, -0.0067, -0.0012],
        ...,
        [ 0.0019,  0.0085,  0.0074,  ..., -0.0180, -0.0181, -0.0048],
        [-0.0063,  0.0056,  0.0045,  ..., -0.0155, -0.0133, -0.0031],
        [-0.0018,  0.0031, -0.0092,  ...,  0.0015,  0.0015, -0.0315]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.7710e-02,  9.0637e-03,  7.8964e-03,  ..., -1.1284e-02,
         -9.3460e-04,  1.1749e-02],
        [-4.6082e-03, -2.8961e-02,  3.7708e-03,  ...,  5.7297e-03,
         -9.7504e-03,  1.6891e-02],
        [ 1.5961e-02,  5.7220e-06, -3.8361e-02,  ..., -2.2430e-03,
          1.1971e-02,  1.1978e-02],
        ...,
        [-6.7711e-05, -1.8265e-02, -2.5803e-02,  ..., -3.2776e-02,
          3.0365e-03,  3.1452e-03],
        [ 6.0654e-03,  1.2417e-03,  3.9520e-03,  ..., -5.9738e-03,
         -4.1565e-02, -4.4975e-03],
        [-1.0597e-02,  1.1520e-02,  2.8095e-03,  ...,  1.1063e-02,
          7.3624e-03, -3.1082e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:51:16 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-07-01 05:51:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7764,  0.8462,  0.1821,  ..., -0.2578,  0.7437,  0.3267],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.3223, -0.4028, -1.4883,  ...,  0.0015,  0.3528,  0.3694],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.0332,  2.8242,  0.1655,  ..., -0.2720,  1.8770,  0.0940],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.1680, -0.6587, -4.6523,  ...,  0.4363,  0.8208,  2.1094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:51:16 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:51:16 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 05:52:32 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 05:53:49 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 05:55:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 5.9166e-03, -4.7646e-03, -3.0003e-03,  ...,  2.6760e-03,
         -4.3983e-03,  4.5133e-04],
        [-1.0967e-03, -2.6150e-03, -2.8801e-03,  ...,  2.8858e-03,
          2.2793e-03,  1.9569e-03],
        [ 1.8044e-03,  2.1019e-03,  3.4161e-03,  ...,  7.5150e-04,
         -2.1172e-03, -3.6545e-03],
        ...,
        [-3.6764e-04,  3.7785e-03, -5.5618e-03,  ...,  9.2506e-04,
         -1.0319e-03,  3.6025e-04],
        [-3.2997e-03,  1.7309e-03,  6.4015e-05,  ...,  2.3041e-03,
         -3.7060e-03, -3.8452e-03],
        [-8.1787e-03, -2.7447e-03,  4.4518e-03,  ..., -7.3586e-03,
          4.7073e-03,  4.9782e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0116, -0.0026, -0.0022,  ..., -0.0189,  0.0030,  0.0032],
        [ 0.0025, -0.0213, -0.0126,  ...,  0.0012,  0.0077,  0.0044],
        [ 0.0081, -0.0080, -0.0102,  ..., -0.0139,  0.0105, -0.0024],
        ...,
        [ 0.0062,  0.0141, -0.0158,  ..., -0.0192, -0.0117, -0.0003],
        [ 0.0091,  0.0153, -0.0007,  ..., -0.0040, -0.0090,  0.0034],
        [-0.0137, -0.0022,  0.0053,  ...,  0.0014, -0.0047, -0.0218]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0458,  0.0082, -0.0147,  ..., -0.0020, -0.0120, -0.0010],
        [ 0.0041, -0.0648, -0.0079,  ..., -0.0059, -0.0017,  0.0133],
        [ 0.0248, -0.0149, -0.0293,  ..., -0.0111,  0.0014, -0.0162],
        ...,
        [ 0.0220,  0.0107, -0.0091,  ..., -0.0585, -0.0003, -0.0017],
        [-0.0054,  0.0002, -0.0104,  ..., -0.0077, -0.0184, -0.0102],
        [-0.0130,  0.0219, -0.0030,  ...,  0.0019, -0.0004, -0.0387]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:55:10 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-07-01 05:55:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0029,  0.9751,  0.1683,  ..., -0.1262,  0.6699,  0.1283],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.5986, -0.4517, -1.6748,  ...,  0.1539,  0.5366,  0.5464],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.4062,  2.8457,  1.8613,  ..., -0.1360,  2.0449,  0.4390],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.0977, -1.0713, -3.8086,  ...,  0.1365,  0.2319,  2.9102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:55:10 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:55:10 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 05:56:32 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 05:57:52 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 05:59:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.9608e-03, -2.6321e-04,  9.6941e-04,  ...,  2.6202e-04,
         -1.2083e-03, -8.5413e-05],
        [ 5.1928e-04, -1.8396e-03, -2.0742e-04,  ...,  9.1648e-04,
         -1.2989e-03,  1.8787e-04],
        [-1.9431e-04, -1.7190e-04, -2.9354e-03,  ..., -6.8140e-04,
         -3.1090e-04,  4.4608e-04],
        ...,
        [ 2.0838e-04,  7.1192e-04,  2.6250e-04,  ..., -2.6035e-03,
         -9.0182e-05,  3.6383e-04],
        [ 2.1398e-05, -6.8128e-05,  7.8201e-04,  ..., -5.9032e-04,
         -3.1452e-03, -1.8835e-05],
        [ 7.8869e-04,  3.8242e-04, -5.3453e-04,  ...,  6.4659e-04,
         -8.6927e-04, -3.1929e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0170, -0.0182,  0.0081,  ..., -0.0044, -0.0100,  0.0098],
        [-0.0061, -0.0158, -0.0048,  ...,  0.0038,  0.0088, -0.0104],
        [-0.0053, -0.0104, -0.0157,  ...,  0.0075, -0.0122,  0.0080],
        ...,
        [ 0.0016,  0.0055,  0.0101,  ..., -0.0144, -0.0055,  0.0117],
        [ 0.0116,  0.0069, -0.0083,  ..., -0.0029, -0.0089, -0.0015],
        [ 0.0073, -0.0026,  0.0064,  ...,  0.0183,  0.0039, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0323,  0.0077,  0.0124,  ..., -0.0242,  0.0172, -0.0040],
        [ 0.0009, -0.0285,  0.0122,  ..., -0.0017,  0.0131,  0.0059],
        [ 0.0049, -0.0052, -0.0582,  ...,  0.0068, -0.0109, -0.0014],
        ...,
        [ 0.0118,  0.0164,  0.0078,  ..., -0.0394, -0.0248,  0.0079],
        [ 0.0043,  0.0219, -0.0169,  ..., -0.0148, -0.0491, -0.0095],
        [-0.0051, -0.0073,  0.0166,  ..., -0.0182,  0.0096, -0.0459]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 05:59:16 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-07-01 05:59:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.1572,  1.0244,  0.0349,  ..., -0.0945,  0.7173,  0.0038],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.6064, -0.2404, -1.7266,  ...,  0.1667,  0.3298,  0.7744],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([3.7188, 3.3262, 2.3496,  ..., 0.1184, 2.4805, 0.4702], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.5938, -1.0088, -3.3320,  ...,  0.9775,  0.3413,  2.6758],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 05:59:16 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 05:59:16 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 06:00:39 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 06:02:01 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 06:03:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0031,  0.0020,  0.0006,  ..., -0.0002, -0.0025, -0.0002],
        [-0.0008,  0.0054,  0.0026,  ...,  0.0023, -0.0006,  0.0017],
        [-0.0005,  0.0035,  0.0081,  ...,  0.0015, -0.0001,  0.0001],
        ...,
        [ 0.0001,  0.0002,  0.0022,  ...,  0.0046, -0.0023, -0.0029],
        [-0.0009, -0.0003, -0.0006,  ...,  0.0002, -0.0007,  0.0012],
        [-0.0013,  0.0004,  0.0025,  ..., -0.0010,  0.0008,  0.0018]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0134,  0.0063,  0.0021,  ..., -0.0178, -0.0099, -0.0240],
        [ 0.0193, -0.0012,  0.0141,  ...,  0.0073,  0.0164, -0.0056],
        [ 0.0100,  0.0210,  0.0081,  ..., -0.0038,  0.0215, -0.0014],
        ...,
        [ 0.0105, -0.0015,  0.0031,  ...,  0.0046,  0.0014, -0.0304],
        [ 0.0006, -0.0075, -0.0123,  ...,  0.0007, -0.0092, -0.0027],
        [ 0.0141,  0.0058, -0.0011,  ..., -0.0129,  0.0114, -0.0116]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.7913e-02,  7.4539e-03, -4.0741e-03,  ...,  6.5279e-04,
          1.1185e-02,  9.2316e-03],
        [-9.5797e-04, -4.9103e-02,  7.2174e-03,  ..., -8.6975e-03,
         -9.7046e-03,  1.8272e-03],
        [-2.6894e-03, -1.2962e-02, -4.6326e-02,  ...,  6.8130e-03,
         -1.6785e-03, -4.0970e-03],
        ...,
        [ 1.7532e-02,  4.9171e-03, -1.2939e-02,  ..., -4.1229e-02,
         -9.3460e-05, -7.3624e-03],
        [ 2.9621e-03,  2.5387e-03,  4.1809e-03,  ...,  1.1200e-02,
         -6.4026e-02, -1.0551e-02],
        [ 2.8778e-02,  1.0788e-02,  2.0370e-02,  ..., -1.4435e-02,
          1.7776e-02, -4.9316e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:03:25 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-07-01 06:03:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.2148,  0.9858,  0.5981,  ..., -0.0562,  0.7329,  0.1262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.4863, -0.3408, -1.3916,  ...,  0.0400,  0.0951,  1.0293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([3.2422, 3.0938, 2.6992,  ..., 0.2322, 2.8535, 0.2688], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.6582, -0.9795, -4.0000,  ...,  1.8975, -0.2954,  4.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:03:25 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 06:03:25 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 06:04:47 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 06:06:13 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 06:07:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0704e-02, -3.5286e-05, -1.1635e-03,  ...,  9.1648e-04,
          1.6994e-03,  1.9665e-03],
        [ 4.7588e-04,  6.5804e-03, -4.6778e-04,  ...,  6.5517e-04,
         -6.0272e-04, -2.6016e-03],
        [-1.0920e-03,  1.1349e-03,  1.2718e-02,  ..., -2.3003e-03,
          1.5581e-04, -1.5221e-03],
        ...,
        [-6.6757e-05,  1.8978e-03, -6.1989e-05,  ...,  1.4381e-02,
          6.9380e-04, -2.0294e-03],
        [ 4.4107e-05,  1.6527e-03, -9.1553e-04,  ...,  1.9760e-03,
          1.4008e-02, -1.5726e-03],
        [ 2.0695e-03, -2.0943e-03, -1.4801e-03,  ...,  5.7554e-04,
         -6.7949e-04,  1.4183e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0506, -0.0205, -0.0001,  ...,  0.0066,  0.0108,  0.0117],
        [ 0.0019,  0.0137,  0.0043,  ...,  0.0042, -0.0108,  0.0054],
        [-0.0032,  0.0131,  0.0558,  ..., -0.0141,  0.0044,  0.0015],
        ...,
        [-0.0040,  0.0005, -0.0164,  ...,  0.0707, -0.0005, -0.0008],
        [ 0.0049, -0.0046, -0.0152,  ...,  0.0182,  0.0507, -0.0110],
        [-0.0177, -0.0013, -0.0098,  ..., -0.0033, -0.0040,  0.0731]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0142, -0.0029,  0.0069,  ...,  0.0163,  0.0212,  0.0164],
        [ 0.0008, -0.0128,  0.0102,  ..., -0.0309, -0.0201,  0.0285],
        [ 0.0217,  0.0133,  0.0074,  ..., -0.0047,  0.0044,  0.0066],
        ...,
        [-0.0102, -0.0084, -0.0194,  ...,  0.0259,  0.0012, -0.0011],
        [ 0.0042, -0.0143,  0.0098,  ...,  0.0071,  0.0100, -0.0027],
        [-0.0162,  0.0229,  0.0017,  ...,  0.0255, -0.0056,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:07:37 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 06:07:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([1.2539e+00, 1.0684e+00, 7.1631e-01,  ..., 6.8855e-04, 8.0811e-01,
        1.1682e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.5967, -0.3042, -1.1904,  ...,  0.2917,  0.1135,  0.8906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([3.1406, 3.3359, 2.1973,  ..., 0.4648, 2.1465, 1.5566], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.9277, -0.5054, -3.9570,  ...,  2.0254, -0.6289,  5.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:07:37 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 06:07:37 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 06:09:02 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 06:10:28 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 06:11:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 3.8795e-03, -2.5558e-04, -2.0695e-04,  ...,  8.5306e-04,
          6.8307e-05,  1.9610e-04],
        [-7.9918e-04,  1.8930e-03,  7.0095e-04,  ..., -1.6384e-03,
          2.5451e-05, -1.6212e-04],
        [-7.2050e-04,  3.5167e-04,  3.3894e-03,  ..., -2.0862e-06,
         -1.0328e-03, -3.6788e-04],
        ...,
        [ 4.9496e-04, -3.7146e-04, -6.2943e-04,  ...,  4.9706e-03,
         -8.2791e-05, -7.4208e-05],
        [ 5.3835e-04,  1.4143e-03, -9.7656e-04,  ...,  1.7376e-03,
          2.5787e-03, -4.5943e-04],
        [ 6.8760e-04,  3.3736e-04,  1.3161e-04,  ...,  7.6866e-04,
         -4.1699e-04,  3.3817e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0054, -0.0088,  0.0115,  ..., -0.0084,  0.0106,  0.0093],
        [-0.0057,  0.0020,  0.0066,  ...,  0.0192, -0.0037, -0.0005],
        [ 0.0040,  0.0185, -0.0017,  ..., -0.0023, -0.0032,  0.0003],
        ...,
        [ 0.0032,  0.0177,  0.0034,  ...,  0.0152, -0.0047, -0.0078],
        [-0.0030,  0.0055, -0.0006,  ..., -0.0096,  0.0038,  0.0009],
        [ 0.0067,  0.0056, -0.0080,  ...,  0.0135, -0.0026,  0.0056]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0337, -0.0111,  0.0100,  ...,  0.0033,  0.0138, -0.0023],
        [ 0.0002, -0.0345,  0.0157,  ..., -0.0002,  0.0027, -0.0120],
        [ 0.0094,  0.0120, -0.0258,  ...,  0.0009, -0.0192, -0.0191],
        ...,
        [ 0.0045,  0.0112, -0.0038,  ..., -0.0509,  0.0044, -0.0026],
        [ 0.0255,  0.0034, -0.0169,  ...,  0.0107, -0.0306, -0.0073],
        [ 0.0131,  0.0265, -0.0085,  ...,  0.0123, -0.0110, -0.0372]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:11:57 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 06:11:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 1.0537,  0.9370,  0.7217,  ..., -0.0292,  0.8315,  0.0245],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2402, -0.2739, -1.3457,  ...,  0.4990, -0.1199,  1.2627],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.7266,  3.4492,  0.6182,  ..., -0.2480,  1.4160,  0.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.6406,  0.2993, -4.7266,  ...,  1.5234, -1.1465,  4.6797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:11:57 root INFO     [order_1_approx] starting weight calculation for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 06:11:57 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 06:13:22 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 06:14:41 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 06:15:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 7.7820e-03, -7.2050e-04, -4.0770e-05,  ..., -5.0592e-04,
          2.6464e-04, -7.0858e-04],
        [ 2.9874e-04,  4.5662e-03, -4.3917e-04,  ...,  4.4394e-04,
         -4.9067e-04,  5.9366e-04],
        [ 7.7486e-04, -1.1845e-03,  7.0190e-03,  ..., -2.0432e-04,
         -1.4143e-03, -9.0659e-05],
        ...,
        [-6.2752e-04, -1.9550e-05, -1.6379e-04,  ...,  8.2016e-03,
         -8.6164e-04, -1.2712e-03],
        [ 4.9591e-04, -1.4508e-04,  2.0671e-04,  ..., -3.0231e-04,
          9.3689e-03, -7.4720e-04],
        [-3.5942e-05,  4.3249e-04, -7.9584e-04,  ..., -5.1975e-04,
         -2.0278e-04,  1.0727e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 1.2650e-02,  6.6948e-03, -2.1839e-03,  ..., -1.3908e-02,
         -2.4338e-03,  2.4796e-05],
        [ 7.1430e-04,  2.2316e-03, -4.8714e-03,  ..., -3.4409e-03,
          8.3160e-03, -6.9351e-03],
        [-2.0218e-02, -2.2297e-03,  1.5160e-02,  ...,  2.9278e-03,
         -3.1338e-03, -3.1853e-03],
        ...,
        [ 1.2932e-03,  8.4457e-03, -6.1836e-03,  ...,  1.3443e-02,
         -1.4839e-02,  2.0691e-02],
        [-2.1114e-03, -2.6688e-02, -2.3605e-02,  ..., -1.2268e-02,
          1.6571e-02,  1.6663e-02],
        [-3.8948e-03,  3.0975e-02,  6.0883e-03,  ..., -1.8063e-03,
          1.4771e-02,  2.9236e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0210,  0.0038,  0.0356,  ..., -0.0079,  0.0060, -0.0103],
        [ 0.0161, -0.0403, -0.0023,  ..., -0.0084, -0.0047, -0.0035],
        [-0.0072,  0.0170, -0.0122,  ..., -0.0016, -0.0074, -0.0034],
        ...,
        [-0.0053,  0.0041, -0.0174,  ..., -0.0341,  0.0107,  0.0030],
        [-0.0004, -0.0080, -0.0069,  ..., -0.0200, -0.0271,  0.0213],
        [-0.0064,  0.0210,  0.0146,  ..., -0.0031,  0.0060, -0.0197]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:16:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To aspire results in aspiration
To characterize results in characterization
To minimize results in minimization
To restore results in restoration
To randomize results in randomization
To standardize results in standardization
To illumine results in illumination
To optimize results in
2024-07-01 06:16:02 root INFO     total operator prediction time: 35262.29777741432 seconds
2024-07-01 06:16:02 __main__ INFO     starting test: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-07-01 06:16:04 root INFO     building operator verb+er_irreg
2024-07-01 06:16:04 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 06:16:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0941,  0.3115, -0.1101,  ...,  0.0576,  0.7510, -0.0802],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1586,  0.1322, -0.1539,  ..., -0.4031, -0.0015,  0.0533],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0704, -0.3569, -0.2656,  ..., -0.3521, -0.3247,  0.2419],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0474,  0.2761,  0.1141,  ..., -0.7861, -0.2644, -0.1309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:16:04 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:16:04 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 06:16:25 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 06:16:48 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 06:17:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.8569e-04, -3.7766e-04,  2.3842e-05,  ...,  9.2387e-05,
          4.5133e-04,  2.0492e-04],
        [-4.1008e-04, -6.4325e-04, -3.4142e-04,  ..., -2.1517e-05,
          1.3494e-04,  3.3975e-05],
        [ 7.1335e-04,  1.9383e-04, -8.6641e-04,  ..., -9.9957e-05,
         -2.9206e-06,  3.1054e-05],
        ...,
        [-2.4319e-04, -9.0742e-04,  4.9973e-04,  ..., -6.2513e-04,
          1.5187e-04, -2.2173e-04],
        [ 9.1791e-05,  4.1366e-05, -1.3375e-04,  ...,  1.3614e-04,
         -1.2760e-03, -3.2830e-04],
        [-8.4460e-05,  3.6979e-04, -5.0604e-05,  ...,  7.6234e-05,
         -4.5681e-04, -8.4877e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.9022e-02,  4.5700e-03,  2.7809e-03,  ..., -4.2610e-03,
         -1.0880e-02,  2.9259e-03],
        [ 6.2332e-03, -2.3926e-02,  9.1171e-03,  ..., -3.2568e-04,
          2.7275e-03,  2.1839e-03],
        [-3.7422e-03,  6.3972e-03, -3.6743e-02,  ...,  7.2241e-04,
         -6.3667e-03, -4.6806e-03],
        ...,
        [-3.3989e-03,  8.2970e-05, -7.1068e-03,  ..., -4.1962e-02,
          2.3956e-03, -3.0861e-03],
        [-3.4351e-03,  6.3782e-03,  4.8523e-03,  ..., -5.3139e-03,
         -3.9490e-02, -4.6463e-03],
        [-5.6648e-03, -4.4594e-03,  2.8000e-03,  ..., -6.0959e-03,
          3.6621e-03, -4.1534e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0385, -0.0003,  0.0012,  ..., -0.0020, -0.0012,  0.0012],
        [ 0.0013, -0.0403,  0.0010,  ...,  0.0035,  0.0078,  0.0023],
        [-0.0046,  0.0022, -0.0367,  ..., -0.0032,  0.0021,  0.0029],
        ...,
        [ 0.0031,  0.0047,  0.0002,  ..., -0.0400,  0.0028,  0.0038],
        [-0.0043,  0.0032,  0.0019,  ..., -0.0005, -0.0373,  0.0071],
        [-0.0012, -0.0012, -0.0013,  ...,  0.0020,  0.0057, -0.0360]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:17:13 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 06:17:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1661,  0.1004, -0.3748,  ..., -0.3103,  0.2455,  0.3857],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1299,  0.2280,  0.0123,  ..., -0.6865, -0.1687, -0.0872],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1808, -0.2598, -0.1663,  ..., -0.9058, -0.1896,  0.2061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0084,  0.4050,  0.2844,  ..., -1.2529, -0.3381,  0.0209],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:17:13 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:17:13 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 06:17:38 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 06:18:02 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 06:18:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.2992e-03,  1.6165e-03,  8.5545e-04,  ..., -5.5981e-04,
          2.3913e-04, -2.9993e-04],
        [ 9.1124e-04, -5.9586e-03,  8.2016e-04,  ...,  3.5954e-04,
         -7.7629e-04, -9.4509e-04],
        [-7.4625e-05,  6.4313e-05, -4.0627e-03,  ..., -9.5463e-04,
          1.2331e-03, -7.6175e-05],
        ...,
        [ 5.5373e-05,  1.1122e-04, -9.6083e-04,  ..., -5.5618e-03,
         -9.4032e-04, -1.4706e-03],
        [ 8.2672e-05, -8.7881e-04,  1.2236e-03,  ..., -1.0643e-03,
         -3.8700e-03, -2.4259e-04],
        [-2.0182e-04,  6.5517e-04,  9.0647e-04,  ..., -1.0729e-04,
         -7.9823e-04, -3.4828e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0668,  0.0050, -0.0056,  ...,  0.0041,  0.0073,  0.0046],
        [-0.0037, -0.0746, -0.0041,  ...,  0.0073, -0.0040,  0.0075],
        [-0.0059, -0.0076, -0.0580,  ..., -0.0035, -0.0110, -0.0023],
        ...,
        [ 0.0102,  0.0064, -0.0014,  ..., -0.0661, -0.0058,  0.0030],
        [-0.0030, -0.0080,  0.0135,  ..., -0.0077, -0.0547,  0.0020],
        [ 0.0003, -0.0025,  0.0023,  ...,  0.0028,  0.0050, -0.0667]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.2500e-02,  1.0094e-02, -3.0003e-03,  ...,  6.1951e-03,
          1.9569e-03,  1.1292e-03],
        [-1.3852e-04, -5.9814e-02, -5.4359e-05,  ...,  3.9434e-04,
         -5.0011e-03,  5.0125e-03],
        [-3.2005e-03,  2.3518e-03, -4.7882e-02,  ...,  3.6564e-03,
          2.3441e-03,  5.6171e-04],
        ...,
        [-2.7981e-03,  6.7558e-03, -2.5749e-03,  ..., -5.4413e-02,
         -5.4779e-03,  4.6043e-03],
        [ 3.1643e-03, -3.2997e-03,  3.6736e-03,  ...,  1.7471e-03,
         -5.1788e-02, -1.0214e-03],
        [ 8.7500e-04, -2.4834e-03, -1.5354e-03,  ..., -3.3646e-03,
          6.9733e-03, -5.9875e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:18:28 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 06:18:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1123, -0.4844, -0.3384,  ..., -0.4243, -0.4058,  0.2864],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0910,  0.4316,  0.1802,  ..., -1.1846, -0.4094, -0.2345],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0685, -0.3113, -0.3833,  ..., -0.5298, -0.4316,  0.0631],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1584,  0.3438,  0.3149,  ..., -0.8682, -0.5386,  0.2603],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:18:28 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:18:28 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 06:18:54 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 06:19:19 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 06:19:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.3398e-03,  6.2561e-04, -1.6184e-03,  ...,  5.0879e-04,
         -5.7745e-04, -8.2159e-04],
        [-5.5695e-04, -4.4174e-03, -4.0913e-04,  ...,  9.5010e-05,
          7.2479e-05,  1.0443e-03],
        [-2.2526e-03, -9.0075e-04, -4.8294e-03,  ..., -2.7037e-04,
          3.7861e-04,  5.2273e-05],
        ...,
        [-5.9462e-04,  1.2369e-03,  3.7098e-04,  ..., -3.7136e-03,
          7.1096e-04,  4.5919e-04],
        [ 2.4796e-04, -2.0921e-05,  1.9217e-04,  ...,  7.9441e-04,
         -4.7646e-03, -1.6203e-03],
        [-3.1400e-04, -1.0500e-03, -1.1597e-03,  ..., -8.0943e-05,
          1.4200e-03, -5.8098e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.2928e-02, -6.7902e-03,  3.7441e-03,  ..., -9.8801e-04,
         -9.9564e-04, -3.9520e-03],
        [-6.1455e-03, -2.9205e-02, -1.7910e-03,  ...,  8.1482e-03,
          1.7643e-05,  7.8440e-04],
        [ 2.9335e-03, -1.9836e-04, -3.4027e-02,  ..., -2.8381e-03,
          9.8133e-04, -4.4479e-03],
        ...,
        [ 3.1796e-03, -5.5351e-03,  2.0218e-03,  ..., -3.9185e-02,
          6.3324e-03, -3.3188e-03],
        [-5.9853e-03,  1.1276e-02, -5.7220e-03,  ...,  6.8512e-03,
         -3.6377e-02,  4.2458e-03],
        [-9.5291e-03,  1.3342e-03, -1.8587e-03,  ..., -1.1124e-02,
         -4.4441e-03, -4.2572e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0335, -0.0016,  0.0035,  ..., -0.0018, -0.0032, -0.0067],
        [-0.0003, -0.0340,  0.0060,  ...,  0.0051, -0.0001,  0.0072],
        [ 0.0033, -0.0020, -0.0284,  ...,  0.0043, -0.0038,  0.0022],
        ...,
        [-0.0027,  0.0035, -0.0021,  ..., -0.0244,  0.0034,  0.0020],
        [-0.0040, -0.0028, -0.0004,  ..., -0.0080, -0.0347, -0.0073],
        [-0.0073, -0.0048, -0.0052,  ..., -0.0048,  0.0074, -0.0330]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:19:47 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 06:19:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2556, -0.3577, -0.2039,  ..., -1.0811, -0.2527,  0.2247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-6.4392e-03,  5.8057e-01,  4.1113e-01,  ..., -1.7344e+00,
        -4.9438e-01, -6.9284e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3369, -0.4189,  0.0342,  ..., -0.5391,  0.2871,  0.0080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2747,  0.5933,  0.3740,  ..., -1.2764, -0.0544,  0.3760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:19:47 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:19:47 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 06:20:16 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 06:20:46 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 06:21:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7776e-03,  6.4898e-04,  1.2851e-04,  ..., -5.3692e-04,
          9.0981e-04, -1.2565e-04],
        [ 3.6812e-04, -2.1152e-03, -2.2864e-04,  ..., -3.7134e-05,
          6.9523e-04,  7.2670e-04],
        [ 5.2166e-04,  3.6526e-04, -2.6054e-03,  ...,  2.2459e-04,
          4.0650e-04,  4.8971e-04],
        ...,
        [ 7.9346e-04,  2.5988e-05, -5.0640e-04,  ..., -1.9665e-03,
          1.3697e-04, -1.8418e-04],
        [-3.2854e-04, -7.1859e-04,  1.7643e-04,  ..., -1.8654e-03,
         -1.8129e-03, -3.4475e-04],
        [-2.7609e-04, -5.5432e-05,  3.0589e-04,  ...,  1.3697e-04,
         -9.8896e-04, -2.2163e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0432, -0.0008,  0.0036,  ..., -0.0016,  0.0047,  0.0013],
        [-0.0050, -0.0374,  0.0008,  ..., -0.0016, -0.0037, -0.0041],
        [ 0.0009, -0.0065, -0.0513,  ...,  0.0053, -0.0018,  0.0031],
        ...,
        [-0.0014, -0.0006,  0.0067,  ..., -0.0445,  0.0132, -0.0011],
        [-0.0019,  0.0021, -0.0018,  ..., -0.0099, -0.0376,  0.0091],
        [ 0.0141, -0.0030,  0.0055,  ...,  0.0097,  0.0008, -0.0535]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.8950e-02, -3.3588e-03,  9.0256e-03,  ...,  2.9526e-03,
         -1.7986e-03, -1.1215e-03],
        [ 3.0918e-03, -4.0344e-02, -3.7746e-03,  ..., -9.8038e-04,
          5.7602e-04,  3.8958e-04],
        [-7.0419e-03, -9.1629e-03, -4.3610e-02,  ...,  1.8444e-03,
         -9.5215e-03,  2.6627e-03],
        ...,
        [-4.3602e-03, -8.3542e-04, -2.7466e-04,  ..., -4.7913e-02,
          7.0229e-03, -1.3374e-02],
        [-4.7646e-03, -4.6577e-03, -2.9640e-03,  ..., -8.0414e-03,
         -3.6377e-02, -5.2872e-03],
        [-1.4362e-03,  3.1586e-03,  2.8610e-05,  ..., -5.2414e-03,
         -3.6831e-03, -4.5380e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:21:19 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 06:21:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0525, -0.3757, -0.3689,  ..., -0.5122, -0.4070,  0.0232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1823,  0.3491,  0.3403,  ..., -0.9014, -0.5591,  0.2598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0317,  0.2856,  0.1113,  ..., -0.9097,  0.7266, -0.2104],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1147,  0.6279,  0.7461,  ..., -1.0273, -0.4050,  0.2449],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:21:19 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:21:19 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 06:21:52 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 06:22:25 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 06:22:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8439e-03,  2.2278e-03, -2.8687e-03,  ..., -2.0409e-04,
         -3.7503e-04,  8.8930e-05],
        [-5.7650e-04, -8.6975e-04, -1.9159e-03,  ..., -2.8634e-04,
          1.9431e-04, -1.0738e-03],
        [ 2.2278e-03,  5.4550e-04, -2.4796e-03,  ..., -5.7697e-04,
         -7.2908e-04, -7.5388e-04],
        ...,
        [-5.8591e-05,  5.9700e-04, -5.0163e-04,  ..., -3.3073e-03,
         -2.6417e-03,  5.4836e-04],
        [-3.4070e-04, -5.3549e-04, -3.3164e-04,  ...,  2.8086e-04,
         -1.0586e-03, -4.9305e-04],
        [-5.6505e-04, -9.1124e-04, -5.5027e-04,  ..., -4.9782e-04,
         -1.0290e-03, -1.5087e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1013, -0.0013,  0.0032,  ..., -0.0047, -0.0010, -0.0035],
        [ 0.0004, -0.0963, -0.0004,  ..., -0.0079, -0.0048,  0.0090],
        [-0.0075, -0.0063, -0.0854,  ...,  0.0040,  0.0066, -0.0019],
        ...,
        [-0.0014,  0.0023, -0.0118,  ..., -0.0753,  0.0012,  0.0068],
        [-0.0005, -0.0077,  0.0082,  ..., -0.0055, -0.0972,  0.0023],
        [-0.0076, -0.0060,  0.0034,  ..., -0.0095, -0.0008, -0.0986]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1033, -0.0088,  0.0068,  ..., -0.0010, -0.0068,  0.0055],
        [-0.0091, -0.1068,  0.0035,  ...,  0.0033, -0.0058,  0.0045],
        [-0.0015, -0.0014, -0.0956,  ..., -0.0012,  0.0144,  0.0061],
        ...,
        [-0.0061,  0.0030, -0.0091,  ..., -0.0820,  0.0052,  0.0013],
        [-0.0009, -0.0022,  0.0025,  ...,  0.0090, -0.0925,  0.0050],
        [-0.0061,  0.0084,  0.0081,  ...,  0.0023, -0.0031, -0.1052]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:23:00 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 06:23:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3228, -0.4368,  0.0188,  ..., -0.5005,  0.2551, -0.0175],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2971,  0.6426,  0.3777,  ..., -1.3105, -0.0721,  0.3943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0349,  0.9272, -0.4604,  ..., -0.8057,  0.8682, -0.4841],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3330,  0.5186,  0.2744,  ..., -0.5664, -0.4082, -0.0112],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:23:00 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:23:00 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 06:23:37 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 06:24:13 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 06:24:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.2349e-03,  1.7858e-04,  2.4586e-03,  ..., -1.7681e-03,
          1.6146e-03,  1.5802e-03],
        [ 3.0174e-03, -5.1765e-03,  1.5717e-03,  ...,  4.4441e-04,
          7.7820e-04, -2.0659e-04],
        [ 2.1410e-04,  7.8726e-04, -3.0193e-03,  ..., -1.6365e-03,
         -1.6189e-04, -7.6890e-06],
        ...,
        [ 4.0579e-04,  1.3828e-03, -1.3828e-03,  ..., -1.8139e-03,
         -1.5745e-03,  1.7815e-03],
        [ 2.2812e-03, -1.0948e-03,  6.6376e-04,  ..., -1.3008e-03,
         -2.9106e-03, -2.2564e-03],
        [ 7.3719e-04, -5.1641e-04, -4.0531e-06,  ...,  3.5954e-04,
          5.4646e-04, -5.2929e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.8430e-02,  5.7945e-03, -7.4577e-03,  ...,  8.2703e-03,
          5.8746e-03, -1.4290e-02],
        [ 9.6054e-03, -1.0162e-01,  3.2730e-03,  ...,  6.8588e-03,
          3.2425e-05, -7.1030e-03],
        [-2.8858e-03,  5.4245e-03, -9.4055e-02,  ...,  2.7256e-03,
         -4.8027e-03, -4.9896e-03],
        ...,
        [ 1.4677e-03,  1.2169e-03,  4.4365e-03,  ..., -9.3262e-02,
         -6.9809e-03, -3.1109e-03],
        [ 5.8136e-03,  1.3294e-03,  2.5826e-03,  ...,  1.9159e-03,
         -9.3140e-02, -2.7523e-03],
        [ 1.1749e-03,  1.6998e-02,  1.3351e-04,  ..., -2.7466e-04,
          8.4229e-03, -9.1370e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1086, -0.0018, -0.0016,  ...,  0.0015, -0.0014, -0.0026],
        [ 0.0005, -0.0900, -0.0100,  ...,  0.0067, -0.0082,  0.0010],
        [-0.0012, -0.0043, -0.0939,  ..., -0.0005, -0.0001, -0.0003],
        ...,
        [ 0.0002,  0.0070,  0.0080,  ..., -0.1054, -0.0054, -0.0005],
        [-0.0049, -0.0009, -0.0049,  ..., -0.0041, -0.0965, -0.0062],
        [-0.0035, -0.0061, -0.0078,  ..., -0.0094, -0.0029, -0.1023]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:24:51 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 06:24:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0353,  0.2737,  0.0737,  ..., -0.8008,  0.6396, -0.2339],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1104,  0.6313,  0.6558,  ..., -0.9448, -0.3845,  0.2074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1383,  0.5186, -0.6982,  ..., -0.5605,  0.9766, -0.8604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4910,  0.2351,  0.1945,  ..., -0.9375, -0.9355, -0.2422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:24:51 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:24:51 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 06:25:30 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 06:26:06 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 06:26:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.0599e-03, -6.9952e-04,  1.3943e-03,  ...,  1.5869e-03,
         -5.3062e-03,  2.2469e-03],
        [-3.2043e-04, -1.1768e-03,  1.1644e-03,  ...,  2.1801e-03,
          3.2024e-03, -3.4466e-03],
        [ 7.3242e-04, -1.6069e-04, -1.7462e-03,  ..., -9.4986e-04,
          7.7009e-05, -1.8435e-03],
        ...,
        [-8.0872e-04, -4.8327e-04, -1.4234e-04,  ..., -4.7455e-03,
         -2.6250e-04,  2.0428e-03],
        [ 5.8270e-04, -9.0408e-04, -1.7109e-03,  ...,  4.2319e-06,
         -5.9843e-05, -1.6212e-04],
        [ 3.0651e-03, -2.8477e-03,  4.3368e-04,  ..., -1.6212e-05,
          2.3537e-03, -3.8452e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0742,  0.0044, -0.0056,  ..., -0.0045,  0.0023,  0.0151],
        [-0.0079, -0.0781, -0.0047,  ..., -0.0024,  0.0034,  0.0023],
        [ 0.0107, -0.0055, -0.0797,  ...,  0.0054, -0.0052,  0.0057],
        ...,
        [-0.0101,  0.0039,  0.0098,  ..., -0.0847, -0.0080,  0.0042],
        [ 0.0145, -0.0082, -0.0018,  ...,  0.0235, -0.0822,  0.0084],
        [-0.0090,  0.0033,  0.0035,  ...,  0.0012, -0.0098, -0.0806]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1072, -0.0004,  0.0110,  ..., -0.0111, -0.0040, -0.0122],
        [-0.0003, -0.1030, -0.0043,  ...,  0.0042,  0.0209, -0.0051],
        [-0.0012, -0.0024, -0.0975,  ..., -0.0033,  0.0037,  0.0127],
        ...,
        [-0.0020, -0.0015, -0.0009,  ..., -0.0999,  0.0083,  0.0032],
        [ 0.0113,  0.0055,  0.0021,  ...,  0.0162, -0.1001, -0.0012],
        [-0.0092, -0.0028,  0.0095,  ...,  0.0139,  0.0045, -0.1041]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:26:47 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 06:26:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0290,  0.7832, -0.3770,  ..., -0.6274,  0.6899, -0.4351],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3103,  0.5000,  0.2369,  ..., -0.4980, -0.3792, -0.0298],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.3677,  0.7090, -1.0234,  ..., -1.3789,  0.0024,  0.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3125, -0.1931,  0.1323,  ..., -1.2217, -1.4209,  1.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:26:47 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:26:47 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 06:27:28 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 06:28:10 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 06:28:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.2616e-03, -1.4315e-03,  2.0828e-03,  ...,  3.7408e-04,
          4.4942e-04, -2.1648e-03],
        [ 3.4046e-04, -5.7983e-03,  1.8406e-03,  ..., -2.5215e-03,
          5.1403e-04, -3.6011e-03],
        [-9.0122e-04,  3.4180e-03, -3.8681e-03,  ..., -2.6441e-04,
          1.1635e-03, -3.1185e-04],
        ...,
        [-1.6422e-03,  3.6478e-05, -1.8320e-03,  ..., -5.1498e-03,
          6.6662e-04,  2.7542e-03],
        [ 2.4872e-03,  2.4471e-03, -1.5783e-03,  ..., -1.6384e-03,
         -6.4011e-03, -6.0844e-04],
        [ 3.6983e-03,  5.2309e-04, -2.1381e-03,  ..., -1.7366e-03,
          6.0940e-04, -2.7103e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0934,  0.0006, -0.0009,  ..., -0.0040,  0.0022,  0.0029],
        [ 0.0069, -0.1097,  0.0177,  ...,  0.0065, -0.0030,  0.0218],
        [ 0.0063,  0.0086, -0.0895,  ...,  0.0017, -0.0087, -0.0049],
        ...,
        [ 0.0093,  0.0049,  0.0100,  ..., -0.0892,  0.0094, -0.0062],
        [-0.0090, -0.0072, -0.0060,  ..., -0.0029, -0.0813,  0.0099],
        [ 0.0060,  0.0078, -0.0014,  ..., -0.0099, -0.0037, -0.1055]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1071,  0.0178, -0.0011,  ..., -0.0103,  0.0043,  0.0007],
        [ 0.0025, -0.1202,  0.0111,  ..., -0.0073, -0.0095,  0.0159],
        [ 0.0005, -0.0033, -0.1086,  ..., -0.0086, -0.0027,  0.0073],
        ...,
        [ 0.0100,  0.0048, -0.0115,  ..., -0.1129,  0.0058, -0.0025],
        [-0.0069, -0.0010, -0.0082,  ..., -0.0035, -0.1033,  0.0118],
        [ 0.0073, -0.0018, -0.0109,  ...,  0.0020,  0.0089, -0.1139]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:28:55 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 06:28:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1228,  0.3782, -0.5391,  ..., -0.4041,  0.6699, -0.6592],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4219,  0.1951,  0.1031,  ..., -0.7383, -0.7588, -0.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4636,  0.6226, -0.8047,  ..., -1.7471,  0.2291, -0.5996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1570,  0.0105,  0.0402,  ..., -0.7637, -1.4375,  0.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:28:55 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:28:55 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 06:29:43 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 06:30:32 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 06:30:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.5826e-03,  2.5234e-03,  2.4962e-04,  ..., -3.0708e-03,
          3.8171e-04, -2.5864e-03],
        [ 3.7003e-03,  2.0103e-03, -2.2447e-04,  ..., -1.7309e-03,
         -2.2354e-03,  2.2755e-03],
        [-3.6907e-04,  6.7472e-04, -3.0637e-04,  ..., -6.1111e-03,
         -5.4216e-04, -1.9493e-03],
        ...,
        [-6.3229e-04, -3.5419e-03,  4.8828e-04,  ...,  3.4046e-03,
          2.0599e-03,  3.2082e-03],
        [-1.6937e-03, -3.0098e-03,  3.9291e-03,  ...,  1.2474e-03,
          1.5020e-03, -4.1771e-04],
        [ 5.7030e-04,  6.0081e-05, -1.0157e-04,  ..., -2.2297e-03,
         -1.4801e-03, -7.7152e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1196, -0.0077, -0.0044,  ..., -0.0098,  0.0072, -0.0030],
        [ 0.0002, -0.1276, -0.0043,  ...,  0.0090, -0.0024, -0.0045],
        [-0.0076,  0.0034, -0.1231,  ..., -0.0139, -0.0188, -0.0058],
        ...,
        [-0.0028,  0.0046,  0.0018,  ..., -0.1135,  0.0085, -0.0041],
        [-0.0044,  0.0013,  0.0045,  ..., -0.0018, -0.1327,  0.0130],
        [ 0.0139, -0.0009, -0.0180,  ..., -0.0080,  0.0206, -0.1119]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1681, -0.0127, -0.0085,  ...,  0.0036,  0.0066,  0.0043],
        [-0.0113, -0.1707, -0.0074,  ...,  0.0051,  0.0029, -0.0064],
        [-0.0078, -0.0017, -0.1500,  ...,  0.0054, -0.0031, -0.0099],
        ...,
        [-0.0120,  0.0068,  0.0189,  ..., -0.1578, -0.0154,  0.0060],
        [-0.0008,  0.0018,  0.0160,  ..., -0.0048, -0.1584, -0.0060],
        [-0.0063,  0.0131,  0.0017,  ..., -0.0131, -0.0190, -0.1438]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:31:01 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 06:31:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2456,  0.4539, -0.6855,  ..., -0.8525, -0.0162,  0.0216],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2312, -0.1625,  0.0589,  ..., -0.8604, -1.0625,  0.7607],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4609,  0.6650, -0.9644,  ..., -1.1855,  0.6240, -0.5166],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0815,  0.4578, -0.1044,  ..., -0.8115, -1.0977,  0.8853],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:31:01 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:31:01 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 06:31:49 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 06:32:40 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 06:33:28 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.4429e-03,  7.3051e-04, -1.3266e-03,  ...,  1.3390e-03,
          5.2786e-04,  1.6718e-03],
        [-2.9397e-04,  2.0618e-03,  7.5531e-04,  ...,  7.8344e-04,
          2.1839e-03,  3.3112e-03],
        [ 2.1610e-03, -2.9430e-03, -1.4043e-04,  ...,  1.2102e-03,
         -5.1260e-04, -7.2479e-04],
        ...,
        [ 2.4605e-03,  1.2577e-04,  3.6812e-03,  ..., -1.2054e-03,
         -3.9635e-03,  1.7347e-03],
        [-1.3781e-04, -2.1219e-05,  2.2125e-03,  ...,  3.2692e-03,
         -2.6073e-03,  1.0891e-03],
        [-1.8053e-03, -8.2207e-04, -3.4046e-03,  ...,  1.5259e-05,
         -2.6774e-04, -1.8997e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1993e-01,  1.0597e-02,  1.0061e-04,  ..., -1.8311e-04,
         -3.2005e-03,  5.6610e-03],
        [ 1.4999e-02, -1.3000e-01, -3.9291e-03,  ...,  5.2643e-04,
         -4.2496e-03, -5.6915e-03],
        [ 7.2594e-03,  3.9635e-03, -1.0876e-01,  ...,  4.2572e-03,
         -7.5607e-03, -6.3324e-04],
        ...,
        [ 2.0409e-04,  3.9520e-03,  2.1706e-03,  ..., -9.1797e-02,
          8.0566e-03, -7.1373e-03],
        [ 1.2589e-02,  1.0811e-02,  8.5449e-03,  ...,  1.6663e-02,
         -1.1200e-01,  2.9774e-03],
        [ 4.6730e-05,  9.9335e-03, -6.2609e-04,  ...,  1.9064e-03,
         -7.4196e-03, -1.1041e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1140,  0.0147,  0.0111,  ...,  0.0106, -0.0124,  0.0062],
        [ 0.0124, -0.1029,  0.0012,  ...,  0.0078, -0.0137, -0.0046],
        [-0.0035,  0.0021, -0.1072,  ...,  0.0034, -0.0043,  0.0075],
        ...,
        [ 0.0053, -0.0022, -0.0049,  ..., -0.1116,  0.0058, -0.0013],
        [ 0.0046, -0.0038, -0.0034,  ...,  0.0064, -0.1153,  0.0007],
        [ 0.0030, -0.0026,  0.0061,  ...,  0.0013,  0.0005, -0.1115]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:33:31 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 06:33:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2725,  0.3718, -0.5210,  ..., -1.0664,  0.1152, -0.3794],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0973, -0.0111, -0.0184,  ..., -0.5391, -0.9995,  0.2002],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2971,  1.6982, -1.6758,  ..., -1.0830,  0.5234, -0.1934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1167,  0.5850, -0.1277,  ...,  0.3057, -0.5864,  0.5811],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:33:31 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:33:31 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 06:34:23 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 06:35:11 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 06:36:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.5640e-03,  3.2997e-04, -1.5342e-04,  ..., -3.1242e-03,
          2.2869e-03, -6.2346e-05],
        [ 2.6131e-03,  1.4725e-03,  1.0033e-03,  ..., -7.0381e-04,
          2.0828e-03,  1.6556e-03],
        [ 1.8430e-04,  1.7583e-04,  5.2071e-03,  ..., -1.7996e-03,
          1.9894e-03, -1.4267e-03],
        ...,
        [-2.6894e-03,  2.5101e-03,  2.2678e-03,  ...,  4.8065e-03,
         -3.0651e-03,  3.7556e-03],
        [-2.4815e-03, -1.7297e-04,  1.5855e-04,  ..., -2.8458e-03,
          2.5101e-03,  2.4147e-03],
        [-1.4687e-03,  2.1572e-03, -2.3842e-04,  ...,  3.0994e-04,
         -1.1563e-04, -5.6505e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.8005e-01,  7.5760e-03,  3.1796e-03,  ..., -1.2779e-03,
          6.5308e-03, -1.4091e-02],
        [ 1.1253e-04, -1.8945e-01, -6.8245e-03,  ..., -1.3809e-03,
          4.3678e-03, -1.0376e-02],
        [ 1.1719e-02,  3.8643e-03, -1.7578e-01,  ..., -8.4991e-03,
          4.2877e-03, -2.4490e-03],
        ...,
        [-8.5449e-03, -1.9875e-03,  1.8784e-02,  ..., -1.8945e-01,
          5.5771e-03,  3.1300e-03],
        [-1.1292e-02,  6.0616e-03,  9.7504e-03,  ...,  7.4196e-03,
         -1.8591e-01, -3.9825e-03],
        [ 2.7275e-04,  3.2883e-03, -1.8673e-03,  ..., -1.1261e-02,
          4.1199e-03, -1.7822e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.2246,  0.0167,  0.0144,  ..., -0.0122,  0.0004, -0.0158],
        [ 0.0039, -0.2378, -0.0105,  ..., -0.0159,  0.0052, -0.0035],
        [ 0.0100,  0.0046, -0.2246,  ..., -0.0083,  0.0038, -0.0174],
        ...,
        [-0.0003,  0.0006,  0.0104,  ..., -0.2402,  0.0175, -0.0061],
        [-0.0116, -0.0008,  0.0038,  ...,  0.0233, -0.2275,  0.0074],
        [-0.0016,  0.0017, -0.0163,  ..., -0.0159, -0.0056, -0.2223]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:36:05 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 06:36:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2546,  0.3945, -0.6162,  ..., -0.7217,  0.3689, -0.3840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0367,  0.3511, -0.1288,  ..., -0.6367, -0.8726,  0.6704],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.4961,  2.3730, -1.6250,  ..., -1.6514,  0.0251,  0.6895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0701,  0.4839, -0.6133,  ...,  0.5391, -0.8633,  0.7080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:36:05 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:36:05 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 06:36:59 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 06:37:56 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 06:38:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7843e-03,  2.5864e-03, -3.4499e-04,  ...,  4.0746e-04,
         -1.4954e-03, -1.6737e-03],
        [-3.3035e-03, -4.2725e-03, -5.1379e-05,  ...,  1.0490e-04,
         -1.4858e-03, -4.3488e-04],
        [-2.1133e-03,  2.1076e-03, -7.6942e-03,  ...,  1.6441e-03,
         -3.7155e-03, -3.9330e-03],
        ...,
        [ 4.8370e-03, -2.8381e-03,  2.2888e-03,  ..., -3.7632e-03,
          4.3678e-03,  2.4223e-04],
        [-1.3990e-03,  5.4359e-04, -2.4986e-03,  ..., -2.3460e-03,
         -7.2327e-03,  1.2445e-03],
        [ 2.0905e-03,  6.9714e-04,  3.2711e-04,  ..., -1.0853e-03,
          1.5469e-03, -5.1117e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0994,  0.0115,  0.0006,  ...,  0.0113,  0.0019, -0.0079],
        [ 0.0033, -0.1030,  0.0016,  ..., -0.0076, -0.0009,  0.0042],
        [-0.0138, -0.0034, -0.1031,  ...,  0.0092,  0.0007,  0.0061],
        ...,
        [ 0.0048,  0.0032,  0.0099,  ..., -0.0820,  0.0013, -0.0095],
        [-0.0157,  0.0043, -0.0088,  ..., -0.0005, -0.1053,  0.0072],
        [ 0.0041,  0.0041, -0.0128,  ...,  0.0011,  0.0051, -0.0999]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0771, -0.0095, -0.0064,  ...,  0.0090, -0.0065, -0.0004],
        [ 0.0086, -0.0909, -0.0065,  ...,  0.0082,  0.0041,  0.0208],
        [-0.0047, -0.0104, -0.0908,  ..., -0.0078, -0.0030,  0.0095],
        ...,
        [-0.0107,  0.0018,  0.0049,  ..., -0.0776,  0.0023,  0.0032],
        [-0.0079,  0.0068, -0.0119,  ...,  0.0024, -0.0957, -0.0055],
        [ 0.0030,  0.0056, -0.0020,  ...,  0.0158,  0.0001, -0.0890]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:38:50 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 06:38:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1694,  0.9409, -0.9253,  ..., -0.6172,  0.2986, -0.1379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0870,  0.4067, -0.1028,  ...,  0.2008, -0.4343,  0.4216],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.0625,  2.1641, -1.8438,  ..., -0.7773,  0.7578,  0.5889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1411,  0.3179, -1.2246,  ...,  0.3862,  0.1543,  0.8604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:38:50 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:38:50 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 06:39:47 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 06:40:41 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 06:41:39 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.6904e-03,  2.1029e-04, -4.6959e-03,  ...,  2.3937e-04,
          2.2278e-03, -7.6675e-03],
        [-1.1063e-03,  1.1864e-03, -5.5161e-03,  ...,  9.8610e-04,
         -3.4714e-03, -3.9062e-03],
        [-6.1188e-03,  2.2430e-03, -1.3523e-03,  ...,  8.1158e-04,
         -9.2459e-04, -5.4979e-04],
        ...,
        [ 2.1324e-03, -9.9087e-04, -2.8729e-04,  ...,  5.8365e-04,
         -2.9259e-03, -7.8201e-04],
        [ 5.4283e-03, -4.8637e-03,  2.7771e-03,  ..., -1.2951e-03,
         -1.3153e-02, -2.2182e-03],
        [-6.8331e-04,  9.2316e-03,  2.8670e-05,  ..., -1.9073e-03,
         -4.7836e-03, -9.4604e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1582, -0.0064, -0.0077,  ..., -0.0067,  0.0042,  0.0070],
        [ 0.0042, -0.1478, -0.0047,  ..., -0.0003, -0.0009,  0.0092],
        [ 0.0064,  0.0025, -0.1332,  ..., -0.0267, -0.0012, -0.0143],
        ...,
        [-0.0117,  0.0055,  0.0032,  ..., -0.1537, -0.0041, -0.0030],
        [ 0.0108,  0.0102,  0.0040,  ...,  0.0019, -0.1453, -0.0117],
        [ 0.0098,  0.0017, -0.0090,  ..., -0.0161, -0.0054, -0.1385]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1426,  0.0006,  0.0046,  ..., -0.0092,  0.0073,  0.0145],
        [-0.0004, -0.1371,  0.0005,  ..., -0.0034, -0.0099,  0.0216],
        [ 0.0049,  0.0086, -0.1628,  ..., -0.0219,  0.0056, -0.0082],
        ...,
        [-0.0097, -0.0005, -0.0046,  ..., -0.1373, -0.0077, -0.0067],
        [ 0.0073,  0.0113, -0.0015,  ...,  0.0051, -0.1600,  0.0074],
        [-0.0022,  0.0068,  0.0053,  ..., -0.0107,  0.0101, -0.1390]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:41:41 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-07-01 06:41:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7583,  1.2109, -0.8267,  ..., -0.8594,  0.0394,  0.3069],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0720,  0.2869, -0.3916,  ...,  0.3167, -0.5195,  0.3997],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.5283,  2.3594, -1.5234,  ..., -1.3252,  1.4072,  0.9326],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6685,  0.5410, -1.0615,  ...,  0.5537, -0.5142,  0.7319],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:41:41 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:41:41 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 06:42:42 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 06:43:42 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 06:44:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1196e-03, -3.2783e-04,  4.6005e-03,  ..., -4.8103e-03,
         -7.8964e-03, -5.1260e-05],
        [-4.8904e-03, -2.3842e-03, -3.2539e-03,  ..., -4.4513e-04,
          3.0766e-03, -2.9335e-03],
        [-1.3914e-03, -7.5607e-03, -3.6507e-03,  ...,  6.2256e-03,
         -1.6279e-03,  5.6686e-03],
        ...,
        [ 6.7186e-04,  5.4932e-03, -4.8676e-03,  ..., -1.9665e-03,
         -8.2397e-04, -1.9531e-03],
        [-4.2305e-03, -2.0027e-03,  3.5439e-03,  ...,  1.2760e-03,
          4.6730e-03,  2.3708e-03],
        [-4.9286e-03,  1.1578e-03,  7.5626e-04,  ...,  1.9684e-03,
         -1.0443e-03, -4.3831e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1011e-01,  2.3727e-02, -2.6531e-03,  ..., -6.8617e-04,
         -8.9798e-03,  2.3441e-03],
        [ 8.7738e-05, -1.2335e-01, -6.4850e-03,  ...,  2.6722e-03,
          5.5313e-03, -4.5013e-04],
        [-2.8896e-03, -1.0612e-02, -1.0724e-01,  ...,  3.3684e-03,
          1.2718e-02, -1.0315e-02],
        ...,
        [ 8.4076e-03, -3.9368e-03, -8.7814e-03,  ..., -1.0425e-01,
          8.4229e-03,  1.5793e-03],
        [ 1.0948e-03, -1.5717e-02,  5.2795e-03,  ...,  3.9215e-03,
         -1.1047e-01, -1.6775e-03],
        [-7.4463e-03,  1.3428e-03, -1.6724e-02,  ...,  9.5215e-03,
          1.3069e-02, -1.2036e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1072,  0.0077, -0.0052,  ..., -0.0089, -0.0114, -0.0064],
        [ 0.0010, -0.1097, -0.0041,  ...,  0.0092,  0.0013,  0.0014],
        [-0.0021, -0.0159, -0.1028,  ..., -0.0041,  0.0077, -0.0107],
        ...,
        [ 0.0058,  0.0122,  0.0024,  ..., -0.1080,  0.0220, -0.0031],
        [-0.0148,  0.0025, -0.0058,  ...,  0.0072, -0.0967,  0.0051],
        [-0.0134, -0.0053, -0.0063,  ..., -0.0056,  0.0039, -0.1002]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:44:44 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-07-01 06:44:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5283,  1.0361, -0.8633,  ..., -0.3872,  0.3723,  0.2573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0825,  0.1636, -0.7139,  ...,  0.2189,  0.0992,  0.5005],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.3467,  2.3574, -1.3047,  ..., -1.0059,  1.2285,  1.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.8076,  0.4329, -1.5137,  ...,  1.5908, -0.6582,  1.2861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:44:45 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:44:45 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 06:45:46 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 06:46:49 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 06:47:49 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0082,  0.0002, -0.0004,  ...,  0.0018, -0.0025, -0.0008],
        [ 0.0061,  0.0034,  0.0041,  ..., -0.0005,  0.0044, -0.0021],
        [-0.0042, -0.0030,  0.0053,  ..., -0.0018, -0.0030,  0.0025],
        ...,
        [ 0.0001, -0.0012, -0.0002,  ...,  0.0124, -0.0021, -0.0022],
        [ 0.0021, -0.0018,  0.0039,  ..., -0.0054,  0.0069,  0.0015],
        [ 0.0003,  0.0022,  0.0015,  ..., -0.0018,  0.0010,  0.0075]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1177, -0.0048, -0.0105,  ..., -0.0078, -0.0061, -0.0003],
        [-0.0023, -0.1191, -0.0028,  ...,  0.0066, -0.0009,  0.0062],
        [ 0.0066,  0.0140, -0.1316,  ..., -0.0005, -0.0087, -0.0096],
        ...,
        [-0.0007, -0.0055, -0.0038,  ..., -0.1371, -0.0059,  0.0047],
        [-0.0093,  0.0020, -0.0151,  ...,  0.0018, -0.1111,  0.0051],
        [ 0.0071, -0.0052,  0.0037,  ..., -0.0086,  0.0052, -0.1229]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1229, -0.0042, -0.0182,  ...,  0.0055, -0.0046,  0.0034],
        [ 0.0059, -0.1353, -0.0030,  ..., -0.0016, -0.0143, -0.0099],
        [ 0.0050,  0.0034, -0.1190,  ..., -0.0007,  0.0117,  0.0003],
        ...,
        [-0.0010, -0.0074, -0.0060,  ..., -0.1281, -0.0015, -0.0053],
        [ 0.0012, -0.0065,  0.0029,  ...,  0.0169, -0.1307,  0.0106],
        [ 0.0031,  0.0016,  0.0062,  ..., -0.0025,  0.0152, -0.1272]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:47:52 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-07-01 06:47:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7168,  1.1729, -0.7261,  ..., -0.6421,  0.6851,  0.4312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3354,  0.3081, -0.5737,  ...,  0.3003, -0.2773,  0.3828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.6523,  2.3770, -1.6729,  ..., -0.7949,  1.8516,  2.0215],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1074,  0.1155, -2.3691,  ...,  0.7529,  0.2573,  1.1221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:47:52 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:47:52 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 06:48:56 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 06:49:59 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 06:51:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0097, -0.0032,  0.0045,  ..., -0.0044, -0.0025, -0.0018],
        [-0.0014, -0.0069,  0.0037,  ..., -0.0001, -0.0015,  0.0005],
        [ 0.0006,  0.0023, -0.0167,  ..., -0.0014, -0.0011,  0.0048],
        ...,
        [ 0.0025, -0.0002,  0.0072,  ..., -0.0059, -0.0033, -0.0044],
        [ 0.0022,  0.0003, -0.0014,  ..., -0.0040, -0.0129,  0.0056],
        [-0.0022,  0.0048, -0.0019,  ..., -0.0028, -0.0005, -0.0130]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0687,  0.0156,  0.0068,  ..., -0.0163,  0.0115, -0.0075],
        [ 0.0007, -0.0739, -0.0102,  ..., -0.0016,  0.0037, -0.0025],
        [ 0.0002, -0.0041, -0.0757,  ...,  0.0014, -0.0004,  0.0086],
        ...,
        [-0.0170, -0.0105, -0.0144,  ..., -0.0824, -0.0089, -0.0017],
        [ 0.0029,  0.0134, -0.0018,  ...,  0.0170, -0.0870,  0.0019],
        [-0.0060, -0.0021,  0.0069,  ..., -0.0043, -0.0017, -0.0623]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.1492e-02,  9.4299e-03,  2.1782e-03,  ..., -2.3193e-03,
          6.8665e-04, -2.2163e-03],
        [ 1.5869e-02, -8.9233e-02, -3.4370e-03,  ...,  7.0343e-03,
          2.3975e-03,  1.5854e-02],
        [-9.3460e-04,  1.3420e-02, -9.9365e-02,  ..., -1.3168e-02,
         -1.6449e-02, -1.8051e-02],
        ...,
        [-1.8005e-02,  2.9259e-03, -4.1733e-03,  ..., -8.2642e-02,
         -5.1575e-03,  1.1604e-02],
        [ 1.0460e-02,  9.2316e-03, -1.5732e-02,  ..., -1.8845e-03,
         -9.8267e-02,  3.4409e-03],
        [-8.0872e-03, -8.2016e-05,  1.2833e-02,  ..., -8.4229e-03,
         -6.1035e-04, -1.0114e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:51:03 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-07-01 06:51:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5967,  1.0576, -0.5586,  ..., -0.4409,  0.5576,  0.6558],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3960,  0.2137, -0.7183,  ...,  0.7603, -0.3120,  0.6016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.9668,  2.7422, -1.2607,  ..., -0.9653,  1.5840,  2.4824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.9512,  0.0726, -2.5059,  ...,  1.2949, -0.2251,  1.6455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:51:03 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:51:03 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 06:52:06 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 06:53:10 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 06:54:14 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0061, -0.0037,  0.0029,  ...,  0.0057,  0.0031, -0.0030],
        [-0.0033,  0.0007, -0.0036,  ..., -0.0045,  0.0052,  0.0029],
        [-0.0015, -0.0068, -0.0041,  ..., -0.0043,  0.0003,  0.0016],
        ...,
        [-0.0032, -0.0089, -0.0025,  ..., -0.0010,  0.0010, -0.0026],
        [ 0.0109,  0.0107, -0.0072,  ..., -0.0051, -0.0080, -0.0017],
        [ 0.0016, -0.0008, -0.0013,  ..., -0.0026,  0.0074, -0.0098]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0683, -0.0004,  0.0104,  ..., -0.0047,  0.0085, -0.0028],
        [-0.0009, -0.0611,  0.0210,  ...,  0.0057,  0.0160, -0.0033],
        [-0.0012, -0.0028, -0.0685,  ..., -0.0209,  0.0009, -0.0164],
        ...,
        [-0.0041, -0.0110,  0.0224,  ..., -0.0660,  0.0091,  0.0091],
        [ 0.0209, -0.0027,  0.0046,  ...,  0.0045, -0.0797,  0.0180],
        [ 0.0004,  0.0127,  0.0086,  ..., -0.0112,  0.0095, -0.0640]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.6660e-02, -6.9523e-04,  4.5395e-03,  ..., -7.2861e-03,
         -7.3700e-03,  5.8746e-04],
        [-2.3270e-03, -8.2275e-02,  1.7862e-03,  ..., -1.1879e-02,
         -1.0216e-02, -5.8365e-03],
        [ 9.3842e-03, -6.5155e-03, -9.3201e-02,  ..., -3.3302e-03,
          4.9210e-04, -6.7978e-03],
        ...,
        [-3.2735e-04, -1.1093e-02,  1.3000e-02,  ..., -7.7209e-02,
         -8.7357e-04,  2.1534e-03],
        [ 3.0518e-05, -5.4932e-03,  1.8860e-02,  ...,  2.8168e-02,
         -1.1847e-01,  1.0544e-02],
        [ 3.1738e-03,  7.0343e-03, -1.4706e-03,  ...,  3.9406e-03,
          8.9645e-04, -7.3608e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:54:16 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-07-01 06:54:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7007,  1.0225, -0.7134,  ..., -0.3425,  0.8115,  0.8423],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4980,  0.0596, -1.0674,  ...,  0.3408,  0.1262,  0.4822],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5303,  2.4648, -1.9883,  ..., -0.8970,  2.3672,  3.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.5371, -0.7671, -3.4609,  ...,  0.7168, -0.1599,  1.9473],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:54:16 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:54:16 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 06:55:23 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 06:56:32 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 06:57:41 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.7564e-03, -2.1076e-04,  1.8387e-03,  ..., -3.9363e-04,
         -9.6178e-04, -1.7128e-03],
        [-4.0169e-03, -3.9597e-03, -2.9964e-03,  ...,  7.2670e-04,
          3.2825e-03, -5.2872e-03],
        [-4.2801e-03, -4.8332e-03, -3.4428e-03,  ...,  2.1338e-04,
         -3.6597e-05,  4.9114e-04],
        ...,
        [ 9.3555e-04,  1.4334e-03, -5.0354e-03,  ..., -5.6458e-03,
         -3.0208e-04, -1.6375e-03],
        [ 2.9774e-03,  7.0810e-04,  6.7368e-03,  ..., -2.4395e-03,
         -4.3182e-03,  1.0422e-02],
        [ 7.8154e-04, -7.8106e-04, -6.7329e-04,  ...,  3.0136e-03,
          2.4681e-03, -6.1188e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0760,  0.0080,  0.0088,  ...,  0.0012, -0.0041, -0.0073],
        [ 0.0112, -0.0894,  0.0002,  ..., -0.0064,  0.0065,  0.0011],
        [ 0.0132,  0.0147, -0.0739,  ..., -0.0009,  0.0069,  0.0006],
        ...,
        [ 0.0070, -0.0029, -0.0102,  ..., -0.0756,  0.0064,  0.0115],
        [-0.0082,  0.0063,  0.0029,  ..., -0.0042, -0.0650, -0.0005],
        [-0.0036, -0.0067, -0.0025,  ..., -0.0102,  0.0097, -0.0775]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0977,  0.0198, -0.0025,  ...,  0.0099, -0.0017, -0.0061],
        [-0.0089, -0.1318,  0.0063,  ..., -0.0058,  0.0070,  0.0211],
        [-0.0123, -0.0269, -0.1077,  ..., -0.0264,  0.0137, -0.0083],
        ...,
        [ 0.0037,  0.0035, -0.0145,  ..., -0.1020,  0.0086,  0.0169],
        [ 0.0011, -0.0127, -0.0129,  ..., -0.0216, -0.1014, -0.0016],
        [-0.0066, -0.0207, -0.0244,  ..., -0.0108, -0.0019, -0.1343]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 06:57:43 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-07-01 06:57:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4111,  1.1484, -0.5361,  ..., -0.4067,  0.6895,  1.0195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8755,  0.0275, -1.0850,  ...,  0.5596, -0.0749,  0.6943],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8076,  2.2520, -2.6094,  ..., -0.7021,  2.0801,  3.2441],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6729, -0.8828, -4.2969,  ...,  0.4893,  0.0337,  1.0586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 06:57:44 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 06:57:44 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 06:58:53 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 07:00:00 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 07:01:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.5319e-03,  2.4624e-03,  7.7486e-05,  ...,  1.7014e-03,
         -2.8000e-03, -2.5558e-03],
        [ 1.0216e-02,  1.1988e-03, -2.6321e-03,  ..., -2.6016e-03,
          7.3586e-03,  6.2866e-03],
        [ 2.5272e-03, -5.4665e-03, -4.9248e-03,  ..., -1.6632e-03,
          4.1275e-03,  7.9107e-04],
        ...,
        [-5.6229e-03, -7.2784e-03, -3.0556e-03,  ..., -3.6120e-04,
          5.3024e-04, -1.2426e-03],
        [-3.0947e-04, -3.1128e-03,  1.4486e-03,  ..., -3.5172e-03,
         -8.7280e-03,  2.6016e-03],
        [-2.1782e-03,  4.0474e-03, -3.7804e-03,  ..., -9.6359e-03,
         -2.6302e-03,  6.2828e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0387,  0.0022,  0.0015,  ..., -0.0158,  0.0060, -0.0054],
        [ 0.0022, -0.0260, -0.0004,  ..., -0.0095,  0.0097,  0.0008],
        [-0.0082,  0.0159, -0.0366,  ...,  0.0064, -0.0047, -0.0036],
        ...,
        [-0.0087, -0.0039, -0.0135,  ..., -0.0341, -0.0033,  0.0070],
        [ 0.0068,  0.0059, -0.0051,  ..., -0.0083, -0.0335,  0.0062],
        [ 0.0015,  0.0042,  0.0122,  ...,  0.0073,  0.0069, -0.0482]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0440, -0.0061,  0.0181,  ..., -0.0109, -0.0102,  0.0004],
        [-0.0048, -0.0633,  0.0107,  ..., -0.0043,  0.0037,  0.0045],
        [ 0.0105, -0.0036, -0.0616,  ..., -0.0034,  0.0109,  0.0237],
        ...,
        [-0.0048,  0.0052, -0.0184,  ..., -0.0583,  0.0002, -0.0055],
        [ 0.0148,  0.0130, -0.0174,  ..., -0.0016, -0.0644,  0.0159],
        [ 0.0097,  0.0081,  0.0021,  ...,  0.0178,  0.0092, -0.0665]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:01:12 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-07-01 07:01:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2117,  0.9634, -0.7690,  ..., -0.3469,  0.9111,  1.2627],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6050, -0.3059, -1.2910,  ...,  0.2766, -0.0629,  0.7290],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6167,  1.2871, -1.9668,  ..., -0.6826,  2.1992,  2.5664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.9639, -1.8018, -4.2773,  ...,  1.6768,  0.5889,  0.5366],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:01:12 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 07:01:12 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 07:02:26 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 07:03:37 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 07:04:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.3346e-02, -4.0054e-03,  3.3808e-04,  ...,  7.6942e-03,
         -4.3449e-03,  1.4746e-04],
        [-7.3280e-03,  2.1011e-02,  2.3975e-03,  ..., -2.5892e-04,
         -4.8637e-03, -1.8072e-03],
        [-4.5991e-04,  1.2627e-03,  2.3972e-02,  ...,  6.9237e-04,
          2.5330e-03,  6.1493e-03],
        ...,
        [ 7.0229e-03,  2.7733e-03, -4.4174e-03,  ...,  2.1805e-02,
          3.7994e-03,  3.9406e-03],
        [-1.7042e-03, -5.2376e-03,  2.5988e-05,  ..., -1.9093e-03,
          1.6647e-02, -2.5725e-04],
        [-1.7881e-03, -1.1520e-03,  1.3351e-03,  ..., -3.9387e-04,
          4.4823e-03,  2.6108e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.1880e-02,  1.9741e-03,  7.6828e-03,  ...,  3.0231e-03,
         -5.9128e-03,  1.6220e-02],
        [ 1.5533e-02, -2.9510e-02,  4.8523e-03,  ..., -3.2082e-03,
         -9.6664e-03,  1.8883e-03],
        [ 7.3395e-03, -1.4061e-02, -4.3121e-02,  ...,  5.9814e-03,
         -6.7558e-03,  4.5729e-04],
        ...,
        [-1.1848e-02,  1.7548e-02,  5.7716e-03,  ..., -4.6753e-02,
          6.8665e-04,  5.2261e-03],
        [-4.5204e-03, -7.0572e-05, -1.3161e-02,  ..., -6.5231e-03,
         -3.2593e-02, -3.2711e-03],
        [ 6.7215e-03,  6.1111e-03, -4.9248e-03,  ...,  3.7842e-03,
          1.6594e-04, -4.8157e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0489,  0.0099,  0.0022,  ..., -0.0052,  0.0149,  0.0135],
        [ 0.0066, -0.0481, -0.0030,  ...,  0.0043,  0.0143,  0.0129],
        [ 0.0087,  0.0005, -0.0402,  ..., -0.0035,  0.0119, -0.0129],
        ...,
        [-0.0103, -0.0142, -0.0104,  ..., -0.0654, -0.0080,  0.0111],
        [ 0.0119, -0.0073,  0.0026,  ..., -0.0111, -0.0698,  0.0054],
        [ 0.0024, -0.0189, -0.0142,  ...,  0.0075,  0.0017, -0.0798]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:04:49 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-07-01 07:04:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3047,  0.8423, -0.9849,  ..., -0.2769,  0.7886,  1.2061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6284, -0.3391, -1.5928,  ...,  0.1709,  0.0226,  0.3733],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2002,  0.9526, -1.2363,  ..., -0.3899,  2.3047,  2.3926],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.4121, -1.4980, -4.2695,  ...,  1.0547, -0.0347,  0.0073],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:04:49 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 07:04:49 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 07:06:09 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 07:07:29 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 07:08:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0033, -0.0056, -0.0031,  ..., -0.0001, -0.0023, -0.0079],
        [ 0.0055,  0.0061,  0.0035,  ..., -0.0014,  0.0059,  0.0034],
        [-0.0015,  0.0012,  0.0082,  ..., -0.0029, -0.0050, -0.0028],
        ...,
        [-0.0073,  0.0088, -0.0048,  ...,  0.0015, -0.0035,  0.0039],
        [-0.0013,  0.0033, -0.0014,  ...,  0.0057, -0.0004, -0.0025],
        [-0.0087, -0.0014, -0.0018,  ..., -0.0078,  0.0070,  0.0001]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.5137e-02,  2.5387e-03, -3.7003e-03,  ..., -6.8932e-03,
          5.6343e-03,  1.2764e-02],
        [-7.5769e-04, -4.3030e-02, -1.1284e-02,  ...,  2.0752e-03,
          7.9803e-03, -1.5366e-02],
        [-5.8632e-03, -3.0289e-03, -3.1143e-02,  ..., -9.5367e-07,
          9.1248e-03,  2.1439e-03],
        ...,
        [ 2.1095e-03,  6.2866e-03, -4.1351e-03,  ..., -1.8265e-02,
          6.5117e-03,  1.2007e-03],
        [-1.0681e-02,  5.5313e-03, -1.4999e-02,  ...,  3.2654e-03,
         -3.5461e-02, -2.3361e-02],
        [-9.4604e-03,  1.4343e-02,  5.9700e-03,  ...,  4.8065e-03,
         -1.7929e-02, -3.9764e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0631, -0.0043, -0.0120,  ..., -0.0039, -0.0242,  0.0163],
        [ 0.0047, -0.0875, -0.0205,  ..., -0.0052,  0.0089,  0.0090],
        [-0.0055, -0.0104, -0.0447,  ...,  0.0030, -0.0178,  0.0129],
        ...,
        [ 0.0074, -0.0037, -0.0113,  ..., -0.0430, -0.0122,  0.0080],
        [ 0.0294, -0.0258, -0.0126,  ..., -0.0157, -0.0668, -0.0286],
        [-0.0205,  0.0187,  0.0012,  ..., -0.0103, -0.0180, -0.0533]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:08:52 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-07-01 07:08:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2345,  0.4685, -0.7344,  ..., -0.2463,  0.8403,  0.9561],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7163, -0.6289, -1.5029,  ...,  0.5938,  0.2242,  0.1667],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.5029,  1.0654, -0.2949,  ..., -0.6768,  2.4102,  2.4023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.6016, -1.1016, -3.4727,  ...,  0.3955,  0.4326, -0.3862],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:08:52 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 07:08:52 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 07:10:15 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 07:11:35 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 07:12:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.6747e-03,  3.8409e-04,  9.5654e-04,  ..., -1.1387e-03,
         -5.2452e-05,  3.6454e-04],
        [-6.8140e-04, -4.5013e-04,  3.9625e-04,  ...,  2.5296e-04,
          8.5449e-04, -6.2895e-04],
        [ 1.5521e-04,  8.3065e-04, -1.5917e-03,  ..., -9.6703e-04,
         -3.1948e-04,  3.2759e-04],
        ...,
        [-1.8990e-04, -9.8288e-05, -6.7234e-04,  ..., -1.2283e-03,
          1.1128e-04, -4.9448e-04],
        [-3.9339e-04, -1.4722e-04,  2.4700e-03,  ..., -2.3880e-03,
         -5.5885e-04,  1.3900e-04],
        [ 9.0027e-04, -5.8842e-04, -9.0504e-04,  ...,  6.1369e-04,
         -7.5054e-04, -1.0843e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0336,  0.0091, -0.0082,  ...,  0.0130,  0.0125,  0.0059],
        [-0.0026, -0.0407, -0.0083,  ...,  0.0073, -0.0020,  0.0010],
        [ 0.0014, -0.0081, -0.0327,  ..., -0.0098,  0.0087,  0.0018],
        ...,
        [ 0.0014,  0.0129, -0.0070,  ..., -0.0403,  0.0172,  0.0065],
        [ 0.0136,  0.0112, -0.0042,  ...,  0.0183, -0.0323,  0.0077],
        [ 0.0046, -0.0074,  0.0105,  ...,  0.0132,  0.0048, -0.0388]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.3792e-02,  8.6670e-03,  6.3210e-03,  ...,  4.2648e-03,
          1.0498e-02,  3.1204e-02],
        [ 1.2352e-02, -4.6967e-02,  7.4673e-04,  ..., -1.0284e-02,
         -1.5625e-02,  1.2505e-02],
        [-1.7868e-02, -4.4289e-03, -6.8481e-02,  ..., -5.3253e-03,
         -1.0254e-02,  2.4700e-03],
        ...,
        [-1.1551e-02,  6.3248e-03, -1.2512e-03,  ..., -5.6244e-02,
         -2.8839e-03,  1.3588e-02],
        [ 2.5444e-03,  8.3923e-03, -1.6537e-03,  ...,  5.0545e-05,
         -2.3438e-02, -4.9324e-03],
        [ 2.7832e-02,  8.1444e-04, -7.8430e-03,  ...,  3.2898e-02,
         -1.1459e-02, -4.3030e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:13:01 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-07-01 07:13:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0830,  0.3364, -0.4609,  ..., -0.1338,  0.8545,  0.8472],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5059, -0.5005, -1.4512,  ...,  0.3618,  0.0098, -0.0263],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2285,  1.3164,  0.8252,  ..., -0.3254,  2.0547,  2.3613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.8867, -0.4375, -2.3281,  ...,  0.4348,  1.6201, -0.4990],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:13:01 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 07:13:01 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 07:14:25 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 07:15:49 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 07:17:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.1490e-03,  3.1662e-03,  1.2436e-03,  ...,  1.9932e-03,
         -1.3304e-03, -2.5063e-03],
        [-1.9016e-03, -6.9618e-05,  1.2913e-03,  ...,  3.4580e-03,
          7.3862e-04, -6.3467e-04],
        [-4.9067e-04,  1.2112e-03,  1.1641e-04,  ...,  1.2665e-03,
         -5.7578e-05,  1.6565e-03],
        ...,
        [-2.2697e-03,  1.8902e-03,  1.4362e-03,  ..., -4.1389e-03,
         -1.1139e-03, -3.3855e-03],
        [-3.7327e-03, -1.9417e-03, -4.7207e-04,  ..., -3.2210e-04,
         -4.4365e-03,  2.6779e-03],
        [-1.8311e-03,  5.5599e-04,  3.2787e-03,  ..., -1.3838e-03,
          2.7771e-03, -6.0425e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.5144e-02,  8.0872e-03, -2.6512e-04,  ...,  3.4561e-03,
          1.2451e-02, -1.0178e-02],
        [ 1.7624e-02, -1.9775e-02,  9.9335e-03,  ..., -1.4771e-02,
          1.2455e-03, -1.0269e-02],
        [ 1.7914e-02,  1.3802e-02, -1.2993e-02,  ..., -1.6602e-02,
         -2.9144e-03, -3.5019e-03],
        ...,
        [ 1.6281e-02, -9.2983e-05, -1.1307e-02,  ..., -1.6068e-02,
         -1.2001e-02, -7.6218e-03],
        [ 3.0632e-03, -3.8376e-03,  1.3321e-02,  ...,  1.0918e-02,
         -1.1040e-02,  1.1482e-02],
        [ 5.3215e-03, -8.1253e-03,  1.0910e-02,  ..., -1.8482e-03,
         -1.2413e-02, -1.9791e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0509,  0.0060,  0.0014,  ..., -0.0002, -0.0140,  0.0107],
        [ 0.0128, -0.0571,  0.0112,  ...,  0.0035, -0.0170,  0.0144],
        [ 0.0040,  0.0107, -0.0563,  ..., -0.0147,  0.0050,  0.0111],
        ...,
        [ 0.0128,  0.0164, -0.0116,  ..., -0.0495, -0.0005, -0.0264],
        [-0.0061,  0.0118,  0.0056,  ...,  0.0217, -0.0618, -0.0045],
        [ 0.0004, -0.0143,  0.0096,  ...,  0.0174, -0.0073, -0.0772]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:17:16 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-07-01 07:17:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1796,  0.3782, -0.1489,  ..., -0.2374,  0.8457,  0.8125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5376, -0.3196, -1.1719,  ...,  0.1197,  0.1550, -0.1570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.4912,  0.8726,  1.0898,  ..., -0.2871,  1.7568,  3.1035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.3711,  0.4888, -1.9121,  ...,  0.7261,  2.1758,  0.7197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:17:16 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 07:17:16 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 07:18:42 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 07:20:05 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 07:21:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.7905e-03,  3.8123e-04, -1.8597e-03,  ...,  2.3289e-03,
         -1.0433e-03,  1.2517e-04],
        [-3.9577e-04, -1.3113e-04,  2.0905e-03,  ..., -1.7023e-03,
          7.8106e-04, -9.5987e-04],
        [ 6.9714e-04, -5.4502e-04,  7.4530e-04,  ..., -5.1689e-04,
          8.6403e-04,  1.2493e-04],
        ...,
        [ 7.2622e-04,  3.4237e-04, -9.1255e-05,  ...,  3.0689e-03,
         -1.2264e-03, -6.4468e-04],
        [ 9.1314e-04,  1.9007e-03,  3.0279e-04,  ...,  8.9359e-04,
          3.1185e-03, -5.9366e-04],
        [ 9.0599e-04, -1.6451e-03, -2.9545e-03,  ...,  2.2354e-03,
         -2.1935e-03,  3.2940e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0043, -0.0074, -0.0076,  ...,  0.0009,  0.0068, -0.0085],
        [ 0.0044, -0.0199, -0.0064,  ..., -0.0070, -0.0014,  0.0157],
        [ 0.0093,  0.0090,  0.0235,  ...,  0.0097, -0.0071,  0.0100],
        ...,
        [-0.0025,  0.0141, -0.0052,  ...,  0.0374,  0.0062,  0.0035],
        [ 0.0153, -0.0043,  0.0188,  ..., -0.0211,  0.0128, -0.0055],
        [-0.0026,  0.0134,  0.0041,  ..., -0.0007,  0.0142,  0.0271]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0071, -0.0238,  0.0054,  ...,  0.0118,  0.0041,  0.0114],
        [-0.0192, -0.0193,  0.0104,  ..., -0.0037, -0.0047,  0.0131],
        [-0.0233,  0.0331,  0.0249,  ...,  0.0049,  0.0173, -0.0040],
        ...,
        [-0.0158, -0.0115,  0.0050,  ...,  0.0197,  0.0083,  0.0149],
        [ 0.0181, -0.0224, -0.0046,  ...,  0.0110,  0.0202, -0.0012],
        [ 0.0034,  0.0145,  0.0062,  ...,  0.0081,  0.0017,  0.0323]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:21:32 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 07:21:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4224,  0.4290,  0.2095,  ..., -0.1412,  0.6562,  0.7378],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6338, -0.1095, -0.8022,  ...,  0.1017,  0.5151, -0.2028],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.2461,  1.3008,  0.2012,  ..., -0.1492,  2.4453,  4.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.1406,  1.6914, -1.5391,  ...,  0.7041,  1.7383,  3.4336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:21:32 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 07:21:32 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 07:22:57 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 07:24:25 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 07:25:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.2839e-04, -7.3433e-04, -1.2207e-04,  ...,  1.9073e-05,
         -1.2875e-05,  7.4482e-04],
        [-1.9622e-04, -2.2364e-04,  2.5463e-04,  ..., -3.6180e-05,
         -4.6253e-04, -1.7810e-04],
        [-3.5000e-04,  3.5858e-04, -5.7888e-04,  ...,  3.8767e-04,
         -9.2626e-05, -3.7217e-04],
        ...,
        [ 6.5184e-04,  4.6182e-04, -2.8849e-04,  ...,  3.7122e-04,
          2.0051e-04, -3.8719e-04],
        [ 8.0228e-05,  1.4949e-04,  2.1994e-05,  ..., -3.5477e-04,
         -7.5221e-05, -1.3685e-04],
        [-2.8539e-04,  1.8573e-04, -6.6638e-05,  ...,  4.6563e-04,
         -1.4794e-04,  2.0528e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.9177e-03,  1.0651e-02, -6.3801e-04,  ..., -9.0103e-03,
          7.5302e-03, -3.9902e-03],
        [-9.7427e-03, -5.8250e-03,  6.4087e-03,  ...,  1.2787e-02,
         -8.2970e-05, -1.2493e-03],
        [-4.0512e-03, -2.3556e-03, -1.2703e-02,  ...,  5.9700e-03,
          4.2534e-04,  1.9817e-03],
        ...,
        [ 1.1154e-02,  1.1505e-02, -8.0109e-03,  ..., -7.5340e-03,
          1.8320e-03, -4.6921e-03],
        [ 1.2608e-03,  1.0460e-02, -1.4961e-02,  ...,  1.1673e-02,
         -2.7714e-03,  5.1270e-03],
        [-1.2474e-02,  7.6981e-03, -2.2400e-02,  ...,  8.9874e-03,
          1.3294e-03, -6.5155e-03]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0329,  0.0242,  0.0069,  ...,  0.0112, -0.0032,  0.0307],
        [ 0.0023, -0.0457,  0.0077,  ..., -0.0078,  0.0131, -0.0103],
        [-0.0111, -0.0106, -0.0218,  ...,  0.0209, -0.0024,  0.0070],
        ...,
        [-0.0153,  0.0153, -0.0139,  ..., -0.0497, -0.0038, -0.0044],
        [ 0.0032,  0.0125, -0.0123,  ..., -0.0158, -0.0641,  0.0287],
        [ 0.0274,  0.0185, -0.0004,  ...,  0.0052, -0.0102, -0.0132]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:25:53 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 07:25:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1969,  0.2749,  0.2278,  ..., -0.1814,  0.4827,  0.8662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4827,  0.1749, -0.6685,  ...,  0.1238,  0.6392,  0.1689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 3.3398,  1.3574, -1.5459,  ..., -1.0332,  1.5137,  3.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4609,  0.8438, -2.7773,  ...,  0.0142,  1.6328,  3.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:25:53 root INFO     [order_1_approx] starting weight calculation for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 07:25:53 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 07:27:19 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 07:28:34 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 07:29:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.4542e-02, -1.1673e-03, -8.4400e-04,  ..., -9.8610e-04,
          1.3485e-03, -3.5992e-03],
        [-4.5991e-04,  9.0408e-03, -2.9278e-04,  ...,  1.4782e-04,
         -1.3256e-03, -1.4763e-03],
        [ 1.0052e-03, -1.4687e-03,  1.3771e-02,  ..., -1.8187e-03,
         -1.2102e-03,  1.1396e-03],
        ...,
        [-1.5926e-03, -1.2665e-03, -6.3086e-04,  ...,  1.5808e-02,
         -2.6035e-03, -9.2554e-04],
        [ 4.5705e-04,  3.4022e-04, -1.8702e-03,  ..., -1.1396e-03,
          2.1347e-02, -1.8225e-03],
        [-1.8415e-03,  1.2457e-05, -1.1292e-03,  ..., -2.1667e-03,
         -2.3305e-04,  2.1515e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 1.4023e-02,  3.9482e-04, -7.3624e-04,  ..., -5.9433e-03,
          2.9846e-02,  4.0054e-05],
        [ 1.2947e-02, -2.4433e-03,  5.5618e-03,  ..., -1.2436e-02,
          1.7776e-03, -1.9897e-02],
        [-7.9498e-03, -1.8021e-02,  1.2764e-02,  ..., -1.9665e-03,
          1.7366e-03, -3.0708e-03],
        ...,
        [ 4.2114e-03, -6.2027e-03, -2.3785e-03,  ...,  1.9974e-02,
         -4.6387e-03,  1.7197e-02],
        [ 1.4442e-02, -1.0513e-02, -1.3443e-02,  ..., -1.5621e-03,
          1.8616e-02,  1.7975e-02],
        [-2.9621e-03,  1.1345e-02, -2.7828e-03,  ...,  4.0627e-04,
         -1.8406e-03,  3.7384e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0117,  0.0133,  0.0256,  ...,  0.0163,  0.0266, -0.0023],
        [ 0.0267, -0.0821,  0.0182,  ...,  0.0137,  0.0199,  0.0047],
        [-0.0063, -0.0181, -0.0134,  ..., -0.0019,  0.0047,  0.0100],
        ...,
        [-0.0099,  0.0186, -0.0030,  ..., -0.0165,  0.0082, -0.0013],
        [-0.0043,  0.0065, -0.0145,  ...,  0.0148, -0.0075,  0.0096],
        [-0.0161,  0.0213, -0.0067,  ..., -0.0078,  0.0185, -0.0057]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:29:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you speak something, you are a speaker
If you perform something, you are a performer
If you mourn something, you are a mourner
If you announce something, you are a announcer
If you deliver something, you are a deliverer
If you suffer something, you are a sufferer
If you examine something, you are a examiner
If you compose something, you are a
2024-07-01 07:29:54 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 07:29:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2771,  0.3003, -0.0110,  ...,  0.0539,  0.0493,  0.0594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1544,  0.1116, -0.1493,  ..., -0.4155,  0.0623,  0.0295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4282,  0.2961, -0.0585,  ..., -0.4707, -0.7070,  0.2334],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0304,  0.2581,  0.1271,  ..., -0.7666, -0.2389, -0.1765],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:29:55 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:29:55 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 07:30:18 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 07:30:41 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 07:31:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.1001e-04, -1.2457e-05, -1.8549e-04,  ..., -2.1827e-04,
          7.7629e-04,  8.3923e-05],
        [-3.0422e-04, -8.5163e-04,  7.6711e-05,  ...,  2.5725e-04,
          4.5347e-04, -1.0937e-04],
        [ 8.8882e-04,  6.7413e-05, -1.2360e-03,  ..., -1.2910e-04,
         -5.3406e-04,  4.6349e-04],
        ...,
        [-5.0211e-04, -6.0511e-04,  2.5988e-04,  ..., -7.1192e-04,
          3.3760e-04, -6.6233e-04],
        [ 2.8324e-04, -3.9756e-05, -1.9813e-04,  ...,  4.5419e-04,
         -1.4639e-03, -6.0380e-05],
        [-1.5545e-04,  1.7929e-04,  1.4937e-04,  ..., -7.8321e-05,
         -3.9124e-04, -1.2140e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0314,  0.0055,  0.0044,  ...,  0.0005, -0.0121,  0.0043],
        [ 0.0005, -0.0339, -0.0016,  ..., -0.0029,  0.0002,  0.0040],
        [-0.0011, -0.0004, -0.0416,  ...,  0.0009, -0.0004, -0.0024],
        ...,
        [-0.0007, -0.0050, -0.0015,  ..., -0.0346, -0.0009,  0.0040],
        [-0.0012,  0.0051,  0.0020,  ..., -0.0017, -0.0429, -0.0009],
        [-0.0037, -0.0073, -0.0019,  ..., -0.0005,  0.0032, -0.0352]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0385, -0.0005,  0.0011,  ..., -0.0021, -0.0008,  0.0012],
        [ 0.0015, -0.0402,  0.0011,  ...,  0.0033,  0.0078,  0.0024],
        [-0.0045,  0.0020, -0.0367,  ..., -0.0027,  0.0020,  0.0025],
        ...,
        [ 0.0030,  0.0044,  0.0002,  ..., -0.0399,  0.0029,  0.0034],
        [-0.0040,  0.0029,  0.0013,  ..., -0.0006, -0.0371,  0.0070],
        [-0.0012, -0.0006, -0.0014,  ...,  0.0021,  0.0058, -0.0367]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:31:06 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 07:31:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4978,  0.5640, -0.0917,  ..., -0.2235, -0.5859,  0.4419],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1492,  0.2142,  0.0152,  ..., -0.7080, -0.1554, -0.1205],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5020,  0.5098,  0.0764,  ..., -0.8740, -0.5532, -0.1938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0214,  0.4346,  0.3022,  ..., -1.3438, -0.4375, -0.0261],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:31:06 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:31:06 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 07:31:31 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 07:31:55 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 07:32:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.1071e-03,  6.5279e-04,  5.9843e-04,  ..., -6.7234e-05,
         -6.6566e-04, -4.1175e-04],
        [ 2.3794e-04, -3.9253e-03,  5.3596e-04,  ..., -3.7503e-04,
         -3.5334e-04, -7.4291e-04],
        [ 5.9700e-04, -7.9536e-04, -2.3098e-03,  ..., -2.4891e-04,
         -2.7514e-04, -9.9897e-05],
        ...,
        [ 2.7966e-04, -3.3092e-04, -7.9346e-04,  ..., -3.3512e-03,
         -1.2417e-03, -6.5041e-04],
        [ 1.0090e-03,  5.9795e-04,  1.0691e-03,  ..., -7.8869e-04,
         -3.4943e-03, -4.7982e-05],
        [-1.8477e-04, -4.0865e-04, -1.3447e-04,  ..., -9.3603e-04,
          1.5676e-05, -2.9011e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0709, -0.0027, -0.0082,  ..., -0.0001,  0.0076, -0.0014],
        [-0.0005, -0.0792, -0.0023,  ..., -0.0004,  0.0030,  0.0062],
        [-0.0032, -0.0056, -0.0630,  ..., -0.0004,  0.0026, -0.0042],
        ...,
        [ 0.0080,  0.0141,  0.0030,  ..., -0.0696, -0.0021,  0.0008],
        [ 0.0058, -0.0090, -0.0010,  ..., -0.0013, -0.0488, -0.0007],
        [-0.0068, -0.0012, -0.0002,  ...,  0.0056,  0.0053, -0.0732]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.1890e-02,  9.8114e-03, -3.2825e-03,  ...,  5.6953e-03,
          1.2236e-03,  1.3943e-03],
        [-7.0620e-04, -5.8990e-02,  3.1471e-05,  ...,  5.9032e-04,
         -4.7150e-03,  4.9057e-03],
        [-2.9640e-03,  2.4338e-03, -4.7272e-02,  ...,  4.0894e-03,
          2.7390e-03,  1.0424e-03],
        ...,
        [-2.9602e-03,  6.6872e-03, -2.1515e-03,  ..., -5.3619e-02,
         -6.4964e-03,  4.8637e-03],
        [ 2.0180e-03, -4.0398e-03,  4.0092e-03,  ...,  9.4509e-04,
         -5.3436e-02, -3.7289e-04],
        [ 1.0242e-03, -2.0580e-03, -1.6165e-03,  ..., -3.2673e-03,
          7.5378e-03, -5.9692e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:32:21 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 07:32:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5762,  0.3638, -0.0818,  ..., -0.5786, -0.8950,  0.2815],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0637,  0.4016,  0.2004,  ..., -1.1533, -0.3689, -0.3086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.4358,  0.6362, -0.1753,  ..., -0.6938, -0.5884, -0.2773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1617,  0.3730,  0.3076,  ..., -0.9189, -0.6431,  0.2800],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:32:21 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:32:21 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 07:32:46 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 07:33:13 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 07:33:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.8744e-03, -2.3282e-04, -1.9093e-03,  ...,  4.1556e-04,
         -2.8753e-04, -4.2701e-04],
        [-2.7561e-04, -3.7670e-03, -4.3941e-04,  ...,  4.6551e-05,
         -1.3733e-04, -2.0206e-05],
        [-2.2163e-03, -6.6376e-04, -3.9597e-03,  ..., -9.3639e-05,
          5.8651e-04,  4.0793e-04],
        ...,
        [-7.1430e-04,  4.4775e-04, -3.9244e-04,  ..., -3.3741e-03,
          5.2357e-04,  3.5429e-04],
        [-7.5877e-05,  2.5988e-04, -3.3069e-04,  ...,  4.2844e-04,
         -3.3264e-03, -2.0523e-03],
        [ 3.8290e-04, -2.2364e-04, -1.2743e-04,  ...,  5.7173e-04,
          4.4298e-04, -4.7607e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0409, -0.0051,  0.0010,  ...,  0.0017, -0.0019,  0.0020],
        [-0.0129, -0.0423,  0.0005,  ..., -0.0003, -0.0042, -0.0033],
        [ 0.0073,  0.0028, -0.0348,  ..., -0.0031,  0.0007,  0.0043],
        ...,
        [-0.0041,  0.0030, -0.0035,  ..., -0.0408,  0.0067,  0.0044],
        [-0.0043,  0.0057, -0.0017,  ...,  0.0009, -0.0406,  0.0022],
        [-0.0109,  0.0019,  0.0006,  ..., -0.0024, -0.0050, -0.0414]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0331, -0.0014,  0.0029,  ...,  0.0002, -0.0014, -0.0059],
        [-0.0013, -0.0346,  0.0062,  ...,  0.0032, -0.0021,  0.0075],
        [ 0.0027, -0.0010, -0.0295,  ...,  0.0026, -0.0051,  0.0017],
        ...,
        [-0.0018,  0.0028, -0.0029,  ..., -0.0260,  0.0037,  0.0024],
        [-0.0056, -0.0023,  0.0005,  ..., -0.0080, -0.0329, -0.0049],
        [-0.0063, -0.0050, -0.0041,  ..., -0.0021,  0.0057, -0.0333]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:33:41 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 07:33:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6641,  0.6226,  0.0923,  ..., -1.0459, -0.6987, -0.2900],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0125,  0.6177,  0.4321,  ..., -1.8418, -0.6289, -0.0705],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6113,  0.9165, -0.0286,  ..., -0.7515, -0.1716, -0.7080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1444,  0.4995,  0.2203,  ..., -1.3838, -0.0742,  0.4580],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:33:41 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:33:41 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 07:34:10 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 07:34:38 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 07:35:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.0638e-03,  1.3428e-03,  1.1177e-03,  ..., -5.4264e-04,
          5.3024e-04, -1.6809e-05],
        [ 1.3647e-03, -2.9869e-03, -3.9625e-04,  ...,  4.4298e-04,
          1.1835e-03,  9.8610e-04],
        [ 2.2626e-04,  4.2844e-04, -2.1114e-03,  ...,  3.5930e-04,
          8.2207e-04, -2.4223e-04],
        ...,
        [ 6.4898e-04, -1.5545e-03, -1.5354e-04,  ..., -1.6861e-03,
         -9.2125e-04,  3.5453e-04],
        [ 1.8024e-04, -9.7275e-05, -7.2384e-04,  ..., -1.8120e-03,
         -2.1286e-03, -6.9904e-04],
        [-6.2847e-04,  3.8123e-04,  6.0081e-05,  ..., -1.3471e-04,
         -9.6607e-04, -2.9602e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0469,  0.0039,  0.0061,  ...,  0.0018, -0.0050,  0.0012],
        [ 0.0006, -0.0399, -0.0038,  ...,  0.0028,  0.0027, -0.0090],
        [-0.0046, -0.0155, -0.0433,  ..., -0.0008,  0.0042,  0.0022],
        ...,
        [-0.0006,  0.0028, -0.0029,  ..., -0.0500,  0.0053,  0.0040],
        [-0.0132, -0.0006, -0.0058,  ..., -0.0051, -0.0420,  0.0011],
        [ 0.0074,  0.0010,  0.0044,  ...,  0.0036,  0.0009, -0.0455]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.9805e-02, -1.4448e-03,  1.0330e-02,  ...,  2.9678e-03,
         -2.0981e-05,  3.7551e-04],
        [ 6.9427e-04, -4.1931e-02, -2.4986e-03,  ..., -1.1072e-03,
          1.0700e-03, -1.3990e-03],
        [-7.4806e-03, -7.5912e-03, -4.6326e-02,  ...,  3.2406e-03,
         -8.7280e-03,  2.8439e-03],
        ...,
        [-2.6932e-03,  1.4648e-03, -9.1076e-05,  ..., -4.7058e-02,
          4.6768e-03, -1.0277e-02],
        [-3.6755e-03, -4.8676e-03, -1.7490e-03,  ..., -8.4534e-03,
         -3.7537e-02, -3.7861e-03],
        [ 8.2970e-05,  2.9812e-03,  1.7910e-03,  ..., -5.3177e-03,
         -3.5439e-03, -4.5349e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:35:07 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 07:35:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4600,  0.6284, -0.1718,  ..., -0.6812, -0.5786, -0.3376],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1844,  0.3799,  0.3303,  ..., -0.9473, -0.6694,  0.2803],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.3711,  1.6621,  0.1179,  ..., -1.2754, -0.0085, -0.0698],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1642,  0.6973,  0.6875,  ..., -1.1816, -0.5449,  0.2151],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:35:07 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:35:07 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 07:35:41 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 07:36:15 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 07:36:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3918e-03,  2.7084e-03, -4.0359e-03,  ...,  2.7657e-05,
         -5.9032e-04,  1.0271e-03],
        [ 6.4850e-04, -9.6178e-04, -2.2430e-03,  ..., -1.6270e-03,
          2.5606e-04, -4.2558e-05],
        [ 1.7624e-03,  1.1311e-03, -1.6212e-03,  ..., -1.0605e-03,
         -2.3532e-04, -1.5249e-03],
        ...,
        [-8.3494e-04,  3.2806e-04, -2.5845e-04,  ..., -4.6349e-03,
         -3.3321e-03,  4.2725e-04],
        [-9.7561e-04,  4.6587e-04, -7.4434e-04,  ...,  1.5593e-03,
         -3.6716e-04, -1.0004e-03],
        [-5.9986e-04, -1.4830e-03, -1.5774e-03,  ..., -6.4707e-04,
         -1.9569e-03, -1.0557e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.7595e-02,  5.2948e-03,  9.3126e-04,  ..., -1.2901e-02,
         -3.6488e-03,  2.7390e-03],
        [-7.2289e-04, -9.2285e-02, -5.7716e-03,  ...,  3.8071e-03,
          3.0422e-04,  5.1231e-03],
        [-6.7368e-03, -6.8817e-03, -8.7708e-02,  ..., -2.8706e-03,
          3.8795e-03,  8.2245e-03],
        ...,
        [-9.5215e-03, -2.4090e-03, -6.3858e-03,  ..., -9.1370e-02,
         -1.3840e-02, -1.5526e-03],
        [ 3.9291e-04, -1.3870e-02, -3.9101e-03,  ..., -2.1610e-03,
         -9.9915e-02,  3.3932e-03],
        [-4.8943e-03,  4.6768e-03,  7.5817e-05,  ..., -8.4991e-03,
          3.4580e-03, -9.0637e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1004, -0.0097,  0.0025,  ..., -0.0025, -0.0030,  0.0048],
        [-0.0111, -0.1010,  0.0027,  ...,  0.0053, -0.0029,  0.0056],
        [ 0.0028,  0.0020, -0.0956,  ..., -0.0015,  0.0167,  0.0114],
        ...,
        [-0.0054,  0.0026, -0.0104,  ..., -0.0828,  0.0044,  0.0036],
        [-0.0011, -0.0042,  0.0018,  ...,  0.0089, -0.0909,  0.0020],
        [-0.0057,  0.0094,  0.0095,  ...,  0.0009, -0.0057, -0.1030]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:36:50 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 07:36:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6079,  0.9043, -0.0399,  ..., -0.7061, -0.1869, -0.7358],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1581,  0.5444,  0.2218,  ..., -1.4346, -0.0937,  0.4895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.7305,  2.2324, -0.0123,  ..., -1.0762,  0.1677, -0.8530],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1666,  0.6123,  0.3831,  ..., -0.7383, -0.5347, -0.1462],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:36:50 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:36:50 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 07:37:23 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 07:37:51 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 07:38:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.4452e-03, -6.3992e-04,  2.1057e-03,  ..., -8.3351e-04,
          1.6284e-04,  4.2319e-04],
        [ 9.4366e-04, -3.6545e-03,  1.5526e-03,  ..., -1.3161e-04,
          1.2836e-03, -1.0223e-03],
        [ 4.1246e-04,  2.0218e-03, -3.2368e-03,  ..., -4.3535e-04,
         -1.1234e-03, -1.1557e-04],
        ...,
        [-5.7316e-04,  1.9779e-03, -9.2220e-04,  ..., -2.5272e-03,
         -1.3103e-03,  2.3956e-03],
        [ 1.5984e-03, -1.6823e-03,  1.5869e-03,  ..., -8.7404e-04,
         -5.8556e-04, -1.9226e-03],
        [ 8.5115e-04, -9.9659e-04,  4.5347e-04,  ..., -8.7619e-05,
         -1.1892e-03, -1.1578e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0883, -0.0031,  0.0008,  ..., -0.0005,  0.0120, -0.0042],
        [ 0.0035, -0.0954,  0.0138,  ...,  0.0078,  0.0045, -0.0019],
        [ 0.0060,  0.0055, -0.0762,  ..., -0.0030, -0.0059, -0.0075],
        ...,
        [ 0.0084, -0.0002,  0.0070,  ..., -0.0962,  0.0014,  0.0028],
        [-0.0109,  0.0131,  0.0105,  ..., -0.0022, -0.0935,  0.0018],
        [ 0.0043,  0.0112, -0.0006,  ..., -0.0086,  0.0049, -0.0936]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1047, -0.0009, -0.0005,  ...,  0.0009, -0.0011, -0.0010],
        [ 0.0026, -0.0894, -0.0065,  ...,  0.0056, -0.0076,  0.0022],
        [-0.0020, -0.0019, -0.0911,  ...,  0.0008,  0.0002,  0.0019],
        ...,
        [ 0.0023,  0.0076,  0.0096,  ..., -0.1046, -0.0067, -0.0018],
        [-0.0055, -0.0007, -0.0055,  ..., -0.0040, -0.0934, -0.0066],
        [-0.0058, -0.0096, -0.0098,  ..., -0.0073, -0.0019, -0.0996]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:38:29 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 07:38:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.2266,  1.5273,  0.0777,  ..., -1.0928, -0.0159, -0.1023],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1565,  0.6953,  0.5991,  ..., -1.0762, -0.5127,  0.1770],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.7725,  1.2803,  0.1226,  ..., -1.0918,  0.2416, -0.9673],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2920,  0.2385,  0.2859,  ..., -1.0342, -1.0605, -0.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:38:29 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:38:29 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 07:39:09 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 07:39:48 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 07:40:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.6883e-03, -2.0564e-05,  4.7612e-04,  ...,  2.6894e-03,
         -3.5267e-03,  1.2865e-03],
        [-1.5259e-04, -3.3188e-03,  1.4651e-04,  ...,  4.0174e-04,
          3.2215e-03, -1.7500e-03],
        [ 9.8705e-05, -5.7602e-04, -4.7188e-03,  ..., -1.9760e-03,
         -1.1110e-03, -1.1549e-03],
        ...,
        [-1.9550e-04, -9.1672e-05,  1.2379e-03,  ..., -6.2523e-03,
          1.1072e-03,  2.2545e-03],
        [ 7.8022e-05, -1.6212e-04, -2.7657e-03,  ...,  6.4135e-04,
         -2.6760e-03,  3.1757e-04],
        [ 3.1052e-03, -2.7771e-03, -1.4954e-03,  ..., -2.2678e-03,
          2.5005e-03, -4.7684e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0909,  0.0108,  0.0034,  ..., -0.0106, -0.0017,  0.0073],
        [-0.0067, -0.0799, -0.0094,  ..., -0.0097,  0.0018,  0.0007],
        [ 0.0086, -0.0110, -0.0886,  ..., -0.0052, -0.0107,  0.0080],
        ...,
        [-0.0175,  0.0073,  0.0107,  ..., -0.0865, -0.0055, -0.0041],
        [ 0.0004, -0.0059,  0.0040,  ...,  0.0157, -0.0772,  0.0015],
        [-0.0029, -0.0020, -0.0035,  ...,  0.0064, -0.0006, -0.1036]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1031,  0.0023,  0.0119,  ..., -0.0076, -0.0044, -0.0090],
        [ 0.0010, -0.1049, -0.0004,  ...,  0.0028,  0.0164, -0.0037],
        [ 0.0052,  0.0019, -0.0977,  ..., -0.0027,  0.0075,  0.0121],
        ...,
        [-0.0016, -0.0008, -0.0028,  ..., -0.1045,  0.0096,  0.0014],
        [ 0.0077,  0.0076,  0.0032,  ...,  0.0137, -0.1016, -0.0030],
        [-0.0054, -0.0030,  0.0035,  ...,  0.0131,  0.0045, -0.1014]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:40:29 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 07:40:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.4463,  1.9062, -0.0238,  ..., -0.8374,  0.1256, -0.7485],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1523,  0.5923,  0.3350,  ..., -0.6499, -0.4958, -0.1599],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.9482,  0.3809,  0.2178,  ..., -1.4414,  0.4453, -0.6567],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2683, -0.0439,  0.1667,  ..., -0.9092, -1.6660,  0.5684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:40:29 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:40:29 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 07:41:03 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 07:41:39 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 07:42:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.2316e-03,  1.7643e-04,  7.1144e-04,  ..., -4.3869e-05,
          8.3065e-04, -9.2554e-04],
        [-2.1911e-04, -4.1733e-03,  3.7169e-04,  ..., -2.2697e-03,
          1.6642e-03, -1.9569e-03],
        [-5.5218e-04,  2.9411e-03, -3.5439e-03,  ..., -1.4973e-03,
          1.3866e-03, -1.1749e-03],
        ...,
        [-1.2608e-03, -2.4872e-03, -1.2398e-03,  ..., -2.5406e-03,
          1.7118e-03,  2.1076e-03],
        [ 1.6298e-03,  4.2748e-04,  1.9550e-04,  ..., -1.7481e-03,
         -5.6000e-03, -1.7052e-03],
        [ 3.3970e-03,  6.1321e-04, -1.4329e-04,  ..., -3.9530e-04,
         -8.7547e-04, -2.1935e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.7158e-02,  4.7913e-03, -8.6021e-04,  ..., -3.0003e-03,
         -2.2030e-03,  1.9217e-03],
        [ 1.4591e-03, -1.0229e-01,  5.6915e-03,  ...,  1.5640e-03,
         -4.8370e-03,  5.4054e-03],
        [-3.1471e-03, -1.2321e-03, -8.3984e-02,  ...,  7.1621e-04,
          1.3695e-03, -4.2439e-04],
        ...,
        [ 1.1230e-02,  8.4991e-03,  3.9577e-04,  ..., -1.1182e-01,
          6.7329e-03,  5.0430e-03],
        [-7.1144e-03,  2.6703e-04, -7.0267e-03,  ...,  1.0586e-04,
         -9.0881e-02,  1.0414e-02],
        [ 1.1612e-02,  2.5940e-03, -5.3902e-03,  ..., -9.8572e-03,
          3.8567e-03, -1.0773e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0284e-01,  1.5732e-02, -1.2999e-03,  ..., -9.6893e-03,
          6.5575e-03, -2.6131e-04],
        [ 1.5688e-03, -1.1371e-01,  7.7209e-03,  ..., -4.2114e-03,
         -4.3716e-03,  1.3618e-02],
        [-2.1553e-03, -2.6531e-03, -1.0547e-01,  ..., -1.0750e-02,
         -3.3474e-03,  6.7368e-03],
        ...,
        [ 4.7150e-03,  1.7548e-03, -1.4633e-02,  ..., -1.0583e-01,
         -1.1063e-04, -3.0594e-03],
        [-7.0877e-03,  1.1902e-03, -5.1880e-04,  ..., -2.5406e-03,
         -1.0132e-01,  1.0643e-02],
        [ 4.9210e-03, -2.6627e-03, -9.6283e-03,  ...,  8.8787e-04,
          7.9269e-03, -1.0925e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:42:21 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 07:42:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.3691,  0.9824,  0.0348,  ..., -0.7964,  0.1586, -0.7686],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2607,  0.2006,  0.1777,  ..., -0.8223, -0.8687, -0.4863],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.2148,  0.5122,  0.8315,  ..., -2.3359,  0.4507, -1.1660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1099,  0.0671,  0.3306,  ..., -1.0283, -1.8027, -0.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:42:21 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:42:22 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 07:43:11 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 07:43:58 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 07:44:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1591e-03,  1.4515e-03,  2.1553e-03,  ..., -3.3569e-03,
          1.9779e-03, -2.5330e-03],
        [ 2.5501e-03, -5.4550e-04, -8.3685e-04,  ..., -3.5286e-04,
         -4.6039e-04,  2.6512e-03],
        [ 3.0804e-04, -3.2291e-03,  9.1362e-04,  ...,  6.8712e-04,
          1.0853e-03, -8.3447e-06],
        ...,
        [ 1.2093e-03, -2.2278e-03, -2.6560e-04,  ...,  3.2959e-03,
          9.4509e-04, -2.3055e-04],
        [-1.1797e-03, -1.3170e-03,  2.5864e-03,  ..., -2.2106e-03,
         -4.5824e-04,  6.9141e-05],
        [ 7.3910e-04,  2.4853e-03, -1.4143e-03,  ..., -3.3855e-05,
         -1.9894e-03, -6.5851e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1401e-01, -6.2599e-03, -5.3253e-03,  ..., -2.3842e-05,
          1.5823e-02, -6.2256e-03],
        [ 1.7118e-03, -1.3098e-01, -8.0490e-03,  ...,  1.1665e-02,
          5.9814e-03, -1.0880e-02],
        [-8.0032e-03,  1.2299e-02, -1.2708e-01,  ..., -7.4387e-03,
         -1.0452e-02,  1.2236e-03],
        ...,
        [-6.4697e-03,  2.2888e-03,  1.1765e-02,  ..., -1.1285e-01,
          9.6130e-03, -2.8858e-03],
        [-8.0109e-03,  8.2245e-03,  5.8594e-03,  ..., -7.4234e-03,
         -1.2097e-01,  1.4282e-02],
        [ 1.2016e-04,  1.5421e-03, -1.1307e-02,  ..., -1.1658e-02,
         -9.9335e-03, -1.0638e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.6699e-01, -9.8877e-03, -8.4000e-03,  ...,  4.5738e-03,
          1.1703e-02,  2.5406e-03],
        [-1.2085e-02, -1.7078e-01, -1.0468e-02,  ...,  3.7231e-03,
         -2.0027e-03, -1.1635e-04],
        [-6.6528e-03, -8.4686e-04, -1.5051e-01,  ...,  3.9673e-03,
         -3.2959e-03, -1.2276e-02],
        ...,
        [-1.0239e-02,  1.3657e-02,  1.7548e-02,  ..., -1.6003e-01,
         -1.4709e-02,  4.0016e-03],
        [ 7.1526e-04, -3.7718e-04,  1.0475e-02,  ..., -6.5842e-03,
         -1.5906e-01, -7.5798e-03],
        [-8.0795e-03,  1.6632e-02, -5.4817e-03,  ..., -1.1009e-02,
         -1.7410e-02, -1.4612e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:44:48 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 07:44:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.3809,  0.2527,  0.1067,  ..., -0.9551,  0.2898, -0.5186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1990, -0.0486,  0.0849,  ..., -0.6421, -1.2529,  0.3992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.1289,  1.5566,  0.5996,  ..., -1.5586,  0.9126, -1.2168],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2778,  0.8135, -0.0093,  ..., -0.9668, -1.6709,  0.1016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:44:48 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:44:48 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 07:45:37 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 07:46:27 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 07:47:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3479e-03,  2.8419e-03, -2.4529e-03,  ...,  9.8228e-04,
         -1.2188e-03,  9.2316e-04],
        [-1.7471e-03,  4.4327e-03,  1.3714e-03,  ..., -6.8760e-04,
          1.6260e-04,  4.8943e-03],
        [-1.3018e-04, -1.0138e-03, -5.2023e-04,  ...,  3.3894e-03,
          1.2817e-03, -2.2659e-03],
        ...,
        [-2.3842e-05,  8.9788e-04,  2.4319e-03,  ..., -1.4281e-04,
         -3.0346e-03, -6.2799e-04],
        [ 1.7052e-03, -1.6613e-03,  1.1711e-03,  ...,  3.0003e-03,
          1.4038e-03, -4.7445e-04],
        [-1.0338e-03,  1.0109e-04, -1.8387e-03,  ..., -1.8394e-04,
         -1.2999e-03,  5.7220e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1719e-01,  3.9787e-03, -6.1569e-03,  ...,  9.8572e-03,
          6.6185e-03, -5.4970e-03],
        [ 1.0551e-02, -1.2927e-01, -2.5272e-04,  ...,  6.4430e-03,
         -1.1322e-02,  2.8667e-03],
        [ 3.8147e-03,  8.5220e-03, -1.1957e-01,  ...,  1.4687e-02,
          9.4376e-03, -6.1722e-03],
        ...,
        [ 1.0391e-02, -9.9182e-05, -8.4686e-03,  ..., -8.7463e-02,
          6.7825e-03, -1.5472e-02],
        [ 1.1185e-02, -7.6675e-03,  1.2016e-04,  ...,  3.8548e-03,
         -1.0529e-01,  1.0910e-03],
        [ 9.1782e-03,  6.4240e-03, -1.0502e-04,  ..., -7.4730e-03,
          5.6610e-03, -1.0748e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0822e-01,  1.5961e-02,  1.0284e-02,  ...,  1.5610e-02,
         -9.4910e-03,  4.6310e-03],
        [ 8.2550e-03, -9.8389e-02,  3.8261e-03,  ...,  3.8452e-03,
         -1.2146e-02, -3.3302e-03],
        [-5.5656e-03,  1.9741e-03, -1.0785e-01,  ...,  8.1482e-03,
         -1.3466e-03,  4.8599e-03],
        ...,
        [ 6.6452e-03, -3.2425e-03, -2.2736e-03,  ..., -1.0687e-01,
          6.4278e-03, -6.8970e-03],
        [ 1.6766e-03, -5.0354e-03, -5.7564e-03,  ...,  2.8973e-03,
         -1.1871e-01,  1.6212e-03],
        [ 2.8458e-03, -4.5700e-03,  5.1460e-03,  ..., -1.1873e-04,
          7.9155e-05, -1.1121e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:47:20 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 07:47:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.5000,  0.3257,  0.4753,  ..., -1.5146,  0.2693, -0.7915],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0645,  0.0296,  0.1735,  ..., -0.7129, -1.2451, -0.2126],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.7461,  2.8379,  0.3242,  ..., -1.4609,  1.1133, -1.0693],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2386,  1.1973,  0.2524,  ...,  0.0977, -0.8003, -0.2288],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:47:20 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:47:20 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 07:48:10 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 07:49:01 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 07:49:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.2583e-03,  4.0054e-05, -1.0338e-03,  ..., -4.5280e-03,
          3.8967e-03, -2.5501e-03],
        [ 2.0847e-03,  1.2398e-03,  4.5657e-05,  ..., -1.4992e-03,
          1.5869e-03,  4.5052e-03],
        [-1.3103e-03, -1.8616e-03,  5.2986e-03,  ..., -1.3599e-03,
          3.7117e-03, -1.1206e-03],
        ...,
        [ 2.9397e-04,  2.2964e-03,  7.3738e-03,  ...,  4.7302e-03,
         -4.1962e-03,  3.7594e-03],
        [-3.9787e-03, -4.0936e-04,  2.4652e-04,  ..., -2.5024e-03,
          3.7880e-03,  5.0659e-03],
        [-2.4204e-03,  3.6087e-03,  1.8892e-03,  ..., -1.9188e-03,
         -1.9064e-03, -1.3590e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1866,  0.0074, -0.0066,  ..., -0.0117,  0.0012, -0.0080],
        [-0.0057, -0.1940, -0.0017,  ..., -0.0051,  0.0151, -0.0068],
        [ 0.0028, -0.0057, -0.1770,  ..., -0.0039, -0.0058, -0.0139],
        ...,
        [-0.0054,  0.0091,  0.0068,  ..., -0.1858,  0.0031, -0.0022],
        [-0.0096,  0.0154,  0.0011,  ...,  0.0098, -0.1915, -0.0029],
        [-0.0050,  0.0113, -0.0111,  ..., -0.0053, -0.0067, -0.1918]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.3340e-01,  1.3680e-02,  1.8768e-02,  ..., -1.9958e-02,
         -3.3226e-03, -1.1444e-02],
        [ 3.2921e-03, -2.4377e-01, -6.5804e-03,  ..., -1.2062e-02,
          2.6417e-03,  1.1749e-03],
        [ 1.2299e-02,  4.9973e-03, -2.2021e-01,  ...,  2.1324e-03,
          8.6746e-03, -1.6083e-02],
        ...,
        [-3.5400e-03,  7.4768e-03,  3.1204e-03,  ..., -2.4670e-01,
          1.9547e-02, -4.9706e-03],
        [-1.2535e-02, -5.3864e-03,  3.5782e-03,  ...,  2.4170e-02,
         -2.2363e-01,  5.6458e-04],
        [ 5.1498e-05,  4.3259e-03, -1.4229e-02,  ..., -1.4648e-02,
         -4.2038e-03, -2.3706e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:49:55 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 07:49:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.4736,  1.0371,  0.3308,  ..., -1.0352,  0.5962, -0.8999],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1923,  0.6304, -0.0562,  ..., -0.7495, -1.3105,  0.0288],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.4160,  3.3008,  0.4531,  ..., -2.5430,  1.1035,  0.2402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.4312,  1.1104, -0.1597,  ..., -0.0503, -1.0938,  0.0415],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:49:55 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:49:55 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 07:50:50 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 07:51:42 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 07:52:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.5019e-03,  7.3004e-04,  1.1940e-03,  ..., -6.7997e-04,
         -1.6479e-03, -1.0929e-03],
        [-1.9245e-03, -2.8896e-03, -1.9007e-03,  ..., -7.2122e-05,
         -2.3861e-03,  1.3752e-03],
        [-3.6430e-03,  4.0627e-03, -7.2594e-03,  ..., -1.9035e-03,
         -1.8139e-03, -4.2305e-03],
        ...,
        [ 2.5158e-03,  4.2510e-04, -1.9722e-03,  ..., -6.5651e-03,
          1.9703e-03, -2.2144e-03],
        [-2.0397e-04,  1.7166e-04, -4.0970e-03,  ..., -2.7752e-03,
         -6.7368e-03,  1.5411e-03],
        [ 3.2959e-03,  1.7595e-03,  1.1597e-03,  ...,  5.2357e-04,
         -5.2595e-04, -4.3831e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0840, -0.0047,  0.0086,  ...,  0.0114, -0.0028, -0.0030],
        [ 0.0057, -0.0933,  0.0042,  ...,  0.0050, -0.0089,  0.0060],
        [-0.0129, -0.0064, -0.0961,  ..., -0.0047, -0.0068,  0.0028],
        ...,
        [-0.0120,  0.0009, -0.0010,  ..., -0.0739,  0.0152, -0.0099],
        [-0.0070,  0.0146, -0.0093,  ..., -0.0002, -0.0926,  0.0112],
        [ 0.0040,  0.0055, -0.0085,  ...,  0.0088,  0.0104, -0.0887]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.8064e-02, -7.2098e-03, -8.7357e-03,  ...,  9.7885e-03,
         -7.5912e-03, -2.8610e-05],
        [ 5.3940e-03, -9.2896e-02, -6.2866e-03,  ...,  6.6757e-03,
          5.1384e-03,  2.3941e-02],
        [-4.3678e-03, -1.0117e-02, -9.3323e-02,  ..., -7.7286e-03,
         -3.5419e-03,  9.4452e-03],
        ...,
        [-7.1526e-03, -3.9291e-03,  7.4806e-03,  ..., -8.3862e-02,
          1.0223e-03, -3.2043e-04],
        [-1.5430e-03,  7.8278e-03, -1.3214e-02,  ...,  2.2430e-03,
         -9.5703e-02,  3.0041e-04],
        [ 2.1744e-03,  4.8637e-03, -2.6455e-03,  ...,  1.4740e-02,
          7.0000e-04, -8.3374e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:52:39 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 07:52:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.7676,  1.7490,  0.1791,  ..., -0.8994,  0.6914, -0.7065],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1818,  0.8716,  0.1697,  ...,  0.0510, -0.5933, -0.1980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.6328,  2.8359,  0.6021,  ..., -2.2129,  2.3887,  0.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.5327,  0.6992, -0.3662,  ..., -0.2015, -0.5444,  0.1965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:52:39 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:52:39 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 07:53:34 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 07:54:31 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 07:55:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.1078e-02,  3.3092e-03, -1.3170e-03,  ..., -2.2621e-03,
          4.5357e-03, -7.8659e-03],
        [-2.9545e-03, -2.2335e-03, -6.9275e-03,  ...,  5.1928e-04,
         -4.2839e-03, -1.8482e-03],
        [-2.5024e-03, -4.8876e-04, -4.8790e-03,  ..., -1.4029e-03,
         -2.3899e-03, -4.6654e-03],
        ...,
        [ 1.7262e-03,  2.9755e-03,  3.3913e-03,  ..., -3.9339e-06,
         -5.1689e-04,  2.2850e-03],
        [ 6.2447e-03, -1.8587e-03,  1.7242e-03,  ..., -2.2621e-03,
         -1.5419e-02,  8.2970e-04],
        [-9.1171e-04,  9.2468e-03,  2.3212e-03,  ..., -4.2992e-03,
         -2.3079e-03, -1.2840e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.4783e-01,  1.0538e-03, -3.6888e-03,  ..., -1.2230e-02,
          1.2543e-02,  1.0681e-02],
        [ 9.0265e-04, -1.4539e-01, -9.9411e-03,  ..., -9.2468e-03,
          6.9733e-03,  2.0248e-02],
        [ 7.7477e-03,  1.7227e-02, -1.2756e-01,  ..., -1.5610e-02,
         -7.4081e-03, -1.4206e-02],
        ...,
        [ 9.6321e-05,  9.5272e-04,  4.8332e-03,  ..., -1.4636e-01,
         -5.5389e-03,  5.9128e-03],
        [ 1.6068e-02,  1.4000e-02,  3.3550e-03,  ...,  4.5276e-04,
         -1.4087e-01,  2.5997e-03],
        [ 1.0967e-03, -7.6408e-03,  3.6831e-03,  ..., -2.4734e-02,
          1.1101e-02, -1.3708e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1399, -0.0016, -0.0007,  ..., -0.0078,  0.0103,  0.0126],
        [ 0.0013, -0.1434, -0.0014,  ..., -0.0014, -0.0038,  0.0139],
        [ 0.0058,  0.0084, -0.1511,  ..., -0.0172,  0.0004, -0.0113],
        ...,
        [-0.0072, -0.0011, -0.0073,  ..., -0.1360, -0.0005, -0.0058],
        [ 0.0013,  0.0096,  0.0014,  ...,  0.0037, -0.1569,  0.0046],
        [-0.0010,  0.0066,  0.0067,  ..., -0.0122,  0.0110, -0.1433]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:55:29 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-07-01 07:55:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.3906,  1.8125,  0.2098,  ..., -1.4033,  0.6440,  0.0771],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2488,  0.6816, -0.1205,  ..., -0.0471, -0.6650, -0.0294],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.4209,  3.3477,  0.8237,  ..., -2.9648,  3.0293, -0.3765],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.7910,  0.8276,  0.0281,  ..., -0.0355, -1.1367, -0.0117],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:55:29 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:55:29 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 07:56:27 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 07:57:27 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 07:58:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.1636e-05, -4.2229e-03,  4.1676e-04,  ...,  2.5892e-04,
         -7.6904e-03, -2.0206e-04],
        [-1.9836e-03, -2.1896e-03, -3.1624e-03,  ..., -1.6618e-04,
          5.7220e-03, -2.5826e-03],
        [-3.2196e-03, -4.5929e-03, -4.1122e-03,  ...,  6.2790e-03,
         -1.7672e-03,  2.2888e-03],
        ...,
        [-6.0499e-05,  2.4452e-03, -8.5068e-03,  ...,  1.8930e-03,
          7.2241e-04, -4.1428e-03],
        [-1.4896e-03, -2.3327e-03,  1.4057e-03,  ...,  9.8896e-04,
          4.1122e-03,  7.8278e-03],
        [ 1.8597e-05,  1.0252e-03, -9.3412e-04,  ...,  1.2550e-03,
         -1.7500e-03, -3.6907e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1149,  0.0153,  0.0034,  ...,  0.0008, -0.0084, -0.0016],
        [ 0.0072, -0.1146,  0.0065,  ..., -0.0005, -0.0015,  0.0069],
        [-0.0165, -0.0091, -0.1027,  ..., -0.0035,  0.0121,  0.0027],
        ...,
        [-0.0074, -0.0050, -0.0105,  ..., -0.1096,  0.0115,  0.0068],
        [-0.0037, -0.0103,  0.0142,  ...,  0.0015, -0.1050,  0.0064],
        [-0.0045,  0.0045, -0.0134,  ..., -0.0095,  0.0087, -0.1110]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1116,  0.0099, -0.0012,  ..., -0.0152, -0.0042, -0.0014],
        [ 0.0106, -0.1103, -0.0027,  ...,  0.0119,  0.0025,  0.0029],
        [-0.0032, -0.0139, -0.0995,  ..., -0.0053,  0.0043, -0.0088],
        ...,
        [ 0.0017,  0.0029, -0.0007,  ..., -0.1144,  0.0180, -0.0039],
        [-0.0128, -0.0032, -0.0085,  ...,  0.0094, -0.0978, -0.0041],
        [-0.0147,  0.0029, -0.0016,  ..., -0.0106,  0.0042, -0.1082]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 07:58:29 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-07-01 07:58:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.3994,  1.4355,  0.2942,  ..., -1.1260,  1.2207,  0.0162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3308,  0.4011, -0.2135,  ..., -0.1334, -0.3259,  0.0887],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.6162,  3.3184,  1.4385,  ..., -2.9414,  2.6738, -0.1167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.0049,  0.5342, -0.0403,  ...,  0.9526, -1.2793,  0.6797],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 07:58:29 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 07:58:30 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 07:59:31 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 08:00:31 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 08:01:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.9809e-03,  1.4782e-03, -6.2370e-04,  ...,  3.7026e-04,
         -8.5497e-04, -1.4439e-03],
        [ 3.4161e-03,  2.7390e-03,  2.3651e-03,  ...,  1.7700e-03,
          3.3302e-03, -5.7364e-04],
        [ 1.6518e-03, -2.4834e-03,  5.3673e-03,  ...,  6.5565e-07,
         -1.2007e-03, -1.2455e-03],
        ...,
        [-1.6861e-03,  2.9516e-04, -5.9366e-04,  ...,  6.1646e-03,
         -2.2221e-03,  9.5749e-04],
        [ 1.1759e-03, -2.2392e-03,  4.4594e-03,  ..., -1.9169e-03,
          2.1305e-03, -7.8440e-04],
        [-2.7771e-03,  1.7023e-03,  6.6376e-04,  ...,  9.1314e-04,
         -1.9226e-03,  6.3934e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1282, -0.0048, -0.0071,  ..., -0.0152, -0.0062,  0.0121],
        [-0.0029, -0.1366, -0.0088,  ...,  0.0124,  0.0086, -0.0035],
        [ 0.0159, -0.0059, -0.1473,  ...,  0.0021,  0.0006, -0.0029],
        ...,
        [ 0.0094, -0.0046, -0.0051,  ..., -0.1367, -0.0106,  0.0107],
        [-0.0006,  0.0015, -0.0053,  ..., -0.0022, -0.1323,  0.0105],
        [ 0.0131,  0.0017,  0.0100,  ..., -0.0013, -0.0058, -0.1346]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2360e-01,  4.5395e-04, -2.1027e-02,  ...,  4.3144e-03,
         -7.7057e-03, -7.6103e-04],
        [ 2.8572e-03, -1.3123e-01, -3.2921e-03,  ..., -7.0381e-04,
         -1.2985e-02, -7.3051e-04],
        [-1.4105e-03,  3.0766e-03, -1.2323e-01,  ...,  1.8177e-03,
          3.4561e-03,  2.4128e-04],
        ...,
        [ 1.3905e-03, -3.7460e-03, -3.5210e-03,  ..., -1.3281e-01,
          1.3237e-03,  9.1267e-04],
        [ 1.9150e-03, -8.0643e-03, -3.4542e-03,  ...,  1.8250e-02,
         -1.3391e-01,  4.4403e-03],
        [ 5.4779e-03, -1.5707e-03,  1.0468e-02,  ..., -1.0300e-04,
          1.3561e-03, -1.2903e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:01:33 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-07-01 08:01:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7749,  1.7188,  0.3743,  ..., -1.4775,  1.5225, -0.2213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.4067,  0.4714, -0.0022,  ..., -0.0204, -0.6216, -0.0326],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.0469,  3.3574,  1.4062,  ..., -2.9395,  2.6758,  0.5542],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.2900, -0.4512, -0.5122,  ...,  0.4355, -0.5869,  0.5981],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:01:33 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:01:33 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 08:02:35 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 08:03:39 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 08:04:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.2212e-03,  1.9014e-05,  3.9597e-03,  ..., -3.2272e-03,
         -4.2152e-03, -1.5554e-03],
        [-6.4545e-03, -7.7057e-03,  7.7915e-04,  ...,  3.4771e-03,
          1.7185e-03, -1.1420e-04],
        [ 7.5388e-04,  3.5810e-04, -1.1856e-02,  ..., -1.2417e-03,
         -2.1629e-03,  3.3531e-03],
        ...,
        [ 9.1457e-04,  1.7691e-04,  1.2875e-04,  ..., -5.1880e-03,
         -5.1403e-04, -2.8877e-03],
        [ 1.2093e-03,  6.2799e-04, -2.0161e-03,  ..., -3.6240e-03,
         -9.7733e-03,  2.8725e-03],
        [-2.0237e-03,  3.6030e-03,  2.3918e-03,  ..., -4.2038e-03,
          7.0381e-04, -1.1734e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0876, -0.0011,  0.0097,  ...,  0.0025,  0.0018, -0.0163],
        [-0.0044, -0.0774, -0.0105,  ..., -0.0047, -0.0050, -0.0023],
        [-0.0037, -0.0059, -0.0826,  ..., -0.0008, -0.0009,  0.0006],
        ...,
        [-0.0193, -0.0078, -0.0095,  ..., -0.0927, -0.0085,  0.0039],
        [ 0.0045,  0.0263, -0.0061,  ...,  0.0112, -0.0871,  0.0128],
        [-0.0067,  0.0145,  0.0125,  ..., -0.0007,  0.0009, -0.0842]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.7473e-02,  7.0114e-03,  1.5152e-02,  ...,  6.6605e-03,
          1.6174e-03,  2.3727e-03],
        [ 3.3455e-03, -9.3323e-02, -1.8661e-02,  ...,  7.5378e-03,
         -1.3990e-03,  1.4214e-02],
        [ 7.6294e-05,  1.6495e-02, -8.9111e-02,  ..., -7.6141e-03,
         -1.2398e-02, -1.2024e-02],
        ...,
        [-1.6724e-02, -5.1022e-05, -1.1703e-02,  ..., -7.3730e-02,
         -1.2875e-03,  1.1246e-02],
        [ 8.8806e-03,  4.5433e-03, -1.2306e-02,  ..., -7.4768e-03,
         -9.2041e-02,  7.6447e-03],
        [-6.0043e-03,  1.0338e-02,  1.6190e-02,  ..., -8.0185e-03,
         -2.4700e-03, -8.3557e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:04:46 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-07-01 08:04:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7710,  1.5371,  0.6343,  ..., -1.3154,  1.2373, -0.0931],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5005,  0.2673, -0.0167,  ...,  0.4583, -0.6250,  0.3040],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.0391,  3.2363,  2.1055,  ..., -2.5566,  2.6016,  1.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.5703, -0.6792, -0.0127,  ...,  1.1660, -0.7109,  1.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:04:46 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:04:46 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 08:05:52 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 08:06:57 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 08:08:05 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0061, -0.0103,  0.0036,  ...,  0.0028,  0.0010, -0.0037],
        [-0.0005, -0.0018, -0.0040,  ..., -0.0017,  0.0022,  0.0030],
        [ 0.0001, -0.0028, -0.0011,  ..., -0.0029,  0.0045,  0.0002],
        ...,
        [-0.0041, -0.0049,  0.0002,  ..., -0.0006,  0.0011, -0.0002],
        [ 0.0083,  0.0045, -0.0015,  ..., -0.0067, -0.0071, -0.0008],
        [ 0.0007, -0.0067, -0.0031,  ..., -0.0023,  0.0039, -0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0669,  0.0118,  0.0032,  ..., -0.0148,  0.0059,  0.0077],
        [ 0.0075, -0.0797, -0.0014,  ..., -0.0085,  0.0120,  0.0101],
        [ 0.0154,  0.0082, -0.0610,  ..., -0.0069,  0.0098, -0.0031],
        ...,
        [-0.0064, -0.0148,  0.0138,  ..., -0.0640,  0.0108,  0.0054],
        [ 0.0162, -0.0058,  0.0144,  ...,  0.0118, -0.0802,  0.0175],
        [-0.0111,  0.0070, -0.0006,  ..., -0.0093,  0.0255, -0.0715]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-8.6243e-02,  1.5736e-03, -6.8321e-03,  ..., -6.9237e-03,
          2.8667e-03, -2.2011e-03],
        [ 3.1052e-03, -9.7839e-02, -6.7673e-03,  ..., -1.6327e-02,
          3.3455e-03, -9.9945e-03],
        [ 8.0872e-03, -8.8348e-03, -1.0596e-01,  ..., -6.8665e-03,
          2.2697e-03, -3.9711e-03],
        ...,
        [-2.0409e-03, -1.2810e-02,  7.9651e-03,  ..., -8.9111e-02,
          4.9438e-03,  2.1362e-03],
        [ 9.1553e-05,  2.1000e-03,  8.6975e-03,  ...,  2.3666e-02,
         -1.2537e-01,  5.8327e-03],
        [-3.4294e-03,  5.5237e-03, -7.7438e-03,  ..., -9.0179e-03,
          1.4816e-02, -9.6313e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:08:07 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-07-01 08:08:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.9380,  1.4854,  0.5923,  ..., -1.2930,  1.2061,  0.2042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5957, -0.2031, -0.2435,  ...,  0.2012, -0.2717,  0.2427],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.6787,  3.4180,  1.6367,  ..., -2.7676,  3.1855,  2.1641],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.4160, -0.8335, -1.8379,  ...,  0.8735, -1.2959,  1.6426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:08:07 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:08:07 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 08:09:17 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 08:10:26 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 08:11:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 6.9885e-03, -1.4534e-03,  3.8853e-03,  ..., -2.5730e-03,
         -2.1076e-04, -8.3542e-04],
        [-2.4948e-03, -3.2091e-04, -2.7037e-04,  ..., -1.8673e-03,
          5.4665e-03, -5.3883e-04],
        [-5.2643e-03,  1.1978e-03,  2.3785e-03,  ...,  1.4763e-03,
         -6.0234e-03, -1.0269e-02],
        ...,
        [ 1.4424e-04,  1.0929e-03, -8.4162e-05,  ...,  1.6594e-04,
          1.2100e-05, -4.8485e-03],
        [ 2.0027e-03,  1.9360e-03,  2.4376e-03,  ..., -7.0381e-03,
          8.2493e-04, -8.9359e-04],
        [-2.4891e-03,  2.1935e-03, -4.6577e-03,  ...,  2.2526e-03,
          6.3019e-03,  2.8610e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.4707e-02,  3.4180e-03, -7.9041e-03,  ..., -8.8272e-03,
         -1.1292e-02, -9.2697e-03],
        [ 8.2626e-03, -8.5754e-02,  5.5809e-03,  ..., -1.1932e-02,
          8.6594e-03,  3.8147e-06],
        [-1.2531e-03,  6.0806e-03, -7.8125e-02,  ..., -1.5686e-02,
         -3.4084e-03,  2.3975e-03],
        ...,
        [-3.1776e-03,  9.5215e-03, -1.3260e-02,  ..., -6.6956e-02,
          1.6510e-02,  3.0079e-03],
        [ 9.8877e-03, -4.5586e-04, -2.4014e-03,  ...,  8.5220e-03,
         -7.0496e-02,  2.1954e-03],
        [-4.4098e-03, -1.6232e-03, -9.3384e-03,  ..., -3.4161e-03,
          4.6806e-03, -8.5938e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0985,  0.0329, -0.0073,  ..., -0.0011, -0.0031, -0.0067],
        [-0.0072, -0.1382,  0.0019,  ..., -0.0084,  0.0018,  0.0250],
        [-0.0140, -0.0235, -0.0974,  ..., -0.0172, -0.0007, -0.0060],
        ...,
        [-0.0008, -0.0011, -0.0087,  ..., -0.1013,  0.0115,  0.0105],
        [-0.0035, -0.0255,  0.0005,  ..., -0.0182, -0.1094, -0.0098],
        [-0.0109, -0.0173, -0.0173,  ..., -0.0060, -0.0106, -0.1271]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:11:37 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-07-01 08:11:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8970,  1.3740,  0.8467,  ..., -1.0820,  1.1328,  0.6147],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1592, -0.3037, -0.0246,  ...,  0.5063, -0.2896,  0.4810],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.4990,  2.4180,  0.8633,  ..., -2.4609,  2.7148,  2.3301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.6191, -1.4609, -2.0938,  ...,  0.2139, -0.9082,  1.3516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:11:37 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:11:37 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 08:12:47 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 08:13:57 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 08:15:08 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0061,  0.0035, -0.0028,  ..., -0.0058, -0.0045, -0.0093],
        [ 0.0090,  0.0169, -0.0089,  ..., -0.0015,  0.0090, -0.0036],
        [ 0.0012, -0.0121,  0.0066,  ..., -0.0007, -0.0003,  0.0081],
        ...,
        [-0.0080, -0.0051, -0.0065,  ...,  0.0040, -0.0007, -0.0001],
        [ 0.0025, -0.0057,  0.0001,  ...,  0.0099,  0.0029,  0.0011],
        [ 0.0002,  0.0044,  0.0062,  ..., -0.0034, -0.0011,  0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.0436e-02, -1.0605e-02,  4.4632e-03,  ..., -1.4732e-02,
          1.6876e-02, -1.0330e-02],
        [ 6.4507e-03, -3.2532e-02, -4.9477e-03,  ...,  3.5620e-04,
          1.3588e-02, -6.8092e-03],
        [-8.1863e-03,  1.4015e-02, -3.8391e-02,  ...,  1.3008e-02,
         -1.3420e-02, -2.0828e-03],
        ...,
        [-1.5076e-02,  9.8114e-03, -1.0010e-02,  ..., -4.2450e-02,
          2.9602e-03, -1.0586e-03],
        [ 1.3046e-02,  1.4076e-02, -5.6305e-03,  ...,  6.9466e-03,
         -3.4576e-02,  8.5907e-03],
        [-3.6061e-05, -7.4844e-03, -1.2293e-03,  ...,  8.0109e-03,
          1.0315e-02, -5.7129e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0544, -0.0060,  0.0221,  ..., -0.0055, -0.0139,  0.0114],
        [-0.0028, -0.0728,  0.0138,  ..., -0.0033,  0.0090,  0.0015],
        [ 0.0023, -0.0064, -0.0763,  ..., -0.0145,  0.0085,  0.0224],
        ...,
        [-0.0082,  0.0075, -0.0042,  ..., -0.0518,  0.0028, -0.0027],
        [ 0.0065,  0.0233, -0.0168,  ..., -0.0083, -0.0642,  0.0203],
        [ 0.0031,  0.0180, -0.0065,  ..., -0.0012,  0.0189, -0.0891]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:15:11 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-07-01 08:15:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6670,  1.3262,  0.5908,  ..., -1.0615,  1.2148,  0.8208],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9414, -0.3284, -0.6870,  ...,  0.3333, -0.4880,  0.6045],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1533,  2.3184,  1.4785,  ..., -2.7852,  2.9492,  2.3711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.7109, -2.3203, -2.8223,  ..., -0.0186, -0.2090,  0.8008],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:15:11 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:15:11 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 08:16:25 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 08:17:37 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 08:18:50 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.8112e-02, -4.3030e-03,  1.4019e-04,  ...,  5.1727e-03,
         -1.2751e-03, -1.3876e-03],
        [-3.6545e-03,  1.7502e-02,  2.3341e-04,  ..., -2.5749e-03,
         -3.8266e-04,  4.8816e-05],
        [-1.0719e-03,  1.6832e-03,  1.5701e-02,  ..., -9.2649e-04,
         -2.1315e-04,  3.5839e-03],
        ...,
        [ 3.4599e-03, -1.8339e-03, -3.1319e-03,  ...,  1.4839e-02,
         -9.2316e-04,  2.0084e-03],
        [-3.4657e-03, -1.2989e-03,  2.1477e-03,  ...,  5.3883e-04,
          1.5762e-02, -1.8835e-03],
        [-1.0147e-03, -4.0245e-03,  3.2692e-03,  ..., -9.3317e-04,
          2.5082e-03,  1.8250e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0128,  0.0120,  0.0136,  ...,  0.0062, -0.0020,  0.0018],
        [ 0.0011, -0.0241, -0.0010,  ...,  0.0006, -0.0019, -0.0035],
        [ 0.0102, -0.0064, -0.0321,  ...,  0.0043,  0.0087,  0.0020],
        ...,
        [ 0.0144,  0.0070, -0.0053,  ..., -0.0278, -0.0088, -0.0061],
        [-0.0041, -0.0074, -0.0160,  ..., -0.0155, -0.0152, -0.0011],
        [ 0.0016, -0.0098, -0.0202,  ..., -0.0057, -0.0140, -0.0605]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0416,  0.0040, -0.0018,  ...,  0.0072,  0.0187,  0.0253],
        [ 0.0054, -0.0517, -0.0114,  ...,  0.0041,  0.0047,  0.0160],
        [-0.0088, -0.0090, -0.0472,  ...,  0.0013,  0.0041, -0.0055],
        ...,
        [-0.0022, -0.0246, -0.0173,  ..., -0.0700, -0.0062,  0.0122],
        [-0.0021, -0.0047,  0.0137,  ..., -0.0069, -0.0616,  0.0050],
        [-0.0010, -0.0184, -0.0163,  ...,  0.0040, -0.0023, -0.0740]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:18:52 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-07-01 08:18:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5498,  0.8721,  0.3003,  ..., -0.9023,  0.9897,  0.8267],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9648, -0.5444, -0.7646,  ...,  0.0676, -0.3196,  0.4736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.5527,  2.4824,  2.4180,  ..., -2.8047,  2.8223,  2.0605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.4551, -1.5654, -3.3984,  ..., -1.4678, -0.3408,  0.2661],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:18:52 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:18:52 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 08:20:11 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 08:21:28 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 08:22:48 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0023e-03, -6.0558e-04, -2.9707e-04,  ..., -7.4804e-05,
         -7.0620e-04, -4.5753e-04],
        [-1.3673e-04, -1.0376e-03,  5.9605e-05,  ...,  1.2922e-04,
          1.2875e-03,  1.1200e-04],
        [-3.8862e-04, -6.0916e-05, -2.1100e-04,  ...,  9.2793e-04,
          1.9383e-04, -1.0386e-03],
        ...,
        [-1.2836e-03,  1.5659e-03,  2.5730e-03,  ..., -6.4707e-04,
          1.4257e-04, -3.3545e-04],
        [ 4.5657e-04, -9.8133e-04, -1.4563e-03,  ...,  1.4591e-03,
         -3.0327e-04, -4.3011e-04],
        [-1.7920e-03,  1.5411e-03, -1.4515e-03,  ..., -1.9054e-03,
          1.1740e-03,  2.0561e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0134, -0.0014, -0.0094,  ...,  0.0007,  0.0027,  0.0186],
        [-0.0022, -0.0485, -0.0144,  ...,  0.0071,  0.0075, -0.0060],
        [-0.0022, -0.0154, -0.0260,  ..., -0.0122,  0.0228,  0.0076],
        ...,
        [-0.0017, -0.0049, -0.0027,  ..., -0.0249, -0.0030,  0.0032],
        [-0.0011, -0.0031, -0.0027,  ..., -0.0146, -0.0310, -0.0151],
        [-0.0040,  0.0183, -0.0051,  ..., -0.0096,  0.0043, -0.0314]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0522,  0.0031, -0.0195,  ...,  0.0103, -0.0219,  0.0135],
        [-0.0034, -0.0862, -0.0136,  ...,  0.0038,  0.0041,  0.0143],
        [ 0.0075, -0.0157, -0.0471,  ..., -0.0040, -0.0037, -0.0082],
        ...,
        [-0.0008, -0.0019,  0.0111,  ..., -0.0549, -0.0198,  0.0153],
        [ 0.0051, -0.0088, -0.0161,  ..., -0.0132, -0.0640, -0.0207],
        [-0.0116,  0.0090, -0.0066,  ..., -0.0044, -0.0102, -0.0589]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:22:51 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-07-01 08:22:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4231,  0.8105,  0.5073,  ..., -0.9746,  1.0762,  0.8423],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9810, -0.8027, -0.9868,  ...,  0.0014, -0.0612,  0.2617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.3994,  2.2031,  3.4297,  ..., -2.8516,  2.5488,  2.7676],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.3555, -1.0918, -2.3262,  ..., -1.9053,  0.3604,  0.9365],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:22:51 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:22:51 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 08:24:14 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 08:25:35 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 08:26:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3704e-03, -3.9291e-04,  6.4468e-04,  ..., -6.4611e-04,
          2.0099e-04,  1.4472e-04],
        [-1.4603e-04, -1.4801e-03,  1.4400e-04,  ...,  7.9727e-04,
         -4.0483e-04, -2.5535e-04],
        [ 5.3501e-04, -3.7968e-05, -1.2951e-03,  ..., -1.3185e-04,
         -9.2268e-04, -3.0637e-05],
        ...,
        [-3.2234e-04, -5.3406e-04, -2.9385e-05,  ..., -3.3054e-03,
          3.5930e-04,  6.4278e-04],
        [-1.5867e-04,  3.2759e-04,  6.6805e-04,  ..., -5.7745e-04,
         -2.0676e-03,  3.6478e-04],
        [-7.7343e-04, -2.5511e-04, -8.2493e-04,  ..., -8.9359e-04,
          3.6383e-04, -1.7500e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0255,  0.0140, -0.0022,  ...,  0.0164, -0.0021,  0.0111],
        [ 0.0006, -0.0192, -0.0009,  ...,  0.0053, -0.0025,  0.0014],
        [-0.0105, -0.0049, -0.0316,  ..., -0.0096,  0.0085, -0.0054],
        ...,
        [-0.0010,  0.0062, -0.0081,  ..., -0.0295,  0.0012,  0.0090],
        [ 0.0122,  0.0001, -0.0117,  ..., -0.0004, -0.0424, -0.0064],
        [ 0.0073, -0.0107,  0.0071,  ...,  0.0004, -0.0131, -0.0367]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0654,  0.0135,  0.0068,  ...,  0.0073,  0.0117,  0.0089],
        [ 0.0090, -0.0496,  0.0058,  ...,  0.0085, -0.0018, -0.0021],
        [-0.0270, -0.0021, -0.0576,  ...,  0.0055, -0.0197,  0.0105],
        ...,
        [-0.0117,  0.0067,  0.0017,  ..., -0.0730,  0.0048,  0.0211],
        [ 0.0122,  0.0128, -0.0048,  ...,  0.0032, -0.0427, -0.0159],
        [ 0.0131, -0.0008, -0.0028,  ...,  0.0211, -0.0079, -0.0537]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:26:58 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-07-01 08:26:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5381,  0.8403,  0.7915,  ..., -0.9463,  0.9990,  0.6929],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2070, -0.5161, -1.1445,  ..., -0.4800, -0.0935,  0.0632],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1338,  1.7412,  4.0898,  ..., -2.4805,  3.0625,  2.5664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.6172, -0.6914, -0.7012,  ..., -2.4453,  1.8926,  1.4658],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:26:58 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:26:58 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 08:28:19 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 08:29:43 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 08:31:07 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.2177e-03,  1.2178e-03, -2.6588e-03,  ...,  1.1635e-03,
         -2.7103e-03, -3.1567e-03],
        [-2.3441e-03, -2.8934e-03,  1.0567e-03,  ...,  2.6340e-03,
          1.0777e-03,  2.8944e-04],
        [-1.1616e-03,  2.1534e-03,  4.2915e-05,  ...,  1.0157e-03,
          9.9850e-04,  9.7179e-04],
        ...,
        [-2.3746e-03, -8.8024e-04,  3.7403e-03,  ..., -5.3940e-03,
         -3.3073e-03, -2.6875e-03],
        [-1.0643e-03, -1.1845e-03, -1.1730e-03,  ...,  2.4140e-05,
         -4.7150e-03,  8.2493e-04],
        [-1.0757e-03, -1.3113e-04,  2.3689e-03,  ..., -1.4753e-03,
          7.5340e-04, -6.2904e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0357, -0.0139, -0.0057,  ..., -0.0073,  0.0145, -0.0042],
        [ 0.0252, -0.0455,  0.0053,  ...,  0.0011,  0.0173, -0.0088],
        [ 0.0084, -0.0108, -0.0288,  ..., -0.0007,  0.0005, -0.0068],
        ...,
        [ 0.0120,  0.0120, -0.0255,  ..., -0.0247, -0.0140, -0.0090],
        [-0.0106,  0.0029,  0.0058,  ...,  0.0093, -0.0280,  0.0037],
        [-0.0069, -0.0093,  0.0193,  ..., -0.0104,  0.0193, -0.0520]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0393,  0.0028, -0.0179,  ..., -0.0160, -0.0045,  0.0059],
        [ 0.0197, -0.0500, -0.0088,  ..., -0.0042,  0.0054,  0.0008],
        [-0.0136,  0.0167, -0.0682,  ..., -0.0066,  0.0066,  0.0135],
        ...,
        [ 0.0299,  0.0107, -0.0074,  ..., -0.0371, -0.0136, -0.0296],
        [ 0.0079,  0.0080,  0.0172,  ...,  0.0346, -0.0599,  0.0058],
        [-0.0018, -0.0135,  0.0180,  ...,  0.0193, -0.0103, -0.0801]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:31:10 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-07-01 08:31:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4688,  0.7334,  1.0859,  ..., -0.9409,  0.8677,  0.9111],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1299, -0.3191, -0.8062,  ..., -0.6226,  0.1328,  0.2876],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.7871,  1.5977,  3.5332,  ..., -2.5234,  3.0371,  2.6074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.6309, -0.3149, -0.1099,  ..., -3.0879,  2.3828,  2.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:31:10 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:31:10 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 08:32:34 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 08:34:00 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 08:35:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.1702e-03, -1.8620e-04, -3.6418e-05,  ...,  4.2295e-04,
          1.3137e-04,  4.8161e-04],
        [-3.2353e-04,  3.0255e-04,  2.0432e-04,  ...,  3.8266e-05,
         -2.3079e-04, -6.1655e-04],
        [-2.0862e-06,  1.0473e-04,  9.6655e-04,  ..., -3.0446e-04,
          2.4176e-04, -4.7088e-04],
        ...,
        [ 2.4915e-04,  7.1907e-04,  3.9673e-04,  ...,  8.1253e-04,
         -1.9693e-04, -2.4939e-04],
        [ 2.8551e-05,  5.5885e-04,  2.1291e-04,  ...,  4.2915e-04,
          1.1444e-03, -3.8028e-04],
        [ 1.3304e-04, -4.6635e-04, -4.6968e-04,  ...,  1.0669e-04,
         -1.0169e-04,  1.4286e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0096, -0.0062, -0.0047,  ..., -0.0024,  0.0085, -0.0016],
        [-0.0171, -0.0387, -0.0061,  ..., -0.0083,  0.0081,  0.0298],
        [-0.0048, -0.0022, -0.0036,  ..., -0.0024, -0.0221,  0.0053],
        ...,
        [-0.0090,  0.0023, -0.0093,  ...,  0.0059,  0.0051, -0.0052],
        [ 0.0022,  0.0119,  0.0010,  ..., -0.0190, -0.0230, -0.0099],
        [-0.0008,  0.0141, -0.0011,  ...,  0.0121,  0.0099,  0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 0.0209, -0.0070,  0.0038,  ...,  0.0162,  0.0095,  0.0137],
        [-0.0178, -0.0170,  0.0023,  ...,  0.0031,  0.0004,  0.0015],
        [-0.0125,  0.0385,  0.0394,  ...,  0.0031,  0.0097,  0.0114],
        ...,
        [-0.0136, -0.0122, -0.0225,  ...,  0.0169,  0.0267,  0.0189],
        [ 0.0087, -0.0031, -0.0219,  ...,  0.0087,  0.0097,  0.0211],
        [ 0.0111,  0.0175, -0.0185,  ...,  0.0116,  0.0015,  0.0346]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:35:26 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 08:35:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3333,  0.5454,  1.2275,  ..., -0.8052,  0.9526,  0.7817],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1699, -0.1821, -0.2747,  ..., -0.7930,  0.5913,  0.4326],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.9736,  1.8262,  3.7070,  ..., -2.3184,  2.5703,  3.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.2500, -0.2058,  0.1119,  ..., -4.5195,  3.8594,  5.3750],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:35:26 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:35:26 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 08:36:52 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 08:38:18 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 08:39:42 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.4359e-04, -1.8950e-03,  1.2052e-04,  ...,  6.6817e-05,
         -8.8990e-05,  6.6662e-04],
        [ 1.2994e-04,  1.4782e-04, -5.4777e-05,  ..., -2.3305e-04,
         -3.9458e-04, -8.2910e-05],
        [ 7.9453e-05,  9.4271e-04, -1.4782e-05,  ..., -2.7180e-04,
          7.2432e-04, -3.8481e-04],
        ...,
        [-5.8055e-05,  2.5940e-04, -4.5037e-04,  ..., -8.7619e-05,
         -5.1355e-04, -3.3665e-04],
        [ 7.6890e-06, -2.1219e-04, -2.5892e-04,  ..., -6.9427e-04,
          4.6074e-05, -4.8637e-04],
        [-2.4021e-05,  1.3399e-03, -2.2268e-04,  ...,  6.3753e-04,
         -6.9737e-06,  6.2108e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0218,  0.0012,  0.0063,  ..., -0.0192,  0.0054, -0.0001],
        [-0.0057, -0.0183, -0.0012,  ...,  0.0077,  0.0028, -0.0081],
        [-0.0154,  0.0024, -0.0270,  ...,  0.0059, -0.0060,  0.0071],
        ...,
        [ 0.0049,  0.0033, -0.0192,  ..., -0.0084, -0.0012, -0.0009],
        [ 0.0020,  0.0133, -0.0252,  ...,  0.0042, -0.0120, -0.0007],
        [-0.0087,  0.0033,  0.0105,  ...,  0.0244,  0.0097,  0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0274, -0.0012,  0.0125,  ...,  0.0146,  0.0008,  0.0231],
        [-0.0103, -0.0369, -0.0039,  ..., -0.0024, -0.0094, -0.0125],
        [-0.0028, -0.0048, -0.0209,  ...,  0.0140,  0.0090,  0.0068],
        ...,
        [-0.0024,  0.0102,  0.0129,  ..., -0.0294,  0.0047, -0.0036],
        [-0.0054,  0.0113, -0.0136,  ..., -0.0078, -0.0549,  0.0043],
        [ 0.0139,  0.0086, -0.0092,  ...,  0.0158, -0.0213, -0.0189]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:39:45 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 08:39:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4766,  0.4753,  0.9224,  ..., -0.8184,  0.8438,  0.7090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.1611, -0.0617, -0.1179,  ..., -1.0088,  0.6821,  0.6938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2129,  1.6006,  2.3398,  ..., -2.9414,  2.1094,  1.7793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 4.2969, -0.2440, -0.1045,  ..., -5.2930,  4.1250,  4.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:39:45 root INFO     [order_1_approx] starting weight calculation for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:39:45 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 08:41:09 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 08:42:28 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 08:43:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7670e-02, -1.7524e-04, -1.0700e-03,  ...,  4.6229e-04,
          8.1301e-04, -4.0627e-03],
        [ 7.9298e-04,  1.1009e-02, -2.4068e-04,  ..., -5.4359e-04,
         -1.2903e-03, -1.7786e-04],
        [ 2.7370e-03, -2.7237e-03,  1.8234e-02,  ..., -3.5763e-03,
         -1.6804e-03,  2.9087e-03],
        ...,
        [-4.3030e-03, -3.4523e-04, -1.6165e-03,  ...,  2.0996e-02,
         -3.4008e-03, -3.7727e-03],
        [ 4.6659e-04,  6.1464e-04, -2.0618e-03,  ..., -1.1377e-03,
          2.7161e-02, -2.0256e-03],
        [ 1.9073e-05, -1.6136e-03, -8.1301e-04,  ..., -4.8637e-03,
          9.3460e-05,  3.1143e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0019,  0.0040, -0.0010,  ...,  0.0105,  0.0321,  0.0098],
        [-0.0036, -0.0267, -0.0070,  ..., -0.0039, -0.0003,  0.0019],
        [-0.0039, -0.0016, -0.0056,  ..., -0.0080,  0.0140, -0.0090],
        ...,
        [ 0.0144, -0.0040, -0.0016,  ..., -0.0158, -0.0139,  0.0233],
        [ 0.0070, -0.0054, -0.0155,  ..., -0.0009,  0.0157,  0.0045],
        [-0.0015,  0.0113,  0.0080,  ...,  0.0002,  0.0027,  0.0108]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0025,  0.0074,  0.0304,  ..., -0.0117,  0.0233,  0.0078],
        [ 0.0189, -0.0753,  0.0127,  ...,  0.0098,  0.0202, -0.0040],
        [-0.0127,  0.0046, -0.0337,  ..., -0.0181,  0.0200, -0.0015],
        ...,
        [ 0.0056,  0.0072,  0.0077,  ..., -0.0149, -0.0132, -0.0099],
        [-0.0117,  0.0035, -0.0341,  ..., -0.0033, -0.0116,  0.0178],
        [-0.0068,  0.0236,  0.0073,  ..., -0.0128,  0.0262, -0.0175]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:43:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you mourn something, you are a mourner
If you compose something, you are a composer
If you deliver something, you are a deliverer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you suffer something, you are a sufferer
If you speak something, you are a speaker
If you perform something, you are a
2024-07-01 08:43:49 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 08:43:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2061, -0.2822,  0.5625,  ...,  0.0942, -0.0155,  0.2173],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1821,  0.1093, -0.1453,  ..., -0.3911,  0.0361,  0.0162],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5957, -0.0874,  0.4355,  ...,  0.1558, -1.1494,  0.6611],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0267,  0.2991,  0.1062,  ..., -0.7891, -0.1909, -0.1247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:43:49 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:43:49 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 08:44:12 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 08:44:36 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 08:44:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.0238e-04,  1.0020e-04,  1.4782e-04,  ...,  1.4234e-04,
          2.5392e-04,  4.5633e-04],
        [-3.9721e-04,  4.9925e-04, -5.4693e-04,  ...,  5.4896e-05,
          9.7322e-04, -1.5056e-04],
        [ 1.2550e-03,  4.4632e-04, -5.2595e-04,  ..., -5.9366e-04,
         -3.4428e-04,  1.0633e-03],
        ...,
        [-2.0862e-06, -5.9223e-04,  6.7413e-05,  ..., -8.5545e-04,
         -1.6713e-04, -4.9400e-04],
        [ 1.2517e-04,  2.3532e-04, -2.6560e-04,  ...,  4.9829e-04,
         -7.7248e-04, -3.1638e-04],
        [-2.7323e-04,  4.6825e-04,  1.0169e-04,  ...,  4.1938e-04,
          3.1424e-04, -8.6498e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.3325e-02,  4.3488e-03,  1.5831e-04,  ...,  9.6321e-05,
         -5.2910e-03,  3.2921e-03],
        [-4.2114e-03, -3.7048e-02,  1.4467e-03,  ...,  4.2305e-03,
          4.2992e-03,  2.5311e-03],
        [-2.8458e-03,  7.8392e-04, -4.1656e-02,  ..., -3.5172e-03,
         -2.8458e-03, -6.8626e-03],
        ...,
        [-3.9825e-03,  1.0357e-03, -3.4523e-04,  ..., -3.9612e-02,
         -5.5075e-04,  8.8406e-04],
        [-4.9057e-03,  4.7836e-03,  7.6485e-04,  ...,  2.4433e-03,
         -3.8513e-02,  7.2327e-03],
        [-3.6392e-03,  1.1253e-03,  6.2218e-03,  ..., -1.2951e-03,
         -2.8915e-03, -3.4576e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0381,  0.0005,  0.0016,  ..., -0.0018, -0.0008,  0.0007],
        [ 0.0021, -0.0398,  0.0012,  ...,  0.0037,  0.0071,  0.0026],
        [-0.0039,  0.0026, -0.0361,  ..., -0.0035,  0.0020,  0.0030],
        ...,
        [ 0.0032,  0.0047,  0.0009,  ..., -0.0399,  0.0034,  0.0040],
        [-0.0050,  0.0025,  0.0013,  ..., -0.0007, -0.0368,  0.0075],
        [-0.0020, -0.0018, -0.0014,  ...,  0.0017,  0.0055, -0.0358]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:45:01 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 08:45:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7754, -0.1575,  0.2349,  ...,  0.0865, -0.6304,  0.5786],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0963,  0.2390, -0.0069,  ..., -0.7275, -0.1422, -0.1116],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5728,  0.1987,  0.5542,  ...,  0.0215, -1.0449,  0.5244],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0438,  0.5693,  0.3713,  ..., -1.2520, -0.3184,  0.0418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:45:01 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:45:01 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 08:45:25 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 08:45:49 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 08:46:13 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.2937e-03,  3.1261e-03,  5.5218e-04,  ..., -8.4829e-04,
          5.9462e-04,  3.5191e-04],
        [ 9.4461e-04, -9.9716e-03,  3.2330e-04,  ..., -1.3065e-03,
          1.3638e-03, -7.9870e-04],
        [-1.0672e-03, -2.3594e-03, -5.2872e-03,  ..., -2.0561e-03,
          2.9030e-03, -2.8419e-04],
        ...,
        [ 1.1759e-03,  8.2302e-04, -4.0936e-04,  ..., -8.3542e-03,
         -9.2173e-04, -3.1376e-04],
        [ 1.6384e-03, -4.5490e-04,  7.9823e-04,  ..., -1.1797e-03,
         -6.6414e-03,  5.3167e-05],
        [-4.6134e-04, -1.9109e-04, -4.1485e-04,  ..., -9.1553e-04,
          1.0824e-03, -8.2169e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0720,  0.0029, -0.0020,  ...,  0.0116,  0.0061, -0.0056],
        [ 0.0038, -0.0642,  0.0020,  ..., -0.0013,  0.0042,  0.0018],
        [-0.0093, -0.0002, -0.0714,  ...,  0.0020, -0.0083, -0.0058],
        ...,
        [-0.0011,  0.0007,  0.0073,  ..., -0.0699, -0.0087,  0.0026],
        [ 0.0032, -0.0083,  0.0087,  ..., -0.0052, -0.0634, -0.0043],
        [-0.0024,  0.0008, -0.0137,  ..., -0.0019, -0.0054, -0.0694]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0620,  0.0106, -0.0035,  ...,  0.0059,  0.0014,  0.0007],
        [ 0.0006, -0.0590, -0.0004,  ..., -0.0001, -0.0046,  0.0043],
        [-0.0020,  0.0027, -0.0460,  ...,  0.0049,  0.0033,  0.0008],
        ...,
        [-0.0030,  0.0063, -0.0020,  ..., -0.0540, -0.0060,  0.0044],
        [ 0.0036, -0.0042,  0.0041,  ...,  0.0013, -0.0522, -0.0007],
        [ 0.0013, -0.0024, -0.0018,  ..., -0.0026,  0.0068, -0.0608]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:46:15 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 08:46:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8096, -0.1439,  0.5571,  ...,  0.1908, -1.4834,  0.8652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0582,  0.4690,  0.1677,  ..., -1.1904, -0.2952, -0.2246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6021,  0.2927,  0.3450,  ...,  0.0157, -1.5381,  0.5459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1407,  0.3584,  0.2988,  ..., -0.9619, -0.6006,  0.3174],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:46:15 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:46:15 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 08:46:41 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 08:47:05 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 08:47:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.1117e-03, -6.1989e-04, -3.1948e-03,  ...,  1.1673e-03,
          9.2924e-05, -1.9121e-03],
        [-5.9414e-04, -6.0959e-03, -1.5116e-04,  ...,  6.4659e-04,
         -1.0014e-03,  4.8923e-04],
        [-3.1662e-03, -6.9571e-04, -5.9090e-03,  ...,  7.8869e-04,
          2.5582e-04, -1.6391e-04],
        ...,
        [-1.3199e-03,  9.3746e-04, -8.3351e-04,  ..., -5.3291e-03,
          1.9193e-04,  6.2180e-04],
        [-6.9189e-04,  8.7857e-05, -3.6430e-04,  ...,  9.0933e-04,
         -6.6223e-03, -1.4362e-03],
        [ 1.6475e-04, -9.2316e-04, -5.2214e-04,  ...,  4.3249e-04,
          1.2379e-03, -6.9504e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0389, -0.0008, -0.0018,  ..., -0.0110, -0.0104,  0.0049],
        [-0.0071, -0.0391,  0.0048,  ..., -0.0039, -0.0057,  0.0026],
        [ 0.0110,  0.0067, -0.0452,  ...,  0.0002,  0.0029,  0.0022],
        ...,
        [-0.0054, -0.0010, -0.0133,  ..., -0.0432, -0.0036,  0.0088],
        [-0.0034,  0.0050, -0.0013,  ...,  0.0054, -0.0430, -0.0015],
        [-0.0061,  0.0019, -0.0041,  ..., -0.0076, -0.0053, -0.0398]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0316, -0.0027,  0.0027,  ..., -0.0003, -0.0020, -0.0054],
        [-0.0012, -0.0340,  0.0073,  ...,  0.0042, -0.0019,  0.0089],
        [ 0.0016, -0.0022, -0.0276,  ...,  0.0034, -0.0061,  0.0032],
        ...,
        [-0.0019,  0.0029, -0.0032,  ..., -0.0266,  0.0034,  0.0017],
        [-0.0057, -0.0030,  0.0003,  ..., -0.0087, -0.0333, -0.0052],
        [-0.0073, -0.0062, -0.0049,  ..., -0.0028,  0.0057, -0.0334]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:47:31 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 08:47:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.7515,  0.2234,  0.6729,  ...,  0.0254, -1.2959,  0.6309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0831,  0.8159,  0.5293,  ..., -1.7178, -0.4622,  0.0298],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8188,  0.1676,  0.5459,  ...,  0.3774, -1.3066,  0.3418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.1947,  0.5176,  0.2700,  ..., -1.4043, -0.0537,  0.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:47:32 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:47:32 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 08:48:04 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 08:48:34 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 08:49:04 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3313e-03,  1.3437e-03,  1.6975e-04,  ..., -4.3631e-04,
          4.5514e-04, -8.8215e-06],
        [ 1.5783e-03, -2.4452e-03, -7.8583e-04,  ...,  1.3483e-04,
          1.1311e-03,  2.4462e-04],
        [-3.9911e-04,  1.5044e-04, -2.6741e-03,  ...,  5.6696e-04,
          5.0831e-04, -8.8739e-04],
        ...,
        [ 2.8729e-04, -1.4648e-03,  3.8815e-04,  ..., -1.7109e-03,
          4.8161e-04,  5.6028e-04],
        [-6.4325e-04, -1.0204e-04, -1.2302e-04,  ..., -2.4128e-03,
         -2.7065e-03, -3.1710e-04],
        [ 4.1008e-05, -3.6120e-04, -9.0981e-04,  ...,  2.5439e-04,
         -7.5722e-04, -2.6112e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.7526e-02,  4.6883e-03, -4.4441e-03,  ...,  1.7309e-03,
         -8.2550e-03,  1.1234e-03],
        [ 2.6798e-04, -5.4565e-02, -2.6436e-03,  ..., -1.5850e-03,
          2.2621e-03, -3.7937e-03],
        [-2.2163e-03, -1.3260e-02, -5.2734e-02,  ...,  4.8256e-03,
         -5.9967e-03, -2.2964e-03],
        ...,
        [-5.0354e-03,  1.2236e-03, -3.8338e-03,  ..., -4.9500e-02,
          2.7847e-03, -3.0231e-03],
        [-4.9706e-03, -5.9700e-04, -3.2005e-03,  ..., -6.3286e-03,
         -4.0100e-02,  7.1764e-05],
        [ 5.5923e-03, -6.5269e-03,  1.8644e-03,  ...,  1.7700e-02,
          5.0468e-03, -5.3375e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0521, -0.0032,  0.0088,  ...,  0.0014, -0.0016, -0.0007],
        [ 0.0013, -0.0442, -0.0027,  ..., -0.0006,  0.0004, -0.0002],
        [-0.0067, -0.0066, -0.0435,  ...,  0.0031, -0.0068,  0.0036],
        ...,
        [-0.0042, -0.0015, -0.0011,  ..., -0.0475,  0.0039, -0.0102],
        [-0.0039, -0.0046, -0.0020,  ..., -0.0065, -0.0385, -0.0020],
        [-0.0028,  0.0035,  0.0019,  ..., -0.0073, -0.0048, -0.0445]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:49:07 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 08:49:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6113,  0.2517,  0.3306,  ...,  0.0023, -1.5127,  0.5186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1636,  0.3669,  0.3242,  ..., -1.0020, -0.6299,  0.3257],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1621,  0.5713,  0.8594,  ...,  0.0676, -0.7261,  0.6216],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0526,  0.6704,  0.6279,  ..., -1.2451, -0.4006,  0.0142],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:49:07 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:49:07 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 08:49:40 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 08:50:14 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 08:50:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1199e-03,  2.3346e-03, -2.7924e-03,  ...,  3.0518e-04,
         -1.3723e-03,  8.6212e-04],
        [-8.4352e-04, -3.8338e-04, -2.1534e-03,  ..., -3.3808e-04,
         -9.8646e-05,  1.6689e-06],
        [ 3.3259e-04,  4.8018e-04, -3.2463e-03,  ..., -5.8031e-04,
         -1.2541e-03, -1.6880e-03],
        ...,
        [-1.2169e-03,  7.4148e-04, -1.5993e-03,  ..., -4.0779e-03,
         -2.6703e-03,  5.7745e-04],
        [ 3.0088e-04, -9.1171e-04,  2.7990e-04,  ...,  1.0824e-03,
         -1.1616e-03, -1.3266e-03],
        [-9.4128e-04, -9.9754e-04,  2.4700e-04,  ...,  3.7766e-04,
         -8.3065e-04, -1.5497e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0930,  0.0089,  0.0017,  ..., -0.0090,  0.0055, -0.0030],
        [-0.0048, -0.0831, -0.0007,  ..., -0.0083,  0.0066,  0.0130],
        [-0.0130,  0.0065, -0.0864,  ...,  0.0090,  0.0161,  0.0070],
        ...,
        [-0.0119, -0.0070, -0.0041,  ..., -0.0844, -0.0098,  0.0054],
        [ 0.0036, -0.0038, -0.0026,  ..., -0.0010, -0.0969,  0.0067],
        [ 0.0022,  0.0103,  0.0007,  ..., -0.0094,  0.0029, -0.1035]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-9.9731e-02, -6.0005e-03,  5.5809e-03,  ..., -1.8454e-03,
         -2.1172e-03,  5.8212e-03],
        [-9.5367e-03, -1.0114e-01,  8.2207e-04,  ...,  1.5087e-03,
         -5.3444e-03,  4.2229e-03],
        [ 1.3733e-04,  7.8201e-05, -9.4360e-02,  ..., -1.5230e-03,
          1.3306e-02,  7.9651e-03],
        ...,
        [-5.3024e-03,  5.3749e-03, -8.1558e-03,  ..., -8.1543e-02,
          2.3766e-03,  2.8477e-03],
        [-7.1526e-04, -3.9406e-03,  5.4321e-03,  ...,  8.5983e-03,
         -9.2224e-02,  5.6992e-03],
        [-7.9498e-03,  9.2545e-03,  7.4310e-03,  ..., -2.2125e-04,
         -5.6686e-03, -9.9976e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:50:49 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 08:50:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8071,  0.1475,  0.4941,  ...,  0.3542, -1.2783,  0.3137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2135,  0.5669,  0.2744,  ..., -1.4629, -0.0723,  0.4861],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.2568,  0.6348,  0.4966,  ...,  0.6416, -0.7583,  0.6167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1823,  0.5781,  0.2822,  ..., -0.8618, -0.5605, -0.0739],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:50:49 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:50:49 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 08:51:24 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 08:52:00 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 08:52:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.0785e-03,  2.3389e-04,  1.7958e-03,  ..., -1.1349e-03,
          1.7703e-05,  2.6493e-03],
        [ 1.2798e-03, -5.7449e-03,  1.9798e-03,  ..., -6.6757e-04,
          7.0810e-04, -1.2417e-03],
        [-2.5153e-05,  2.9602e-03, -3.8719e-03,  ..., -1.8282e-03,
         -5.5218e-04, -1.0777e-04],
        ...,
        [ 1.2598e-03,  9.2030e-04, -9.9182e-04,  ..., -3.4294e-03,
         -2.3174e-03,  2.0561e-03],
        [ 2.4033e-03, -1.3218e-03,  3.2878e-04,  ..., -1.1501e-03,
         -2.0790e-03, -3.1161e-04],
        [ 5.4216e-04, -1.0023e-03, -5.1594e-04,  ..., -1.4029e-03,
         -7.3528e-04, -1.9550e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0856,  0.0033, -0.0024,  ..., -0.0014,  0.0104,  0.0007],
        [ 0.0040, -0.1006,  0.0008,  ...,  0.0154, -0.0013,  0.0077],
        [ 0.0087,  0.0100, -0.0895,  ..., -0.0082, -0.0104, -0.0063],
        ...,
        [-0.0076,  0.0057,  0.0043,  ..., -0.0909,  0.0015, -0.0023],
        [-0.0070,  0.0056,  0.0072,  ..., -0.0009, -0.0926, -0.0025],
        [ 0.0032,  0.0115,  0.0010,  ..., -0.0140,  0.0088, -0.0808]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1088, -0.0074,  0.0004,  ...,  0.0015, -0.0042,  0.0004],
        [-0.0006, -0.0929, -0.0109,  ...,  0.0026, -0.0086,  0.0017],
        [-0.0005, -0.0060, -0.0933,  ..., -0.0004,  0.0013,  0.0012],
        ...,
        [-0.0026,  0.0047,  0.0061,  ..., -0.1042, -0.0037, -0.0018],
        [-0.0036,  0.0016, -0.0032,  ..., -0.0070, -0.0967, -0.0038],
        [-0.0063, -0.0086, -0.0107,  ..., -0.0057, -0.0010, -0.1043]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:52:35 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 08:52:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.0654,  0.5410,  0.7134,  ...,  0.0277, -0.6611,  0.5396],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0515,  0.6787,  0.5542,  ..., -1.1504, -0.3838, -0.0187],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.8398,  0.4844,  0.8286,  ...,  0.5703, -0.3496,  0.6533],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4541,  0.4321,  0.1427,  ..., -1.3604, -1.0781, -0.5308],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:52:35 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:52:35 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 08:53:09 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 08:53:49 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 08:54:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0050,  0.0016,  0.0008,  ...,  0.0026, -0.0032,  0.0020],
        [ 0.0006, -0.0036,  0.0003,  ...,  0.0021,  0.0033, -0.0025],
        [ 0.0003, -0.0014, -0.0038,  ..., -0.0021, -0.0003, -0.0025],
        ...,
        [-0.0007,  0.0010,  0.0006,  ..., -0.0053,  0.0014,  0.0029],
        [-0.0006,  0.0013, -0.0016,  ...,  0.0005, -0.0016, -0.0002],
        [ 0.0028, -0.0017, -0.0012,  ...,  0.0006,  0.0036, -0.0059]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0828,  0.0093,  0.0148,  ..., -0.0153,  0.0019,  0.0091],
        [ 0.0033, -0.0802, -0.0128,  ..., -0.0052,  0.0074,  0.0008],
        [ 0.0097, -0.0006, -0.0748,  ..., -0.0001,  0.0041,  0.0018],
        ...,
        [-0.0066, -0.0029,  0.0048,  ..., -0.0912,  0.0014,  0.0063],
        [ 0.0062,  0.0010, -0.0089,  ...,  0.0186, -0.0842,  0.0016],
        [-0.0078,  0.0045, -0.0048,  ...,  0.0021, -0.0052, -0.0930]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1052,  0.0007,  0.0111,  ..., -0.0076, -0.0040, -0.0117],
        [ 0.0025, -0.1046, -0.0025,  ...,  0.0038,  0.0200, -0.0062],
        [ 0.0059, -0.0006, -0.0920,  ..., -0.0007,  0.0052,  0.0148],
        ...,
        [-0.0022,  0.0020, -0.0047,  ..., -0.0978,  0.0121,  0.0017],
        [ 0.0047,  0.0081,  0.0040,  ...,  0.0167, -0.0979, -0.0047],
        [-0.0085, -0.0044,  0.0068,  ...,  0.0133,  0.0018, -0.0975]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:54:29 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 08:54:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.0352,  0.5239,  0.3706,  ...,  0.4819, -0.6138,  0.4897],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1704,  0.5679,  0.2482,  ..., -0.7710, -0.5283, -0.0917],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.5889,  0.3833,  0.9404,  ..., -0.1890, -0.2627,  0.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4412,  0.3286, -0.1559,  ..., -1.3975, -1.0400,  0.5688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:54:29 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:54:29 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 08:55:06 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 08:55:39 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 08:56:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.8378e-04, -3.6526e-04, -3.8743e-05,  ...,  5.7077e-04,
          1.5402e-03, -2.3117e-03],
        [ 8.5878e-04, -3.2501e-03,  2.2984e-03,  ..., -2.0676e-03,
          1.2608e-03, -2.6474e-03],
        [-5.2595e-04,  4.0169e-03, -2.4052e-03,  ...,  7.7295e-04,
          8.9598e-04, -1.1616e-03],
        ...,
        [-2.2049e-03, -2.0409e-03, -1.3435e-04,  ..., -2.9397e-04,
          7.4577e-04, -1.3971e-04],
        [ 2.3537e-03, -1.5247e-04, -8.1420e-05,  ..., -1.1101e-03,
         -4.8294e-03, -1.5354e-03],
        [ 3.1414e-03,  1.2732e-03, -3.7026e-04,  ...,  3.5119e-04,
         -4.6015e-04, -1.0910e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-8.2886e-02,  7.0076e-03, -3.9673e-03,  ...,  4.7760e-03,
          4.4670e-03,  7.5874e-03],
        [ 1.6651e-03, -1.0638e-01, -1.6794e-03,  ...,  5.7869e-03,
         -8.5754e-03,  1.3969e-02],
        [-5.6458e-03, -5.2605e-03, -9.6130e-02,  ...,  4.4594e-03,
         -1.1536e-02,  4.1962e-05],
        ...,
        [ 2.3079e-04,  4.0741e-03,  6.8359e-03,  ..., -9.1553e-02,
          3.6926e-03, -5.3101e-03],
        [ 7.4654e-03,  4.0245e-03, -5.1727e-03,  ..., -6.1417e-03,
         -7.8186e-02,  1.9043e-02],
        [ 1.4511e-02, -9.0027e-04, -1.6617e-02,  ..., -5.8222e-04,
          1.5976e-02, -1.0614e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1083,  0.0178,  0.0002,  ..., -0.0139,  0.0051,  0.0019],
        [ 0.0035, -0.1137,  0.0075,  ..., -0.0040, -0.0056,  0.0141],
        [-0.0043, -0.0028, -0.1030,  ..., -0.0076, -0.0014,  0.0077],
        ...,
        [ 0.0040,  0.0041, -0.0122,  ..., -0.1087,  0.0042, -0.0058],
        [-0.0067,  0.0019, -0.0074,  ..., -0.0016, -0.1022,  0.0073],
        [ 0.0062, -0.0038, -0.0137,  ..., -0.0060,  0.0077, -0.1113]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:56:19 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 08:56:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.3467,  0.3474,  0.5137,  ...,  0.3599, -0.2622,  0.4575],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3911,  0.3596,  0.0624,  ..., -1.0615, -0.8716, -0.4600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.6211,  0.7534,  1.0439,  ..., -0.6709, -0.1118, -0.1719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4644,  0.2617, -0.1365,  ..., -1.2754, -1.3340,  0.1777],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:56:19 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:56:19 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 08:57:04 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 08:57:51 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 08:58:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.6926e-03,  3.2635e-03, -1.4973e-03,  ..., -2.5635e-03,
         -3.4351e-03, -3.3398e-03],
        [ 2.5215e-03, -3.0422e-04, -1.6460e-03,  ..., -5.0068e-04,
         -2.8725e-03, -4.0913e-04],
        [ 1.8539e-03, -2.2259e-03, -3.9816e-04,  ..., -1.7128e-03,
          1.9989e-03,  1.4238e-03],
        ...,
        [ 1.0748e-03, -9.0981e-04, -1.7834e-03,  ...,  2.8610e-04,
         -1.3590e-04, -6.1178e-04],
        [-2.3289e-03, -3.4733e-03,  1.5497e-03,  ..., -2.4300e-03,
         -9.6989e-04,  1.3685e-03],
        [ 7.7915e-04, -6.1798e-04,  7.5436e-04,  ...,  8.5831e-05,
         -4.8018e-04, -2.1076e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.1041e-01, -9.7885e-03, -1.0185e-02,  ..., -9.4604e-03,
          1.1772e-02, -1.4244e-02],
        [ 2.6550e-03, -1.3013e-01, -5.1384e-03,  ...,  4.6158e-03,
          1.2474e-03, -4.9591e-05],
        [ 2.1019e-03,  4.4441e-03, -1.2915e-01,  ..., -2.9144e-03,
         -1.6766e-03, -5.8098e-03],
        ...,
        [-1.5137e-02,  2.1458e-03,  6.4049e-03,  ..., -1.2000e-01,
         -8.2302e-04,  2.9964e-03],
        [ 7.9269e-03, -7.9575e-03,  1.6602e-02,  ..., -4.5547e-03,
         -1.3391e-01,  1.5236e-02],
        [ 8.1940e-03, -5.1308e-04, -6.0158e-03,  ..., -1.2413e-02,
         -3.6449e-03, -1.0028e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1660, -0.0097, -0.0094,  ...,  0.0012,  0.0112, -0.0023],
        [-0.0154, -0.1680, -0.0032,  ...,  0.0009, -0.0030, -0.0009],
        [-0.0073, -0.0032, -0.1520,  ...,  0.0070,  0.0048, -0.0138],
        ...,
        [-0.0117,  0.0080,  0.0148,  ..., -0.1595, -0.0100,  0.0021],
        [-0.0025,  0.0042,  0.0128,  ..., -0.0054, -0.1516, -0.0069],
        [-0.0034,  0.0155, -0.0061,  ..., -0.0104, -0.0138, -0.1423]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 08:58:43 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 08:58:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.0615,  0.2384,  0.5576,  ..., -0.1119, -0.1895,  0.4314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3347,  0.2397, -0.1509,  ..., -1.0029, -0.7949,  0.4036],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.6387,  1.0195,  1.1729,  ..., -0.9497,  0.1509, -0.1587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4661,  0.9004, -0.2412,  ..., -1.4629, -1.2314,  0.6528],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 08:58:43 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 08:58:43 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 08:59:27 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 09:00:09 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 09:00:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.0054e-05, -7.8011e-04, -1.6012e-03,  ...,  3.3617e-05,
          2.9793e-03,  1.7986e-03],
        [-9.5844e-04,  3.9101e-03,  1.1024e-03,  ..., -2.3499e-03,
          3.6621e-03,  4.3755e-03],
        [ 2.3823e-03, -1.3933e-03,  1.3323e-03,  ...,  2.9507e-03,
         -7.3433e-04, -1.8396e-03],
        ...,
        [ 2.5139e-03,  6.3062e-05,  2.2583e-03,  ..., -8.0872e-04,
         -3.0327e-04,  8.2064e-04],
        [ 2.5311e-03, -1.9608e-03, -2.5702e-04,  ...,  4.9553e-03,
          2.5215e-03,  1.1206e-03],
        [-2.6512e-04, -1.0481e-03, -1.8263e-03,  ..., -2.1064e-04,
          1.2207e-04,  1.2531e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1187,  0.0156, -0.0078,  ..., -0.0036, -0.0015,  0.0030],
        [ 0.0145, -0.1208,  0.0012,  ...,  0.0054, -0.0055, -0.0091],
        [-0.0025, -0.0013, -0.1085,  ...,  0.0029,  0.0080, -0.0014],
        ...,
        [-0.0026, -0.0075, -0.0106,  ..., -0.0919,  0.0016, -0.0133],
        [ 0.0137,  0.0098,  0.0071,  ...,  0.0119, -0.1008,  0.0156],
        [ 0.0061, -0.0007, -0.0106,  ...,  0.0061,  0.0047, -0.1167]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1098,  0.0166,  0.0095,  ...,  0.0103, -0.0091, -0.0027],
        [ 0.0059, -0.0975,  0.0051,  ...,  0.0038, -0.0103, -0.0060],
        [ 0.0008,  0.0031, -0.1116,  ...,  0.0042, -0.0024,  0.0014],
        ...,
        [ 0.0087, -0.0074,  0.0015,  ..., -0.1089,  0.0101, -0.0034],
        [ 0.0061, -0.0050, -0.0016,  ...,  0.0020, -0.1186, -0.0008],
        [-0.0008, -0.0050,  0.0085,  ...,  0.0010, -0.0015, -0.1103]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:01:02 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 09:01:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.0410,  0.4597,  0.5708,  ..., -0.4368, -0.0927, -0.1113],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3457,  0.1718, -0.1370,  ..., -0.8960, -0.9473,  0.1321],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.8652,  1.7578,  0.7134,  ..., -0.8188, -0.4033,  0.4199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5586,  1.2510, -0.2830,  ..., -0.1318, -0.6143,  0.2944],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:01:02 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:01:02 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 09:01:54 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 09:02:45 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 09:03:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0059, -0.0005,  0.0006,  ..., -0.0037,  0.0015,  0.0002],
        [ 0.0020,  0.0039,  0.0020,  ..., -0.0003,  0.0021,  0.0035],
        [-0.0029, -0.0015,  0.0057,  ..., -0.0028,  0.0033, -0.0011],
        ...,
        [ 0.0011,  0.0029,  0.0074,  ...,  0.0080, -0.0072,  0.0051],
        [-0.0033,  0.0003, -0.0003,  ..., -0.0038,  0.0055,  0.0045],
        [-0.0017,  0.0002,  0.0018,  ..., -0.0005, -0.0022,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1976,  0.0093, -0.0028,  ..., -0.0088,  0.0011, -0.0030],
        [ 0.0072, -0.1838,  0.0061,  ..., -0.0202, -0.0021,  0.0015],
        [ 0.0040,  0.0013, -0.1915,  ..., -0.0038, -0.0070,  0.0003],
        ...,
        [-0.0075,  0.0007,  0.0187,  ..., -0.1987,  0.0115, -0.0007],
        [-0.0045,  0.0183, -0.0033,  ...,  0.0092, -0.1902,  0.0105],
        [ 0.0080,  0.0086, -0.0077,  ..., -0.0073,  0.0069, -0.1953]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.2070e-01,  1.0086e-02,  1.3321e-02,  ..., -1.8768e-02,
          3.5057e-03, -7.4310e-03],
        [ 6.4545e-03, -2.3303e-01, -1.0773e-02,  ..., -1.5244e-02,
          5.6343e-03,  2.0981e-04],
        [ 7.8812e-03,  6.4507e-03, -2.1838e-01,  ...,  3.2997e-04,
          7.4997e-03, -1.5320e-02],
        ...,
        [-5.9204e-03,  6.8169e-03,  6.6757e-03,  ..., -2.3706e-01,
          1.5747e-02, -6.2065e-03],
        [-9.6970e-03, -5.4779e-03,  2.4071e-03,  ...,  2.4307e-02,
         -2.1973e-01, -1.0519e-03],
        [ 1.1225e-03, -1.0185e-03, -1.6663e-02,  ..., -1.1375e-02,
         -1.6842e-03, -2.2363e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:03:39 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 09:03:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.1240,  0.6602,  0.6836,  ..., -0.6245,  0.0860, -0.1664],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3989,  0.7021, -0.2307,  ..., -1.1377, -0.9722,  0.4775],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.8418,  2.5332,  0.3511,  ..., -0.8252,  0.1953,  1.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1377,  0.6182, -0.8340,  ..., -0.7334, -0.3872,  0.8423],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:03:39 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:03:39 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 09:04:32 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 09:05:29 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 09:06:24 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-5.6763e-03,  2.6112e-03, -4.7326e-04,  ...,  3.0785e-03,
         -2.4643e-03, -1.0996e-03],
        [-9.9373e-04, -7.6523e-03, -4.9496e-04,  ...,  8.2827e-04,
         -5.7373e-03,  2.8801e-03],
        [ 5.1832e-04,  3.0689e-03, -1.0460e-02,  ...,  1.9226e-03,
         -2.5539e-03, -3.3245e-03],
        ...,
        [ 4.8637e-05,  7.5769e-04, -9.7656e-04,  ..., -2.8324e-03,
          6.5506e-05, -4.4131e-04],
        [-1.8892e-03,  1.4992e-03, -6.2466e-04,  ..., -4.5967e-03,
         -6.5498e-03,  1.4458e-03],
        [ 3.6297e-03,  3.5787e-04,  9.0218e-04,  ...,  3.1834e-03,
         -1.3895e-03, -8.9340e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0990,  0.0049,  0.0035,  ...,  0.0157, -0.0071,  0.0005],
        [ 0.0086, -0.0835,  0.0100,  ..., -0.0076, -0.0054,  0.0014],
        [-0.0111,  0.0002, -0.0786,  ..., -0.0023, -0.0012,  0.0062],
        ...,
        [-0.0035, -0.0084, -0.0063,  ..., -0.0701,  0.0036, -0.0012],
        [-0.0028,  0.0070, -0.0085,  ..., -0.0071, -0.1036,  0.0036],
        [-0.0172,  0.0139, -0.0147,  ...,  0.0012, -0.0016, -0.0785]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.5684e-02, -5.3902e-03, -6.1302e-03,  ...,  4.5853e-03,
         -1.2733e-02,  3.7651e-03],
        [ 4.1771e-03, -1.0065e-01, -6.4812e-03,  ...,  8.0032e-03,
          9.6970e-03,  2.1194e-02],
        [ 2.0523e-03, -1.0788e-02, -9.5886e-02,  ..., -5.7259e-03,
          9.4128e-04,  1.1948e-02],
        ...,
        [ 6.1417e-04,  3.7308e-03,  5.8365e-03,  ..., -8.6731e-02,
          2.8706e-04,  4.2267e-03],
        [ 1.6212e-05,  5.3444e-03, -1.3390e-02,  ...,  4.7684e-03,
         -9.7717e-02, -4.0207e-03],
        [ 5.8937e-03,  6.1989e-03, -3.3340e-03,  ...,  1.1566e-02,
         -2.3079e-04, -9.0393e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:06:26 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 09:06:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.1865,  1.0518,  0.4033,  ..., -0.5083, -0.2471,  0.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4368,  0.9185, -0.2150,  ..., -0.1157, -0.4580,  0.2037],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.8398,  1.9795, -0.1528,  ..., -0.2935,  0.9600,  1.3828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.4229,  0.5015, -1.4961,  ..., -0.8086,  0.4819,  0.6382],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:06:26 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:06:26 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 09:07:22 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 09:08:19 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 09:09:18 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0009, -0.0030,  0.0005,  ..., -0.0024,  0.0045, -0.0046],
        [-0.0020,  0.0047, -0.0025,  ...,  0.0015, -0.0040, -0.0025],
        [-0.0033, -0.0001,  0.0070,  ..., -0.0026, -0.0001, -0.0026],
        ...,
        [-0.0005, -0.0010,  0.0050,  ...,  0.0082, -0.0061,  0.0045],
        [ 0.0051, -0.0026,  0.0029,  ..., -0.0018, -0.0052,  0.0001],
        [-0.0017,  0.0082, -0.0009,  ..., -0.0103, -0.0040, -0.0006]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.3245e-01, -1.1871e-02,  3.7308e-03,  ..., -1.1757e-02,
          1.1398e-02,  1.2093e-02],
        [ 1.7042e-03, -1.4624e-01,  4.6349e-03,  ..., -1.4000e-02,
          2.1149e-02,  8.2588e-04],
        [ 4.9973e-03,  1.0567e-02, -1.3892e-01,  ..., -4.8485e-03,
          2.1378e-02, -1.2535e-02],
        ...,
        [-7.3891e-03, -5.1155e-03,  1.1314e-02,  ..., -1.5625e-01,
         -1.4610e-03,  1.0117e-02],
        [ 2.8191e-03,  2.8091e-02,  1.8406e-03,  ...,  5.4359e-05,
         -1.3818e-01, -3.4943e-03],
        [ 9.2316e-03, -1.3535e-02, -5.2032e-03,  ..., -1.7334e-02,
          6.0959e-03, -1.4087e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1471,  0.0045,  0.0018,  ..., -0.0158,  0.0202,  0.0153],
        [-0.0024, -0.1384,  0.0002,  ..., -0.0059,  0.0029,  0.0181],
        [-0.0038,  0.0049, -0.1606,  ..., -0.0197,  0.0106, -0.0091],
        ...,
        [-0.0081, -0.0098, -0.0160,  ..., -0.1464,  0.0022, -0.0111],
        [ 0.0044,  0.0046, -0.0080,  ...,  0.0036, -0.1655,  0.0027],
        [-0.0013,  0.0051,  0.0036,  ..., -0.0122,  0.0171, -0.1576]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:09:20 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-07-01 09:09:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.0625,  1.3770,  0.1539,  ..., -0.4670,  0.1335,  0.6387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7393,  0.3645, -0.5127,  ..., -0.4600, -0.2117,  0.4761],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8369,  2.4512, -0.2681,  ..., -1.0195,  1.6035,  1.3613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1621,  0.8032, -1.0361,  ..., -0.3547,  0.1821,  0.2246],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:09:20 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:09:20 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 09:10:19 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 09:11:18 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 09:12:17 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0019, -0.0029, -0.0006,  ...,  0.0017, -0.0108, -0.0018],
        [-0.0068, -0.0003, -0.0044,  ...,  0.0023,  0.0015, -0.0074],
        [-0.0012, -0.0081, -0.0024,  ...,  0.0093, -0.0017,  0.0026],
        ...,
        [-0.0007,  0.0030, -0.0069,  ...,  0.0003,  0.0017,  0.0008],
        [-0.0013, -0.0022,  0.0023,  ...,  0.0021,  0.0052,  0.0053],
        [-0.0016,  0.0011,  0.0003,  ..., -0.0027,  0.0007, -0.0041]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1208,  0.0185,  0.0034,  ...,  0.0009,  0.0025, -0.0059],
        [ 0.0088, -0.1272,  0.0145,  ...,  0.0012,  0.0050,  0.0010],
        [-0.0037, -0.0058, -0.0901,  ..., -0.0097,  0.0050,  0.0029],
        ...,
        [ 0.0007, -0.0049, -0.0109,  ..., -0.1080,  0.0201, -0.0025],
        [ 0.0074, -0.0107,  0.0156,  ...,  0.0072, -0.0995, -0.0034],
        [-0.0029,  0.0073, -0.0112,  ..., -0.0044,  0.0042, -0.1094]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2671e-01,  4.5929e-03, -1.3657e-03,  ..., -1.2207e-02,
         -7.8659e-03,  5.5389e-03],
        [ 1.3710e-02, -1.2384e-01,  8.2493e-04,  ...,  5.8517e-03,
          7.1526e-06,  4.3945e-03],
        [ 1.2398e-03, -9.7580e-03, -1.0645e-01,  ..., -2.1954e-03,
          2.3918e-03, -8.6212e-03],
        ...,
        [ 5.8289e-03,  2.7847e-03,  2.5921e-03,  ..., -1.2036e-01,
          1.6418e-02, -5.9967e-03],
        [-7.9269e-03, -1.3885e-03, -2.6340e-03,  ...,  8.5373e-03,
         -1.0931e-01,  3.9864e-03],
        [ 7.7820e-04,  6.8054e-03, -1.2077e-02,  ..., -1.0658e-02,
         -1.9455e-03, -1.1841e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:12:20 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-07-01 09:12:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.9722,  0.9810, -0.0759,  ..., -0.1611,  0.4873,  0.6772],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8735,  0.2681, -0.8442,  ..., -0.4810,  0.2896,  0.3508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.6655,  2.7266,  0.0635,  ..., -0.6709,  1.4355,  1.9668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0186,  0.4287, -1.5166,  ...,  0.6309,  0.0590,  1.4980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:12:20 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:12:20 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 09:13:22 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 09:14:24 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 09:15:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0017,  0.0003,  0.0001,  ..., -0.0002, -0.0013, -0.0002],
        [ 0.0022,  0.0016,  0.0024,  ..., -0.0009,  0.0010, -0.0014],
        [ 0.0001, -0.0050,  0.0060,  ..., -0.0008, -0.0026,  0.0021],
        ...,
        [ 0.0000, -0.0041,  0.0006,  ...,  0.0019, -0.0022,  0.0013],
        [ 0.0036, -0.0011,  0.0013,  ..., -0.0007,  0.0030, -0.0028],
        [ 0.0019,  0.0014,  0.0011,  ...,  0.0009,  0.0024,  0.0035]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.2561e-01, -6.7062e-03, -5.5885e-03,  ..., -2.0767e-02,
          4.9362e-03,  1.0727e-02],
        [ 5.3787e-03, -1.0730e-01, -5.1575e-03,  ...,  6.5384e-03,
         -9.6359e-03, -4.0016e-03],
        [ 1.3031e-02, -5.5552e-05, -1.2402e-01,  ...,  6.1646e-03,
          1.5755e-03, -5.8136e-03],
        ...,
        [-6.3057e-03, -2.0866e-03, -1.1581e-02,  ..., -1.1871e-01,
         -1.7151e-02,  1.0941e-02],
        [-1.4587e-02,  9.7427e-03,  1.1795e-02,  ..., -9.5367e-04,
         -1.2122e-01,  1.0025e-02],
        [ 1.4656e-02,  1.3084e-02,  9.1362e-04,  ..., -1.4099e-02,
          9.5520e-03, -1.1475e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.4880e-01, -1.8492e-03, -2.0279e-02,  ...,  1.1702e-03,
         -5.8060e-03,  2.0065e-03],
        [-8.5831e-05, -1.5405e-01, -7.0801e-03,  ..., -4.4556e-03,
         -1.6068e-02, -2.8038e-03],
        [-7.9880e-03, -1.1921e-03, -1.4392e-01,  ..., -2.6283e-03,
          1.0849e-02,  2.5616e-03],
        ...,
        [ 6.4850e-05, -3.2539e-03, -3.6850e-03,  ..., -1.5088e-01,
          5.8556e-03,  3.8910e-04],
        [ 4.4479e-03, -7.7858e-03, -7.5531e-03,  ...,  1.8082e-02,
         -1.5698e-01,  4.5509e-03],
        [ 1.5205e-02, -4.3869e-03,  4.1962e-03,  ...,  6.1417e-03,
          6.7329e-03, -1.4783e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:15:28 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-07-01 09:15:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4807,  1.2715, -0.1510,  ..., -0.5176,  0.8140,  0.6714],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.6733,  0.4412, -0.5420,  ..., -0.1873,  0.1027,  0.0958],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1113,  2.4473, -0.4561,  ..., -0.8096,  1.6357,  2.3789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1279, -0.0330, -2.0625,  ..., -0.1353,  0.5728,  1.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:15:29 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:15:29 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 09:16:30 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 09:17:33 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 09:18:38 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0075, -0.0052,  0.0013,  ..., -0.0069,  0.0003, -0.0005],
        [-0.0077, -0.0014,  0.0032,  ...,  0.0033,  0.0031,  0.0012],
        [-0.0072, -0.0040, -0.0059,  ..., -0.0042,  0.0017, -0.0002],
        ...,
        [-0.0027, -0.0019, -0.0036,  ..., -0.0002,  0.0002, -0.0035],
        [ 0.0007,  0.0031, -0.0002,  ..., -0.0013, -0.0099,  0.0009],
        [-0.0030,  0.0085,  0.0032,  ..., -0.0017,  0.0005, -0.0118]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0760,  0.0136, -0.0014,  ..., -0.0088,  0.0125, -0.0107],
        [ 0.0038, -0.0667,  0.0007,  ...,  0.0054,  0.0065, -0.0015],
        [-0.0148, -0.0202, -0.0789,  ..., -0.0066,  0.0083, -0.0018],
        ...,
        [-0.0260,  0.0035, -0.0158,  ..., -0.0822, -0.0075,  0.0019],
        [-0.0053,  0.0079, -0.0055,  ...,  0.0065, -0.0715, -0.0014],
        [ 0.0174,  0.0066,  0.0136,  ...,  0.0010, -0.0020, -0.0812]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1089,  0.0030,  0.0044,  ..., -0.0068,  0.0078, -0.0076],
        [ 0.0079, -0.0947, -0.0137,  ...,  0.0044,  0.0039,  0.0156],
        [ 0.0043,  0.0158, -0.1070,  ..., -0.0076, -0.0113, -0.0072],
        ...,
        [-0.0218,  0.0032, -0.0107,  ..., -0.0931, -0.0008,  0.0056],
        [ 0.0074,  0.0123, -0.0071,  ...,  0.0042, -0.1099,  0.0159],
        [-0.0015,  0.0036,  0.0191,  ..., -0.0089,  0.0046, -0.1080]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:18:40 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-07-01 09:18:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3354,  1.2910,  0.0271,  ..., -0.3140,  0.6836,  0.8853],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5161,  0.2079, -0.7051,  ...,  0.2937,  0.0427,  0.6924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.5000,  2.8105, -0.0105,  ..., -1.1885,  1.5918,  2.9824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0527, -0.7217, -2.2949,  ...,  0.3164,  1.2148,  1.7598],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:18:40 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:18:40 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 09:19:45 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 09:20:52 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 09:21:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0107, -0.0111, -0.0002,  ...,  0.0051, -0.0016, -0.0109],
        [-0.0071,  0.0135,  0.0015,  ..., -0.0042,  0.0006, -0.0008],
        [ 0.0018, -0.0049,  0.0028,  ..., -0.0033,  0.0008, -0.0055],
        ...,
        [-0.0083, -0.0085, -0.0053,  ...,  0.0025,  0.0055, -0.0010],
        [ 0.0084, -0.0010, -0.0048,  ..., -0.0043,  0.0034,  0.0005],
        [ 0.0064,  0.0033, -0.0041,  ..., -0.0021,  0.0039,  0.0010]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-5.2612e-02, -1.0347e-03, -2.0008e-03,  ..., -5.5733e-03,
          8.7738e-03,  3.1281e-04],
        [-6.3248e-03, -7.2083e-02,  9.9659e-05,  ..., -1.3031e-02,
          1.5198e-02,  7.1144e-03],
        [ 3.3684e-03, -6.5384e-03, -6.8726e-02,  ..., -2.4155e-02,
         -1.3016e-02, -1.4999e-02],
        ...,
        [ 2.4109e-03, -1.7517e-02,  1.8845e-03,  ..., -6.5002e-02,
          1.4000e-02, -1.8158e-02],
        [ 1.4954e-02,  8.4076e-03, -1.3065e-03,  ...,  1.2283e-02,
         -8.2092e-02,  8.7433e-03],
        [-1.0971e-02,  2.2675e-02,  3.8586e-03,  ..., -1.0529e-02,
          1.5961e-02, -6.8054e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0382e-01, -7.9422e-03,  2.5024e-03,  ..., -4.7607e-03,
          2.6436e-03,  3.6106e-03],
        [-2.4319e-03, -1.2158e-01,  1.7609e-02,  ..., -1.1002e-02,
         -2.5539e-03, -2.8305e-03],
        [ 8.3008e-03, -1.2703e-02, -1.1865e-01,  ..., -1.1124e-02,
         -3.5095e-04, -1.2001e-02],
        ...,
        [ 3.5515e-03, -1.4091e-02,  7.4577e-03,  ..., -1.0083e-01,
          7.3204e-03,  3.9825e-03],
        [ 1.6861e-03,  4.4518e-03,  6.1798e-03,  ...,  1.6205e-02,
         -1.3428e-01,  4.0932e-03],
        [-5.9586e-03,  1.5688e-03, -6.4354e-03,  ...,  1.6718e-03,
         -1.2016e-04, -1.0345e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:21:59 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-07-01 09:21:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5366,  1.1191, -0.2181,  ..., -0.3723,  0.7622,  1.0654],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5288, -0.0072, -0.9102,  ..., -0.0604,  0.2678,  0.6284],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.4248,  3.2578, -0.7354,  ..., -0.6211,  1.8096,  3.6172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.2119, -1.3779, -4.5352,  ...,  0.0366,  0.8428,  2.1914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:21:59 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:21:59 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 09:23:08 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 09:24:18 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 09:25:25 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0116, -0.0065,  0.0038,  ..., -0.0031,  0.0020,  0.0058],
        [ 0.0011,  0.0129, -0.0020,  ...,  0.0031,  0.0055, -0.0051],
        [ 0.0008, -0.0026,  0.0117,  ...,  0.0134,  0.0033, -0.0065],
        ...,
        [ 0.0068,  0.0002, -0.0050,  ...,  0.0085,  0.0045, -0.0031],
        [ 0.0046, -0.0022,  0.0076,  ..., -0.0073,  0.0070,  0.0019],
        [ 0.0051, -0.0057,  0.0014,  ...,  0.0115,  0.0049,  0.0127]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0520,  0.0145,  0.0007,  ..., -0.0010,  0.0036, -0.0060],
        [ 0.0043, -0.0718,  0.0050,  ..., -0.0053,  0.0042,  0.0192],
        [ 0.0011,  0.0014, -0.0562,  ..., -0.0121, -0.0004,  0.0018],
        ...,
        [ 0.0022,  0.0158, -0.0134,  ..., -0.0566,  0.0044, -0.0013],
        [-0.0037, -0.0006, -0.0062,  ..., -0.0057, -0.0566, -0.0136],
        [ 0.0025, -0.0052, -0.0086,  ..., -0.0071,  0.0052, -0.0672]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1072,  0.0293, -0.0034,  ...,  0.0007, -0.0092, -0.0108],
        [-0.0016, -0.1477,  0.0072,  ..., -0.0120, -0.0013,  0.0141],
        [-0.0055, -0.0242, -0.1145,  ..., -0.0194,  0.0092, -0.0091],
        ...,
        [ 0.0053, -0.0024, -0.0162,  ..., -0.1213,  0.0134,  0.0121],
        [-0.0076, -0.0064, -0.0130,  ..., -0.0231, -0.1147, -0.0156],
        [-0.0166, -0.0026, -0.0443,  ..., -0.0079, -0.0158, -0.1328]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:25:27 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-07-01 09:25:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6948,  1.2490, -0.0282,  ..., -0.5312,  0.7329,  1.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4629, -0.3120, -0.9658,  ...,  0.1312,  0.5435,  0.7222],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.3760,  2.9766, -1.5098,  ..., -0.1416,  1.4043,  3.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.1035, -1.2852, -5.8711,  ...,  0.3899,  0.7104,  1.6201],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:25:27 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:25:27 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 09:26:38 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 09:27:48 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 09:28:58 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0027,  0.0055,  0.0088,  ...,  0.0066,  0.0029, -0.0108],
        [ 0.0124, -0.0029,  0.0002,  ...,  0.0047,  0.0058, -0.0005],
        [ 0.0121, -0.0096, -0.0019,  ...,  0.0152,  0.0017, -0.0065],
        ...,
        [-0.0165, -0.0043,  0.0004,  ..., -0.0028,  0.0045, -0.0005],
        [ 0.0022, -0.0012, -0.0064,  ...,  0.0065, -0.0072, -0.0002],
        [-0.0030,  0.0035, -0.0071,  ..., -0.0088,  0.0023,  0.0050]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0210,  0.0095,  0.0023,  ..., -0.0079,  0.0128, -0.0073],
        [ 0.0145, -0.0083, -0.0051,  ..., -0.0019,  0.0023, -0.0037],
        [-0.0089,  0.0046, -0.0180,  ..., -0.0027,  0.0081, -0.0084],
        ...,
        [-0.0139, -0.0087, -0.0025,  ..., -0.0241,  0.0146,  0.0061],
        [-0.0058,  0.0100, -0.0081,  ..., -0.0126, -0.0287,  0.0036],
        [-0.0042,  0.0033, -0.0108,  ..., -0.0092,  0.0004, -0.0404]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0588, -0.0034,  0.0163,  ..., -0.0077, -0.0086, -0.0061],
        [-0.0008, -0.0629, -0.0103,  ..., -0.0080,  0.0098,  0.0005],
        [ 0.0156, -0.0050, -0.0681,  ..., -0.0140,  0.0047,  0.0264],
        ...,
        [-0.0170,  0.0186, -0.0033,  ..., -0.0415,  0.0013, -0.0057],
        [ 0.0153,  0.0106, -0.0112,  ...,  0.0056, -0.0795,  0.0175],
        [ 0.0003,  0.0005,  0.0163,  ...,  0.0007,  0.0124, -0.0767]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:29:00 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-07-01 09:29:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5981,  1.3311, -0.3093,  ..., -0.2510,  0.7241,  1.4697],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4585, -0.5259, -1.6348,  ...,  0.0180,  0.3066,  0.7974],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1807,  2.1016, -0.8457,  ..., -0.0198,  1.5996,  3.8613],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-2.3379, -1.3057, -5.9336,  ...,  0.7515,  2.0234,  1.3809],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:29:00 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:29:00 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 09:30:12 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 09:31:25 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 09:32:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0174, -0.0024, -0.0016,  ...,  0.0084, -0.0041,  0.0005],
        [-0.0090,  0.0170,  0.0018,  ...,  0.0045, -0.0028, -0.0018],
        [ 0.0011,  0.0022,  0.0222,  ..., -0.0016,  0.0049,  0.0048],
        ...,
        [ 0.0051, -0.0034, -0.0011,  ...,  0.0150, -0.0092,  0.0062],
        [-0.0045, -0.0011,  0.0035,  ..., -0.0063,  0.0181, -0.0022],
        [-0.0014, -0.0056,  0.0036,  ...,  0.0007,  0.0081,  0.0226]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0169,  0.0089,  0.0051,  ..., -0.0038,  0.0007,  0.0060],
        [ 0.0071, -0.0360,  0.0040,  ...,  0.0017, -0.0097, -0.0021],
        [-0.0021, -0.0106, -0.0327,  ...,  0.0068, -0.0049, -0.0049],
        ...,
        [ 0.0035, -0.0003, -0.0089,  ..., -0.0265,  0.0044, -0.0194],
        [ 0.0045,  0.0042, -0.0016,  ..., -0.0062, -0.0123, -0.0049],
        [ 0.0008, -0.0046, -0.0144,  ...,  0.0036, -0.0132, -0.0299]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0398,  0.0268,  0.0108,  ...,  0.0033, -0.0040,  0.0154],
        [ 0.0113, -0.0717, -0.0103,  ...,  0.0088, -0.0004,  0.0189],
        [-0.0016, -0.0147, -0.0429,  ..., -0.0082,  0.0003, -0.0172],
        ...,
        [-0.0079, -0.0164, -0.0323,  ..., -0.0652,  0.0088, -0.0060],
        [ 0.0090,  0.0009, -0.0028,  ..., -0.0008, -0.0598,  0.0086],
        [-0.0010, -0.0007, -0.0107,  ...,  0.0056, -0.0062, -0.0616]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:32:39 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-07-01 09:32:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5449,  1.1562, -0.5957,  ..., -0.0693,  0.5527,  1.3730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.7627, -0.4734, -2.0996,  ...,  0.1292,  0.2649,  0.5635],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.7383,  2.1016,  0.2070,  ...,  0.4607,  1.4531,  3.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.6875, -0.5752, -5.5352,  ..., -0.3276,  1.3096,  0.9604],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:32:39 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:32:39 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 09:33:57 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 09:35:16 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 09:36:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0004,  0.0020,  0.0014,  ..., -0.0038, -0.0012,  0.0004],
        [-0.0013,  0.0007,  0.0010,  ..., -0.0015,  0.0011, -0.0004],
        [-0.0039, -0.0014,  0.0017,  ..., -0.0040,  0.0006, -0.0002],
        ...,
        [-0.0016,  0.0005, -0.0005,  ...,  0.0002, -0.0016, -0.0025],
        [-0.0007, -0.0004,  0.0010,  ...,  0.0009,  0.0007, -0.0006],
        [-0.0007,  0.0009,  0.0001,  ..., -0.0018,  0.0029,  0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-9.3613e-03, -1.4648e-02, -3.2959e-03,  ..., -2.4231e-02,
         -2.4247e-04,  9.3994e-03],
        [ 1.0254e-02, -3.4241e-02, -8.1863e-03,  ...,  1.1978e-02,
         -1.9350e-03, -1.8738e-02],
        [ 1.6403e-02, -1.9140e-03, -9.9640e-03,  ..., -1.5137e-02,
          3.7651e-03, -3.2730e-03],
        ...,
        [-1.5221e-02,  3.8414e-03, -2.7180e-05,  ..., -2.2522e-02,
          2.4796e-03, -1.4236e-02],
        [-1.0231e-02,  5.0926e-03, -1.9102e-03,  ..., -8.7833e-04,
         -1.7899e-02, -9.7275e-03],
        [-8.9874e-03,  6.0310e-03, -4.9133e-03,  ...,  1.0567e-03,
         -9.2468e-03, -3.1372e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-7.5500e-02,  5.0316e-03, -7.6714e-03,  ...,  8.2588e-04,
         -1.6418e-02,  1.1032e-02],
        [ 1.0345e-02, -8.0811e-02, -1.8661e-02,  ...,  9.9945e-03,
          8.4076e-03,  4.1437e-04],
        [-5.5008e-03, -2.7418e-05, -6.1340e-02,  ..., -1.5305e-02,
         -6.6071e-03, -3.3455e-03],
        ...,
        [ 8.6975e-03, -6.4087e-04,  1.4282e-02,  ..., -6.9824e-02,
          4.8370e-03,  2.0885e-04],
        [ 5.2757e-03, -9.6893e-03,  3.9215e-03,  ..., -9.5825e-03,
         -7.2754e-02, -8.7357e-03],
        [ 5.7297e-03,  1.0803e-02, -7.2250e-03,  ...,  3.4084e-03,
         -2.5101e-02, -7.5806e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:36:37 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-07-01 09:36:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4646,  0.7842, -0.3311,  ..., -0.0037,  0.6270,  1.4893],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.8472, -0.4546, -2.0762,  ...,  0.2695,  0.7378,  0.4751],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.6953,  2.0586,  1.3271,  ...,  0.4519,  1.7432,  3.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.3193, -0.1716, -5.1680,  ..., -1.3633,  2.6289,  1.2002],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:36:37 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:36:37 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 09:37:56 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 09:39:20 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 09:40:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.9645e-04, -1.7395e-03,  1.2493e-04,  ...,  1.2627e-03,
         -1.6489e-03, -2.6059e-04],
        [ 1.5128e-04, -8.9312e-04, -4.6420e-04,  ...,  9.5177e-04,
         -1.0071e-03, -6.1560e-04],
        [-1.0529e-03,  2.2144e-03, -7.4148e-04,  ..., -1.0185e-03,
          5.0545e-04,  3.7670e-04],
        ...,
        [-1.5965e-03,  1.8559e-03, -2.3007e-04,  ..., -2.1629e-03,
          1.4648e-03,  1.7118e-03],
        [-1.0514e-04,  3.7646e-04,  6.2323e-04,  ..., -1.0090e-03,
         -3.3879e-04,  1.4515e-03],
        [ 8.1348e-04, -8.7261e-04, -3.1412e-05,  ..., -1.5438e-05,
         -1.1101e-03, -6.6280e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0328,  0.0009, -0.0099,  ...,  0.0089,  0.0015,  0.0071],
        [-0.0058, -0.0299, -0.0090,  ...,  0.0106,  0.0052,  0.0112],
        [-0.0048,  0.0029, -0.0412,  ..., -0.0025,  0.0059,  0.0022],
        ...,
        [-0.0061,  0.0065,  0.0083,  ..., -0.0228,  0.0111, -0.0076],
        [ 0.0149, -0.0034, -0.0009,  ...,  0.0091, -0.0367,  0.0104],
        [ 0.0113, -0.0097,  0.0031,  ...,  0.0200,  0.0043, -0.0365]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0701,  0.0060, -0.0008,  ..., -0.0109,  0.0149,  0.0142],
        [ 0.0084, -0.0766, -0.0048,  ..., -0.0001,  0.0039,  0.0064],
        [-0.0180, -0.0007, -0.0974,  ..., -0.0196, -0.0086,  0.0136],
        ...,
        [-0.0069,  0.0155, -0.0045,  ..., -0.0527, -0.0004,  0.0115],
        [ 0.0122,  0.0003,  0.0148,  ...,  0.0119, -0.0612, -0.0154],
        [ 0.0155, -0.0093, -0.0213,  ...,  0.0052,  0.0004, -0.0740]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:40:47 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-07-01 09:40:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6514,  0.7627,  0.0491,  ...,  0.1715,  0.5601,  1.2158],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5737, -0.1892, -1.8584,  ..., -0.1023,  0.4683,  0.3027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1211,  2.4199,  2.1094,  ...,  0.9443,  2.1914,  3.7578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.0986, -0.1375, -4.0742,  ..., -1.1250,  3.9883,  3.5273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:40:47 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:40:47 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 09:42:05 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 09:43:30 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 09:44:56 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 9.9301e-05,  4.8542e-04,  1.2898e-04,  ...,  1.5821e-03,
         -1.5712e-04, -9.4223e-04],
        [-7.8106e-04,  9.3269e-04, -2.4021e-04,  ...,  1.6747e-03,
          1.6713e-04, -4.3416e-04],
        [-1.0395e-03,  9.9373e-04,  2.2769e-04,  ...,  1.3566e-04,
          1.5283e-04,  2.6178e-04],
        ...,
        [-1.1148e-03, -8.5211e-04,  6.4945e-04,  ..., -1.8501e-03,
         -5.9366e-04, -7.2479e-04],
        [-2.5821e-04, -2.2185e-04,  1.1045e-04,  ..., -1.3208e-04,
         -8.4639e-04,  6.1274e-04],
        [-6.2132e-04,  7.4196e-04,  6.6137e-04,  ...,  2.3067e-04,
          1.2360e-03, -2.0046e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0096,  0.0027,  0.0051,  ..., -0.0037,  0.0010, -0.0128],
        [ 0.0263, -0.0159, -0.0005,  ...,  0.0074, -0.0002, -0.0116],
        [ 0.0078, -0.0031, -0.0243,  ..., -0.0249,  0.0142, -0.0034],
        ...,
        [ 0.0097, -0.0027, -0.0065,  ..., -0.0031,  0.0008, -0.0028],
        [ 0.0054,  0.0044,  0.0063,  ...,  0.0202, -0.0054,  0.0100],
        [ 0.0001,  0.0055,  0.0206,  ..., -0.0022,  0.0211, -0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.5023e-02,  1.3206e-02,  9.7580e-03,  ...,  7.8106e-04,
         -1.4549e-02, -7.8506e-03],
        [-7.0877e-03, -5.0629e-02, -3.4065e-03,  ..., -7.6218e-03,
         -1.0918e-02,  1.9360e-03],
        [-2.2240e-03,  1.9073e-06, -7.4951e-02,  ..., -1.8967e-02,
          1.0017e-02,  1.5434e-02],
        ...,
        [ 3.5492e-02,  9.2010e-03, -9.9792e-03,  ..., -4.4037e-02,
         -1.0788e-02, -4.0680e-02],
        [ 1.4717e-02,  1.8753e-02,  1.9798e-03,  ...,  2.0737e-02,
         -6.8542e-02,  6.7825e-03],
        [-1.8265e-02,  1.6079e-03,  5.8899e-03,  ...,  1.7853e-02,
         -1.9043e-02, -1.0571e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:44:58 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-07-01 09:44:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.5996,  0.7197,  0.4124,  ...,  0.1449,  0.6255,  1.2324],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.4373, -0.0278, -1.7441,  ..., -0.4502,  0.8906,  0.3774],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1201,  2.3594,  2.2969,  ...,  0.5713,  1.7695,  4.1172],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9541,  0.1060, -3.4922,  ..., -1.1299,  4.9219,  3.9336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:44:59 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:44:59 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 09:46:24 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 09:47:49 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 09:49:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.3823e-03,  1.5831e-04, -4.7207e-04,  ...,  1.1702e-03,
          8.3256e-04,  8.1062e-04],
        [-9.4604e-04, -4.4942e-05,  5.2452e-04,  ..., -7.2765e-04,
         -7.5197e-04, -6.7663e-04],
        [ 2.9325e-04, -5.7650e-04,  1.0939e-03,  ..., -8.2588e-04,
          3.4904e-04,  4.5240e-05],
        ...,
        [ 4.5242e-03,  3.3665e-04, -4.8399e-04,  ...,  4.8523e-03,
         -1.4400e-03, -2.5749e-03],
        [ 1.6670e-03,  1.4572e-03, -2.2352e-05,  ...,  1.7567e-03,
          2.2907e-03, -1.4238e-03],
        [ 2.6531e-03, -1.5192e-03, -1.8234e-03,  ...,  1.6308e-03,
         -1.3494e-03,  2.1954e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 2.2919e-02, -1.9932e-04,  6.8207e-03,  ...,  2.8362e-03,
          1.9112e-03,  1.8509e-02],
        [-3.5820e-03, -1.4107e-02, -9.2316e-03,  ..., -5.9471e-03,
         -1.0014e-03,  7.2861e-03],
        [ 5.1155e-03,  4.6387e-03,  2.9099e-02,  ..., -6.8378e-04,
         -2.7466e-02, -3.6182e-03],
        ...,
        [-4.2686e-03, -3.0499e-03, -2.7039e-02,  ...,  3.5522e-02,
          5.9395e-03, -2.0885e-03],
        [-1.9550e-05, -7.7324e-03, -3.3798e-03,  ..., -9.8114e-03,
          9.5291e-03,  1.6365e-03],
        [-2.9411e-03,  1.5114e-02, -3.7308e-03,  ..., -1.0757e-02,
          5.9547e-03,  3.8544e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.4261e-02, -2.8946e-02, -2.4242e-03,  ...,  2.9175e-02,
          2.1515e-03,  2.4841e-02],
        [ 6.5727e-03, -5.6122e-02,  5.9357e-03,  ..., -2.7428e-03,
         -1.0834e-02,  1.6327e-02],
        [ 3.8300e-03,  2.5940e-02, -3.6560e-02,  ..., -6.8665e-04,
          2.2678e-03,  1.3933e-03],
        ...,
        [-9.1553e-05, -1.9180e-02, -2.9984e-03,  ..., -4.8828e-02,
         -6.1989e-03,  3.0899e-03],
        [ 6.2370e-03, -3.7766e-03,  1.1002e-02,  ...,  9.0637e-03,
         -3.3905e-02,  3.8116e-02],
        [-1.7242e-02,  2.0798e-02, -1.8097e-02,  ...,  1.7029e-02,
         -1.7662e-03, -2.7588e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:49:24 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 09:49:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3403,  0.7686,  0.6235,  ...,  0.2625,  0.6992,  1.1973],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3362, -0.0187, -1.3906,  ..., -0.3997,  1.2979,  1.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.0596,  2.1992,  1.7529,  ...,  1.0615,  1.6475,  4.8906],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.9648,  0.2228, -3.1934,  ...,  0.0889,  6.5352,  7.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:49:24 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:49:24 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 09:50:51 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 09:52:17 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 09:53:44 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.5545e-04, -3.1090e-04, -2.7108e-04,  ..., -3.8576e-04,
          8.0228e-05,  4.7159e-04],
        [ 7.4863e-04,  3.9339e-04, -2.5606e-04,  ...,  2.7180e-05,
         -2.5773e-04, -5.3644e-06],
        [-2.0218e-04,  4.3726e-04,  2.6131e-04,  ...,  5.5730e-05,
          1.7238e-04,  1.8692e-04],
        ...,
        [ 3.9482e-04,  8.7798e-05, -3.2878e-04,  ...,  4.5681e-04,
         -1.7929e-04, -5.1641e-04],
        [ 8.9347e-05, -9.7811e-05,  1.0312e-05,  ..., -5.4073e-04,
          2.5749e-04, -1.4961e-05],
        [-5.2357e-04, -3.9721e-04, -2.9755e-04,  ...,  8.6427e-06,
          3.0303e-04,  3.8028e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0252,  0.0104, -0.0005,  ..., -0.0124,  0.0054,  0.0135],
        [-0.0060,  0.0010,  0.0077,  ..., -0.0015,  0.0036, -0.0086],
        [ 0.0025, -0.0014, -0.0010,  ...,  0.0073,  0.0020,  0.0059],
        ...,
        [-0.0044,  0.0116,  0.0026,  ..., -0.0017, -0.0134, -0.0007],
        [ 0.0074,  0.0254, -0.0025,  ..., -0.0018,  0.0064, -0.0005],
        [-0.0027, -0.0032, -0.0061,  ...,  0.0122,  0.0134,  0.0082]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-4.3640e-02,  1.6068e-02, -1.2405e-02,  ...,  1.7059e-02,
          4.3154e-04,  3.0777e-02],
        [-7.1487e-03, -6.5979e-02, -5.6458e-03,  ...,  8.4534e-03,
          1.6129e-02, -3.2684e-02],
        [-8.4152e-03, -1.4389e-02, -4.3518e-02,  ...,  1.6846e-02,
          1.5011e-03,  1.2695e-02],
        ...,
        [-3.8147e-05,  1.2100e-02,  5.0812e-03,  ..., -6.8298e-02,
          8.3542e-03, -1.5327e-02],
        [ 5.3902e-03,  1.7944e-02, -1.1848e-02,  ..., -4.6158e-03,
         -8.7830e-02,  1.1490e-02],
        [ 1.3168e-02,  8.7280e-03,  1.2947e-02,  ...,  7.5417e-03,
         -3.5248e-02, -5.1270e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:53:46 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 09:53:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2847,  0.6958,  0.5762,  ...,  0.0662,  0.4858,  1.1680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2559,  0.0612, -1.1758,  ..., -0.4492,  1.5146,  1.2061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.8018, 2.4082, 0.3691,  ..., 0.5083, 0.8555, 3.2129], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-1.1357,  0.7812, -4.2812,  ..., -0.5903,  7.5703,  7.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:53:46 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:53:46 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 09:55:15 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 09:56:41 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 09:58:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0376e-02, -9.6035e-04, -9.3222e-05,  ..., -1.1816e-03,
          7.3195e-04, -1.3018e-03],
        [ 1.3447e-03,  5.9280e-03, -4.0674e-04,  ..., -2.4939e-04,
         -9.5844e-04,  7.9632e-04],
        [ 8.8263e-04, -9.8991e-04,  9.1171e-03,  ..., -1.3447e-03,
         -7.4434e-04,  5.6362e-04],
        ...,
        [-9.9373e-04, -5.8126e-04, -6.1512e-04,  ...,  1.0742e-02,
         -2.1877e-03, -1.2665e-03],
        [ 9.1934e-04, -6.6698e-05, -9.0456e-04,  ..., -1.0414e-03,
          1.4069e-02, -1.5283e-04],
        [-2.1420e-03, -5.9783e-05, -4.1604e-04,  ..., -6.4182e-04,
          6.7294e-05,  1.4061e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 2.5299e-02, -2.6722e-03, -7.1640e-03,  ..., -5.8441e-03,
          3.0716e-02, -1.6785e-03],
        [ 1.0086e-02, -2.6836e-03,  2.7962e-03,  ...,  8.2970e-05,
          1.0086e-02, -1.3443e-02],
        [-5.8136e-03, -2.5009e-02,  1.7548e-02,  ..., -6.0654e-04,
          3.1567e-03, -8.3923e-03],
        ...,
        [ 7.6637e-03,  2.6817e-03, -1.8143e-02,  ...,  1.5839e-02,
         -5.7983e-03,  1.1665e-02],
        [-4.1819e-04, -5.1498e-03, -2.1210e-02,  ..., -1.7776e-02,
          1.6510e-02,  8.0719e-03],
        [-4.7607e-03,  1.0567e-02, -4.4556e-03,  ..., -2.0390e-03,
          7.9727e-03,  4.5013e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.2589e-02,  1.2657e-02,  2.0203e-02,  ..., -7.1220e-03,
          1.3962e-02,  2.5742e-02],
        [ 2.1759e-02, -8.9966e-02,  1.3931e-02,  ...,  1.7986e-03,
          8.9645e-05, -1.0101e-02],
        [-1.3947e-02,  7.2002e-04, -2.3987e-02,  ..., -1.8539e-02,
          1.1230e-02,  5.7793e-03],
        ...,
        [ 1.8204e-02,  2.2507e-02, -1.5659e-03,  ..., -5.1636e-02,
          8.6288e-03, -7.9117e-03],
        [-1.7685e-02,  1.8890e-02, -2.9053e-02,  ..., -5.7449e-03,
         -1.4725e-02,  1.5915e-02],
        [ 4.3106e-03,  3.0060e-02,  3.6602e-03,  ..., -1.5411e-02,
          3.0212e-02, -1.2085e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:58:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you examine something, you are a examiner
If you speak something, you are a speaker
If you perform something, you are a performer
If you suffer something, you are a sufferer
If you compose something, you are a composer
If you announce something, you are a
2024-07-01 09:58:12 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 09:58:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8921, -0.5557, -0.1487,  ...,  0.7437,  0.3887,  0.4155],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1511,  0.1127, -0.1427,  ..., -0.3796,  0.0344,  0.0311],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.2734, -0.5752, -0.1305,  ...,  0.3423, -0.2698,  0.6450],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0297,  0.2549,  0.1653,  ..., -0.7603, -0.2332, -0.1836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:58:12 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 09:58:12 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 09:58:35 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 09:58:58 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 09:59:22 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-6.5899e-04, -5.0402e-04,  1.9956e-04,  ...,  7.3254e-05,
          5.2023e-04, -1.4400e-04],
        [-3.4451e-04, -6.4945e-04, -2.1541e-04,  ...,  8.9943e-05,
          2.0802e-04,  9.0122e-05],
        [ 3.9840e-04, -1.5807e-04, -1.0700e-03,  ..., -2.0432e-04,
         -2.0623e-04,  8.6069e-05],
        ...,
        [-8.5473e-05, -5.2643e-04,  1.9717e-04,  ..., -3.6764e-04,
          4.0483e-04, -7.4506e-05],
        [ 5.3835e-04, -1.0657e-04, -4.0746e-04,  ...,  4.8256e-04,
         -1.1873e-03,  2.0409e-04],
        [ 5.3465e-05,  4.5395e-04, -2.1625e-04,  ...,  5.5432e-06,
         -4.2248e-04, -9.0170e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.0701e-02,  5.6124e-04, -9.2316e-04,  ..., -1.2608e-03,
         -5.1613e-03, -1.6880e-03],
        [-4.3221e-03, -2.6245e-02,  2.1896e-03,  ...,  2.1362e-04,
         -1.9951e-03, -1.4305e-05],
        [ 2.6093e-03,  1.4210e-03, -4.0436e-02,  ..., -4.7607e-03,
         -4.0817e-04,  1.2445e-03],
        ...,
        [ 1.3456e-03,  3.4637e-03, -5.0888e-03,  ..., -2.9892e-02,
          1.3494e-04, -5.0812e-03],
        [-1.2302e-04, -2.2354e-03,  5.6725e-03,  ..., -1.9159e-03,
         -3.0563e-02,  1.6117e-04],
        [ 6.8932e-03, -9.7198e-03, -4.5090e-03,  ..., -3.3975e-04,
          1.0139e-02, -2.9984e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0379,  0.0006,  0.0012,  ..., -0.0021, -0.0006,  0.0010],
        [ 0.0015, -0.0399,  0.0007,  ...,  0.0035,  0.0080,  0.0023],
        [-0.0051,  0.0021, -0.0363,  ..., -0.0029,  0.0021,  0.0029],
        ...,
        [ 0.0033,  0.0040,  0.0002,  ..., -0.0395,  0.0027,  0.0042],
        [-0.0041,  0.0030,  0.0009,  ..., -0.0011, -0.0369,  0.0076],
        [-0.0011, -0.0007, -0.0012,  ...,  0.0025,  0.0062, -0.0362]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 09:59:24 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 09:59:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.3027, -0.4995, -0.1281,  ...,  0.5146, -0.2285,  0.8198],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1210,  0.1862,  0.0416,  ..., -0.6787, -0.1545, -0.1781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.5029, -0.3564, -0.4590,  ...,  0.3108, -0.2891,  0.6406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0161,  0.4949,  0.3572,  ..., -1.2900, -0.4514,  0.0242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 09:59:24 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 09:59:24 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 09:59:48 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 10:00:13 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 10:00:37 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.4447e-03,  1.4038e-03,  8.6498e-04,  ..., -9.0504e-04,
          2.0361e-04, -7.5150e-04],
        [ 4.1008e-04, -4.9515e-03, -1.5366e-04,  ..., -1.5335e-03,
         -5.2071e-04, -4.3297e-04],
        [ 9.0218e-04, -1.0586e-03, -4.1809e-03,  ..., -1.4324e-03,
          1.6985e-03, -3.7503e-04],
        ...,
        [-4.9925e-04,  4.9591e-04,  1.2338e-04,  ..., -5.1346e-03,
         -2.3384e-03, -5.7793e-04],
        [ 3.0565e-04, -6.3181e-05,  1.1835e-03,  ..., -1.0633e-03,
         -3.7766e-03, -3.0851e-04],
        [-7.2861e-04,  1.0881e-03,  6.4325e-04,  ..., -4.2057e-04,
         -2.8682e-04, -3.9482e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.1228e-02, -8.3923e-05, -1.2291e-02,  ...,  4.9095e-03,
          1.0468e-02, -7.8430e-03],
        [ 2.1706e-03, -7.6843e-02, -7.8773e-04,  ...,  3.8586e-03,
          1.6527e-03,  1.6602e-02],
        [ 1.6212e-04, -9.3155e-03, -6.4087e-02,  ...,  5.1651e-03,
          3.4027e-03, -1.1406e-02],
        ...,
        [ 2.7294e-03,  4.0932e-03, -6.5651e-03,  ..., -7.2083e-02,
          1.6403e-04, -2.4548e-03],
        [ 3.9673e-03, -4.9515e-03,  4.8981e-03,  ..., -6.1798e-03,
         -6.3416e-02,  4.8599e-03],
        [-3.8624e-03, -5.8670e-03, -8.6441e-03,  ..., -2.4910e-03,
          4.0054e-03, -7.2876e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0619,  0.0094, -0.0034,  ...,  0.0054,  0.0014,  0.0003],
        [-0.0005, -0.0594, -0.0002,  ...,  0.0006, -0.0043,  0.0044],
        [-0.0021,  0.0021, -0.0469,  ...,  0.0038,  0.0026,  0.0007],
        ...,
        [-0.0026,  0.0063, -0.0020,  ..., -0.0544, -0.0062,  0.0043],
        [ 0.0021, -0.0040,  0.0050,  ...,  0.0015, -0.0527,  0.0001],
        [ 0.0013, -0.0022, -0.0020,  ..., -0.0032,  0.0073, -0.0601]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:00:39 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 10:00:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.6592, -0.7769, -0.1727,  ...,  0.4146, -0.3435,  0.8232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0623,  0.3950,  0.2595,  ..., -1.1396, -0.3584, -0.3191],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.8096, -0.6719, -0.6216,  ...,  0.7646, -0.2651,  0.5181],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2578,  0.4290,  0.3975,  ..., -0.8496, -0.6250,  0.3057],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:00:39 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:00:39 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 10:01:05 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 10:01:30 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 10:01:55 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.8141e-03, -9.5463e-04, -3.4332e-03,  ...,  5.2071e-04,
         -7.7200e-04, -6.6566e-04],
        [ 5.6076e-04, -5.0278e-03,  3.5286e-05,  ...,  6.6996e-05,
         -1.0757e-03,  8.9836e-04],
        [-2.1553e-03, -3.4094e-05, -4.6234e-03,  ...,  6.4564e-04,
         -4.1723e-05, -9.0694e-04],
        ...,
        [-6.4564e-04,  6.8283e-04, -1.5306e-04,  ..., -4.6082e-03,
         -2.1994e-05, -8.2636e-04],
        [-2.0325e-04,  1.2512e-03,  1.1027e-05,  ...,  7.7248e-04,
         -5.1956e-03, -9.6035e-04],
        [ 5.1069e-04,  1.4973e-04, -1.1027e-05,  ...,  5.2452e-04,
          9.0742e-04, -5.7678e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-4.3579e-02, -8.1940e-03, -2.6913e-03,  ...,  4.1542e-03,
         -1.1263e-03, -1.4343e-03],
        [-2.5520e-03, -3.5370e-02,  4.6158e-04,  ..., -3.8338e-03,
         -1.6012e-03, -2.4509e-03],
        [ 3.7842e-03,  2.2392e-03, -3.4424e-02,  ...,  1.1768e-03,
          5.4703e-03,  3.9520e-03],
        ...,
        [-5.9891e-03,  7.6294e-06, -2.9926e-03,  ..., -4.4647e-02,
          5.3368e-03, -9.5558e-04],
        [-6.5918e-03,  6.1493e-03, -2.2850e-03,  ...,  2.5368e-04,
         -3.9001e-02, -4.2572e-03],
        [-1.2886e-02,  9.9754e-04,  2.4853e-03,  ..., -7.7019e-03,
         -4.9973e-03, -3.8757e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0315, -0.0018,  0.0015,  ...,  0.0029, -0.0032, -0.0058],
        [-0.0021, -0.0356,  0.0073,  ...,  0.0042, -0.0010,  0.0073],
        [ 0.0029, -0.0027, -0.0288,  ...,  0.0035, -0.0048,  0.0021],
        ...,
        [-0.0030,  0.0026, -0.0015,  ..., -0.0246,  0.0043,  0.0033],
        [-0.0053, -0.0039,  0.0007,  ..., -0.0095, -0.0333, -0.0065],
        [-0.0083, -0.0059, -0.0037,  ..., -0.0039,  0.0051, -0.0334]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:01:58 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 10:01:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.9463, -0.4849, -0.5664,  ...,  0.3752, -0.3774,  0.7905],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0047,  0.7041,  0.5078,  ..., -1.7617, -0.6465,  0.0039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.8193, -0.7246, -0.2568,  ...,  0.8462,  0.5640,  0.1128],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2021,  0.6299,  0.4607,  ..., -1.1768, -0.0273,  0.4287],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:01:58 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:01:58 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 10:02:28 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 10:02:59 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 10:03:29 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1954e-03,  4.3106e-04,  1.7338e-03,  ..., -9.7847e-04,
          1.3332e-03, -3.7384e-04],
        [ 1.3840e-04, -3.0327e-03,  1.0929e-03,  ..., -1.3628e-03,
          7.8773e-04, -4.4012e-04],
        [-1.2612e-04, -3.2902e-05, -3.7632e-03,  ...,  8.9169e-04,
         -1.4889e-04, -5.3644e-04],
        ...,
        [-1.3113e-04, -1.3847e-03, -2.6822e-04,  ..., -3.5706e-03,
         -1.8597e-05,  3.7253e-05],
        [ 5.5611e-05, -5.2738e-04,  4.5800e-04,  ..., -2.7256e-03,
         -4.8027e-03, -8.8692e-04],
        [-4.8828e-04, -5.7793e-04,  4.3154e-04,  ..., -7.9918e-04,
         -9.3889e-04, -3.3569e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0490,  0.0025,  0.0063,  ...,  0.0065, -0.0008,  0.0013],
        [ 0.0012, -0.0433,  0.0003,  ...,  0.0015, -0.0027, -0.0047],
        [ 0.0023, -0.0096, -0.0478,  ..., -0.0027, -0.0032,  0.0035],
        ...,
        [ 0.0018,  0.0057, -0.0003,  ..., -0.0522,  0.0035,  0.0036],
        [-0.0013, -0.0015, -0.0099,  ..., -0.0002, -0.0407,  0.0044],
        [-0.0057, -0.0029,  0.0061,  ...,  0.0001,  0.0025, -0.0429]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0506, -0.0007,  0.0100,  ...,  0.0037, -0.0007,  0.0005],
        [ 0.0011, -0.0426, -0.0039,  ..., -0.0019,  0.0013,  0.0006],
        [-0.0079, -0.0074, -0.0452,  ...,  0.0042, -0.0088,  0.0035],
        ...,
        [-0.0009, -0.0024, -0.0004,  ..., -0.0461,  0.0042, -0.0126],
        [-0.0036, -0.0045, -0.0022,  ..., -0.0066, -0.0356, -0.0057],
        [ 0.0005,  0.0021,  0.0009,  ..., -0.0065, -0.0034, -0.0436]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:03:32 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 10:03:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.8535, -0.7656, -0.6099,  ...,  0.7241, -0.2430,  0.5059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2881,  0.4429,  0.4243,  ..., -0.8755, -0.6489,  0.3088],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.5918,  0.0654, -0.0922,  ...,  0.6011,  0.8369,  0.4827],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1643,  0.7915,  0.9600,  ..., -0.9326, -0.5127,  0.1833],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:03:32 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:03:32 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 10:04:05 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 10:04:39 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 10:05:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.1237e-03,  2.4338e-03, -2.9144e-03,  ...,  1.8346e-04,
         -1.2455e-03,  4.7684e-06],
        [-2.8801e-04, -7.5340e-04, -2.6970e-03,  ...,  4.3058e-04,
         -5.1928e-04, -7.7581e-04],
        [ 1.6146e-03,  1.2722e-03, -3.3989e-03,  ..., -1.5821e-03,
         -2.5368e-03, -2.7161e-03],
        ...,
        [-7.7343e-04,  4.7493e-04, -1.1263e-03,  ..., -6.1073e-03,
         -3.0804e-03,  8.5640e-04],
        [-9.6273e-04,  2.8205e-04,  1.5459e-03,  ...,  2.6588e-03,
          1.1244e-03, -5.8889e-04],
        [-5.3358e-04, -2.0523e-03, -4.9019e-04,  ..., -5.0545e-04,
         -2.2449e-03, -1.9989e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0826, -0.0039, -0.0031,  ...,  0.0038,  0.0034, -0.0013],
        [ 0.0053, -0.0742, -0.0009,  ...,  0.0110,  0.0087,  0.0067],
        [-0.0051,  0.0005, -0.0792,  ..., -0.0025,  0.0066, -0.0001],
        ...,
        [-0.0081, -0.0055, -0.0067,  ..., -0.0800, -0.0031,  0.0010],
        [-0.0011, -0.0104, -0.0035,  ...,  0.0004, -0.0800,  0.0023],
        [ 0.0030,  0.0075,  0.0037,  ..., -0.0012,  0.0039, -0.0924]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1001, -0.0093,  0.0022,  ..., -0.0020, -0.0031,  0.0025],
        [-0.0100, -0.0991,  0.0017,  ...,  0.0054, -0.0044,  0.0053],
        [-0.0021,  0.0023, -0.0925,  ..., -0.0013,  0.0149,  0.0107],
        ...,
        [-0.0076,  0.0017, -0.0093,  ..., -0.0820,  0.0047, -0.0011],
        [-0.0025, -0.0014,  0.0050,  ...,  0.0083, -0.0911,  0.0005],
        [-0.0061,  0.0073,  0.0098,  ..., -0.0020, -0.0048, -0.1018]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:05:14 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 10:05:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.8301, -0.7627, -0.2585,  ...,  0.8140,  0.5356,  0.0895],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2207,  0.6890,  0.4707,  ..., -1.2168, -0.0433,  0.4563],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.4238,  0.3494, -0.5283,  ...,  0.8721,  0.7832, -0.0237],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1283,  0.7612,  0.6631,  ..., -0.5967, -0.4326, -0.1450],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:05:14 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:05:14 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 10:05:50 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 10:06:25 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 10:07:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.9215e-03, -9.6226e-04,  3.0460e-03,  ...,  7.3671e-05,
         -1.0061e-04,  8.2970e-04],
        [ 6.2084e-04, -4.1122e-03,  1.6289e-03,  ..., -4.8280e-04,
          3.1986e-03, -1.1463e-03],
        [ 8.7082e-05,  2.2354e-03, -4.1656e-03,  ..., -8.8263e-04,
          7.2145e-04, -9.6512e-04],
        ...,
        [-5.6839e-04,  1.4029e-03, -5.9080e-04,  ..., -2.9831e-03,
         -1.4267e-03,  3.5973e-03],
        [ 9.4318e-04, -2.3422e-03,  1.8158e-03,  ..., -7.6580e-04,
         -6.5613e-04, -1.9894e-03],
        [ 1.6308e-03, -3.2687e-04,  1.2636e-03,  ...,  2.4867e-04,
         -3.8576e-04,  1.3828e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0852, -0.0106, -0.0071,  ...,  0.0063,  0.0104, -0.0091],
        [ 0.0008, -0.1010,  0.0016,  ...,  0.0005, -0.0040, -0.0010],
        [ 0.0040,  0.0135, -0.0931,  ..., -0.0078, -0.0057,  0.0031],
        ...,
        [ 0.0106, -0.0109, -0.0009,  ..., -0.1008, -0.0031, -0.0065],
        [-0.0068,  0.0056,  0.0072,  ..., -0.0023, -0.1042, -0.0122],
        [ 0.0004,  0.0026,  0.0020,  ..., -0.0150,  0.0056, -0.0849]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1082, -0.0027, -0.0031,  ...,  0.0026,  0.0023,  0.0018],
        [ 0.0028, -0.0916, -0.0065,  ...,  0.0036, -0.0084,  0.0012],
        [ 0.0021, -0.0007, -0.0927,  ...,  0.0033, -0.0013,  0.0016],
        ...,
        [ 0.0015,  0.0072,  0.0089,  ..., -0.1033, -0.0063, -0.0024],
        [-0.0008, -0.0012, -0.0066,  ..., -0.0030, -0.0954, -0.0116],
        [-0.0040, -0.0057, -0.0105,  ..., -0.0059, -0.0040, -0.1024]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:07:06 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 10:07:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-2.4551,  0.0712, -0.1032,  ...,  0.5029,  0.7705,  0.4277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1572,  0.7910,  0.8467,  ..., -0.8584, -0.4849,  0.1470],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.1992,  0.9668, -0.6992,  ...,  1.2021,  0.9033, -0.3132],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3760,  0.3657,  0.5034,  ..., -1.1084, -1.0469, -0.5674],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:07:06 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:07:06 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 10:07:46 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 10:08:28 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 10:09:09 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.9673e-03,  9.9182e-05,  9.4175e-05,  ...,  3.2272e-03,
         -4.2152e-03,  8.7452e-04],
        [-6.8092e-04, -4.7951e-03, -7.9346e-04,  ...,  5.6219e-04,
          1.7710e-03, -9.7609e-04],
        [ 1.1082e-03, -5.5599e-04, -4.4708e-03,  ..., -9.8801e-04,
          9.3365e-04, -8.8024e-04],
        ...,
        [-1.0748e-03,  1.2455e-03,  1.5163e-03,  ..., -4.2496e-03,
          1.9169e-04,  1.4200e-03],
        [-6.4039e-04,  3.5453e-04, -3.2024e-03,  ..., -7.8297e-04,
         -2.0390e-03,  4.3893e-04],
        [ 4.0984e-04, -1.5507e-03, -1.0242e-03,  ..., -1.7576e-03,
          9.6512e-04, -2.8133e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0803,  0.0100,  0.0111,  ..., -0.0075, -0.0005,  0.0011],
        [-0.0035, -0.0812, -0.0178,  ..., -0.0036, -0.0096,  0.0030],
        [ 0.0051, -0.0040, -0.0736,  ..., -0.0058, -0.0032,  0.0077],
        ...,
        [-0.0064, -0.0034,  0.0102,  ..., -0.0817,  0.0001, -0.0027],
        [ 0.0065, -0.0077, -0.0053,  ...,  0.0172, -0.0804,  0.0048],
        [-0.0004, -0.0053,  0.0136,  ...,  0.0004,  0.0040, -0.0879]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1076,  0.0022,  0.0098,  ..., -0.0091, -0.0021, -0.0083],
        [ 0.0038, -0.1052,  0.0007,  ...,  0.0054,  0.0148, -0.0040],
        [ 0.0021, -0.0019, -0.0977,  ..., -0.0043,  0.0056,  0.0158],
        ...,
        [-0.0041,  0.0013, -0.0052,  ..., -0.1042,  0.0122,  0.0024],
        [ 0.0054,  0.0049,  0.0044,  ...,  0.0139, -0.1000, -0.0058],
        [-0.0075, -0.0017,  0.0064,  ...,  0.0140,  0.0033, -0.1003]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:09:12 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 10:09:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-2.0977,  0.2983, -0.4456,  ...,  0.6919,  0.6445, -0.0455],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1178,  0.7485,  0.5947,  ..., -0.5327, -0.4080, -0.1610],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.8770,  0.9521, -0.5044,  ...,  1.0029,  1.0195, -0.1572],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4402,  0.2808,  0.5635,  ..., -1.6865, -1.5215,  0.4561],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:09:12 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:09:12 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 10:09:56 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 10:10:36 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 10:11:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0042, -0.0011, -0.0003,  ..., -0.0019,  0.0019, -0.0019],
        [ 0.0007, -0.0064,  0.0016,  ..., -0.0050,  0.0014, -0.0018],
        [ 0.0003,  0.0022, -0.0044,  ..., -0.0015,  0.0008, -0.0008],
        ...,
        [-0.0009, -0.0017, -0.0021,  ..., -0.0048, -0.0001,  0.0015],
        [ 0.0032,  0.0007, -0.0017,  ..., -0.0031, -0.0075, -0.0015],
        [ 0.0034,  0.0005, -0.0027,  ...,  0.0003, -0.0013, -0.0042]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0937,  0.0095, -0.0063,  ..., -0.0010,  0.0017,  0.0156],
        [ 0.0021, -0.1152,  0.0015,  ...,  0.0049,  0.0028,  0.0198],
        [-0.0010, -0.0026, -0.1071,  ...,  0.0046,  0.0015, -0.0064],
        ...,
        [ 0.0053,  0.0092,  0.0020,  ..., -0.1174,  0.0041, -0.0017],
        [ 0.0024, -0.0005,  0.0100,  ..., -0.0106, -0.1004,  0.0125],
        [ 0.0115,  0.0149, -0.0183,  ..., -0.0099,  0.0072, -0.1029]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0626e-01,  1.5533e-02, -3.6011e-03,  ..., -1.1391e-02,
          5.6648e-03,  4.8256e-03],
        [ 5.2872e-03, -1.1462e-01,  6.7673e-03,  ..., -2.4605e-04,
         -7.8125e-03,  1.6846e-02],
        [-2.4414e-03, -1.7834e-03, -1.0980e-01,  ..., -9.4681e-03,
         -5.0774e-03,  9.5215e-03],
        ...,
        [ 2.1286e-03,  2.1286e-03, -1.1177e-02,  ..., -1.1273e-01,
          1.8034e-03,  2.2411e-03],
        [-4.1275e-03, -8.5831e-05, -8.2550e-03,  ..., -2.9297e-03,
         -9.9487e-02,  1.0666e-02],
        [ 1.5297e-03, -4.1695e-03, -1.4221e-02,  ..., -3.6850e-03,
          8.8730e-03, -1.0486e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:11:13 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 10:11:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.6885,  0.7383, -0.5581,  ...,  0.8267,  0.6426, -0.2620],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3325,  0.3098,  0.3523,  ..., -0.8848, -0.8623, -0.4995],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.3750,  1.0742, -0.4497,  ...,  0.3247,  1.5537, -0.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0291,  0.4429,  0.7573,  ..., -1.6699, -1.5371,  0.0562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:11:13 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:11:14 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 10:12:03 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 10:12:52 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 10:13:43 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.5253e-03,  7.9334e-05,  1.8444e-03,  ..., -1.1978e-03,
          2.4815e-03, -8.7595e-04],
        [ 1.4648e-03, -1.9169e-03,  2.2650e-05,  ...,  3.3951e-03,
         -1.2321e-03,  2.9221e-03],
        [-1.5106e-03, -3.9101e-03,  2.0561e-03,  ..., -4.0007e-04,
          2.0599e-03,  5.9700e-04],
        ...,
        [ 1.1482e-03, -3.5915e-03, -3.6526e-04,  ...,  1.4706e-03,
          1.5192e-03, -6.5660e-04],
        [-4.8332e-03, -3.8910e-03,  2.1420e-03,  ...,  3.1166e-03,
         -7.3767e-04,  5.0735e-04],
        [ 9.6369e-04, -1.1463e-03, -5.0783e-04,  ...,  1.1597e-03,
         -3.4571e-04,  1.3351e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1169, -0.0004, -0.0078,  ..., -0.0082,  0.0048, -0.0008],
        [-0.0012, -0.1163, -0.0054,  ...,  0.0158,  0.0164, -0.0138],
        [-0.0112,  0.0091, -0.1094,  ..., -0.0042, -0.0159, -0.0048],
        ...,
        [-0.0016, -0.0083,  0.0040,  ..., -0.1171, -0.0008,  0.0055],
        [-0.0134,  0.0038,  0.0078,  ...,  0.0088, -0.1178,  0.0026],
        [-0.0071, -0.0020, -0.0112,  ...,  0.0058,  0.0024, -0.1076]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1611, -0.0098, -0.0123,  ...,  0.0015,  0.0135, -0.0062],
        [-0.0120, -0.1674, -0.0102,  ..., -0.0012, -0.0013, -0.0063],
        [-0.0052, -0.0077, -0.1547,  ...,  0.0074,  0.0079, -0.0191],
        ...,
        [-0.0087,  0.0091,  0.0138,  ..., -0.1588, -0.0129,  0.0006],
        [ 0.0043, -0.0003,  0.0145,  ..., -0.0093, -0.1566, -0.0101],
        [-0.0102,  0.0169, -0.0005,  ..., -0.0104, -0.0136, -0.1414]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:13:46 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 10:13:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.2871,  0.6382, -0.3694,  ...,  0.6558,  0.6636, -0.1550],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3303,  0.2003,  0.3726,  ..., -1.2002, -1.1445,  0.3115],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.8984,  1.2031, -0.6191,  ...,  0.5674,  2.1309, -0.4043],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.1422,  1.1377,  0.6260,  ..., -1.3291, -1.4092,  0.5020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:13:46 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:13:46 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 10:14:35 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 10:15:27 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 10:16:12 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0007,  0.0006, -0.0022,  ...,  0.0017,  0.0012,  0.0012],
        [-0.0019,  0.0027, -0.0018,  ...,  0.0008,  0.0011,  0.0022],
        [-0.0008, -0.0002, -0.0011,  ...,  0.0035, -0.0046, -0.0019],
        ...,
        [ 0.0011,  0.0018,  0.0026,  ..., -0.0012, -0.0020,  0.0009],
        [-0.0014,  0.0003,  0.0023,  ...,  0.0046, -0.0029,  0.0012],
        [-0.0006, -0.0031, -0.0024,  ...,  0.0016, -0.0022, -0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1259,  0.0159, -0.0177,  ..., -0.0019, -0.0096,  0.0082],
        [ 0.0149, -0.1244,  0.0061,  ...,  0.0067, -0.0100, -0.0056],
        [ 0.0079,  0.0105, -0.1140,  ...,  0.0025, -0.0021, -0.0059],
        ...,
        [ 0.0079, -0.0122, -0.0203,  ..., -0.1006,  0.0127, -0.0192],
        [ 0.0110, -0.0041, -0.0028,  ...,  0.0089, -0.1099,  0.0078],
        [ 0.0177,  0.0153, -0.0023,  ...,  0.0005,  0.0058, -0.1066]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1128,  0.0165,  0.0071,  ...,  0.0062, -0.0119,  0.0070],
        [ 0.0120, -0.0954,  0.0057,  ...,  0.0047, -0.0151, -0.0043],
        [-0.0077,  0.0030, -0.1024,  ..., -0.0021, -0.0011,  0.0103],
        ...,
        [ 0.0066, -0.0050, -0.0045,  ..., -0.1089,  0.0130, -0.0075],
        [-0.0018, -0.0064,  0.0038,  ...,  0.0075, -0.1197,  0.0018],
        [ 0.0031, -0.0041,  0.0082,  ...,  0.0010,  0.0014, -0.1082]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:16:15 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 10:16:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.5078,  0.6626, -0.3140,  ...,  0.1573,  0.9238, -0.2910],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0075,  0.2993,  0.4592,  ..., -1.1494, -1.0752,  0.0432],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-2.3887,  1.9854, -1.1660,  ...,  0.4556,  2.2266,  0.0952],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4395,  1.2275,  0.6445,  ..., -0.4136, -0.6943, -0.0508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:16:15 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:16:15 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 10:17:04 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 10:17:58 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 10:18:52 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 4.0221e-04,  1.1883e-03,  6.6102e-05,  ..., -2.7237e-03,
          1.1797e-03,  6.4373e-06],
        [ 2.5806e-03,  8.7357e-04, -6.2227e-04,  ..., -8.3065e-04,
          1.6270e-03,  3.0899e-03],
        [-1.7452e-03, -1.0672e-03,  1.1301e-03,  ..., -1.1806e-03,
          1.5688e-03, -7.3552e-05],
        ...,
        [ 1.7385e-03,  3.3264e-03,  5.1880e-03,  ...,  3.1509e-03,
         -5.0850e-03,  3.3302e-03],
        [-2.4681e-03, -1.1606e-03,  1.2426e-03,  ..., -1.6327e-03,
          2.5177e-03,  3.1147e-03],
        [-1.6146e-03,  2.3594e-03,  3.9816e-04,  ..., -1.0548e-03,
         -3.0327e-03, -1.6394e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.2130,  0.0089,  0.0059,  ..., -0.0112, -0.0021, -0.0168],
        [ 0.0011, -0.2118, -0.0103,  ..., -0.0038,  0.0089, -0.0019],
        [ 0.0152,  0.0039, -0.2083,  ..., -0.0186,  0.0086, -0.0105],
        ...,
        [ 0.0015, -0.0068,  0.0148,  ..., -0.2186,  0.0065,  0.0015],
        [-0.0032, -0.0009,  0.0027,  ...,  0.0203, -0.2030, -0.0024],
        [-0.0072,  0.0084, -0.0074,  ..., -0.0160,  0.0009, -0.2067]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.2998e-01,  9.9487e-03,  1.9577e-02,  ..., -2.0416e-02,
         -8.4877e-05, -9.0256e-03],
        [ 3.7670e-03, -2.3938e-01, -9.9640e-03,  ..., -1.3062e-02,
          4.9286e-03,  6.0806e-03],
        [ 1.4992e-02,  3.2558e-03, -2.1704e-01,  ...,  1.1147e-02,
          1.3199e-02, -2.0844e-02],
        ...,
        [-6.6490e-03,  5.4092e-03, -4.0703e-03,  ..., -2.5562e-01,
          1.6220e-02, -1.3313e-02],
        [-1.3741e-02, -3.5820e-03,  2.3842e-03,  ...,  2.2491e-02,
         -2.2888e-01, -1.8272e-03],
        [ 2.0008e-03,  3.4409e-03, -6.8665e-03,  ..., -1.3931e-02,
         -8.5220e-03, -2.2974e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:18:55 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 10:18:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.2822,  0.7749, -0.4375,  ...,  0.3567,  1.3691, -0.3293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1396,  0.8765,  0.4131,  ..., -1.0176, -1.0938,  0.3481],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.4717,  2.5117, -1.2061,  ..., -0.2173,  2.4336,  1.6543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.7949,  1.1777,  0.2847,  ..., -0.4495, -1.1562,  0.2339],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:18:55 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:18:55 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 10:19:52 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 10:20:48 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 10:21:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-7.2784e-03,  2.8152e-03, -8.5545e-04,  ..., -1.1206e-03,
          1.6413e-03, -4.7722e-03],
        [-1.2808e-03, -2.9602e-03,  1.8921e-03,  ..., -2.4867e-04,
         -1.3981e-03, -9.5367e-05],
        [ 2.5063e-03,  3.1357e-03, -6.5536e-03,  ..., -7.9632e-04,
         -1.5192e-03, -1.8759e-03],
        ...,
        [ 2.6970e-03, -1.7643e-03, -8.0681e-04,  ..., -6.1798e-03,
          2.6665e-03, -1.0967e-03],
        [-4.0665e-03,  2.8057e-03, -3.0975e-03,  ..., -3.1490e-03,
         -6.8283e-03, -3.6693e-04],
        [ 2.1858e-03, -2.6112e-03,  9.7036e-04,  ..., -3.2973e-04,
          1.5221e-03, -8.3160e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0938,  0.0030, -0.0098,  ...,  0.0163, -0.0077,  0.0018],
        [ 0.0175, -0.0943,  0.0167,  ..., -0.0007, -0.0097,  0.0102],
        [-0.0149, -0.0046, -0.0959,  ..., -0.0044, -0.0079,  0.0081],
        ...,
        [-0.0033,  0.0047,  0.0043,  ..., -0.0836,  0.0044, -0.0013],
        [-0.0024,  0.0048, -0.0125,  ..., -0.0129, -0.0988,  0.0066],
        [ 0.0018, -0.0038, -0.0182,  ...,  0.0013,  0.0037, -0.0934]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0825, -0.0037, -0.0122,  ...,  0.0106, -0.0017, -0.0004],
        [ 0.0070, -0.1068, -0.0079,  ...,  0.0064,  0.0021,  0.0202],
        [-0.0136, -0.0111, -0.1010,  ..., -0.0081, -0.0028,  0.0058],
        ...,
        [-0.0012, -0.0050,  0.0130,  ..., -0.0884,  0.0003,  0.0065],
        [-0.0050,  0.0062, -0.0154,  ...,  0.0132, -0.0946, -0.0056],
        [-0.0020,  0.0041, -0.0035,  ...,  0.0154,  0.0037, -0.0980]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:21:28 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 10:21:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-1.4814,  1.1660, -0.6812,  ...,  0.2413,  1.3311,  0.0327],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.3423,  0.8940,  0.4497,  ..., -0.3191, -0.5151, -0.0624],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.6416,  2.5957, -1.0791,  ..., -0.0508,  3.4082,  1.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.4619,  0.7256,  0.3113,  ..., -0.7173, -0.5767,  0.3574],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:21:28 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:21:28 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 10:22:24 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 10:23:23 lre.functional WARNING  [insert_o_j] layer transformer.h.14 does not match transformer.h.13.ln_1
2024-07-01 10:24:23 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0024,  0.0022,  0.0002,  ...,  0.0013,  0.0053, -0.0091],
        [-0.0042,  0.0042, -0.0056,  ..., -0.0026, -0.0038, -0.0006],
        [-0.0036,  0.0004,  0.0024,  ..., -0.0015, -0.0011, -0.0047],
        ...,
        [-0.0002,  0.0012,  0.0053,  ...,  0.0089, -0.0067,  0.0032],
        [ 0.0064, -0.0039,  0.0007,  ..., -0.0032, -0.0058,  0.0029],
        [-0.0026,  0.0129,  0.0071,  ..., -0.0049, -0.0070, -0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1658,  0.0050,  0.0055,  ..., -0.0237,  0.0095,  0.0105],
        [ 0.0015, -0.1411, -0.0033,  ...,  0.0058,  0.0134,  0.0025],
        [ 0.0086,  0.0133, -0.1342,  ..., -0.0108,  0.0069, -0.0139],
        ...,
        [-0.0087, -0.0039,  0.0050,  ..., -0.1582, -0.0055,  0.0060],
        [ 0.0061,  0.0027,  0.0010,  ..., -0.0052, -0.1527, -0.0106],
        [ 0.0056, -0.0079,  0.0029,  ..., -0.0151,  0.0023, -0.1349]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1482,  0.0024,  0.0009,  ..., -0.0100,  0.0088,  0.0151],
        [-0.0012, -0.1367,  0.0021,  ...,  0.0032,  0.0020,  0.0137],
        [ 0.0047,  0.0053, -0.1517,  ..., -0.0213,  0.0015, -0.0091],
        ...,
        [-0.0111, -0.0083, -0.0173,  ..., -0.1351,  0.0022, -0.0095],
        [-0.0022,  0.0063, -0.0079,  ..., -0.0015, -0.1693,  0.0023],
        [-0.0025,  0.0086, -0.0005,  ..., -0.0169,  0.0100, -0.1486]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:24:25 root INFO     h_layer_name='transformer.h.14.ln_1' z_layer_name='transformer.h.15'
2024-07-01 10:24:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8438,  1.3477, -0.6504,  ..., -0.1353,  1.3633,  0.8623],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.5298,  0.7158,  0.1421,  ..., -0.2910, -0.6978,  0.0925],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1104,  3.0547, -0.7051,  ..., -0.4622,  3.9902,  0.9829],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3931,  0.9766,  0.3484,  ..., -0.4509, -0.7197,  0.4089],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:24:25 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:24:25 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 10:25:24 lre.functional WARNING  [insert_s_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 10:26:26 lre.functional WARNING  [insert_o_j] layer transformer.h.15 does not match transformer.h.14.ln_1
2024-07-01 10:27:26 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0009, -0.0042, -0.0003,  ..., -0.0013, -0.0083, -0.0011],
        [ 0.0004, -0.0007, -0.0034,  ..., -0.0014,  0.0043, -0.0019],
        [-0.0008, -0.0034, -0.0021,  ...,  0.0014, -0.0021,  0.0049],
        ...,
        [ 0.0050,  0.0009, -0.0077,  ...,  0.0029,  0.0005, -0.0044],
        [-0.0002, -0.0062, -0.0007,  ...,  0.0011,  0.0044,  0.0032],
        [ 0.0023,  0.0008, -0.0043,  ...,  0.0015, -0.0025, -0.0077]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1115,  0.0106, -0.0022,  ..., -0.0137,  0.0017,  0.0010],
        [ 0.0100, -0.1276,  0.0011,  ...,  0.0024,  0.0007, -0.0001],
        [ 0.0084, -0.0120, -0.1117,  ..., -0.0039,  0.0054, -0.0042],
        ...,
        [ 0.0090, -0.0136, -0.0081,  ..., -0.1110,  0.0113,  0.0078],
        [-0.0097, -0.0033,  0.0123,  ..., -0.0044, -0.1057,  0.0055],
        [ 0.0072,  0.0083, -0.0193,  ..., -0.0091,  0.0110, -0.1132]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1246,  0.0039, -0.0055,  ..., -0.0253, -0.0017, -0.0036],
        [ 0.0086, -0.1285,  0.0006,  ...,  0.0127,  0.0006,  0.0037],
        [-0.0066, -0.0126, -0.1091,  ..., -0.0027,  0.0018, -0.0100],
        ...,
        [ 0.0005,  0.0032,  0.0064,  ..., -0.1290,  0.0139, -0.0043],
        [-0.0087, -0.0030, -0.0115,  ...,  0.0166, -0.1035, -0.0032],
        [-0.0096,  0.0014, -0.0060,  ..., -0.0048,  0.0017, -0.1246]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:27:29 root INFO     h_layer_name='transformer.h.15.ln_1' z_layer_name='transformer.h.16'
2024-07-01 10:27:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.8652,  1.2949, -0.5229,  ..., -0.0393,  1.7188,  0.5225],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2944,  0.4106,  0.1805,  ..., -0.4380, -0.3411,  0.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8735,  3.1406, -0.2139,  ..., -0.1799,  4.3555,  1.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3071,  1.1406,  0.3274,  ...,  0.4944, -0.9839,  0.8555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:27:29 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:27:29 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 10:28:32 lre.functional WARNING  [insert_s_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 10:29:32 lre.functional WARNING  [insert_o_j] layer transformer.h.16 does not match transformer.h.15.ln_1
2024-07-01 10:30:34 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0384e-02,  2.3518e-03, -7.7486e-04,  ...,  1.0548e-03,
         -3.4580e-03, -9.5940e-04],
        [ 7.3700e-03,  9.8648e-03,  6.1417e-04,  ...,  8.9312e-04,
          3.0212e-03, -1.7786e-03],
        [ 1.2331e-03, -2.8400e-03,  7.4615e-03,  ...,  1.0681e-03,
         -9.3651e-04,  3.0804e-04],
        ...,
        [-6.4278e-03, -3.2520e-03, -2.0671e-04,  ...,  7.3776e-03,
         -3.8586e-03,  3.2043e-03],
        [ 6.2904e-03,  3.8109e-03,  3.7041e-03,  ...,  6.9189e-04,
          4.6234e-03, -3.4199e-03],
        [-8.4043e-05,  5.6953e-03,  2.0218e-03,  ...,  1.2245e-03,
         -3.9673e-03,  9.3765e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.0950e-01, -7.4196e-04,  4.1275e-03,  ..., -3.1071e-03,
         -6.9427e-03,  3.8605e-03],
        [-3.4313e-03, -1.1523e-01, -4.8447e-03,  ...,  5.7945e-03,
          1.1108e-02,  2.3918e-03],
        [ 2.4796e-03,  1.3474e-02, -1.1346e-01,  ...,  4.5357e-03,
         -1.0605e-03, -1.9073e-03],
        ...,
        [-5.0068e-06,  3.1815e-03, -8.3008e-03,  ..., -1.0291e-01,
         -1.8051e-02,  7.2632e-03],
        [ 1.7548e-04, -9.1553e-05, -1.5976e-02,  ..., -3.8071e-03,
         -1.1182e-01,  5.5275e-03],
        [ 4.6844e-03,  1.4206e-02, -1.6842e-03,  ..., -4.8676e-03,
         -2.8915e-03, -1.0669e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1334,  0.0039, -0.0148,  ...,  0.0037, -0.0050,  0.0033],
        [ 0.0074, -0.1449, -0.0067,  ..., -0.0023, -0.0211, -0.0142],
        [-0.0074,  0.0046, -0.1379,  ...,  0.0019,  0.0077,  0.0072],
        ...,
        [ 0.0009, -0.0019, -0.0134,  ..., -0.1376,  0.0025, -0.0021],
        [-0.0010, -0.0078,  0.0016,  ...,  0.0216, -0.1498,  0.0164],
        [-0.0019, -0.0034,  0.0095,  ..., -0.0037,  0.0098, -0.1359]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:30:37 root INFO     h_layer_name='transformer.h.16.ln_1' z_layer_name='transformer.h.17'
2024-07-01 10:30:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.6260,  1.5947, -0.3638,  ..., -0.2383,  2.0371,  0.4805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2610,  0.5479,  0.1636,  ..., -0.2448, -0.3870,  0.2002],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8887,  2.5742, -0.0400,  ...,  0.0940,  4.3008,  2.0000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2551,  0.7544, -0.2292,  ...,  0.2549, -0.8330,  0.9976],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:30:37 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:30:37 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 10:31:41 lre.functional WARNING  [insert_s_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 10:32:44 lre.functional WARNING  [insert_o_j] layer transformer.h.17 does not match transformer.h.16.ln_1
2024-07-01 10:33:46 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.9825e-03, -3.9864e-03,  1.8902e-03,  ..., -4.8981e-03,
         -3.2997e-03, -1.2445e-04],
        [-3.3021e-04,  3.0160e-04,  4.2915e-03,  ...,  2.6054e-03,
         -2.5940e-03,  7.0763e-04],
        [-1.8978e-03,  1.9388e-03, -1.8263e-03,  ..., -3.1891e-03,
         -3.1109e-03, -1.9970e-03],
        ...,
        [ 3.9864e-03, -1.4629e-03, -3.1719e-03,  ..., -2.4033e-03,
          5.1856e-06, -3.1815e-03],
        [ 1.1911e-03, -3.5419e-03, -3.7003e-03,  ..., -4.1733e-03,
         -4.8828e-03,  2.7046e-03],
        [ 1.8082e-03,  4.4632e-04, -5.1498e-03,  ..., -1.4200e-03,
          4.3488e-04, -1.0086e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.3059e-02,  1.1139e-02, -9.4414e-05,  ..., -1.1818e-02,
          6.3019e-03, -2.0264e-02],
        [-2.0580e-03, -6.6650e-02, -1.3062e-02,  ...,  2.1076e-03,
          7.5684e-03, -8.9188e-03],
        [-6.9618e-03,  2.2926e-03, -6.3354e-02,  ..., -3.5343e-03,
          1.9363e-02,  7.6523e-03],
        ...,
        [-2.2217e-02,  1.9093e-03, -3.2806e-03,  ..., -7.1777e-02,
         -9.4528e-03,  4.8327e-04],
        [ 1.0192e-05,  1.4977e-02,  8.5449e-03,  ...,  2.0844e-02,
         -7.1899e-02,  7.6790e-03],
        [-1.2741e-02, -8.9874e-03,  1.3046e-02,  ..., -4.2191e-03,
          3.2539e-03, -7.4524e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0969,  0.0072, -0.0016,  ..., -0.0078,  0.0027, -0.0027],
        [ 0.0020, -0.0872, -0.0150,  ...,  0.0159, -0.0030,  0.0121],
        [ 0.0073,  0.0199, -0.0909,  ..., -0.0058, -0.0101, -0.0116],
        ...,
        [-0.0167,  0.0074, -0.0036,  ..., -0.0826,  0.0056,  0.0128],
        [ 0.0119,  0.0041, -0.0092,  ..., -0.0036, -0.0900, -0.0028],
        [-0.0032,  0.0019,  0.0123,  ..., -0.0112, -0.0016, -0.0914]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:33:49 root INFO     h_layer_name='transformer.h.17.ln_1' z_layer_name='transformer.h.18'
2024-07-01 10:33:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4482,  1.5361, -0.1011,  ..., -0.0924,  2.1211,  0.6768],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1691,  0.5742,  0.1594,  ...,  0.2355, -0.4783,  0.3914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.8965,  2.1445,  0.2639,  ..., -0.6270,  4.5547,  2.5312],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1338,  0.7197, -0.6548,  ...,  0.4617, -0.3652,  2.1914],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:33:49 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:33:49 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 10:34:52 lre.functional WARNING  [insert_s_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 10:35:51 lre.functional WARNING  [insert_o_j] layer transformer.h.18 does not match transformer.h.17.ln_1
2024-07-01 10:36:57 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0022, -0.0013,  0.0030,  ...,  0.0031,  0.0018,  0.0010],
        [ 0.0007, -0.0046, -0.0003,  ...,  0.0024, -0.0010,  0.0004],
        [ 0.0037,  0.0019, -0.0042,  ...,  0.0013, -0.0014,  0.0014],
        ...,
        [-0.0019,  0.0013, -0.0003,  ..., -0.0052,  0.0020,  0.0037],
        [ 0.0037,  0.0020, -0.0026,  ...,  0.0007, -0.0043,  0.0022],
        [ 0.0037, -0.0015, -0.0010,  ...,  0.0005,  0.0020, -0.0064]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0765,  0.0099,  0.0025,  ..., -0.0065,  0.0087,  0.0002],
        [-0.0039, -0.0822,  0.0182,  ..., -0.0166,  0.0061, -0.0198],
        [-0.0034,  0.0011, -0.0857,  ..., -0.0224,  0.0020,  0.0004],
        ...,
        [-0.0026, -0.0114,  0.0141,  ..., -0.0818,  0.0111,  0.0042],
        [ 0.0105,  0.0125,  0.0148,  ..., -0.0015, -0.0946,  0.0190],
        [-0.0012,  0.0120,  0.0075,  ..., -0.0048,  0.0108, -0.0659]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0813, -0.0103, -0.0030,  ..., -0.0019,  0.0022,  0.0051],
        [-0.0025, -0.1094, -0.0044,  ..., -0.0133, -0.0044, -0.0189],
        [ 0.0063, -0.0136, -0.1001,  ..., -0.0109, -0.0003, -0.0083],
        ...,
        [-0.0030, -0.0066,  0.0114,  ..., -0.0872,  0.0007,  0.0066],
        [ 0.0067, -0.0024,  0.0088,  ...,  0.0143, -0.1034, -0.0052],
        [ 0.0044, -0.0030, -0.0024,  ..., -0.0106,  0.0046, -0.0889]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:37:00 root INFO     h_layer_name='transformer.h.18.ln_1' z_layer_name='transformer.h.19'
2024-07-01 10:37:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4421,  1.2031, -0.0330,  ...,  0.0386,  2.0449,  0.9092],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1373,  0.3567, -0.1151,  ...,  0.1164, -0.3877,  0.4314],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7441,  2.2754,  0.1794,  ..., -0.1599,  5.4727,  2.7988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.6753,  1.6016, -2.0801,  ..., -0.6387, -0.9878,  2.2754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:37:00 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:37:00 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 10:38:10 lre.functional WARNING  [insert_s_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 10:39:20 lre.functional WARNING  [insert_o_j] layer transformer.h.19 does not match transformer.h.18.ln_1
2024-07-01 10:40:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.6251e-02,  2.3842e-03, -4.7278e-04,  ...,  4.8828e-04,
         -6.2332e-03, -2.1820e-03],
        [-7.9203e-04,  3.3989e-03, -3.8910e-03,  ..., -9.7370e-04,
          6.8092e-03,  5.8174e-04],
        [ 2.5406e-03, -9.8572e-03,  1.4412e-02,  ...,  1.6928e-05,
          1.0633e-03, -3.4542e-03],
        ...,
        [-4.4441e-03,  8.2245e-03,  4.2868e-04,  ...,  9.7275e-03,
         -5.3062e-03, -8.3694e-03],
        [ 3.3836e-03,  5.4321e-03,  9.7122e-03,  ..., -8.3694e-03,
          3.5210e-03, -2.0523e-03],
        [-3.8662e-03,  2.2411e-04, -8.5373e-03,  ...,  7.6523e-03,
          4.0741e-03,  7.1754e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0634,  0.0064,  0.0148,  ...,  0.0033, -0.0061, -0.0044],
        [ 0.0114, -0.0779,  0.0090,  ..., -0.0016,  0.0177,  0.0108],
        [ 0.0255,  0.0039, -0.0630,  ..., -0.0121,  0.0051, -0.0175],
        ...,
        [ 0.0012,  0.0119, -0.0076,  ..., -0.0613,  0.0033,  0.0008],
        [-0.0011, -0.0080,  0.0017,  ...,  0.0082, -0.0692, -0.0004],
        [ 0.0096, -0.0057, -0.0086,  ...,  0.0004, -0.0037, -0.0772]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0205e-01,  2.5452e-02, -3.6087e-03,  ..., -5.1155e-03,
          7.5579e-04, -9.0561e-03],
        [ 2.9564e-03, -1.2671e-01, -6.0005e-03,  ...,  5.2795e-03,
         -5.8060e-03,  3.0426e-02],
        [-9.3155e-03, -2.1683e-02, -1.1609e-01,  ..., -2.3941e-02,
         -4.1237e-03, -1.2077e-02],
        ...,
        [ 2.3499e-03, -2.7275e-03, -1.3687e-02,  ..., -1.0339e-01,
          1.9791e-02,  1.5015e-02],
        [-9.7351e-03, -1.2939e-02, -8.9188e-03,  ..., -2.3071e-02,
         -1.0791e-01, -2.2173e-05],
        [-4.7607e-03,  1.2054e-03, -2.3544e-02,  ...,  7.9880e-03,
         -5.6038e-03, -1.3306e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:40:33 root INFO     h_layer_name='transformer.h.19.ln_1' z_layer_name='transformer.h.20'
2024-07-01 10:40:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4194,  0.9565,  0.0919,  ..., -0.2839,  2.0703,  1.1133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.5073,  0.3118, -0.2986,  ...,  0.1978, -0.1370,  0.9390],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.5967,  1.2998, -0.2468,  ...,  0.4182,  5.0586,  2.4570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.3184,  2.4258, -3.1797,  ..., -1.2490, -2.1543,  2.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:40:33 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:40:33 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 10:41:42 lre.functional WARNING  [insert_s_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 10:42:50 lre.functional WARNING  [insert_o_j] layer transformer.h.20 does not match transformer.h.19.ln_1
2024-07-01 10:43:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0025,  0.0010, -0.0032,  ..., -0.0026, -0.0059, -0.0083],
        [ 0.0038,  0.0115, -0.0062,  ..., -0.0004,  0.0079, -0.0044],
        [-0.0004, -0.0083, -0.0007,  ...,  0.0072, -0.0078,  0.0026],
        ...,
        [-0.0020, -0.0110, -0.0053,  ..., -0.0070,  0.0025,  0.0065],
        [ 0.0064, -0.0070,  0.0017,  ...,  0.0100,  0.0026, -0.0009],
        [-0.0026,  0.0042,  0.0027,  ..., -0.0019, -0.0052,  0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.5940e-02, -2.9316e-03, -1.9836e-03,  ..., -8.8272e-03,
          5.5885e-03, -6.5918e-03],
        [ 9.6588e-03, -2.1011e-02, -2.8992e-04,  ..., -2.7332e-03,
          6.4697e-03,  7.5378e-03],
        [-6.4163e-03,  1.3771e-03, -4.0466e-02,  ...,  4.6730e-03,
         -1.0773e-02,  7.9956e-03],
        ...,
        [-7.5798e-03,  5.4665e-03, -4.8065e-03,  ..., -3.6926e-02,
          3.8300e-03,  5.3139e-03],
        [-5.6915e-03,  3.6850e-03, -5.2376e-03,  ..., -4.1542e-03,
         -2.0416e-02, -1.4877e-04],
        [-3.7670e-05,  3.7689e-03,  1.4732e-02,  ..., -3.2272e-03,
          1.7776e-03, -4.8859e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0458, -0.0143,  0.0192,  ..., -0.0064, -0.0071,  0.0148],
        [-0.0039, -0.0501,  0.0121,  ..., -0.0109,  0.0124, -0.0047],
        [ 0.0113, -0.0037, -0.0724,  ..., -0.0070,  0.0069,  0.0191],
        ...,
        [ 0.0024,  0.0153,  0.0018,  ..., -0.0656,  0.0090, -0.0099],
        [ 0.0032,  0.0122, -0.0204,  ..., -0.0185, -0.0768,  0.0130],
        [ 0.0042,  0.0110, -0.0077,  ..., -0.0102,  0.0037, -0.0881]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:43:56 root INFO     h_layer_name='transformer.h.20.ln_1' z_layer_name='transformer.h.21'
2024-07-01 10:43:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3164,  0.9370,  0.0513,  ..., -0.0645,  2.2285,  1.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.2639,  0.6045, -0.7764,  ..., -0.2363, -0.3735,  0.8481],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.7686,  0.4365,  0.7920,  ...,  0.4595,  4.6328,  1.5479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.1250,  2.3047, -2.9727,  ..., -1.2568, -1.5273,  2.1855],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:43:56 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:43:56 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 10:45:08 lre.functional WARNING  [insert_s_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 10:46:22 lre.functional WARNING  [insert_o_j] layer transformer.h.21 does not match transformer.h.20.ln_1
2024-07-01 10:47:36 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 0.0041,  0.0032, -0.0006,  ...,  0.0036, -0.0046,  0.0044],
        [-0.0053,  0.0040,  0.0025,  ...,  0.0053, -0.0043, -0.0020],
        [ 0.0002,  0.0037,  0.0093,  ..., -0.0013,  0.0043,  0.0039],
        ...,
        [ 0.0029, -0.0005, -0.0023,  ...,  0.0037, -0.0062,  0.0024],
        [-0.0034,  0.0029,  0.0040,  ..., -0.0035,  0.0089, -0.0002],
        [-0.0022, -0.0041,  0.0030,  ...,  0.0004,  0.0075,  0.0128]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0252,  0.0008,  0.0157,  ...,  0.0165, -0.0100,  0.0064],
        [ 0.0060, -0.0406, -0.0065,  ..., -0.0026, -0.0147,  0.0036],
        [ 0.0199,  0.0079, -0.0266,  ...,  0.0024,  0.0086, -0.0072],
        ...,
        [ 0.0115,  0.0085, -0.0081,  ..., -0.0190,  0.0031, -0.0095],
        [-0.0060, -0.0029,  0.0002,  ...,  0.0009, -0.0269,  0.0118],
        [ 0.0074, -0.0074, -0.0127,  ...,  0.0092, -0.0062, -0.0424]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0556,  0.0019,  0.0173,  ...,  0.0127,  0.0047,  0.0091],
        [-0.0019, -0.0583, -0.0159,  ...,  0.0103,  0.0028,  0.0146],
        [-0.0056,  0.0031, -0.0463,  ..., -0.0117,  0.0058, -0.0029],
        ...,
        [-0.0015, -0.0074, -0.0245,  ..., -0.0835,  0.0011,  0.0043],
        [-0.0002, -0.0076, -0.0081,  ..., -0.0140, -0.0770,  0.0141],
        [ 0.0049, -0.0128,  0.0066,  ..., -0.0149, -0.0072, -0.0844]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:47:40 root INFO     h_layer_name='transformer.h.21.ln_1' z_layer_name='transformer.h.22'
2024-07-01 10:47:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.2349,  0.4939, -0.1055,  ...,  0.1476,  1.9551,  0.9307],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.8604,  0.8887, -1.1680,  ..., -0.4690, -0.7803,  0.7241],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.1348,  0.1538,  1.2188,  ...,  0.5981,  4.7773,  1.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 3.4141,  3.1074, -3.4375,  ..., -2.7188, -1.5850,  1.3672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:47:40 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:47:40 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 10:49:01 lre.functional WARNING  [insert_s_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 10:50:22 lre.functional WARNING  [insert_o_j] layer transformer.h.22 does not match transformer.h.21.ln_1
2024-07-01 10:51:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 8.8263e-04, -2.8348e-04,  1.3962e-03,  ...,  2.4128e-03,
         -3.3760e-03, -4.2496e-03],
        [-1.3275e-03, -4.1771e-03,  7.1383e-04,  ..., -2.4185e-03,
          1.3800e-03,  1.1168e-03],
        [ 3.6011e-03, -2.9449e-03,  8.0156e-04,  ..., -4.1733e-03,
          1.2388e-03, -6.3477e-03],
        ...,
        [ 1.7710e-03,  1.6346e-03,  5.4455e-04,  ...,  1.6003e-03,
          2.9159e-04,  4.6234e-03],
        [ 4.5624e-03,  3.8338e-03,  2.9993e-04,  ...,  2.3723e-04,
         -3.8548e-03, -4.3640e-03],
        [-8.7585e-03,  1.8370e-04, -1.2980e-03,  ..., -3.7060e-03,
          4.9553e-03, -5.6148e-05]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0139, -0.0006, -0.0044,  ..., -0.0234,  0.0052,  0.0227],
        [-0.0070, -0.0444, -0.0118,  ...,  0.0119,  0.0010, -0.0013],
        [ 0.0037, -0.0082, -0.0367,  ..., -0.0171,  0.0237,  0.0035],
        ...,
        [ 0.0090,  0.0035,  0.0025,  ..., -0.0380, -0.0036, -0.0002],
        [ 0.0090,  0.0110, -0.0149,  ...,  0.0009, -0.0330, -0.0127],
        [-0.0047,  0.0046, -0.0028,  ...,  0.0007, -0.0064, -0.0275]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0851,  0.0101, -0.0140,  ...,  0.0043, -0.0276,  0.0029],
        [ 0.0007, -0.1365, -0.0012,  ..., -0.0088,  0.0189,  0.0091],
        [-0.0116,  0.0069, -0.1031,  ..., -0.0009,  0.0226, -0.0159],
        ...,
        [ 0.0258,  0.0033,  0.0056,  ..., -0.0720, -0.0035,  0.0067],
        [ 0.0035, -0.0078,  0.0049,  ..., -0.0287, -0.0764, -0.0229],
        [-0.0102, -0.0027, -0.0119,  ...,  0.0020,  0.0056, -0.0867]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:51:42 root INFO     h_layer_name='transformer.h.22.ln_1' z_layer_name='transformer.h.23'
2024-07-01 10:51:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3022,  0.1600,  0.2839,  ...,  0.1770,  1.7969,  0.5767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7910,  0.8198, -1.0713,  ..., -0.4424, -0.5483,  0.7876],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-1.0771,  0.0562,  2.2188,  ...,  0.4216,  4.8984,  1.4658],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.7090,  3.7715, -2.9141,  ..., -3.4297, -0.5166,  1.2188],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:51:42 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:51:42 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 10:53:03 lre.functional WARNING  [insert_s_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 10:54:24 lre.functional WARNING  [insert_o_j] layer transformer.h.23 does not match transformer.h.22.ln_1
2024-07-01 10:55:47 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.9684e-03,  4.1199e-04, -1.9598e-04,  ...,  1.3313e-03,
          6.0892e-04,  3.2127e-05],
        [-1.4913e-04, -1.8797e-03, -1.6248e-04,  ...,  3.8099e-04,
         -6.8474e-04, -9.4366e-04],
        [ 4.4680e-04, -1.9777e-04, -2.0580e-03,  ..., -1.2589e-03,
         -1.0502e-04, -9.1648e-04],
        ...,
        [ 4.1914e-04, -1.0481e-03, -7.2813e-04,  ..., -2.8076e-03,
          1.8191e-04,  1.4973e-04],
        [ 2.4188e-04,  9.1124e-04,  1.7519e-03,  ..., -8.3542e-04,
         -1.1406e-03,  7.6771e-04],
        [ 2.2042e-04, -2.3794e-04,  9.4414e-05,  ..., -2.4080e-05,
          4.1342e-04, -2.3479e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0335, -0.0021, -0.0021,  ...,  0.0202, -0.0041,  0.0126],
        [-0.0072, -0.0169, -0.0039,  ...,  0.0085, -0.0114,  0.0038],
        [-0.0067, -0.0003, -0.0196,  ...,  0.0061, -0.0044,  0.0084],
        ...,
        [-0.0106,  0.0114, -0.0170,  ..., -0.0231,  0.0092,  0.0139],
        [ 0.0083,  0.0195, -0.0155,  ...,  0.0084, -0.0167,  0.0039],
        [ 0.0011, -0.0109,  0.0021,  ...,  0.0217,  0.0014, -0.0260]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.9397e-02,  2.0325e-02,  4.0894e-03,  ...,  1.3321e-02,
          6.1378e-03,  6.7215e-03],
        [ 1.0361e-02, -5.8136e-02,  9.7122e-03,  ...,  3.0670e-03,
         -1.5068e-04,  2.7409e-03],
        [-2.6379e-03,  3.6526e-03, -6.7688e-02,  ...,  5.4359e-05,
         -1.9989e-02,  2.1973e-02],
        ...,
        [-2.3453e-02, -4.3640e-03, -8.3466e-03,  ..., -7.8491e-02,
          2.5253e-02,  2.4551e-02],
        [ 1.1757e-02,  1.4915e-02, -1.3748e-02,  ..., -6.3515e-03,
         -5.8624e-02, -1.6907e-02],
        [ 2.0660e-02, -2.0370e-02, -2.0332e-03,  ...,  4.7455e-03,
         -2.1011e-02, -8.1848e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 10:55:49 root INFO     h_layer_name='transformer.h.23.ln_1' z_layer_name='transformer.h.24'
2024-07-01 10:55:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.4146,  0.0545,  0.4097,  ...,  0.2189,  1.7715,  0.3689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 1.2236,  1.0596, -1.1904,  ..., -0.9219, -0.5327,  0.4534],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2080,  0.4746,  2.5801,  ...,  0.7432,  5.3477,  1.9707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 2.2168,  3.9141, -3.0625,  ..., -3.9473, -0.1497,  2.0000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 10:55:49 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 10:55:49 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 10:57:15 lre.functional WARNING  [insert_s_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 10:58:39 lre.functional WARNING  [insert_o_j] layer transformer.h.24 does not match transformer.h.23.ln_1
2024-07-01 11:00:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0068,  0.0008, -0.0024,  ...,  0.0022, -0.0008, -0.0022],
        [-0.0025, -0.0045,  0.0009,  ...,  0.0033, -0.0007, -0.0002],
        [-0.0010,  0.0026, -0.0058,  ...,  0.0024,  0.0003,  0.0008],
        ...,
        [-0.0033, -0.0018,  0.0005,  ..., -0.0086, -0.0024, -0.0027],
        [-0.0025, -0.0028, -0.0025,  ..., -0.0013, -0.0042,  0.0034],
        [-0.0024, -0.0010,  0.0045,  ..., -0.0020,  0.0048, -0.0100]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.7896e-03, -3.0403e-03,  3.1872e-03,  ..., -2.1057e-03,
          2.1210e-03, -6.9695e-03],
        [ 2.1805e-02, -7.2289e-03,  1.4816e-02,  ...,  1.4549e-02,
          5.9814e-03,  2.6245e-03],
        [-3.9406e-03, -1.6037e-02, -1.8967e-02,  ..., -1.3924e-02,
          7.1564e-03, -8.6365e-03],
        ...,
        [ 4.3907e-03, -7.6294e-03, -1.9791e-02,  ..., -2.8343e-03,
         -4.3259e-03, -1.9928e-02],
        [-1.0933e-02, -1.5450e-02,  6.2943e-05,  ...,  2.4979e-02,
         -1.0864e-02, -2.3251e-03],
        [-1.0612e-02,  4.3526e-03,  2.1667e-02,  ..., -5.6305e-03,
          1.2497e-02, -2.4460e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0718,  0.0124, -0.0150,  ..., -0.0263, -0.0108,  0.0195],
        [ 0.0013, -0.0398, -0.0086,  ...,  0.0144, -0.0080,  0.0063],
        [-0.0166, -0.0030, -0.0742,  ..., -0.0127, -0.0057,  0.0051],
        ...,
        [ 0.0235,  0.0064, -0.0011,  ..., -0.0491, -0.0202, -0.0184],
        [ 0.0015,  0.0027, -0.0041,  ...,  0.0160, -0.0515, -0.0099],
        [ 0.0010, -0.0030,  0.0140,  ...,  0.0142, -0.0030, -0.0790]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:00:05 root INFO     h_layer_name='transformer.h.24.ln_1' z_layer_name='transformer.h.25'
2024-07-01 11:00:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.3750,  0.0437,  0.7148,  ...,  0.1338,  1.7236,  0.4880],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.9229,  1.2402, -1.0117,  ..., -1.1299, -0.1624,  0.3862],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.2664,  0.6816,  2.5410,  ...,  0.4849,  5.2812,  2.1387],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.7822,  4.3594, -2.4590,  ..., -2.8125,  0.7725,  2.0879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:00:05 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 11:00:05 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 11:01:30 lre.functional WARNING  [insert_s_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 11:02:56 lre.functional WARNING  [insert_o_j] layer transformer.h.25 does not match transformer.h.24.ln_1
2024-07-01 11:04:16 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 2.8114e-03, -1.1234e-03, -6.3658e-04,  ...,  2.5463e-03,
         -1.6098e-03,  6.1417e-04],
        [ 1.0538e-03,  1.5068e-04,  1.7290e-03,  ..., -1.0605e-03,
         -4.5872e-04, -3.6526e-04],
        [ 8.6880e-04,  4.3344e-04,  1.3466e-03,  ...,  8.5831e-06,
         -8.6451e-04, -6.3324e-04],
        ...,
        [ 2.2244e-04,  1.4448e-04, -1.8859e-04,  ...,  3.7918e-03,
         -1.9445e-03,  1.5223e-04],
        [ 3.4571e-06,  1.0910e-03, -3.7360e-04,  ...,  6.4993e-04,
          3.6907e-03, -9.2363e-04],
        [-2.9206e-04, -1.1778e-03,  5.4455e-04,  ...,  4.3869e-04,
          1.4019e-03,  4.5509e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0130, -0.0006,  0.0145,  ..., -0.0034,  0.0076,  0.0037],
        [ 0.0016, -0.0123, -0.0057,  ..., -0.0009, -0.0042,  0.0108],
        [-0.0001,  0.0003,  0.0165,  ...,  0.0111, -0.0166,  0.0122],
        ...,
        [-0.0068, -0.0011, -0.0179,  ...,  0.0369,  0.0078,  0.0079],
        [ 0.0088, -0.0025,  0.0121,  ..., -0.0073,  0.0078, -0.0006],
        [-0.0061,  0.0195,  0.0049,  ..., -0.0041,  0.0082,  0.0137]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[ 1.0895e-02, -1.3214e-02,  5.3167e-05,  ...,  1.4854e-02,
         -9.3994e-03,  3.3054e-03],
        [-1.4969e-02, -3.4912e-02, -4.6997e-03,  ...,  2.2087e-03,
         -3.7804e-03,  1.0729e-03],
        [-2.7069e-02,  2.2919e-02,  1.4008e-02,  ..., -7.2289e-03,
          1.6785e-02,  1.9547e-02],
        ...,
        [-2.6535e-02, -1.7557e-03, -2.6291e-02,  ...,  3.4607e-02,
          3.3855e-04,  1.5839e-02],
        [-1.5440e-03, -1.3412e-02, -1.6449e-02,  ...,  1.3351e-02,
          1.8768e-03,  1.6632e-02],
        [ 7.2174e-03,  1.6998e-02, -2.6688e-02,  ..., -6.2790e-03,
         -6.9771e-03,  2.0569e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:04:19 root INFO     h_layer_name='transformer.h.25.ln_1' z_layer_name='transformer.h.26'
2024-07-01 11:04:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0435,  0.1694,  0.7769,  ...,  0.1993,  1.7148,  0.6094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.7417,  1.2275, -1.0410,  ..., -1.2891, -0.0498,  0.6177],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.4822, 0.7363, 2.5566,  ..., 0.5640, 4.8672, 2.8848], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.7559,  5.8242, -1.4199,  ..., -4.5469,  1.9893,  3.5195],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:04:19 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 11:04:19 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 11:05:41 lre.functional WARNING  [insert_s_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 11:07:09 lre.functional WARNING  [insert_o_j] layer transformer.h.26 does not match transformer.h.25.ln_1
2024-07-01 11:08:35 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.7059e-04, -5.3215e-04,  5.3525e-05,  ...,  9.6500e-05,
         -9.5665e-05,  4.3058e-04],
        [-6.0081e-04, -3.9935e-04,  1.5998e-04,  ..., -9.8467e-05,
         -3.6049e-04, -7.1526e-07],
        [ 2.6822e-04, -7.4625e-04,  1.4126e-05,  ..., -2.5058e-04,
          8.6367e-05, -1.8930e-04],
        ...,
        [ 5.6505e-04, -5.3644e-06, -1.6403e-04,  ...,  6.4373e-06,
          1.6606e-04, -1.7011e-04],
        [-2.0325e-04,  1.4460e-04, -2.1398e-05,  ..., -1.5926e-04,
         -2.2197e-04,  2.1029e-04],
        [-2.8419e-04, -3.5644e-04, -4.2260e-05,  ...,  2.5368e-04,
         -2.1064e-04, -1.8823e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0007, -0.0021,  0.0002,  ..., -0.0013, -0.0039,  0.0198],
        [-0.0027,  0.0212, -0.0078,  ...,  0.0173, -0.0111, -0.0141],
        [ 0.0024,  0.0039,  0.0118,  ..., -0.0013,  0.0073,  0.0041],
        ...,
        [-0.0066,  0.0124, -0.0038,  ...,  0.0066,  0.0036,  0.0031],
        [ 0.0012,  0.0309, -0.0007,  ...,  0.0046,  0.0244,  0.0029],
        [ 0.0031, -0.0025, -0.0078,  ...,  0.0032,  0.0009,  0.0155]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0464,  0.0197,  0.0168,  ...,  0.0212,  0.0036,  0.0323],
        [-0.0226, -0.0377,  0.0031,  ...,  0.0244, -0.0128, -0.0186],
        [ 0.0219, -0.0187, -0.0437,  ...,  0.0131, -0.0061,  0.0143],
        ...,
        [-0.0068,  0.0041, -0.0054,  ..., -0.0491, -0.0013,  0.0073],
        [ 0.0017,  0.0318, -0.0099,  ..., -0.0102, -0.0555, -0.0034],
        [ 0.0043,  0.0038,  0.0011,  ...,  0.0216, -0.0081, -0.0431]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:08:38 root INFO     h_layer_name='transformer.h.26.ln_1' z_layer_name='transformer.h.27'
2024-07-01 11:08:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.0287,  0.2201,  0.6440,  ...,  0.0412,  1.4980,  0.5757],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.6099,  1.3252, -0.8325,  ..., -0.9497,  0.2091,  0.5952],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 2.3672,  0.9805,  1.2314,  ..., -0.3667,  4.5703,  1.4775],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 1.1328,  5.2539, -2.1641,  ..., -5.8008, -0.7119,  1.6611],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:08:38 root INFO     [order_1_approx] starting weight calculation for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 11:08:38 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 11:10:05 lre.functional WARNING  [insert_s_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 11:11:32 lre.functional WARNING  [insert_o_j] layer transformer.h.27 does not match transformer.h.26.ln_1
2024-07-01 11:12:59 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.0101e-02, -4.1270e-04, -9.5510e-04,  ..., -7.5340e-04,
          5.1260e-05, -1.1740e-03],
        [ 1.1921e-03,  5.3520e-03, -6.6090e-04,  ...,  6.1393e-05,
         -1.0338e-03, -1.6296e-04],
        [ 5.9509e-04, -7.2575e-04,  7.9498e-03,  ..., -6.5994e-04,
         -6.9141e-04,  4.1533e-04],
        ...,
        [-2.6417e-03, -1.0653e-03,  4.5490e-04,  ...,  9.5215e-03,
         -1.0939e-03, -1.4725e-03],
        [ 6.5565e-04,  2.4652e-04, -1.6270e-03,  ..., -4.9973e-04,
          1.2260e-02, -5.4026e-04],
        [ 5.6088e-05,  5.7840e-04, -1.3580e-03,  ..., -1.3199e-03,
         -1.1196e-03,  1.3176e-02]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[ 0.0059,  0.0098, -0.0023,  ..., -0.0144,  0.0031,  0.0114],
        [-0.0076, -0.0114,  0.0082,  ...,  0.0159,  0.0019, -0.0020],
        [-0.0037, -0.0094,  0.0078,  ...,  0.0013,  0.0044, -0.0123],
        ...,
        [-0.0014, -0.0173, -0.0046,  ...,  0.0175, -0.0195,  0.0127],
        [ 0.0121, -0.0045, -0.0018,  ..., -0.0104,  0.0034,  0.0132],
        [-0.0048,  0.0125, -0.0011,  ..., -0.0016,  0.0187,  0.0201]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.0773e-02,  2.8214e-02,  2.2049e-02,  ..., -1.4961e-02,
          1.2520e-02,  2.0172e-02],
        [ 9.3384e-03, -6.8054e-02, -2.9678e-03,  ...,  6.3820e-03,
          2.7008e-02, -1.3184e-02],
        [ 6.8512e-03, -1.6327e-02, -2.1210e-02,  ..., -3.8849e-02,
         -4.7722e-03,  3.8204e-03],
        ...,
        [ 1.7242e-02,  1.8677e-02, -3.1109e-03,  ...,  1.3046e-03,
         -5.6686e-03,  1.3100e-02],
        [-9.5520e-03, -2.1194e-02, -3.9276e-02,  ..., -1.7670e-02,
         -1.8219e-02, -6.1417e-03],
        [ 6.6071e-03,  2.0660e-02,  1.3351e-02,  ..., -7.1297e-03,
         -5.9128e-05, -8.6060e-03]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:13:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you deliver something, you are a deliverer
If you mourn something, you are a mourner
If you perform something, you are a performer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you compose something, you are a composer
If you speak something, you are a speaker
If you suffer something, you are a
2024-07-01 11:13:02 root INFO     h_layer_name='transformer.h.1.ln_1' z_layer_name='transformer.h.2'
2024-07-01 11:13:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.7246, -0.0273, -0.4460,  ...,  0.7998, -0.1873, -0.5010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.1588,  0.0898, -0.1575,  ..., -0.3762,  0.0268,  0.0614],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([-0.1389, -0.0374, -0.1265,  ...,  0.7300, -1.0332,  0.0740],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0038,  0.2600,  0.1516,  ..., -0.7402, -0.2240, -0.1274],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:13:02 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:13:02 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 11:13:25 lre.functional WARNING  [insert_s_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 11:13:48 lre.functional WARNING  [insert_o_j] layer transformer.h.2 does not match transformer.h.1.ln_1
2024-07-01 11:14:11 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.0065e-04, -2.8300e-04,  3.1519e-04,  ...,  6.2704e-05,
          9.2077e-04, -4.7088e-06],
        [-3.7956e-04, -4.0460e-04, -2.7847e-04,  ..., -1.9073e-04,
          4.0913e-04, -2.4462e-04],
        [ 5.0306e-04,  3.1638e-04, -5.2691e-04,  ..., -4.7922e-04,
          1.7357e-04,  3.5572e-04],
        ...,
        [-3.7718e-04, -6.5184e-04, -6.6161e-06,  ..., -5.4979e-04,
         -2.2233e-05, -4.0507e-04],
        [ 5.0354e-04, -1.6546e-04, -1.9026e-04,  ...,  2.3711e-04,
         -9.9754e-04, -2.7800e-04],
        [ 2.0730e-04, -3.8576e-04,  2.7490e-04,  ...,  4.1890e-04,
         -4.5061e-05, -8.0204e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-2.2491e-02,  1.1148e-03,  5.0545e-04,  ...,  1.3351e-03,
          4.3755e-03, -9.3002e-03],
        [-1.5621e-03, -2.7359e-02,  6.2943e-05,  ..., -7.0810e-04,
          3.3054e-03,  2.5883e-03],
        [ 2.6321e-03, -2.6951e-03, -3.8574e-02,  ..., -7.6065e-03,
          6.5269e-03, -2.9716e-03],
        ...,
        [ 6.3934e-03,  4.6844e-03, -9.9564e-03,  ..., -3.7933e-02,
         -3.2196e-03,  1.6136e-03],
        [-3.1853e-03,  2.6131e-03,  8.3694e-03,  ...,  2.0065e-03,
         -3.6102e-02,  3.2578e-03],
        [-2.0866e-03,  2.9831e-03,  3.3617e-04,  ..., -3.1548e-03,
          8.5526e-03, -2.8229e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.7567e-02,  2.1458e-05,  1.5535e-03,  ..., -1.6975e-03,
         -8.7738e-04,  5.5075e-04],
        [ 1.5688e-03, -3.9276e-02,  3.4189e-04,  ...,  3.2635e-03,
          7.3967e-03,  2.6989e-03],
        [-4.6463e-03,  1.9245e-03, -3.5767e-02,  ..., -2.9316e-03,
          2.0370e-03,  2.4433e-03],
        ...,
        [ 3.0708e-03,  3.9902e-03,  3.3283e-04,  ..., -3.8879e-02,
          3.0422e-03,  3.8261e-03],
        [-4.2381e-03,  2.8095e-03,  1.0481e-03,  ..., -9.5034e-04,
         -3.5980e-02,  7.0343e-03],
        [-1.6394e-03, -1.2760e-03, -1.8005e-03,  ...,  2.3575e-03,
          6.1569e-03, -3.5797e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:14:14 root INFO     h_layer_name='transformer.h.2.ln_1' z_layer_name='transformer.h.3'
2024-07-01 11:14:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2386,  0.2235, -0.1769,  ...,  0.4282, -0.6221, -0.1403],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.1143,  0.2170,  0.0436,  ..., -0.6787, -0.1680, -0.1011],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.0981,  0.2485, -0.0073,  ...,  0.5366, -0.8740,  0.0362],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0395,  0.5166,  0.3418,  ..., -1.3379, -0.4199,  0.0295],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:14:14 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:14:14 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 11:14:38 lre.functional WARNING  [insert_s_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 11:15:03 lre.functional WARNING  [insert_o_j] layer transformer.h.3 does not match transformer.h.2.ln_1
2024-07-01 11:15:27 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.5967e-03,  7.7724e-04, -9.2983e-06,  ..., -1.3170e-03,
         -1.0490e-03, -5.8985e-04],
        [ 1.5199e-05, -6.4430e-03, -1.0014e-03,  ..., -2.2840e-04,
         -3.9577e-05, -6.5231e-04],
        [-3.9172e-04,  2.1887e-04, -4.7073e-03,  ..., -1.5297e-03,
          2.1229e-03, -1.5440e-03],
        ...,
        [ 1.1711e-03,  9.4175e-04, -6.3229e-04,  ..., -4.4594e-03,
         -8.3447e-04, -1.2779e-03],
        [ 1.0157e-03, -2.8133e-05,  4.2915e-04,  ..., -1.8382e-04,
         -4.6501e-03, -3.1281e-04],
        [-6.7568e-04, -2.2888e-05,  7.3493e-05,  ..., -1.0663e-04,
         -1.1797e-03, -4.7188e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0699,  0.0038, -0.0032,  ...,  0.0037,  0.0108,  0.0002],
        [ 0.0024, -0.0695, -0.0015,  ..., -0.0018,  0.0022,  0.0036],
        [-0.0048, -0.0050, -0.0542,  ...,  0.0050, -0.0025,  0.0002],
        ...,
        [ 0.0065, -0.0030, -0.0075,  ..., -0.0663,  0.0013, -0.0082],
        [ 0.0069, -0.0066, -0.0050,  ..., -0.0004, -0.0630, -0.0003],
        [-0.0021, -0.0155,  0.0069,  ..., -0.0057, -0.0053, -0.0638]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-6.0730e-02,  9.1019e-03, -3.4676e-03,  ...,  5.8670e-03,
          1.4277e-03,  1.4725e-03],
        [ 7.9823e-04, -5.9479e-02, -2.0885e-04,  ..., -2.7418e-06,
         -4.5662e-03,  5.2147e-03],
        [-2.8839e-03,  2.8191e-03, -4.6997e-02,  ...,  3.0975e-03,
          2.3689e-03,  7.2956e-05],
        ...,
        [-3.4943e-03,  5.9814e-03, -2.6951e-03,  ..., -5.3406e-02,
         -6.0539e-03,  4.1466e-03],
        [ 1.6909e-03, -3.8662e-03,  4.7226e-03,  ...,  1.9550e-03,
         -5.2185e-02,  1.1444e-04],
        [ 5.0783e-04, -1.2255e-03, -1.4973e-03,  ..., -2.3460e-03,
          7.1259e-03, -5.8777e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:15:29 root INFO     h_layer_name='transformer.h.3.ln_1' z_layer_name='transformer.h.4'
2024-07-01 11:15:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([-0.1819, -0.0687, -0.1497,  ...,  0.7861, -1.1533,  0.0583],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0211,  0.4048,  0.2391,  ..., -1.1123, -0.3452, -0.2280],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2964,  0.1143, -0.2595,  ...,  0.7285, -0.5850, -0.1560],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0792,  0.5068,  0.2864,  ..., -1.0381, -0.5337,  0.3958],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:15:29 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:15:29 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 11:15:54 lre.functional WARNING  [insert_s_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 11:16:19 lre.functional WARNING  [insert_o_j] layer transformer.h.4 does not match transformer.h.3.ln_1
2024-07-01 11:16:45 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.8981e-03, -5.8603e-04, -3.4676e-03,  ...,  7.7438e-04,
         -8.1253e-04, -5.9986e-04],
        [ 4.7016e-04, -4.4670e-03,  1.2815e-04,  ...,  4.2892e-04,
         -5.1975e-04,  1.7238e-04],
        [-2.9888e-03, -2.1505e-04, -5.1384e-03,  ...,  5.6624e-05,
          2.5702e-04,  7.0000e-04],
        ...,
        [-1.6146e-03,  1.1072e-03, -7.2813e-04,  ..., -4.9629e-03,
          1.0071e-03,  2.2531e-04],
        [-7.0524e-04,  7.5102e-04, -4.4751e-04,  ...,  1.7583e-04,
         -5.0316e-03, -1.8573e-04],
        [ 2.5678e-04, -1.8001e-05, -1.5044e-04,  ...,  4.4012e-04,
          1.2245e-03, -5.5923e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-3.8879e-02, -6.0043e-03, -8.1024e-03,  ...,  2.9869e-03,
         -1.1635e-04, -1.9836e-04],
        [-4.5624e-03, -3.9948e-02,  6.8550e-03,  ...,  1.3056e-03,
         -8.1158e-04, -1.1158e-03],
        [ 9.9716e-03, -2.0638e-03, -3.2501e-02,  ..., -5.2757e-03,
          1.6203e-03,  2.5558e-03],
        ...,
        [ 1.3418e-03, -4.3106e-04, -1.0117e-02,  ..., -3.6835e-02,
         -4.1428e-03,  6.6948e-03],
        [-7.9803e-03,  1.3161e-04, -2.2011e-03,  ...,  8.0013e-04,
         -2.8076e-02,  7.6246e-04],
        [-6.0959e-03, -3.3073e-03,  6.7711e-05,  ..., -4.2763e-03,
         -2.7037e-04, -3.2532e-02]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-3.2867e-02, -2.4700e-03,  3.2959e-03,  ...,  2.2392e-03,
         -2.1057e-03, -5.6114e-03],
        [-2.9659e-03, -3.5492e-02,  7.7248e-03,  ...,  4.1580e-03,
          2.9516e-04,  6.7101e-03],
        [ 3.4676e-03, -2.2392e-03, -2.9099e-02,  ...,  3.7727e-03,
         -4.5509e-03,  2.0180e-03],
        ...,
        [-1.5316e-03,  3.8395e-03, -3.0975e-03,  ..., -2.5070e-02,
          4.7531e-03,  8.2970e-04],
        [-6.2904e-03, -2.6226e-03, -3.8147e-06,  ..., -8.7204e-03,
         -3.1342e-02, -6.2103e-03],
        [-6.9046e-03, -5.2490e-03, -4.3755e-03,  ..., -2.8725e-03,
          5.5504e-03, -3.2990e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:16:47 root INFO     h_layer_name='transformer.h.4.ln_1' z_layer_name='transformer.h.5'
2024-07-01 11:16:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.0868,  0.2629, -0.0099,  ...,  0.5913, -1.0059,  0.0019],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0391,  0.7388,  0.4883,  ..., -1.8350, -0.6045,  0.0122],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.1467, -0.3523, -0.2421,  ...,  0.6172, -0.0938, -0.1934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.2778,  0.7656,  0.2466,  ..., -1.3564,  0.0332,  0.6226],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:16:47 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:16:47 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 11:17:18 lre.functional WARNING  [insert_s_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 11:17:48 lre.functional WARNING  [insert_o_j] layer transformer.h.5 does not match transformer.h.4.ln_1
2024-07-01 11:18:19 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.1133e-03, -3.1066e-04,  1.3332e-03,  ..., -3.5429e-04,
          1.3266e-03, -9.0647e-04],
        [ 1.4219e-03, -3.5610e-03,  3.4952e-04,  ..., -1.1015e-03,
          8.2254e-05, -4.2677e-04],
        [-1.8835e-04,  1.3628e-03, -2.1935e-03,  ...,  1.1873e-03,
         -6.4754e-04,  5.1641e-04],
        ...,
        [ 3.0708e-04, -8.1587e-04, -6.5947e-04,  ..., -1.2665e-03,
          1.8120e-04,  2.3842e-07],
        [-3.0088e-04, -1.0443e-03,  4.4525e-05,  ..., -2.0409e-03,
         -2.8515e-03,  4.0936e-04],
        [ 2.7132e-04, -1.5748e-04, -7.0572e-04,  ..., -8.4591e-04,
          2.9683e-05, -3.4256e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0496,  0.0037,  0.0023,  ..., -0.0015, -0.0029,  0.0047],
        [ 0.0004, -0.0413, -0.0036,  ...,  0.0076,  0.0018,  0.0026],
        [ 0.0036, -0.0118, -0.0531,  ...,  0.0045, -0.0004, -0.0027],
        ...,
        [ 0.0002,  0.0072, -0.0029,  ..., -0.0492,  0.0012, -0.0010],
        [ 0.0008,  0.0057, -0.0045,  ..., -0.0073, -0.0406,  0.0057],
        [ 0.0020, -0.0041, -0.0008,  ...,  0.0035, -0.0008, -0.0453]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-5.0446e-02, -2.0199e-03,  7.9117e-03,  ...,  3.9062e-03,
          1.2016e-03,  2.0142e-03],
        [ 2.1381e-03, -4.2175e-02, -5.4092e-03,  ..., -1.7653e-03,
          2.4557e-04, -1.5032e-04],
        [-7.4234e-03, -7.9880e-03, -4.5502e-02,  ...,  4.3526e-03,
         -8.0414e-03,  2.2869e-03],
        ...,
        [-4.7588e-04, -1.0700e-03, -1.6212e-03,  ..., -4.5898e-02,
          6.0616e-03, -1.4610e-02],
        [-2.6703e-03, -3.5324e-03, -2.3041e-03,  ..., -4.3106e-03,
         -3.7018e-02, -4.8447e-03],
        [ 9.5367e-07,  4.3144e-03,  5.2643e-04,  ..., -6.3400e-03,
         -5.1460e-03, -4.2877e-02]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:18:21 root INFO     h_layer_name='transformer.h.5.ln_1' z_layer_name='transformer.h.6'
2024-07-01 11:18:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.2612,  0.0614, -0.2352,  ...,  0.6357, -0.5278, -0.1962],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0955,  0.5356,  0.3103,  ..., -1.0762, -0.5532,  0.4141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.3054, 0.1970, 0.5166,  ..., 0.4443, 0.0117, 0.2515], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([ 0.0635,  0.8940,  0.7104,  ..., -1.1318, -0.5415,  0.4512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:18:22 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:18:22 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 11:18:55 lre.functional WARNING  [insert_s_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 11:19:30 lre.functional WARNING  [insert_o_j] layer transformer.h.6 does not match transformer.h.5.ln_1
2024-07-01 11:20:03 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.5362e-03,  1.5392e-03, -1.5793e-03,  ...,  1.0128e-03,
         -5.0545e-04,  9.7752e-04],
        [-1.4648e-03, -1.1959e-03, -1.3790e-03,  ..., -2.6917e-04,
         -2.2411e-04, -2.8968e-05],
        [ 1.3428e-03,  1.0958e-03, -3.8967e-03,  ..., -6.3848e-04,
         -1.3809e-03, -1.9913e-03],
        ...,
        [-9.0599e-04,  6.8760e-04, -1.2865e-03,  ..., -4.3983e-03,
         -1.8177e-03, -2.8467e-04],
        [-1.2770e-03,  1.6384e-03,  7.0953e-04,  ...,  1.7176e-03,
         -4.0698e-04, -3.6430e-04],
        [-7.3910e-04, -1.5144e-03, -5.0843e-05,  ..., -7.3624e-04,
         -7.9823e-04, -2.2621e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0848,  0.0016, -0.0033,  ...,  0.0051,  0.0068, -0.0028],
        [-0.0024, -0.0751, -0.0013,  ...,  0.0002,  0.0076,  0.0038],
        [ 0.0002, -0.0073, -0.0852,  ...,  0.0012,  0.0139,  0.0064],
        ...,
        [-0.0032, -0.0090, -0.0110,  ..., -0.0818, -0.0032,  0.0020],
        [ 0.0053, -0.0061, -0.0018,  ...,  0.0058, -0.0867,  0.0061],
        [-0.0077,  0.0009,  0.0077,  ..., -0.0034, -0.0066, -0.0974]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1028, -0.0091,  0.0056,  ..., -0.0018, -0.0025,  0.0035],
        [-0.0073, -0.1042,  0.0033,  ...,  0.0038, -0.0037,  0.0048],
        [-0.0009,  0.0009, -0.0930,  ..., -0.0010,  0.0128,  0.0095],
        ...,
        [-0.0059,  0.0040, -0.0080,  ..., -0.0828,  0.0039,  0.0016],
        [-0.0041, -0.0030,  0.0020,  ...,  0.0078, -0.0937,  0.0010],
        [-0.0078,  0.0089,  0.0078,  ..., -0.0040, -0.0030, -0.1057]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:20:06 root INFO     h_layer_name='transformer.h.6.ln_1' z_layer_name='transformer.h.7'
2024-07-01 11:20:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1263, -0.3455, -0.2222,  ...,  0.5356, -0.1044, -0.2042],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.3071,  0.8511,  0.2522,  ..., -1.4219,  0.0222,  0.6802],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.2131, -0.3079,  0.1675,  ...,  0.9102,  0.0715,  0.1620],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0686,  0.8774,  0.3496,  ..., -0.8511, -0.5977,  0.0264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:20:06 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:20:06 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 11:20:43 lre.functional WARNING  [insert_s_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 11:21:18 lre.functional WARNING  [insert_o_j] layer transformer.h.7 does not match transformer.h.6.ln_1
2024-07-01 11:21:53 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-3.8509e-03, -6.9618e-04,  2.1286e-03,  ..., -4.3821e-04,
         -1.7107e-05,  2.6107e-04],
        [ 1.4219e-03, -5.1918e-03,  2.7485e-03,  ...,  3.3498e-04,
          1.4925e-03, -6.6376e-04],
        [-1.5569e-04,  2.0905e-03, -4.1351e-03,  ..., -1.7321e-04,
         -5.1355e-04,  3.2067e-05],
        ...,
        [ 2.3770e-04,  8.8692e-04, -1.1873e-03,  ..., -3.5782e-03,
         -1.1034e-03,  2.2297e-03],
        [ 2.9993e-04, -1.0815e-03,  6.9141e-04,  ..., -1.4133e-03,
         -1.2665e-03, -8.3590e-04],
        [ 1.9760e-03, -9.2506e-04,  9.5558e-04,  ...,  3.0565e-04,
         -8.1730e-04, -1.5936e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0749, -0.0042, -0.0056,  ...,  0.0029, -0.0008, -0.0068],
        [-0.0009, -0.0881,  0.0051,  ...,  0.0014,  0.0062,  0.0037],
        [ 0.0046,  0.0054, -0.0905,  ..., -0.0063, -0.0091,  0.0039],
        ...,
        [ 0.0064, -0.0084,  0.0125,  ..., -0.0856,  0.0007, -0.0024],
        [-0.0013,  0.0036, -0.0098,  ..., -0.0060, -0.0848,  0.0017],
        [-0.0039,  0.0032, -0.0068,  ..., -0.0192, -0.0002, -0.0862]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1071, -0.0041, -0.0041,  ...,  0.0015,  0.0009,  0.0008],
        [ 0.0001, -0.0913, -0.0091,  ...,  0.0052, -0.0104,  0.0032],
        [ 0.0035, -0.0007, -0.0948,  ...,  0.0023, -0.0003, -0.0006],
        ...,
        [ 0.0003,  0.0055,  0.0090,  ..., -0.1018, -0.0042, -0.0026],
        [-0.0028,  0.0014, -0.0077,  ..., -0.0030, -0.0952, -0.0070],
        [-0.0043, -0.0062, -0.0104,  ..., -0.0058, -0.0028, -0.0997]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:21:56 root INFO     h_layer_name='transformer.h.7.ln_1' z_layer_name='transformer.h.8'
2024-07-01 11:21:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.2394, 0.1710, 0.3704,  ..., 0.3069, 0.0006, 0.1687], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([ 0.0605,  0.8936,  0.6240,  ..., -1.0391, -0.5132,  0.4099],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8750, -0.2935,  0.3838,  ...,  1.3018,  0.4299,  0.4819],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2976,  0.5435,  0.1097,  ..., -1.2178, -1.1426, -0.4331],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:21:56 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:21:56 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 11:22:35 lre.functional WARNING  [insert_s_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 11:23:15 lre.functional WARNING  [insert_o_j] layer transformer.h.8 does not match transformer.h.7.ln_1
2024-07-01 11:23:54 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-2.3136e-03,  4.1771e-04,  7.4959e-04,  ...,  3.1776e-03,
         -4.7417e-03,  7.7724e-04],
        [-3.1757e-04, -3.2215e-03, -7.9584e-04,  ...,  6.8665e-05,
          4.2038e-03, -2.1152e-03],
        [ 1.0700e-03, -1.4458e-03, -4.2877e-03,  ..., -2.7332e-03,
         -1.4675e-04, -3.1357e-03],
        ...,
        [-6.1870e-05,  1.0357e-03,  7.5006e-04,  ..., -4.5052e-03,
          1.1930e-03,  3.9124e-04],
        [-6.1798e-04,  1.9026e-04, -1.3351e-03,  ...,  1.3552e-03,
         -2.0866e-03,  6.6948e-04],
        [ 1.8463e-03, -9.7156e-06, -7.5221e-05,  ..., -1.7939e-03,
          1.8864e-03, -2.1877e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0861,  0.0136,  0.0056,  ...,  0.0074,  0.0005,  0.0043],
        [ 0.0032, -0.0809,  0.0002,  ..., -0.0003, -0.0032,  0.0075],
        [ 0.0140,  0.0087, -0.0739,  ...,  0.0037, -0.0011,  0.0113],
        ...,
        [-0.0100,  0.0079,  0.0099,  ..., -0.0767, -0.0104, -0.0023],
        [-0.0003, -0.0078, -0.0059,  ...,  0.0021, -0.0894,  0.0042],
        [ 0.0068, -0.0005,  0.0099,  ...,  0.0020,  0.0059, -0.0921]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1091, -0.0027,  0.0096,  ..., -0.0073, -0.0060, -0.0109],
        [ 0.0036, -0.1017, -0.0049,  ...,  0.0034,  0.0189, -0.0057],
        [ 0.0035, -0.0025, -0.0972,  ..., -0.0035,  0.0050,  0.0118],
        ...,
        [-0.0011,  0.0020, -0.0037,  ..., -0.1034,  0.0116,  0.0025],
        [ 0.0029,  0.0017,  0.0075,  ...,  0.0147, -0.1000, -0.0051],
        [-0.0062, -0.0052,  0.0088,  ...,  0.0118,  0.0030, -0.0983]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:23:57 root INFO     h_layer_name='transformer.h.8.ln_1' z_layer_name='transformer.h.9'
2024-07-01 11:23:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.1589, -0.2476,  0.1033,  ...,  0.6201,  0.0415,  0.0977],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0592,  0.8545,  0.3059,  ..., -0.7510, -0.5552,  0.0069],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 1.1318, -0.6729,  0.1172,  ...,  1.1602,  0.4800,  0.4844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.5713,  0.3916,  0.0502,  ..., -1.3750, -1.7959,  0.4712],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:23:57 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:23:57 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 11:24:38 lre.functional WARNING  [insert_s_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 11:25:19 lre.functional WARNING  [insert_o_j] layer transformer.h.9 does not match transformer.h.8.ln_1
2024-07-01 11:26:02 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0020, -0.0012,  0.0020,  ..., -0.0005,  0.0006, -0.0025],
        [-0.0019, -0.0075,  0.0022,  ..., -0.0041,  0.0007, -0.0031],
        [-0.0003,  0.0038, -0.0058,  ..., -0.0022,  0.0016,  0.0008],
        ...,
        [ 0.0004, -0.0011, -0.0022,  ..., -0.0029,  0.0014,  0.0018],
        [ 0.0011, -0.0003, -0.0015,  ..., -0.0038, -0.0061, -0.0011],
        [ 0.0036,  0.0014, -0.0019,  ..., -0.0002, -0.0005, -0.0029]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-7.9102e-02, -3.4676e-03, -1.0117e-02,  ..., -4.4174e-03,
         -4.9248e-03,  2.0390e-03],
        [ 9.1743e-04, -1.0736e-01,  4.7989e-03,  ...,  3.7994e-03,
         -2.6207e-03,  1.2161e-02],
        [-3.7537e-03,  4.0207e-03, -8.5388e-02,  ..., -7.6103e-04,
         -6.8054e-03, -6.4163e-03],
        ...,
        [ 4.0054e-05, -7.7057e-04, -4.0245e-03,  ..., -1.0187e-01,
          5.6152e-03,  8.3351e-04],
        [ 6.1512e-04,  6.2637e-03,  5.8060e-03,  ..., -1.2268e-02,
         -8.8501e-02,  1.1925e-02],
        [ 6.9313e-03,  1.6861e-02, -8.5602e-03,  ..., -4.1199e-03,
          6.3972e-03, -1.0388e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1096,  0.0154, -0.0038,  ..., -0.0108,  0.0055,  0.0021],
        [ 0.0028, -0.1148,  0.0085,  ..., -0.0022, -0.0089,  0.0168],
        [-0.0014, -0.0017, -0.1076,  ..., -0.0080, -0.0045,  0.0088],
        ...,
        [ 0.0052,  0.0028, -0.0159,  ..., -0.1085,  0.0047, -0.0043],
        [-0.0080, -0.0010, -0.0071,  ..., -0.0048, -0.1023,  0.0114],
        [-0.0014, -0.0053, -0.0117,  ...,  0.0015,  0.0106, -0.1069]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:26:04 root INFO     h_layer_name='transformer.h.9.ln_1' z_layer_name='transformer.h.10'
2024-07-01 11:26:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.5459, -0.1997,  0.1835,  ...,  0.7646,  0.2510,  0.2979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2603,  0.4507,  0.0365,  ..., -0.9468, -0.9170, -0.3757],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.8516, -0.2229,  0.6221,  ...,  0.9243,  0.9771, -0.2271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0916,  0.6675,  0.1304,  ..., -1.2559, -1.6621,  0.2263],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:26:04 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:26:04 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 11:26:54 lre.functional WARNING  [insert_s_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 11:27:42 lre.functional WARNING  [insert_o_j] layer transformer.h.10 does not match transformer.h.9.ln_1
2024-07-01 11:28:32 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-0.0030,  0.0013,  0.0010,  ..., -0.0030,  0.0010, -0.0020],
        [ 0.0009, -0.0001,  0.0012,  ...,  0.0025, -0.0009,  0.0014],
        [-0.0027, -0.0040,  0.0017,  ..., -0.0013,  0.0006,  0.0003],
        ...,
        [ 0.0018, -0.0026, -0.0030,  ...,  0.0025,  0.0001, -0.0008],
        [-0.0051, -0.0036,  0.0031,  ...,  0.0037, -0.0012, -0.0012],
        [-0.0008, -0.0021,  0.0002,  ..., -0.0005,  0.0007,  0.0022]],
       device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0969, -0.0048, -0.0084,  ..., -0.0145,  0.0006,  0.0028],
        [ 0.0093, -0.0974, -0.0063,  ...,  0.0048,  0.0018, -0.0021],
        [ 0.0004,  0.0007, -0.0948,  ..., -0.0070, -0.0092,  0.0008],
        ...,
        [-0.0021, -0.0003, -0.0043,  ..., -0.0896, -0.0023,  0.0064],
        [-0.0005,  0.0050,  0.0124,  ...,  0.0046, -0.1002,  0.0060],
        [-0.0051, -0.0046, -0.0013,  ..., -0.0036,  0.0108, -0.0866]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.1727, -0.0085, -0.0097,  ...,  0.0046,  0.0099,  0.0009],
        [-0.0102, -0.1809, -0.0072,  ..., -0.0008, -0.0022, -0.0055],
        [-0.0059, -0.0063, -0.1610,  ...,  0.0062,  0.0038, -0.0120],
        ...,
        [-0.0090,  0.0128,  0.0175,  ..., -0.1740, -0.0164,  0.0066],
        [ 0.0038,  0.0038,  0.0128,  ..., -0.0095, -0.1631, -0.0090],
        [-0.0065,  0.0178, -0.0067,  ..., -0.0137, -0.0138, -0.1541]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:28:34 root INFO     h_layer_name='transformer.h.10.ln_1' z_layer_name='transformer.h.11'
2024-07-01 11:28:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.6797, -0.4238,  0.0268,  ...,  0.6611,  0.2620,  0.2489],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-4.2432e-01,  2.8174e-01, -2.3794e-04,  ..., -9.6289e-01,
        -1.3301e+00,  3.1885e-01], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_j1: tensor([ 0.6191, -0.2067,  1.2539,  ...,  0.5220,  1.2666, -0.1565],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.0778,  1.1113, -0.2583,  ..., -1.1152, -1.6094,  0.4849],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:28:34 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:28:34 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 11:29:22 lre.functional WARNING  [insert_s_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 11:30:09 lre.functional WARNING  [insert_o_j] layer transformer.h.11 does not match transformer.h.10.ln_1
2024-07-01 11:31:00 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-1.3447e-03, -9.3794e-04, -9.2316e-04,  ...,  2.7885e-03,
          1.8883e-03,  2.2011e-03],
        [-2.7013e-04,  4.9171e-03, -4.6492e-05,  ...,  4.9925e-04,
          2.9545e-03,  3.6602e-03],
        [-9.3985e-04, -2.5826e-03,  4.9257e-04,  ...,  2.2068e-03,
         -2.8133e-04, -1.2255e-03],
        ...,
        [ 3.0670e-03,  7.1883e-05,  3.0346e-03,  ..., -3.4094e-04,
         -1.2064e-03,  2.2259e-03],
        [-1.1702e-03, -2.2907e-03,  1.3914e-03,  ...,  3.0880e-03,
         -7.7152e-04,  1.0891e-03],
        [-1.2245e-03, -5.8746e-04, -2.2278e-03,  ...,  3.7193e-04,
          1.6813e-03, -2.4343e-04]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-1.2299e-01,  1.3962e-02, -4.8523e-03,  ...,  2.9678e-03,
         -7.4539e-03,  7.0572e-04],
        [ 1.1940e-02, -1.2854e-01,  2.2945e-03,  ..., -2.6150e-03,
         -5.1117e-03, -9.6207e-03],
        [ 6.2485e-03,  9.9030e-03, -1.2109e-01,  ...,  4.7073e-03,
          6.8588e-03, -4.2114e-03],
        ...,
        [ 1.9348e-02, -5.6992e-03, -1.1185e-02,  ..., -9.3689e-02,
         -1.9073e-05, -1.6281e-02],
        [ 1.0933e-02,  1.6937e-03,  4.7951e-03,  ...,  1.0811e-02,
         -1.0980e-01,  9.3994e-03],
        [ 4.6730e-03,  6.5804e-03, -5.6171e-04,  ..., -6.4945e-04,
          6.5899e-04, -1.1743e-01]], device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-1.1200e-01,  1.7990e-02,  4.1962e-03,  ...,  7.0763e-03,
         -8.5526e-03,  1.7166e-04],
        [ 1.1673e-02, -9.7046e-02, -1.4248e-03,  ...,  1.6193e-03,
         -9.8572e-03, -6.7062e-03],
        [ 1.2569e-03,  1.7700e-03, -1.0858e-01,  ..., -1.7815e-03,
         -2.0714e-03,  7.5340e-03],
        ...,
        [ 9.7122e-03, -5.1498e-03, -4.0054e-03,  ..., -1.0822e-01,
          1.1490e-02, -8.6365e-03],
        [ 3.5553e-03, -4.7874e-03, -6.4850e-05,  ...,  2.8248e-03,
         -1.2177e-01,  5.7335e-03],
        [ 8.2016e-04, -7.6904e-03,  1.2672e-02,  ...,  2.1267e-04,
         -8.6784e-04, -1.1353e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:31:02 root INFO     h_layer_name='transformer.h.11.ln_1' z_layer_name='transformer.h.12'
2024-07-01 11:31:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.4451, -0.1444,  0.2690,  ...,  0.4380,  0.4907, -0.1247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0767,  0.4548,  0.0410,  ..., -0.8613, -1.1465,  0.1633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([0.5659, 0.4526, 0.5801,  ..., 0.2571, 1.1934, 0.2241], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.3247,  1.1494, -0.1366,  ..., -0.3672, -0.9023,  0.1128],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:31:02 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:31:02 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 11:31:56 lre.functional WARNING  [insert_s_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 11:32:48 lre.functional WARNING  [insert_o_j] layer transformer.h.12 does not match transformer.h.11.ln_1
2024-07-01 11:33:40 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[ 1.7195e-03,  1.5807e-04, -1.4186e-04,  ..., -1.6365e-03,
          1.2474e-03, -1.0538e-03],
        [-2.5010e-04,  6.2370e-04,  9.2840e-04,  ..., -1.3447e-03,
          8.1491e-04,  1.1892e-03],
        [-7.8976e-05, -1.6785e-03,  3.5534e-03,  ..., -1.7509e-03,
          2.8114e-03, -9.1314e-05],
        ...,
        [ 3.2177e-03,  2.2163e-03,  5.0812e-03,  ...,  5.3787e-03,
         -3.5534e-03,  3.7098e-03],
        [ 7.4339e-04,  7.8297e-04,  1.0672e-03,  ..., -1.7500e-03,
          2.6264e-03,  2.2774e-03],
        [-2.6169e-03,  5.4693e-04, -2.8276e-04,  ..., -1.3828e-03,
         -2.3308e-03,  1.5955e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.1993,  0.0056,  0.0114,  ..., -0.0086,  0.0036, -0.0156],
        [ 0.0019, -0.1995, -0.0029,  ..., -0.0028,  0.0092,  0.0011],
        [-0.0032, -0.0017, -0.1776,  ..., -0.0071,  0.0029, -0.0135],
        ...,
        [-0.0040, -0.0133,  0.0251,  ..., -0.2050,  0.0069,  0.0039],
        [-0.0043, -0.0008,  0.0024,  ...,  0.0113, -0.1912,  0.0037],
        [ 0.0012,  0.0027,  0.0018,  ..., -0.0109, -0.0016, -0.2004]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-2.2827e-01,  1.4595e-02,  1.5190e-02,  ..., -2.0935e-02,
         -1.9474e-03, -5.0812e-03],
        [ 3.9940e-03, -2.3621e-01, -1.0529e-02,  ..., -8.3466e-03,
          5.4588e-03,  1.7643e-03],
        [ 1.7944e-02,  1.1139e-02, -2.1997e-01,  ...,  7.8278e-03,
          9.5367e-03, -1.8295e-02],
        ...,
        [-4.5090e-03,  1.5926e-03, -1.3342e-03,  ..., -2.5122e-01,
          1.8890e-02, -1.4839e-02],
        [-1.0307e-02, -1.4420e-03, -7.9036e-05,  ...,  1.9547e-02,
         -2.3340e-01,  1.3294e-03],
        [-1.5604e-04,  8.8959e-03, -9.4299e-03,  ..., -1.6342e-02,
         -3.6736e-03, -2.2717e-01]], device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:33:43 root INFO     h_layer_name='transformer.h.12.ln_1' z_layer_name='transformer.h.13'
2024-07-01 11:33:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([ 0.3240, -0.1367,  0.6270,  ...,  0.2844,  0.7031, -0.1488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.0891,  0.8579, -0.2408,  ..., -0.8564, -1.2510,  0.3357],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.5879, 0.5811, 0.5728,  ..., 0.0673, 1.0957, 0.9458], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.6816,  1.0088, -0.5220,  ..., -0.2664, -1.0664,  0.2029],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:33:43 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:33:43 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 11:34:38 lre.functional WARNING  [insert_s_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 11:35:34 lre.functional WARNING  [insert_o_j] layer transformer.h.13 does not match transformer.h.12.ln_1
2024-07-01 11:36:30 root INFO     [order_1_approx] weight calculation finished 

                        s_o: tensor([[-4.9400e-03,  1.2851e-04,  8.4066e-04,  ..., -1.5736e-03,
         -4.2748e-04, -2.7733e-03],
        [ 1.5783e-04, -1.9798e-03,  8.5878e-04,  ...,  9.0063e-05,
         -7.8201e-04,  1.5621e-03],
        [-1.1320e-03,  2.4796e-03, -5.2986e-03,  ..., -8.8024e-04,
         -1.0996e-03, -2.3308e-03],
        ...,
        [ 4.3755e-03, -2.6608e-03, -3.2496e-04,  ..., -2.9182e-03,
          2.5043e-03, -1.5697e-03],
        [-1.0443e-03, -3.1452e-03, -1.9722e-03,  ..., -2.9011e-03,
         -5.1193e-03,  2.2869e-03],
        [ 1.2312e-03, -9.8419e-04,  1.9894e-03,  ...,  1.5926e-03,
          2.2948e-04, -6.2561e-03]], device='cuda:0', dtype=torch.float16) 

                        s_s: tensor([[-0.0921,  0.0076,  0.0111,  ...,  0.0043, -0.0101,  0.0040],
        [ 0.0195, -0.0922,  0.0069,  ..., -0.0139, -0.0071,  0.0038],
        [ 0.0008, -0.0062, -0.0839,  ..., -0.0072, -0.0077,  0.0106],
        ...,
        [-0.0041, -0.0065, -0.0018,  ..., -0.0754,  0.0034, -0.0090],
        [ 0.0018, -0.0006, -0.0155,  ..., -0.0140, -0.1065,  0.0035],
        [ 0.0042,  0.0037, -0.0093,  ...,  0.0010,  0.0090, -0.0886]],
       device='cuda:0', dtype=torch.float16) 

                        o_o: tensor([[-0.0792, -0.0058, -0.0113,  ...,  0.0059, -0.0007,  0.0031],
        [ 0.0067, -0.0984, -0.0027,  ...,  0.0048,  0.0021,  0.0207],
        [-0.0131, -0.0101, -0.1000,  ..., -0.0073,  0.0022,  0.0049],
        ...,
        [-0.0032, -0.0049,  0.0065,  ..., -0.0805,  0.0013,  0.0061],
        [-0.0100,  0.0058, -0.0148,  ...,  0.0064, -0.0902, -0.0124],
        [ 0.0038,  0.0036, -0.0046,  ...,  0.0164, -0.0002, -0.0894]],
       device='cuda:0', dtype=torch.float16) 

                    
2024-07-01 11:36:32 root INFO     h_layer_name='transformer.h.13.ln_1' z_layer_name='transformer.h.14'
2024-07-01 11:36:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j: tensor([0.3071, 0.2064, 0.2834,  ..., 0.1104, 0.6387, 0.0967], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j: tensor([-0.2529,  0.8330, -0.1088,  ..., -0.2847, -0.6685,  0.0629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_j1: tensor([1.7979, 0.7783, 0.7207,  ..., 0.0767, 1.7529, 0.5166], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1: tensor([-0.2058,  0.9653, -0.9229,  ..., -0.5449, -0.3994, -0.0593],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                    
2024-07-01 11:36:32 root INFO     [order_1_approx] starting weight calculation for If you perform something, you are a performer
If you suffer something, you are a sufferer
If you announce something, you are a announcer
If you examine something, you are a examiner
If you deliver something, you are a deliverer
If you compose something, you are a composer
If you speak something, you are a speaker
If you mourn something, you are a
2024-07-01 11:36:32 lre.functional WARNING  [insert_s_j] layer transformer.h.14 does not match transformer.h.13.ln_1
