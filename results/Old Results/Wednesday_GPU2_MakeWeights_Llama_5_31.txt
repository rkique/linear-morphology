2024-07-31 17:10:45 root INFO     loading model + tokenizer
2024-07-31 17:10:48 root INFO     model + tokenizer loaded
2024-07-31 17:10:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-07-31 17:10:48 root INFO     building operator meronyms - part
2024-07-31 17:10:49 root INFO     [order_1_approx] starting weight calculation for A part of a byte is a bit
A part of a staircase is a step
A part of a gigabit is a megabit
A part of a door is a hinge
A part of a sword is a blade
A part of a torso is a chest
A part of a orthography is a hyphenation
A part of a seafront is a
2024-07-31 17:10:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:13:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0807,  0.0026, -0.0012,  ...,  0.1251, -0.0803,  0.0504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3262, -4.0547, -2.3438,  ...,  5.9062, -3.3945, -0.4316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0228, -0.0030,  0.0082,  ...,  0.0121, -0.0320, -0.0216],
        [ 0.0169,  0.0340, -0.0188,  ...,  0.0290, -0.0342, -0.0158],
        [ 0.0397, -0.0070, -0.0021,  ..., -0.0291, -0.0060, -0.0174],
        ...,
        [-0.0108, -0.0019,  0.0082,  ...,  0.0245, -0.0093,  0.0024],
        [ 0.0208, -0.0161, -0.0024,  ..., -0.0074,  0.0230, -0.0168],
        [-0.0118,  0.0057, -0.0362,  ...,  0.0207, -0.0144,  0.0112]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3125, -4.3711, -1.9961,  ...,  5.7227, -3.1094, -0.6890]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:13:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a byte is a bit
A part of a staircase is a step
A part of a gigabit is a megabit
A part of a door is a hinge
A part of a sword is a blade
A part of a torso is a chest
A part of a orthography is a hyphenation
A part of a seafront is a
2024-07-31 17:13:43 root INFO     [order_1_approx] starting weight calculation for A part of a gigabit is a megabit
A part of a byte is a bit
A part of a orthography is a hyphenation
A part of a staircase is a step
A part of a seafront is a harbor
A part of a torso is a chest
A part of a sword is a blade
A part of a door is a
2024-07-31 17:13:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:16:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1215,  0.0594, -0.0894,  ..., -0.1672, -0.0831, -0.0900],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2646, -4.5547,  0.5527,  ...,  1.3047, -2.2949,  0.5303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0263, -0.0398,  0.0085,  ...,  0.0191, -0.0079, -0.0370],
        [-0.0007, -0.0075, -0.0148,  ..., -0.0101,  0.0152, -0.0447],
        [ 0.0257,  0.0324, -0.0033,  ...,  0.0098, -0.0387,  0.0198],
        ...,
        [ 0.0129, -0.0047,  0.0264,  ...,  0.0027,  0.0068,  0.0070],
        [ 0.0038,  0.0019,  0.0047,  ...,  0.0041,  0.0173,  0.0063],
        [ 0.0083,  0.0025, -0.0147,  ...,  0.0090, -0.0071, -0.0024]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1289, -3.6602,  0.3071,  ...,  1.5879, -2.0234,  0.6680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:16:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a gigabit is a megabit
A part of a byte is a bit
A part of a orthography is a hyphenation
A part of a staircase is a step
A part of a seafront is a harbor
A part of a torso is a chest
A part of a sword is a blade
A part of a door is a
2024-07-31 17:16:37 root INFO     [order_1_approx] starting weight calculation for A part of a sword is a blade
A part of a torso is a chest
A part of a door is a hinge
A part of a staircase is a step
A part of a byte is a bit
A part of a gigabit is a megabit
A part of a seafront is a harbor
A part of a orthography is a
2024-07-31 17:16:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:19:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0810,  0.0110,  0.1550,  ..., -0.1392,  0.1267, -0.2507],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.7334, -2.0977,  0.5381,  ...,  3.1289, -2.0449,  0.5547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0064, -0.0737,  0.0235,  ..., -0.0557, -0.0623, -0.0282],
        [ 0.0903,  0.0222, -0.0335,  ...,  0.0401,  0.0454,  0.0033],
        [-0.0202,  0.0150, -0.0381,  ...,  0.0189,  0.0019,  0.0413],
        ...,
        [ 0.0542,  0.0220, -0.0009,  ...,  0.0075,  0.0027, -0.0077],
        [-0.0201,  0.0156, -0.0358,  ...,  0.0385, -0.0004, -0.0050],
        [ 0.0640, -0.0173, -0.0038,  ...,  0.0346,  0.0238,  0.0037]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3359, -1.1914,  0.6069,  ...,  3.0371, -1.8086,  1.2559]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:19:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a sword is a blade
A part of a torso is a chest
A part of a door is a hinge
A part of a staircase is a step
A part of a byte is a bit
A part of a gigabit is a megabit
A part of a seafront is a harbor
A part of a orthography is a
2024-07-31 17:19:30 root INFO     [order_1_approx] starting weight calculation for A part of a staircase is a step
A part of a orthography is a hyphenation
A part of a seafront is a harbor
A part of a torso is a chest
A part of a sword is a blade
A part of a door is a hinge
A part of a gigabit is a megabit
A part of a byte is a
2024-07-31 17:19:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:22:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0492,  0.0855, -0.2048,  ..., -0.0367, -0.2286, -0.0280],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9883, -4.2266,  0.3313,  ...,  0.1445, -3.1133, -0.2275],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0197,  0.0195, -0.0373,  ..., -0.0057,  0.0277,  0.0002],
        [-0.0089, -0.1008,  0.0869,  ...,  0.0019, -0.0458, -0.0067],
        [-0.0184, -0.0290,  0.0366,  ..., -0.0464,  0.0188,  0.0048],
        ...,
        [-0.0233,  0.0114, -0.0281,  ...,  0.0708,  0.0155, -0.0320],
        [-0.0246, -0.0014,  0.0024,  ...,  0.0256,  0.0107, -0.0231],
        [-0.0104, -0.0420, -0.0043,  ...,  0.0362, -0.0225,  0.0197]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.5566, -2.5000,  0.4072,  ...,  0.3113, -3.2051,  0.2561]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:22:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a staircase is a step
A part of a orthography is a hyphenation
A part of a seafront is a harbor
A part of a torso is a chest
A part of a sword is a blade
A part of a door is a hinge
A part of a gigabit is a megabit
A part of a byte is a
2024-07-31 17:22:26 root INFO     [order_1_approx] starting weight calculation for A part of a staircase is a step
A part of a door is a hinge
A part of a sword is a blade
A part of a byte is a bit
A part of a seafront is a harbor
A part of a orthography is a hyphenation
A part of a torso is a chest
A part of a gigabit is a
2024-07-31 17:22:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:25:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1059, -0.0152,  0.0165,  ..., -0.1445, -0.0613,  0.0402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9082, -1.6621,  0.6177,  ...,  2.0625, -3.0898, -0.6577],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0187,  0.0314,  0.0201,  ...,  0.0025,  0.0113,  0.0210],
        [-0.0048,  0.0068,  0.0073,  ...,  0.0017,  0.0104,  0.0023],
        [-0.0042, -0.0079,  0.0215,  ..., -0.0086,  0.0222,  0.0569],
        ...,
        [-0.0206,  0.0308, -0.0126,  ...,  0.0467, -0.0114,  0.0120],
        [ 0.0015, -0.0064, -0.0177,  ...,  0.0020,  0.0229,  0.0026],
        [ 0.0148,  0.0058, -0.0196,  ...,  0.0151, -0.0069, -0.0085]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6855, -1.2842,  1.0293,  ...,  1.8975, -2.9785, -0.5293]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:25:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a staircase is a step
A part of a door is a hinge
A part of a sword is a blade
A part of a byte is a bit
A part of a seafront is a harbor
A part of a orthography is a hyphenation
A part of a torso is a chest
A part of a gigabit is a
2024-07-31 17:25:24 root INFO     [order_1_approx] starting weight calculation for A part of a torso is a chest
A part of a gigabit is a megabit
A part of a staircase is a step
A part of a orthography is a hyphenation
A part of a door is a hinge
A part of a byte is a bit
A part of a seafront is a harbor
A part of a sword is a
2024-07-31 17:25:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:28:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0618,  0.0039,  0.0082,  ..., -0.1575, -0.0580,  0.0067],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5854, -5.5273, -0.1377,  ...,  2.8320, -3.6094,  0.2983],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0329,  0.0199, -0.0050,  ...,  0.0125, -0.0303, -0.0020],
        [ 0.0142, -0.0131,  0.0087,  ..., -0.0405,  0.0296, -0.0014],
        [-0.0154, -0.0231,  0.0223,  ..., -0.0304, -0.0138, -0.0110],
        ...,
        [-0.0195,  0.0110,  0.0025,  ...,  0.0384, -0.0245,  0.0088],
        [-0.0007, -0.0211,  0.0033,  ...,  0.0254,  0.0508, -0.0195],
        [ 0.0482, -0.0387,  0.0227,  ...,  0.0119,  0.0259,  0.0424]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2944, -4.1719, -0.4326,  ...,  2.1777, -3.1094,  1.4883]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:28:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a torso is a chest
A part of a gigabit is a megabit
A part of a staircase is a step
A part of a orthography is a hyphenation
A part of a door is a hinge
A part of a byte is a bit
A part of a seafront is a harbor
A part of a sword is a
2024-07-31 17:28:23 root INFO     [order_1_approx] starting weight calculation for A part of a staircase is a step
A part of a seafront is a harbor
A part of a orthography is a hyphenation
A part of a byte is a bit
A part of a sword is a blade
A part of a door is a hinge
A part of a gigabit is a megabit
A part of a torso is a
2024-07-31 17:28:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:31:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0380,  0.0596, -0.0574,  ...,  0.0970, -0.0122, -0.0577],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6240, -5.2812,  3.1953,  ...,  0.9443, -3.1055, -0.2012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0805, -0.0914, -0.0001,  ...,  0.0483,  0.0643, -0.0444],
        [ 0.0496, -0.0188, -0.0154,  ..., -0.0059,  0.0348,  0.0200],
        [ 0.0268,  0.0468, -0.0222,  ...,  0.0059, -0.0030, -0.0040],
        ...,
        [-0.0660,  0.0430,  0.0378,  ..., -0.0053,  0.0750, -0.0573],
        [-0.0092, -0.0151, -0.0013,  ...,  0.0125, -0.0622, -0.0206],
        [-0.0789, -0.0637,  0.0275,  ...,  0.0238,  0.0652,  0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9277, -4.3477,  3.1484,  ...,  1.3916, -3.4277,  0.7314]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:31:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a staircase is a step
A part of a seafront is a harbor
A part of a orthography is a hyphenation
A part of a byte is a bit
A part of a sword is a blade
A part of a door is a hinge
A part of a gigabit is a megabit
A part of a torso is a
2024-07-31 17:31:18 root INFO     [order_1_approx] starting weight calculation for A part of a gigabit is a megabit
A part of a seafront is a harbor
A part of a sword is a blade
A part of a torso is a chest
A part of a door is a hinge
A part of a byte is a bit
A part of a orthography is a hyphenation
A part of a staircase is a
2024-07-31 17:31:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:34:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0967, -0.1216, -0.1787,  ...,  0.0050, -0.1159, -0.0211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8516, -1.7217,  2.6523,  ...,  2.4375, -5.5742, -0.9790],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5884e-02, -1.9745e-02,  3.1952e-02,  ...,  1.3275e-02,
         -1.0178e-02, -1.3069e-02],
        [ 1.5259e-05,  5.2109e-03,  2.0874e-02,  ...,  2.1667e-03,
         -1.8860e-02, -9.8572e-03],
        [ 5.4626e-03,  9.3155e-03,  3.7289e-03,  ..., -2.1423e-02,
         -4.7684e-03,  1.8021e-02],
        ...,
        [ 1.4305e-03,  1.1581e-02, -3.5744e-03,  ...,  4.6768e-03,
         -6.5384e-03,  3.9330e-03],
        [ 9.2850e-03, -1.4145e-02, -1.5961e-02,  ...,  1.3664e-02,
          7.4692e-03, -2.1210e-03],
        [ 1.5869e-03, -2.3651e-04,  2.2614e-02,  ...,  1.8402e-02,
          6.1798e-03, -1.6190e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0234, -1.3682,  2.6035,  ...,  2.2129, -5.4492, -0.2222]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:34:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a gigabit is a megabit
A part of a seafront is a harbor
A part of a sword is a blade
A part of a torso is a chest
A part of a door is a hinge
A part of a byte is a bit
A part of a orthography is a hyphenation
A part of a staircase is a
2024-07-31 17:34:18 root INFO     total operator prediction time: 1410.3401401042938 seconds
2024-07-31 17:34:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-07-31 17:34:18 root INFO     building operator synonyms - exact
2024-07-31 17:34:18 root INFO     [order_1_approx] starting weight calculation for Another word for list is listing
Another word for mend is repair
Another word for monument is memorial
Another word for bicycle is bike
Another word for hieroglyph is hieroglyphic
Another word for cloth is fabric
Another word for dollars is bucks
Another word for father is
2024-07-31 17:34:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:37:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0889, -0.0491, -0.1379,  ..., -0.0004, -0.1422, -0.0399],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6338, -2.3145,  0.3896,  ...,  0.3872, -3.1016, -2.3984],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0258, -0.0171,  0.0238,  ...,  0.0191, -0.0330,  0.0175],
        [ 0.0029,  0.0044,  0.0063,  ...,  0.0105,  0.0371,  0.0122],
        [-0.0300, -0.0356,  0.0054,  ...,  0.0251, -0.0202, -0.0207],
        ...,
        [ 0.0108, -0.0113, -0.0139,  ...,  0.0037, -0.0492,  0.0144],
        [-0.0045, -0.0320, -0.0219,  ..., -0.0013,  0.0033, -0.0198],
        [ 0.0037, -0.0017,  0.0170,  ..., -0.0166, -0.0260, -0.0129]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7314, -2.1855,  1.0098,  ..., -0.1523, -2.8867, -2.4062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:37:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for list is listing
Another word for mend is repair
Another word for monument is memorial
Another word for bicycle is bike
Another word for hieroglyph is hieroglyphic
Another word for cloth is fabric
Another word for dollars is bucks
Another word for father is
2024-07-31 17:37:16 root INFO     [order_1_approx] starting weight calculation for Another word for hieroglyph is hieroglyphic
Another word for father is dad
Another word for list is listing
Another word for mend is repair
Another word for bicycle is bike
Another word for monument is memorial
Another word for cloth is fabric
Another word for dollars is
2024-07-31 17:37:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:40:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0911, -0.1562, -0.0006,  ...,  0.1240, -0.0049,  0.0358],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5684, -1.8672,  2.4492,  ..., -2.9492,  0.5781, -2.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0708, -0.0625,  0.0346,  ..., -0.0096,  0.0287, -0.0030],
        [-0.0025, -0.0129, -0.0116,  ..., -0.0430,  0.0310,  0.0049],
        [ 0.0061, -0.0348,  0.0245,  ..., -0.0134, -0.0007,  0.0208],
        ...,
        [-0.0026,  0.0221,  0.0073,  ...,  0.0196, -0.0170, -0.0228],
        [-0.0580,  0.0231, -0.0411,  ...,  0.0399,  0.0362,  0.0258],
        [ 0.0081, -0.0250,  0.0186,  ...,  0.0033, -0.0289, -0.0010]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9414, -1.7129,  2.4961,  ..., -2.9180,  0.7134, -2.0234]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:40:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for hieroglyph is hieroglyphic
Another word for father is dad
Another word for list is listing
Another word for mend is repair
Another word for bicycle is bike
Another word for monument is memorial
Another word for cloth is fabric
Another word for dollars is
2024-07-31 17:40:14 root INFO     [order_1_approx] starting weight calculation for Another word for list is listing
Another word for father is dad
Another word for dollars is bucks
Another word for monument is memorial
Another word for cloth is fabric
Another word for mend is repair
Another word for hieroglyph is hieroglyphic
Another word for bicycle is
2024-07-31 17:40:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:43:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0565,  0.0192, -0.2272,  ..., -0.1387,  0.0011, -0.1458],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8052, -4.9805,  1.4365,  ...,  0.3867, -0.8335, -2.5352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0056, -0.0181,  0.0299,  ...,  0.0092,  0.0028,  0.0224],
        [-0.0016,  0.0106, -0.0011,  ...,  0.0025,  0.0057, -0.0028],
        [ 0.0163, -0.0188,  0.0330,  ..., -0.0153,  0.0093,  0.0039],
        ...,
        [ 0.0115, -0.0154,  0.0085,  ...,  0.0068, -0.0014,  0.0117],
        [-0.0032,  0.0179, -0.0177,  ..., -0.0070,  0.0073, -0.0121],
        [ 0.0077, -0.0164,  0.0254,  ..., -0.0059,  0.0069,  0.0057]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3662, -4.9297,  1.5254,  ...,  0.2661, -0.9546, -2.2891]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:43:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for list is listing
Another word for father is dad
Another word for dollars is bucks
Another word for monument is memorial
Another word for cloth is fabric
Another word for mend is repair
Another word for hieroglyph is hieroglyphic
Another word for bicycle is
2024-07-31 17:43:15 root INFO     [order_1_approx] starting weight calculation for Another word for father is dad
Another word for dollars is bucks
Another word for cloth is fabric
Another word for bicycle is bike
Another word for monument is memorial
Another word for list is listing
Another word for hieroglyph is hieroglyphic
Another word for mend is
2024-07-31 17:43:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:46:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0300,  0.1912, -0.1005,  ...,  0.1061, -0.1628,  0.0403],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4434, -6.4688,  2.2598,  ...,  4.1875, -5.0938,  1.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0187, -0.0216,  0.1147,  ...,  0.0012,  0.0620,  0.0242],
        [ 0.0361,  0.0049,  0.0787,  ..., -0.0251,  0.0129,  0.0142],
        [ 0.0127, -0.0082,  0.0591,  ..., -0.0108, -0.0242, -0.0397],
        ...,
        [ 0.0535,  0.0099,  0.0216,  ..., -0.0091, -0.0083,  0.0315],
        [ 0.0492, -0.0273,  0.1305,  ..., -0.0517,  0.0651,  0.0668],
        [-0.0083, -0.0240,  0.0416,  ..., -0.0578, -0.0463,  0.0585]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3008, -5.3984,  1.4062,  ...,  3.5527, -3.2422,  1.5469]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:46:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for father is dad
Another word for dollars is bucks
Another word for cloth is fabric
Another word for bicycle is bike
Another word for monument is memorial
Another word for list is listing
Another word for hieroglyph is hieroglyphic
Another word for mend is
2024-07-31 17:46:12 root INFO     [order_1_approx] starting weight calculation for Another word for hieroglyph is hieroglyphic
Another word for dollars is bucks
Another word for monument is memorial
Another word for bicycle is bike
Another word for father is dad
Another word for list is listing
Another word for mend is repair
Another word for cloth is
2024-07-31 17:46:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:49:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0138, -0.0329, -0.2419,  ...,  0.1050,  0.0303,  0.1213],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8125, -4.0156,  2.4570,  ..., -0.6318, -2.6426,  0.7402],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0356, -0.0123,  0.0045,  ..., -0.0025,  0.0427,  0.0052],
        [-0.0041,  0.0305,  0.0209,  ..., -0.0104, -0.0557, -0.0297],
        [-0.0090, -0.0511, -0.0219,  ..., -0.0630,  0.0684,  0.0216],
        ...,
        [ 0.0511,  0.0197,  0.0323,  ..., -0.0036, -0.0911, -0.0372],
        [-0.0341, -0.0536, -0.0528,  ...,  0.0088,  0.1180,  0.0513],
        [ 0.0192,  0.0707,  0.0617,  ...,  0.0097, -0.1046, -0.0157]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9727, -4.6328,  3.2656,  ..., -0.9248, -1.5684,  0.2285]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:49:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for hieroglyph is hieroglyphic
Another word for dollars is bucks
Another word for monument is memorial
Another word for bicycle is bike
Another word for father is dad
Another word for list is listing
Another word for mend is repair
Another word for cloth is
2024-07-31 17:49:13 root INFO     [order_1_approx] starting weight calculation for Another word for mend is repair
Another word for cloth is fabric
Another word for bicycle is bike
Another word for dollars is bucks
Another word for hieroglyph is hieroglyphic
Another word for list is listing
Another word for father is dad
Another word for monument is
2024-07-31 17:49:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:52:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0495,  0.1860,  0.1135,  ...,  0.0598, -0.1708, -0.0273],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8320, -4.3672,  1.7520,  ...,  0.4062, -4.6875, -2.3867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0408, -0.0220,  0.0285,  ..., -0.0059, -0.0679,  0.0228],
        [ 0.0565, -0.0021,  0.0614,  ..., -0.0085,  0.0731, -0.0304],
        [ 0.0182, -0.0240,  0.0275,  ..., -0.0250, -0.0329, -0.0049],
        ...,
        [ 0.0101,  0.0447,  0.0724,  ...,  0.0558,  0.0435, -0.0330],
        [-0.0115, -0.0820,  0.0471,  ..., -0.0066,  0.0285, -0.0267],
        [ 0.0221,  0.0420,  0.0189,  ...,  0.0208,  0.0206, -0.0005]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0547, -4.1875,  2.5898,  ..., -0.1978, -3.2891, -1.9824]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:52:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mend is repair
Another word for cloth is fabric
Another word for bicycle is bike
Another word for dollars is bucks
Another word for hieroglyph is hieroglyphic
Another word for list is listing
Another word for father is dad
Another word for monument is
2024-07-31 17:52:15 root INFO     [order_1_approx] starting weight calculation for Another word for mend is repair
Another word for father is dad
Another word for cloth is fabric
Another word for list is listing
Another word for dollars is bucks
Another word for bicycle is bike
Another word for monument is memorial
Another word for hieroglyph is
2024-07-31 17:52:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:55:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0353,  0.0261, -0.0961,  ..., -0.0854, -0.1277, -0.0942],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3477, -2.5469,  6.7891,  ...,  0.4731, -0.0586,  1.2256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1018,  0.0543,  0.0631,  ..., -0.0274, -0.0049, -0.0179],
        [ 0.0422,  0.0472,  0.0539,  ..., -0.0027,  0.0018,  0.0295],
        [ 0.0092, -0.0122,  0.0328,  ...,  0.0064,  0.0271, -0.0308],
        ...,
        [ 0.0027,  0.0105,  0.0298,  ...,  0.0379, -0.0296,  0.0350],
        [ 0.0119, -0.0164, -0.0095,  ..., -0.0564, -0.0053,  0.0163],
        [-0.0146,  0.0209, -0.0059,  ...,  0.0417, -0.0264,  0.0327]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7031, -2.8477,  6.3867,  ...,  1.1113, -0.4983,  1.4404]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:55:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mend is repair
Another word for father is dad
Another word for cloth is fabric
Another word for list is listing
Another word for dollars is bucks
Another word for bicycle is bike
Another word for monument is memorial
Another word for hieroglyph is
2024-07-31 17:55:13 root INFO     [order_1_approx] starting weight calculation for Another word for mend is repair
Another word for father is dad
Another word for cloth is fabric
Another word for hieroglyph is hieroglyphic
Another word for dollars is bucks
Another word for bicycle is bike
Another word for monument is memorial
Another word for list is
2024-07-31 17:55:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 17:58:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0273,  0.0457, -0.1331,  ...,  0.1790, -0.0436, -0.0154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8516, -2.4082,  3.2227,  ..., -0.2070, -2.3379, -3.0527],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0684, -0.0251,  0.0477,  ...,  0.0242, -0.0171,  0.0094],
        [ 0.0217,  0.0057,  0.0250,  ...,  0.0404,  0.0252, -0.0070],
        [-0.0119, -0.0308,  0.0046,  ..., -0.0007, -0.0230, -0.0026],
        ...,
        [ 0.0323,  0.0264,  0.0291,  ...,  0.0184,  0.0235, -0.0289],
        [-0.0127,  0.0208,  0.0234,  ...,  0.0033, -0.0321, -0.0174],
        [-0.0012, -0.0026, -0.0148,  ...,  0.0155,  0.0289,  0.0300]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5820, -1.9902,  3.6406,  ..., -0.3477, -3.2500, -2.5801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 17:58:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mend is repair
Another word for father is dad
Another word for cloth is fabric
Another word for hieroglyph is hieroglyphic
Another word for dollars is bucks
Another word for bicycle is bike
Another word for monument is memorial
Another word for list is
2024-07-31 17:58:11 root INFO     total operator prediction time: 1433.347984790802 seconds
2024-07-31 17:58:11 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - misc
2024-07-31 17:58:11 root INFO     building operator hypernyms - misc
2024-07-31 17:58:12 root INFO     [order_1_approx] starting weight calculation for The toothbrush falls into the category of brush
The diary falls into the category of journal
The croissant falls into the category of pastry
The plum falls into the category of fruit
The sofa falls into the category of furniture
The cake falls into the category of dessert
The computer falls into the category of device
The cup falls into the category of
2024-07-31 17:58:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:01:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0494, -0.2793,  0.2046,  ...,  0.1718,  0.0470, -0.1317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7910, -0.7905, -0.4341,  ..., -4.4609, -2.3066,  0.6680],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193,  0.0070, -0.0096,  ...,  0.0146, -0.0115,  0.0206],
        [ 0.0089,  0.0253, -0.0097,  ...,  0.0094, -0.0258,  0.0313],
        [-0.0163, -0.0648,  0.0019,  ..., -0.0419, -0.0327, -0.0191],
        ...,
        [-0.0107, -0.0166,  0.0028,  ...,  0.0058, -0.0048, -0.0107],
        [ 0.0364, -0.0123, -0.0077,  ...,  0.0060, -0.0054,  0.0169],
        [ 0.0027,  0.0122,  0.0069,  ...,  0.0170,  0.0105,  0.0016]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7676, -0.6074, -0.2400,  ..., -4.6172, -1.9443,  0.5742]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:01:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothbrush falls into the category of brush
The diary falls into the category of journal
The croissant falls into the category of pastry
The plum falls into the category of fruit
The sofa falls into the category of furniture
The cake falls into the category of dessert
The computer falls into the category of device
The cup falls into the category of
2024-07-31 18:01:08 root INFO     [order_1_approx] starting weight calculation for The croissant falls into the category of pastry
The cup falls into the category of tableware
The plum falls into the category of fruit
The cake falls into the category of dessert
The sofa falls into the category of furniture
The toothbrush falls into the category of brush
The computer falls into the category of device
The diary falls into the category of
2024-07-31 18:01:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:04:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1464,  0.0551, -0.1644,  ..., -0.0098, -0.1249,  0.1010],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2920, -3.3535,  1.2832,  ..., -2.4863, -3.6758,  0.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0703, -0.0036,  0.0074,  ..., -0.0500,  0.0009,  0.0289],
        [-0.0232,  0.0209, -0.0343,  ..., -0.0159, -0.0026, -0.0024],
        [ 0.0223, -0.0319,  0.0034,  ..., -0.0167,  0.0022,  0.0200],
        ...,
        [-0.0382,  0.0057,  0.0051,  ...,  0.0636, -0.0060, -0.0154],
        [-0.0067, -0.0130,  0.0243,  ..., -0.0099,  0.0097,  0.0116],
        [ 0.0289,  0.0129,  0.0004,  ..., -0.0032,  0.0033, -0.0235]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.3711, -3.1543,  1.0361,  ..., -2.2168, -3.6543,  0.5303]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:04:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The croissant falls into the category of pastry
The cup falls into the category of tableware
The plum falls into the category of fruit
The cake falls into the category of dessert
The sofa falls into the category of furniture
The toothbrush falls into the category of brush
The computer falls into the category of device
The diary falls into the category of
2024-07-31 18:04:08 root INFO     [order_1_approx] starting weight calculation for The croissant falls into the category of pastry
The diary falls into the category of journal
The plum falls into the category of fruit
The cake falls into the category of dessert
The cup falls into the category of tableware
The computer falls into the category of device
The sofa falls into the category of furniture
The toothbrush falls into the category of
2024-07-31 18:04:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:07:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0811,  0.0060,  0.0726,  ..., -0.0601, -0.1370, -0.0801],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9165, -2.5898, -0.8594,  ..., -3.2461, -3.6035,  1.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0137, -0.0144, -0.0142,  ..., -0.0201, -0.0068,  0.0293],
        [ 0.0384,  0.0041,  0.0149,  ..., -0.0002,  0.0085, -0.0236],
        [-0.0320, -0.0150, -0.0132,  ..., -0.0220, -0.0148, -0.0047],
        ...,
        [ 0.0135, -0.0146,  0.0236,  ...,  0.0088,  0.0398, -0.0270],
        [ 0.0145, -0.0150,  0.0150,  ...,  0.0079,  0.0122, -0.0118],
        [ 0.0247,  0.0178,  0.0258,  ...,  0.0083,  0.0048, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8135, -2.3477, -1.0693,  ..., -2.7461, -3.5859,  1.3896]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:07:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The croissant falls into the category of pastry
The diary falls into the category of journal
The plum falls into the category of fruit
The cake falls into the category of dessert
The cup falls into the category of tableware
The computer falls into the category of device
The sofa falls into the category of furniture
The toothbrush falls into the category of
2024-07-31 18:07:08 root INFO     [order_1_approx] starting weight calculation for The croissant falls into the category of pastry
The diary falls into the category of journal
The sofa falls into the category of furniture
The plum falls into the category of fruit
The toothbrush falls into the category of brush
The cake falls into the category of dessert
The cup falls into the category of tableware
The computer falls into the category of
2024-07-31 18:07:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:10:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0903, -0.1366,  0.0632,  ...,  0.0898,  0.0599, -0.0790],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4707, -4.1250, -0.5508,  ..., -0.6162, -2.6562, -0.8184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0060,  0.0008, -0.0290,  ...,  0.0097, -0.0120,  0.0143],
        [ 0.0043,  0.0195,  0.0054,  ..., -0.0181,  0.0175, -0.0130],
        [-0.0070, -0.0159, -0.0139,  ...,  0.0020, -0.0220,  0.0189],
        ...,
        [ 0.0060, -0.0017,  0.0029,  ...,  0.0036,  0.0099, -0.0021],
        [ 0.0036, -0.0174, -0.0113,  ...,  0.0139,  0.0028,  0.0069],
        [ 0.0002,  0.0011,  0.0178,  ..., -0.0021,  0.0262, -0.0187]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6602, -4.3828, -0.5464,  ..., -0.6514, -2.6250, -0.9160]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:10:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The croissant falls into the category of pastry
The diary falls into the category of journal
The sofa falls into the category of furniture
The plum falls into the category of fruit
The toothbrush falls into the category of brush
The cake falls into the category of dessert
The cup falls into the category of tableware
The computer falls into the category of
2024-07-31 18:10:04 root INFO     [order_1_approx] starting weight calculation for The plum falls into the category of fruit
The sofa falls into the category of furniture
The croissant falls into the category of pastry
The toothbrush falls into the category of brush
The cup falls into the category of tableware
The diary falls into the category of journal
The computer falls into the category of device
The cake falls into the category of
2024-07-31 18:10:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:13:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0291,  0.1007,  0.0675,  ...,  0.0945, -0.1990, -0.0354],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5410, -6.9922, -1.2236,  ..., -3.3145, -4.4219,  1.9531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.1130,  0.0371, -0.0505,  ..., -0.0618,  0.1247, -0.0194],
        [ 0.0905, -0.0066,  0.0225,  ...,  0.0111, -0.1531,  0.0266],
        [-0.0465, -0.0131,  0.0075,  ..., -0.0284,  0.0320,  0.0109],
        ...,
        [ 0.1114, -0.0427,  0.0044,  ...,  0.0614, -0.1122,  0.0122],
        [-0.0317, -0.0040, -0.0162,  ..., -0.0190,  0.0466,  0.0093],
        [ 0.0280,  0.0027,  0.0095,  ...,  0.0115,  0.0026,  0.0093]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6045, -5.2734, -1.8203,  ..., -1.9424, -4.8867,  2.1348]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:13:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plum falls into the category of fruit
The sofa falls into the category of furniture
The croissant falls into the category of pastry
The toothbrush falls into the category of brush
The cup falls into the category of tableware
The diary falls into the category of journal
The computer falls into the category of device
The cake falls into the category of
2024-07-31 18:13:01 root INFO     [order_1_approx] starting weight calculation for The toothbrush falls into the category of brush
The diary falls into the category of journal
The cake falls into the category of dessert
The computer falls into the category of device
The cup falls into the category of tableware
The croissant falls into the category of pastry
The sofa falls into the category of furniture
The plum falls into the category of
2024-07-31 18:13:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:15:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1313, -0.1877, -0.3218,  ...,  0.1859,  0.0207, -0.1263],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8340, -5.9570,  1.1777,  ..., -2.5762, -0.1289, -0.9019],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.4474e-02, -1.2428e-02, -1.0815e-01,  ...,  3.6438e-02,
          1.0506e-02,  1.9104e-02],
        [-1.4847e-02, -8.3740e-02,  2.2974e-01,  ..., -7.3303e-02,
         -8.3069e-02, -6.9397e-02],
        [-2.1744e-04,  3.3203e-02, -1.3611e-01,  ...,  4.3060e-02,
         -2.9488e-03,  2.8168e-02],
        ...,
        [ 4.8462e-02, -1.1743e-01,  1.6626e-01,  ..., -1.9119e-02,
         -3.3691e-02, -3.1494e-02],
        [ 4.6387e-03,  5.5908e-02, -1.5491e-01,  ...,  5.0262e-02,
          7.4768e-02,  2.6199e-02],
        [-1.8417e-02, -1.4023e-02,  1.6919e-01,  ..., -7.1472e-02,
         -5.0842e-02, -2.2278e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3237, -4.4297,  0.1416,  ..., -1.3691, -1.0312,  0.5269]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:15:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The toothbrush falls into the category of brush
The diary falls into the category of journal
The cake falls into the category of dessert
The computer falls into the category of device
The cup falls into the category of tableware
The croissant falls into the category of pastry
The sofa falls into the category of furniture
The plum falls into the category of
2024-07-31 18:15:56 root INFO     [order_1_approx] starting weight calculation for The croissant falls into the category of pastry
The toothbrush falls into the category of brush
The cup falls into the category of tableware
The diary falls into the category of journal
The plum falls into the category of fruit
The cake falls into the category of dessert
The computer falls into the category of device
The sofa falls into the category of
2024-07-31 18:15:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:18:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1282, -0.0905,  0.0377,  ...,  0.2318, -0.0739, -0.0752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.5137, -5.8203,  2.6758,  ..., -1.8418, -3.0293,  0.8633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234, -0.0287, -0.0192,  ...,  0.0188, -0.0165,  0.0052],
        [-0.0130, -0.0019,  0.0097,  ..., -0.0126,  0.0110,  0.0106],
        [-0.0219, -0.0041, -0.0098,  ..., -0.0052, -0.0255,  0.0132],
        ...,
        [ 0.0057, -0.0101, -0.0010,  ...,  0.0211,  0.0083, -0.0039],
        [-0.0037, -0.0308, -0.0058,  ...,  0.0157,  0.0155, -0.0325],
        [ 0.0088,  0.0204, -0.0010,  ..., -0.0204,  0.0061,  0.0033]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.1191, -5.8711,  2.3691,  ..., -1.9609, -2.6406,  0.9126]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:18:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The croissant falls into the category of pastry
The toothbrush falls into the category of brush
The cup falls into the category of tableware
The diary falls into the category of journal
The plum falls into the category of fruit
The cake falls into the category of dessert
The computer falls into the category of device
The sofa falls into the category of
2024-07-31 18:18:52 root INFO     [order_1_approx] starting weight calculation for The plum falls into the category of fruit
The cake falls into the category of dessert
The computer falls into the category of device
The diary falls into the category of journal
The sofa falls into the category of furniture
The cup falls into the category of tableware
The toothbrush falls into the category of brush
The croissant falls into the category of
2024-07-31 18:18:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:21:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0834,  0.0967, -0.1628,  ...,  0.0064, -0.0294, -0.0485],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6475, -5.1719, -1.5762,  ..., -1.1924, -3.6621,  1.8682],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0243,  0.0366, -0.0718,  ..., -0.0138, -0.0340, -0.0031],
        [ 0.0980, -0.0327, -0.0095,  ...,  0.0138,  0.0204,  0.0279],
        [-0.0543, -0.0345,  0.0422,  ..., -0.0073, -0.0346, -0.0377],
        ...,
        [ 0.0153,  0.0220,  0.0099,  ...,  0.0555, -0.0223,  0.0288],
        [ 0.0018, -0.0200,  0.0083,  ..., -0.0031,  0.0373, -0.0045],
        [ 0.0447,  0.0057, -0.0061,  ..., -0.0033, -0.0042,  0.0138]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0137, -4.0703, -2.0605,  ..., -1.3945, -3.2480,  2.0312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:21:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plum falls into the category of fruit
The cake falls into the category of dessert
The computer falls into the category of device
The diary falls into the category of journal
The sofa falls into the category of furniture
The cup falls into the category of tableware
The toothbrush falls into the category of brush
The croissant falls into the category of
2024-07-31 18:21:46 root INFO     total operator prediction time: 1414.452898979187 seconds
2024-07-31 18:21:46 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - substance
2024-07-31 18:21:46 root INFO     building operator meronyms - substance
2024-07-31 18:21:46 root INFO     [order_1_approx] starting weight calculation for A wig is made up of hair
A yogurt is made up of milk
A spoon is made up of aluminium
A body is made up of flesh
A wall is made up of cement
A flag is made up of fabric
A bottle is made up of glass
A cloud is made up of
2024-07-31 18:21:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:24:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1114,  0.1344,  0.0167,  ..., -0.0861, -0.0601, -0.1677],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9277, -0.8237,  1.7676,  ..., -2.9277,  2.0547, -1.1211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.7618e-03,  1.3618e-02,  1.1917e-02,  ...,  2.3804e-03,
          1.0315e-02,  1.9394e-02],
        [-4.2572e-03,  2.5085e-02, -1.3962e-02,  ...,  2.6657e-02,
         -2.2869e-03, -4.9896e-03],
        [-3.6011e-03, -7.1335e-03,  5.9509e-03,  ...,  1.2901e-02,
         -1.0925e-02, -1.6663e-02],
        ...,
        [ 2.2141e-02, -2.5909e-02, -8.0643e-03,  ...,  7.9193e-03,
         -4.9591e-05, -3.2921e-03],
        [-1.9714e-02,  1.1574e-02,  1.2207e-03,  ...,  1.6479e-02,
         -8.6060e-03,  5.3253e-03],
        [ 2.5864e-03, -2.2552e-02,  4.0527e-02,  ...,  3.2272e-03,
         -1.8112e-02,  1.3313e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8242, -1.0127,  1.8486,  ..., -2.8242,  1.7705, -1.1318]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:24:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wig is made up of hair
A yogurt is made up of milk
A spoon is made up of aluminium
A body is made up of flesh
A wall is made up of cement
A flag is made up of fabric
A bottle is made up of glass
A cloud is made up of
2024-07-31 18:24:48 root INFO     [order_1_approx] starting weight calculation for A body is made up of flesh
A cloud is made up of vapor
A wall is made up of cement
A spoon is made up of aluminium
A bottle is made up of glass
A wig is made up of hair
A flag is made up of fabric
A yogurt is made up of
2024-07-31 18:24:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:27:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0501, -0.0504, -0.0834,  ...,  0.2913, -0.0826, -0.0878],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9668, -3.4062,  2.3750,  ..., -3.7910, -1.2637, -0.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0032,  0.0063, -0.0039,  ...,  0.0280,  0.0075,  0.0069],
        [-0.0463,  0.0247, -0.0145,  ...,  0.0029,  0.0167,  0.0197],
        [-0.0002,  0.0121,  0.0025,  ...,  0.0212,  0.0272,  0.0213],
        ...,
        [ 0.0156, -0.0128,  0.0068,  ...,  0.0124,  0.0119, -0.0217],
        [-0.0562,  0.0325, -0.0168,  ...,  0.0340,  0.0323,  0.0297],
        [ 0.0244, -0.0174,  0.0244,  ...,  0.0150,  0.0211,  0.0104]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8203, -3.8965,  2.4023,  ..., -3.3535, -1.5420, -0.5620]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:27:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A body is made up of flesh
A cloud is made up of vapor
A wall is made up of cement
A spoon is made up of aluminium
A bottle is made up of glass
A wig is made up of hair
A flag is made up of fabric
A yogurt is made up of
2024-07-31 18:27:46 root INFO     [order_1_approx] starting weight calculation for A flag is made up of fabric
A wall is made up of cement
A bottle is made up of glass
A body is made up of flesh
A spoon is made up of aluminium
A yogurt is made up of milk
A cloud is made up of vapor
A wig is made up of
2024-07-31 18:27:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:30:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0656,  0.2007, -0.0096,  ...,  0.0649,  0.1909, -0.1541],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7480, -7.6172, -1.6758,  ..., -1.1895, -1.5312,  0.1543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0432, -0.0222, -0.0837,  ...,  0.0651, -0.0013,  0.0398],
        [-0.0110,  0.0120,  0.0236,  ...,  0.0049, -0.0153, -0.0221],
        [-0.0319, -0.0109,  0.0400,  ..., -0.0167, -0.0139, -0.0166],
        ...,
        [ 0.0467,  0.0077, -0.0228,  ...,  0.0329, -0.0020,  0.0151],
        [ 0.0288,  0.0220,  0.0068,  ...,  0.0056,  0.0055, -0.0251],
        [-0.0333, -0.0113,  0.0198,  ..., -0.0380,  0.0074, -0.0091]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3516, -7.1250, -1.3926,  ..., -1.6865, -1.6133,  0.7764]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:30:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flag is made up of fabric
A wall is made up of cement
A bottle is made up of glass
A body is made up of flesh
A spoon is made up of aluminium
A yogurt is made up of milk
A cloud is made up of vapor
A wig is made up of
2024-07-31 18:30:45 root INFO     [order_1_approx] starting weight calculation for A yogurt is made up of milk
A bottle is made up of glass
A cloud is made up of vapor
A body is made up of flesh
A wall is made up of cement
A wig is made up of hair
A flag is made up of fabric
A spoon is made up of
2024-07-31 18:30:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:33:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0736, -0.0587, -0.0403,  ..., -0.0176,  0.0079, -0.0199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1680, -1.6777, -2.4941,  ..., -2.0195, -1.0811, -0.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0047,  0.0127, -0.0010,  ...,  0.0192,  0.0054, -0.0205],
        [-0.0182,  0.0681, -0.0367,  ..., -0.0219,  0.0011, -0.0095],
        [-0.0435,  0.0122,  0.0062,  ...,  0.0319, -0.0259, -0.0111],
        ...,
        [-0.0012, -0.0051, -0.0166,  ...,  0.0118,  0.0409, -0.0260],
        [-0.0097, -0.0101,  0.0033,  ...,  0.0313,  0.0241, -0.0170],
        [-0.0032,  0.0092,  0.0214,  ...,  0.0204, -0.0033, -0.0224]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8438, -1.2900, -2.1914,  ..., -1.8252, -1.2871, -0.8110]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:33:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A yogurt is made up of milk
A bottle is made up of glass
A cloud is made up of vapor
A body is made up of flesh
A wall is made up of cement
A wig is made up of hair
A flag is made up of fabric
A spoon is made up of
2024-07-31 18:33:43 root INFO     [order_1_approx] starting weight calculation for A yogurt is made up of milk
A body is made up of flesh
A bottle is made up of glass
A cloud is made up of vapor
A flag is made up of fabric
A spoon is made up of aluminium
A wig is made up of hair
A wall is made up of
2024-07-31 18:33:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:36:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0563,  0.0663,  0.1193,  ...,  0.0364, -0.0807, -0.0794],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3164, -8.2031,  0.9746,  ..., -0.6357, -0.8496,  0.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0023,  0.0433, -0.0482,  ..., -0.0445,  0.0414,  0.0225],
        [-0.0033, -0.0285,  0.0449,  ...,  0.0380, -0.0438, -0.0042],
        [-0.0187, -0.0140, -0.0055,  ..., -0.0045,  0.0013, -0.0110],
        ...,
        [ 0.0262, -0.0216,  0.0257,  ...,  0.0242, -0.0212,  0.0020],
        [ 0.0092,  0.0190, -0.0230,  ..., -0.0121, -0.0023,  0.0039],
        [-0.0056, -0.0139,  0.0386,  ...,  0.0023,  0.0049, -0.0032]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9102, -7.0391,  0.9302,  ..., -0.3586, -0.9932,  0.5898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:36:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A yogurt is made up of milk
A body is made up of flesh
A bottle is made up of glass
A cloud is made up of vapor
A flag is made up of fabric
A spoon is made up of aluminium
A wig is made up of hair
A wall is made up of
2024-07-31 18:36:43 root INFO     [order_1_approx] starting weight calculation for A flag is made up of fabric
A bottle is made up of glass
A cloud is made up of vapor
A wig is made up of hair
A wall is made up of cement
A spoon is made up of aluminium
A yogurt is made up of milk
A body is made up of
2024-07-31 18:36:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:39:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0431,  0.1410, -0.0213,  ..., -0.0607, -0.1188, -0.1460],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0781, -6.8828,  3.0977,  ..., -3.3809, -3.6660, -0.0532],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0384e-02, -3.2597e-03, -1.5717e-03,  ...,  3.4180e-03,
         -1.6510e-02,  7.6294e-04],
        [-8.4991e-03, -1.1353e-02,  6.9427e-03,  ...,  1.0895e-02,
          9.2697e-03, -2.6581e-02],
        [-1.7380e-02,  2.4109e-02, -8.3923e-05,  ..., -2.4338e-03,
         -2.8046e-02, -1.9653e-02],
        ...,
        [-1.1124e-02, -9.5215e-03, -6.8893e-03,  ...,  3.6011e-02,
          1.4206e-02, -3.2593e-02],
        [ 1.0376e-03,  1.6670e-03,  2.0885e-03,  ..., -1.0147e-02,
          2.9392e-03,  4.2725e-04],
        [-1.8311e-04,  1.4282e-02,  2.3285e-02,  ...,  8.7662e-03,
         -1.1320e-03,  3.1128e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0352, -6.4492,  2.7363,  ..., -3.6016, -4.0625, -0.0907]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:39:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A flag is made up of fabric
A bottle is made up of glass
A cloud is made up of vapor
A wig is made up of hair
A wall is made up of cement
A spoon is made up of aluminium
A yogurt is made up of milk
A body is made up of
2024-07-31 18:39:40 root INFO     [order_1_approx] starting weight calculation for A wig is made up of hair
A yogurt is made up of milk
A wall is made up of cement
A body is made up of flesh
A cloud is made up of vapor
A bottle is made up of glass
A spoon is made up of aluminium
A flag is made up of
2024-07-31 18:39:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:42:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0105,  0.1602, -0.2676,  ..., -0.0045, -0.0728, -0.3032],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4531, -7.6562,  2.4141,  ..., -1.5117, -0.8179, -1.0576],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0019,  0.0837,  0.0637,  ...,  0.0486, -0.0189,  0.0672],
        [-0.0176, -0.0345, -0.0752,  ..., -0.0320,  0.0120, -0.0187],
        [ 0.0025,  0.0366,  0.0321,  ...,  0.0288, -0.0217, -0.0083],
        ...,
        [ 0.0173, -0.0127, -0.0296,  ...,  0.0073,  0.0002, -0.0376],
        [-0.0013,  0.0018, -0.0066,  ..., -0.0123,  0.0155,  0.0121],
        [ 0.0012, -0.0529, -0.0309,  ..., -0.0591,  0.0302,  0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3301, -6.3477,  1.7441,  ..., -1.3682, -1.0107,  0.2314]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:42:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A wig is made up of hair
A yogurt is made up of milk
A wall is made up of cement
A body is made up of flesh
A cloud is made up of vapor
A bottle is made up of glass
A spoon is made up of aluminium
A flag is made up of
2024-07-31 18:42:36 root INFO     [order_1_approx] starting weight calculation for A body is made up of flesh
A wall is made up of cement
A wig is made up of hair
A yogurt is made up of milk
A flag is made up of fabric
A cloud is made up of vapor
A spoon is made up of aluminium
A bottle is made up of
2024-07-31 18:42:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:45:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0248,  0.1097, -0.0713,  ..., -0.0125,  0.0707,  0.0500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4922, -7.4570,  1.1309,  ..., -1.8711,  0.7959,  0.4980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0074,  0.0014, -0.0051,  ...,  0.0053, -0.0070,  0.0042],
        [-0.0056,  0.0110, -0.0040,  ...,  0.0071, -0.0112, -0.0032],
        [-0.0081, -0.0021,  0.0056,  ...,  0.0099, -0.0027, -0.0034],
        ...,
        [ 0.0190,  0.0055,  0.0042,  ...,  0.0242, -0.0075,  0.0018],
        [ 0.0150, -0.0059,  0.0058,  ...,  0.0133,  0.0138, -0.0060],
        [ 0.0076,  0.0124,  0.0092,  ...,  0.0089, -0.0186,  0.0128]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3203, -7.5898,  1.1816,  ..., -1.9570,  0.7651,  0.3057]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:45:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A body is made up of flesh
A wall is made up of cement
A wig is made up of hair
A yogurt is made up of milk
A flag is made up of fabric
A cloud is made up of vapor
A spoon is made up of aluminium
A bottle is made up of
2024-07-31 18:45:34 root INFO     total operator prediction time: 1428.0661034584045 seconds
2024-07-31 18:45:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - intensity
2024-07-31 18:45:34 root INFO     building operator synonyms - intensity
2024-07-31 18:45:34 root INFO     [order_1_approx] starting weight calculation for A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for love is adore
A more intense word for unfortunate is tragic
A more intense word for ask is beg
A more intense word for tired is exhausted
A more intense word for cry is scream
A more intense word for boring is
2024-07-31 18:45:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:48:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0570,  0.0268,  0.0171,  ..., -0.0160,  0.0200,  0.0316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6914, -1.9121,  4.4766,  ..., -2.9023, -4.8555, -1.1631],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0462, -0.0106,  0.0151,  ...,  0.0174, -0.0065,  0.0469],
        [-0.0403,  0.0791,  0.0173,  ..., -0.0078, -0.0195, -0.0252],
        [-0.0079, -0.0010,  0.0084,  ...,  0.0020,  0.0058,  0.0047],
        ...,
        [ 0.0081,  0.0351,  0.0614,  ..., -0.0127, -0.0417, -0.0149],
        [ 0.0388, -0.0202,  0.0346,  ..., -0.0227, -0.0252, -0.0071],
        [ 0.0191,  0.0156,  0.0218,  ...,  0.0095, -0.0205,  0.0055]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7070, -2.0625,  4.5000,  ..., -2.3711, -4.3438, -1.1299]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:48:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for love is adore
A more intense word for unfortunate is tragic
A more intense word for ask is beg
A more intense word for tired is exhausted
A more intense word for cry is scream
A more intense word for boring is
2024-07-31 18:48:31 root INFO     [order_1_approx] starting weight calculation for A more intense word for guilty is remorseful
A more intense word for cry is scream
A more intense word for boring is tedious
A more intense word for ask is beg
A more intense word for unfortunate is tragic
A more intense word for love is adore
A more intense word for tired is exhausted
A more intense word for sad is
2024-07-31 18:48:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:51:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0191, -0.0726, -0.1399,  ...,  0.0704, -0.2603,  0.1310],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7988, -3.3320,  2.5605,  ..., -0.9146, -0.7070, -1.8965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.9182e-05,  4.8103e-03, -1.6235e-02,  ...,  2.6428e-02,
          2.0218e-02,  6.7902e-03],
        [-2.6077e-02,  1.3626e-02,  4.0627e-03,  ..., -1.2733e-02,
          1.2619e-02, -8.3160e-03],
        [-2.2186e-02, -1.5976e-02, -4.5776e-05,  ..., -1.2314e-02,
         -9.8190e-03,  2.5082e-04],
        ...,
        [-1.4603e-02,  1.3405e-02, -7.8735e-03,  ..., -1.2238e-02,
          8.4610e-03, -5.4054e-03],
        [-2.1652e-02, -3.1738e-02, -1.0233e-03,  ..., -2.6932e-02,
          2.3537e-03, -8.6517e-03],
        [-2.5330e-02, -1.3954e-02, -2.2598e-02,  ..., -1.5884e-02,
          7.1983e-03,  1.0567e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5938, -2.8457,  3.0156,  ..., -0.7676, -0.1860, -1.8682]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:51:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for guilty is remorseful
A more intense word for cry is scream
A more intense word for boring is tedious
A more intense word for ask is beg
A more intense word for unfortunate is tragic
A more intense word for love is adore
A more intense word for tired is exhausted
A more intense word for sad is
2024-07-31 18:51:28 root INFO     [order_1_approx] starting weight calculation for A more intense word for ask is beg
A more intense word for tired is exhausted
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for love is adore
A more intense word for unfortunate is tragic
A more intense word for sad is desparate
A more intense word for cry is
2024-07-31 18:51:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:54:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0434, -0.1296, -0.1761,  ..., -0.1219, -0.3567,  0.1733],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.1562, -5.5938,  1.6299,  ...,  1.0430, -0.4629,  0.2979],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0226, -0.0349, -0.0143,  ...,  0.0276, -0.0152, -0.0137],
        [ 0.0020,  0.0276,  0.0035,  ..., -0.0302,  0.0501, -0.0069],
        [ 0.0118, -0.0205, -0.0133,  ...,  0.0651, -0.0444, -0.0149],
        ...,
        [ 0.0128,  0.0160,  0.0059,  ..., -0.0398,  0.0471, -0.0119],
        [ 0.0534,  0.0490, -0.0102,  ...,  0.0371, -0.0381,  0.0290],
        [ 0.0104,  0.0046, -0.0183,  ..., -0.0042,  0.0157,  0.0247]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.3008, -5.4844,  1.4990,  ...,  0.8945, -0.9814,  0.0981]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:54:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for ask is beg
A more intense word for tired is exhausted
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for love is adore
A more intense word for unfortunate is tragic
A more intense word for sad is desparate
A more intense word for cry is
2024-07-31 18:54:26 root INFO     [order_1_approx] starting weight calculation for A more intense word for ask is beg
A more intense word for cry is scream
A more intense word for tired is exhausted
A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for love is adore
A more intense word for unfortunate is
2024-07-31 18:54:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 18:57:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0035,  0.0925, -0.0795,  ..., -0.0754, -0.1848, -0.3389],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.0039, -2.4961,  2.0820,  ..., -0.4551,  0.0557, -3.3477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0208,  0.0223,  0.0317,  ..., -0.0059,  0.0180, -0.0116],
        [-0.0439,  0.0085,  0.0317,  ...,  0.0231, -0.0037,  0.0127],
        [-0.0002,  0.0020, -0.0036,  ...,  0.0173,  0.0159,  0.0166],
        ...,
        [ 0.0221,  0.0373, -0.0109,  ..., -0.0018, -0.0159, -0.0420],
        [ 0.0042, -0.0217, -0.0244,  ...,  0.0246,  0.0131,  0.0226],
        [ 0.0130, -0.0358, -0.0276,  ...,  0.0112, -0.0726,  0.0137]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2578, -1.8867,  2.4043,  ..., -0.8208,  0.5127, -4.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 18:57:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for ask is beg
A more intense word for cry is scream
A more intense word for tired is exhausted
A more intense word for sad is desparate
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for love is adore
A more intense word for unfortunate is
2024-07-31 18:57:24 root INFO     [order_1_approx] starting weight calculation for A more intense word for unfortunate is tragic
A more intense word for tired is exhausted
A more intense word for cry is scream
A more intense word for ask is beg
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for sad is desparate
A more intense word for love is
2024-07-31 18:57:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:00:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0490,  0.0245, -0.0518,  ...,  0.0713, -0.0243,  0.0980],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1406, -5.0859, -1.7910,  ...,  0.0330, -4.7891,  0.3975],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0022, -0.0001,  0.0057,  ...,  0.0172, -0.0210,  0.0132],
        [-0.0113,  0.0114,  0.0074,  ...,  0.0058, -0.0064, -0.0093],
        [-0.0075, -0.0025, -0.0017,  ..., -0.0115, -0.0118, -0.0026],
        ...,
        [ 0.0201,  0.0045,  0.0029,  ...,  0.0086,  0.0076, -0.0214],
        [ 0.0007, -0.0055, -0.0037,  ..., -0.0080,  0.0088,  0.0210],
        [-0.0039, -0.0015, -0.0016,  ..., -0.0043, -0.0014, -0.0137]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8398, -4.9180, -1.1289,  ..., -0.2605, -4.4531,  0.6406]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:00:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for unfortunate is tragic
A more intense word for tired is exhausted
A more intense word for cry is scream
A more intense word for ask is beg
A more intense word for guilty is remorseful
A more intense word for boring is tedious
A more intense word for sad is desparate
A more intense word for love is
2024-07-31 19:00:21 root INFO     [order_1_approx] starting weight calculation for A more intense word for ask is beg
A more intense word for boring is tedious
A more intense word for tired is exhausted
A more intense word for sad is desparate
A more intense word for unfortunate is tragic
A more intense word for cry is scream
A more intense word for love is adore
A more intense word for guilty is
2024-07-31 19:00:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:03:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0463,  0.0111, -0.0947,  ...,  0.0668, -0.0942,  0.1299],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5205, -3.3984,  1.2344,  ..., -1.8408, -2.1406,  0.7256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0092,  0.0116, -0.0078,  ..., -0.0194, -0.0258,  0.0088],
        [-0.0175,  0.0227, -0.0027,  ..., -0.0080, -0.0112, -0.0281],
        [ 0.0173,  0.0120,  0.0135,  ...,  0.0200,  0.0120,  0.0072],
        ...,
        [-0.0087,  0.0059,  0.0066,  ..., -0.0101,  0.0136, -0.0164],
        [ 0.0099, -0.0038,  0.0176,  ..., -0.0129,  0.0231,  0.0097],
        [-0.0242,  0.0075, -0.0217,  ...,  0.0078, -0.0270,  0.0083]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2734, -2.7070,  1.4150,  ..., -1.3213, -1.7764,  0.6128]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:03:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for ask is beg
A more intense word for boring is tedious
A more intense word for tired is exhausted
A more intense word for sad is desparate
A more intense word for unfortunate is tragic
A more intense word for cry is scream
A more intense word for love is adore
A more intense word for guilty is
2024-07-31 19:03:18 root INFO     [order_1_approx] starting weight calculation for A more intense word for ask is beg
A more intense word for unfortunate is tragic
A more intense word for cry is scream
A more intense word for guilty is remorseful
A more intense word for sad is desparate
A more intense word for love is adore
A more intense word for boring is tedious
A more intense word for tired is
2024-07-31 19:03:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:06:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1146, -0.2769, -0.1025,  ...,  0.2189,  0.0119,  0.1476],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0469, -6.7500,  3.3066,  ..., -2.7656, -0.7090,  0.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0215,  0.0086,  0.0399,  ..., -0.0041,  0.0456, -0.0013],
        [-0.0199,  0.0148,  0.0033,  ..., -0.0240,  0.0225, -0.0211],
        [-0.0724,  0.0051,  0.0265,  ..., -0.0037,  0.0118, -0.0008],
        ...,
        [-0.0366, -0.0349,  0.0284,  ...,  0.0007,  0.0310, -0.0192],
        [-0.0189,  0.0211,  0.0048,  ..., -0.0014,  0.0138, -0.0013],
        [-0.0219, -0.0003,  0.0026,  ...,  0.0044,  0.0020,  0.0071]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2109, -5.3828,  3.4609,  ..., -1.3975, -0.1519, -0.0453]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:06:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for ask is beg
A more intense word for unfortunate is tragic
A more intense word for cry is scream
A more intense word for guilty is remorseful
A more intense word for sad is desparate
A more intense word for love is adore
A more intense word for boring is tedious
A more intense word for tired is
2024-07-31 19:06:17 root INFO     [order_1_approx] starting weight calculation for A more intense word for boring is tedious
A more intense word for cry is scream
A more intense word for love is adore
A more intense word for sad is desparate
A more intense word for tired is exhausted
A more intense word for unfortunate is tragic
A more intense word for guilty is remorseful
A more intense word for ask is
2024-07-31 19:06:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:09:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0537, -0.1176, -0.2178,  ..., -0.0249, -0.1519, -0.0656],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4043, -6.5000,  0.2104,  ..., -0.9434, -3.5234, -2.9277],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.9501e-02, -4.9011e-02,  2.0721e-02,  ...,  3.6469e-02,
         -4.7546e-02,  3.6194e-02],
        [-2.9663e-02,  1.9089e-02, -2.0859e-02,  ..., -5.9090e-03,
         -2.9297e-02,  1.5411e-02],
        [-3.1616e-02, -2.2125e-02,  2.5024e-03,  ...,  6.0439e-05,
          2.4460e-02, -3.9253e-03],
        ...,
        [ 2.4460e-02,  1.7624e-02,  9.7656e-04,  ...,  2.3560e-02,
          8.4209e-04, -2.4048e-02],
        [ 1.6907e-02,  7.9193e-03,  9.2316e-03,  ..., -3.5034e-02,
          3.2310e-03,  2.1606e-02],
        [-2.4490e-03, -1.0834e-02, -1.2367e-02,  ..., -2.1027e-02,
         -2.0264e-02,  3.1708e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7520, -6.0938,  0.6050,  ..., -0.8052, -3.1074, -2.2559]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:09:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more intense word for boring is tedious
A more intense word for cry is scream
A more intense word for love is adore
A more intense word for sad is desparate
A more intense word for tired is exhausted
A more intense word for unfortunate is tragic
A more intense word for guilty is remorseful
A more intense word for ask is
2024-07-31 19:09:16 root INFO     total operator prediction time: 1422.2445816993713 seconds
2024-07-31 19:09:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hypernyms - animals
2024-07-31 19:09:16 root INFO     building operator hypernyms - animals
2024-07-31 19:09:16 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The quail falls into the category of fowl
The human falls into the category of primate
The jaguar falls into the category of feline
The jackal falls into the category of canine
The mamba falls into the category of snake
The buffalo falls into the category of bovid
The coyote falls into the category of
2024-07-31 19:09:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:12:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1704,  0.0043, -0.2568,  ..., -0.0524,  0.1052,  0.0991],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6470, -4.7500,  1.5322,  ..., -3.9355, -5.8750,  0.5928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0697, -0.0340,  0.0282,  ..., -0.0232, -0.0286, -0.0172],
        [ 0.0481, -0.0528,  0.0776,  ...,  0.0383, -0.0540,  0.0044],
        [-0.0370,  0.0202, -0.0158,  ..., -0.0221,  0.0312,  0.0127],
        ...,
        [ 0.0024, -0.0070,  0.0308,  ...,  0.0049, -0.0015,  0.0025],
        [-0.0618,  0.0532, -0.0689,  ..., -0.0045,  0.0540,  0.0111],
        [ 0.0474,  0.0017,  0.0439,  ...,  0.0161, -0.0398, -0.0035]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1138, -3.9258,  0.9668,  ..., -3.2031, -6.9883,  1.4238]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:12:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The butterfly falls into the category of insect
The quail falls into the category of fowl
The human falls into the category of primate
The jaguar falls into the category of feline
The jackal falls into the category of canine
The mamba falls into the category of snake
The buffalo falls into the category of bovid
The coyote falls into the category of
2024-07-31 19:12:16 root INFO     [order_1_approx] starting weight calculation for The human falls into the category of primate
The quail falls into the category of fowl
The butterfly falls into the category of insect
The mamba falls into the category of snake
The jackal falls into the category of canine
The jaguar falls into the category of feline
The coyote falls into the category of canine
The buffalo falls into the category of
2024-07-31 19:12:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:15:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1560, -0.0712,  0.1033,  ..., -0.0336, -0.0908, -0.0047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4102, -6.6641,  3.1855,  ..., -0.5713, -8.4297, -0.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0739, -0.0184,  0.0027,  ...,  0.0132, -0.0449,  0.0204],
        [ 0.0208, -0.0236,  0.0146,  ...,  0.0043, -0.0372,  0.0046],
        [-0.0566, -0.0219,  0.0372,  ...,  0.0339, -0.0230, -0.0106],
        ...,
        [-0.0032, -0.0204,  0.0017,  ...,  0.0102, -0.0035, -0.0065],
        [-0.0443, -0.0040,  0.0115,  ...,  0.0010,  0.0422,  0.0008],
        [ 0.0035, -0.0065,  0.0133,  ..., -0.0515,  0.0127,  0.0312]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9180, -5.9023,  2.8379,  ..., -0.1636, -8.7422,  0.0215]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:15:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The human falls into the category of primate
The quail falls into the category of fowl
The butterfly falls into the category of insect
The mamba falls into the category of snake
The jackal falls into the category of canine
The jaguar falls into the category of feline
The coyote falls into the category of canine
The buffalo falls into the category of
2024-07-31 19:15:17 root INFO     [order_1_approx] starting weight calculation for The quail falls into the category of fowl
The coyote falls into the category of canine
The butterfly falls into the category of insect
The buffalo falls into the category of bovid
The jaguar falls into the category of feline
The human falls into the category of primate
The jackal falls into the category of canine
The mamba falls into the category of
2024-07-31 19:15:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:18:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0875, -0.0843,  0.0581,  ...,  0.0958, -0.2727, -0.1054],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7695, -4.0039,  2.6875,  ..., -0.3438, -4.2930, -0.8853],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0975, -0.0313,  0.0656,  ..., -0.0224, -0.0366, -0.0152],
        [-0.0833,  0.0556, -0.0295,  ...,  0.0887,  0.0193,  0.0503],
        [-0.0515, -0.0055,  0.0409,  ..., -0.0234, -0.1087, -0.0123],
        ...,
        [-0.0880,  0.0351, -0.0446,  ...,  0.1329,  0.0544,  0.0465],
        [-0.1998,  0.0634, -0.0917,  ...,  0.0890, -0.0098, -0.0418],
        [ 0.0471,  0.0233,  0.0247,  ..., -0.0329, -0.0147,  0.0487]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0410, -4.6250,  2.8145,  ..., -0.5171, -4.4336, -0.3594]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:18:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The quail falls into the category of fowl
The coyote falls into the category of canine
The butterfly falls into the category of insect
The buffalo falls into the category of bovid
The jaguar falls into the category of feline
The human falls into the category of primate
The jackal falls into the category of canine
The mamba falls into the category of
2024-07-31 19:18:17 root INFO     [order_1_approx] starting weight calculation for The butterfly falls into the category of insect
The human falls into the category of primate
The jaguar falls into the category of feline
The buffalo falls into the category of bovid
The coyote falls into the category of canine
The quail falls into the category of fowl
The mamba falls into the category of snake
The jackal falls into the category of
2024-07-31 19:18:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:21:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1990, -0.0993, -0.0153,  ...,  0.0791, -0.0004, -0.0248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1924, -4.8281,  1.3594,  ..., -3.3965, -6.6953,  2.3125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0923,  0.0104, -0.0114,  ..., -0.0179, -0.0200, -0.0215],
        [ 0.0078, -0.0341,  0.0269,  ..., -0.0091,  0.0847, -0.0037],
        [ 0.0029,  0.0304,  0.0575,  ..., -0.0240, -0.0260,  0.0272],
        ...,
        [-0.0060, -0.0532,  0.0105,  ...,  0.0078,  0.0726, -0.0439],
        [-0.0511,  0.0241, -0.0479,  ...,  0.0223, -0.0170,  0.0763],
        [ 0.0536,  0.0633, -0.0029,  ..., -0.0155,  0.0364,  0.0264]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2183, -3.4844,  1.4580,  ..., -2.3730, -7.7578,  2.6934]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:21:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The butterfly falls into the category of insect
The human falls into the category of primate
The jaguar falls into the category of feline
The buffalo falls into the category of bovid
The coyote falls into the category of canine
The quail falls into the category of fowl
The mamba falls into the category of snake
The jackal falls into the category of
2024-07-31 19:21:16 root INFO     [order_1_approx] starting weight calculation for The buffalo falls into the category of bovid
The coyote falls into the category of canine
The butterfly falls into the category of insect
The quail falls into the category of fowl
The jaguar falls into the category of feline
The mamba falls into the category of snake
The jackal falls into the category of canine
The human falls into the category of
2024-07-31 19:21:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:24:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 3.0518e-05, -1.7871e-01,  7.0312e-02,  ..., -6.4697e-02,
        -7.4890e-02,  2.8534e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6187, -5.7969,  2.9160,  ..., -1.8145, -6.4531, -0.5703],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.8888e-03, -5.4703e-03,  7.1564e-03,  ...,  1.9274e-03,
          2.0809e-03,  1.4557e-02],
        [-5.4474e-03,  1.0818e-02, -1.3451e-02,  ...,  1.7181e-02,
          1.6434e-02, -1.6525e-02],
        [ 1.9897e-02, -3.2158e-03, -1.2886e-02,  ...,  1.1948e-02,
         -1.5244e-02, -1.2794e-02],
        ...,
        [-1.5388e-02,  7.4959e-03,  3.9978e-03,  ..., -1.5354e-03,
         -1.2894e-02,  1.8356e-02],
        [-8.9111e-03,  2.4124e-02, -2.4902e-02,  ...,  6.8054e-03,
          2.4017e-02, -1.6449e-02],
        [-6.8665e-05,  2.9182e-03, -2.1805e-02,  ...,  1.5038e-02,
          4.2114e-03,  1.7891e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4624, -6.5312,  3.1855,  ..., -1.7344, -6.6875, -0.4893]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:24:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The buffalo falls into the category of bovid
The coyote falls into the category of canine
The butterfly falls into the category of insect
The quail falls into the category of fowl
The jaguar falls into the category of feline
The mamba falls into the category of snake
The jackal falls into the category of canine
The human falls into the category of
2024-07-31 19:24:15 root INFO     [order_1_approx] starting weight calculation for The mamba falls into the category of snake
The buffalo falls into the category of bovid
The human falls into the category of primate
The quail falls into the category of fowl
The jaguar falls into the category of feline
The jackal falls into the category of canine
The coyote falls into the category of canine
The butterfly falls into the category of
2024-07-31 19:24:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:27:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0701,  0.0793,  0.0560,  ..., -0.1890,  0.0303, -0.0159],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6592, -3.8320,  3.3281,  ..., -2.6484, -3.2246, -2.2637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0455, -0.0566, -0.0217,  ...,  0.0373,  0.0284, -0.0408],
        [ 0.0609, -0.0848, -0.0126,  ...,  0.0437,  0.0048, -0.0275],
        [-0.0765,  0.0744,  0.0120,  ..., -0.0482, -0.0068,  0.0316],
        ...,
        [-0.0387,  0.0339,  0.0172,  ..., -0.0113, -0.0085,  0.0043],
        [-0.0473,  0.0552,  0.0114,  ..., -0.0105,  0.0107,  0.0025],
        [ 0.0770, -0.1074, -0.0216,  ...,  0.0281,  0.0194, -0.0785]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4570, -2.5586,  2.0996,  ..., -2.9629, -3.7617, -0.3379]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:27:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The mamba falls into the category of snake
The buffalo falls into the category of bovid
The human falls into the category of primate
The quail falls into the category of fowl
The jaguar falls into the category of feline
The jackal falls into the category of canine
The coyote falls into the category of canine
The butterfly falls into the category of
2024-07-31 19:27:15 root INFO     [order_1_approx] starting weight calculation for The jaguar falls into the category of feline
The mamba falls into the category of snake
The butterfly falls into the category of insect
The jackal falls into the category of canine
The coyote falls into the category of canine
The buffalo falls into the category of bovid
The human falls into the category of primate
The quail falls into the category of
2024-07-31 19:27:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:30:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1951, -0.0829, -0.1053,  ..., -0.0352, -0.0423, -0.1561],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1250, -3.4902,  3.8945,  ..., -1.6758, -6.5078, -0.6963],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0707, -0.0717,  0.0019,  ..., -0.0045, -0.0465,  0.0245],
        [ 0.0323, -0.0630,  0.0658,  ..., -0.0450, -0.0755,  0.0178],
        [-0.0277,  0.0529, -0.0114,  ..., -0.0271,  0.0229,  0.0236],
        ...,
        [ 0.0211, -0.0508,  0.0282,  ...,  0.0069, -0.0294, -0.0449],
        [-0.0291,  0.0688, -0.0531,  ...,  0.0578,  0.0851,  0.0450],
        [ 0.0392, -0.0446,  0.0692,  ..., -0.0309, -0.0058,  0.0912]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4688, -2.6094,  3.2852,  ..., -1.2676, -6.8984, -0.3313]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:30:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The jaguar falls into the category of feline
The mamba falls into the category of snake
The butterfly falls into the category of insect
The jackal falls into the category of canine
The coyote falls into the category of canine
The buffalo falls into the category of bovid
The human falls into the category of primate
The quail falls into the category of
2024-07-31 19:30:14 root INFO     [order_1_approx] starting weight calculation for The quail falls into the category of fowl
The buffalo falls into the category of bovid
The coyote falls into the category of canine
The jackal falls into the category of canine
The mamba falls into the category of snake
The human falls into the category of primate
The butterfly falls into the category of insect
The jaguar falls into the category of
2024-07-31 19:30:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:33:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0294,  0.0366, -0.0507,  ..., -0.0298, -0.0237, -0.1622],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0273, -5.5586, -0.9453,  ..., -3.4258, -6.9570, -3.3281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0144, -0.0147,  0.0153,  ..., -0.0047,  0.0097,  0.0090],
        [ 0.0035, -0.0224,  0.0129,  ..., -0.0042, -0.0173,  0.0247],
        [-0.0004,  0.0013, -0.0122,  ..., -0.0256, -0.0012, -0.0039],
        ...,
        [ 0.0044, -0.0066, -0.0002,  ..., -0.0055, -0.0109,  0.0003],
        [ 0.0009,  0.0091, -0.0276,  ...,  0.0175,  0.0288, -0.0022],
        [-0.0121, -0.0226,  0.0313,  ..., -0.0229, -0.0146,  0.0279]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3584, -4.4844, -1.4102,  ..., -3.2344, -7.4688, -2.4492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:33:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The quail falls into the category of fowl
The buffalo falls into the category of bovid
The coyote falls into the category of canine
The jackal falls into the category of canine
The mamba falls into the category of snake
The human falls into the category of primate
The butterfly falls into the category of insect
The jaguar falls into the category of
2024-07-31 19:33:12 root INFO     total operator prediction time: 1435.8518600463867 seconds
2024-07-31 19:33:12 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on hyponyms - misc
2024-07-31 19:33:12 root INFO     building operator hyponyms - misc
2024-07-31 19:33:12 root INFO     [order_1_approx] starting weight calculation for A more specific term for a boat is ferry
A more specific term for a gun is rifle
A more specific term for a church is chapel
A more specific term for a cloud is thundercloud
A more specific term for a candy is lollipop
A more specific term for a backpack is daypack
A more specific term for a song is lullaby
A more specific term for a flask is
2024-07-31 19:33:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:36:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0962, -0.1338, -0.0693,  ..., -0.1548,  0.2058, -0.1182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2402, -3.2969, -0.8877,  ...,  0.0215,  3.0918,  0.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0585,  0.0098, -0.0593,  ...,  0.0872, -0.0051,  0.0225],
        [-0.0501,  0.0018,  0.0214,  ..., -0.0268, -0.0151,  0.0273],
        [ 0.0548, -0.0706,  0.1761,  ...,  0.0734, -0.0779,  0.0288],
        ...,
        [-0.0021, -0.0197,  0.0569,  ..., -0.0058,  0.0066, -0.0515],
        [-0.0634, -0.0328, -0.0230,  ...,  0.0294,  0.1261, -0.0817],
        [ 0.0501,  0.1228, -0.0845,  ...,  0.0272,  0.0710,  0.0898]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2246, -3.8438, -0.9561,  ...,  1.0498,  3.3203, -0.2002]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:36:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a boat is ferry
A more specific term for a gun is rifle
A more specific term for a church is chapel
A more specific term for a cloud is thundercloud
A more specific term for a candy is lollipop
A more specific term for a backpack is daypack
A more specific term for a song is lullaby
A more specific term for a flask is
2024-07-31 19:36:12 root INFO     [order_1_approx] starting weight calculation for A more specific term for a boat is ferry
A more specific term for a cloud is thundercloud
A more specific term for a flask is thermos
A more specific term for a candy is lollipop
A more specific term for a backpack is daypack
A more specific term for a song is lullaby
A more specific term for a gun is rifle
A more specific term for a church is
2024-07-31 19:36:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:39:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0027,  0.0222, -0.0583,  ...,  0.1072, -0.1536,  0.0419],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2168, -6.6953,  3.9668,  ..., -1.9980, -0.4204,  1.2949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0005, -0.0212, -0.0081,  ...,  0.0010, -0.0047, -0.0356],
        [ 0.0001,  0.0096,  0.0013,  ..., -0.0101,  0.0389, -0.0050],
        [ 0.0108,  0.0160,  0.0133,  ..., -0.0179, -0.0173, -0.0137],
        ...,
        [-0.0268, -0.0011,  0.0141,  ..., -0.0007,  0.0137, -0.0087],
        [-0.0016, -0.0060, -0.0041,  ...,  0.0136,  0.0197, -0.0493],
        [ 0.0108,  0.0114, -0.0069,  ...,  0.0139, -0.0062,  0.0171]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2012, -6.5977,  3.9727,  ..., -2.0020, -0.2576,  0.9189]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:39:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a boat is ferry
A more specific term for a cloud is thundercloud
A more specific term for a flask is thermos
A more specific term for a candy is lollipop
A more specific term for a backpack is daypack
A more specific term for a song is lullaby
A more specific term for a gun is rifle
A more specific term for a church is
2024-07-31 19:39:14 root INFO     [order_1_approx] starting weight calculation for A more specific term for a flask is thermos
A more specific term for a song is lullaby
A more specific term for a church is chapel
A more specific term for a backpack is daypack
A more specific term for a boat is ferry
A more specific term for a candy is lollipop
A more specific term for a gun is rifle
A more specific term for a cloud is
2024-07-31 19:39:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:42:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0972,  0.0391,  0.1038,  ..., -0.1050, -0.0779, -0.1338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2705, -3.4414,  4.2305,  ..., -0.4741, -1.0088,  1.4727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.2369e-02, -4.0283e-02,  1.2573e-02,  ..., -3.0426e-02,
         -1.2802e-02,  1.8875e-02],
        [ 2.3575e-02,  3.6438e-02,  2.4734e-02,  ...,  1.3351e-03,
         -1.2398e-05,  3.3112e-03],
        [-6.8665e-05, -2.1072e-02,  4.1321e-02,  ..., -1.2787e-02,
         -1.0422e-02,  4.8065e-03],
        ...,
        [-2.0309e-02, -1.3374e-02,  1.9119e-02,  ...,  1.7426e-02,
         -1.7731e-02, -2.0828e-02],
        [-4.1161e-03,  3.3783e-02,  2.6794e-02,  ..., -6.9702e-02,
          4.5654e-02, -1.9836e-04],
        [ 1.5617e-02, -4.4632e-03, -1.9440e-02,  ...,  1.2909e-02,
         -1.1581e-02,  1.0300e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5332, -3.8906,  4.1406,  ..., -0.2803, -1.1689,  1.4648]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:42:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a flask is thermos
A more specific term for a song is lullaby
A more specific term for a church is chapel
A more specific term for a backpack is daypack
A more specific term for a boat is ferry
A more specific term for a candy is lollipop
A more specific term for a gun is rifle
A more specific term for a cloud is
2024-07-31 19:42:13 root INFO     [order_1_approx] starting weight calculation for A more specific term for a church is chapel
A more specific term for a backpack is daypack
A more specific term for a gun is rifle
A more specific term for a song is lullaby
A more specific term for a boat is ferry
A more specific term for a flask is thermos
A more specific term for a cloud is thundercloud
A more specific term for a candy is
2024-07-31 19:42:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:45:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0594,  0.2561, -0.0168,  ..., -0.0307, -0.0770, -0.0362],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2266, -9.4922,  0.4634,  ..., -1.1484, -1.6113,  5.8828],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103, -0.0240,  0.0085,  ...,  0.0098,  0.0065,  0.0233],
        [ 0.0154,  0.0109,  0.0036,  ...,  0.0130,  0.0131, -0.0300],
        [-0.0093, -0.0066,  0.0072,  ...,  0.0227,  0.0093,  0.0087],
        ...,
        [ 0.0199, -0.0153,  0.0179,  ...,  0.0461, -0.0083, -0.0137],
        [ 0.0082,  0.0036, -0.0267,  ...,  0.0066,  0.0195, -0.0016],
        [-0.0249,  0.0219,  0.0552,  ..., -0.0173,  0.0118,  0.0050]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1074, -9.2812,  0.4106,  ..., -1.1230, -1.6377,  5.5625]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:45:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a church is chapel
A more specific term for a backpack is daypack
A more specific term for a gun is rifle
A more specific term for a song is lullaby
A more specific term for a boat is ferry
A more specific term for a flask is thermos
A more specific term for a cloud is thundercloud
A more specific term for a candy is
2024-07-31 19:45:12 root INFO     [order_1_approx] starting weight calculation for A more specific term for a boat is ferry
A more specific term for a church is chapel
A more specific term for a cloud is thundercloud
A more specific term for a candy is lollipop
A more specific term for a song is lullaby
A more specific term for a flask is thermos
A more specific term for a backpack is daypack
A more specific term for a gun is
2024-07-31 19:45:12 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:48:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0888, -0.0063,  0.0491,  ..., -0.0547, -0.0441, -0.1636],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9526, -4.8711, -0.1436,  ...,  0.2061, -1.7871,  0.2725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0023, -0.0231, -0.0359,  ..., -0.0166,  0.0071, -0.0060],
        [ 0.0048,  0.0153,  0.0345,  ..., -0.0042, -0.0150, -0.0049],
        [-0.0111, -0.0226,  0.0265,  ..., -0.0108,  0.0239,  0.0231],
        ...,
        [ 0.0047, -0.0124,  0.0010,  ...,  0.0503,  0.0002,  0.0168],
        [-0.0084,  0.0037,  0.0162,  ...,  0.0058,  0.0070,  0.0137],
        [ 0.0131,  0.0146,  0.0313,  ...,  0.0037, -0.0231,  0.0303]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5615, -4.2266, -0.0211,  ...,  0.3723, -1.1719,  0.3857]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:48:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a boat is ferry
A more specific term for a church is chapel
A more specific term for a cloud is thundercloud
A more specific term for a candy is lollipop
A more specific term for a song is lullaby
A more specific term for a flask is thermos
A more specific term for a backpack is daypack
A more specific term for a gun is
2024-07-31 19:48:11 root INFO     [order_1_approx] starting weight calculation for A more specific term for a gun is rifle
A more specific term for a candy is lollipop
A more specific term for a boat is ferry
A more specific term for a flask is thermos
A more specific term for a song is lullaby
A more specific term for a church is chapel
A more specific term for a cloud is thundercloud
A more specific term for a backpack is
2024-07-31 19:48:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:51:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0786,  0.0662,  0.0867,  ...,  0.0687, -0.2297, -0.1125],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2109, -3.2891, -1.3555,  ...,  1.7539,  2.4883,  0.1689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0101,  0.0091, -0.0066,  ...,  0.0161,  0.0242,  0.0264],
        [ 0.0133,  0.0231,  0.0051,  ...,  0.0110,  0.0337, -0.0108],
        [-0.0019, -0.0038,  0.0258,  ..., -0.0088, -0.0206,  0.0162],
        ...,
        [-0.0021, -0.0008, -0.0150,  ...,  0.0133,  0.0005, -0.0229],
        [ 0.0218, -0.0004, -0.0011,  ...,  0.0146,  0.0111, -0.0068],
        [ 0.0164, -0.0093,  0.0123,  ...,  0.0171, -0.0017,  0.0237]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0840, -3.0977, -1.4541,  ...,  1.8389,  2.2090,  0.7300]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:51:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a gun is rifle
A more specific term for a candy is lollipop
A more specific term for a boat is ferry
A more specific term for a flask is thermos
A more specific term for a song is lullaby
A more specific term for a church is chapel
A more specific term for a cloud is thundercloud
A more specific term for a backpack is
2024-07-31 19:51:10 root INFO     [order_1_approx] starting weight calculation for A more specific term for a candy is lollipop
A more specific term for a backpack is daypack
A more specific term for a boat is ferry
A more specific term for a gun is rifle
A more specific term for a flask is thermos
A more specific term for a cloud is thundercloud
A more specific term for a church is chapel
A more specific term for a song is
2024-07-31 19:51:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:54:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1182,  0.1990, -0.0246,  ...,  0.0722, -0.1309, -0.1296],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0130, -7.5859,  3.0781,  ..., -0.7607, -2.6289, -0.5479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440, -0.0513, -0.0081,  ...,  0.0462, -0.0423, -0.0014],
        [ 0.0273,  0.0012, -0.0326,  ..., -0.0058, -0.0116, -0.0324],
        [ 0.0096,  0.0238,  0.0356,  ...,  0.0034, -0.0067,  0.0342],
        ...,
        [ 0.0198,  0.0170,  0.0118,  ...,  0.0235, -0.0040,  0.0022],
        [-0.0212, -0.0171, -0.0121,  ...,  0.0085,  0.0103, -0.0056],
        [-0.0277, -0.0270, -0.0059,  ..., -0.0418,  0.0006,  0.0063]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1553, -6.2109,  2.6680,  ..., -0.8286, -1.9414,  0.6279]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:54:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a candy is lollipop
A more specific term for a backpack is daypack
A more specific term for a boat is ferry
A more specific term for a gun is rifle
A more specific term for a flask is thermos
A more specific term for a cloud is thundercloud
A more specific term for a church is chapel
A more specific term for a song is
2024-07-31 19:54:09 root INFO     [order_1_approx] starting weight calculation for A more specific term for a backpack is daypack
A more specific term for a gun is rifle
A more specific term for a church is chapel
A more specific term for a flask is thermos
A more specific term for a cloud is thundercloud
A more specific term for a candy is lollipop
A more specific term for a song is lullaby
A more specific term for a boat is
2024-07-31 19:54:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 19:57:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0117, -0.0538,  0.0859,  ..., -0.0706, -0.1132,  0.0111],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2898, -5.3477,  0.7832,  ...,  1.4111, -0.0197,  1.0020],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0312,  0.0136, -0.0188,  ..., -0.0239,  0.0119,  0.0138],
        [ 0.0107,  0.0211, -0.0188,  ..., -0.0246,  0.0036, -0.0138],
        [-0.0062, -0.0225,  0.0314,  ...,  0.0030,  0.0004,  0.0078],
        ...,
        [ 0.0051, -0.0095,  0.0055,  ...,  0.0057, -0.0080, -0.0046],
        [ 0.0176, -0.0042,  0.0077,  ..., -0.0007,  0.0153, -0.0149],
        [ 0.0038, -0.0300, -0.0068,  ..., -0.0070, -0.0166, -0.0033]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1312, -5.2500,  0.9092,  ...,  1.7031,  0.0801,  1.4072]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 19:57:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A more specific term for a backpack is daypack
A more specific term for a gun is rifle
A more specific term for a church is chapel
A more specific term for a flask is thermos
A more specific term for a cloud is thundercloud
A more specific term for a candy is lollipop
A more specific term for a song is lullaby
A more specific term for a boat is
2024-07-31 19:57:10 root INFO     total operator prediction time: 1437.616242647171 seconds
2024-07-31 19:57:10 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on antonyms - binary
2024-07-31 19:57:10 root INFO     building operator antonyms - binary
2024-07-31 19:57:10 root INFO     [order_1_approx] starting weight calculation for The opposite of climb is descend
The opposite of down is up
The opposite of anterior is posterior
The opposite of exit is entrance
The opposite of below is above
The opposite of rise is sink
The opposite of uphill is downhill
The opposite of south is
2024-07-31 19:57:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:00:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1006, -0.0775, -0.0452,  ...,  0.0944, -0.0458, -0.0027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8887, -3.4883,  0.3828,  ..., -1.0488,  0.6016, -3.9258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0064, -0.0494, -0.0246,  ...,  0.0004,  0.0331,  0.0430],
        [-0.0035,  0.0124, -0.0284,  ..., -0.0139, -0.0245, -0.0098],
        [-0.0261, -0.0160, -0.0379,  ...,  0.0564,  0.0275,  0.0571],
        ...,
        [ 0.0226, -0.0307, -0.0144,  ...,  0.0387, -0.0190, -0.0059],
        [ 0.0096, -0.0260, -0.0068,  ...,  0.0334,  0.0191,  0.0068],
        [-0.0393,  0.0204,  0.0106,  ..., -0.0009,  0.0401,  0.0007]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3750, -3.4492,  1.8467,  ..., -0.8364,  0.6597, -3.5117]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:00:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of climb is descend
The opposite of down is up
The opposite of anterior is posterior
The opposite of exit is entrance
The opposite of below is above
The opposite of rise is sink
The opposite of uphill is downhill
The opposite of south is
2024-07-31 20:00:07 root INFO     [order_1_approx] starting weight calculation for The opposite of uphill is downhill
The opposite of down is up
The opposite of rise is sink
The opposite of exit is entrance
The opposite of south is north
The opposite of climb is descend
The opposite of anterior is posterior
The opposite of below is
2024-07-31 20:00:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:03:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0857, -0.1105,  0.0641,  ..., -0.0245, -0.2131, -0.0507],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4297, -1.9580,  0.6060,  ..., -0.2148,  2.0820, -0.9600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0068, -0.0214, -0.0114,  ...,  0.0258,  0.0468, -0.0424],
        [ 0.0442,  0.0575,  0.0189,  ...,  0.0425,  0.0170,  0.0413],
        [ 0.0706,  0.0241,  0.0113,  ...,  0.0637,  0.0272, -0.0008],
        ...,
        [ 0.0639, -0.0055,  0.0074,  ..., -0.0023, -0.0254,  0.0456],
        [ 0.0367, -0.0175,  0.0411,  ...,  0.0392,  0.0347,  0.0094],
        [ 0.0055, -0.0245,  0.0172,  ...,  0.0187,  0.0444,  0.0036]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9258, -1.3496,  1.9902,  ...,  0.4863,  1.4902, -0.1953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:03:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of uphill is downhill
The opposite of down is up
The opposite of rise is sink
The opposite of exit is entrance
The opposite of south is north
The opposite of climb is descend
The opposite of anterior is posterior
The opposite of below is
2024-07-31 20:03:01 root INFO     [order_1_approx] starting weight calculation for The opposite of south is north
The opposite of exit is entrance
The opposite of down is up
The opposite of below is above
The opposite of rise is sink
The opposite of uphill is downhill
The opposite of climb is descend
The opposite of anterior is
2024-07-31 20:03:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:05:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1265, -0.0480, -0.0224,  ...,  0.0078, -0.1827, -0.0305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6924, -2.9434,  2.9043,  ..., -3.7207, -2.0879, -4.6953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0110, -0.0334, -0.0333,  ...,  0.1044, -0.0494,  0.0380],
        [ 0.0341,  0.0283, -0.1013,  ...,  0.0271,  0.0564,  0.0189],
        [ 0.0614, -0.0060,  0.0056,  ...,  0.0069,  0.0363, -0.0500],
        ...,
        [-0.0566,  0.0682, -0.0575,  ...,  0.0222,  0.0031,  0.0218],
        [ 0.0594, -0.0213,  0.0368,  ...,  0.0312,  0.0160, -0.0339],
        [-0.1494,  0.0358, -0.1516,  ...,  0.0695,  0.0211,  0.0703]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7905, -1.5742,  2.9062,  ..., -2.9570, -2.1973, -2.8574]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:05:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of south is north
The opposite of exit is entrance
The opposite of down is up
The opposite of below is above
The opposite of rise is sink
The opposite of uphill is downhill
The opposite of climb is descend
The opposite of anterior is
2024-07-31 20:05:56 root INFO     [order_1_approx] starting weight calculation for The opposite of climb is descend
The opposite of rise is sink
The opposite of anterior is posterior
The opposite of uphill is downhill
The opposite of below is above
The opposite of down is up
The opposite of south is north
The opposite of exit is
2024-07-31 20:05:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:08:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0346, -0.0225, -0.1506,  ...,  0.1170, -0.0947, -0.0521],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1377, -2.6465, -2.3125,  ...,  2.1445, -2.0137, -3.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0078,  0.0680, -0.0454,  ...,  0.0377,  0.0609,  0.0178],
        [-0.0269,  0.0287,  0.0131,  ...,  0.0005,  0.0430,  0.0126],
        [ 0.0027, -0.0118, -0.0575,  ...,  0.0176, -0.0065,  0.0198],
        ...,
        [ 0.0220, -0.0021, -0.0043,  ...,  0.0350, -0.0085, -0.0023],
        [ 0.0148, -0.0750,  0.0113,  ...,  0.0416, -0.0315, -0.0469],
        [-0.0095,  0.0415, -0.0807,  ..., -0.0663,  0.0876,  0.0514]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6064, -1.4365, -1.6094,  ...,  1.8760, -2.6309, -2.1211]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:08:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of climb is descend
The opposite of rise is sink
The opposite of anterior is posterior
The opposite of uphill is downhill
The opposite of below is above
The opposite of down is up
The opposite of south is north
The opposite of exit is
2024-07-31 20:08:55 root INFO     [order_1_approx] starting weight calculation for The opposite of south is north
The opposite of below is above
The opposite of exit is entrance
The opposite of down is up
The opposite of anterior is posterior
The opposite of climb is descend
The opposite of rise is sink
The opposite of uphill is
2024-07-31 20:08:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:11:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0216,  0.0289, -0.1285,  ..., -0.0170, -0.3423,  0.1027],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8613, -0.8604,  0.9854,  ..., -0.5396, -3.9648, -0.8330],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0762, -0.0657, -0.0142,  ...,  0.0127, -0.0204,  0.0716],
        [ 0.0104,  0.0617,  0.0119,  ...,  0.0140,  0.0231, -0.0665],
        [ 0.0485,  0.0557, -0.0422,  ...,  0.0124, -0.0614,  0.0123],
        ...,
        [ 0.0727,  0.0399, -0.0142,  ...,  0.0388, -0.0476, -0.0149],
        [ 0.0094, -0.0483,  0.0096,  ..., -0.0332,  0.0019, -0.0015],
        [-0.0025,  0.0204, -0.0138,  ..., -0.0286, -0.0292, -0.0124]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0527, -1.2588,  1.0615,  ..., -0.8066, -3.6562, -0.8384]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:11:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of south is north
The opposite of below is above
The opposite of exit is entrance
The opposite of down is up
The opposite of anterior is posterior
The opposite of climb is descend
The opposite of rise is sink
The opposite of uphill is
2024-07-31 20:11:50 root INFO     [order_1_approx] starting weight calculation for The opposite of rise is sink
The opposite of below is above
The opposite of anterior is posterior
The opposite of south is north
The opposite of uphill is downhill
The opposite of exit is entrance
The opposite of climb is descend
The opposite of down is
2024-07-31 20:11:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:14:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1074, -0.0268, -0.0834,  ..., -0.0381, -0.1965, -0.0597],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0977, -5.2109,  0.4053,  ...,  0.2561, -0.1611, -3.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0497, -0.0259, -0.0340,  ..., -0.0116, -0.0052,  0.0136],
        [-0.1255,  0.0739,  0.0184,  ...,  0.0175, -0.0756, -0.0346],
        [-0.0182, -0.0036,  0.0104,  ...,  0.0286,  0.0009,  0.0328],
        ...,
        [ 0.0618, -0.0538, -0.0406,  ..., -0.0044,  0.0201, -0.0043],
        [ 0.1050, -0.0706,  0.0436,  ...,  0.0403,  0.0344,  0.0191],
        [-0.1235,  0.0526, -0.0318,  ...,  0.0008, -0.0418, -0.0141]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7383, -3.7422, -0.1392,  ..., -0.7266, -0.3647, -1.5859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:14:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of rise is sink
The opposite of below is above
The opposite of anterior is posterior
The opposite of south is north
The opposite of uphill is downhill
The opposite of exit is entrance
The opposite of climb is descend
The opposite of down is
2024-07-31 20:14:46 root INFO     [order_1_approx] starting weight calculation for The opposite of exit is entrance
The opposite of below is above
The opposite of climb is descend
The opposite of anterior is posterior
The opposite of uphill is downhill
The opposite of down is up
The opposite of south is north
The opposite of rise is
2024-07-31 20:14:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:17:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0410, -0.0832, -0.0974,  ...,  0.0600, -0.2478, -0.0990],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8115, -0.7969,  1.6992,  ..., -0.5991, -3.1426, -2.1445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0058,  0.0192,  0.0247,  ...,  0.0351, -0.0071,  0.0907],
        [ 0.0231,  0.0417,  0.0340,  ...,  0.0056,  0.0234, -0.0251],
        [-0.0084, -0.0017, -0.0307,  ..., -0.0066, -0.0688, -0.0029],
        ...,
        [ 0.0108,  0.0257,  0.0353,  ..., -0.0033, -0.0047, -0.0240],
        [-0.0116, -0.0267, -0.0137,  ...,  0.0404, -0.0310, -0.0070],
        [-0.0388, -0.0146,  0.0035,  ..., -0.0279,  0.0096, -0.0196]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6406, -1.0527,  2.0039,  ..., -0.4194, -2.4141, -1.8506]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:17:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of exit is entrance
The opposite of below is above
The opposite of climb is descend
The opposite of anterior is posterior
The opposite of uphill is downhill
The opposite of down is up
The opposite of south is north
The opposite of rise is
2024-07-31 20:17:46 root INFO     [order_1_approx] starting weight calculation for The opposite of south is north
The opposite of below is above
The opposite of uphill is downhill
The opposite of rise is sink
The opposite of exit is entrance
The opposite of down is up
The opposite of anterior is posterior
The opposite of climb is
2024-07-31 20:17:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:20:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0405,  0.0589, -0.0385,  ..., -0.1160, -0.3037,  0.1573],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6973, -1.0283,  2.1445,  ..., -0.5293, -3.1406, -1.2725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.6337e-02, -1.8250e-02, -2.6505e-02,  ...,  2.3727e-03,
         -1.8417e-02, -1.3412e-02],
        [ 2.6459e-02,  8.8043e-03,  2.1179e-02,  ...,  2.6733e-02,
         -2.0233e-02,  1.3863e-02],
        [ 2.6703e-02, -2.8198e-02, -4.2419e-02,  ..., -1.4389e-02,
         -1.4114e-02, -4.5395e-03],
        ...,
        [ 9.8877e-03,  2.1362e-02,  7.0877e-03,  ..., -1.5625e-02,
          5.9547e-03, -4.7760e-03],
        [-1.9531e-02,  4.2664e-02,  1.7426e-02,  ...,  1.9836e-02,
         -1.3885e-02,  1.8723e-02],
        [ 4.5654e-02, -4.9591e-05,  2.0905e-02,  ...,  1.3809e-02,
          4.4434e-02,  5.9433e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4355, -1.5371,  2.5430,  ..., -0.1572, -3.3887, -1.1631]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:20:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of south is north
The opposite of below is above
The opposite of uphill is downhill
The opposite of rise is sink
The opposite of exit is entrance
The opposite of down is up
The opposite of anterior is posterior
The opposite of climb is
2024-07-31 20:20:44 root INFO     total operator prediction time: 1414.4803440570831 seconds
2024-07-31 20:20:44 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - member
2024-07-31 20:20:44 root INFO     building operator meronyms - member
2024-07-31 20:20:44 root INFO     [order_1_approx] starting weight calculation for A bee is a member of a swarm
A parishioner is a member of a parish
A kitten is a member of a litter
A page is a member of a book
A senator is a member of a senate
A bird is a member of a flock
A singer is a member of a choir
A crow is a member of a
2024-07-31 20:20:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:23:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1293,  0.0529, -0.0423,  ..., -0.2235, -0.0231, -0.0516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 7.3828, -1.8809,  3.7441,  ..., -0.9580, -3.2363,  1.2422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0033,  0.0033, -0.0384,  ..., -0.0278,  0.0681,  0.0105],
        [ 0.0374,  0.0092,  0.0886,  ...,  0.0284,  0.0116,  0.0019],
        [-0.0433, -0.0111,  0.0220,  ...,  0.0284,  0.0057,  0.0076],
        ...,
        [ 0.0556, -0.0404,  0.0383,  ...,  0.0424, -0.0102,  0.0051],
        [-0.0003, -0.0138, -0.0482,  ...,  0.0575,  0.0506,  0.0273],
        [-0.0185,  0.0136,  0.0247,  ...,  0.0124,  0.0084,  0.0009]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.6914, -1.4434,  3.5430,  ..., -0.3555, -2.8281,  1.5029]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:23:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bee is a member of a swarm
A parishioner is a member of a parish
A kitten is a member of a litter
A page is a member of a book
A senator is a member of a senate
A bird is a member of a flock
A singer is a member of a choir
A crow is a member of a
2024-07-31 20:23:42 root INFO     [order_1_approx] starting weight calculation for A kitten is a member of a litter
A singer is a member of a choir
A senator is a member of a senate
A bird is a member of a flock
A bee is a member of a swarm
A crow is a member of a murder
A page is a member of a book
A parishioner is a member of a
2024-07-31 20:23:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:26:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 7.8979e-02,  1.4661e-01, -1.8823e-01,  ...,  2.1619e-01,
        -1.3110e-01, -1.2207e-04], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5762, -6.1172,  4.8086,  ..., -2.0703,  0.5522,  0.5752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0020, -0.0042, -0.0047,  ...,  0.0107,  0.0026, -0.0046],
        [-0.0079,  0.0078, -0.0095,  ...,  0.0024,  0.0042,  0.0020],
        [ 0.0087, -0.0014,  0.0128,  ...,  0.0005, -0.0063, -0.0090],
        ...,
        [-0.0035,  0.0071, -0.0021,  ..., -0.0057,  0.0034,  0.0021],
        [-0.0003, -0.0081,  0.0015,  ...,  0.0033,  0.0002, -0.0090],
        [-0.0062, -0.0015, -0.0031,  ..., -0.0026,  0.0026,  0.0084]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0117, -6.0703,  4.8477,  ..., -1.9023,  0.1719,  0.6504]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:26:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A kitten is a member of a litter
A singer is a member of a choir
A senator is a member of a senate
A bird is a member of a flock
A bee is a member of a swarm
A crow is a member of a murder
A page is a member of a book
A parishioner is a member of a
2024-07-31 20:26:42 root INFO     [order_1_approx] starting weight calculation for A singer is a member of a choir
A bird is a member of a flock
A page is a member of a book
A crow is a member of a murder
A parishioner is a member of a parish
A bee is a member of a swarm
A senator is a member of a senate
A kitten is a member of a
2024-07-31 20:26:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:29:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0713,  0.0164,  0.1570,  ..., -0.0246, -0.0005, -0.0908],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8438, -2.5059, -0.9795,  ..., -0.9062, -0.3711, -2.1992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0023, -0.0266,  0.0240,  ...,  0.0284, -0.0219,  0.0117],
        [-0.0054,  0.0089,  0.0123,  ...,  0.0258, -0.0064,  0.0045],
        [-0.0062, -0.0270,  0.0429,  ..., -0.0584, -0.0371,  0.0231],
        ...,
        [ 0.0374,  0.0008,  0.0095,  ...,  0.0404,  0.0160, -0.0103],
        [ 0.0322,  0.0163, -0.0411,  ...,  0.0242,  0.0613, -0.0143],
        [-0.0341, -0.0277,  0.0124,  ..., -0.0197, -0.0079,  0.0222]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8203, -2.5098, -0.9600,  ..., -0.8325, -0.4927, -2.3770]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:29:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A singer is a member of a choir
A bird is a member of a flock
A page is a member of a book
A crow is a member of a murder
A parishioner is a member of a parish
A bee is a member of a swarm
A senator is a member of a senate
A kitten is a member of a
2024-07-31 20:29:42 root INFO     [order_1_approx] starting weight calculation for A senator is a member of a senate
A crow is a member of a murder
A singer is a member of a choir
A page is a member of a book
A parishioner is a member of a parish
A kitten is a member of a litter
A bee is a member of a swarm
A bird is a member of a
2024-07-31 20:29:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:32:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0767,  0.1221, -0.0191,  ..., -0.0878, -0.0623, -0.1154],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9648, -3.2930,  1.4922,  ..., -0.0195, -3.1055,  0.2334],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0110, -0.0057,  0.0053,  ...,  0.0071, -0.0204,  0.0006],
        [-0.0012,  0.0068,  0.0315,  ...,  0.0060, -0.0027, -0.0250],
        [-0.0196, -0.0050,  0.0159,  ..., -0.0061, -0.0152,  0.0073],
        ...,
        [ 0.0293, -0.0032,  0.0023,  ...,  0.0316,  0.0169, -0.0114],
        [ 0.0396, -0.0151, -0.0302,  ...,  0.0125,  0.0393,  0.0111],
        [-0.0084, -0.0109,  0.0136,  ...,  0.0030, -0.0068,  0.0053]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8281, -3.2969,  0.8970,  ...,  0.5093, -2.7383,  0.2272]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:32:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A senator is a member of a senate
A crow is a member of a murder
A singer is a member of a choir
A page is a member of a book
A parishioner is a member of a parish
A kitten is a member of a litter
A bee is a member of a swarm
A bird is a member of a
2024-07-31 20:32:43 root INFO     [order_1_approx] starting weight calculation for A parishioner is a member of a parish
A singer is a member of a choir
A bird is a member of a flock
A crow is a member of a murder
A kitten is a member of a litter
A bee is a member of a swarm
A senator is a member of a senate
A page is a member of a
2024-07-31 20:32:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:35:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0288,  0.1772, -0.1202,  ..., -0.0959, -0.0966,  0.0789],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8066, -1.2012,  1.7285,  ..., -0.0391, -0.3328, -1.1406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0504,  0.0262,  0.0325,  ..., -0.0177, -0.0051,  0.0016],
        [-0.0718,  0.0225,  0.0542,  ...,  0.0027, -0.0274, -0.0417],
        [ 0.0027, -0.0807, -0.0430,  ...,  0.0190, -0.0433,  0.0207],
        ...,
        [-0.0081, -0.0054,  0.0020,  ..., -0.0064,  0.0128, -0.0296],
        [ 0.0406,  0.0447, -0.0446,  ...,  0.0410,  0.0242,  0.0063],
        [ 0.0010, -0.0502,  0.0157,  ...,  0.0249, -0.0016,  0.0701]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6621, -0.7129,  2.2871,  ...,  0.6733,  0.0352, -0.9834]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:35:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A parishioner is a member of a parish
A singer is a member of a choir
A bird is a member of a flock
A crow is a member of a murder
A kitten is a member of a litter
A bee is a member of a swarm
A senator is a member of a senate
A page is a member of a
2024-07-31 20:35:39 root INFO     [order_1_approx] starting weight calculation for A bird is a member of a flock
A page is a member of a book
A singer is a member of a choir
A bee is a member of a swarm
A parishioner is a member of a parish
A kitten is a member of a litter
A crow is a member of a murder
A senator is a member of a
2024-07-31 20:35:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:38:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1279,  0.2416, -0.1022,  ...,  0.1241, -0.0461,  0.1436],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9990, -3.7500,  3.6543,  ..., -0.7441,  0.9673, -0.6250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0236,  0.0261, -0.0006,  ..., -0.0010, -0.0198, -0.0063],
        [-0.0078,  0.0058, -0.0029,  ...,  0.0108,  0.0226, -0.0025],
        [-0.0160, -0.0020,  0.0104,  ..., -0.0176, -0.0262,  0.0007],
        ...,
        [ 0.0085,  0.0088,  0.0083,  ...,  0.0191, -0.0038, -0.0136],
        [ 0.0175,  0.0375, -0.0171,  ...,  0.0016,  0.0104, -0.0058],
        [ 0.0049, -0.0230, -0.0095,  ...,  0.0061,  0.0160,  0.0233]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2363, -3.4609,  3.8359,  ..., -0.6489,  1.2002, -0.5913]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:38:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bird is a member of a flock
A page is a member of a book
A singer is a member of a choir
A bee is a member of a swarm
A parishioner is a member of a parish
A kitten is a member of a litter
A crow is a member of a murder
A senator is a member of a
2024-07-31 20:38:38 root INFO     [order_1_approx] starting weight calculation for A bird is a member of a flock
A page is a member of a book
A crow is a member of a murder
A bee is a member of a swarm
A kitten is a member of a litter
A senator is a member of a senate
A parishioner is a member of a parish
A singer is a member of a
2024-07-31 20:38:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:41:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0703,  0.1210,  0.0255,  ...,  0.0908, -0.0628,  0.0316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1367, -4.6367,  4.2891,  ...,  0.1377, -0.8003, -1.6221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-4.0039e-02, -4.6539e-02,  2.2934e-02,  ..., -5.9967e-03,
          8.4000e-03, -5.8327e-03],
        [ 4.8126e-02,  1.8921e-02, -2.7504e-03,  ..., -5.8174e-05,
          1.5472e-02, -2.2842e-02],
        [-7.0381e-03, -1.6479e-02,  1.9424e-02,  ..., -1.7426e-02,
          1.8097e-02, -2.4689e-02],
        ...,
        [ 3.0762e-02,  1.7456e-02,  8.6136e-03,  ...,  7.8857e-02,
          1.4477e-03, -1.4778e-02],
        [ 2.9297e-02,  3.9062e-02, -4.1290e-02,  ..., -4.1008e-03,
          6.0005e-03,  4.4983e-02],
        [ 2.6459e-02, -1.4565e-02, -1.5373e-02,  ..., -6.0081e-04,
         -3.1464e-02,  2.4918e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9893, -4.2656,  4.6367,  ...,  0.5752, -0.6641, -1.6904]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:41:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A bird is a member of a flock
A page is a member of a book
A crow is a member of a murder
A bee is a member of a swarm
A kitten is a member of a litter
A senator is a member of a senate
A parishioner is a member of a parish
A singer is a member of a
2024-07-31 20:41:36 root INFO     [order_1_approx] starting weight calculation for A page is a member of a book
A parishioner is a member of a parish
A crow is a member of a murder
A bird is a member of a flock
A singer is a member of a choir
A senator is a member of a senate
A kitten is a member of a litter
A bee is a member of a
2024-07-31 20:41:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:44:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1273,  0.1332,  0.0292,  ..., -0.0892, -0.0152, -0.1262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1914, -2.5566,  2.9473,  ..., -1.6953, -0.6743,  0.1553],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 7.9346e-03, -2.0981e-04,  1.7929e-04,  ...,  5.5161e-03,
         -2.0416e-02,  1.6541e-02],
        [-1.1002e-02,  1.7654e-02,  1.9989e-02,  ..., -8.1177e-03,
         -5.4703e-03,  5.2338e-03],
        [-2.2751e-02,  2.0706e-02,  1.2909e-02,  ..., -2.1957e-02,
         -7.3776e-03,  5.6458e-03],
        ...,
        [ 3.2959e-03,  1.7090e-02,  5.1651e-03,  ...,  3.9948e-02,
         -2.3590e-02, -1.1230e-02],
        [ 5.7161e-05, -1.3132e-03, -1.4793e-02,  ...,  5.3596e-04,
          3.6682e-02, -8.5907e-03],
        [ 5.9032e-04, -2.2945e-03,  1.7242e-03,  ..., -8.5449e-03,
         -1.5587e-02,  3.6011e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3164, -2.0664,  3.0859,  ..., -1.5244, -0.7700,  0.3831]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:44:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A page is a member of a book
A parishioner is a member of a parish
A crow is a member of a murder
A bird is a member of a flock
A singer is a member of a choir
A senator is a member of a senate
A kitten is a member of a litter
A bee is a member of a
2024-07-31 20:44:35 root INFO     total operator prediction time: 1430.467726945877 seconds
2024-07-31 20:44:35 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_irreg
2024-07-31 20:44:35 root INFO     building operator noun - plural_irreg
2024-07-31 20:44:35 root INFO     [order_1_approx] starting weight calculation for The plural form of county is counties
The plural form of basis is bases
The plural form of industry is industries
The plural form of duty is duties
The plural form of datum is data
The plural form of species is species
The plural form of strategy is strategies
The plural form of country is
2024-07-31 20:44:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:47:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0813, -0.0919, -0.1573,  ..., -0.1632, -0.1266,  0.0275],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8794, -5.6797,  1.6973,  ..., -1.3594,  0.8760, -3.4727],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0096,  0.1514, -0.0031,  ..., -0.0483,  0.0043,  0.0383],
        [ 0.0092, -0.1418,  0.0453,  ...,  0.0581,  0.0626, -0.0465],
        [-0.0174,  0.0078,  0.0087,  ...,  0.0102,  0.0020,  0.0148],
        ...,
        [ 0.0031, -0.1146,  0.0201,  ...,  0.0454,  0.0247, -0.0379],
        [-0.0493,  0.0633, -0.0059,  ..., -0.0224,  0.0067, -0.0221],
        [ 0.0373, -0.1210, -0.0123,  ...,  0.0511, -0.0029, -0.0022]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4805, -1.7129,  2.3516,  ...,  1.1367, -1.2236, -0.2266]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:47:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of county is counties
The plural form of basis is bases
The plural form of industry is industries
The plural form of duty is duties
The plural form of datum is data
The plural form of species is species
The plural form of strategy is strategies
The plural form of country is
2024-07-31 20:47:34 root INFO     [order_1_approx] starting weight calculation for The plural form of county is counties
The plural form of species is species
The plural form of duty is duties
The plural form of strategy is strategies
The plural form of datum is data
The plural form of country is countries
The plural form of basis is bases
The plural form of industry is
2024-07-31 20:47:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:50:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1555,  0.0643,  0.0153,  ..., -0.0720,  0.1270, -0.0080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4375, -3.4160,  1.0898,  ..., -0.9409, -2.0059, -2.3555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0402, -0.0107,  0.0165,  ..., -0.0481, -0.0542,  0.0429],
        [ 0.1132,  0.0544,  0.1107,  ...,  0.0010,  0.1497,  0.0029],
        [-0.0483, -0.0127, -0.0463,  ..., -0.0412, -0.0425, -0.0170],
        ...,
        [ 0.0452,  0.0071,  0.0482,  ...,  0.0143,  0.0115, -0.0349],
        [-0.0687,  0.0036, -0.0759,  ...,  0.0643, -0.0930, -0.0400],
        [ 0.0828,  0.0469,  0.0884,  ...,  0.0094,  0.1705, -0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3242,  1.5488,  0.0068,  ..., -0.0869, -5.7539,  2.5820]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:50:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of county is counties
The plural form of species is species
The plural form of duty is duties
The plural form of strategy is strategies
The plural form of datum is data
The plural form of country is countries
The plural form of basis is bases
The plural form of industry is
2024-07-31 20:50:32 root INFO     [order_1_approx] starting weight calculation for The plural form of industry is industries
The plural form of strategy is strategies
The plural form of species is species
The plural form of datum is data
The plural form of basis is bases
The plural form of country is countries
The plural form of county is counties
The plural form of duty is
2024-07-31 20:50:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:53:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0126,  0.1689, -0.1289,  ...,  0.0570, -0.0780, -0.1689],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8281, -1.1943,  2.5527,  ..., -1.9082, -2.5684, -3.0488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0134, -0.0223,  0.0187,  ..., -0.0137, -0.0030, -0.0144],
        [-0.0403,  0.0208,  0.0132,  ..., -0.0182,  0.0032,  0.0055],
        [ 0.0070, -0.0005, -0.0176,  ...,  0.0014, -0.0059,  0.0076],
        ...,
        [ 0.0222, -0.0163,  0.0070,  ...,  0.0498,  0.0105, -0.0038],
        [ 0.0026,  0.0291,  0.0002,  ...,  0.0517,  0.0060, -0.0150],
        [-0.0404, -0.0170, -0.0075,  ..., -0.0391,  0.0697, -0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7852, -0.8638,  2.5684,  ..., -1.8447, -3.1133, -1.4180]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:53:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of industry is industries
The plural form of strategy is strategies
The plural form of species is species
The plural form of datum is data
The plural form of basis is bases
The plural form of country is countries
The plural form of county is counties
The plural form of duty is
2024-07-31 20:53:30 root INFO     [order_1_approx] starting weight calculation for The plural form of strategy is strategies
The plural form of basis is bases
The plural form of datum is data
The plural form of duty is duties
The plural form of species is species
The plural form of country is countries
The plural form of industry is industries
The plural form of county is
2024-07-31 20:53:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:56:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1135,  0.0375, -0.0936,  ..., -0.0933,  0.0995, -0.0376],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3403, -4.6484,  2.4219,  ..., -2.3789,  2.3672, -3.5625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0079, -0.1024,  0.1744,  ...,  0.1031, -0.0273,  0.0521],
        [-0.0103, -0.0844,  0.1097,  ...,  0.1914,  0.0434,  0.0305],
        [-0.0098,  0.0329, -0.1256,  ...,  0.0166,  0.0115,  0.0149],
        ...,
        [-0.0302,  0.0174,  0.0254,  ...,  0.0197, -0.0041, -0.0018],
        [-0.0230,  0.1301, -0.2632,  ..., -0.1859, -0.0419, -0.0677],
        [ 0.0125, -0.0690,  0.1638,  ...,  0.1530,  0.0313,  0.0038]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2422,  1.0273,  1.3008,  ..., -0.4570, -4.7266,  1.5391]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:56:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of strategy is strategies
The plural form of basis is bases
The plural form of datum is data
The plural form of duty is duties
The plural form of species is species
The plural form of country is countries
The plural form of industry is industries
The plural form of county is
2024-07-31 20:56:28 root INFO     [order_1_approx] starting weight calculation for The plural form of industry is industries
The plural form of species is species
The plural form of county is counties
The plural form of duty is duties
The plural form of basis is bases
The plural form of datum is data
The plural form of country is countries
The plural form of strategy is
2024-07-31 20:56:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 20:59:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1960,  0.0089,  0.0525,  ..., -0.0266,  0.0328, -0.1696],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2812, -2.7891,  0.7939,  ...,  0.5947, -2.3828, -3.9180],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.1343, -0.0537, -0.0196,  ..., -0.2637, -0.2537, -0.0156],
        [ 0.1891,  0.0542,  0.0709,  ...,  0.2607,  0.2421,  0.0217],
        [ 0.0130,  0.0058, -0.0060,  ...,  0.0406,  0.0308, -0.0169],
        ...,
        [ 0.1450,  0.0296,  0.0268,  ...,  0.2189,  0.2034,  0.0155],
        [-0.0980,  0.0057, -0.0364,  ..., -0.0728, -0.0266, -0.0447],
        [ 0.1224,  0.0209,  0.0166,  ...,  0.1978,  0.1805,  0.0198]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-5.5859,  7.0000,  1.6992,  ...,  7.5820, -4.9531,  2.7188]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 20:59:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of industry is industries
The plural form of species is species
The plural form of county is counties
The plural form of duty is duties
The plural form of basis is bases
The plural form of datum is data
The plural form of country is countries
The plural form of strategy is
2024-07-31 20:59:30 root INFO     [order_1_approx] starting weight calculation for The plural form of industry is industries
The plural form of strategy is strategies
The plural form of species is species
The plural form of country is countries
The plural form of county is counties
The plural form of basis is bases
The plural form of duty is duties
The plural form of datum is
2024-07-31 20:59:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:02:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0374,  0.1379, -0.0626,  ..., -0.0500, -0.2024, -0.0762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0898, -2.7344,  1.4531,  ..., -0.4023, -4.4844, -1.9570],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.1002,  0.0418,  0.0823,  ...,  0.0107, -0.1256, -0.0027],
        [-0.0874,  0.0928, -0.0197,  ..., -0.0139,  0.0753,  0.0359],
        [ 0.0510,  0.0092,  0.0002,  ..., -0.0190,  0.0620, -0.0099],
        ...,
        [-0.0989,  0.0539, -0.0216,  ..., -0.0564,  0.1522,  0.0190],
        [ 0.0441,  0.0020,  0.0069,  ...,  0.0157,  0.0117, -0.0128],
        [-0.0759,  0.0375, -0.0212,  ..., -0.0162,  0.0718,  0.0267]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5586, -2.0488,  1.9688,  ...,  0.3735, -4.4219, -1.2715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:02:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of industry is industries
The plural form of strategy is strategies
The plural form of species is species
The plural form of country is countries
The plural form of county is counties
The plural form of basis is bases
The plural form of duty is duties
The plural form of datum is
2024-07-31 21:02:28 root INFO     [order_1_approx] starting weight calculation for The plural form of datum is data
The plural form of industry is industries
The plural form of species is species
The plural form of strategy is strategies
The plural form of duty is duties
The plural form of county is counties
The plural form of country is countries
The plural form of basis is
2024-07-31 21:02:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:05:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1008, -0.1279, -0.1475,  ...,  0.1643, -0.2192, -0.1498],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1367, -2.7246,  1.2656,  ..., -1.5508, -2.4902, -2.7754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0072, -0.0037, -0.0251,  ..., -0.0213, -0.0384, -0.0245],
        [ 0.0124,  0.0369,  0.0314,  ...,  0.0203,  0.0336,  0.0034],
        [-0.0088,  0.0327, -0.0081,  ...,  0.0167, -0.0211,  0.0383],
        ...,
        [ 0.0323, -0.0087, -0.0118,  ..., -0.0004,  0.0387,  0.0217],
        [ 0.0065,  0.0180,  0.0366,  ...,  0.0176,  0.0132,  0.0124],
        [-0.0193, -0.0052,  0.0149,  ...,  0.0086, -0.0106,  0.0198]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7734,  0.6836,  1.0459,  ...,  0.7402, -1.0977, -1.7871]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:05:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of datum is data
The plural form of industry is industries
The plural form of species is species
The plural form of strategy is strategies
The plural form of duty is duties
The plural form of county is counties
The plural form of country is countries
The plural form of basis is
2024-07-31 21:05:27 root INFO     [order_1_approx] starting weight calculation for The plural form of country is countries
The plural form of duty is duties
The plural form of strategy is strategies
The plural form of industry is industries
The plural form of county is counties
The plural form of basis is bases
The plural form of datum is data
The plural form of species is
2024-07-31 21:05:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:08:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0292, -0.1576, -0.0259,  ..., -0.0891, -0.0176, -0.0725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1367, -2.9570,  0.0356,  ..., -0.4688, -3.7930, -3.0508],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0132, -0.0428,  0.0338,  ..., -0.0645, -0.1448, -0.0029],
        [ 0.1138,  0.0456, -0.0053,  ...,  0.1438,  0.1923, -0.0584],
        [ 0.0155,  0.0248, -0.0194,  ...,  0.0046,  0.0249,  0.0056],
        ...,
        [-0.0407,  0.0143, -0.0118,  ...,  0.0472,  0.0642, -0.0071],
        [ 0.0002, -0.0061, -0.0162,  ...,  0.0346,  0.0280, -0.0214],
        [ 0.0847,  0.0215, -0.0292,  ...,  0.1307,  0.1515,  0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5723, -0.3730,  0.5825,  ..., -0.1323, -3.0605, -0.9492]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:08:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of country is countries
The plural form of duty is duties
The plural form of strategy is strategies
The plural form of industry is industries
The plural form of county is counties
The plural form of basis is bases
The plural form of datum is data
The plural form of species is
2024-07-31 21:08:27 root INFO     total operator prediction time: 1432.7423236370087 seconds
2024-07-31 21:08:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on Ving - verb_inf
2024-07-31 21:08:27 root INFO     building operator Ving - verb_inf
2024-07-31 21:08:28 root INFO     [order_1_approx] starting weight calculation for applying is the active form of apply
managing is the active form of manage
continuing is the active form of continue
losing is the active form of lose
creating is the active form of create
adding is the active form of add
allowing is the active form of allow
achieving is the active form of
2024-07-31 21:08:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:11:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0665,  0.2756, -0.0159,  ...,  0.1031, -0.0283,  0.0808],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4082, -2.2188, -0.7710,  ...,  0.7891, -2.4375, -2.9746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0206, -0.0178, -0.0251,  ...,  0.0077, -0.0256,  0.0057],
        [-0.0116,  0.0394,  0.0225,  ...,  0.0268,  0.0309, -0.0040],
        [-0.0315, -0.0414, -0.0397,  ..., -0.0322, -0.1099,  0.0116],
        ...,
        [ 0.0221,  0.0427,  0.0375,  ...,  0.0194,  0.0522,  0.0041],
        [ 0.0754,  0.0350,  0.0143,  ...,  0.0137,  0.0579, -0.0190],
        [ 0.0272,  0.0061,  0.0259,  ...,  0.0360,  0.0524, -0.0036]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0537, -1.8906, -2.3281,  ...,  1.5508, -1.8242, -2.3242]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:11:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for applying is the active form of apply
managing is the active form of manage
continuing is the active form of continue
losing is the active form of lose
creating is the active form of create
adding is the active form of add
allowing is the active form of allow
achieving is the active form of
2024-07-31 21:11:26 root INFO     [order_1_approx] starting weight calculation for allowing is the active form of allow
adding is the active form of add
applying is the active form of apply
creating is the active form of create
losing is the active form of lose
managing is the active form of manage
achieving is the active form of achieve
continuing is the active form of
2024-07-31 21:11:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:14:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1289, -0.0060, -0.0089,  ...,  0.0809,  0.0110, -0.0400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0361, -4.4531,  0.5830,  ...,  1.2676,  1.2754, -1.8955],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0021,  0.0003, -0.0283,  ..., -0.0052,  0.0283,  0.0055],
        [-0.0049,  0.0167, -0.0014,  ..., -0.0010,  0.0369,  0.0105],
        [ 0.0123, -0.0004,  0.0156,  ...,  0.0015, -0.0207, -0.0028],
        ...,
        [ 0.0181,  0.0044,  0.0105,  ...,  0.0164, -0.0172,  0.0055],
        [ 0.0080,  0.0190, -0.0151,  ...,  0.0016,  0.0370,  0.0036],
        [-0.0019,  0.0016,  0.0117,  ..., -0.0035, -0.0132, -0.0011]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4500, -4.3008,  0.4702,  ...,  0.7686,  1.7227, -2.5020]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:14:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for allowing is the active form of allow
adding is the active form of add
applying is the active form of apply
creating is the active form of create
losing is the active form of lose
managing is the active form of manage
achieving is the active form of achieve
continuing is the active form of
2024-07-31 21:14:25 root INFO     [order_1_approx] starting weight calculation for creating is the active form of create
continuing is the active form of continue
applying is the active form of apply
managing is the active form of manage
losing is the active form of lose
allowing is the active form of allow
achieving is the active form of achieve
adding is the active form of
2024-07-31 21:14:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:17:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0368, -0.0334,  0.0534,  ...,  0.0010, -0.1144, -0.0424],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0312, -2.4219, -1.6035,  ...,  2.9414, -3.5508, -1.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0193, -0.0017, -0.0018,  ...,  0.0023,  0.0064,  0.0028],
        [-0.0022,  0.0003,  0.0106,  ..., -0.0093,  0.0165, -0.0038],
        [-0.0024, -0.0101,  0.0116,  ..., -0.0187, -0.0380, -0.0042],
        ...,
        [ 0.0074,  0.0115,  0.0231,  ..., -0.0275, -0.0300, -0.0323],
        [-0.0183, -0.0144, -0.0050,  ...,  0.0307, -0.0013,  0.0050],
        [ 0.0219,  0.0016, -0.0136,  ..., -0.0187, -0.0032,  0.0146]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2695, -1.8496, -1.9551,  ...,  2.6992, -3.7324, -1.0947]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:17:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for creating is the active form of create
continuing is the active form of continue
applying is the active form of apply
managing is the active form of manage
losing is the active form of lose
allowing is the active form of allow
achieving is the active form of achieve
adding is the active form of
2024-07-31 21:17:27 root INFO     [order_1_approx] starting weight calculation for continuing is the active form of continue
adding is the active form of add
applying is the active form of apply
achieving is the active form of achieve
creating is the active form of create
losing is the active form of lose
allowing is the active form of allow
managing is the active form of
2024-07-31 21:17:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:20:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0273,  0.3271,  0.2498,  ...,  0.1013, -0.1383, -0.0840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9277, -3.8086,  0.5278,  ...,  1.6094, -1.7422, -3.2031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0179, -0.0039,  0.0146,  ..., -0.0274, -0.0018,  0.0040],
        [ 0.0069,  0.0146,  0.0037,  ..., -0.0124,  0.0266, -0.0029],
        [ 0.0022, -0.0157,  0.0090,  ..., -0.0168, -0.0194, -0.0107],
        ...,
        [-0.0073, -0.0004,  0.0023,  ...,  0.0009, -0.0214, -0.0028],
        [-0.0049, -0.0074, -0.0159,  ..., -0.0036, -0.0218,  0.0042],
        [-0.0124, -0.0079, -0.0047,  ...,  0.0067,  0.0085,  0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9556, -3.4863, -0.1484,  ...,  1.1758, -2.1914, -2.9668]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:20:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for continuing is the active form of continue
adding is the active form of add
applying is the active form of apply
achieving is the active form of achieve
creating is the active form of create
losing is the active form of lose
allowing is the active form of allow
managing is the active form of
2024-07-31 21:20:29 root INFO     [order_1_approx] starting weight calculation for achieving is the active form of achieve
adding is the active form of add
continuing is the active form of continue
managing is the active form of manage
allowing is the active form of allow
creating is the active form of create
applying is the active form of apply
losing is the active form of
2024-07-31 21:20:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:23:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0378,  0.1565,  0.1445,  ...,  0.0824,  0.1307, -0.0652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7178, -2.3203, -1.2070,  ...,  0.9624,  0.8535, -1.9971],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0009, -0.0090, -0.0040,  ...,  0.0046,  0.0070,  0.0078],
        [-0.0019,  0.0148,  0.0043,  ...,  0.0011,  0.0298, -0.0208],
        [ 0.0008, -0.0040,  0.0027,  ..., -0.0003, -0.0017,  0.0062],
        ...,
        [ 0.0110,  0.0027, -0.0137,  ...,  0.0162, -0.0136,  0.0135],
        [ 0.0128,  0.0079, -0.0302,  ..., -0.0051, -0.0169, -0.0018],
        [ 0.0026, -0.0020,  0.0150,  ...,  0.0173,  0.0145,  0.0175]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6782, -2.6465, -1.3965,  ...,  1.3584,  0.5522, -1.6943]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:23:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for achieving is the active form of achieve
adding is the active form of add
continuing is the active form of continue
managing is the active form of manage
allowing is the active form of allow
creating is the active form of create
applying is the active form of apply
losing is the active form of
2024-07-31 21:23:25 root INFO     [order_1_approx] starting weight calculation for allowing is the active form of allow
creating is the active form of create
continuing is the active form of continue
achieving is the active form of achieve
adding is the active form of add
losing is the active form of lose
managing is the active form of manage
applying is the active form of
2024-07-31 21:23:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:26:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.1620, 0.1235, 0.1017,  ..., 0.0238, 0.0697, 0.0064], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2031, -3.8203, -1.2432,  ...,  3.2793, -2.8301, -2.6074],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0207, -0.0166,  0.0364,  ...,  0.0006,  0.0298,  0.0236],
        [ 0.0232, -0.0040,  0.0363,  ...,  0.0108,  0.0554,  0.0314],
        [ 0.0086, -0.0113,  0.0238,  ..., -0.0151, -0.0281,  0.0053],
        ...,
        [-0.0027, -0.0073,  0.0040,  ...,  0.0283,  0.0025, -0.0051],
        [ 0.0357, -0.0074, -0.0019,  ...,  0.0107,  0.0611,  0.0373],
        [ 0.0376, -0.0136,  0.0108,  ...,  0.0046,  0.0457,  0.0174]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4214, -3.3945, -1.1719,  ...,  3.2500, -2.3887, -2.1113]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:26:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for allowing is the active form of allow
creating is the active form of create
continuing is the active form of continue
achieving is the active form of achieve
adding is the active form of add
losing is the active form of lose
managing is the active form of manage
applying is the active form of
2024-07-31 21:26:25 root INFO     [order_1_approx] starting weight calculation for allowing is the active form of allow
continuing is the active form of continue
losing is the active form of lose
adding is the active form of add
applying is the active form of apply
achieving is the active form of achieve
managing is the active form of manage
creating is the active form of
2024-07-31 21:26:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:29:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1440,  0.2129,  0.2047,  ...,  0.0789, -0.0203, -0.1051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0957, -4.2891,  0.7485,  ...,  3.2500, -1.8965, -0.6523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0150, -0.0013,  0.0035,  ...,  0.0056,  0.0107,  0.0087],
        [ 0.0115,  0.0088, -0.0126,  ...,  0.0020,  0.0352,  0.0105],
        [-0.0015, -0.0123,  0.0130,  ..., -0.0047,  0.0008, -0.0258],
        ...,
        [ 0.0016, -0.0002, -0.0118,  ..., -0.0005,  0.0006, -0.0138],
        [ 0.0248,  0.0047, -0.0333,  ...,  0.0051,  0.0117,  0.0257],
        [ 0.0140,  0.0006, -0.0086,  ..., -0.0052, -0.0065, -0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0397, -3.7207,  0.4631,  ...,  3.1250, -1.7109, -0.6216]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:29:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for allowing is the active form of allow
continuing is the active form of continue
losing is the active form of lose
adding is the active form of add
applying is the active form of apply
achieving is the active form of achieve
managing is the active form of manage
creating is the active form of
2024-07-31 21:29:24 root INFO     [order_1_approx] starting weight calculation for applying is the active form of apply
creating is the active form of create
losing is the active form of lose
continuing is the active form of continue
achieving is the active form of achieve
adding is the active form of add
managing is the active form of manage
allowing is the active form of
2024-07-31 21:29:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:32:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0998, -0.1218,  0.2017,  ..., -0.0995,  0.1067, -0.0343],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5918, -5.6797, -1.7168,  ...,  2.0059, -2.5059, -1.0137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0143, -0.0072, -0.0129,  ..., -0.0038,  0.0077, -0.0005],
        [-0.0028,  0.0161, -0.0043,  ...,  0.0134,  0.0211,  0.0031],
        [-0.0019, -0.0161,  0.0122,  ..., -0.0130, -0.0021, -0.0338],
        ...,
        [-0.0105,  0.0002,  0.0179,  ...,  0.0046, -0.0097,  0.0141],
        [ 0.0229,  0.0221, -0.0281,  ..., -0.0012,  0.0109,  0.0006],
        [-0.0002, -0.0001,  0.0038,  ..., -0.0026,  0.0084,  0.0123]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6387, -5.7305, -2.0020,  ...,  2.1797, -2.5742, -1.1650]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:32:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for applying is the active form of apply
creating is the active form of create
losing is the active form of lose
continuing is the active form of continue
achieving is the active form of achieve
adding is the active form of add
managing is the active form of manage
allowing is the active form of
2024-07-31 21:32:23 root INFO     total operator prediction time: 1435.999675989151 seconds
2024-07-31 21:32:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - Ved
2024-07-31 21:32:23 root INFO     building operator verb_Ving - Ved
2024-07-31 21:32:24 root INFO     [order_1_approx] starting weight calculation for After something is operating, it has operated
After something is expecting, it has expected
After something is becoming, it has became
After something is agreeing, it has agreed
After something is understanding, it has understood
After something is existing, it has existed
After something is replacing, it has replaced
After something is considering, it has
2024-07-31 21:32:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:35:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0462,  0.0358,  0.0755,  ...,  0.1500,  0.0408, -0.0559],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2070, -1.1992,  2.7051,  ..., -1.8564, -0.9966,  0.0156],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0096,  0.0275, -0.0199,  ...,  0.0575,  0.0148,  0.0210],
        [-0.0628,  0.0138,  0.0099,  ...,  0.0112, -0.0382,  0.0021],
        [ 0.0179,  0.0397, -0.0203,  ..., -0.0404, -0.0238,  0.0010],
        ...,
        [-0.0153, -0.0176, -0.0008,  ...,  0.0056,  0.0008, -0.0201],
        [ 0.0450,  0.0136,  0.0219,  ..., -0.0270, -0.0011, -0.0295],
        [ 0.0408, -0.0216,  0.0194,  ...,  0.0496, -0.0144, -0.0238]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8594, -1.4600,  2.4238,  ..., -1.5742, -1.1885, -0.6870]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:35:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is operating, it has operated
After something is expecting, it has expected
After something is becoming, it has became
After something is agreeing, it has agreed
After something is understanding, it has understood
After something is existing, it has existed
After something is replacing, it has replaced
After something is considering, it has
2024-07-31 21:35:23 root INFO     [order_1_approx] starting weight calculation for After something is expecting, it has expected
After something is replacing, it has replaced
After something is operating, it has operated
After something is considering, it has considered
After something is understanding, it has understood
After something is becoming, it has became
After something is existing, it has existed
After something is agreeing, it has
2024-07-31 21:35:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:38:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0184, -0.0264, -0.0045,  ...,  0.1488, -0.0531,  0.0028],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2051, -3.5449,  0.8623,  ..., -0.4395, -2.0234, -0.5879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0121,  0.0064,  0.0395,  ...,  0.0012, -0.0143,  0.0183],
        [ 0.0184,  0.0349,  0.0154,  ...,  0.0137,  0.0118, -0.0011],
        [ 0.0054,  0.0197, -0.0092,  ..., -0.0064, -0.0061, -0.0271],
        ...,
        [ 0.0020, -0.0153,  0.0028,  ...,  0.0059, -0.0110,  0.0002],
        [ 0.0082,  0.0083, -0.0432,  ..., -0.0073,  0.0126, -0.0197],
        [ 0.0021, -0.0109,  0.0289,  ...,  0.0072, -0.0421, -0.0151]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8203, -3.5488,  1.1992,  ..., -0.4639, -1.9365, -1.1289]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:38:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is expecting, it has expected
After something is replacing, it has replaced
After something is operating, it has operated
After something is considering, it has considered
After something is understanding, it has understood
After something is becoming, it has became
After something is existing, it has existed
After something is agreeing, it has
2024-07-31 21:38:23 root INFO     [order_1_approx] starting weight calculation for After something is agreeing, it has agreed
After something is considering, it has considered
After something is replacing, it has replaced
After something is expecting, it has expected
After something is operating, it has operated
After something is becoming, it has became
After something is existing, it has existed
After something is understanding, it has
2024-07-31 21:38:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:41:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0594,  0.1619,  0.0371,  ...,  0.2432, -0.0859, -0.1289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9004,  1.0605,  1.4170,  ..., -1.0176, -2.6934,  0.6543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0199, -0.0248,  0.0044,  ..., -0.0127, -0.0403,  0.0233],
        [-0.0266,  0.0063, -0.0123,  ...,  0.0065, -0.0113, -0.0169],
        [ 0.0057,  0.0141, -0.0325,  ...,  0.0078, -0.0264, -0.0311],
        ...,
        [ 0.0328, -0.0095, -0.0075,  ...,  0.0307,  0.0042, -0.0210],
        [ 0.0382,  0.0176,  0.0068,  ..., -0.0033,  0.0598, -0.0071],
        [ 0.0086, -0.0045,  0.0247,  ..., -0.0159, -0.0398,  0.0173]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3867,  0.7280,  1.7695,  ..., -0.5518, -2.1328,  0.3591]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:41:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is agreeing, it has agreed
After something is considering, it has considered
After something is replacing, it has replaced
After something is expecting, it has expected
After something is operating, it has operated
After something is becoming, it has became
After something is existing, it has existed
After something is understanding, it has
2024-07-31 21:41:25 root INFO     [order_1_approx] starting weight calculation for After something is operating, it has operated
After something is considering, it has considered
After something is expecting, it has expected
After something is becoming, it has became
After something is agreeing, it has agreed
After something is understanding, it has understood
After something is existing, it has existed
After something is replacing, it has
2024-07-31 21:41:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:44:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0126,  0.0061, -0.0833,  ...,  0.0839,  0.0663,  0.0155],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.7568, -1.0957, -0.7422,  ..., -1.7344, -0.9434,  0.2207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0093, -0.0212, -0.0675,  ..., -0.0074,  0.1479,  0.0936],
        [ 0.1326, -0.0018, -0.1230,  ...,  0.0532,  0.3794,  0.0467],
        [-0.0765,  0.0452,  0.0186,  ..., -0.1006, -0.2585, -0.0970],
        ...,
        [-0.1351,  0.0153,  0.0575,  ..., -0.0557, -0.2952, -0.0309],
        [ 0.0643, -0.0057,  0.0357,  ..., -0.0084,  0.0743,  0.0447],
        [-0.0736,  0.0202,  0.0609,  ...,  0.0331, -0.1865, -0.0473]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4922,  1.2461, -2.2539,  ..., -3.9277, -0.2148, -1.1895]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:44:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is operating, it has operated
After something is considering, it has considered
After something is expecting, it has expected
After something is becoming, it has became
After something is agreeing, it has agreed
After something is understanding, it has understood
After something is existing, it has existed
After something is replacing, it has
2024-07-31 21:44:23 root INFO     [order_1_approx] starting weight calculation for After something is replacing, it has replaced
After something is existing, it has existed
After something is becoming, it has became
After something is expecting, it has expected
After something is agreeing, it has agreed
After something is understanding, it has understood
After something is considering, it has considered
After something is operating, it has
2024-07-31 21:44:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:47:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0341, -0.0927,  0.0274,  ...,  0.0728,  0.0368, -0.0884],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3594, -1.5039,  0.9897,  ..., -2.5859, -2.0703, -0.8184],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0048, -0.0320,  0.0232,  ...,  0.0397, -0.0072,  0.0087],
        [ 0.0514,  0.0735, -0.0158,  ...,  0.0291,  0.0536,  0.0393],
        [-0.0463,  0.0304, -0.0601,  ..., -0.0425, -0.0635,  0.0022],
        ...,
        [ 0.0055,  0.0099, -0.0356,  ...,  0.0040, -0.0068, -0.0141],
        [ 0.0072, -0.0273, -0.0142,  ..., -0.0188, -0.0294,  0.0225],
        [-0.0287, -0.0032,  0.0106,  ..., -0.0148, -0.0245, -0.0019]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3398, -0.7451,  0.3105,  ..., -2.0273, -2.6250, -1.6094]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:47:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is replacing, it has replaced
After something is existing, it has existed
After something is becoming, it has became
After something is expecting, it has expected
After something is agreeing, it has agreed
After something is understanding, it has understood
After something is considering, it has considered
After something is operating, it has
2024-07-31 21:47:22 root INFO     [order_1_approx] starting weight calculation for After something is replacing, it has replaced
After something is considering, it has considered
After something is operating, it has operated
After something is understanding, it has understood
After something is agreeing, it has agreed
After something is becoming, it has became
After something is expecting, it has expected
After something is existing, it has
2024-07-31 21:47:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:50:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0012,  0.2379, -0.0429,  ..., -0.0823, -0.1169, -0.1875],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1816e+00, -8.4033e-01, -1.4648e-03,  ..., -1.3574e+00,
        -1.9922e+00, -1.6719e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0584,  0.0187, -0.0634,  ...,  0.0455, -0.0578,  0.0131],
        [-0.0635,  0.0197, -0.0479,  ..., -0.0184,  0.0103,  0.0138],
        [ 0.0067, -0.0148, -0.0557,  ..., -0.0464, -0.0391, -0.0127],
        ...,
        [-0.0010, -0.0202, -0.0318,  ...,  0.0451,  0.0100, -0.0328],
        [ 0.0463, -0.0677, -0.0002,  ..., -0.0083,  0.0906,  0.0547],
        [-0.0229, -0.0158, -0.0017,  ...,  0.0669, -0.0028, -0.0136]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5586, -0.9160,  0.2659,  ..., -0.9033, -1.3203, -2.1582]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:50:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is replacing, it has replaced
After something is considering, it has considered
After something is operating, it has operated
After something is understanding, it has understood
After something is agreeing, it has agreed
After something is becoming, it has became
After something is expecting, it has expected
After something is existing, it has
2024-07-31 21:50:22 root INFO     [order_1_approx] starting weight calculation for After something is existing, it has existed
After something is replacing, it has replaced
After something is understanding, it has understood
After something is becoming, it has became
After something is operating, it has operated
After something is considering, it has considered
After something is agreeing, it has agreed
After something is expecting, it has
2024-07-31 21:50:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:53:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1788,  0.1598,  0.0625,  ..., -0.0050, -0.0677, -0.0035],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5352, -0.7227, -1.8467,  ..., -1.4893, -3.3945, -2.2793],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.3651e-02, -1.3924e-02,  2.4765e-02,  ..., -2.0111e-02,
         -2.5635e-02,  4.4189e-02],
        [-4.7089e-02,  4.4067e-02,  1.5320e-02,  ...,  2.9465e-02,
         -2.7878e-02,  1.2375e-02],
        [ 3.8574e-02, -1.3222e-02, -1.4572e-03,  ..., -2.6550e-02,
          3.2883e-03, -9.3155e-03],
        ...,
        [ 1.5274e-02, -1.4687e-02,  1.4496e-04,  ..., -6.5994e-03,
         -1.8997e-02, -1.3939e-02],
        [ 3.0518e-05,  4.3854e-02, -2.5513e-02,  ...,  4.1443e-02,
          8.8379e-02,  2.6093e-03],
        [ 3.2379e-02,  1.7227e-02,  1.1414e-02,  ...,  4.8370e-02,
          2.9175e-02, -3.0518e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.7344, -1.2559, -1.3301,  ..., -1.4521, -2.5625, -2.9785]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:53:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is existing, it has existed
After something is replacing, it has replaced
After something is understanding, it has understood
After something is becoming, it has became
After something is operating, it has operated
After something is considering, it has considered
After something is agreeing, it has agreed
After something is expecting, it has
2024-07-31 21:53:20 root INFO     [order_1_approx] starting weight calculation for After something is replacing, it has replaced
After something is considering, it has considered
After something is expecting, it has expected
After something is existing, it has existed
After something is agreeing, it has agreed
After something is understanding, it has understood
After something is operating, it has operated
After something is becoming, it has
2024-07-31 21:53:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:56:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0002,  0.1735,  0.1666,  ...,  0.1541,  0.0380, -0.0734],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6328,  0.8154,  2.4453,  ..., -0.3267,  0.5024, -1.4199],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0024,  0.0356,  0.0347,  ...,  0.0522,  0.1075,  0.0141],
        [ 0.0075,  0.0422,  0.0618,  ...,  0.0037,  0.0500,  0.0064],
        [-0.0313, -0.0210, -0.0519,  ..., -0.0527, -0.0777, -0.0028],
        ...,
        [-0.0084,  0.0044, -0.0374,  ..., -0.0233, -0.0303, -0.0011],
        [-0.0055, -0.0015, -0.0238,  ..., -0.0386, -0.0590, -0.0135],
        [ 0.0068, -0.0067,  0.0028,  ...,  0.0746,  0.0476, -0.0268]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1562,  1.5820,  1.9170,  ..., -0.2075, -0.0659, -1.5723]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:56:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for After something is replacing, it has replaced
After something is considering, it has considered
After something is expecting, it has expected
After something is existing, it has existed
After something is agreeing, it has agreed
After something is understanding, it has understood
After something is operating, it has operated
After something is becoming, it has
2024-07-31 21:56:22 root INFO     total operator prediction time: 1438.7641444206238 seconds
2024-07-31 21:56:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - Ved
2024-07-31 21:56:22 root INFO     building operator verb_inf - Ved
2024-07-31 21:56:22 root INFO     [order_1_approx] starting weight calculation for If the present form is refer, the past form is referred
If the present form is improve, the past form is improved
If the present form is continue, the past form is continued
If the present form is locate, the past form is located
If the present form is appear, the past form is appeared
If the present form is accept, the past form is accepted
If the present form is describe, the past form is described
If the present form is achieve, the past form is
2024-07-31 21:56:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 21:59:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0658,  0.1825, -0.0596,  ...,  0.1578, -0.1108,  0.0605],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2881,  1.4590, -0.4385,  ..., -2.7148, -1.4199, -0.5684],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188,  0.0397, -0.0207,  ...,  0.0184,  0.0602, -0.0020],
        [-0.0295,  0.0094,  0.0052,  ...,  0.0033, -0.0195,  0.0098],
        [ 0.0056,  0.0111, -0.0305,  ..., -0.0169, -0.0451, -0.0047],
        ...,
        [-0.0133,  0.0505, -0.0159,  ..., -0.0143,  0.0247,  0.0159],
        [ 0.0230,  0.0711, -0.0638,  ..., -0.0417,  0.0009, -0.0026],
        [-0.0334, -0.0083, -0.0212,  ...,  0.0543,  0.0074,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1057,  1.0713, -0.8750,  ..., -3.1816, -1.8018, -1.3359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 21:59:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is refer, the past form is referred
If the present form is improve, the past form is improved
If the present form is continue, the past form is continued
If the present form is locate, the past form is located
If the present form is appear, the past form is appeared
If the present form is accept, the past form is accepted
If the present form is describe, the past form is described
If the present form is achieve, the past form is
2024-07-31 21:59:26 root INFO     [order_1_approx] starting weight calculation for If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is achieve, the past form is achieved
If the present form is appear, the past form is appeared
If the present form is refer, the past form is referred
If the present form is accept, the past form is accepted
If the present form is improve, the past form is improved
If the present form is locate, the past form is
2024-07-31 21:59:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:02:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0020,  0.2369, -0.1235,  ...,  0.0130, -0.0368, -0.0876],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1895, -0.8774, -0.9502,  ..., -2.1016, -1.4902, -2.6133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0184, -0.0229, -0.0247,  ...,  0.0184,  0.0440,  0.0381],
        [-0.0054,  0.0307, -0.0425,  ..., -0.0048, -0.0028, -0.0083],
        [ 0.0353, -0.0004, -0.0071,  ..., -0.0200, -0.0071,  0.0012],
        ...,
        [ 0.0069, -0.0152, -0.0081,  ..., -0.0098,  0.0264,  0.0071],
        [-0.0062, -0.0085, -0.0282,  ..., -0.0270,  0.0129,  0.0142],
        [ 0.0100,  0.0522,  0.0185,  ...,  0.0209, -0.0259,  0.0181]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6099, -0.9956, -0.9336,  ..., -1.6309, -1.2031, -2.3281]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:02:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is achieve, the past form is achieved
If the present form is appear, the past form is appeared
If the present form is refer, the past form is referred
If the present form is accept, the past form is accepted
If the present form is improve, the past form is improved
If the present form is locate, the past form is
2024-07-31 22:02:31 root INFO     [order_1_approx] starting weight calculation for If the present form is continue, the past form is continued
If the present form is refer, the past form is referred
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is appear, the past form is appeared
If the present form is improve, the past form is improved
If the present form is locate, the past form is located
If the present form is describe, the past form is
2024-07-31 22:02:31 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:05:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0410,  0.2808,  0.1132,  ...,  0.0032, -0.0484, -0.0551],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6475,  0.2932,  5.0000,  ..., -1.1836, -1.0771, -2.8672],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0314, -0.0100, -0.0099,  ..., -0.0004,  0.0032, -0.0173],
        [-0.0319,  0.0112,  0.0012,  ..., -0.0151, -0.0220,  0.0271],
        [ 0.0507, -0.0089,  0.0045,  ...,  0.0124, -0.0422, -0.0293],
        ...,
        [-0.0066, -0.0101, -0.0048,  ..., -0.0030,  0.0151, -0.0308],
        [ 0.0175, -0.0066, -0.0550,  ..., -0.0151,  0.0147,  0.0223],
        [ 0.0099, -0.0305,  0.0541,  ..., -0.0108, -0.0342,  0.0434]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7085,  0.4526,  4.6367,  ..., -1.4863, -0.8398, -2.5098]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:05:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is continue, the past form is continued
If the present form is refer, the past form is referred
If the present form is achieve, the past form is achieved
If the present form is accept, the past form is accepted
If the present form is appear, the past form is appeared
If the present form is improve, the past form is improved
If the present form is locate, the past form is located
If the present form is describe, the past form is
2024-07-31 22:05:37 root INFO     [order_1_approx] starting weight calculation for If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is locate, the past form is located
If the present form is accept, the past form is accepted
If the present form is refer, the past form is referred
If the present form is achieve, the past form is achieved
If the present form is improve, the past form is improved
If the present form is appear, the past form is
2024-07-31 22:05:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:08:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0206,  0.2386,  0.0312,  ..., -0.0814,  0.0556, -0.1012],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3242,  1.3594,  1.1455,  ...,  0.3511, -3.0410,  0.5615],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0149, -0.0257, -0.0309,  ...,  0.0070,  0.0388, -0.0028],
        [-0.0053,  0.0164, -0.0020,  ..., -0.0007, -0.0198,  0.0118],
        [ 0.0047, -0.0179,  0.0110,  ..., -0.0390, -0.0138,  0.0073],
        ...,
        [-0.0294, -0.0235, -0.0049,  ..., -0.0217,  0.0070,  0.0233],
        [ 0.0564, -0.0088,  0.0095,  ..., -0.0113, -0.0037,  0.0094],
        [ 0.0367,  0.0123,  0.0041,  ...,  0.0231,  0.0007,  0.0225]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0371,  1.2744,  1.3447,  ..., -0.0679, -3.1562,  0.1279]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:08:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is locate, the past form is located
If the present form is accept, the past form is accepted
If the present form is refer, the past form is referred
If the present form is achieve, the past form is achieved
If the present form is improve, the past form is improved
If the present form is appear, the past form is
2024-07-31 22:08:43 root INFO     [order_1_approx] starting weight calculation for If the present form is appear, the past form is appeared
If the present form is improve, the past form is improved
If the present form is accept, the past form is accepted
If the present form is describe, the past form is described
If the present form is achieve, the past form is achieved
If the present form is locate, the past form is located
If the present form is refer, the past form is referred
If the present form is continue, the past form is
2024-07-31 22:08:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:11:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0249, -0.0218, -0.0329,  ..., -0.0224, -0.1148, -0.0386],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1914, -1.1777,  2.2910,  ..., -0.9141,  1.4492, -1.4492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0164,  0.0118, -0.0311,  ..., -0.0048,  0.0486, -0.0386],
        [-0.0200, -0.0021,  0.0129,  ..., -0.0320, -0.0338, -0.0090],
        [ 0.0186,  0.0247, -0.0243,  ..., -0.0344, -0.0093, -0.0217],
        ...,
        [-0.0250,  0.0234,  0.0033,  ...,  0.0107,  0.0241, -0.0073],
        [ 0.0338,  0.0307, -0.0003,  ...,  0.0126,  0.0327,  0.0027],
        [-0.0138, -0.0029,  0.0073,  ...,  0.0093,  0.0080, -0.0052]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6211, -1.3457,  1.6660,  ..., -0.2910,  1.5234, -1.3633]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:11:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is appear, the past form is appeared
If the present form is improve, the past form is improved
If the present form is accept, the past form is accepted
If the present form is describe, the past form is described
If the present form is achieve, the past form is achieved
If the present form is locate, the past form is located
If the present form is refer, the past form is referred
If the present form is continue, the past form is
2024-07-31 22:11:50 root INFO     [order_1_approx] starting weight calculation for If the present form is improve, the past form is improved
If the present form is achieve, the past form is achieved
If the present form is appear, the past form is appeared
If the present form is refer, the past form is referred
If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is locate, the past form is located
If the present form is accept, the past form is
2024-07-31 22:11:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:14:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0530,  0.1499, -0.1163,  ...,  0.1593, -0.0632, -0.0308],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0674,  0.4580, -1.2686,  ..., -0.4097, -2.8789,  0.4141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0226, -0.0334,  0.0044,  ..., -0.0025,  0.0330,  0.0147],
        [ 0.0040,  0.0082, -0.0185,  ..., -0.0019, -0.0420, -0.0025],
        [ 0.0467, -0.0343, -0.0013,  ..., -0.0378, -0.0584, -0.0151],
        ...,
        [ 0.0170, -0.0168, -0.0170,  ..., -0.0152, -0.0103, -0.0076],
        [ 0.0264,  0.0124, -0.0462,  ...,  0.0076,  0.0130,  0.0068],
        [ 0.0223, -0.0160, -0.0213,  ...,  0.0128, -0.0353, -0.0160]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3721,  0.1362, -1.8184,  ..., -0.6621, -2.9414, -0.1494]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:14:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is improve, the past form is improved
If the present form is achieve, the past form is achieved
If the present form is appear, the past form is appeared
If the present form is refer, the past form is referred
If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is locate, the past form is located
If the present form is accept, the past form is
2024-07-31 22:14:59 root INFO     [order_1_approx] starting weight calculation for If the present form is describe, the past form is described
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is appear, the past form is appeared
If the present form is locate, the past form is located
If the present form is continue, the past form is continued
If the present form is improve, the past form is improved
If the present form is refer, the past form is
2024-07-31 22:14:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:18:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0394,  0.0532, -0.0193,  ...,  0.0781, -0.0073, -0.0397],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0391, -1.6084,  0.4658,  ...,  1.3818, -2.3301, -2.5840],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0182, -0.0167,  0.0009,  ..., -0.0251,  0.0345, -0.0016],
        [-0.0417,  0.0210,  0.0165,  ..., -0.0033, -0.0062,  0.0385],
        [ 0.0441, -0.0007,  0.0027,  ..., -0.0219, -0.0128,  0.0014],
        ...,
        [ 0.0028, -0.0015, -0.0206,  ...,  0.0016,  0.0243,  0.0166],
        [ 0.0225, -0.0500, -0.0193,  ..., -0.0073, -0.0474,  0.0361],
        [ 0.0071,  0.0126, -0.0077,  ...,  0.0300, -0.0242,  0.0146]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5952, -2.0742,  0.0195,  ...,  1.6367, -2.3984, -2.2109]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:18:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is describe, the past form is described
If the present form is accept, the past form is accepted
If the present form is achieve, the past form is achieved
If the present form is appear, the past form is appeared
If the present form is locate, the past form is located
If the present form is continue, the past form is continued
If the present form is improve, the past form is improved
If the present form is refer, the past form is
2024-07-31 22:18:07 root INFO     [order_1_approx] starting weight calculation for If the present form is accept, the past form is accepted
If the present form is appear, the past form is appeared
If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is refer, the past form is referred
If the present form is locate, the past form is located
If the present form is achieve, the past form is achieved
If the present form is improve, the past form is
2024-07-31 22:18:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:21:15 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0307,  0.1062,  0.1143,  ...,  0.0118, -0.0572, -0.0033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6455,  0.3960,  1.0195,  ..., -1.1396, -0.4766, -2.1543],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0254,  0.0053, -0.0118,  ...,  0.0103,  0.0068, -0.0042],
        [-0.0547,  0.0125, -0.0015,  ...,  0.0223, -0.0480,  0.0249],
        [ 0.0307,  0.0510, -0.0400,  ..., -0.0004, -0.0345, -0.0037],
        ...,
        [ 0.0051, -0.0064, -0.0076,  ..., -0.0154,  0.0236,  0.0068],
        [ 0.0312,  0.0201, -0.0133,  ..., -0.0016,  0.0131,  0.0197],
        [-0.0163, -0.0342,  0.0378,  ...,  0.0313, -0.0298, -0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6826,  0.4641,  0.9937,  ..., -1.2012, -0.1331, -2.1641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:21:16 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If the present form is accept, the past form is accepted
If the present form is appear, the past form is appeared
If the present form is describe, the past form is described
If the present form is continue, the past form is continued
If the present form is refer, the past form is referred
If the present form is locate, the past form is located
If the present form is achieve, the past form is achieved
If the present form is improve, the past form is
2024-07-31 22:21:16 root INFO     total operator prediction time: 1493.3979349136353 seconds
2024-07-31 22:21:16 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_inf - 3pSg
2024-07-31 22:21:16 root INFO     building operator verb_inf - 3pSg
2024-07-31 22:21:16 root INFO     [order_1_approx] starting weight calculation for I maintain, he maintains
I seem, he seems
I continue, he continues
I avoid, he avoids
I remember, he remembers
I tell, he tells
I achieve, he achieves
I represent, he
2024-07-31 22:21:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:24:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1125,  0.4404, -0.1765,  ..., -0.1031,  0.0005, -0.1493],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4307, -3.3145,  1.0742,  ..., -0.7461, -6.4609, -0.6240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0210, -0.0316, -0.0256,  ...,  0.0189,  0.0626,  0.0080],
        [-0.0016,  0.0773, -0.0113,  ...,  0.0531,  0.1372, -0.0264],
        [-0.0246, -0.0227,  0.0093,  ..., -0.0424, -0.1006,  0.0006],
        ...,
        [ 0.0400,  0.0281, -0.0170,  ...,  0.0197,  0.1223,  0.0022],
        [ 0.0323,  0.0717, -0.0328,  ..., -0.0107,  0.0206, -0.0110],
        [ 0.0427,  0.0361, -0.0124,  ...,  0.0539,  0.0948, -0.0072]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4424, -2.2188, -0.3076,  ...,  1.3027, -7.1406, -0.3274]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:24:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I maintain, he maintains
I seem, he seems
I continue, he continues
I avoid, he avoids
I remember, he remembers
I tell, he tells
I achieve, he achieves
I represent, he
2024-07-31 22:24:17 root INFO     [order_1_approx] starting weight calculation for I represent, he represents
I remember, he remembers
I continue, he continues
I achieve, he achieves
I seem, he seems
I avoid, he avoids
I tell, he tells
I maintain, he
2024-07-31 22:24:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:27:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1693,  0.2173, -0.0776,  ..., -0.1670,  0.0809, -0.1268],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3516, -4.4570, -1.9297,  ..., -0.7349, -5.5742, -0.2207],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0060, -0.0210,  0.0127,  ...,  0.0355, -0.0142, -0.0135],
        [-0.0232,  0.0386,  0.0059,  ...,  0.0090,  0.0046,  0.0332],
        [-0.0140, -0.0390,  0.0206,  ..., -0.0119, -0.0134, -0.0042],
        ...,
        [ 0.0008, -0.0278,  0.0496,  ..., -0.0436,  0.0112,  0.0172],
        [-0.0012,  0.0303, -0.0139,  ...,  0.0027, -0.0588,  0.0906],
        [ 0.0122,  0.0216, -0.0487,  ...,  0.0202, -0.0029, -0.0013]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5723, -4.4688, -1.4639,  ...,  0.2231, -6.3438, -1.5830]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:27:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I represent, he represents
I remember, he remembers
I continue, he continues
I achieve, he achieves
I seem, he seems
I avoid, he avoids
I tell, he tells
I maintain, he
2024-07-31 22:27:19 root INFO     [order_1_approx] starting weight calculation for I avoid, he avoids
I tell, he tells
I seem, he seems
I represent, he represents
I continue, he continues
I maintain, he maintains
I remember, he remembers
I achieve, he
2024-07-31 22:27:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:30:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0348,  0.2305, -0.0885,  ...,  0.0191, -0.0014,  0.0427],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7969, -3.2754, -2.2734,  ..., -1.2783, -9.1719, -1.1904],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0197, -0.0124, -0.0307,  ...,  0.0410, -0.0019, -0.0020],
        [-0.0340,  0.0468,  0.0132,  ..., -0.0468, -0.0128,  0.0076],
        [ 0.0036,  0.0170,  0.0129,  ..., -0.0042,  0.0003, -0.0382],
        ...,
        [ 0.0365,  0.0739,  0.1077,  ..., -0.0735,  0.0106, -0.0095],
        [ 0.0132,  0.0654,  0.0968,  ..., -0.0165, -0.0077,  0.0048],
        [ 0.0123, -0.0164,  0.0047,  ...,  0.0309,  0.0114,  0.0296]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7676, -2.8516, -1.2822,  ...,  0.4248, -7.9023, -1.1133]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:30:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I avoid, he avoids
I tell, he tells
I seem, he seems
I represent, he represents
I continue, he continues
I maintain, he maintains
I remember, he remembers
I achieve, he
2024-07-31 22:30:16 root INFO     [order_1_approx] starting weight calculation for I avoid, he avoids
I remember, he remembers
I seem, he seems
I maintain, he maintains
I continue, he continues
I represent, he represents
I achieve, he achieves
I tell, he
2024-07-31 22:30:16 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:33:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0574,  0.1592,  0.0051,  ..., -0.0800,  0.0654, -0.0507],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([  2.6113,  -3.1680,  -0.2344,  ...,   1.0693, -11.5781,  -1.9316],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0270, -0.0150,  0.0259,  ...,  0.0025, -0.0410,  0.0167],
        [-0.0045,  0.0204, -0.0057,  ..., -0.0023, -0.0011,  0.0031],
        [-0.0215, -0.0043,  0.0282,  ..., -0.0025, -0.0057,  0.0061],
        ...,
        [ 0.0297,  0.0079, -0.0269,  ..., -0.0051,  0.0238,  0.0076],
        [-0.0279, -0.0109,  0.0098,  ...,  0.0136,  0.0316,  0.0143],
        [ 0.0111,  0.0176, -0.0133,  ...,  0.0171,  0.0377, -0.0017]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[  2.7188,  -3.4492,  -0.3232,  ...,   1.2861, -12.0703,  -2.3223]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:33:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I avoid, he avoids
I remember, he remembers
I seem, he seems
I maintain, he maintains
I continue, he continues
I represent, he represents
I achieve, he achieves
I tell, he
2024-07-31 22:33:15 root INFO     [order_1_approx] starting weight calculation for I represent, he represents
I remember, he remembers
I avoid, he avoids
I maintain, he maintains
I continue, he continues
I achieve, he achieves
I tell, he tells
I seem, he
2024-07-31 22:33:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:36:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0873,  0.2854, -0.0663,  ..., -0.1317, -0.0119,  0.0317],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3691, -2.3906, -2.4551,  ...,  1.2959, -6.0977, -1.7197],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0062, -0.0200,  0.0292,  ..., -0.0226, -0.0227,  0.0124],
        [-0.0359,  0.0066, -0.0222,  ..., -0.0264,  0.0202,  0.0162],
        [ 0.0075, -0.0246,  0.0009,  ...,  0.0278, -0.0194, -0.0196],
        ...,
        [ 0.0143,  0.0052,  0.0051,  ..., -0.0002,  0.0030,  0.0179],
        [ 0.0105, -0.0281,  0.0023,  ..., -0.0501,  0.0068,  0.0309],
        [ 0.0072, -0.0043, -0.0144,  ...,  0.0462,  0.0286, -0.0024]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4141, -2.6484, -1.8574,  ...,  2.0273, -6.1406, -2.1660]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:36:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I represent, he represents
I remember, he remembers
I avoid, he avoids
I maintain, he maintains
I continue, he continues
I achieve, he achieves
I tell, he tells
I seem, he
2024-07-31 22:36:14 root INFO     [order_1_approx] starting weight calculation for I seem, he seems
I avoid, he avoids
I tell, he tells
I represent, he represents
I continue, he continues
I maintain, he maintains
I achieve, he achieves
I remember, he
2024-07-31 22:36:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:39:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2092,  0.1832,  0.0153,  ...,  0.0767,  0.0442, -0.0090],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6055, -3.1113, -2.1621,  ..., -0.5635, -6.0469, -2.4395],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0249, -0.0081,  0.0215,  ...,  0.0263,  0.0088,  0.0214],
        [-0.0208,  0.0252, -0.0082,  ..., -0.0176,  0.0149, -0.0032],
        [-0.0022,  0.0199,  0.0008,  ..., -0.0169, -0.0150,  0.0010],
        ...,
        [-0.0028,  0.0019, -0.0066,  ..., -0.0026,  0.0118, -0.0049],
        [ 0.0083, -0.0042, -0.0148,  ..., -0.0385, -0.0193,  0.0293],
        [ 0.0218,  0.0127, -0.0270,  ..., -0.0075,  0.0193, -0.0168]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8818, -3.0234, -1.8652,  ..., -0.2192, -6.6289, -2.6445]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:39:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I seem, he seems
I avoid, he avoids
I tell, he tells
I represent, he represents
I continue, he continues
I maintain, he maintains
I achieve, he achieves
I remember, he
2024-07-31 22:39:11 root INFO     [order_1_approx] starting weight calculation for I avoid, he avoids
I represent, he represents
I maintain, he maintains
I seem, he seems
I remember, he remembers
I tell, he tells
I achieve, he achieves
I continue, he
2024-07-31 22:39:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:42:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0540,  0.0598, -0.1697,  ..., -0.0656,  0.0038, -0.0569],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9766, -5.0469, -1.4844,  ..., -0.7686, -4.4727, -0.9160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0077,  0.0080,  0.0004,  ...,  0.0104, -0.0224, -0.0021],
        [-0.0234,  0.0260,  0.0109,  ..., -0.0040,  0.0129, -0.0383],
        [-0.0067,  0.0203, -0.0176,  ..., -0.0346,  0.0164, -0.0326],
        ...,
        [ 0.0127,  0.0213,  0.0376,  ...,  0.0121, -0.0143,  0.0230],
        [-0.0128,  0.0393, -0.0222,  ..., -0.0367,  0.0001,  0.0085],
        [ 0.0104, -0.0039,  0.0029,  ..., -0.0012,  0.0054,  0.0167]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6465, -5.1289, -1.7090,  ..., -0.2388, -4.5703, -1.2764]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:42:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I avoid, he avoids
I represent, he represents
I maintain, he maintains
I seem, he seems
I remember, he remembers
I tell, he tells
I achieve, he achieves
I continue, he
2024-07-31 22:42:09 root INFO     [order_1_approx] starting weight calculation for I tell, he tells
I continue, he continues
I remember, he remembers
I achieve, he achieves
I maintain, he maintains
I seem, he seems
I represent, he represents
I avoid, he
2024-07-31 22:42:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:45:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2445,  0.2170, -0.0012,  ...,  0.0066,  0.0458,  0.0867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2363, -2.3125, -3.1191,  ...,  1.3496, -7.2539, -0.6582],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0296, -0.0109, -0.0019,  ...,  0.0297,  0.0285, -0.0117],
        [-0.0359,  0.0618, -0.0107,  ..., -0.0206,  0.0181,  0.0098],
        [-0.0064, -0.0322,  0.0173,  ..., -0.0008,  0.0342, -0.0225],
        ...,
        [-0.0109, -0.0271,  0.0036,  ..., -0.0145, -0.0047,  0.0179],
        [ 0.0164,  0.0361,  0.0487,  ..., -0.0089, -0.0066,  0.0070],
        [ 0.0148,  0.0478, -0.0273,  ...,  0.0211, -0.0041, -0.0190]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6250, -2.0449, -2.8809,  ...,  1.3457, -7.2695, -1.0322]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:45:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for I tell, he tells
I continue, he continues
I remember, he remembers
I achieve, he achieves
I maintain, he maintains
I seem, he seems
I represent, he represents
I avoid, he
2024-07-31 22:45:04 root INFO     total operator prediction time: 1428.4220950603485 seconds
2024-07-31 22:45:04 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_Ving - 3pSg
2024-07-31 22:45:04 root INFO     building operator verb_Ving - 3pSg
2024-07-31 22:45:04 root INFO     [order_1_approx] starting weight calculation for When something is receiving, it receives
When something is seeming, it seems
When something is promoting, it promotes
When something is allowing, it allows
When something is becoming, it becomes
When something is reducing, it reduces
When something is describing, it describes
When something is referring, it
2024-07-31 22:45:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:48:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0719, -0.0372, -0.0297,  ...,  0.0708,  0.0034,  0.0216],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3062, -4.3281,  1.8154,  ...,  1.6250, -4.9766, -0.8594],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0576, -0.0300,  0.0351,  ..., -0.0049, -0.0787,  0.0261],
        [ 0.0621,  0.1024, -0.0745,  ...,  0.0556,  0.4192,  0.0217],
        [-0.0033, -0.0616,  0.0416,  ..., -0.0607, -0.2242, -0.0825],
        ...,
        [ 0.0064, -0.0021, -0.0229,  ..., -0.0078,  0.0544,  0.0391],
        [ 0.0266, -0.0178,  0.0422,  ..., -0.0060, -0.1707, -0.0243],
        [ 0.1088,  0.0700, -0.0184,  ...,  0.0750,  0.2554, -0.0456]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5908, -1.3594,  0.7939,  ...,  2.4570, -6.6133,  0.3291]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:48:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is receiving, it receives
When something is seeming, it seems
When something is promoting, it promotes
When something is allowing, it allows
When something is becoming, it becomes
When something is reducing, it reduces
When something is describing, it describes
When something is referring, it
2024-07-31 22:48:06 root INFO     [order_1_approx] starting weight calculation for When something is seeming, it seems
When something is reducing, it reduces
When something is receiving, it receives
When something is allowing, it allows
When something is referring, it refers
When something is becoming, it becomes
When something is describing, it describes
When something is promoting, it
2024-07-31 22:48:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:51:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0760,  0.0997, -0.0166,  ...,  0.2186,  0.1051, -0.1013],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6875, -4.3867, -0.6543,  ..., -0.0430, -7.6875, -0.1113],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.4223e-03, -4.6783e-02, -1.1971e-02,  ..., -8.5144e-03,
         -1.0876e-01,  3.0167e-02],
        [-4.3640e-03,  4.5959e-02, -1.5099e-02,  ...,  2.5696e-02,
          8.6426e-02,  3.4485e-03],
        [ 1.7166e-02,  5.2452e-04, -1.5137e-02,  ..., -1.9897e-02,
         -3.4180e-02, -7.0076e-03],
        ...,
        [-1.9852e-02, -5.4703e-03, -1.9043e-02,  ...,  1.4648e-02,
          3.4119e-02,  2.3270e-02],
        [ 6.2332e-03,  3.2745e-02, -2.8477e-03,  ..., -8.3771e-03,
         -2.3056e-02,  4.8485e-03],
        [ 1.8127e-02, -8.3923e-05, -1.7273e-02,  ...,  2.6184e-02,
         -8.5678e-03,  2.7752e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.8203, -3.6328, -0.2830,  ...,  0.2168, -8.0781, -0.1925]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:51:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is seeming, it seems
When something is reducing, it reduces
When something is receiving, it receives
When something is allowing, it allows
When something is referring, it refers
When something is becoming, it becomes
When something is describing, it describes
When something is promoting, it
2024-07-31 22:51:02 root INFO     [order_1_approx] starting weight calculation for When something is seeming, it seems
When something is allowing, it allows
When something is reducing, it reduces
When something is referring, it refers
When something is describing, it describes
When something is becoming, it becomes
When something is promoting, it promotes
When something is receiving, it
2024-07-31 22:51:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:54:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0174,  0.3740,  0.0485,  ...,  0.0668, -0.0978, -0.1670],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1992, -2.4727, -1.9326,  ..., -1.4805, -4.7500, -3.2500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.6747e-03, -1.5381e-02,  1.7197e-02,  ...,  4.3030e-03,
          4.5959e-02,  4.8096e-02],
        [-1.9714e-02,  4.2572e-03,  4.4739e-02,  ...,  1.7487e-02,
          8.7219e-02,  4.5502e-02],
        [ 8.0872e-03, -4.3030e-03, -1.8524e-02,  ..., -1.2627e-02,
         -2.6779e-02, -3.4088e-02],
        ...,
        [ 1.7380e-02, -3.0518e-05,  5.2399e-02,  ...,  2.4460e-02,
          9.1309e-02,  3.8452e-02],
        [ 2.1667e-02,  5.8746e-03, -5.7770e-02,  ..., -4.0894e-02,
         -1.0632e-01, -5.0446e-02],
        [ 1.1925e-02,  2.4300e-03, -2.3575e-02,  ...,  1.1688e-02,
         -7.5531e-04, -1.8311e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3794, -1.9922, -1.9160,  ..., -0.8247, -5.3398, -3.4062]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:54:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is seeming, it seems
When something is allowing, it allows
When something is reducing, it reduces
When something is referring, it refers
When something is describing, it describes
When something is becoming, it becomes
When something is promoting, it promotes
When something is receiving, it
2024-07-31 22:54:04 root INFO     [order_1_approx] starting weight calculation for When something is promoting, it promotes
When something is referring, it refers
When something is receiving, it receives
When something is reducing, it reduces
When something is seeming, it seems
When something is describing, it describes
When something is allowing, it allows
When something is becoming, it
2024-07-31 22:54:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:56:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0220,  0.2058,  0.0999,  ...,  0.1543,  0.0743, -0.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8984, -3.1582,  0.8223,  ...,  1.5244, -1.0078, -2.3145],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0070,  0.0178,  0.0146,  ...,  0.0221,  0.0336,  0.0248],
        [-0.0227, -0.0053, -0.0008,  ..., -0.0168, -0.0015,  0.0101],
        [-0.0150, -0.0010, -0.0148,  ..., -0.0243, -0.0495,  0.0163],
        ...,
        [ 0.0322,  0.0136, -0.0036,  ...,  0.0064,  0.0066,  0.0153],
        [-0.0123,  0.0774, -0.0270,  ..., -0.0166, -0.0757, -0.0089],
        [ 0.0005, -0.0090, -0.0024,  ...,  0.0334,  0.0051, -0.0097]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6289, -2.8906,  0.6274,  ...,  1.6670, -0.9844, -2.2578]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:57:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is promoting, it promotes
When something is referring, it refers
When something is receiving, it receives
When something is reducing, it reduces
When something is seeming, it seems
When something is describing, it describes
When something is allowing, it allows
When something is becoming, it
2024-07-31 22:57:00 root INFO     [order_1_approx] starting weight calculation for When something is allowing, it allows
When something is reducing, it reduces
When something is describing, it describes
When something is receiving, it receives
When something is promoting, it promotes
When something is becoming, it becomes
When something is referring, it refers
When something is seeming, it
2024-07-31 22:57:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 22:59:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.0292, 0.2057, 0.2301,  ..., 0.0319, 0.0130, 0.0610], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2617, -2.6445, -1.8906,  ...,  1.6074, -3.3496, -2.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0247, -0.0375, -0.0053,  ...,  0.0270,  0.0073,  0.0173],
        [ 0.0159,  0.0191,  0.0179,  ..., -0.0055,  0.0131,  0.0223],
        [ 0.0163,  0.0082,  0.0146,  ...,  0.0154,  0.0049, -0.0028],
        ...,
        [-0.0003,  0.0297,  0.0011,  ..., -0.0093,  0.0218,  0.0231],
        [-0.0422,  0.0067,  0.0072,  ...,  0.0070, -0.0978, -0.1023],
        [ 0.0016,  0.0141,  0.0161,  ...,  0.0220,  0.0138, -0.0085]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2793, -2.2695, -1.6113,  ...,  2.1152, -4.8633, -1.7676]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 22:59:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is allowing, it allows
When something is reducing, it reduces
When something is describing, it describes
When something is receiving, it receives
When something is promoting, it promotes
When something is becoming, it becomes
When something is referring, it refers
When something is seeming, it
2024-07-31 22:59:59 root INFO     [order_1_approx] starting weight calculation for When something is describing, it describes
When something is referring, it refers
When something is seeming, it seems
When something is promoting, it promotes
When something is becoming, it becomes
When something is allowing, it allows
When something is receiving, it receives
When something is reducing, it
2024-07-31 22:59:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:02:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0105,  0.0487,  0.1211,  ...,  0.1694,  0.0474, -0.1106],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2334, -2.5000,  0.3125,  ..., -3.0820, -5.5703, -4.3398],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0081, -0.0134, -0.0029,  ..., -0.0273,  0.0372,  0.0522],
        [ 0.0378,  0.0447,  0.0232,  ..., -0.0444,  0.2432,  0.1279],
        [-0.0082,  0.0107, -0.0135,  ...,  0.0218, -0.1112, -0.0574],
        ...,
        [ 0.0425,  0.0199,  0.0484,  ..., -0.0170,  0.2024,  0.1238],
        [ 0.0178,  0.0100, -0.0297,  ...,  0.0259, -0.1443, -0.0908],
        [ 0.0414,  0.0209, -0.0050,  ...,  0.0303,  0.1055,  0.0131]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3662,  0.9648, -1.1562,  ..., -0.0977, -7.7109, -3.2227]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:02:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is describing, it describes
When something is referring, it refers
When something is seeming, it seems
When something is promoting, it promotes
When something is becoming, it becomes
When something is allowing, it allows
When something is receiving, it receives
When something is reducing, it
2024-07-31 23:02:52 root INFO     [order_1_approx] starting weight calculation for When something is referring, it refers
When something is allowing, it allows
When something is becoming, it becomes
When something is receiving, it receives
When something is promoting, it promotes
When something is reducing, it reduces
When something is seeming, it seems
When something is describing, it
2024-07-31 23:02:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:05:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0395,  0.1589,  0.0947,  ...,  0.0825,  0.1066, -0.1038],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1680, -4.9102,  4.2930,  ...,  0.9902, -4.1680, -2.1270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0019, -0.0211, -0.0031,  ..., -0.0172, -0.0330,  0.0019],
        [ 0.0050,  0.0217, -0.0082,  ..., -0.0012,  0.0246,  0.0222],
        [-0.0067,  0.0198,  0.0487,  ...,  0.0128, -0.1188, -0.0251],
        ...,
        [ 0.0436,  0.0120, -0.0007,  ...,  0.0170,  0.0536, -0.0039],
        [ 0.0029, -0.0024, -0.0648,  ..., -0.0264,  0.0451, -0.0151],
        [ 0.0023, -0.0326,  0.0352,  ...,  0.0044, -0.0605,  0.0152]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4844, -4.3047,  3.4121,  ...,  1.5186, -3.7266, -2.4688]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:05:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is referring, it refers
When something is allowing, it allows
When something is becoming, it becomes
When something is receiving, it receives
When something is promoting, it promotes
When something is reducing, it reduces
When something is seeming, it seems
When something is describing, it
2024-07-31 23:05:52 root INFO     [order_1_approx] starting weight calculation for When something is reducing, it reduces
When something is describing, it describes
When something is seeming, it seems
When something is receiving, it receives
When something is referring, it refers
When something is becoming, it becomes
When something is promoting, it promotes
When something is allowing, it
2024-07-31 23:05:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:08:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0076,  0.0999,  0.1842,  ...,  0.0596,  0.0015, -0.1500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3145, -4.5664, -0.9102,  ..., -1.0771, -6.1758,  0.3496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0055, -0.0049, -0.0122,  ...,  0.0123, -0.0138,  0.0086],
        [ 0.0019,  0.0468,  0.0053,  ...,  0.0362,  0.0673,  0.0124],
        [ 0.0133, -0.0302,  0.0023,  ..., -0.0192, -0.0348, -0.0129],
        ...,
        [ 0.0087, -0.0067,  0.0213,  ..., -0.0180,  0.0179,  0.0357],
        [ 0.0331,  0.0606, -0.0133,  ..., -0.0063, -0.0181, -0.0111],
        [ 0.0005, -0.0275, -0.0209,  ...,  0.0425, -0.0400, -0.0307]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4941, -3.9023, -0.4304,  ..., -0.1953, -6.5547,  0.2783]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:08:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When something is reducing, it reduces
When something is describing, it describes
When something is seeming, it seems
When something is receiving, it receives
When something is referring, it refers
When something is becoming, it becomes
When something is promoting, it promotes
When something is allowing, it
2024-07-31 23:08:52 root INFO     total operator prediction time: 1427.5301055908203 seconds
2024-07-31 23:08:52 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun - plural_reg
2024-07-31 23:08:52 root INFO     building operator noun - plural_reg
2024-07-31 23:08:52 root INFO     [order_1_approx] starting weight calculation for The plural form of period is periods
The plural form of friend is friends
The plural form of village is villages
The plural form of hour is hours
The plural form of fact is facts
The plural form of office is offices
The plural form of population is populations
The plural form of government is
2024-07-31 23:08:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:11:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0455,  0.0033,  0.0611,  ...,  0.0151, -0.1130, -0.1724],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3604, -1.4766,  0.2756,  ..., -1.6953, -0.5977, -2.3945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0064,  0.0116, -0.0317,  ...,  0.0442, -0.0161,  0.0192],
        [-0.0090,  0.0076,  0.0224,  ..., -0.0025,  0.0183,  0.0229],
        [-0.0341,  0.0142, -0.0181,  ...,  0.0032, -0.0147, -0.0068],
        ...,
        [-0.0072,  0.0140,  0.0222,  ...,  0.0131, -0.0420,  0.0097],
        [ 0.0027, -0.0157, -0.0421,  ..., -0.0186, -0.0036, -0.0250],
        [ 0.0049,  0.0108,  0.0245,  ...,  0.0003, -0.0369,  0.0172]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3311, -0.8779,  0.5288,  ..., -1.7168, -0.7119, -2.1074]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:11:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of period is periods
The plural form of friend is friends
The plural form of village is villages
The plural form of hour is hours
The plural form of fact is facts
The plural form of office is offices
The plural form of population is populations
The plural form of government is
2024-07-31 23:11:53 root INFO     [order_1_approx] starting weight calculation for The plural form of government is governments
The plural form of population is populations
The plural form of friend is friends
The plural form of village is villages
The plural form of hour is hours
The plural form of period is periods
The plural form of fact is facts
The plural form of office is
2024-07-31 23:11:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:14:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0421,  0.0173, -0.0398,  ...,  0.0521, -0.1344, -0.1824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3633, -2.8789,  1.5791,  ...,  0.0606,  0.0049, -1.3271],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0305, -0.0466, -0.0123,  ..., -0.0006, -0.0268,  0.0149],
        [ 0.0293, -0.0374, -0.0184,  ...,  0.0348,  0.0168,  0.0203],
        [ 0.0252,  0.0078, -0.0036,  ...,  0.0168, -0.0056,  0.0005],
        ...,
        [ 0.0276, -0.0028,  0.0248,  ...,  0.0374, -0.0253,  0.0306],
        [-0.0399,  0.0865,  0.0273,  ..., -0.0275,  0.0155, -0.0124],
        [ 0.0032, -0.0267, -0.0042,  ...,  0.0256,  0.0143,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5742, -1.5488,  1.4854,  ...,  1.0400, -2.7070,  0.2480]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:14:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of government is governments
The plural form of population is populations
The plural form of friend is friends
The plural form of village is villages
The plural form of hour is hours
The plural form of period is periods
The plural form of fact is facts
The plural form of office is
2024-07-31 23:14:53 root INFO     [order_1_approx] starting weight calculation for The plural form of office is offices
The plural form of government is governments
The plural form of period is periods
The plural form of village is villages
The plural form of fact is facts
The plural form of population is populations
The plural form of hour is hours
The plural form of friend is
2024-07-31 23:14:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:17:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0926, -0.0820, -0.0306,  ..., -0.0086, -0.0618, -0.1118],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1738, -2.1328,  2.8750,  ...,  0.0291, -0.9043, -1.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0681, -0.0234, -0.0141,  ..., -0.0001, -0.0234, -0.0050],
        [-0.0019, -0.0179, -0.0116,  ...,  0.0233, -0.0047, -0.0215],
        [-0.0251, -0.0061, -0.0240,  ...,  0.0300,  0.0028,  0.0082],
        ...,
        [-0.0208,  0.0052, -0.0019,  ...,  0.0419, -0.0227, -0.0028],
        [ 0.0345, -0.0145,  0.0117,  ...,  0.0117,  0.0026, -0.0120],
        [-0.0291,  0.0161,  0.0130,  ...,  0.0248, -0.0168, -0.0004]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0898, -2.1113,  3.1367,  ...,  0.3679, -2.4922, -0.4365]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:17:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of office is offices
The plural form of government is governments
The plural form of period is periods
The plural form of village is villages
The plural form of fact is facts
The plural form of population is populations
The plural form of hour is hours
The plural form of friend is
2024-07-31 23:17:51 root INFO     [order_1_approx] starting weight calculation for The plural form of friend is friends
The plural form of period is periods
The plural form of village is villages
The plural form of fact is facts
The plural form of office is offices
The plural form of hour is hours
The plural form of government is governments
The plural form of population is
2024-07-31 23:17:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:20:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0481, -0.1479,  0.1351,  ..., -0.0293,  0.0850, -0.1760],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4492, -3.7734,  0.8418,  ..., -1.5391, -2.8613, -1.7969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0302, -0.0082, -0.0463,  ..., -0.0115, -0.0107, -0.0589],
        [ 0.0088,  0.0356,  0.0929,  ...,  0.0038,  0.0182,  0.0829],
        [ 0.0095,  0.0098,  0.0124,  ..., -0.0329,  0.0052, -0.0038],
        ...,
        [-0.0024, -0.0213,  0.0576,  ...,  0.0234,  0.0180,  0.0156],
        [-0.0112, -0.0187, -0.0474,  ..., -0.0075, -0.0219, -0.0025],
        [ 0.0226,  0.0325,  0.0352,  ...,  0.0462,  0.0063,  0.0135]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3652, -2.8477,  1.4414,  ..., -1.0020, -3.8242, -0.8628]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:20:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of friend is friends
The plural form of period is periods
The plural form of village is villages
The plural form of fact is facts
The plural form of office is offices
The plural form of hour is hours
The plural form of government is governments
The plural form of population is
2024-07-31 23:20:51 root INFO     [order_1_approx] starting weight calculation for The plural form of fact is facts
The plural form of hour is hours
The plural form of village is villages
The plural form of friend is friends
The plural form of office is offices
The plural form of government is governments
The plural form of population is populations
The plural form of period is
2024-07-31 23:20:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:23:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1138, -0.0829,  0.0160,  ..., -0.0934, -0.1624, -0.2279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.0126, -2.9453,  2.2383,  ..., -1.0586, -0.3506, -0.8970],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331, -0.0527, -0.0193,  ..., -0.0146,  0.0098,  0.0293],
        [-0.0114,  0.0513,  0.0059,  ..., -0.0014, -0.0182,  0.0225],
        [ 0.0043,  0.0234, -0.0447,  ..., -0.0108, -0.0353,  0.0013],
        ...,
        [-0.0226,  0.0476,  0.0325,  ...,  0.0668, -0.0118,  0.0138],
        [-0.0601,  0.0006,  0.0381,  ...,  0.0585, -0.0123,  0.0641],
        [-0.0082, -0.0060,  0.0045,  ..., -0.0080,  0.0384, -0.0236]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0942, -1.4551,  2.5859,  ..., -1.8086, -2.0156,  0.3833]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:23:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of fact is facts
The plural form of hour is hours
The plural form of village is villages
The plural form of friend is friends
The plural form of office is offices
The plural form of government is governments
The plural form of population is populations
The plural form of period is
2024-07-31 23:23:52 root INFO     [order_1_approx] starting weight calculation for The plural form of friend is friends
The plural form of period is periods
The plural form of government is governments
The plural form of population is populations
The plural form of office is offices
The plural form of hour is hours
The plural form of fact is facts
The plural form of village is
2024-07-31 23:23:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:26:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0214,  0.2284, -0.0652,  ..., -0.0717, -0.1417,  0.0403],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7573, -5.1523,  2.7441,  ..., -2.0547,  0.9653, -0.7920],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0560, -0.0361, -0.0236,  ..., -0.0039, -0.0415,  0.0260],
        [-0.0044, -0.0475,  0.0525,  ...,  0.0358,  0.0351,  0.0100],
        [-0.0082,  0.0323,  0.0074,  ..., -0.0291, -0.0330,  0.0275],
        ...,
        [-0.0069,  0.0225,  0.0406,  ...,  0.0353,  0.0017, -0.0026],
        [ 0.0468,  0.0087, -0.0389,  ..., -0.0251, -0.0194, -0.0300],
        [-0.0404,  0.0427,  0.0519,  ...,  0.0262,  0.0094, -0.0073]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9429, -2.5527,  2.1094,  ..., -0.7480, -1.2402,  0.6602]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:26:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of friend is friends
The plural form of period is periods
The plural form of government is governments
The plural form of population is populations
The plural form of office is offices
The plural form of hour is hours
The plural form of fact is facts
The plural form of village is
2024-07-31 23:26:52 root INFO     [order_1_approx] starting weight calculation for The plural form of fact is facts
The plural form of government is governments
The plural form of period is periods
The plural form of office is offices
The plural form of friend is friends
The plural form of population is populations
The plural form of village is villages
The plural form of hour is
2024-07-31 23:26:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:29:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1815, -0.1196,  0.0876,  ...,  0.0754, -0.0132, -0.0690],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2852, -2.7246,  1.2012,  ..., -1.7461,  0.7090, -2.4766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0266, -0.0640, -0.0636,  ...,  0.0565,  0.0639,  0.0292],
        [ 0.0162,  0.0276,  0.0314,  ..., -0.0309, -0.0266, -0.0286],
        [ 0.0028,  0.0149,  0.0357,  ..., -0.0037, -0.0271,  0.0236],
        ...,
        [-0.0229,  0.0233,  0.0425,  ...,  0.0046, -0.0552, -0.0204],
        [ 0.0015, -0.0640, -0.0523,  ...,  0.0521,  0.0833,  0.0201],
        [-0.0116,  0.0280,  0.0513,  ..., -0.0385, -0.0307, -0.0211]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.3828, -1.1475,  1.8896,  ...,  1.0566, -3.0293, -0.0039]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:29:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of fact is facts
The plural form of government is governments
The plural form of period is periods
The plural form of office is offices
The plural form of friend is friends
The plural form of population is populations
The plural form of village is villages
The plural form of hour is
2024-07-31 23:29:52 root INFO     [order_1_approx] starting weight calculation for The plural form of population is populations
The plural form of hour is hours
The plural form of period is periods
The plural form of village is villages
The plural form of friend is friends
The plural form of government is governments
The plural form of office is offices
The plural form of fact is
2024-07-31 23:29:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:32:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0073, -0.0210, -0.1138,  ..., -0.0776, -0.0698, -0.1214],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4062, -3.0605,  1.7559,  ...,  0.8740, -1.5732, -2.0762],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0693, -0.0325,  0.0388,  ..., -0.0070, -0.0135,  0.0024],
        [-0.0961,  0.0258, -0.0363,  ..., -0.0225,  0.0316, -0.0291],
        [-0.0010, -0.0092, -0.0068,  ...,  0.0063,  0.0066, -0.0113],
        ...,
        [ 0.0048,  0.0148,  0.0283,  ..., -0.0076,  0.0176,  0.0198],
        [ 0.0306,  0.0017,  0.0189,  ...,  0.0544, -0.0049, -0.0069],
        [-0.0834, -0.0334, -0.0439,  ...,  0.0209, -0.0269,  0.0281]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3496, -1.8145,  1.6631,  ...,  0.7012, -2.8320, -1.0977]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:32:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The plural form of population is populations
The plural form of hour is hours
The plural form of period is periods
The plural form of village is villages
The plural form of friend is friends
The plural form of government is governments
The plural form of office is offices
The plural form of fact is
2024-07-31 23:32:49 root INFO     total operator prediction time: 1437.6824696063995 seconds
2024-07-31 23:32:49 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb_3pSg - Ved
2024-07-31 23:32:49 root INFO     building operator verb_3pSg - Ved
2024-07-31 23:32:49 root INFO     [order_1_approx] starting weight calculation for When he allows something, something has been allowed
When he proposes something, something has been proposed
When he fails something, something has been failed
When he intends something, something has been intended
When he creates something, something has been created
When he becomes something, something has been became
When he introduces something, something has been introduced
When he spends something, something has been
2024-07-31 23:32:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:35:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1410,  0.1086,  0.0874,  ...,  0.1188, -0.0252, -0.2247],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4316, -1.4932, -2.0781,  ..., -1.3906, -2.8047, -1.3711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0196, -0.0063,  0.0184,  ..., -0.0349,  0.0114, -0.0015],
        [-0.0191,  0.0222,  0.0124,  ...,  0.0065,  0.0004,  0.0152],
        [-0.0097, -0.0191, -0.0281,  ..., -0.0195,  0.0041, -0.0203],
        ...,
        [ 0.0152, -0.0122, -0.0124,  ...,  0.0010,  0.0101,  0.0131],
        [-0.0061, -0.0141, -0.0201,  ...,  0.0028, -0.0252, -0.0178],
        [-0.0195,  0.0023,  0.0108,  ..., -0.0047,  0.0459, -0.0018]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1934, -1.8486, -1.9756,  ..., -1.2998, -2.8164, -1.3174]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:35:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he allows something, something has been allowed
When he proposes something, something has been proposed
When he fails something, something has been failed
When he intends something, something has been intended
When he creates something, something has been created
When he becomes something, something has been became
When he introduces something, something has been introduced
When he spends something, something has been
2024-07-31 23:35:45 root INFO     [order_1_approx] starting weight calculation for When he allows something, something has been allowed
When he proposes something, something has been proposed
When he creates something, something has been created
When he introduces something, something has been introduced
When he spends something, something has been spent
When he fails something, something has been failed
When he becomes something, something has been became
When he intends something, something has been
2024-07-31 23:35:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:38:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1385,  0.2067, -0.0431,  ..., -0.1034,  0.0119, -0.1338],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8740,  1.3945, -0.5439,  ..., -0.9834, -2.8457, -3.4824],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0066, -0.0061, -0.0118,  ..., -0.0127,  0.0067, -0.0056],
        [-0.0247,  0.0273, -0.0241,  ..., -0.0463,  0.0085,  0.0064],
        [ 0.0133, -0.0113, -0.0016,  ..., -0.0207, -0.0126, -0.0486],
        ...,
        [-0.0004,  0.0060, -0.0009,  ..., -0.0188,  0.0233,  0.0214],
        [-0.0065,  0.0252,  0.0085,  ...,  0.0511,  0.0108, -0.0243],
        [-0.0027, -0.0244,  0.0298,  ...,  0.0407,  0.0376, -0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7578,  1.2412, -0.4575,  ..., -0.6167, -2.7266, -3.7949]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:38:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he allows something, something has been allowed
When he proposes something, something has been proposed
When he creates something, something has been created
When he introduces something, something has been introduced
When he spends something, something has been spent
When he fails something, something has been failed
When he becomes something, something has been became
When he intends something, something has been
2024-07-31 23:38:42 root INFO     [order_1_approx] starting weight calculation for When he proposes something, something has been proposed
When he spends something, something has been spent
When he allows something, something has been allowed
When he becomes something, something has been became
When he intends something, something has been intended
When he fails something, something has been failed
When he introduces something, something has been introduced
When he creates something, something has been
2024-07-31 23:38:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:41:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0568,  0.2180,  0.0393,  ...,  0.1313, -0.1199, -0.0806],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3018, -1.0566,  1.5059,  ...,  0.1616, -3.2812, -0.0176],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0206, -0.0231, -0.0270,  ...,  0.0201, -0.0093, -0.0008],
        [-0.0123,  0.0175, -0.0046,  ...,  0.0063,  0.0069, -0.0038],
        [-0.0012,  0.0133, -0.0214,  ..., -0.0059, -0.0071, -0.0047],
        ...,
        [ 0.0199,  0.0211, -0.0106,  ...,  0.0108,  0.0084,  0.0032],
        [ 0.0074,  0.0294,  0.0033,  ..., -0.0157,  0.0065, -0.0077],
        [-0.0006, -0.0097, -0.0038,  ...,  0.0097,  0.0061,  0.0114]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3469, -1.3926,  1.7090,  ...,  0.3682, -3.2520,  0.2086]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:41:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he proposes something, something has been proposed
When he spends something, something has been spent
When he allows something, something has been allowed
When he becomes something, something has been became
When he intends something, something has been intended
When he fails something, something has been failed
When he introduces something, something has been introduced
When he creates something, something has been
2024-07-31 23:41:41 root INFO     [order_1_approx] starting weight calculation for When he intends something, something has been intended
When he proposes something, something has been proposed
When he creates something, something has been created
When he spends something, something has been spent
When he becomes something, something has been became
When he allows something, something has been allowed
When he introduces something, something has been introduced
When he fails something, something has been
2024-07-31 23:41:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:44:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1158,  0.0276, -0.0757,  ..., -0.0869,  0.0977, -0.1732],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9482, -0.3691,  2.9180,  ..., -1.1533, -2.7402, -1.8281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0489, -0.0481,  0.0634,  ...,  0.0277,  0.0117, -0.0303],
        [-0.0024,  0.0263, -0.0187,  ...,  0.0255, -0.0054,  0.0343],
        [ 0.0228,  0.0351, -0.0939,  ..., -0.0141, -0.0150,  0.0102],
        ...,
        [ 0.0052,  0.0068, -0.0589,  ..., -0.0120, -0.0145,  0.0044],
        [ 0.0276,  0.0907, -0.0294,  ..., -0.0199, -0.0146, -0.0054],
        [-0.0193,  0.0287,  0.0510,  ...,  0.0256,  0.0359, -0.0087]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5449, -0.3870,  2.0703,  ..., -1.7412, -3.1113, -1.2988]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:44:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he intends something, something has been intended
When he proposes something, something has been proposed
When he creates something, something has been created
When he spends something, something has been spent
When he becomes something, something has been became
When he allows something, something has been allowed
When he introduces something, something has been introduced
When he fails something, something has been
2024-07-31 23:44:39 root INFO     [order_1_approx] starting weight calculation for When he becomes something, something has been became
When he intends something, something has been intended
When he creates something, something has been created
When he introduces something, something has been introduced
When he spends something, something has been spent
When he allows something, something has been allowed
When he fails something, something has been failed
When he proposes something, something has been
2024-07-31 23:44:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:47:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0433,  0.0606, -0.0881,  ...,  0.0065,  0.0338, -0.0606],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7949, -1.7695,  1.6689,  ..., -0.3330, -2.3164,  0.8047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0287, -0.0446,  0.0376,  ..., -0.0302, -0.0594,  0.0236],
        [-0.0034,  0.0123, -0.0027,  ...,  0.0048,  0.0255,  0.0081],
        [ 0.0154, -0.0266, -0.0181,  ..., -0.0320, -0.0071, -0.0083],
        ...,
        [ 0.0193, -0.0537,  0.0229,  ..., -0.0290, -0.0483,  0.0078],
        [ 0.0068,  0.0202, -0.0180,  ..., -0.0059, -0.0202, -0.0028],
        [ 0.0253, -0.0222,  0.0069,  ...,  0.0032, -0.0336,  0.0161]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9468, -1.3672,  1.5332,  ..., -0.8442, -2.2969,  0.4763]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:47:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he becomes something, something has been became
When he intends something, something has been intended
When he creates something, something has been created
When he introduces something, something has been introduced
When he spends something, something has been spent
When he allows something, something has been allowed
When he fails something, something has been failed
When he proposes something, something has been
2024-07-31 23:47:36 root INFO     [order_1_approx] starting weight calculation for When he proposes something, something has been proposed
When he intends something, something has been intended
When he creates something, something has been created
When he becomes something, something has been became
When he fails something, something has been failed
When he allows something, something has been allowed
When he spends something, something has been spent
When he introduces something, something has been
2024-07-31 23:47:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:50:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1597,  0.1527,  0.0165,  ...,  0.1338,  0.0850, -0.0178],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7510,  0.4382,  1.9316,  ...,  0.8750, -2.5352, -0.3066],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0057, -0.0113,  0.0124,  ...,  0.0070, -0.0161,  0.0007],
        [-0.0126, -0.0020, -0.0084,  ..., -0.0087, -0.0012, -0.0061],
        [ 0.0373,  0.0182, -0.0256,  ..., -0.0320,  0.0033, -0.0323],
        ...,
        [ 0.0201, -0.0110, -0.0141,  ...,  0.0025,  0.0053,  0.0042],
        [ 0.0121,  0.0450, -0.0005,  ..., -0.0047, -0.0229,  0.0038],
        [ 0.0145,  0.0066,  0.0104,  ...,  0.0150,  0.0221, -0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6357,  0.3015,  1.8037,  ...,  0.7734, -2.5645, -0.3110]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:50:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he proposes something, something has been proposed
When he intends something, something has been intended
When he creates something, something has been created
When he becomes something, something has been became
When he fails something, something has been failed
When he allows something, something has been allowed
When he spends something, something has been spent
When he introduces something, something has been
2024-07-31 23:50:33 root INFO     [order_1_approx] starting weight calculation for When he fails something, something has been failed
When he proposes something, something has been proposed
When he spends something, something has been spent
When he introduces something, something has been introduced
When he allows something, something has been allowed
When he intends something, something has been intended
When he creates something, something has been created
When he becomes something, something has been
2024-07-31 23:50:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:53:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0442,  0.1069,  0.0041,  ...,  0.1207,  0.0010, -0.0867],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7070,  1.5303,  2.2324,  ...,  0.1677, -0.4390, -0.8418],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0107,  0.0098,  0.0415,  ...,  0.0118,  0.0356,  0.0125],
        [-0.0288, -0.0006,  0.0124,  ..., -0.0135, -0.0351,  0.0339],
        [-0.0125, -0.0152, -0.0279,  ..., -0.0350, -0.0087,  0.0228],
        ...,
        [ 0.0148,  0.0309, -0.0047,  ..., -0.0181, -0.0083,  0.0205],
        [ 0.0297,  0.0383,  0.0120,  ..., -0.0035, -0.0295, -0.0019],
        [-0.0351, -0.0152,  0.0329,  ...,  0.0528,  0.0072, -0.0347]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9395,  0.9604,  2.0508,  ..., -0.0879,  0.0371, -0.5674]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:53:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he fails something, something has been failed
When he proposes something, something has been proposed
When he spends something, something has been spent
When he introduces something, something has been introduced
When he allows something, something has been allowed
When he intends something, something has been intended
When he creates something, something has been created
When he becomes something, something has been
2024-07-31 23:53:32 root INFO     [order_1_approx] starting weight calculation for When he creates something, something has been created
When he becomes something, something has been became
When he fails something, something has been failed
When he spends something, something has been spent
When he intends something, something has been intended
When he introduces something, something has been introduced
When he proposes something, something has been proposed
When he allows something, something has been
2024-07-31 23:53:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:56:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0880,  0.1394,  0.1234,  ...,  0.0150, -0.0190, -0.2059],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1367, -2.6660,  0.4858,  ..., -0.1265, -2.2188,  0.5879],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.5400e-02, -4.3030e-02, -2.1667e-02,  ...,  3.0319e-02,
         -9.8114e-03, -2.3956e-03],
        [-9.5139e-03,  2.5604e-02, -7.9880e-03,  ...,  2.8610e-02,
          1.4923e-02,  1.6251e-03],
        [ 7.2060e-03, -2.9343e-02, -2.6718e-02,  ..., -3.1311e-02,
         -1.2619e-02,  1.5411e-03],
        ...,
        [ 5.3162e-02, -7.9422e-03, -3.9368e-03,  ..., -7.1716e-03,
         -6.8588e-03,  3.2776e-02],
        [ 2.5497e-02,  5.8350e-02, -3.2425e-04,  ...,  9.9030e-03,
         -3.8147e-06,  5.4588e-03],
        [-6.6948e-03, -6.7902e-03, -8.1863e-03,  ...,  2.9709e-02,
          6.7444e-03, -4.1718e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6406, -2.8477,  0.3691,  ..., -0.4934, -1.9609,  0.7466]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:56:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for When he creates something, something has been created
When he becomes something, something has been became
When he fails something, something has been failed
When he spends something, something has been spent
When he intends something, something has been intended
When he introduces something, something has been introduced
When he proposes something, something has been proposed
When he allows something, something has been
2024-07-31 23:56:29 root INFO     total operator prediction time: 1419.6927046775818 seconds
2024-07-31 23:56:29 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj - superlative
2024-07-31 23:56:29 root INFO     building operator adj - superlative
2024-07-31 23:56:29 root INFO     [order_1_approx] starting weight calculation for If something is the most wealthy, it is wealthiest
If something is the most sexy, it is sexiest
If something is the most hot, it is hottest
If something is the most dense, it is densest
If something is the most dumb, it is dumbest
If something is the most shiny, it is shiniest
If something is the most huge, it is hugest
If something is the most weak, it is
2024-07-31 23:56:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-07-31 23:59:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0205,  0.0379,  0.0168,  ..., -0.0659,  0.0342, -0.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3916, -4.5469, -2.2734,  ..., -4.6250,  0.9512, -4.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0872, -0.0196, -0.0422,  ...,  0.0291, -0.0232,  0.0011],
        [ 0.0287, -0.0132,  0.0375,  ...,  0.0098,  0.0729,  0.0438],
        [ 0.0161, -0.0446,  0.0168,  ...,  0.0269, -0.0060, -0.0309],
        ...,
        [-0.0269,  0.0272, -0.0265,  ..., -0.0122, -0.0669, -0.0091],
        [ 0.0632,  0.0166, -0.0217,  ...,  0.0122,  0.0518, -0.0036],
        [ 0.0625,  0.0023, -0.0054,  ...,  0.0620,  0.0687, -0.0286]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.5615, -3.5898, -1.9434,  ..., -4.4805,  1.2754, -3.7812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-07-31 23:59:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most wealthy, it is wealthiest
If something is the most sexy, it is sexiest
If something is the most hot, it is hottest
If something is the most dense, it is densest
If something is the most dumb, it is dumbest
If something is the most shiny, it is shiniest
If something is the most huge, it is hugest
If something is the most weak, it is
2024-07-31 23:59:32 root INFO     [order_1_approx] starting weight calculation for If something is the most shiny, it is shiniest
If something is the most weak, it is weakest
If something is the most huge, it is hugest
If something is the most hot, it is hottest
If something is the most sexy, it is sexiest
If something is the most dense, it is densest
If something is the most wealthy, it is wealthiest
If something is the most dumb, it is
2024-07-31 23:59:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:02:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0269,  0.0852,  0.1097,  ...,  0.0529,  0.0077,  0.0649],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4414, -2.6602,  2.5840,  ..., -4.7031, -1.6465, -0.9360],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0290, -0.0361,  0.0140,  ..., -0.0040,  0.0041,  0.0027],
        [-0.0251,  0.0110,  0.0370,  ..., -0.0165,  0.0143,  0.0092],
        [ 0.0178, -0.0086,  0.0151,  ...,  0.0153, -0.0334, -0.0401],
        ...,
        [ 0.0193, -0.0040, -0.0143,  ..., -0.0060,  0.0056,  0.0421],
        [ 0.0194,  0.0433,  0.0128,  ...,  0.0142, -0.0242, -0.0093],
        [-0.0036,  0.0263, -0.0024,  ..., -0.0011,  0.0259, -0.0136]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7085, -2.3750,  2.6504,  ..., -4.4492, -1.0801, -0.9639]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:02:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most shiny, it is shiniest
If something is the most weak, it is weakest
If something is the most huge, it is hugest
If something is the most hot, it is hottest
If something is the most sexy, it is sexiest
If something is the most dense, it is densest
If something is the most wealthy, it is wealthiest
If something is the most dumb, it is
2024-08-01 00:02:35 root INFO     [order_1_approx] starting weight calculation for If something is the most shiny, it is shiniest
If something is the most sexy, it is sexiest
If something is the most dumb, it is dumbest
If something is the most huge, it is hugest
If something is the most hot, it is hottest
If something is the most weak, it is weakest
If something is the most dense, it is densest
If something is the most wealthy, it is
2024-08-01 00:02:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:05:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0646,  0.3313,  0.0748,  ...,  0.0797,  0.0442, -0.2150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4756, -5.0781, -1.7861,  ..., -3.1484, -2.8398, -1.4092],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.6757e-05, -1.6747e-03,  2.3132e-02,  ...,  2.2385e-02,
          7.1182e-03,  1.4977e-02],
        [ 2.4872e-02, -1.0956e-02,  4.6143e-02,  ..., -6.8588e-03,
          6.6284e-02,  2.2476e-02],
        [ 2.4681e-03, -3.7842e-02,  9.1362e-04,  ...,  8.2493e-04,
          7.1716e-04, -2.3651e-03],
        ...,
        [ 2.4414e-02, -9.8877e-03,  1.8616e-02,  ...,  8.5449e-04,
          1.9501e-02,  2.0447e-02],
        [-9.5978e-03, -1.0719e-03, -4.3793e-03,  ...,  7.4310e-03,
          2.0966e-02, -3.1853e-04],
        [ 1.3428e-03, -8.0872e-03,  1.8668e-04,  ...,  1.4191e-02,
          2.1072e-02, -3.9024e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1558, -4.2812, -1.5781,  ..., -2.9668, -2.5645, -1.1367]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:05:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most shiny, it is shiniest
If something is the most sexy, it is sexiest
If something is the most dumb, it is dumbest
If something is the most huge, it is hugest
If something is the most hot, it is hottest
If something is the most weak, it is weakest
If something is the most dense, it is densest
If something is the most wealthy, it is
2024-08-01 00:05:39 root INFO     [order_1_approx] starting weight calculation for If something is the most dense, it is densest
If something is the most wealthy, it is wealthiest
If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most huge, it is hugest
If something is the most weak, it is weakest
If something is the most hot, it is hottest
If something is the most sexy, it is
2024-08-01 00:05:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:08:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0773,  0.1720,  0.0992,  ...,  0.0744, -0.0381, -0.0262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5410, -3.3008, -2.1035,  ..., -0.2246, -2.8867, -3.2070],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0212,  0.0180,  0.0257,  ..., -0.0063,  0.0027,  0.0055],
        [ 0.0210,  0.0210,  0.0115,  ..., -0.0265,  0.0297,  0.0043],
        [ 0.0056, -0.0046, -0.0044,  ..., -0.0032, -0.0185, -0.0080],
        ...,
        [ 0.0204,  0.0222,  0.0005,  ...,  0.0039,  0.0327, -0.0202],
        [ 0.0049, -0.0315, -0.0049,  ..., -0.0024, -0.0102,  0.0155],
        [ 0.0085,  0.0029,  0.0050,  ...,  0.0075,  0.0150, -0.0162]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.4961, -2.9551, -2.2422,  ..., -0.3271, -2.6562, -2.9785]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:08:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most dense, it is densest
If something is the most wealthy, it is wealthiest
If something is the most shiny, it is shiniest
If something is the most dumb, it is dumbest
If something is the most huge, it is hugest
If something is the most weak, it is weakest
If something is the most hot, it is hottest
If something is the most sexy, it is
2024-08-01 00:08:43 root INFO     [order_1_approx] starting weight calculation for If something is the most sexy, it is sexiest
If something is the most hot, it is hottest
If something is the most wealthy, it is wealthiest
If something is the most weak, it is weakest
If something is the most dense, it is densest
If something is the most huge, it is hugest
If something is the most dumb, it is dumbest
If something is the most shiny, it is
2024-08-01 00:08:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:11:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0303,  0.0533,  0.1554,  ...,  0.2155,  0.2157, -0.1348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.8750, -1.4531, -2.3242,  ...,  0.4316, -2.3066,  1.1006],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0231, -0.0049,  0.0093,  ..., -0.0114,  0.0162,  0.0111],
        [ 0.0121,  0.0413,  0.0280,  ...,  0.0191,  0.0196, -0.0188],
        [ 0.0161, -0.0244,  0.0249,  ..., -0.0234, -0.0072, -0.0044],
        ...,
        [ 0.0196,  0.0033,  0.0106,  ...,  0.0181, -0.0068, -0.0168],
        [-0.0049, -0.0011,  0.0114,  ...,  0.0235,  0.0151,  0.0090],
        [ 0.0006,  0.0231,  0.0006,  ..., -0.0044, -0.0102, -0.0029]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7910e+00, -1.6709e+00, -2.3359e+00,  ...,  2.1973e-03,
         -1.9639e+00,  1.1660e+00]], device='cuda:0', dtype=torch.float16,
       grad_fn=<SubBackward0>) 

                    
2024-08-01 00:11:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most sexy, it is sexiest
If something is the most hot, it is hottest
If something is the most wealthy, it is wealthiest
If something is the most weak, it is weakest
If something is the most dense, it is densest
If something is the most huge, it is hugest
If something is the most dumb, it is dumbest
If something is the most shiny, it is
2024-08-01 00:11:48 root INFO     [order_1_approx] starting weight calculation for If something is the most hot, it is hottest
If something is the most sexy, it is sexiest
If something is the most wealthy, it is wealthiest
If something is the most dumb, it is dumbest
If something is the most huge, it is hugest
If something is the most weak, it is weakest
If something is the most shiny, it is shiniest
If something is the most dense, it is
2024-08-01 00:11:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:14:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1516,  0.1750,  0.0385,  ..., -0.1115,  0.1339,  0.0343],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.3008, -3.3711,  0.9043,  ..., -4.3438, -4.5312, -2.2754],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0024, -0.0260, -0.0214,  ..., -0.0316,  0.0420, -0.0113],
        [-0.0055,  0.0675,  0.0100,  ..., -0.0192, -0.0172, -0.0263],
        [-0.0092, -0.0052,  0.0137,  ..., -0.0208, -0.1247, -0.0536],
        ...,
        [ 0.0331,  0.0138,  0.0527,  ..., -0.0164,  0.0237, -0.0022],
        [-0.0009, -0.0097, -0.0092,  ..., -0.0113,  0.1444,  0.0018],
        [-0.0210, -0.0042, -0.0077,  ..., -0.0040,  0.0085, -0.0450]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.6055, -2.7109,  0.2520,  ..., -3.1504, -2.8828, -2.3613]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:14:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most hot, it is hottest
If something is the most sexy, it is sexiest
If something is the most wealthy, it is wealthiest
If something is the most dumb, it is dumbest
If something is the most huge, it is hugest
If something is the most weak, it is weakest
If something is the most shiny, it is shiniest
If something is the most dense, it is
2024-08-01 00:14:51 root INFO     [order_1_approx] starting weight calculation for If something is the most weak, it is weakest
If something is the most dumb, it is dumbest
If something is the most dense, it is densest
If something is the most sexy, it is sexiest
If something is the most shiny, it is shiniest
If something is the most wealthy, it is wealthiest
If something is the most huge, it is hugest
If something is the most hot, it is
2024-08-01 00:14:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:17:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1335, -0.0012,  0.0267,  ...,  0.0818, -0.0215, -0.1451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5938, -4.1133, -3.0117,  ..., -3.1562, -3.5234,  0.4033],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-3.1342e-02,  1.2505e-02, -1.9745e-02,  ..., -7.6180e-03,
         -5.6366e-02,  1.1444e-05],
        [ 1.1047e-02, -6.0242e-02,  6.1615e-02,  ...,  2.0584e-02,
          2.6215e-02,  5.7526e-03],
        [-6.3896e-03, -4.4983e-02,  2.7954e-02,  ...,  2.0813e-02,
         -2.4902e-02,  1.2070e-02],
        ...,
        [ 1.1932e-02,  9.8572e-03,  7.1716e-03,  ...,  4.0855e-03,
         -5.2032e-03, -2.0309e-02],
        [ 3.2318e-02, -5.7159e-02,  2.3026e-02,  ..., -3.7415e-02,
          2.3804e-02, -2.3346e-02],
        [ 2.6520e-02, -8.3923e-05,  1.4809e-02,  ..., -2.0332e-03,
          2.1317e-02, -2.3621e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.2500, -3.5703, -3.2363,  ..., -3.0664, -3.2422,  0.5068]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:17:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weak, it is weakest
If something is the most dumb, it is dumbest
If something is the most dense, it is densest
If something is the most sexy, it is sexiest
If something is the most shiny, it is shiniest
If something is the most wealthy, it is wealthiest
If something is the most huge, it is hugest
If something is the most hot, it is
2024-08-01 00:17:54 root INFO     [order_1_approx] starting weight calculation for If something is the most weak, it is weakest
If something is the most dumb, it is dumbest
If something is the most wealthy, it is wealthiest
If something is the most shiny, it is shiniest
If something is the most sexy, it is sexiest
If something is the most dense, it is densest
If something is the most hot, it is hottest
If something is the most huge, it is
2024-08-01 00:17:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:20:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0540,  0.0517,  0.0320,  ..., -0.0712,  0.0055, -0.2668],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4629, -3.1230, -0.7104,  ..., -1.9336, -5.1875, -0.4150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0053, -0.0038, -0.0165,  ..., -0.0077, -0.0026, -0.0094],
        [-0.0061,  0.0094,  0.0172,  ..., -0.0042, -0.0024,  0.0254],
        [ 0.0235,  0.0011,  0.0012,  ...,  0.0047, -0.0072, -0.0239],
        ...,
        [-0.0325, -0.0231,  0.0021,  ..., -0.0251, -0.0150,  0.0061],
        [ 0.0080,  0.0237,  0.0109,  ..., -0.0006,  0.0198,  0.0356],
        [ 0.0130, -0.0135, -0.0060,  ...,  0.0457,  0.0395, -0.0292]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0862, -3.1367, -0.7910,  ..., -2.1445, -3.9746, -0.4058]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:20:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is the most weak, it is weakest
If something is the most dumb, it is dumbest
If something is the most wealthy, it is wealthiest
If something is the most shiny, it is shiniest
If something is the most sexy, it is sexiest
If something is the most dense, it is densest
If something is the most hot, it is hottest
If something is the most huge, it is
2024-08-01 00:20:57 root INFO     total operator prediction time: 1468.0659866333008 seconds
2024-08-01 00:20:57 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+er_irreg
2024-08-01 00:20:57 root INFO     building operator verb+er_irreg
2024-08-01 00:20:57 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you borrow something, you are a borrower
If you consume something, you are a consumer
If you preach something, you are a preacher
If you subscribe something, you are a subscriber
If you listen something, you are a listener
If you send something, you are a sender
If you manage something, you are a
2024-08-01 00:20:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:23:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1616,  0.3599,  0.0278,  ...,  0.1008, -0.0646, -0.1022],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9121, -3.1172,  2.6719,  ..., -1.2070, -3.3320, -4.8359],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0117, -0.0446,  0.0101,  ..., -0.0123, -0.0498,  0.0145],
        [ 0.0042,  0.0033,  0.0089,  ..., -0.0161, -0.0053,  0.0080],
        [-0.0023, -0.0398, -0.0266,  ..., -0.0060, -0.0616, -0.0291],
        ...,
        [ 0.0264,  0.0222,  0.0190,  ...,  0.0261, -0.0033,  0.0234],
        [-0.0091,  0.0231,  0.0077,  ..., -0.0088,  0.0127, -0.0129],
        [ 0.0020, -0.0246,  0.0169,  ..., -0.0114, -0.0256, -0.0110]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2070, -2.8770,  1.6221,  ..., -1.0762, -2.8496, -4.8203]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:23:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you borrow something, you are a borrower
If you consume something, you are a consumer
If you preach something, you are a preacher
If you subscribe something, you are a subscriber
If you listen something, you are a listener
If you send something, you are a sender
If you manage something, you are a
2024-08-01 00:23:53 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you send something, you are a sender
If you listen something, you are a listener
If you manage something, you are a manager
If you borrow something, you are a borrower
If you consume something, you are a consumer
If you subscribe something, you are a subscriber
If you preach something, you are a
2024-08-01 00:23:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:26:51 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1014,  0.0662,  0.0807,  ...,  0.0210, -0.0713,  0.0127],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9453, -5.6406,  4.7188,  ...,  1.9727, -2.7754, -1.5098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0276, -0.0154,  0.0226,  ..., -0.0203, -0.0141, -0.0347],
        [-0.0106,  0.0385, -0.0141,  ...,  0.0031,  0.0327, -0.0043],
        [ 0.0050, -0.0044, -0.0094,  ..., -0.0099, -0.0494, -0.0159],
        ...,
        [ 0.0469,  0.0088,  0.0139,  ...,  0.0446,  0.0300,  0.0106],
        [ 0.0114, -0.0115, -0.0138,  ...,  0.0197, -0.0108,  0.0102],
        [ 0.0002,  0.0303,  0.0012,  ...,  0.0279, -0.0095, -0.0174]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4023, -4.8203,  3.7578,  ...,  1.2305, -2.8242, -1.4932]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:26:52 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you send something, you are a sender
If you listen something, you are a listener
If you manage something, you are a manager
If you borrow something, you are a borrower
If you consume something, you are a consumer
If you subscribe something, you are a subscriber
If you preach something, you are a
2024-08-01 00:26:52 root INFO     [order_1_approx] starting weight calculation for If you send something, you are a sender
If you manage something, you are a manager
If you listen something, you are a listener
If you receive something, you are a receiver
If you subscribe something, you are a subscriber
If you preach something, you are a preacher
If you consume something, you are a consumer
If you borrow something, you are a
2024-08-01 00:26:52 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:29:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0862,  0.1421, -0.0642,  ..., -0.1555,  0.0792, -0.2310],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7598, -2.1543,  0.8130,  ..., -1.5449, -1.5645, -4.4062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0095, -0.0130,  0.0332,  ...,  0.0474,  0.0034, -0.0009],
        [-0.0077,  0.0093,  0.0215,  ...,  0.0194,  0.0047, -0.0056],
        [-0.0192, -0.0027, -0.0115,  ..., -0.0360,  0.0154, -0.0181],
        ...,
        [ 0.0505, -0.0127, -0.0229,  ..., -0.0083,  0.0141,  0.0441],
        [ 0.0108, -0.0288, -0.0106,  ..., -0.0196, -0.0206, -0.0105],
        [-0.0321,  0.0283,  0.0224,  ...,  0.0205,  0.0096, -0.0131]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5312, -1.7656,  1.0781,  ..., -1.7266, -1.3691, -4.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:29:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you send something, you are a sender
If you manage something, you are a manager
If you listen something, you are a listener
If you receive something, you are a receiver
If you subscribe something, you are a subscriber
If you preach something, you are a preacher
If you consume something, you are a consumer
If you borrow something, you are a
2024-08-01 00:29:49 root INFO     [order_1_approx] starting weight calculation for If you listen something, you are a listener
If you send something, you are a sender
If you manage something, you are a manager
If you borrow something, you are a borrower
If you consume something, you are a consumer
If you subscribe something, you are a subscriber
If you preach something, you are a preacher
If you receive something, you are a
2024-08-01 00:29:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:32:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0319,  0.2656,  0.0610,  ..., -0.0089, -0.0567, -0.1709],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1094, -0.6455, -1.3145,  ..., -1.2520, -3.0547, -4.0078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0376, -0.0084, -0.0023,  ..., -0.0267, -0.0206, -0.0094],
        [-0.0162,  0.0357,  0.0061,  ...,  0.0077, -0.0475, -0.0003],
        [ 0.0085, -0.0051, -0.0197,  ...,  0.0025,  0.0046,  0.0086],
        ...,
        [ 0.0261, -0.0079,  0.0159,  ...,  0.0178,  0.0145,  0.0074],
        [-0.0084,  0.0221, -0.0033,  ..., -0.0294,  0.0030, -0.0013],
        [-0.0005, -0.0262,  0.0181,  ...,  0.0299,  0.0612,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3823, -0.9775, -1.0674,  ..., -0.9180, -3.0254, -3.4102]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:32:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you listen something, you are a listener
If you send something, you are a sender
If you manage something, you are a manager
If you borrow something, you are a borrower
If you consume something, you are a consumer
If you subscribe something, you are a subscriber
If you preach something, you are a preacher
If you receive something, you are a
2024-08-01 00:32:46 root INFO     [order_1_approx] starting weight calculation for If you borrow something, you are a borrower
If you receive something, you are a receiver
If you preach something, you are a preacher
If you consume something, you are a consumer
If you listen something, you are a listener
If you manage something, you are a manager
If you send something, you are a sender
If you subscribe something, you are a
2024-08-01 00:32:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:35:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0329,  0.1301, -0.0627,  ...,  0.0129,  0.1015,  0.0466],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7871, -1.1416,  1.0420,  ...,  1.2715, -1.1270, -4.4688],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0106, -0.0192,  0.0371,  ..., -0.0147,  0.0300,  0.0292],
        [-0.0241,  0.0338,  0.0219,  ..., -0.0051, -0.0168,  0.0020],
        [ 0.0308, -0.0090, -0.0152,  ...,  0.0128, -0.0265, -0.0210],
        ...,
        [ 0.0394,  0.0322,  0.0247,  ...,  0.0338,  0.0181,  0.0262],
        [ 0.0097, -0.0341, -0.0156,  ..., -0.0103, -0.0306, -0.0223],
        [ 0.0392, -0.0286, -0.0035,  ..., -0.0278, -0.0147, -0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7031, -1.0713,  1.1104,  ...,  1.3496, -0.9380, -4.4023]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:35:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you borrow something, you are a borrower
If you receive something, you are a receiver
If you preach something, you are a preacher
If you consume something, you are a consumer
If you listen something, you are a listener
If you manage something, you are a manager
If you send something, you are a sender
If you subscribe something, you are a
2024-08-01 00:35:43 root INFO     [order_1_approx] starting weight calculation for If you receive something, you are a receiver
If you borrow something, you are a borrower
If you preach something, you are a preacher
If you send something, you are a sender
If you manage something, you are a manager
If you consume something, you are a consumer
If you subscribe something, you are a subscriber
If you listen something, you are a
2024-08-01 00:35:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:38:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2361,  0.1064,  0.1349,  ...,  0.0837,  0.1958, -0.1400],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8682, -2.2227,  1.7793,  ...,  0.6201, -3.2285, -4.9844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0163,  0.0098,  0.0032,  ...,  0.0058,  0.0126,  0.0125],
        [-0.0170,  0.0355, -0.0042,  ...,  0.0110,  0.0047,  0.0115],
        [ 0.0043,  0.0020,  0.0065,  ..., -0.0044,  0.0009,  0.0077],
        ...,
        [ 0.0107, -0.0124,  0.0076,  ..., -0.0104, -0.0112,  0.0102],
        [ 0.0137, -0.0056, -0.0049,  ..., -0.0091, -0.0116,  0.0086],
        [-0.0121,  0.0045,  0.0131,  ...,  0.0253,  0.0097, -0.0010]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8672, -2.2227,  2.1309,  ...,  0.7202, -3.3418, -4.8047]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:38:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you receive something, you are a receiver
If you borrow something, you are a borrower
If you preach something, you are a preacher
If you send something, you are a sender
If you manage something, you are a manager
If you consume something, you are a consumer
If you subscribe something, you are a subscriber
If you listen something, you are a
2024-08-01 00:38:40 root INFO     [order_1_approx] starting weight calculation for If you listen something, you are a listener
If you receive something, you are a receiver
If you subscribe something, you are a subscriber
If you send something, you are a sender
If you manage something, you are a manager
If you borrow something, you are a borrower
If you preach something, you are a preacher
If you consume something, you are a
2024-08-01 00:38:40 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:41:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2234,  0.1190, -0.0558,  ...,  0.1416,  0.0167, -0.1257],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3145,  0.4053,  2.1719,  ..., -2.0117, -3.0664, -1.5264],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0051, -0.0033,  0.0024,  ...,  0.0058,  0.0218,  0.0100],
        [-0.0306,  0.0199,  0.0024,  ..., -0.0082, -0.0009, -0.0028],
        [ 0.0182, -0.0049,  0.0044,  ..., -0.0220, -0.0196, -0.0246],
        ...,
        [ 0.0160,  0.0103,  0.0211,  ...,  0.0091,  0.0121, -0.0062],
        [ 0.0278,  0.0133,  0.0007,  ..., -0.0287, -0.0276, -0.0092],
        [ 0.0184, -0.0043,  0.0059,  ..., -0.0196, -0.0099, -0.0187]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1484,  0.3782,  1.9961,  ..., -1.8643, -2.9043, -1.7373]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:41:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you listen something, you are a listener
If you receive something, you are a receiver
If you subscribe something, you are a subscriber
If you send something, you are a sender
If you manage something, you are a manager
If you borrow something, you are a borrower
If you preach something, you are a preacher
If you consume something, you are a
2024-08-01 00:41:36 root INFO     [order_1_approx] starting weight calculation for If you subscribe something, you are a subscriber
If you preach something, you are a preacher
If you receive something, you are a receiver
If you borrow something, you are a borrower
If you consume something, you are a consumer
If you listen something, you are a listener
If you manage something, you are a manager
If you send something, you are a
2024-08-01 00:41:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:44:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0587,  0.1520,  0.1145,  ...,  0.0187,  0.0305, -0.1381],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3760, -2.5820, -1.8506,  ..., -0.0312, -1.2334, -2.6504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0396, -0.0320,  0.0388,  ...,  0.0234,  0.0108, -0.0107],
        [-0.0561,  0.0348,  0.0417,  ..., -0.0066,  0.0199, -0.0323],
        [ 0.0094,  0.0045, -0.0093,  ..., -0.0004, -0.0206,  0.0170],
        ...,
        [ 0.0022, -0.0033, -0.0112,  ...,  0.0002, -0.0258,  0.0191],
        [ 0.0027, -0.0010,  0.0220,  ..., -0.0196, -0.0147, -0.0034],
        [ 0.0017,  0.0118, -0.0099,  ...,  0.0093, -0.0012, -0.0030]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.6543, -2.7969, -1.7695,  ..., -0.4031, -1.5254, -2.6758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:44:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you subscribe something, you are a subscriber
If you preach something, you are a preacher
If you receive something, you are a receiver
If you borrow something, you are a borrower
If you consume something, you are a consumer
If you listen something, you are a listener
If you manage something, you are a manager
If you send something, you are a
2024-08-01 00:44:34 root INFO     total operator prediction time: 1416.7904253005981 seconds
2024-08-01 00:44:34 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on over+adj_reg
2024-08-01 00:44:34 root INFO     building operator over+adj_reg
2024-08-01 00:44:34 root INFO     [order_1_approx] starting weight calculation for If something is too ambitious, it is overambitious
If something is too shadowed, it is overshadowed
If something is too written, it is overwritten
If something is too qualified, it is overqualified
If something is too taken, it is overtaken
If something is too thrown, it is overthrown
If something is too sold, it is oversold
If something is too loaded, it is
2024-08-01 00:44:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:47:34 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-8.0383e-02, -4.9744e-02, -1.7334e-01,  ..., -4.5776e-05,
        -1.0114e-01,  8.0444e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9932, -3.2109,  0.4971,  ...,  1.2734, -2.5469, -1.8994],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0470, -0.0030,  0.0133,  ..., -0.0296, -0.0056,  0.0506],
        [ 0.0188, -0.0072,  0.0065,  ..., -0.0025,  0.0235, -0.0007],
        [ 0.0421,  0.0093,  0.0498,  ..., -0.0374,  0.0297, -0.0062],
        ...,
        [-0.0112,  0.0701,  0.0244,  ...,  0.0035, -0.0383, -0.0108],
        [ 0.0192, -0.0001, -0.0228,  ...,  0.0123,  0.0254, -0.0065],
        [ 0.0052,  0.0035, -0.0363,  ..., -0.0075,  0.0294,  0.0025]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8369, -2.1406,  0.4766,  ...,  1.0967, -1.8828, -1.2471]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:47:35 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too ambitious, it is overambitious
If something is too shadowed, it is overshadowed
If something is too written, it is overwritten
If something is too qualified, it is overqualified
If something is too taken, it is overtaken
If something is too thrown, it is overthrown
If something is too sold, it is oversold
If something is too loaded, it is
2024-08-01 00:47:35 root INFO     [order_1_approx] starting weight calculation for If something is too sold, it is oversold
If something is too taken, it is overtaken
If something is too shadowed, it is overshadowed
If something is too loaded, it is overloaded
If something is too ambitious, it is overambitious
If something is too qualified, it is overqualified
If something is too written, it is overwritten
If something is too thrown, it is
2024-08-01 00:47:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:50:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2367,  0.0131, -0.0358,  ..., -0.0480, -0.1188,  0.1252],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6973, -4.1680,  0.4282,  ...,  0.2622, -1.9082, -2.6309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0303, -0.0025, -0.0284,  ..., -0.0273, -0.0345,  0.0021],
        [-0.0249,  0.0475, -0.0115,  ...,  0.0177,  0.0158,  0.0547],
        [ 0.0356, -0.0435, -0.0208,  ...,  0.0023, -0.0234, -0.0080],
        ...,
        [-0.0003,  0.0027, -0.0399,  ..., -0.0113,  0.0076, -0.0197],
        [-0.0356,  0.0151,  0.0862,  ..., -0.0158,  0.0359, -0.0309],
        [-0.0043,  0.0055, -0.0219,  ...,  0.0225,  0.0030,  0.0295]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6895, -3.6016, -0.1406,  ...,  0.5620, -1.7051, -2.4629]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:50:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sold, it is oversold
If something is too taken, it is overtaken
If something is too shadowed, it is overshadowed
If something is too loaded, it is overloaded
If something is too ambitious, it is overambitious
If something is too qualified, it is overqualified
If something is too written, it is overwritten
If something is too thrown, it is
2024-08-01 00:50:36 root INFO     [order_1_approx] starting weight calculation for If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too thrown, it is overthrown
If something is too qualified, it is overqualified
If something is too taken, it is overtaken
If something is too shadowed, it is overshadowed
If something is too written, it is overwritten
If something is too sold, it is
2024-08-01 00:50:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:53:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0319, -0.0269,  0.0247,  ...,  0.0168,  0.0496,  0.1233],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4336, -2.9883,  0.0547,  ..., -1.7900, -3.0137, -1.1279],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0964e-02, -1.7197e-02,  1.3763e-02,  ...,  1.8936e-02,
         -6.1066e-02,  1.4420e-02],
        [-3.8528e-04,  3.2288e-02, -2.0309e-02,  ...,  7.9727e-04,
         -5.3253e-03,  5.7640e-03],
        [ 1.4015e-02, -6.7062e-03,  1.6663e-02,  ..., -2.7725e-02,
         -3.8147e-05,  2.5360e-02],
        ...,
        [ 6.7215e-03, -2.1698e-02,  9.8114e-03,  ..., -5.3215e-03,
          1.0231e-02,  1.6785e-03],
        [ 5.3406e-03, -4.1466e-03,  8.6746e-03,  ...,  1.7395e-02,
          1.4786e-02,  5.6381e-03],
        [-1.2596e-02,  1.6830e-02, -6.6185e-03,  ...,  1.6518e-03,
         -4.2496e-03,  6.8245e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3672, -3.1973, -0.1522,  ..., -1.2373, -2.7168, -1.1738]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:53:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too thrown, it is overthrown
If something is too qualified, it is overqualified
If something is too taken, it is overtaken
If something is too shadowed, it is overshadowed
If something is too written, it is overwritten
If something is too sold, it is
2024-08-01 00:53:37 root INFO     [order_1_approx] starting weight calculation for If something is too thrown, it is overthrown
If something is too shadowed, it is overshadowed
If something is too sold, it is oversold
If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too taken, it is overtaken
If something is too qualified, it is
2024-08-01 00:53:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:56:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0186,  0.1099, -0.1287,  ..., -0.0113,  0.0140, -0.1086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2812, -3.0176,  0.9004,  ...,  0.4587, -1.3311, -2.8262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0073,  0.0108,  0.0446,  ..., -0.0004, -0.0205,  0.0383],
        [-0.0161,  0.0083, -0.0512,  ..., -0.0369, -0.0378,  0.0239],
        [ 0.0418, -0.0236,  0.0430,  ..., -0.0203, -0.0362,  0.0318],
        ...,
        [-0.0051,  0.0145, -0.0192,  ...,  0.0133,  0.0090,  0.0047],
        [-0.0126,  0.0057, -0.0014,  ...,  0.0117,  0.0293, -0.0351],
        [ 0.0007,  0.0004, -0.0045,  ...,  0.0230,  0.0189, -0.0053]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3896, -3.5566,  0.9126,  ...,  0.5552, -0.4424, -2.4082]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:56:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too thrown, it is overthrown
If something is too shadowed, it is overshadowed
If something is too sold, it is oversold
If something is too written, it is overwritten
If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too taken, it is overtaken
If something is too qualified, it is
2024-08-01 00:56:37 root INFO     [order_1_approx] starting weight calculation for If something is too taken, it is overtaken
If something is too sold, it is oversold
If something is too loaded, it is overloaded
If something is too written, it is overwritten
If something is too shadowed, it is overshadowed
If something is too thrown, it is overthrown
If something is too qualified, it is overqualified
If something is too ambitious, it is
2024-08-01 00:56:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 00:59:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0439,  0.1925, -0.1514,  ...,  0.0628, -0.1331, -0.0575],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6133, -3.4688,  0.6250,  ...,  0.5283, -1.0830, -2.7578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0121,  0.0002,  0.0056,  ..., -0.0105,  0.0090,  0.0092],
        [-0.0166,  0.0148, -0.0142,  ..., -0.0085, -0.0009, -0.0174],
        [ 0.0248, -0.0089,  0.0409,  ...,  0.0080,  0.0262,  0.0089],
        ...,
        [ 0.0059,  0.0304,  0.0137,  ..., -0.0039,  0.0079, -0.0116],
        [ 0.0032,  0.0062,  0.0186,  ...,  0.0138,  0.0041, -0.0221],
        [-0.0173, -0.0025, -0.0119,  ..., -0.0132, -0.0149,  0.0043]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5352, -2.7754,  0.5850,  ...,  0.3076, -0.5850, -3.0664]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 00:59:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too taken, it is overtaken
If something is too sold, it is oversold
If something is too loaded, it is overloaded
If something is too written, it is overwritten
If something is too shadowed, it is overshadowed
If something is too thrown, it is overthrown
If something is too qualified, it is overqualified
If something is too ambitious, it is
2024-08-01 00:59:38 root INFO     [order_1_approx] starting weight calculation for If something is too sold, it is oversold
If something is too taken, it is overtaken
If something is too thrown, it is overthrown
If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too shadowed, it is overshadowed
If something is too qualified, it is overqualified
If something is too written, it is
2024-08-01 00:59:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:02:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1073,  0.0701,  0.0553,  ..., -0.1342, -0.1018,  0.0497],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2988, -3.5273,  1.8730,  ..., -0.4829, -1.6631, -2.7109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0251,  0.0187,  0.0173,  ..., -0.0157,  0.0078,  0.0195],
        [-0.0172,  0.0185, -0.0174,  ..., -0.0033,  0.0076,  0.0150],
        [ 0.0048, -0.0075,  0.0601,  ...,  0.0198, -0.0253,  0.0012],
        ...,
        [ 0.0070, -0.0115,  0.0254,  ...,  0.0120, -0.0138,  0.0025],
        [ 0.0054,  0.0052, -0.0043,  ...,  0.0048, -0.0007,  0.0242],
        [ 0.0180,  0.0057,  0.0101,  ...,  0.0034, -0.0136,  0.0226]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2129, -3.6602,  1.7783,  ..., -0.0469, -2.0059, -2.3613]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:02:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sold, it is oversold
If something is too taken, it is overtaken
If something is too thrown, it is overthrown
If something is too ambitious, it is overambitious
If something is too loaded, it is overloaded
If something is too shadowed, it is overshadowed
If something is too qualified, it is overqualified
If something is too written, it is
2024-08-01 01:02:37 root INFO     [order_1_approx] starting weight calculation for If something is too sold, it is oversold
If something is too written, it is overwritten
If something is too loaded, it is overloaded
If something is too qualified, it is overqualified
If something is too ambitious, it is overambitious
If something is too taken, it is overtaken
If something is too thrown, it is overthrown
If something is too shadowed, it is
2024-08-01 01:02:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:05:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1660, -0.1026, -0.1862,  ...,  0.1417, -0.1433,  0.0270],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5469, -2.6836,  1.3906,  ..., -0.0911, -0.9507, -1.8662],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0315,  0.0143, -0.0046,  ...,  0.0051,  0.0094,  0.0016],
        [ 0.0026,  0.0205,  0.0305,  ...,  0.0026,  0.0248, -0.0109],
        [-0.0017, -0.0086,  0.0187,  ..., -0.0086,  0.0511,  0.0052],
        ...,
        [ 0.0166, -0.0078,  0.0069,  ...,  0.0121,  0.0569, -0.0070],
        [ 0.0039,  0.0015, -0.0194,  ..., -0.0060, -0.0009, -0.0097],
        [-0.0067, -0.0197,  0.0041,  ...,  0.0073,  0.0058, -0.0040]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8125, -2.7344,  1.4082,  ...,  0.3000, -1.2402, -1.6406]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:05:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too sold, it is oversold
If something is too written, it is overwritten
If something is too loaded, it is overloaded
If something is too qualified, it is overqualified
If something is too ambitious, it is overambitious
If something is too taken, it is overtaken
If something is too thrown, it is overthrown
If something is too shadowed, it is
2024-08-01 01:05:37 root INFO     [order_1_approx] starting weight calculation for If something is too written, it is overwritten
If something is too sold, it is oversold
If something is too qualified, it is overqualified
If something is too ambitious, it is overambitious
If something is too shadowed, it is overshadowed
If something is too loaded, it is overloaded
If something is too thrown, it is overthrown
If something is too taken, it is
2024-08-01 01:05:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:08:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0850,  0.0232, -0.0977,  ..., -0.0308, -0.0533,  0.0807],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6367, -3.5273,  0.7920,  ..., -0.3130, -1.8672, -2.7695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0199, -0.0006,  0.0480,  ..., -0.0174, -0.0193,  0.0253],
        [-0.0246,  0.0149, -0.0237,  ...,  0.0229, -0.0180,  0.0069],
        [ 0.0220, -0.0235,  0.0168,  ..., -0.0046,  0.0068,  0.0123],
        ...,
        [ 0.0073, -0.0285,  0.0199,  ...,  0.0032, -0.0063, -0.0052],
        [ 0.0066,  0.0040,  0.0004,  ..., -0.0126,  0.0219, -0.0034],
        [ 0.0060, -0.0035,  0.0042,  ...,  0.0212,  0.0065,  0.0294]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7129, -3.7656,  0.6724,  ..., -0.0459, -1.3271, -2.8418]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:08:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If something is too written, it is overwritten
If something is too sold, it is oversold
If something is too qualified, it is overqualified
If something is too ambitious, it is overambitious
If something is too shadowed, it is overshadowed
If something is too loaded, it is overloaded
If something is too thrown, it is overthrown
If something is too taken, it is
2024-08-01 01:08:37 root INFO     total operator prediction time: 1443.0711476802826 seconds
2024-08-01 01:08:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ly_reg
2024-08-01 01:08:37 root INFO     building operator adj+ly_reg
2024-08-01 01:08:37 root INFO     [order_1_approx] starting weight calculation for The adjective form of strong is strongly
The adjective form of federal is federally
The adjective form of traditional is traditionally
The adjective form of decided is decidedly
The adjective form of clinical is clinically
The adjective form of creative is creatively
The adjective form of international is internationally
The adjective form of critical is
2024-08-01 01:08:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:11:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0441, -0.1005, -0.0782,  ...,  0.0681, -0.0303,  0.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4990, -2.5879,  2.1895,  ..., -1.9854, -0.1904, -0.0488],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0187, -0.0462, -0.0238,  ..., -0.0428,  0.0418, -0.0669],
        [ 0.0274,  0.0582,  0.0277,  ...,  0.0408, -0.0458,  0.0146],
        [ 0.0225,  0.0026,  0.0034,  ...,  0.0204, -0.0382,  0.0247],
        ...,
        [ 0.0253, -0.0493, -0.0143,  ...,  0.0338,  0.1002, -0.0354],
        [ 0.0205,  0.0499, -0.0220,  ...,  0.0426, -0.0495,  0.0271],
        [ 0.0441,  0.0322, -0.0284,  ...,  0.0438, -0.0143,  0.0189]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1055, -3.0352,  1.7373,  ..., -0.5381, -1.5244, -0.2686]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:11:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of strong is strongly
The adjective form of federal is federally
The adjective form of traditional is traditionally
The adjective form of decided is decidedly
The adjective form of clinical is clinically
The adjective form of creative is creatively
The adjective form of international is internationally
The adjective form of critical is
2024-08-01 01:11:36 root INFO     [order_1_approx] starting weight calculation for The adjective form of clinical is clinically
The adjective form of traditional is traditionally
The adjective form of critical is critically
The adjective form of international is internationally
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of federal is federally
The adjective form of creative is
2024-08-01 01:11:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:14:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0664,  0.0532,  0.1147,  ...,  0.0784, -0.0431, -0.0470],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.1113, -2.2266,  3.6836,  ..., -1.2676, -0.1392,  0.3633],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0056, -0.0338, -0.0133,  ..., -0.0417, -0.0447,  0.0296],
        [-0.0135,  0.0188, -0.0316,  ...,  0.0064,  0.0215, -0.0249],
        [ 0.0126, -0.0077, -0.0132,  ...,  0.0049, -0.0452, -0.0242],
        ...,
        [ 0.0120,  0.0233, -0.0016,  ...,  0.0351,  0.0413, -0.0198],
        [ 0.0095,  0.0017,  0.0061,  ...,  0.0393,  0.0192, -0.0070],
        [-0.0107, -0.0332, -0.0109,  ..., -0.0057, -0.0054, -0.0133]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2725, -2.1973,  3.3574,  ..., -1.3281, -0.2068,  0.3789]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:14:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of clinical is clinically
The adjective form of traditional is traditionally
The adjective form of critical is critically
The adjective form of international is internationally
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of federal is federally
The adjective form of creative is
2024-08-01 01:14:37 root INFO     [order_1_approx] starting weight calculation for The adjective form of international is internationally
The adjective form of critical is critically
The adjective form of federal is federally
The adjective form of creative is creatively
The adjective form of clinical is clinically
The adjective form of strong is strongly
The adjective form of decided is decidedly
The adjective form of traditional is
2024-08-01 01:14:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:17:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2032,  0.0016, -0.1440,  ..., -0.0396, -0.1343,  0.1278],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0586, -3.1445,  0.6641,  ...,  0.3550, -4.0078, -0.8330],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0358, -0.0668, -0.0394,  ..., -0.0126,  0.0584, -0.0321],
        [-0.0350,  0.0483,  0.0115,  ...,  0.0069, -0.0325, -0.0149],
        [-0.0067,  0.0276, -0.0120,  ..., -0.0319, -0.0117, -0.0472],
        ...,
        [ 0.0160,  0.0472, -0.0133,  ...,  0.0268, -0.0376,  0.0300],
        [ 0.0111,  0.0004, -0.0291,  ..., -0.0205,  0.1281,  0.0142],
        [-0.0117,  0.0016,  0.0228,  ...,  0.0155, -0.0959, -0.0403]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0410, -3.5664,  1.4492,  ..., -0.4282, -3.2246, -2.1758]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:17:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of international is internationally
The adjective form of critical is critically
The adjective form of federal is federally
The adjective form of creative is creatively
The adjective form of clinical is clinically
The adjective form of strong is strongly
The adjective form of decided is decidedly
The adjective form of traditional is
2024-08-01 01:17:36 root INFO     [order_1_approx] starting weight calculation for The adjective form of traditional is traditionally
The adjective form of international is internationally
The adjective form of federal is federally
The adjective form of critical is critically
The adjective form of creative is creatively
The adjective form of strong is strongly
The adjective form of decided is decidedly
The adjective form of clinical is
2024-08-01 01:17:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:20:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1567, -0.0285, -0.0359,  ..., -0.0838, -0.0598, -0.0587],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3604, -0.8701, -0.2871,  ..., -1.7266,  1.5928, -0.4258],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0402, -0.0541, -0.0319,  ..., -0.0154, -0.0271,  0.0060],
        [-0.0083, -0.0058,  0.0113,  ...,  0.0061,  0.0198, -0.0024],
        [ 0.0422, -0.0188,  0.0400,  ..., -0.0124, -0.0025, -0.0209],
        ...,
        [ 0.0438,  0.0587, -0.0040,  ..., -0.0053,  0.0168,  0.0213],
        [-0.0512,  0.0169, -0.0831,  ...,  0.0041, -0.0275,  0.0124],
        [-0.0222,  0.0142, -0.0306,  ..., -0.0097, -0.0224, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0547, -0.8433, -0.0356,  ..., -0.9404,  1.0645, -0.1064]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:20:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of traditional is traditionally
The adjective form of international is internationally
The adjective form of federal is federally
The adjective form of critical is critically
The adjective form of creative is creatively
The adjective form of strong is strongly
The adjective form of decided is decidedly
The adjective form of clinical is
2024-08-01 01:20:36 root INFO     [order_1_approx] starting weight calculation for The adjective form of strong is strongly
The adjective form of federal is federally
The adjective form of creative is creatively
The adjective form of traditional is traditionally
The adjective form of critical is critically
The adjective form of international is internationally
The adjective form of clinical is clinically
The adjective form of decided is
2024-08-01 01:20:36 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:23:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0790,  0.0249,  0.0341,  ...,  0.0511, -0.0570, -0.0163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5078, -4.2539,  2.3184,  ..., -0.3184, -3.2227, -1.4492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0468, -0.0173,  0.0090,  ..., -0.0721, -0.0410, -0.0117],
        [ 0.0166,  0.0175,  0.0659,  ..., -0.0364, -0.0044, -0.0253],
        [ 0.0406, -0.0207,  0.0696,  ..., -0.0488, -0.0623,  0.0158],
        ...,
        [ 0.0056,  0.0201,  0.0010,  ...,  0.0689, -0.0011,  0.0243],
        [ 0.0141,  0.0154,  0.0035,  ...,  0.0215,  0.0555,  0.0150],
        [ 0.0046, -0.0085,  0.0544,  ..., -0.0049, -0.0357,  0.0272]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.0898, -4.1289,  1.0430,  ..., -1.6416, -4.1758, -3.2637]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:23:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of strong is strongly
The adjective form of federal is federally
The adjective form of creative is creatively
The adjective form of traditional is traditionally
The adjective form of critical is critically
The adjective form of international is internationally
The adjective form of clinical is clinically
The adjective form of decided is
2024-08-01 01:23:38 root INFO     [order_1_approx] starting weight calculation for The adjective form of traditional is traditionally
The adjective form of creative is creatively
The adjective form of international is internationally
The adjective form of critical is critically
The adjective form of clinical is clinically
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of federal is
2024-08-01 01:23:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:26:37 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0868,  0.0491,  0.0557,  ..., -0.2085, -0.0903,  0.0753],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4775, -1.8535,  4.0430,  ..., -2.0176, -1.0068, -0.7725],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0285, -0.0598, -0.0432,  ..., -0.0074, -0.0272, -0.0155],
        [ 0.0106,  0.0190, -0.0281,  ...,  0.0105, -0.0166, -0.0209],
        [ 0.0084,  0.0525, -0.0305,  ...,  0.0069, -0.0834, -0.0233],
        ...,
        [-0.0063,  0.0636, -0.0780,  ..., -0.0122, -0.0031,  0.0015],
        [ 0.0066, -0.0121, -0.0127,  ...,  0.0317,  0.0102, -0.0137],
        [-0.0005, -0.0154,  0.0433,  ..., -0.0045,  0.0393, -0.0207]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.2285, -2.1934,  2.9727,  ..., -2.5098, -1.0918, -0.3796]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:26:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of traditional is traditionally
The adjective form of creative is creatively
The adjective form of international is internationally
The adjective form of critical is critically
The adjective form of clinical is clinically
The adjective form of decided is decidedly
The adjective form of strong is strongly
The adjective form of federal is
2024-08-01 01:26:39 root INFO     [order_1_approx] starting weight calculation for The adjective form of decided is decidedly
The adjective form of critical is critically
The adjective form of international is internationally
The adjective form of clinical is clinically
The adjective form of federal is federally
The adjective form of traditional is traditionally
The adjective form of creative is creatively
The adjective form of strong is
2024-08-01 01:26:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:29:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0210, -0.1971,  0.1154,  ..., -0.1233, -0.0177,  0.1742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4023, -3.5742, -0.8657,  ..., -0.2041, -4.9844, -4.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0150, -0.0315, -0.0262,  ..., -0.0409, -0.0124, -0.0047],
        [-0.0063, -0.0226,  0.0094,  ..., -0.0166, -0.0019, -0.0249],
        [-0.0077, -0.0056,  0.0369,  ..., -0.0201, -0.0187, -0.0018],
        ...,
        [-0.0144,  0.0276, -0.0432,  ...,  0.0303,  0.0067,  0.0218],
        [ 0.0315,  0.0225,  0.0044,  ...,  0.0549,  0.0768, -0.0220],
        [-0.0234, -0.0173,  0.0065,  ...,  0.0310,  0.0183, -0.0132]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.0000, -3.1699, -0.5986,  ..., -0.7026, -4.6328, -3.9395]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:29:38 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of decided is decidedly
The adjective form of critical is critically
The adjective form of international is internationally
The adjective form of clinical is clinically
The adjective form of federal is federally
The adjective form of traditional is traditionally
The adjective form of creative is creatively
The adjective form of strong is
2024-08-01 01:29:39 root INFO     [order_1_approx] starting weight calculation for The adjective form of traditional is traditionally
The adjective form of clinical is clinically
The adjective form of strong is strongly
The adjective form of federal is federally
The adjective form of decided is decidedly
The adjective form of critical is critically
The adjective form of creative is creatively
The adjective form of international is
2024-08-01 01:29:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:32:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0173,  0.0574,  0.0870,  ...,  0.0614, -0.1014,  0.0925],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6719, -1.6035,  0.0876,  ..., -2.4141, -0.6963, -1.4941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0762, -0.0261,  0.0201,  ...,  0.0466,  0.0486,  0.0018],
        [-0.0901,  0.0051,  0.0114,  ..., -0.0393, -0.0486, -0.0241],
        [ 0.0818, -0.0269,  0.0282,  ...,  0.0247,  0.0359,  0.0064],
        ...,
        [-0.0825,  0.0706, -0.0462,  ..., -0.0217, -0.0312, -0.0017],
        [ 0.0439, -0.0073,  0.0007,  ..., -0.0092,  0.0076, -0.0201],
        [-0.0528, -0.0041,  0.0147,  ..., -0.0266, -0.0313, -0.0251]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3242, -2.7246,  1.5625,  ..., -3.7578, -0.8545, -2.1953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:32:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The adjective form of traditional is traditionally
The adjective form of clinical is clinically
The adjective form of strong is strongly
The adjective form of federal is federally
The adjective form of decided is decidedly
The adjective form of critical is critically
The adjective form of creative is creatively
The adjective form of international is
2024-08-01 01:32:39 root INFO     total operator prediction time: 1442.200185060501 seconds
2024-08-01 01:32:39 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+tion_irreg
2024-08-01 01:32:39 root INFO     building operator verb+tion_irreg
2024-08-01 01:32:39 root INFO     [order_1_approx] starting weight calculation for To colonize results in colonization
To privatize results in privatization
To randomize results in randomization
To characterize results in characterization
To optimize results in optimization
To consult results in consulation
To derive results in derivation
To deprive results in
2024-08-01 01:32:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:35:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0688,  0.0824, -0.2229,  ..., -0.0649,  0.1606,  0.0757],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1250, -5.8516,  2.5996,  ...,  0.5781, -1.7188, -2.1445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0269, -0.0165, -0.0458,  ...,  0.0010, -0.0481, -0.0179],
        [ 0.0007,  0.0679,  0.1316,  ...,  0.0718,  0.0565,  0.0899],
        [-0.0060, -0.0563, -0.0377,  ...,  0.0163, -0.0419, -0.0269],
        ...,
        [-0.0214,  0.0088,  0.0100,  ..., -0.0310,  0.0333, -0.0053],
        [-0.0294,  0.0075, -0.0915,  ..., -0.0220,  0.0037, -0.0123],
        [ 0.0323, -0.0373,  0.0566,  ...,  0.0542, -0.0089,  0.0050]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.1162, -2.7871,  1.6230,  ...,  0.4812, -3.0059, -1.5801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:35:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To colonize results in colonization
To privatize results in privatization
To randomize results in randomization
To characterize results in characterization
To optimize results in optimization
To consult results in consulation
To derive results in derivation
To deprive results in
2024-08-01 01:35:37 root INFO     [order_1_approx] starting weight calculation for To characterize results in characterization
To optimize results in optimization
To privatize results in privatization
To deprive results in deprivation
To derive results in derivation
To randomize results in randomization
To colonize results in colonization
To consult results in
2024-08-01 01:35:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:38:31 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0242,  0.1538, -0.0809,  ..., -0.0798, -0.1533, -0.0061],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2900, -3.1758,  2.9023,  ...,  0.3545, -0.4976, -1.4600],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0391, -0.0187,  0.0137,  ..., -0.0284,  0.0254,  0.0400],
        [-0.0381,  0.0339, -0.0166,  ...,  0.0041, -0.0388, -0.0411],
        [ 0.0465, -0.0119, -0.0461,  ...,  0.0099,  0.0353,  0.0252],
        ...,
        [-0.0116,  0.0161, -0.0026,  ..., -0.0164, -0.0233, -0.0357],
        [-0.0221, -0.0230,  0.0015,  ...,  0.0206,  0.0466,  0.0441],
        [ 0.0078,  0.0518,  0.0395,  ..., -0.0015, -0.0202,  0.0111]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1941, -4.0117,  3.4551,  ..., -0.1865, -0.3320, -1.7578]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:38:32 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To characterize results in characterization
To optimize results in optimization
To privatize results in privatization
To deprive results in deprivation
To derive results in derivation
To randomize results in randomization
To colonize results in colonization
To consult results in
2024-08-01 01:38:32 root INFO     [order_1_approx] starting weight calculation for To optimize results in optimization
To colonize results in colonization
To deprive results in deprivation
To privatize results in privatization
To derive results in derivation
To randomize results in randomization
To consult results in consulation
To characterize results in
2024-08-01 01:38:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:41:32 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0629,  0.1272,  0.0157,  ...,  0.0360, -0.0137, -0.1011],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.9111, -1.1162,  4.6484,  ...,  2.2832, -2.1328, -1.6992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0430, -0.0309,  0.0999,  ..., -0.0950, -0.0832, -0.0396],
        [ 0.0395,  0.0438, -0.0665,  ...,  0.0839,  0.0541,  0.0349],
        [-0.0353, -0.0421,  0.0526,  ..., -0.0388, -0.0620, -0.0545],
        ...,
        [ 0.0381, -0.0122, -0.0514,  ...,  0.0273,  0.0339,  0.0346],
        [ 0.0966,  0.0071, -0.0248,  ...,  0.0581,  0.0072,  0.0613],
        [ 0.0464,  0.0033, -0.0428,  ...,  0.0682,  0.0273,  0.0338]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.4688,  0.0762,  3.4277,  ...,  2.9492, -1.2480, -0.6562]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:41:33 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To optimize results in optimization
To colonize results in colonization
To deprive results in deprivation
To privatize results in privatization
To derive results in derivation
To randomize results in randomization
To consult results in consulation
To characterize results in
2024-08-01 01:41:33 root INFO     [order_1_approx] starting weight calculation for To colonize results in colonization
To characterize results in characterization
To deprive results in deprivation
To optimize results in optimization
To derive results in derivation
To randomize results in randomization
To consult results in consulation
To privatize results in
2024-08-01 01:41:33 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:44:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0415,  0.1072, -0.1643,  ..., -0.1443,  0.1045,  0.1487],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4717, -5.6641,  3.3438,  ..., -1.7646, -0.5469, -2.2480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0167, -0.0256,  0.0250,  ...,  0.0060,  0.0150,  0.0137],
        [-0.0045, -0.0265,  0.0271,  ...,  0.0385,  0.0130,  0.0364],
        [-0.0033,  0.0114, -0.0176,  ..., -0.0071, -0.0327, -0.0320],
        ...,
        [-0.0079, -0.0031,  0.0145,  ...,  0.0013,  0.0334,  0.0219],
        [ 0.0007,  0.0230, -0.0121,  ..., -0.0073, -0.0149, -0.0144],
        [ 0.0377, -0.0337,  0.0492,  ...,  0.0452,  0.0342,  0.0569]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.1270, -4.5234,  2.4316,  ..., -1.0850, -1.0068, -0.6416]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:44:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To colonize results in colonization
To characterize results in characterization
To deprive results in deprivation
To optimize results in optimization
To derive results in derivation
To randomize results in randomization
To consult results in consulation
To privatize results in
2024-08-01 01:44:30 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To characterize results in characterization
To privatize results in privatization
To consult results in consulation
To colonize results in colonization
To deprive results in deprivation
To optimize results in optimization
To derive results in
2024-08-01 01:44:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:47:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1399,  0.3203,  0.0406,  ...,  0.1788, -0.0202,  0.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5713, -4.1016,  1.3789,  ..., -0.3831, -1.2217, -1.4756],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0724, -0.0395, -0.0449,  ..., -0.0338, -0.0880,  0.0673],
        [-0.0124,  0.0473,  0.0199,  ...,  0.0394,  0.0531,  0.0093],
        [-0.0205, -0.0372, -0.0265,  ...,  0.0357,  0.0036, -0.0346],
        ...,
        [-0.0570,  0.0036, -0.0071,  ..., -0.0026,  0.0098,  0.0191],
        [-0.0243, -0.0413, -0.0590,  ..., -0.0105, -0.0141, -0.0060],
        [ 0.0833,  0.0839,  0.0931,  ...,  0.0916,  0.1072, -0.0048]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4727, -3.5469,  1.1113,  ..., -0.7231, -2.4277, -0.1367]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:47:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To randomize results in randomization
To characterize results in characterization
To privatize results in privatization
To consult results in consulation
To colonize results in colonization
To deprive results in deprivation
To optimize results in optimization
To derive results in
2024-08-01 01:47:30 root INFO     [order_1_approx] starting weight calculation for To privatize results in privatization
To consult results in consulation
To derive results in derivation
To deprive results in deprivation
To colonize results in colonization
To characterize results in characterization
To optimize results in optimization
To randomize results in
2024-08-01 01:47:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:50:27 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0296,  0.2495, -0.0064,  ..., -0.0048,  0.1255, -0.0489],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8018, -2.9492,  0.2520,  ...,  0.8545, -3.3457, -4.0430],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0078,  0.1022,  0.0122,  ..., -0.0558, -0.0015, -0.0123],
        [-0.0027, -0.0490, -0.0073,  ...,  0.0595, -0.0018,  0.0134],
        [-0.0114,  0.0190, -0.0125,  ..., -0.0016,  0.0004, -0.0117],
        ...,
        [ 0.0083, -0.0409,  0.0134,  ...,  0.0395, -0.0164,  0.0235],
        [ 0.0336,  0.0214, -0.0127,  ..., -0.0070,  0.0234,  0.0206],
        [ 0.0059, -0.0633, -0.0089,  ...,  0.0326,  0.0071,  0.0071]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.9912, -2.7012,  0.3975,  ...,  1.3955, -3.2578, -3.8516]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:50:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To privatize results in privatization
To consult results in consulation
To derive results in derivation
To deprive results in deprivation
To colonize results in colonization
To characterize results in characterization
To optimize results in optimization
To randomize results in
2024-08-01 01:50:28 root INFO     [order_1_approx] starting weight calculation for To randomize results in randomization
To deprive results in deprivation
To consult results in consulation
To privatize results in privatization
To optimize results in optimization
To derive results in derivation
To characterize results in characterization
To colonize results in
2024-08-01 01:50:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:53:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1313,  0.0566,  0.0072,  ..., -0.0873,  0.2625, -0.0746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.1387, -2.6973,  3.8672,  ..., -0.9102, -1.2793, -2.6016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.5986e-02, -1.7761e-02, -3.1921e-02,  ..., -9.2407e-02,
         -5.1270e-02,  1.7990e-02],
        [ 9.3018e-02,  3.9520e-02,  1.0919e-01,  ...,  2.1606e-01,
          1.0730e-01,  8.2550e-03],
        [-7.0679e-02, -1.3741e-02, -5.4901e-02,  ..., -8.5938e-02,
         -5.8228e-02, -1.1871e-02],
        ...,
        [ 6.4331e-02,  9.6817e-03,  8.8318e-02,  ...,  1.5063e-01,
          9.0393e-02, -5.9032e-04],
        [-1.5717e-03,  4.2191e-03, -4.7211e-02,  ..., -6.0303e-02,
         -7.8430e-03,  1.2863e-02],
        [ 9.4482e-02,  1.6937e-02,  9.0576e-02,  ...,  2.0532e-01,
          8.0078e-02,  1.1063e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.0352,  0.0215,  2.5508,  ...,  1.1777, -1.9277, -0.4277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:53:29 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To randomize results in randomization
To deprive results in deprivation
To consult results in consulation
To privatize results in privatization
To optimize results in optimization
To derive results in derivation
To characterize results in characterization
To colonize results in
2024-08-01 01:53:29 root INFO     [order_1_approx] starting weight calculation for To consult results in consulation
To randomize results in randomization
To privatize results in privatization
To deprive results in deprivation
To colonize results in colonization
To characterize results in characterization
To derive results in derivation
To optimize results in
2024-08-01 01:53:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:56:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0287,  0.0559, -0.0658,  ..., -0.0919,  0.2117, -0.0410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3359, -2.0996,  0.6177,  ..., -0.6152, -2.1094, -2.4922],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0739, -0.0828, -0.0782,  ..., -0.0611, -0.0160,  0.0346],
        [ 0.2247,  0.1266,  0.2292,  ...,  0.0983, -0.0139,  0.0353],
        [-0.0910, -0.0636, -0.1072,  ..., -0.0097,  0.0081, -0.0306],
        ...,
        [ 0.0097,  0.0184,  0.0842,  ...,  0.0152,  0.0015, -0.0043],
        [-0.0073, -0.0410, -0.0069,  ...,  0.0091,  0.0112, -0.0402],
        [ 0.2065,  0.1143,  0.2278,  ...,  0.1003, -0.0012,  0.0288]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6221,  2.2285, -1.1875,  ...,  0.4912, -2.0820,  0.8359]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:56:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To consult results in consulation
To randomize results in randomization
To privatize results in privatization
To deprive results in deprivation
To colonize results in colonization
To characterize results in characterization
To derive results in derivation
To optimize results in
2024-08-01 01:56:27 root INFO     total operator prediction time: 1428.157898426056 seconds
2024-08-01 01:56:27 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+able_reg
2024-08-01 01:56:27 root INFO     building operator verb+able_reg
2024-08-01 01:56:28 root INFO     [order_1_approx] starting weight calculation for If you can advise something, that thing is advisable
If you can renew something, that thing is renewable
If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is affordable
If you can prevent something, that thing is preventable
If you can protect something, that thing is protectable
If you can recommend something, that thing is
2024-08-01 01:56:28 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 01:59:26 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1000,  0.3459,  0.0696,  ...,  0.1157,  0.1700,  0.0496],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.9717, -0.5161, -0.9536,  ..., -1.4297, -7.2891, -3.3711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0037,  0.0082, -0.0122,  ...,  0.0141,  0.0190, -0.0603],
        [-0.0400,  0.0274,  0.0295,  ...,  0.0089,  0.0085,  0.0135],
        [ 0.0172, -0.0152,  0.0255,  ..., -0.0331, -0.0641,  0.0432],
        ...,
        [-0.0262,  0.0396, -0.0461,  ...,  0.0370,  0.0386, -0.0170],
        [ 0.0323,  0.0095, -0.0272,  ...,  0.0218, -0.0339, -0.0174],
        [-0.0263,  0.0080, -0.0150,  ...,  0.0204, -0.0188, -0.0300]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.7168, -1.0059, -1.2549,  ..., -0.9297, -6.6289, -3.3457]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 01:59:27 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can advise something, that thing is advisable
If you can renew something, that thing is renewable
If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can afford something, that thing is affordable
If you can prevent something, that thing is preventable
If you can protect something, that thing is protectable
If you can recommend something, that thing is
2024-08-01 01:59:27 root INFO     [order_1_approx] starting weight calculation for If you can prevent something, that thing is preventable
If you can sustain something, that thing is sustainable
If you can avoid something, that thing is avoidable
If you can afford something, that thing is affordable
If you can renew something, that thing is renewable
If you can advise something, that thing is advisable
If you can recommend something, that thing is recommendable
If you can protect something, that thing is
2024-08-01 01:59:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:02:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0023, -0.1176,  0.0254,  ...,  0.1646,  0.0186, -0.0555],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1191, -2.8281, -2.0898,  ..., -1.5752, -5.5195, -1.9189],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0108, -0.0437,  0.0177,  ..., -0.0057,  0.0116,  0.0008],
        [-0.0486,  0.0066, -0.0110,  ..., -0.0004,  0.0223,  0.0286],
        [ 0.0342, -0.0364,  0.0038,  ..., -0.0023, -0.0086, -0.0169],
        ...,
        [ 0.0320,  0.0157, -0.0002,  ..., -0.0109,  0.0120, -0.0345],
        [ 0.0463,  0.0252, -0.0118,  ...,  0.0099, -0.0399, -0.0077],
        [ 0.0278, -0.0253, -0.0098,  ...,  0.0104,  0.0024, -0.0217]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9604, -2.5391, -2.3086,  ..., -1.8604, -5.6523, -1.8535]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:02:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can prevent something, that thing is preventable
If you can sustain something, that thing is sustainable
If you can avoid something, that thing is avoidable
If you can afford something, that thing is affordable
If you can renew something, that thing is renewable
If you can advise something, that thing is advisable
If you can recommend something, that thing is recommendable
If you can protect something, that thing is
2024-08-01 02:02:26 root INFO     [order_1_approx] starting weight calculation for If you can afford something, that thing is affordable
If you can protect something, that thing is protectable
If you can renew something, that thing is renewable
If you can avoid something, that thing is avoidable
If you can prevent something, that thing is preventable
If you can sustain something, that thing is sustainable
If you can recommend something, that thing is recommendable
If you can advise something, that thing is
2024-08-01 02:02:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:05:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0536,  0.2754, -0.1541,  ...,  0.0921,  0.0929,  0.0257],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0254, -0.7808, -2.9590,  ...,  0.7563, -8.1641, -1.2422],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0303, -0.0382, -0.0385,  ...,  0.0242,  0.0016, -0.0051],
        [-0.0146, -0.0092, -0.0255,  ..., -0.0304,  0.0553,  0.0310],
        [ 0.0144, -0.0062, -0.0800,  ..., -0.0022, -0.0402, -0.0258],
        ...,
        [-0.0115,  0.0112, -0.0102,  ...,  0.0010,  0.0004, -0.0340],
        [ 0.0142,  0.0143, -0.0933,  ...,  0.0668,  0.0005, -0.0014],
        [ 0.0321,  0.0357,  0.0305,  ...,  0.0234, -0.0167, -0.0102]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3770, -0.7573, -2.5449,  ...,  1.3438, -7.7422, -1.3740]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:05:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can afford something, that thing is affordable
If you can protect something, that thing is protectable
If you can renew something, that thing is renewable
If you can avoid something, that thing is avoidable
If you can prevent something, that thing is preventable
If you can sustain something, that thing is sustainable
If you can recommend something, that thing is recommendable
If you can advise something, that thing is
2024-08-01 02:05:25 root INFO     [order_1_approx] starting weight calculation for If you can renew something, that thing is renewable
If you can afford something, that thing is affordable
If you can sustain something, that thing is sustainable
If you can recommend something, that thing is recommendable
If you can prevent something, that thing is preventable
If you can protect something, that thing is protectable
If you can advise something, that thing is advisable
If you can avoid something, that thing is
2024-08-01 02:05:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:08:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.1545, 0.0246, 0.0349,  ..., 0.1034, 0.0735, 0.0836], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7046,  0.1523, -2.9199,  ..., -0.4934, -7.6953, -1.6934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0155, -0.0879,  0.0275,  ...,  0.0481,  0.0360,  0.0045],
        [-0.0271,  0.0191, -0.0382,  ..., -0.0238,  0.0275,  0.0140],
        [ 0.0335, -0.0457,  0.0435,  ...,  0.0502,  0.0402, -0.0052],
        ...,
        [ 0.0004, -0.0108,  0.0629,  ...,  0.0155,  0.0121, -0.0234],
        [ 0.0318,  0.0040,  0.0059,  ..., -0.0201,  0.0145, -0.0257],
        [ 0.0193, -0.0026,  0.0271,  ...,  0.0263, -0.0071, -0.0405]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2876,  0.2529, -2.8867,  ..., -0.7461, -6.9141, -1.8730]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:08:25 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can renew something, that thing is renewable
If you can afford something, that thing is affordable
If you can sustain something, that thing is sustainable
If you can recommend something, that thing is recommendable
If you can prevent something, that thing is preventable
If you can protect something, that thing is protectable
If you can advise something, that thing is advisable
If you can avoid something, that thing is
2024-08-01 02:08:25 root INFO     [order_1_approx] starting weight calculation for If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can prevent something, that thing is preventable
If you can protect something, that thing is protectable
If you can advise something, that thing is advisable
If you can renew something, that thing is renewable
If you can recommend something, that thing is recommendable
If you can afford something, that thing is
2024-08-01 02:08:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:11:23 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0655,  0.2559,  0.1113,  ...,  0.2234,  0.1794,  0.0397],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3125, -0.8008, -3.4844,  ..., -2.3438, -9.9531, -1.5107],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0106, -0.0141,  0.0014,  ...,  0.0042,  0.0130,  0.0052],
        [-0.0001, -0.0021,  0.0192,  ..., -0.0111,  0.0095,  0.0086],
        [ 0.0103, -0.0101,  0.0073,  ...,  0.0081,  0.0122,  0.0117],
        ...,
        [ 0.0246, -0.0076,  0.0322,  ...,  0.0287,  0.0407, -0.0072],
        [-0.0245,  0.0162,  0.0043,  ..., -0.0022, -0.0081,  0.0034],
        [ 0.0106, -0.0362, -0.0309,  ...,  0.0132, -0.0344, -0.0115]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0693, -1.0156, -2.9785,  ..., -1.6836, -8.7031, -1.8564]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:11:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can prevent something, that thing is preventable
If you can protect something, that thing is protectable
If you can advise something, that thing is advisable
If you can renew something, that thing is renewable
If you can recommend something, that thing is recommendable
If you can afford something, that thing is
2024-08-01 02:11:24 root INFO     [order_1_approx] starting weight calculation for If you can avoid something, that thing is avoidable
If you can renew something, that thing is renewable
If you can protect something, that thing is protectable
If you can afford something, that thing is affordable
If you can advise something, that thing is advisable
If you can prevent something, that thing is preventable
If you can recommend something, that thing is recommendable
If you can sustain something, that thing is
2024-08-01 02:11:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:14:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0644,  0.1885,  0.0229,  ...,  0.1475,  0.1917, -0.0961],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1074, -2.3086, -2.1680,  ..., -3.7012, -6.0234, -1.8652],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0066, -0.0027,  0.0128,  ..., -0.0008,  0.0101, -0.0135],
        [-0.0201,  0.0214, -0.0068,  ..., -0.0058,  0.0214,  0.0073],
        [ 0.0279, -0.0027,  0.0249,  ...,  0.0049, -0.0073, -0.0187],
        ...,
        [ 0.0150, -0.0014,  0.0228,  ..., -0.0067, -0.0027,  0.0025],
        [ 0.0028,  0.0134,  0.0054,  ..., -0.0041, -0.0250, -0.0138],
        [-0.0152,  0.0056, -0.0165,  ..., -0.0053, -0.0254, -0.0122]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8301, -2.2441, -2.0625,  ..., -3.4629, -5.9414, -1.9443]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:14:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can avoid something, that thing is avoidable
If you can renew something, that thing is renewable
If you can protect something, that thing is protectable
If you can afford something, that thing is affordable
If you can advise something, that thing is advisable
If you can prevent something, that thing is preventable
If you can recommend something, that thing is recommendable
If you can sustain something, that thing is
2024-08-01 02:14:22 root INFO     [order_1_approx] starting weight calculation for If you can recommend something, that thing is recommendable
If you can sustain something, that thing is sustainable
If you can advise something, that thing is advisable
If you can afford something, that thing is affordable
If you can protect something, that thing is protectable
If you can avoid something, that thing is avoidable
If you can prevent something, that thing is preventable
If you can renew something, that thing is
2024-08-01 02:14:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:17:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1102,  0.2163, -0.0368,  ..., -0.1608,  0.2382, -0.0991],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.0215, -2.5898, -0.8179,  ..., -3.5039, -5.6406, -2.5625],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0107, -0.0424,  0.0353,  ...,  0.0198,  0.0456, -0.0105],
        [-0.0283, -0.0106, -0.0341,  ..., -0.0057,  0.0485,  0.0089],
        [ 0.0202, -0.0126,  0.0064,  ..., -0.0063, -0.0028, -0.0101],
        ...,
        [ 0.0224, -0.0305,  0.0469,  ...,  0.0127, -0.0381, -0.0153],
        [ 0.0530, -0.0167,  0.0258,  ...,  0.0100,  0.0087, -0.0072],
        [ 0.0090,  0.0219,  0.0090,  ...,  0.0138, -0.0070, -0.0441]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.7373, -2.4648, -0.8989,  ..., -3.9062, -5.7422, -2.4531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:17:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can recommend something, that thing is recommendable
If you can sustain something, that thing is sustainable
If you can advise something, that thing is advisable
If you can afford something, that thing is affordable
If you can protect something, that thing is protectable
If you can avoid something, that thing is avoidable
If you can prevent something, that thing is preventable
If you can renew something, that thing is
2024-08-01 02:17:21 root INFO     [order_1_approx] starting weight calculation for If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can protect something, that thing is protectable
If you can afford something, that thing is affordable
If you can advise something, that thing is advisable
If you can recommend something, that thing is recommendable
If you can prevent something, that thing is
2024-08-01 02:17:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:20:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0361,  0.0420,  0.1135,  ...,  0.0969,  0.0234,  0.0019],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0391, -1.9990, -2.5996,  ..., -1.5742, -7.0469, -3.0234],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0073, -0.0074,  0.0086,  ..., -0.0122,  0.0005,  0.0368],
        [-0.0371, -0.0088,  0.0157,  ..., -0.0149,  0.0152,  0.0535],
        [ 0.0070, -0.0173,  0.0596,  ...,  0.0108, -0.0098, -0.0481],
        ...,
        [ 0.0011,  0.0063,  0.0150,  ...,  0.0185,  0.0006, -0.0327],
        [ 0.0687,  0.0139, -0.0377,  ...,  0.0025, -0.0326, -0.0425],
        [ 0.0672, -0.0259, -0.0113,  ...,  0.0313,  0.0153, -0.0491]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8828, -1.9219, -2.8965,  ..., -2.0664, -6.7109, -2.9102]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:20:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for If you can avoid something, that thing is avoidable
If you can sustain something, that thing is sustainable
If you can renew something, that thing is renewable
If you can protect something, that thing is protectable
If you can afford something, that thing is affordable
If you can advise something, that thing is advisable
If you can recommend something, that thing is recommendable
If you can prevent something, that thing is
2024-08-01 02:20:22 root INFO     total operator prediction time: 1434.7901058197021 seconds
2024-08-01 02:20:22 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on un+adj_reg
2024-08-01 02:20:22 root INFO     building operator un+adj_reg
2024-08-01 02:20:22 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of aware is unaware
The opposite of specified is unspecified
The opposite of restricted is unrestricted
The opposite of available is unavailable
The opposite of known is unknown
The opposite of wanted is unwanted
The opposite of happy is
2024-08-01 02:20:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:23:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0177, -0.1930,  0.0043,  ..., -0.0660, -0.1305,  0.1642],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9199, -2.5020,  1.3838,  ..., -3.1035, -1.0576, -0.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0366, -0.0101, -0.0042,  ..., -0.0298, -0.0214,  0.0055],
        [-0.0490, -0.0115,  0.0414,  ..., -0.0045,  0.0135, -0.0384],
        [ 0.0024, -0.0019, -0.0088,  ...,  0.0229, -0.0166,  0.0055],
        ...,
        [-0.0109, -0.0332, -0.0077,  ..., -0.0043, -0.0165, -0.0190],
        [-0.0021,  0.0070, -0.0405,  ...,  0.0183, -0.0385, -0.0007],
        [-0.0474, -0.0179, -0.0206,  ..., -0.0168, -0.0035,  0.0017]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4121, -1.4658,  1.3809,  ..., -2.6602, -1.4053, -0.5146]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:23:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of aware is unaware
The opposite of specified is unspecified
The opposite of restricted is unrestricted
The opposite of available is unavailable
The opposite of known is unknown
The opposite of wanted is unwanted
The opposite of happy is
2024-08-01 02:23:23 root INFO     [order_1_approx] starting weight calculation for The opposite of happy is unhappy
The opposite of specified is unspecified
The opposite of available is unavailable
The opposite of aware is unaware
The opposite of known is unknown
The opposite of wanted is unwanted
The opposite of comfortable is uncomfortable
The opposite of restricted is
2024-08-01 02:23:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:26:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0323, -0.0618, -0.2136,  ...,  0.0260,  0.0340,  0.0289],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7949,  0.2488,  2.2676,  ...,  0.5381, -2.1113, -1.9014],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0369, -0.0502, -0.0674,  ..., -0.0323,  0.0323,  0.0597],
        [-0.0596,  0.0611,  0.0170,  ...,  0.0173,  0.1254, -0.0571],
        [ 0.0580,  0.0218, -0.0084,  ...,  0.0034, -0.0594, -0.0214],
        ...,
        [ 0.0531,  0.0242,  0.0222,  ...,  0.0147, -0.0099, -0.0199],
        [ 0.0455, -0.0372,  0.0032,  ..., -0.0031, -0.1013,  0.0142],
        [-0.0423,  0.0210,  0.0064,  ...,  0.0691,  0.1677,  0.0164]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1621,  1.0723,  1.9258,  ...,  0.2639, -2.5918, -0.6338]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:26:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of happy is unhappy
The opposite of specified is unspecified
The opposite of available is unavailable
The opposite of aware is unaware
The opposite of known is unknown
The opposite of wanted is unwanted
The opposite of comfortable is uncomfortable
The opposite of restricted is
2024-08-01 02:26:23 root INFO     [order_1_approx] starting weight calculation for The opposite of known is unknown
The opposite of wanted is unwanted
The opposite of aware is unaware
The opposite of restricted is unrestricted
The opposite of available is unavailable
The opposite of happy is unhappy
The opposite of specified is unspecified
The opposite of comfortable is
2024-08-01 02:26:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:29:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1226, -0.1284,  0.0687,  ..., -0.0092, -0.2369,  0.2051],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0000, -0.4805,  1.8320,  ..., -1.8086,  1.1221,  1.4248],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0194, -0.0061, -0.0160,  ...,  0.0019, -0.0264, -0.0123],
        [-0.0041,  0.0337,  0.0155,  ..., -0.0107, -0.0158, -0.0105],
        [-0.0016,  0.0194, -0.0056,  ...,  0.0354, -0.0106, -0.0025],
        ...,
        [ 0.0183,  0.0014, -0.0136,  ...,  0.0119, -0.0133, -0.0371],
        [-0.0248,  0.0317, -0.0341,  ...,  0.0254,  0.0127,  0.0200],
        [-0.0198, -0.0178, -0.0353,  ...,  0.0026, -0.0032,  0.0157]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9346, -0.4194,  1.8965,  ..., -1.9639,  1.0020,  1.7646]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:29:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of known is unknown
The opposite of wanted is unwanted
The opposite of aware is unaware
The opposite of restricted is unrestricted
The opposite of available is unavailable
The opposite of happy is unhappy
The opposite of specified is unspecified
The opposite of comfortable is
2024-08-01 02:29:22 root INFO     [order_1_approx] starting weight calculation for The opposite of aware is unaware
The opposite of wanted is unwanted
The opposite of happy is unhappy
The opposite of comfortable is uncomfortable
The opposite of restricted is unrestricted
The opposite of known is unknown
The opposite of specified is unspecified
The opposite of available is
2024-08-01 02:29:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:32:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0428, -0.0513,  0.0474,  ...,  0.0352, -0.1118, -0.0584],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2637, -2.9062,  1.4424,  ..., -1.0889, -1.3545, -0.6201],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0103, -0.0040, -0.0045,  ...,  0.0061, -0.0085,  0.0508],
        [-0.0358, -0.0048, -0.0164,  ...,  0.0151,  0.1251,  0.0158],
        [ 0.0037,  0.0199,  0.0145,  ...,  0.0136, -0.0209, -0.0058],
        ...,
        [-0.0282, -0.0177,  0.0113,  ..., -0.0125,  0.0297,  0.0037],
        [ 0.0009,  0.0456, -0.0087,  ...,  0.0121, -0.0391, -0.0113],
        [-0.0182, -0.0203, -0.0157,  ...,  0.0321,  0.0591,  0.0345]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9438, -0.7031,  0.9404,  ..., -0.6035, -2.3809,  0.5596]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:32:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of aware is unaware
The opposite of wanted is unwanted
The opposite of happy is unhappy
The opposite of comfortable is uncomfortable
The opposite of restricted is unrestricted
The opposite of known is unknown
The opposite of specified is unspecified
The opposite of available is
2024-08-01 02:32:19 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of known is unknown
The opposite of happy is unhappy
The opposite of restricted is unrestricted
The opposite of wanted is unwanted
The opposite of specified is unspecified
The opposite of available is unavailable
The opposite of aware is
2024-08-01 02:32:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:35:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1196,  0.0373, -0.1934,  ..., -0.0302,  0.0331,  0.0144],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8691, -2.2305,  3.4316,  ..., -2.5117, -2.0020, -0.8989],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0413,  0.0004, -0.0267,  ..., -0.0047, -0.0001, -0.0024],
        [-0.0359,  0.0446, -0.0402,  ...,  0.0340,  0.0116, -0.0217],
        [-0.0725, -0.0166,  0.0328,  ...,  0.0176, -0.0285, -0.0215],
        ...,
        [ 0.0005,  0.0565, -0.0012,  ...,  0.0335,  0.0086, -0.0061],
        [ 0.0020, -0.0292, -0.0279,  ..., -0.0132, -0.0155,  0.0128],
        [-0.0193,  0.0352,  0.0112,  ...,  0.0462,  0.0373,  0.0192]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0391, -1.5449,  3.1621,  ..., -2.3320, -2.5977,  0.1675]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:35:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of known is unknown
The opposite of happy is unhappy
The opposite of restricted is unrestricted
The opposite of wanted is unwanted
The opposite of specified is unspecified
The opposite of available is unavailable
The opposite of aware is
2024-08-01 02:35:18 root INFO     [order_1_approx] starting weight calculation for The opposite of specified is unspecified
The opposite of comfortable is uncomfortable
The opposite of available is unavailable
The opposite of aware is unaware
The opposite of restricted is unrestricted
The opposite of happy is unhappy
The opposite of wanted is unwanted
The opposite of known is
2024-08-01 02:35:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:38:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0554,  0.1021, -0.0472,  ...,  0.0853, -0.0790, -0.0791],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5972,  0.9648,  0.7925,  ...,  1.1367, -2.3750, -0.1523],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0205, -0.0161,  0.0074,  ...,  0.0283,  0.0012, -0.0019],
        [-0.0072,  0.0224,  0.0008,  ...,  0.0147,  0.0236, -0.0326],
        [-0.0027, -0.0106,  0.0329,  ...,  0.0215, -0.0330,  0.0061],
        ...,
        [-0.0014,  0.0099, -0.0280,  ...,  0.0046, -0.0301,  0.0145],
        [-0.0227, -0.0167,  0.0168,  ...,  0.0257, -0.0131,  0.0104],
        [-0.0048,  0.0164, -0.0119,  ..., -0.0284,  0.0435,  0.0097]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6689,  1.2812,  0.8428,  ...,  0.9380, -2.8125,  0.2454]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:38:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of specified is unspecified
The opposite of comfortable is uncomfortable
The opposite of available is unavailable
The opposite of aware is unaware
The opposite of restricted is unrestricted
The opposite of happy is unhappy
The opposite of wanted is unwanted
The opposite of known is
2024-08-01 02:38:14 root INFO     [order_1_approx] starting weight calculation for The opposite of comfortable is uncomfortable
The opposite of available is unavailable
The opposite of wanted is unwanted
The opposite of happy is unhappy
The opposite of aware is unaware
The opposite of known is unknown
The opposite of restricted is unrestricted
The opposite of specified is
2024-08-01 02:38:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:41:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0295,  0.0059, -0.1309,  ..., -0.0497, -0.1143, -0.1492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4219,  1.1035,  0.5879,  ...,  1.6143, -0.6094, -1.3486],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0043,  0.0040, -0.0118,  ..., -0.0278, -0.0602,  0.0258],
        [-0.0390,  0.0136, -0.0039,  ...,  0.0226,  0.1158, -0.0042],
        [ 0.0140,  0.0101, -0.0542,  ..., -0.0058,  0.0048,  0.0076],
        ...,
        [-0.0143,  0.0294,  0.0398,  ..., -0.0158,  0.0125, -0.0338],
        [ 0.0243,  0.0123,  0.1011,  ...,  0.0196, -0.0499, -0.0103],
        [-0.0548,  0.0294, -0.0424,  ...,  0.0330,  0.0809,  0.0275]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2383,  2.5391,  0.7979,  ...,  2.3457, -1.2500, -0.1240]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:41:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of comfortable is uncomfortable
The opposite of available is unavailable
The opposite of wanted is unwanted
The opposite of happy is unhappy
The opposite of aware is unaware
The opposite of known is unknown
The opposite of restricted is unrestricted
The opposite of specified is
2024-08-01 02:41:10 root INFO     [order_1_approx] starting weight calculation for The opposite of happy is unhappy
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of aware is unaware
The opposite of specified is unspecified
The opposite of known is unknown
The opposite of comfortable is uncomfortable
The opposite of wanted is
2024-08-01 02:41:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:44:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1094, -0.0317, -0.1632,  ..., -0.0131, -0.0529,  0.0064],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5469, -2.5098,  0.5205,  ...,  0.2942, -2.7852, -1.7617],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0201, -0.0253,  0.0268,  ...,  0.0118, -0.0326,  0.0041],
        [-0.0579,  0.0510,  0.0283,  ..., -0.0157,  0.0339,  0.0016],
        [-0.0254,  0.0178,  0.0003,  ..., -0.0241, -0.0433, -0.0248],
        ...,
        [-0.0076,  0.0172, -0.0023,  ...,  0.0280,  0.0312, -0.0232],
        [ 0.0376, -0.0409, -0.0175,  ...,  0.0168, -0.0466, -0.0220],
        [-0.0882,  0.0881, -0.0476,  ...,  0.0037,  0.0851,  0.0281]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5977, -1.4258,  0.7031,  ...,  0.0330, -3.4121,  0.1172]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:44:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The opposite of happy is unhappy
The opposite of available is unavailable
The opposite of restricted is unrestricted
The opposite of aware is unaware
The opposite of specified is unspecified
The opposite of known is unknown
The opposite of comfortable is uncomfortable
The opposite of wanted is
2024-08-01 02:44:09 root INFO     total operator prediction time: 1426.834822177887 seconds
2024-08-01 02:44:09 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on re+verb_reg
2024-08-01 02:44:09 root INFO     building operator re+verb_reg
2024-08-01 02:44:09 root INFO     [order_1_approx] starting weight calculation for To adjust again is to readjust
To integrate again is to reintegrate
To emerge again is to reemerge
To consider again is to reconsider
To appoint again is to reappoint
To send again is to resend
To appear again is to reappear
To generate again is to
2024-08-01 02:44:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:47:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0336,  0.3123,  0.1049,  ...,  0.0975,  0.0988,  0.0301],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.5703, -1.0957, -0.0586,  ...,  2.1035, -4.1133, -4.0547],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0560,  0.0109, -0.0286,  ..., -0.0140, -0.0366, -0.0112],
        [-0.0429, -0.0067,  0.0147,  ...,  0.0371,  0.0594,  0.0460],
        [ 0.0095, -0.0022,  0.0159,  ...,  0.0074, -0.0054, -0.0180],
        ...,
        [-0.0188,  0.0050,  0.0266,  ...,  0.0616,  0.0375,  0.0218],
        [ 0.0272,  0.0092, -0.0233,  ..., -0.0384, -0.0247, -0.0051],
        [-0.0127, -0.0096,  0.0188,  ...,  0.0390,  0.0671,  0.0355]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.4375, -1.4453, -0.0382,  ...,  2.0332, -3.4727, -3.9746]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:47:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust again is to readjust
To integrate again is to reintegrate
To emerge again is to reemerge
To consider again is to reconsider
To appoint again is to reappoint
To send again is to resend
To appear again is to reappear
To generate again is to
2024-08-01 02:47:09 root INFO     [order_1_approx] starting weight calculation for To generate again is to regenerate
To appear again is to reappear
To appoint again is to reappoint
To integrate again is to reintegrate
To adjust again is to readjust
To consider again is to reconsider
To emerge again is to reemerge
To send again is to
2024-08-01 02:47:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:50:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0929,  0.2299,  0.1274,  ..., -0.0070,  0.1196, -0.0353],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4387, -3.6445, -1.2217,  ...,  1.1484, -3.2988, -2.7305],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0003,  0.0046,  0.0135,  ...,  0.0198,  0.0160,  0.0180],
        [-0.0102, -0.0005,  0.0099,  ...,  0.0091,  0.0097,  0.0090],
        [ 0.0150,  0.0300, -0.0050,  ..., -0.0222,  0.0109, -0.0316],
        ...,
        [-0.0195, -0.0695,  0.0164,  ...,  0.0266,  0.0055,  0.0504],
        [ 0.0488,  0.0471, -0.0293,  ..., -0.0324, -0.0517, -0.0230],
        [-0.0049, -0.0054,  0.0120,  ...,  0.0067, -0.0036,  0.0334]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.4692, -3.0859, -1.7656,  ...,  2.5625, -4.4883, -2.4570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:50:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To generate again is to regenerate
To appear again is to reappear
To appoint again is to reappoint
To integrate again is to reintegrate
To adjust again is to readjust
To consider again is to reconsider
To emerge again is to reemerge
To send again is to
2024-08-01 02:50:08 root INFO     [order_1_approx] starting weight calculation for To adjust again is to readjust
To consider again is to reconsider
To send again is to resend
To integrate again is to reintegrate
To appoint again is to reappoint
To generate again is to regenerate
To emerge again is to reemerge
To appear again is to
2024-08-01 02:50:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:53:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0457,  0.2720, -0.1875,  ..., -0.0099,  0.1880,  0.0358],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4658, -1.4102, -1.5664,  ...,  3.9219, -4.7969, -2.9746],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0156, -0.0063,  0.0186,  ..., -0.0047, -0.0135,  0.0228],
        [ 0.0174,  0.0006,  0.0003,  ..., -0.0065,  0.0235, -0.0020],
        [ 0.0088,  0.0182,  0.0499,  ..., -0.0273,  0.0112,  0.0040],
        ...,
        [-0.0219, -0.0113,  0.0107,  ...,  0.0219, -0.0058,  0.0137],
        [ 0.0229,  0.0121, -0.0354,  ...,  0.0155, -0.0436, -0.0646],
        [ 0.0319, -0.0096, -0.0210,  ..., -0.0023,  0.0146,  0.0191]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0896, -1.6973, -1.5898,  ...,  4.2188, -4.8086, -3.1719]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:53:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To adjust again is to readjust
To consider again is to reconsider
To send again is to resend
To integrate again is to reintegrate
To appoint again is to reappoint
To generate again is to regenerate
To emerge again is to reemerge
To appear again is to
2024-08-01 02:53:07 root INFO     [order_1_approx] starting weight calculation for To emerge again is to reemerge
To send again is to resend
To generate again is to regenerate
To appear again is to reappear
To consider again is to reconsider
To appoint again is to reappoint
To integrate again is to reintegrate
To adjust again is to
2024-08-01 02:53:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:56:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0045,  0.2467, -0.1688,  ..., -0.0901,  0.0598, -0.0393],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5522, -2.2812, -1.6660,  ...,  2.0938, -4.3594, -4.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0120,  0.0099, -0.0083,  ..., -0.0172, -0.0133,  0.0074],
        [ 0.0129, -0.0181, -0.0150,  ...,  0.0051,  0.0422,  0.0180],
        [ 0.0003,  0.0112, -0.0143,  ..., -0.0135,  0.0076,  0.0240],
        ...,
        [ 0.0055, -0.0370,  0.0167,  ...,  0.0506,  0.0302,  0.0123],
        [-0.0149,  0.0094, -0.0132,  ..., -0.0341, -0.0262, -0.0244],
        [ 0.0219,  0.0097,  0.0058,  ...,  0.0058, -0.0081,  0.0086]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7778, -0.4355, -2.1484,  ...,  3.4297, -4.2695, -4.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:56:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To emerge again is to reemerge
To send again is to resend
To generate again is to regenerate
To appear again is to reappear
To consider again is to reconsider
To appoint again is to reappoint
To integrate again is to reintegrate
To adjust again is to
2024-08-01 02:56:06 root INFO     [order_1_approx] starting weight calculation for To appoint again is to reappoint
To appear again is to reappear
To generate again is to regenerate
To emerge again is to reemerge
To send again is to resend
To adjust again is to readjust
To consider again is to reconsider
To integrate again is to
2024-08-01 02:56:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 02:59:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0102,  0.1675, -0.0852,  ...,  0.0480,  0.2092,  0.0150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7148, -3.5039,  1.5547,  ...,  1.5127, -5.1328, -4.5859],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0446,  0.0011,  0.0192,  ..., -0.0481, -0.0984, -0.0189],
        [ 0.0730, -0.0275, -0.0302,  ...,  0.0578,  0.1401,  0.0303],
        [-0.0607,  0.0175,  0.0105,  ..., -0.0702, -0.1047, -0.0222],
        ...,
        [ 0.1449,  0.0078,  0.0203,  ...,  0.0930,  0.1609,  0.0186],
        [-0.0497, -0.0108, -0.0017,  ..., -0.0612, -0.0915,  0.0134],
        [ 0.0414, -0.0147, -0.0072,  ...,  0.0196,  0.0529,  0.0179]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.7383, -1.4531, -0.1953,  ...,  3.9297, -6.1758, -4.1367]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 02:59:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To appoint again is to reappoint
To appear again is to reappear
To generate again is to regenerate
To emerge again is to reemerge
To send again is to resend
To adjust again is to readjust
To consider again is to reconsider
To integrate again is to
2024-08-01 02:59:07 root INFO     [order_1_approx] starting weight calculation for To send again is to resend
To integrate again is to reintegrate
To generate again is to regenerate
To adjust again is to readjust
To emerge again is to reemerge
To consider again is to reconsider
To appear again is to reappear
To appoint again is to
2024-08-01 02:59:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:02:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0740,  0.3037, -0.1309,  ..., -0.0311, -0.0110, -0.1265],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3965, -4.9609,  0.5879,  ...,  2.2188, -6.1055, -4.8086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0333,  0.0002,  0.0405,  ..., -0.0180, -0.0313,  0.0199],
        [-0.0316, -0.0169, -0.0181,  ...,  0.0397,  0.0573,  0.0190],
        [ 0.0338,  0.0297,  0.0390,  ..., -0.0725, -0.0099, -0.0190],
        ...,
        [-0.0467, -0.0084, -0.0458,  ...,  0.0516,  0.0154,  0.0176],
        [-0.0056,  0.0024, -0.0348,  ...,  0.0282, -0.0099, -0.0026],
        [-0.0080, -0.0102,  0.0040,  ...,  0.0120,  0.0044,  0.0271]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0938, -2.9023, -1.2900,  ...,  3.9961, -5.0469, -3.7344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:02:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To send again is to resend
To integrate again is to reintegrate
To generate again is to regenerate
To adjust again is to readjust
To emerge again is to reemerge
To consider again is to reconsider
To appear again is to reappear
To appoint again is to
2024-08-01 03:02:08 root INFO     [order_1_approx] starting weight calculation for To generate again is to regenerate
To adjust again is to readjust
To appear again is to reappear
To send again is to resend
To consider again is to reconsider
To integrate again is to reintegrate
To appoint again is to reappoint
To emerge again is to
2024-08-01 03:02:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:05:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2362,  0.1531, -0.0278,  ...,  0.0489,  0.0300, -0.0303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0205, -0.6123, -1.1172,  ...,  2.8008, -4.1406, -2.8945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0300, -0.0079, -0.0007,  ..., -0.0075, -0.0288, -0.0278],
        [-0.0075,  0.0333, -0.0198,  ...,  0.0343,  0.0092, -0.0224],
        [-0.0219,  0.0321, -0.0395,  ..., -0.0081,  0.0192, -0.0244],
        ...,
        [ 0.0027,  0.0062,  0.0186,  ...,  0.0148,  0.0125, -0.0112],
        [ 0.0266, -0.0028,  0.0110,  ...,  0.0066, -0.0395,  0.0302],
        [ 0.0031,  0.0298, -0.0475,  ...,  0.0074,  0.0240, -0.0202]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7705, -0.9551, -1.3691,  ...,  2.6797, -3.9531, -3.4277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:05:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To generate again is to regenerate
To adjust again is to readjust
To appear again is to reappear
To send again is to resend
To consider again is to reconsider
To integrate again is to reintegrate
To appoint again is to reappoint
To emerge again is to
2024-08-01 03:05:06 root INFO     [order_1_approx] starting weight calculation for To integrate again is to reintegrate
To appear again is to reappear
To emerge again is to reemerge
To appoint again is to reappoint
To adjust again is to readjust
To generate again is to regenerate
To send again is to resend
To consider again is to
2024-08-01 03:05:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:08:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0352,  0.2068, -0.0185,  ...,  0.0725,  0.1162, -0.0161],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.2812, -4.0781,  1.6191,  ..., -0.0547, -2.8574, -3.2715],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0956, -0.0178,  0.0681,  ..., -0.0261, -0.0180,  0.0275],
        [-0.0707, -0.0209, -0.0221,  ...,  0.0384,  0.0173,  0.0225],
        [ 0.1033, -0.0068,  0.0833,  ..., -0.0798, -0.0201,  0.0460],
        ...,
        [-0.1243,  0.0054, -0.0856,  ...,  0.0733,  0.0647, -0.0392],
        [ 0.0949,  0.0217,  0.0199,  ..., -0.0425, -0.0211,  0.0088],
        [-0.0042, -0.0206, -0.0026,  ...,  0.0202, -0.0024,  0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.0322, -3.2773,  0.0352,  ...,  2.1699, -3.8242, -2.9473]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:08:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To integrate again is to reintegrate
To appear again is to reappear
To emerge again is to reemerge
To appoint again is to reappoint
To adjust again is to readjust
To generate again is to regenerate
To send again is to resend
To consider again is to
2024-08-01 03:08:01 root INFO     total operator prediction time: 1432.1351747512817 seconds
2024-08-01 03:08:01 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on adj+ness_reg
2024-08-01 03:08:01 root INFO     building operator adj+ness_reg
2024-08-01 03:08:01 root INFO     [order_1_approx] starting weight calculation for The state of being innovative is innovativeness
The state of being foreign is foreignness
The state of being weak is weakness
The state of being obvious is obviousness
The state of being connected is connectedness
The state of being impressive is impressiveness
The state of being aware is awareness
The state of being serious is
2024-08-01 03:08:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:10:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0259,  0.0582,  0.0019,  ...,  0.0593, -0.1837,  0.1500],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6113, -2.6484, -1.8271,  ..., -3.3027, -1.6465, -3.6484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0060, -0.0191, -0.0046,  ..., -0.0280,  0.0116,  0.0134],
        [-0.0053,  0.0015, -0.0161,  ...,  0.0040,  0.0245,  0.0253],
        [-0.0404, -0.0492, -0.0113,  ...,  0.0227, -0.0200,  0.0110],
        ...,
        [-0.0436, -0.0005, -0.0169,  ..., -0.0077,  0.0050, -0.0081],
        [ 0.0125,  0.0313,  0.0317,  ...,  0.0191,  0.0013, -0.0131],
        [-0.0146, -0.0433, -0.0203,  ...,  0.0178,  0.0106, -0.0117]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0859, -2.3320, -0.6758,  ..., -3.4980, -2.5938, -3.3008]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:10:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being innovative is innovativeness
The state of being foreign is foreignness
The state of being weak is weakness
The state of being obvious is obviousness
The state of being connected is connectedness
The state of being impressive is impressiveness
The state of being aware is awareness
The state of being serious is
2024-08-01 03:10:59 root INFO     [order_1_approx] starting weight calculation for The state of being aware is awareness
The state of being impressive is impressiveness
The state of being innovative is innovativeness
The state of being weak is weakness
The state of being serious is seriousness
The state of being connected is connectedness
The state of being obvious is obviousness
The state of being foreign is
2024-08-01 03:10:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:13:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0103,  0.0922,  0.1945,  ..., -0.1393,  0.0566, -0.0453],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1025, -3.2500,  0.6699,  ..., -2.3672, -3.4336, -1.1309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0293,  0.0073, -0.0231,  ...,  0.0009, -0.0206, -0.0037],
        [-0.0111,  0.0018,  0.0589,  ..., -0.0258,  0.0576,  0.0013],
        [ 0.0164, -0.0110, -0.0052,  ..., -0.0076,  0.0021, -0.0316],
        ...,
        [-0.0211,  0.0282,  0.0196,  ..., -0.0344,  0.0423, -0.0114],
        [ 0.0361, -0.0143, -0.0289,  ..., -0.0070,  0.0102, -0.0193],
        [-0.0155,  0.0249,  0.0338,  ...,  0.0256,  0.0267, -0.0025]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5986, -1.4951,  0.6519,  ..., -1.1924, -3.9688,  0.8047]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:14:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being aware is awareness
The state of being impressive is impressiveness
The state of being innovative is innovativeness
The state of being weak is weakness
The state of being serious is seriousness
The state of being connected is connectedness
The state of being obvious is obviousness
The state of being foreign is
2024-08-01 03:14:00 root INFO     [order_1_approx] starting weight calculation for The state of being serious is seriousness
The state of being weak is weakness
The state of being innovative is innovativeness
The state of being impressive is impressiveness
The state of being foreign is foreignness
The state of being connected is connectedness
The state of being obvious is obviousness
The state of being aware is
2024-08-01 03:14:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:17:00 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1141,  0.1589,  0.0212,  ...,  0.1102,  0.0542, -0.0742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8159, -1.4434, -0.2485,  ..., -0.7280, -4.7852,  1.1309],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098, -0.0027, -0.0151,  ..., -0.0130,  0.0003,  0.0079],
        [-0.0186,  0.0188,  0.0025,  ...,  0.0363,  0.0421, -0.0376],
        [-0.0450,  0.0017,  0.0196,  ...,  0.0295,  0.0154, -0.0168],
        ...,
        [ 0.0138,  0.0190, -0.0066,  ...,  0.0023, -0.0341,  0.0012],
        [ 0.0368,  0.0016,  0.0063,  ...,  0.0080, -0.0026, -0.0013],
        [ 0.0249,  0.0015,  0.0249,  ...,  0.0487,  0.0038,  0.0025]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3418, -1.0459,  1.1895,  ..., -1.4648, -5.5781,  1.6230]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:17:01 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being serious is seriousness
The state of being weak is weakness
The state of being innovative is innovativeness
The state of being impressive is impressiveness
The state of being foreign is foreignness
The state of being connected is connectedness
The state of being obvious is obviousness
The state of being aware is
2024-08-01 03:17:01 root INFO     [order_1_approx] starting weight calculation for The state of being weak is weakness
The state of being obvious is obviousness
The state of being aware is awareness
The state of being impressive is impressiveness
The state of being foreign is foreignness
The state of being connected is connectedness
The state of being serious is seriousness
The state of being innovative is
2024-08-01 03:17:01 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:19:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0179, -0.0035,  0.1431,  ...,  0.0139, -0.0200,  0.0076],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8501, -3.2812, -0.2373,  ...,  1.9023, -0.8447, -2.4512],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0032, -0.0011,  0.0146,  ..., -0.0074, -0.0213,  0.0022],
        [-0.0073, -0.0014, -0.0037,  ...,  0.0034,  0.0177, -0.0021],
        [-0.0068, -0.0102, -0.0092,  ...,  0.0144, -0.0048, -0.0103],
        ...,
        [ 0.0091,  0.0140,  0.0205,  ...,  0.0131,  0.0043,  0.0106],
        [-0.0001,  0.0218, -0.0094,  ...,  0.0137, -0.0069, -0.0037],
        [ 0.0226, -0.0039,  0.0079,  ...,  0.0098,  0.0028,  0.0027]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7964, -3.1699, -0.3123,  ...,  2.0117, -1.4014, -2.0449]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:19:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being weak is weakness
The state of being obvious is obviousness
The state of being aware is awareness
The state of being impressive is impressiveness
The state of being foreign is foreignness
The state of being connected is connectedness
The state of being serious is seriousness
The state of being innovative is
2024-08-01 03:19:55 root INFO     [order_1_approx] starting weight calculation for The state of being connected is connectedness
The state of being aware is awareness
The state of being obvious is obviousness
The state of being foreign is foreignness
The state of being impressive is impressiveness
The state of being serious is seriousness
The state of being innovative is innovativeness
The state of being weak is
2024-08-01 03:19:55 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:22:49 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0543, -0.0341,  0.1499,  ..., -0.0734,  0.0598,  0.0751],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3125, -4.0547, -1.2725,  ..., -5.7070, -0.5679, -4.2344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0098,  0.0550, -0.1335,  ..., -0.0131, -0.0501, -0.0408],
        [-0.0425, -0.1077,  0.2252,  ...,  0.0279,  0.1096,  0.1106],
        [ 0.0019, -0.0122,  0.0020,  ...,  0.0240,  0.0178, -0.0213],
        ...,
        [-0.0313, -0.0893,  0.1444,  ...,  0.0072,  0.0512,  0.0630],
        [ 0.0482,  0.1044, -0.1582,  ..., -0.0068, -0.0742, -0.0861],
        [-0.0046, -0.1042,  0.2139,  ...,  0.0450,  0.1069,  0.0880]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0859,  2.4688, -0.4219,  ..., -1.2969, -6.0039,  2.1602]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:22:50 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being connected is connectedness
The state of being aware is awareness
The state of being obvious is obviousness
The state of being foreign is foreignness
The state of being impressive is impressiveness
The state of being serious is seriousness
The state of being innovative is innovativeness
The state of being weak is
2024-08-01 03:22:50 root INFO     [order_1_approx] starting weight calculation for The state of being innovative is innovativeness
The state of being foreign is foreignness
The state of being weak is weakness
The state of being connected is connectedness
The state of being obvious is obviousness
The state of being serious is seriousness
The state of being aware is awareness
The state of being impressive is
2024-08-01 03:22:50 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:25:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0483,  0.2104,  0.0361,  ..., -0.1892, -0.1575,  0.0675],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4648, -1.8252, -1.3145,  ..., -0.4351, -3.4082, -4.0391],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0345, -0.0148,  0.0450,  ..., -0.0043, -0.1544,  0.0138],
        [-0.0268,  0.0406, -0.0078,  ...,  0.0082,  0.1140,  0.0142],
        [-0.0179, -0.0251,  0.0012,  ..., -0.0190,  0.1310,  0.0010],
        ...,
        [-0.0039,  0.0228, -0.0069,  ..., -0.0050,  0.1056,  0.0244],
        [ 0.0040, -0.0012, -0.0003,  ...,  0.0289, -0.0258, -0.0067],
        [-0.0429, -0.0066,  0.0081,  ...,  0.0011,  0.1699,  0.0281]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0840,  0.3662,  2.0117,  ...,  0.9897, -4.4648, -0.5859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:25:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being innovative is innovativeness
The state of being foreign is foreignness
The state of being weak is weakness
The state of being connected is connectedness
The state of being obvious is obviousness
The state of being serious is seriousness
The state of being aware is awareness
The state of being impressive is
2024-08-01 03:25:53 root INFO     [order_1_approx] starting weight calculation for The state of being connected is connectedness
The state of being foreign is foreignness
The state of being innovative is innovativeness
The state of being aware is awareness
The state of being serious is seriousness
The state of being weak is weakness
The state of being impressive is impressiveness
The state of being obvious is
2024-08-01 03:25:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:28:54 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0187,  0.2859,  0.1365,  ...,  0.0819, -0.1638, -0.0212],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0713, -2.7891, -0.9780,  ..., -2.1367, -5.0781,  1.3047],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0170, -0.0174, -0.0300,  ...,  0.0036, -0.0355,  0.0165],
        [-0.0132,  0.0365, -0.0604,  ...,  0.0381,  0.0288, -0.0208],
        [ 0.0020, -0.0140, -0.0180,  ...,  0.0665, -0.0379, -0.0101],
        ...,
        [ 0.0036, -0.0005, -0.0023,  ...,  0.0309,  0.0331,  0.0277],
        [ 0.0282, -0.0054,  0.0409,  ...,  0.0059, -0.0125, -0.0065],
        [ 0.0084,  0.0072,  0.0173,  ...,  0.0121,  0.0006,  0.0189]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7998, -1.0645, -0.0732,  ..., -1.4629, -6.7070,  0.5796]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:28:55 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being connected is connectedness
The state of being foreign is foreignness
The state of being innovative is innovativeness
The state of being aware is awareness
The state of being serious is seriousness
The state of being weak is weakness
The state of being impressive is impressiveness
The state of being obvious is
2024-08-01 03:28:55 root INFO     [order_1_approx] starting weight calculation for The state of being serious is seriousness
The state of being foreign is foreignness
The state of being aware is awareness
The state of being weak is weakness
The state of being innovative is innovativeness
The state of being impressive is impressiveness
The state of being obvious is obviousness
The state of being connected is
2024-08-01 03:28:56 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:31:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0161,  0.0989,  0.0536,  ...,  0.1892, -0.0242,  0.0350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1582, -2.2148, -1.8525,  ...,  1.7959, -2.3633, -1.2363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0228,  0.0205,  0.0165,  ..., -0.0420, -0.1318,  0.0229],
        [ 0.0571, -0.0460, -0.0434,  ...,  0.0730,  0.2563,  0.0183],
        [ 0.0150, -0.0023,  0.0309,  ...,  0.0181, -0.0375, -0.0114],
        ...,
        [ 0.0450, -0.0454, -0.0189,  ...,  0.0519,  0.1475,  0.0516],
        [-0.0384,  0.0449,  0.0506,  ..., -0.0359, -0.1462, -0.0071],
        [ 0.0641, -0.0741, -0.0625,  ...,  0.0893,  0.2500,  0.0333]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.9619,  0.8262, -1.7422,  ...,  3.6172, -4.3633,  2.2969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:31:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The state of being serious is seriousness
The state of being foreign is foreignness
The state of being aware is awareness
The state of being weak is weakness
The state of being innovative is innovativeness
The state of being impressive is impressiveness
The state of being obvious is obviousness
The state of being connected is
2024-08-01 03:31:58 root INFO     total operator prediction time: 1436.615613937378 seconds
2024-08-01 03:31:58 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on noun+less_reg
2024-08-01 03:31:58 root INFO     building operator noun+less_reg
2024-08-01 03:31:58 root INFO     [order_1_approx] starting weight calculation for Something without bone is boneless
Something without soul is soulless
Something without thought is thoughtless
Something without collar is collarless
Something without spine is spineless
Something without guilt is guiltless
Something without sleeve is sleeveless
Something without goal is
2024-08-01 03:31:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:34:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0934, -0.0316,  0.0108,  ..., -0.0249, -0.1385, -0.0034],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6191, -2.8691, -2.2539,  ..., -2.3711, -1.8242, -1.6094],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0019,  0.0127, -0.0287,  ..., -0.0202, -0.0087,  0.0173],
        [ 0.0190, -0.0006,  0.0256,  ...,  0.0092,  0.0134,  0.0003],
        [ 0.0101,  0.0033, -0.0020,  ..., -0.0032, -0.0139, -0.0196],
        ...,
        [-0.0016, -0.0057,  0.0389,  ..., -0.0005, -0.0105, -0.0185],
        [-0.0117,  0.0014, -0.0270,  ..., -0.0172, -0.0059, -0.0145],
        [ 0.0095, -0.0048,  0.0605,  ...,  0.0534, -0.0034, -0.0001]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6670, -2.0762, -1.8682,  ..., -2.1758, -2.2285,  0.0430]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:34:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without bone is boneless
Something without soul is soulless
Something without thought is thoughtless
Something without collar is collarless
Something without spine is spineless
Something without guilt is guiltless
Something without sleeve is sleeveless
Something without goal is
2024-08-01 03:34:58 root INFO     [order_1_approx] starting weight calculation for Something without goal is goalless
Something without sleeve is sleeveless
Something without soul is soulless
Something without collar is collarless
Something without bone is boneless
Something without spine is spineless
Something without thought is thoughtless
Something without guilt is
2024-08-01 03:34:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:37:58 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0309, -0.0412,  0.0660,  ...,  0.2261,  0.0030,  0.0589],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0664, -2.7461,  0.8916,  ..., -2.5664, -0.9453, -1.2578],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-3.9673e-03,  5.8365e-03, -5.7953e-02,  ..., -6.1035e-05,
         -2.9938e-02, -1.0590e-02],
        [-1.5961e-02,  1.1124e-02,  1.1072e-01,  ..., -3.4027e-03,
          4.5471e-02,  3.4332e-02],
        [ 2.6276e-02, -2.8900e-02, -8.0566e-02,  ...,  3.5706e-02,
         -5.6946e-02, -2.5314e-02],
        ...,
        [ 1.9958e-02, -4.6387e-03,  7.1899e-02,  ..., -2.8305e-03,
          4.1443e-02,  1.9806e-02],
        [ 4.5593e-02,  6.6338e-03, -7.2250e-03,  ..., -7.1869e-03,
          3.0212e-03, -5.2490e-03],
        [-5.7678e-03, -1.2808e-03,  4.5563e-02,  ...,  4.9286e-02,
          3.6499e-02,  2.5314e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3057,  0.0195, -0.9785,  ..., -1.2686, -1.6328, -0.0898]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:37:59 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without goal is goalless
Something without sleeve is sleeveless
Something without soul is soulless
Something without collar is collarless
Something without bone is boneless
Something without spine is spineless
Something without thought is thoughtless
Something without guilt is
2024-08-01 03:37:59 root INFO     [order_1_approx] starting weight calculation for Something without goal is goalless
Something without soul is soulless
Something without spine is spineless
Something without thought is thoughtless
Something without bone is boneless
Something without collar is collarless
Something without guilt is guiltless
Something without sleeve is
2024-08-01 03:37:59 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:40:53 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-7.0496e-02, -1.6553e-01,  1.3550e-01,  ...,  4.0161e-02,
        -3.0518e-05,  4.2084e-02], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9766, -3.7148, -2.4785,  ..., -0.4619, -1.2695,  0.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-4.2534e-04, -6.0577e-03,  9.1553e-03,  ...,  4.8637e-03,
         -3.6469e-03, -7.0076e-03],
        [ 1.7014e-02, -1.6876e-02,  8.2703e-03,  ...,  2.6283e-03,
          1.9241e-02,  2.5558e-03],
        [ 6.8550e-03,  7.8964e-03, -1.3443e-02,  ...,  4.6921e-03,
          8.1024e-03,  2.3285e-02],
        ...,
        [-3.6240e-04, -8.7738e-05, -2.2888e-05,  ...,  6.6042e-04,
          4.8332e-03, -1.0162e-02],
        [-1.3151e-03,  2.9358e-02, -2.2491e-02,  ..., -8.9569e-03,
          1.9043e-02, -1.6670e-03],
        [ 2.3636e-02, -4.0283e-03,  9.0179e-03,  ...,  2.9327e-02,
         -2.4452e-03, -1.0956e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8047, -3.3125, -2.2266,  ..., -0.2394, -1.4785,  0.2583]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:40:54 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without goal is goalless
Something without soul is soulless
Something without spine is spineless
Something without thought is thoughtless
Something without bone is boneless
Something without collar is collarless
Something without guilt is guiltless
Something without sleeve is
2024-08-01 03:40:54 root INFO     [order_1_approx] starting weight calculation for Something without collar is collarless
Something without spine is spineless
Something without soul is soulless
Something without goal is goalless
Something without sleeve is sleeveless
Something without guilt is guiltless
Something without thought is thoughtless
Something without bone is
2024-08-01 03:40:54 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:43:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1604, -0.1013,  0.0551,  ..., -0.0443, -0.0256,  0.0562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6279, -1.4492, -0.0751,  ..., -1.5586, -1.9453, -1.6240],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 2.6398e-03, -4.4594e-03, -7.2403e-03,  ...,  6.8665e-05,
          5.8411e-02,  1.8570e-02],
        [-3.0918e-03, -2.6665e-03,  9.0866e-03,  ...,  3.0121e-02,
          1.1848e-02, -8.6441e-03],
        [ 3.1189e-02, -2.9205e-02,  1.6785e-02,  ..., -1.3161e-02,
         -2.8763e-02, -5.1483e-02],
        ...,
        [-1.5686e-02,  2.8519e-02,  1.2604e-02,  ..., -3.7804e-03,
         -4.1809e-02, -4.8943e-03],
        [ 3.6560e-02,  5.5420e-02, -2.8656e-02,  ..., -2.0386e-02,
         -3.3936e-02, -2.9922e-02],
        [-1.2474e-02,  2.8038e-03, -1.6632e-03,  ...,  3.1189e-02,
         -4.1565e-02, -2.0203e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0869, -0.9614,  0.0759,  ..., -1.2129, -3.1445, -1.6855]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:43:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without collar is collarless
Something without spine is spineless
Something without soul is soulless
Something without goal is goalless
Something without sleeve is sleeveless
Something without guilt is guiltless
Something without thought is thoughtless
Something without bone is
2024-08-01 03:43:57 root INFO     [order_1_approx] starting weight calculation for Something without bone is boneless
Something without soul is soulless
Something without guilt is guiltless
Something without goal is goalless
Something without collar is collarless
Something without spine is spineless
Something without sleeve is sleeveless
Something without thought is
2024-08-01 03:43:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:46:56 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1451, -0.1387,  0.1316,  ...,  0.0488,  0.0038, -0.0149],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8203, -2.0664,  1.1406,  ..., -2.0137, -3.0977, -0.8711],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0148,  0.0501, -0.0138,  ..., -0.0170, -0.0046,  0.0041],
        [ 0.0123,  0.0118, -0.0103,  ...,  0.0165,  0.0047, -0.0177],
        [ 0.0125,  0.0247,  0.0058,  ..., -0.0089, -0.0181, -0.0225],
        ...,
        [-0.0149, -0.0227,  0.0127,  ...,  0.0019,  0.0024, -0.0051],
        [-0.0113, -0.0136,  0.0034,  ..., -0.0012,  0.0225,  0.0043],
        [ 0.0099, -0.0122, -0.0059,  ...,  0.0462,  0.0127, -0.0154]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8115, -1.8594,  1.1133,  ..., -1.9277, -2.6895, -0.5962]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:46:57 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without bone is boneless
Something without soul is soulless
Something without guilt is guiltless
Something without goal is goalless
Something without collar is collarless
Something without spine is spineless
Something without sleeve is sleeveless
Something without thought is
2024-08-01 03:46:57 root INFO     [order_1_approx] starting weight calculation for Something without spine is spineless
Something without sleeve is sleeveless
Something without bone is boneless
Something without goal is goalless
Something without collar is collarless
Something without thought is thoughtless
Something without guilt is guiltless
Something without soul is
2024-08-01 03:46:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:49:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0662,  0.0263,  0.0024,  ..., -0.0835, -0.0923,  0.0214],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6367, -1.3770, -0.1855,  ..., -3.6094, -2.2812,  0.5137],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0218, -0.0149, -0.0358,  ..., -0.0609,  0.0303,  0.0277],
        [ 0.0674,  0.0132,  0.0531,  ...,  0.0819, -0.0662,  0.0003],
        [-0.0093, -0.0207, -0.0543,  ..., -0.0215,  0.0183,  0.0075],
        ...,
        [ 0.0329,  0.0204,  0.0423,  ...,  0.0347, -0.0284,  0.0115],
        [ 0.0418,  0.0119,  0.0097,  ...,  0.0057,  0.0463,  0.0098],
        [ 0.0202,  0.0226, -0.0080,  ...,  0.0409, -0.0152, -0.0069]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4961, -0.4927, -0.0359,  ..., -2.3496, -0.8643,  0.3872]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:49:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without spine is spineless
Something without sleeve is sleeveless
Something without bone is boneless
Something without goal is goalless
Something without collar is collarless
Something without thought is thoughtless
Something without guilt is guiltless
Something without soul is
2024-08-01 03:49:58 root INFO     [order_1_approx] starting weight calculation for Something without soul is soulless
Something without bone is boneless
Something without collar is collarless
Something without sleeve is sleeveless
Something without guilt is guiltless
Something without thought is thoughtless
Something without goal is goalless
Something without spine is
2024-08-01 03:49:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:52:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1080, -0.1366,  0.0719,  ...,  0.1602,  0.0494, -0.0186],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2832, -1.8496, -2.5039,  ..., -1.5430, -2.4336, -0.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0142,  0.0074,  0.0233,  ..., -0.0222,  0.0184, -0.0002],
        [ 0.0412, -0.0100,  0.0584,  ...,  0.0161,  0.0172,  0.0346],
        [ 0.0223, -0.0664, -0.0154,  ..., -0.0233, -0.0362, -0.0180],
        ...,
        [-0.0057,  0.0015,  0.0072,  ..., -0.0019, -0.0160,  0.0111],
        [ 0.0052,  0.0546, -0.0408,  ..., -0.0172,  0.0195,  0.0085],
        [-0.0248, -0.0086, -0.0360,  ...,  0.0112, -0.0063, -0.0057]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2246, -0.7227, -2.2715,  ..., -0.7354, -2.7324, -0.0330]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:52:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without soul is soulless
Something without bone is boneless
Something without collar is collarless
Something without sleeve is sleeveless
Something without guilt is guiltless
Something without thought is thoughtless
Something without goal is goalless
Something without spine is
2024-08-01 03:52:58 root INFO     [order_1_approx] starting weight calculation for Something without soul is soulless
Something without spine is spineless
Something without bone is boneless
Something without thought is thoughtless
Something without sleeve is sleeveless
Something without guilt is guiltless
Something without goal is goalless
Something without collar is
2024-08-01 03:52:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:55:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0530, -0.2045,  0.1852,  ...,  0.1532, -0.0486,  0.0406],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2764, -2.8574, -1.1025,  ...,  0.3557,  1.7520,  0.3916],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0076, -0.0019, -0.0291,  ...,  0.0080, -0.0146,  0.0212],
        [ 0.0886,  0.0046, -0.0276,  ..., -0.0137,  0.0850,  0.0222],
        [-0.0054, -0.0012, -0.0271,  ..., -0.0147, -0.0044, -0.0149],
        ...,
        [ 0.0571,  0.0124, -0.0291,  ..., -0.0068,  0.0089, -0.0569],
        [-0.0791,  0.0132, -0.0483,  ..., -0.0095, -0.0346, -0.0019],
        [ 0.0450, -0.0118, -0.0086,  ...,  0.0087,  0.0446, -0.0153]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4062, -0.7773, -0.9121,  ...,  0.9170, -0.0576,  1.2344]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:55:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Something without soul is soulless
Something without spine is spineless
Something without bone is boneless
Something without thought is thoughtless
Something without sleeve is sleeveless
Something without guilt is guiltless
Something without goal is goalless
Something without collar is
2024-08-01 03:55:48 root INFO     total operator prediction time: 1430.7998688220978 seconds
2024-08-01 03:55:48 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on verb+ment_irreg
2024-08-01 03:55:48 root INFO     building operator verb+ment_irreg
2024-08-01 03:55:49 root INFO     [order_1_approx] starting weight calculation for To enroll results in a enrollment
To commit results in a commitment
To reinforce results in a reinforcement
To reimburse results in a reimbursement
To amuse results in a amusement
To establish results in a establishment
To manage results in a management
To acknowledge results in a
2024-08-01 03:55:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 03:58:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0510,  0.2472, -0.1255,  ...,  0.1134,  0.0464, -0.0302],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.1406, -3.5195, -1.4248,  ...,  1.5342, -3.1016,  1.4717],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0510, -0.0115,  0.0102,  ..., -0.0827, -0.0367,  0.0054],
        [-0.0343,  0.0293,  0.0047,  ...,  0.0863,  0.0275,  0.0186],
        [ 0.0025, -0.0174,  0.0096,  ..., -0.0057, -0.0068, -0.0256],
        ...,
        [-0.0088,  0.0166, -0.0196,  ...,  0.0432,  0.0063,  0.0094],
        [-0.0277,  0.0234, -0.0014,  ...,  0.0241,  0.0115,  0.0077],
        [ 0.0353, -0.0058, -0.0063,  ...,  0.0422, -0.0458,  0.0484]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.9395, -2.2109, -1.6221,  ...,  2.0039, -2.5781,  1.6738]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 03:58:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To enroll results in a enrollment
To commit results in a commitment
To reinforce results in a reinforcement
To reimburse results in a reimbursement
To amuse results in a amusement
To establish results in a establishment
To manage results in a management
To acknowledge results in a
2024-08-01 03:58:45 root INFO     [order_1_approx] starting weight calculation for To acknowledge results in a acknowledgement
To enroll results in a enrollment
To reinforce results in a reinforcement
To establish results in a establishment
To commit results in a commitment
To manage results in a management
To amuse results in a amusement
To reimburse results in a
2024-08-01 03:58:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:01:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0844,  0.1153, -0.1647,  ...,  0.1643,  0.1387, -0.0232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3242, -3.3789, -0.7559,  ..., -1.1836, -2.2734, -2.4238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0446, -0.0472, -0.0746,  ...,  0.0197, -0.0786,  0.0075],
        [-0.0796,  0.0713,  0.1873,  ...,  0.0121,  0.1343, -0.0051],
        [-0.0065, -0.0229,  0.0012,  ..., -0.0177, -0.0019, -0.0267],
        ...,
        [-0.0288,  0.0492,  0.1343,  ...,  0.0017,  0.0895,  0.0165],
        [ 0.0170,  0.0033, -0.0100,  ...,  0.0061, -0.0048,  0.0188],
        [-0.0047,  0.0037,  0.0500,  ...,  0.0295,  0.0147,  0.0416]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0352,  1.8047, -1.1543,  ...,  1.7031, -2.9160, -0.3379]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:01:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To acknowledge results in a acknowledgement
To enroll results in a enrollment
To reinforce results in a reinforcement
To establish results in a establishment
To commit results in a commitment
To manage results in a management
To amuse results in a amusement
To reimburse results in a
2024-08-01 04:01:44 root INFO     [order_1_approx] starting weight calculation for To commit results in a commitment
To establish results in a establishment
To amuse results in a amusement
To manage results in a management
To acknowledge results in a acknowledgement
To reimburse results in a reimbursement
To reinforce results in a reinforcement
To enroll results in a
2024-08-01 04:01:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:04:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1076,  0.0333, -0.0936,  ..., -0.0737,  0.1978, -0.1951],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.4395, -3.1523, -0.8125,  ...,  2.1953, -1.0996, -5.2266],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0578,  0.0871, -0.0020,  ..., -0.0224, -0.0978, -0.0453],
        [-0.0667, -0.0649, -0.0190,  ...,  0.0816,  0.1427,  0.0651],
        [ 0.0560,  0.0052,  0.0239,  ..., -0.0294, -0.0497, -0.0555],
        ...,
        [-0.0390, -0.0526, -0.0069,  ...,  0.0581,  0.0828,  0.0341],
        [ 0.0117,  0.0231, -0.0036,  ...,  0.0077, -0.0272, -0.0163],
        [-0.0168, -0.0543, -0.0298,  ...,  0.0428,  0.0531,  0.0827]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-4.4258,  2.3164, -2.6719,  ...,  5.3359, -1.9043, -1.6387]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:04:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To commit results in a commitment
To establish results in a establishment
To amuse results in a amusement
To manage results in a management
To acknowledge results in a acknowledgement
To reimburse results in a reimbursement
To reinforce results in a reinforcement
To enroll results in a
2024-08-01 04:04:46 root INFO     [order_1_approx] starting weight calculation for To commit results in a commitment
To establish results in a establishment
To manage results in a management
To acknowledge results in a acknowledgement
To reinforce results in a reinforcement
To enroll results in a enrollment
To reimburse results in a reimbursement
To amuse results in a
2024-08-01 04:04:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:07:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0581,  0.1024, -0.1516,  ...,  0.0410,  0.1050,  0.1173],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.2266, -2.3086,  1.7480,  ...,  2.4180, -1.0078, -1.4160],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.1483, -0.0872, -0.0692,  ..., -0.0637, -0.0790,  0.0044],
        [ 0.0980,  0.1256,  0.0649,  ...,  0.0426,  0.1180,  0.0887],
        [-0.0207, -0.0291,  0.0029,  ...,  0.0374, -0.0741, -0.0578],
        ...,
        [ 0.0322,  0.0289,  0.0074,  ...,  0.0098,  0.0371, -0.0048],
        [ 0.0204,  0.0345,  0.0246,  ..., -0.0091, -0.0237,  0.0023],
        [ 0.0530,  0.0516,  0.0230,  ...,  0.0395,  0.0441,  0.0734]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0430,  1.1523,  0.2988,  ...,  2.9219, -1.0098,  0.1992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:07:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To commit results in a commitment
To establish results in a establishment
To manage results in a management
To acknowledge results in a acknowledgement
To reinforce results in a reinforcement
To enroll results in a enrollment
To reimburse results in a reimbursement
To amuse results in a
2024-08-01 04:07:46 root INFO     [order_1_approx] starting weight calculation for To reimburse results in a reimbursement
To reinforce results in a reinforcement
To establish results in a establishment
To acknowledge results in a acknowledgement
To enroll results in a enrollment
To commit results in a commitment
To amuse results in a amusement
To manage results in a
2024-08-01 04:07:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:10:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0648,  0.3101, -0.1306,  ...,  0.0275, -0.1190, -0.1300],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0508, -4.1250,  2.3984,  ...,  2.6191, -2.3008, -3.6445],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0801, -0.0842, -0.0435,  ..., -0.0905, -0.0685,  0.0873],
        [-0.1095,  0.1115,  0.0588,  ...,  0.1431,  0.0979, -0.0908],
        [ 0.0146, -0.0463, -0.0159,  ..., -0.0140, -0.0187,  0.0255],
        ...,
        [-0.0321,  0.0235,  0.0479,  ...,  0.0629,  0.0183, -0.0344],
        [-0.0235,  0.0060,  0.0222,  ...,  0.0106,  0.0105,  0.0039],
        [-0.0341,  0.0137,  0.0455,  ...,  0.0504,  0.0208, -0.0054]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6250, -0.9180,  1.2764,  ...,  3.7383, -1.3340, -2.0859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:10:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reimburse results in a reimbursement
To reinforce results in a reinforcement
To establish results in a establishment
To acknowledge results in a acknowledgement
To enroll results in a enrollment
To commit results in a commitment
To amuse results in a amusement
To manage results in a
2024-08-01 04:10:48 root INFO     [order_1_approx] starting weight calculation for To commit results in a commitment
To acknowledge results in a acknowledgement
To reinforce results in a reinforcement
To reimburse results in a reimbursement
To manage results in a management
To amuse results in a amusement
To enroll results in a enrollment
To establish results in a
2024-08-01 04:10:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:13:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1716,  0.1787, -0.1716,  ...,  0.0503, -0.0044,  0.0372],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.4863, -4.0039, -0.6606,  ...,  3.4844, -2.4102, -0.9214],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0170, -0.0135,  0.0313,  ...,  0.0013, -0.0275,  0.0039],
        [-0.0552,  0.0573,  0.0478,  ...,  0.0457,  0.0927, -0.0319],
        [ 0.0754,  0.0062, -0.0223,  ..., -0.0172, -0.0003, -0.0310],
        ...,
        [-0.0210, -0.0554, -0.0009,  ..., -0.0290, -0.0177,  0.0313],
        [ 0.0251,  0.0367,  0.0183,  ...,  0.0292,  0.0080,  0.0809],
        [ 0.0073, -0.0316,  0.0052,  ...,  0.0217, -0.0155,  0.0109]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6396, -2.7070, -0.3218,  ...,  2.9805, -1.2705, -1.5137]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:13:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To commit results in a commitment
To acknowledge results in a acknowledgement
To reinforce results in a reinforcement
To reimburse results in a reimbursement
To manage results in a management
To amuse results in a amusement
To enroll results in a enrollment
To establish results in a
2024-08-01 04:13:45 root INFO     [order_1_approx] starting weight calculation for To reinforce results in a reinforcement
To manage results in a management
To enroll results in a enrollment
To reimburse results in a reimbursement
To amuse results in a amusement
To establish results in a establishment
To acknowledge results in a acknowledgement
To commit results in a
2024-08-01 04:13:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:16:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0005,  0.2273, -0.1433,  ...,  0.0735,  0.0074, -0.1506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.3379, -4.0820, -0.5669,  ..., -0.4478, -1.1621, -1.5645],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0099, -0.0012,  0.0148,  ..., -0.0333,  0.0251,  0.0256],
        [-0.0255,  0.0757, -0.0287,  ...,  0.0473,  0.0170,  0.0147],
        [ 0.0328, -0.0156,  0.0098,  ...,  0.0275, -0.0296, -0.0351],
        ...,
        [-0.0026,  0.0251, -0.0311,  ...,  0.0537,  0.0144,  0.0128],
        [ 0.0005,  0.0089,  0.0032,  ..., -0.0285, -0.0353,  0.0003],
        [ 0.0211, -0.0088,  0.0206,  ..., -0.0207,  0.0065,  0.0417]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0234, -3.0703, -0.4014,  ..., -0.0183, -0.9556, -0.7749]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:16:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To reinforce results in a reinforcement
To manage results in a management
To enroll results in a enrollment
To reimburse results in a reimbursement
To amuse results in a amusement
To establish results in a establishment
To acknowledge results in a acknowledgement
To commit results in a
2024-08-01 04:16:44 root INFO     [order_1_approx] starting weight calculation for To establish results in a establishment
To acknowledge results in a acknowledgement
To amuse results in a amusement
To enroll results in a enrollment
To reimburse results in a reimbursement
To commit results in a commitment
To manage results in a management
To reinforce results in a
2024-08-01 04:16:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:19:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0052, -0.0923,  0.0846,  ...,  0.1810,  0.1335,  0.1965],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0605, -3.3086,  2.1602,  ...,  3.8105, -2.2422, -3.8262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.1768e-01, -4.6936e-02, -1.6199e-01,  ...,  6.2622e-02,
         -2.0312e-01,  3.4973e-02],
        [ 1.0950e-01,  7.3975e-02,  1.4050e-01,  ..., -3.2867e-02,
          1.6296e-01, -2.8931e-02],
        [-5.8746e-03, -1.5083e-02, -2.4918e-02,  ...,  1.4854e-02,
         -6.9336e-02, -2.5589e-02],
        ...,
        [ 5.3284e-02,  7.2021e-03,  4.4891e-02,  ..., -2.6321e-02,
          5.4993e-02, -4.5471e-03],
        [ 4.3518e-02,  1.9638e-02,  7.6111e-02,  ...,  4.6600e-02,
          5.0262e-02,  2.2034e-02],
        [ 6.0303e-02, -3.0518e-05,  5.8929e-02,  ..., -5.9738e-03,
          6.2805e-02,  1.5320e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-3.1309,  2.0469,  0.4131,  ...,  6.2930, -1.2217, -0.8477]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:19:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for To establish results in a establishment
To acknowledge results in a acknowledgement
To amuse results in a amusement
To enroll results in a enrollment
To reimburse results in a reimbursement
To commit results in a commitment
To manage results in a management
To reinforce results in a
2024-08-01 04:19:45 root INFO     total operator prediction time: 1436.6281678676605 seconds
2024-08-01 04:19:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - nationality
2024-08-01 04:19:45 root INFO     building operator name - nationality
2024-08-01 04:19:45 root INFO     [order_1_approx] starting weight calculation for copernicus was polish
rousseau was french
fermi was italian
kepler was german
raphael was italian
confucius was chinese
truman was american
lincoln was
2024-08-01 04:19:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:22:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0790,  0.0866, -0.0620,  ..., -0.1323,  0.1783, -0.0345],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6191, -1.4248,  2.3516,  ..., -3.4902,  2.1016, -2.6719],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0283,  0.0008, -0.0085,  ...,  0.0047, -0.0251, -0.0037],
        [ 0.0200,  0.0273, -0.0156,  ..., -0.0015,  0.0059,  0.0213],
        [ 0.0008,  0.0086,  0.0233,  ...,  0.0207, -0.0261,  0.0051],
        ...,
        [ 0.0027,  0.0350, -0.0128,  ...,  0.0218,  0.0044,  0.0180],
        [-0.0163, -0.0026,  0.0226,  ...,  0.0061, -0.0215, -0.0115],
        [ 0.0097,  0.0294, -0.0049,  ..., -0.0140,  0.0118,  0.0082]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1875, -1.4814,  1.7012,  ..., -2.9062,  1.8994, -2.3418]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:22:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for copernicus was polish
rousseau was french
fermi was italian
kepler was german
raphael was italian
confucius was chinese
truman was american
lincoln was
2024-08-01 04:22:47 root INFO     [order_1_approx] starting weight calculation for kepler was german
rousseau was french
lincoln was american
confucius was chinese
fermi was italian
truman was american
copernicus was polish
raphael was
2024-08-01 04:22:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:25:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2537, -0.0902,  0.0745,  ..., -0.0865, -0.0207,  0.0532],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.6328, -4.4766,  2.0430,  ..., -4.0938, -1.6963, -1.9766],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0241, -0.0141, -0.0328,  ...,  0.0074,  0.0341,  0.0184],
        [ 0.0076,  0.0150,  0.0069,  ..., -0.0029,  0.0231, -0.0046],
        [ 0.0005,  0.0114,  0.0082,  ..., -0.0081, -0.0023, -0.0087],
        ...,
        [ 0.0161,  0.0049,  0.0158,  ...,  0.0204,  0.0147,  0.0126],
        [-0.0117, -0.0099,  0.0268,  ..., -0.0169,  0.0436,  0.0204],
        [ 0.0040,  0.0270, -0.0247,  ..., -0.0243,  0.0237,  0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8672, -3.8770,  1.8311,  ..., -3.4922, -0.8076, -1.4531]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:25:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was german
rousseau was french
lincoln was american
confucius was chinese
fermi was italian
truman was american
copernicus was polish
raphael was
2024-08-01 04:25:49 root INFO     [order_1_approx] starting weight calculation for raphael was italian
copernicus was polish
kepler was german
rousseau was french
lincoln was american
confucius was chinese
truman was american
fermi was
2024-08-01 04:25:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:28:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2183,  0.0901, -0.1621,  ...,  0.0410, -0.0447,  0.1436],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9902, -3.5430,  0.0276,  ..., -1.5781, -1.0332,  0.2866],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0120, -0.0497, -0.0107,  ...,  0.0141,  0.0045, -0.0654],
        [-0.0054,  0.0580, -0.0348,  ..., -0.0256, -0.0008,  0.0645],
        [ 0.0150, -0.0262,  0.0147,  ...,  0.0023, -0.0119, -0.0040],
        ...,
        [ 0.0101, -0.0069,  0.0242,  ...,  0.0548,  0.0449,  0.0269],
        [-0.0209, -0.0070, -0.0178,  ...,  0.0128,  0.0220,  0.0003],
        [ 0.0131,  0.0835,  0.0187,  ..., -0.0083,  0.0293,  0.0033]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.4004, -3.4551,  0.4041,  ..., -0.9033, -0.2402, -0.1250]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:28:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was italian
copernicus was polish
kepler was german
rousseau was french
lincoln was american
confucius was chinese
truman was american
fermi was
2024-08-01 04:28:49 root INFO     [order_1_approx] starting weight calculation for fermi was italian
copernicus was polish
truman was american
raphael was italian
kepler was german
lincoln was american
confucius was chinese
rousseau was
2024-08-01 04:28:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:31:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1389, -0.1460, -0.3411,  ..., -0.1237,  0.0443,  0.0260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.7695, -4.0430,  1.4707,  ..., -4.7031, -0.2461,  1.8506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0331, -0.0061, -0.0380,  ...,  0.1665, -0.0868, -0.0616],
        [ 0.0410, -0.0066,  0.0158,  ..., -0.1625,  0.0904,  0.0956],
        [-0.0479, -0.0065, -0.0267,  ...,  0.0792, -0.0767, -0.0482],
        ...,
        [ 0.0530, -0.0083,  0.0074,  ..., -0.1076,  0.0891,  0.0634],
        [-0.0064,  0.0043, -0.0436,  ...,  0.0321, -0.0253,  0.0162],
        [ 0.0095,  0.0544, -0.0095,  ..., -0.0873,  0.0213,  0.0990]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.4160, -0.9375, -0.1201,  ..., -1.4141,  0.1218,  3.7578]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:31:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for fermi was italian
copernicus was polish
truman was american
raphael was italian
kepler was german
lincoln was american
confucius was chinese
rousseau was
2024-08-01 04:31:49 root INFO     [order_1_approx] starting weight calculation for rousseau was french
kepler was german
lincoln was american
confucius was chinese
fermi was italian
truman was american
raphael was italian
copernicus was
2024-08-01 04:31:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:34:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0372, -0.0383, -0.2744,  ...,  0.1071,  0.1245, -0.0843],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7227, -5.4375, -0.0852,  ..., -4.7773, -1.5908, -0.6504],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0250,  0.0037,  0.0107,  ...,  0.0082,  0.0215, -0.0091],
        [ 0.0203,  0.0154, -0.0095,  ..., -0.0137, -0.0168,  0.0203],
        [ 0.0119,  0.0027,  0.0271,  ...,  0.0005, -0.0143, -0.0120],
        ...,
        [-0.0027,  0.0113,  0.0227,  ..., -0.0035,  0.0016,  0.0439],
        [-0.0057, -0.0019, -0.0029,  ..., -0.0194,  0.0198,  0.0103],
        [-0.0152,  0.0412, -0.0121,  ..., -0.0057, -0.0179,  0.0025]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2344, -4.4766, -0.2402,  ..., -3.4336, -1.1055,  0.3604]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:34:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for rousseau was french
kepler was german
lincoln was american
confucius was chinese
fermi was italian
truman was american
raphael was italian
copernicus was
2024-08-01 04:34:45 root INFO     [order_1_approx] starting weight calculation for kepler was german
truman was american
copernicus was polish
fermi was italian
raphael was italian
rousseau was french
lincoln was american
confucius was
2024-08-01 04:34:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:37:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0979, -0.0240, -0.2610,  ...,  0.1250, -0.0991, -0.1084],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.6699, -0.9863,  2.2441,  ..., -5.3281,  0.2441,  1.2998],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0063,  0.0055,  0.0041,  ...,  0.0129,  0.0027,  0.0138],
        [ 0.0030,  0.0312,  0.0227,  ...,  0.0114,  0.0033,  0.0057],
        [ 0.0044, -0.0189, -0.0075,  ..., -0.0048, -0.0212, -0.0193],
        ...,
        [ 0.0010,  0.0313,  0.0037,  ...,  0.0138,  0.0113,  0.0121],
        [ 0.0146,  0.0017, -0.0159,  ...,  0.0122, -0.0010,  0.0069],
        [ 0.0107,  0.0029, -0.0133,  ..., -0.0137,  0.0108, -0.0067]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.9160, -0.9561,  2.4121,  ..., -5.0859,  0.3618,  1.2012]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:37:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for kepler was german
truman was american
copernicus was polish
fermi was italian
raphael was italian
rousseau was french
lincoln was american
confucius was
2024-08-01 04:37:44 root INFO     [order_1_approx] starting weight calculation for raphael was italian
rousseau was french
fermi was italian
confucius was chinese
copernicus was polish
truman was american
lincoln was american
kepler was
2024-08-01 04:37:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:40:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0588,  0.1160,  0.0103,  ...,  0.1196,  0.0281, -0.0410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2676, -4.8047,  1.7217,  ..., -2.7324, -1.3799,  0.0767],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0544, -0.0025, -0.0973,  ..., -0.0306,  0.0385, -0.0417],
        [ 0.0922,  0.0493, -0.0089,  ..., -0.0588,  0.0779,  0.0275],
        [-0.0282, -0.0222,  0.0389,  ...,  0.0375, -0.1044,  0.0522],
        ...,
        [ 0.0802,  0.0577,  0.0399,  ..., -0.0508,  0.0815,  0.0012],
        [ 0.0039,  0.0070,  0.0580,  ..., -0.0360,  0.0704,  0.0027],
        [-0.0652,  0.0112,  0.0618,  ...,  0.0180, -0.0110,  0.0979]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5312, -3.6250,  0.5352,  ..., -1.2266, -1.3086, -0.1200]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:40:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was italian
rousseau was french
fermi was italian
confucius was chinese
copernicus was polish
truman was american
lincoln was american
kepler was
2024-08-01 04:40:44 root INFO     [order_1_approx] starting weight calculation for fermi was italian
rousseau was french
confucius was chinese
copernicus was polish
kepler was german
lincoln was american
raphael was italian
truman was
2024-08-01 04:40:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:43:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1304,  0.1229, -0.1451,  ...,  0.0544, -0.0635,  0.0681],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9453, -2.8008,  0.5947,  ..., -3.5488,  2.3887, -1.4648],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0028,  0.0330, -0.0875,  ..., -0.0509, -0.0107, -0.0020],
        [ 0.0316,  0.0209, -0.0241,  ...,  0.0113, -0.0106, -0.0023],
        [-0.0089,  0.0482, -0.0568,  ..., -0.0012, -0.0463,  0.0269],
        ...,
        [-0.0015,  0.0160,  0.0475,  ...,  0.0369, -0.0111, -0.0192],
        [-0.0005,  0.0078,  0.0206,  ...,  0.0288, -0.0002, -0.0033],
        [-0.0099,  0.0194, -0.0201,  ..., -0.0061, -0.0003,  0.0339]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.3086, -2.1367, -0.1284,  ..., -3.1973,  3.1172, -1.3164]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:43:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for fermi was italian
rousseau was french
confucius was chinese
copernicus was polish
kepler was german
lincoln was american
raphael was italian
truman was
2024-08-01 04:43:42 root INFO     total operator prediction time: 1436.651972770691 seconds
2024-08-01 04:43:42 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - language
2024-08-01 04:43:42 root INFO     building operator country - language
2024-08-01 04:43:42 root INFO     [order_1_approx] starting weight calculation for The country of nicaragua primarily speaks the language of spanish
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of palestine primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of guatemala primarily speaks the language of
2024-08-01 04:43:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:46:45 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0119, -0.1639, -0.1420,  ...,  0.0835, -0.1555, -0.0981],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0117, -0.8535,  0.9312,  ..., -0.6289, -1.8066, -4.0938],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-6.9427e-04, -2.2659e-02,  3.2318e-02,  ...,  1.8044e-03,
          1.7715e-02, -1.5137e-02],
        [-5.7602e-03, -1.4015e-02,  3.8300e-02,  ...,  1.7517e-02,
          6.8665e-03, -6.8207e-03],
        [ 2.1439e-02,  1.2398e-02, -3.1250e-02,  ..., -1.1429e-02,
         -1.3733e-02,  2.7710e-02],
        ...,
        [ 7.0953e-04,  2.1637e-02, -2.6703e-02,  ...,  1.8845e-03,
         -7.2784e-03,  1.5205e-02],
        [ 1.0315e-02,  6.5804e-05,  8.7509e-03,  ...,  6.3858e-03,
          2.0782e-02, -7.8659e-03],
        [-6.2408e-03, -2.1896e-02,  2.8610e-02,  ...,  2.1011e-02,
          5.9662e-03, -2.0126e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.5273, -0.4773,  0.2095,  ..., -0.8633, -1.9561, -3.6855]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:46:46 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of nicaragua primarily speaks the language of spanish
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of palestine primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of guatemala primarily speaks the language of
2024-08-01 04:46:46 root INFO     [order_1_approx] starting weight calculation for The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of nicaragua primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of mozambique primarily speaks the language of portuguese
The country of cambodia primarily speaks the language of
2024-08-01 04:46:46 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:49:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2361, -0.0137, -0.1069,  ..., -0.0219, -0.2061, -0.0456],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.7305, -2.4199,  1.0791,  ..., -0.4863, -0.9385,  1.2832],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0234, -0.0969,  0.0865,  ...,  0.0718,  0.1214,  0.0274],
        [ 0.0233, -0.0495,  0.0641,  ...,  0.0410,  0.0522,  0.0152],
        [-0.0238,  0.0982, -0.0305,  ..., -0.0596, -0.1310, -0.0126],
        ...,
        [-0.0155,  0.0390, -0.0570,  ..., -0.0225, -0.0809,  0.0081],
        [ 0.0098, -0.0302,  0.0184,  ...,  0.0331,  0.1068, -0.0163],
        [-0.0061, -0.0288, -0.0106,  ...,  0.0048,  0.0309,  0.0222]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2490, -1.3506, -0.3086,  ..., -1.1055, -0.2954,  1.8486]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:49:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of cyprus primarily speaks the language of greek
The country of nicaragua primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of mozambique primarily speaks the language of portuguese
The country of cambodia primarily speaks the language of
2024-08-01 04:49:51 root INFO     [order_1_approx] starting weight calculation for The country of cambodia primarily speaks the language of khmer
The country of palestine primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of mozambique primarily speaks the language of
2024-08-01 04:49:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:52:55 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1273,  0.0143, -0.0975,  ...,  0.1810, -0.2092, -0.0354],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-3.1201e-01, -3.8945e+00,  1.1855e+00,  ..., -8.2275e-02,
        -8.6914e-02,  1.4648e-03], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.4850e-03, -2.6260e-02,  3.1281e-02,  ...,  4.1351e-03,
          1.4282e-02, -1.2131e-02],
        [ 1.3649e-02, -4.0245e-03,  2.6581e-02,  ...,  2.4490e-03,
          2.1255e-02, -5.3406e-05],
        [ 1.7365e-02,  5.8533e-02, -3.3691e-02,  ...,  1.5564e-03,
         -1.4282e-02,  1.9684e-02],
        ...,
        [-7.8430e-03,  1.4381e-02, -1.8997e-02,  ..., -1.2436e-02,
         -3.0670e-03, -4.3259e-03],
        [ 1.5335e-03,  5.8708e-03, -2.1858e-03,  ...,  1.4664e-02,
          1.4946e-02,  1.2360e-02],
        [-4.8065e-03, -1.4503e-02,  2.6306e-02,  ...,  2.4979e-02,
          1.6830e-02,  3.2425e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.0232, -3.7441,  0.6118,  ..., -0.0653, -0.0487,  0.2849]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:52:56 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of cambodia primarily speaks the language of khmer
The country of palestine primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of australia primarily speaks the language of english
The country of mozambique primarily speaks the language of
2024-08-01 04:52:57 root INFO     [order_1_approx] starting weight calculation for The country of guatemala primarily speaks the language of spanish
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of palestine primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of cambodia primarily speaks the language of khmer
The country of argentina primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of
2024-08-01 04:52:57 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:56:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0395, -0.1025, -0.0992,  ...,  0.1060, -0.1721, -0.1284],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.2930, -1.8955,  0.4146,  ..., -0.1599, -0.9111, -3.4844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-2.8656e-02, -3.6224e-02,  6.6772e-02,  ..., -2.3178e-02,
          2.9846e-02, -5.0995e-02],
        [ 8.1100e-03, -1.1108e-02,  2.1896e-02,  ...,  0.0000e+00,
          1.7548e-02, -1.0925e-02],
        [ 1.1230e-02,  1.8509e-02, -7.0679e-02,  ...,  1.5015e-02,
         -2.4597e-02,  3.5767e-02],
        ...,
        [ 9.5901e-03,  2.0432e-02, -3.6469e-02,  ...,  9.7122e-03,
         -1.1063e-02,  2.5696e-02],
        [-5.0507e-03, -9.3002e-03,  3.0792e-02,  ...,  1.3611e-02,
          1.3535e-02, -6.9122e-03],
        [-4.6692e-03, -2.9572e-02,  3.9154e-02,  ..., -7.6294e-06,
          5.1880e-03, -2.4414e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6489, -1.5957, -0.1909,  ..., -0.3813, -0.7383, -3.1445]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:56:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of guatemala primarily speaks the language of spanish
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of palestine primarily speaks the language of arabic
The country of cyprus primarily speaks the language of greek
The country of cambodia primarily speaks the language of khmer
The country of argentina primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of
2024-08-01 04:56:02 root INFO     [order_1_approx] starting weight calculation for The country of palestine primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of cyprus primarily speaks the language of
2024-08-01 04:56:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 04:59:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1747, -0.0690, -0.1025,  ...,  0.1143, -0.0255,  0.0865],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3594, -4.4258, -1.0488,  ..., -1.7090, -1.6562, -1.2764],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0090, -0.0702,  0.0610,  ...,  0.0380,  0.0990, -0.0072],
        [-0.0105, -0.0076,  0.0198,  ...,  0.0049,  0.0374,  0.0149],
        [ 0.0134,  0.0435, -0.0310,  ..., -0.0123, -0.0424, -0.0035],
        ...,
        [ 0.0227,  0.0572, -0.0394,  ..., -0.0122, -0.0485,  0.0072],
        [-0.0082, -0.0513,  0.0364,  ...,  0.0381,  0.0811, -0.0022],
        [-0.0213, -0.0059,  0.0112,  ...,  0.0218,  0.0047,  0.0102]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6025, -4.1133, -1.5205,  ..., -2.1855, -1.2080, -1.0762]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 04:59:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of palestine primarily speaks the language of arabic
The country of argentina primarily speaks the language of spanish
The country of nicaragua primarily speaks the language of spanish
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of guatemala primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of cyprus primarily speaks the language of
2024-08-01 04:59:09 root INFO     [order_1_approx] starting weight calculation for The country of nicaragua primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of palestine primarily speaks the language of
2024-08-01 04:59:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:02:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1161,  0.0429, -0.2151,  ...,  0.2720,  0.1067,  0.0842],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0322, -4.4062, -0.0046,  ..., -2.1270,  0.7676, -0.6055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.1932e-02, -6.1035e-03,  7.5684e-03,  ...,  1.1467e-02,
          2.6642e-02, -1.2527e-02],
        [-6.4621e-03,  6.1798e-03,  5.9967e-03,  ...,  5.2452e-04,
          2.1332e-02, -8.1329e-03],
        [ 1.1963e-02, -7.5607e-03, -6.1035e-05,  ..., -1.8587e-03,
         -1.3992e-02,  1.1826e-02],
        ...,
        [ 8.3847e-03,  1.3290e-02, -7.5912e-03,  ..., -3.9864e-03,
         -2.0660e-02,  1.3268e-02],
        [-1.5991e-02, -2.3785e-03, -4.2419e-03,  ...,  1.5808e-02,
          9.9640e-03, -4.3411e-03],
        [-1.1559e-02, -1.0246e-02, -1.5774e-03,  ...,  1.1253e-02,
          6.7749e-03,  5.4703e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7451, -4.3359, -0.0677,  ..., -2.3672,  0.8604, -0.4448]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:02:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of nicaragua primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of argentina primarily speaks the language of spanish
The country of guatemala primarily speaks the language of spanish
The country of cyprus primarily speaks the language of greek
The country of palestine primarily speaks the language of
2024-08-01 05:02:14 root INFO     [order_1_approx] starting weight calculation for The country of cyprus primarily speaks the language of greek
The country of mozambique primarily speaks the language of portuguese
The country of nicaragua primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of argentina primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of guatemala primarily speaks the language of spanish
The country of australia primarily speaks the language of
2024-08-01 05:02:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:05:19 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0210,  0.0707, -0.0574,  ...,  0.0361, -0.0523, -0.0350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2627, -2.2715,  0.9849,  ...,  0.0522, -0.8750, -1.7695],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-4.2267e-03, -8.8806e-03, -7.6675e-03,  ...,  1.2474e-02,
          2.4963e-02, -2.3865e-02],
        [-1.2100e-02, -1.2054e-03,  7.7057e-03,  ...,  1.9318e-02,
          4.1077e-02, -1.8005e-02],
        [ 2.0264e-02,  1.5656e-02,  6.2103e-03,  ..., -1.7288e-02,
         -2.2919e-02,  2.2583e-02],
        ...,
        [ 3.0403e-03,  6.3171e-03, -5.1880e-03,  ...,  8.3923e-05,
         -1.5594e-02,  6.8321e-03],
        [-1.4832e-02, -2.7924e-03,  1.3664e-02,  ...,  2.6337e-02,
          2.2858e-02, -1.7456e-02],
        [-1.9440e-02, -1.9684e-02, -1.4091e-02,  ...,  2.2614e-02,
          2.6718e-02, -8.4381e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4707, -2.2246,  0.6079,  ...,  0.0319, -0.7212, -1.5342]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:05:20 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of cyprus primarily speaks the language of greek
The country of mozambique primarily speaks the language of portuguese
The country of nicaragua primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of argentina primarily speaks the language of spanish
The country of palestine primarily speaks the language of arabic
The country of guatemala primarily speaks the language of spanish
The country of australia primarily speaks the language of
2024-08-01 05:05:20 root INFO     [order_1_approx] starting weight calculation for The country of cyprus primarily speaks the language of greek
The country of guatemala primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of argentina primarily speaks the language of
2024-08-01 05:05:20 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:08:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1733, -0.0544, -0.2363,  ...,  0.0341, -0.0916, -0.0288],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8369, -3.3125,  0.2632,  ...,  0.8672,  0.4004, -1.4414],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0035,  0.0016,  0.0085,  ...,  0.0021,  0.0031, -0.0183],
        [-0.0132,  0.0062,  0.0004,  ...,  0.0183,  0.0098, -0.0044],
        [ 0.0369, -0.0093, -0.0048,  ..., -0.0073, -0.0151,  0.0113],
        ...,
        [ 0.0240, -0.0076, -0.0086,  ..., -0.0132, -0.0134,  0.0138],
        [-0.0116, -0.0005,  0.0089,  ...,  0.0097,  0.0135,  0.0067],
        [-0.0222, -0.0044, -0.0199,  ...,  0.0142, -0.0056, -0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1602, -3.1387, -0.1880,  ...,  0.7554,  0.7637, -1.3594]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:08:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country of cyprus primarily speaks the language of greek
The country of guatemala primarily speaks the language of spanish
The country of cambodia primarily speaks the language of khmer
The country of mozambique primarily speaks the language of portuguese
The country of australia primarily speaks the language of english
The country of palestine primarily speaks the language of arabic
The country of nicaragua primarily speaks the language of spanish
The country of argentina primarily speaks the language of
2024-08-01 05:08:26 root INFO     total operator prediction time: 1483.8506126403809 seconds
2024-08-01 05:08:26 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - shelter
2024-08-01 05:08:26 root INFO     building operator animal - shelter
2024-08-01 05:08:26 root INFO     [order_1_approx] starting weight calculation for The place fish lives in is called sea
The place ant lives in is called anthill
The place pig lives in is called sty
The place trout lives in is called river
The place locust lives in is called nest
The place beaver lives in is called dam
The place hippopotamus lives in is called river
The place fly lives in is called
2024-08-01 05:08:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:11:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0945,  0.0132, -0.1144,  ..., -0.0701,  0.0149,  0.0963],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9102, -3.8125,  2.9785,  ...,  0.8706, -0.2358,  0.3506],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0001, -0.0161,  0.0019,  ...,  0.0116, -0.0325,  0.0131],
        [-0.0609, -0.0233,  0.0036,  ...,  0.0346,  0.0071,  0.0082],
        [ 0.0467,  0.0137,  0.0197,  ..., -0.0101, -0.0244, -0.0036],
        ...,
        [-0.0246, -0.0072,  0.0018,  ..., -0.0083, -0.0008,  0.0032],
        [ 0.0051, -0.0181, -0.0109,  ...,  0.0073,  0.0296,  0.0061],
        [-0.0354, -0.0028, -0.0194,  ..., -0.0588,  0.0121,  0.0479]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0117, -3.7695,  2.2578,  ...,  0.4751, -0.2620,  0.4556]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:11:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fish lives in is called sea
The place ant lives in is called anthill
The place pig lives in is called sty
The place trout lives in is called river
The place locust lives in is called nest
The place beaver lives in is called dam
The place hippopotamus lives in is called river
The place fly lives in is called
2024-08-01 05:11:26 root INFO     [order_1_approx] starting weight calculation for The place pig lives in is called sty
The place beaver lives in is called dam
The place trout lives in is called river
The place locust lives in is called nest
The place fly lives in is called nest
The place fish lives in is called sea
The place ant lives in is called anthill
The place hippopotamus lives in is called
2024-08-01 05:11:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:14:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0671, -0.0312, -0.0615,  ..., -0.1115,  0.1232, -0.2178],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8477, -6.5234,  1.3945,  ..., -2.5996,  1.3262, -0.0996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0019, -0.0024, -0.0142,  ..., -0.0106, -0.0174, -0.0197],
        [ 0.0004, -0.0025,  0.0458,  ..., -0.0118,  0.0308,  0.0148],
        [-0.0039,  0.0182, -0.0415,  ...,  0.0156, -0.0454, -0.0099],
        ...,
        [ 0.0030,  0.0001,  0.0018,  ...,  0.0013, -0.0031,  0.0113],
        [ 0.0006,  0.0037, -0.0272,  ...,  0.0190, -0.0172, -0.0037],
        [-0.0068, -0.0129,  0.0214,  ..., -0.0026,  0.0226,  0.0057]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.9375, -6.2188,  0.9922,  ..., -2.3516,  0.9590,  0.0498]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:14:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place pig lives in is called sty
The place beaver lives in is called dam
The place trout lives in is called river
The place locust lives in is called nest
The place fly lives in is called nest
The place fish lives in is called sea
The place ant lives in is called anthill
The place hippopotamus lives in is called
2024-08-01 05:14:26 root INFO     [order_1_approx] starting weight calculation for The place locust lives in is called nest
The place beaver lives in is called dam
The place ant lives in is called anthill
The place fly lives in is called nest
The place hippopotamus lives in is called river
The place pig lives in is called sty
The place trout lives in is called river
The place fish lives in is called
2024-08-01 05:14:26 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:17:24 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0422,  0.1183, -0.0915,  ..., -0.1721, -0.1720,  0.0479],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0605, -5.4102,  2.0195,  ..., -3.5137, -0.9434, -1.9707],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0046, -0.0835,  0.0103,  ...,  0.0497,  0.0046,  0.0402],
        [-0.0296, -0.0095,  0.0201,  ...,  0.0393, -0.0076,  0.0086],
        [ 0.0188,  0.0078,  0.0009,  ..., -0.0073,  0.0018, -0.0174],
        ...,
        [-0.0107, -0.0189,  0.0086,  ..., -0.0028,  0.0132, -0.0066],
        [ 0.0318,  0.0346, -0.0017,  ..., -0.0301,  0.0078, -0.0082],
        [-0.0222, -0.0345, -0.0130,  ...,  0.0066,  0.0135,  0.0185]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3945, -4.9297,  1.6533,  ..., -3.0586, -1.4092, -1.6260]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:17:24 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place locust lives in is called nest
The place beaver lives in is called dam
The place ant lives in is called anthill
The place fly lives in is called nest
The place hippopotamus lives in is called river
The place pig lives in is called sty
The place trout lives in is called river
The place fish lives in is called
2024-08-01 05:17:25 root INFO     [order_1_approx] starting weight calculation for The place locust lives in is called nest
The place ant lives in is called anthill
The place hippopotamus lives in is called river
The place fish lives in is called sea
The place fly lives in is called nest
The place pig lives in is called sty
The place beaver lives in is called dam
The place trout lives in is called
2024-08-01 05:17:25 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:20:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0671,  0.0197, -0.1439,  ..., -0.1277,  0.0098, -0.0429],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.5547, -6.2656,  2.4805,  ..., -2.0449,  0.0562, -3.4297],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0467, -0.1504,  0.0577,  ..., -0.0255,  0.0060,  0.0179],
        [-0.0413,  0.0131, -0.0331,  ..., -0.0323,  0.0291,  0.0156],
        [-0.0135, -0.0411, -0.0126,  ...,  0.0028, -0.0095, -0.0146],
        ...,
        [ 0.0183,  0.0517, -0.0177,  ...,  0.0648,  0.0045, -0.0236],
        [ 0.0510,  0.0125, -0.0075,  ...,  0.0241, -0.0042, -0.0215],
        [-0.0190, -0.1848,  0.0486,  ..., -0.0213,  0.1006,  0.0637]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6523, -6.0469,  2.9023,  ..., -2.0684, -0.2712, -2.0117]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:20:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place locust lives in is called nest
The place ant lives in is called anthill
The place hippopotamus lives in is called river
The place fish lives in is called sea
The place fly lives in is called nest
The place pig lives in is called sty
The place beaver lives in is called dam
The place trout lives in is called
2024-08-01 05:20:24 root INFO     [order_1_approx] starting weight calculation for The place ant lives in is called anthill
The place trout lives in is called river
The place hippopotamus lives in is called river
The place fish lives in is called sea
The place fly lives in is called nest
The place locust lives in is called nest
The place pig lives in is called sty
The place beaver lives in is called
2024-08-01 05:20:24 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:23:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0555,  0.1533, -0.1194,  ..., -0.0774, -0.0248, -0.0034],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.7949, -7.7539, -1.4170,  ..., -3.9355,  1.6377, -0.5996],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0142, -0.0658, -0.0249,  ..., -0.0471, -0.0204,  0.0093],
        [-0.0035,  0.0487, -0.0518,  ...,  0.0443,  0.0471,  0.0036],
        [-0.0300,  0.0087,  0.0409,  ...,  0.0513, -0.0785,  0.0007],
        ...,
        [ 0.0172,  0.0132, -0.0078,  ...,  0.0692, -0.0029,  0.0108],
        [ 0.0302,  0.0284,  0.0178,  ...,  0.0710, -0.0240, -0.0035],
        [-0.0276,  0.0151, -0.0634,  ..., -0.0373,  0.0142,  0.0528]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8652, -6.6250, -1.7617,  ..., -3.5723,  1.5615, -0.6040]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:23:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place ant lives in is called anthill
The place trout lives in is called river
The place hippopotamus lives in is called river
The place fish lives in is called sea
The place fly lives in is called nest
The place locust lives in is called nest
The place pig lives in is called sty
The place beaver lives in is called
2024-08-01 05:23:22 root INFO     [order_1_approx] starting weight calculation for The place fly lives in is called nest
The place locust lives in is called nest
The place trout lives in is called river
The place beaver lives in is called dam
The place pig lives in is called sty
The place fish lives in is called sea
The place hippopotamus lives in is called river
The place ant lives in is called
2024-08-01 05:23:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:26:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0883,  0.0463, -0.0144,  ..., -0.1036, -0.0859, -0.2139],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4336, -6.0625,  1.2012,  ..., -2.6152,  2.0273, -3.2109],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-1.8967e-02, -7.1167e-02, -6.1768e-02,  ...,  6.8054e-03,
          7.9346e-03,  7.9346e-03],
        [-1.4160e-01, -9.2041e-02, -1.6016e-01,  ...,  2.6260e-02,
          5.7983e-02, -6.1035e-05],
        [ 7.0648e-03,  1.1749e-02,  2.1973e-02,  ..., -5.7587e-02,
         -3.7842e-02, -2.2400e-02],
        ...,
        [-8.5205e-02, -8.8959e-03, -9.1064e-02,  ...,  1.1215e-02,
          4.8218e-02,  1.1963e-02],
        [ 4.6936e-02,  1.8311e-02,  8.4473e-02,  ..., -1.0193e-02,
          1.9836e-03, -2.3605e-02],
        [-1.2573e-01, -5.9998e-02, -8.2886e-02,  ..., -3.9482e-04,
         -5.5542e-03, -2.7466e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2676, -3.6816,  1.3672,  ..., -1.5713,  1.3730, -1.9375]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:26:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fly lives in is called nest
The place locust lives in is called nest
The place trout lives in is called river
The place beaver lives in is called dam
The place pig lives in is called sty
The place fish lives in is called sea
The place hippopotamus lives in is called river
The place ant lives in is called
2024-08-01 05:26:22 root INFO     [order_1_approx] starting weight calculation for The place fish lives in is called sea
The place pig lives in is called sty
The place ant lives in is called anthill
The place hippopotamus lives in is called river
The place beaver lives in is called dam
The place trout lives in is called river
The place fly lives in is called nest
The place locust lives in is called
2024-08-01 05:26:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:29:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0895, -0.2013, -0.0604,  ..., -0.1058,  0.0970,  0.0565],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.9805, -5.8516,  2.3398,  ..., -0.4304,  1.7266, -3.7344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188, -0.0047, -0.0113,  ...,  0.0098,  0.0408,  0.0261],
        [-0.0242, -0.0162,  0.0396,  ...,  0.0413, -0.0267, -0.0181],
        [-0.0265,  0.0055,  0.0205,  ..., -0.0118, -0.1262, -0.0406],
        ...,
        [-0.0782,  0.0325,  0.0413,  ...,  0.0858,  0.0286,  0.0518],
        [-0.0270,  0.0320, -0.0250,  ..., -0.0142,  0.0225, -0.0319],
        [ 0.0280,  0.0183,  0.0220,  ...,  0.0017, -0.0329,  0.0354]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 5.1367, -5.4844,  2.5332,  ...,  0.0784,  1.7666, -3.1406]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:29:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place fish lives in is called sea
The place pig lives in is called sty
The place ant lives in is called anthill
The place hippopotamus lives in is called river
The place beaver lives in is called dam
The place trout lives in is called river
The place fly lives in is called nest
The place locust lives in is called
2024-08-01 05:29:22 root INFO     [order_1_approx] starting weight calculation for The place ant lives in is called anthill
The place trout lives in is called river
The place beaver lives in is called dam
The place locust lives in is called nest
The place fish lives in is called sea
The place hippopotamus lives in is called river
The place fly lives in is called nest
The place pig lives in is called
2024-08-01 05:29:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:32:22 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0160,  0.1642,  0.0218,  ...,  0.0654,  0.1056, -0.1119],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.8906, -7.1641,  3.8203,  ..., -2.0898,  0.2935,  1.4629],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0196, -0.0341,  0.0073,  ...,  0.0166,  0.0012, -0.0265],
        [-0.0003,  0.0106,  0.0179,  ...,  0.0134, -0.0045,  0.0084],
        [ 0.0031,  0.0162,  0.0092,  ..., -0.0319, -0.0054, -0.0085],
        ...,
        [-0.0101,  0.0016, -0.0119,  ...,  0.0168, -0.0056,  0.0061],
        [ 0.0215,  0.0056,  0.0096,  ...,  0.0167,  0.0098,  0.0183],
        [-0.0043, -0.0147,  0.0014,  ...,  0.0142, -0.0363,  0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.8438, -6.9805,  3.9102,  ..., -2.1133,  0.3022,  1.5615]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:32:23 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The place ant lives in is called anthill
The place trout lives in is called river
The place beaver lives in is called dam
The place locust lives in is called nest
The place fish lives in is called sea
The place hippopotamus lives in is called river
The place fly lives in is called nest
The place pig lives in is called
2024-08-01 05:32:23 root INFO     total operator prediction time: 1436.996556520462 seconds
2024-08-01 05:32:23 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on male - female
2024-08-01 05:32:23 root INFO     building operator male - female
2024-08-01 05:32:23 root INFO     [order_1_approx] starting weight calculation for A female manager is known as a manageress
A female hound is known as a bitch
A female uncle is known as a aunt
A female man is known as a woman
A female mister is known as a miss
A female headmaster is known as a headmistress
A female waiter is known as a waitress
A female hero is known as a
2024-08-01 05:32:23 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:35:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1246,  0.2703, -0.0007,  ...,  0.0573, -0.0672, -0.0323],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.5859, -6.4453, -0.6948,  ..., -1.7812, -3.1172,  0.1060],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0042, -0.0146,  0.0488,  ..., -0.0072, -0.0008, -0.0186],
        [ 0.0362,  0.0086,  0.0040,  ...,  0.0400,  0.0210, -0.0264],
        [-0.0143,  0.0357,  0.0384,  ..., -0.0124, -0.0288, -0.0260],
        ...,
        [ 0.0385,  0.0207,  0.0046,  ...,  0.0664,  0.0062,  0.0191],
        [-0.0149,  0.0098, -0.0041,  ..., -0.0062, -0.0011,  0.0030],
        [ 0.0283, -0.0172, -0.0075,  ...,  0.0335,  0.0276,  0.0274]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4688, -5.3906, -1.2100,  ..., -0.8247, -3.0215, -0.0402]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:35:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female manager is known as a manageress
A female hound is known as a bitch
A female uncle is known as a aunt
A female man is known as a woman
A female mister is known as a miss
A female headmaster is known as a headmistress
A female waiter is known as a waitress
A female hero is known as a
2024-08-01 05:35:22 root INFO     [order_1_approx] starting weight calculation for A female hero is known as a heroine
A female uncle is known as a aunt
A female man is known as a woman
A female headmaster is known as a headmistress
A female waiter is known as a waitress
A female hound is known as a bitch
A female mister is known as a miss
A female manager is known as a
2024-08-01 05:35:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:38:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0081,  0.2084,  0.1191,  ...,  0.3003,  0.0077, -0.1736],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 5.3281, -5.2578, -0.1968,  ...,  1.7725, -2.8164, -3.1055],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0257, -0.0469,  0.0005,  ..., -0.0363, -0.0667,  0.0390],
        [ 0.0227,  0.0178,  0.0041,  ...,  0.0482,  0.1047, -0.0204],
        [-0.0046, -0.0250,  0.0141,  ..., -0.0196, -0.0249, -0.0129],
        ...,
        [ 0.0235,  0.0207, -0.0098,  ...,  0.0160,  0.0041, -0.0144],
        [ 0.0124, -0.0178, -0.0034,  ..., -0.0306, -0.0151,  0.0068],
        [ 0.0305,  0.0012, -0.0023,  ...,  0.0330,  0.0305,  0.0062]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3047, -3.5508,  0.1206,  ...,  1.8457, -3.1738, -2.8398]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:38:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female hero is known as a heroine
A female uncle is known as a aunt
A female man is known as a woman
A female headmaster is known as a headmistress
A female waiter is known as a waitress
A female hound is known as a bitch
A female mister is known as a miss
A female manager is known as a
2024-08-01 05:38:22 root INFO     [order_1_approx] starting weight calculation for A female waiter is known as a waitress
A female uncle is known as a aunt
A female headmaster is known as a headmistress
A female hero is known as a heroine
A female manager is known as a manageress
A female mister is known as a miss
A female hound is known as a bitch
A female man is known as a
2024-08-01 05:38:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:41:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0298, -0.0412,  0.1265,  ...,  0.1038, -0.0947, -0.0163],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8633, -2.4609, -0.7104,  ...,  0.7974, -3.3555,  1.2646],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0082, -0.0242, -0.0162,  ..., -0.0346,  0.0432,  0.0259],
        [-0.0331,  0.0341,  0.0416,  ..., -0.0276,  0.0395,  0.0151],
        [ 0.0335, -0.0151,  0.0381,  ...,  0.0140, -0.0691, -0.0049],
        ...,
        [ 0.0204,  0.0035,  0.0461,  ...,  0.0107,  0.0174, -0.0024],
        [ 0.0095,  0.0214, -0.0273,  ...,  0.0033,  0.0153,  0.0002],
        [-0.0064, -0.0201, -0.0025,  ...,  0.0091,  0.0074,  0.0038]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.0352, -2.1973, -0.8110,  ...,  0.6973, -3.1758,  1.6895]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:41:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female waiter is known as a waitress
A female uncle is known as a aunt
A female headmaster is known as a headmistress
A female hero is known as a heroine
A female manager is known as a manageress
A female mister is known as a miss
A female hound is known as a bitch
A female man is known as a
2024-08-01 05:41:18 root INFO     [order_1_approx] starting weight calculation for A female hound is known as a bitch
A female hero is known as a heroine
A female mister is known as a miss
A female man is known as a woman
A female manager is known as a manageress
A female uncle is known as a aunt
A female waiter is known as a waitress
A female headmaster is known as a
2024-08-01 05:41:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:44:16 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0491,  0.1613,  0.0506,  ...,  0.1300, -0.0809,  0.2386],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 6.9844, -4.6484, -0.8750,  ...,  0.0483, -6.1484, -0.5742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0162, -0.0253,  0.0149,  ..., -0.0331, -0.0406,  0.0273],
        [-0.0165, -0.0035, -0.0281,  ..., -0.0103,  0.0045,  0.0089],
        [ 0.0378, -0.0017,  0.0020,  ...,  0.0087,  0.0023, -0.0375],
        ...,
        [ 0.0687,  0.0016, -0.0123,  ...,  0.0423,  0.0545, -0.0259],
        [ 0.0314, -0.0338,  0.0004,  ..., -0.0143,  0.0181, -0.0483],
        [-0.0195, -0.0056,  0.0160,  ..., -0.0372, -0.0342,  0.0261]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 6.7773, -3.6797, -0.3174,  ...,  0.8120, -4.8711, -1.3818]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:44:17 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female hound is known as a bitch
A female hero is known as a heroine
A female mister is known as a miss
A female man is known as a woman
A female manager is known as a manageress
A female uncle is known as a aunt
A female waiter is known as a waitress
A female headmaster is known as a
2024-08-01 05:44:17 root INFO     [order_1_approx] starting weight calculation for A female waiter is known as a waitress
A female manager is known as a manageress
A female man is known as a woman
A female uncle is known as a aunt
A female headmaster is known as a headmistress
A female hound is known as a bitch
A female hero is known as a heroine
A female mister is known as a
2024-08-01 05:44:17 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:47:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.0434, 0.3264, 0.1214,  ..., 0.1265, 0.0033, 0.1813], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6758, -2.0254, -1.7256,  ...,  0.6069, -4.8359, -1.3701],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0141,  0.0071,  0.0322,  ..., -0.0092,  0.0182, -0.0139],
        [-0.0265,  0.0341,  0.0128,  ...,  0.0474,  0.0986, -0.0370],
        [ 0.0449, -0.0063,  0.0227,  ..., -0.0038, -0.0640,  0.0082],
        ...,
        [-0.0262, -0.0281,  0.0764,  ...,  0.0349,  0.0522, -0.0321],
        [-0.0002, -0.0008, -0.0198,  ..., -0.0047,  0.0148, -0.0257],
        [ 0.0108, -0.0464,  0.0605,  ...,  0.0267, -0.0326, -0.0428]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5156, -1.7793, -1.5859,  ...,  0.3569, -4.5625, -1.1338]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:47:15 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female waiter is known as a waitress
A female manager is known as a manageress
A female man is known as a woman
A female uncle is known as a aunt
A female headmaster is known as a headmistress
A female hound is known as a bitch
A female hero is known as a heroine
A female mister is known as a
2024-08-01 05:47:15 root INFO     [order_1_approx] starting weight calculation for A female manager is known as a manageress
A female uncle is known as a aunt
A female hound is known as a bitch
A female mister is known as a miss
A female headmaster is known as a headmistress
A female hero is known as a heroine
A female man is known as a woman
A female waiter is known as a
2024-08-01 05:47:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:50:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1581,  0.1058, -0.0958,  ...,  0.0590,  0.1578, -0.0539],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.3750, -0.9121, -0.0044,  ...,  1.4502, -2.2598, -0.2905],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0083, -0.0249,  0.0029,  ..., -0.0048, -0.0196,  0.0172],
        [-0.0077,  0.0016, -0.0057,  ...,  0.0097,  0.0286, -0.0089],
        [-0.0038, -0.0061,  0.0026,  ..., -0.0096, -0.0278, -0.0143],
        ...,
        [ 0.0033,  0.0102, -0.0055,  ...,  0.0107,  0.0010, -0.0017],
        [ 0.0226,  0.0014, -0.0243,  ..., -0.0093,  0.0234, -0.0124],
        [ 0.0051, -0.0030, -0.0104,  ...,  0.0031, -0.0070,  0.0120]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2461, -0.6216, -0.4263,  ...,  1.5088, -2.1152, -0.2180]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:50:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female manager is known as a manageress
A female uncle is known as a aunt
A female hound is known as a bitch
A female mister is known as a miss
A female headmaster is known as a headmistress
A female hero is known as a heroine
A female man is known as a woman
A female waiter is known as a
2024-08-01 05:50:13 root INFO     [order_1_approx] starting weight calculation for A female headmaster is known as a headmistress
A female mister is known as a miss
A female man is known as a woman
A female manager is known as a manageress
A female waiter is known as a waitress
A female hero is known as a heroine
A female hound is known as a bitch
A female uncle is known as a
2024-08-01 05:50:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:53:09 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0042,  0.2109,  0.0774,  ...,  0.0239, -0.0525,  0.0018],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4258, -0.7925, -1.7510,  ..., -0.0312, -5.1328, -1.2637],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0369, -0.0472, -0.0106,  ..., -0.0742,  0.0488, -0.0245],
        [ 0.0294, -0.0105,  0.0202,  ...,  0.0339, -0.0013, -0.0133],
        [ 0.0410, -0.0017,  0.0225,  ..., -0.0133, -0.0604, -0.0041],
        ...,
        [-0.0387, -0.0308,  0.0239,  ..., -0.0138, -0.0193, -0.0174],
        [ 0.0183, -0.0081, -0.0203,  ..., -0.0308,  0.0131,  0.0221],
        [ 0.0306,  0.0101, -0.0040,  ...,  0.0260,  0.0105,  0.0069]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.6406, -1.0654, -4.1836,  ...,  0.6401, -3.8301, -1.2314]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:53:10 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female headmaster is known as a headmistress
A female mister is known as a miss
A female man is known as a woman
A female manager is known as a manageress
A female waiter is known as a waitress
A female hero is known as a heroine
A female hound is known as a bitch
A female uncle is known as a
2024-08-01 05:53:10 root INFO     [order_1_approx] starting weight calculation for A female waiter is known as a waitress
A female mister is known as a miss
A female headmaster is known as a headmistress
A female manager is known as a manageress
A female man is known as a woman
A female hero is known as a heroine
A female uncle is known as a aunt
A female hound is known as a
2024-08-01 05:53:10 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:56:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0576,  0.1433, -0.0097,  ...,  0.0161,  0.0465, -0.1034],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.1953, -5.9570, -1.3350,  ..., -1.1240, -2.7793,  2.5098],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0189,  0.0055,  0.0439,  ...,  0.0168, -0.0267, -0.0197],
        [ 0.0359,  0.0386, -0.0088,  ...,  0.0289,  0.0376, -0.0110],
        [ 0.0420,  0.0102,  0.0153,  ...,  0.0125, -0.0199, -0.0114],
        ...,
        [ 0.0100,  0.0053, -0.0367,  ...,  0.0304,  0.0240, -0.0125],
        [ 0.0045, -0.0562, -0.0298,  ...,  0.0014,  0.0123,  0.0693],
        [ 0.0029,  0.0213,  0.0016,  ...,  0.0014, -0.0341, -0.0105]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.3164, -5.2812, -0.7334,  ..., -0.9175, -2.8926,  2.3984]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:56:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A female waiter is known as a waitress
A female mister is known as a miss
A female headmaster is known as a headmistress
A female manager is known as a manageress
A female man is known as a woman
A female hero is known as a heroine
A female uncle is known as a aunt
A female hound is known as a
2024-08-01 05:56:08 root INFO     total operator prediction time: 1425.2371394634247 seconds
2024-08-01 05:56:08 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on name - occupation
2024-08-01 05:56:08 root INFO     building operator name - occupation
2024-08-01 05:56:08 root INFO     [order_1_approx] starting weight calculation for descartes was known for their work as a  mathematician
raphael was known for their work as a  painter
napoleon was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
balzac was known for their work as a  novelist
darwin was known for their work as a  naturalist
edison was known for their work as a  inventor
shakespeare was known for their work as a 
2024-08-01 05:56:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 05:59:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0072,  0.1104, -0.2871,  ...,  0.0085,  0.2413, -0.0363],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6484, -4.5547,  3.6133,  ..., -2.8535, -1.9980,  0.6348],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.2665e-03,  1.9424e-02,  1.6617e-02,  ...,  1.7136e-02,
          1.1238e-02,  1.2993e-02],
        [ 4.3640e-03,  2.1210e-03, -1.5478e-03,  ..., -5.1422e-03,
          1.2350e-04, -1.1292e-02],
        [ 9.4147e-03,  5.2872e-03,  8.6441e-03,  ..., -5.2929e-05,
          4.3221e-03,  1.0429e-02],
        ...,
        [ 1.1719e-02,  6.4507e-03,  1.2497e-02,  ...,  7.9422e-03,
         -9.3079e-03,  2.4529e-03],
        [-1.2817e-03, -1.0056e-02, -2.9373e-03,  ...,  3.1853e-03,
         -8.4610e-03, -1.5211e-04],
        [-4.9286e-03, -1.0405e-03, -1.0086e-02,  ..., -3.7117e-03,
          1.6270e-03, -1.1778e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.6348, -4.6953,  3.6250,  ..., -2.8125, -1.9482,  0.6826]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 05:59:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for descartes was known for their work as a  mathematician
raphael was known for their work as a  painter
napoleon was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
balzac was known for their work as a  novelist
darwin was known for their work as a  naturalist
edison was known for their work as a  inventor
shakespeare was known for their work as a 
2024-08-01 05:59:11 root INFO     [order_1_approx] starting weight calculation for shakespeare was known for their work as a  playwright
napoleon was known for their work as a  emperor
darwin was known for their work as a  naturalist
raphael was known for their work as a  painter
balzac was known for their work as a  novelist
michelangelo was known for their work as a  sculptor
edison was known for their work as a  inventor
descartes was known for their work as a 
2024-08-01 05:59:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:02:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0031, -0.0985, -0.0967,  ...,  0.1295,  0.2180, -0.0167],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.3896, -4.6289,  1.2939,  ..., -6.5547,  0.5498, -1.2227],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0422, -0.0110,  0.0071,  ...,  0.0251,  0.0426, -0.0035],
        [ 0.0369, -0.0051,  0.0082,  ...,  0.0109,  0.0255,  0.0148],
        [-0.0161,  0.0170,  0.0098,  ..., -0.0165, -0.0273,  0.0047],
        ...,
        [-0.0103,  0.0122, -0.0019,  ..., -0.0087,  0.0354,  0.0150],
        [ 0.0289, -0.0068,  0.0248,  ...,  0.0152, -0.0203,  0.0051],
        [ 0.0339, -0.0142,  0.0010,  ...,  0.0166,  0.0209,  0.0073]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3877, -4.5859,  1.1729,  ..., -6.4414,  0.5962, -1.1553]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:02:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for shakespeare was known for their work as a  playwright
napoleon was known for their work as a  emperor
darwin was known for their work as a  naturalist
raphael was known for their work as a  painter
balzac was known for their work as a  novelist
michelangelo was known for their work as a  sculptor
edison was known for their work as a  inventor
descartes was known for their work as a 
2024-08-01 06:02:14 root INFO     [order_1_approx] starting weight calculation for descartes was known for their work as a  mathematician
balzac was known for their work as a  novelist
edison was known for their work as a  inventor
raphael was known for their work as a  painter
shakespeare was known for their work as a  playwright
darwin was known for their work as a  naturalist
michelangelo was known for their work as a  sculptor
napoleon was known for their work as a 
2024-08-01 06:02:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:05:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0948, -0.1443,  0.1005,  ...,  0.1587,  0.0367,  0.1211],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.9897, -5.2031,  1.0850,  ..., -0.4390,  2.2539, -1.7480],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0317, -0.0101,  0.0111,  ...,  0.0321,  0.0088, -0.0109],
        [ 0.0152,  0.0010,  0.0054,  ...,  0.0009,  0.0083, -0.0035],
        [ 0.0058,  0.0039,  0.0007,  ..., -0.0035, -0.0018, -0.0105],
        ...,
        [-0.0129,  0.0235,  0.0022,  ...,  0.0078, -0.0070,  0.0163],
        [-0.0083, -0.0053, -0.0025,  ..., -0.0027,  0.0083,  0.0074],
        [ 0.0072, -0.0088,  0.0006,  ...,  0.0008, -0.0008,  0.0112]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7954, -5.1914,  0.8154,  ..., -0.3335,  2.1934, -1.5420]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:05:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for descartes was known for their work as a  mathematician
balzac was known for their work as a  novelist
edison was known for their work as a  inventor
raphael was known for their work as a  painter
shakespeare was known for their work as a  playwright
darwin was known for their work as a  naturalist
michelangelo was known for their work as a  sculptor
napoleon was known for their work as a 
2024-08-01 06:05:18 root INFO     [order_1_approx] starting weight calculation for raphael was known for their work as a  painter
edison was known for their work as a  inventor
balzac was known for their work as a  novelist
shakespeare was known for their work as a  playwright
darwin was known for their work as a  naturalist
descartes was known for their work as a  mathematician
napoleon was known for their work as a  emperor
michelangelo was known for their work as a 
2024-08-01 06:05:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:08:21 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0997, -0.0054, -0.1659,  ...,  0.0093,  0.0463,  0.0687],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9736, -7.5391,  1.6123,  ..., -5.4883,  0.6895, -0.2949],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0119, -0.0111, -0.0034,  ...,  0.0166, -0.0017, -0.0061],
        [ 0.0434, -0.0041, -0.0079,  ...,  0.0392,  0.0039,  0.0104],
        [ 0.0095, -0.0006,  0.0110,  ..., -0.0132,  0.0088,  0.0201],
        ...,
        [ 0.0212,  0.0003, -0.0112,  ...,  0.0269,  0.0049,  0.0086],
        [ 0.0110, -0.0139, -0.0025,  ...,  0.0082,  0.0093,  0.0190],
        [ 0.0028,  0.0049,  0.0054,  ...,  0.0027,  0.0037,  0.0029]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8848, -7.1523,  1.5977,  ..., -5.3516,  0.8560, -0.2715]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:08:22 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for raphael was known for their work as a  painter
edison was known for their work as a  inventor
balzac was known for their work as a  novelist
shakespeare was known for their work as a  playwright
darwin was known for their work as a  naturalist
descartes was known for their work as a  mathematician
napoleon was known for their work as a  emperor
michelangelo was known for their work as a 
2024-08-01 06:08:22 root INFO     [order_1_approx] starting weight calculation for darwin was known for their work as a  naturalist
michelangelo was known for their work as a  sculptor
napoleon was known for their work as a  emperor
shakespeare was known for their work as a  playwright
descartes was known for their work as a  mathematician
raphael was known for their work as a  painter
balzac was known for their work as a  novelist
edison was known for their work as a 
2024-08-01 06:08:22 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:11:25 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1067,  0.2622, -0.1559,  ...,  0.1504,  0.1198, -0.0889],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8320, -4.1445,  1.3701,  ..., -1.5156,  0.7266, -1.4150],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0188, -0.0156,  0.0311,  ...,  0.0408,  0.0169, -0.0210],
        [ 0.0258, -0.0224,  0.0037,  ...,  0.0336,  0.0075, -0.0162],
        [-0.0134,  0.0136,  0.0101,  ..., -0.0101, -0.0146,  0.0177],
        ...,
        [ 0.0302,  0.0099,  0.0186,  ...,  0.0624, -0.0026, -0.0051],
        [-0.0109,  0.0224, -0.0208,  ..., -0.0097,  0.0139,  0.0168],
        [ 0.0581, -0.0483,  0.0024,  ...,  0.0427,  0.0368, -0.0102]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6094, -4.3242,  1.3887,  ..., -1.1660,  0.7759, -1.3701]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:11:26 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for darwin was known for their work as a  naturalist
michelangelo was known for their work as a  sculptor
napoleon was known for their work as a  emperor
shakespeare was known for their work as a  playwright
descartes was known for their work as a  mathematician
raphael was known for their work as a  painter
balzac was known for their work as a  novelist
edison was known for their work as a 
2024-08-01 06:11:26 root INFO     [order_1_approx] starting weight calculation for napoleon was known for their work as a  emperor
shakespeare was known for their work as a  playwright
darwin was known for their work as a  naturalist
descartes was known for their work as a  mathematician
michelangelo was known for their work as a  sculptor
edison was known for their work as a  inventor
raphael was known for their work as a  painter
balzac was known for their work as a 
2024-08-01 06:11:27 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:14:29 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1606,  0.0870, -0.1724,  ..., -0.1604, -0.0471, -0.0836],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4531, -4.3477,  3.1445,  ..., -4.5664, -0.2656,  0.2256],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0374, -0.0418,  0.0360,  ...,  0.0646,  0.0074,  0.0029],
        [ 0.0229,  0.0323,  0.0320,  ...,  0.0413, -0.0109,  0.0039],
        [-0.0187,  0.0336,  0.0562,  ..., -0.0061,  0.0064, -0.0031],
        ...,
        [ 0.0598,  0.0164, -0.0192,  ...,  0.0261, -0.0103, -0.0182],
        [ 0.0231,  0.0249,  0.0186,  ...,  0.0339,  0.0099,  0.0318],
        [-0.0076, -0.0563,  0.0093,  ...,  0.0317, -0.0014,  0.0082]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.3955, -4.4844,  2.9219,  ..., -4.2891,  0.0427, -0.5156]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:14:30 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for napoleon was known for their work as a  emperor
shakespeare was known for their work as a  playwright
darwin was known for their work as a  naturalist
descartes was known for their work as a  mathematician
michelangelo was known for their work as a  sculptor
edison was known for their work as a  inventor
raphael was known for their work as a  painter
balzac was known for their work as a 
2024-08-01 06:14:30 root INFO     [order_1_approx] starting weight calculation for darwin was known for their work as a  naturalist
edison was known for their work as a  inventor
descartes was known for their work as a  mathematician
napoleon was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
balzac was known for their work as a  novelist
shakespeare was known for their work as a  playwright
raphael was known for their work as a 
2024-08-01 06:14:30 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:17:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2068, -0.1193,  0.0933,  ..., -0.0987, -0.0529,  0.0182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.8633, -6.2109,  2.6328,  ..., -6.3711, -0.5957, -2.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 5.0430e-03, -1.9741e-03, -9.9106e-03,  ...,  7.0496e-03,
          3.2928e-02, -1.8524e-02],
        [-1.2360e-02, -9.2957e-02, -1.8402e-02,  ..., -1.4091e-02,
          7.8125e-02, -1.7761e-02],
        [ 1.1566e-02,  1.3016e-02,  2.5055e-02,  ...,  2.6150e-03,
          9.8419e-04,  5.5199e-03],
        ...,
        [ 2.7496e-02, -4.9194e-02, -1.3733e-02,  ...,  1.1604e-02,
          4.7852e-02, -1.0185e-02],
        [ 2.0256e-03, -2.5528e-02,  1.2688e-02,  ..., -6.8741e-03,
          4.7874e-03,  2.0332e-03],
        [-7.7667e-03, -7.2937e-02, -5.4932e-02,  ...,  8.4076e-03,
          3.5889e-02, -1.5259e-05]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.2930, -4.6094,  2.3047,  ..., -5.2734, -0.4531, -0.8691]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:17:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for darwin was known for their work as a  naturalist
edison was known for their work as a  inventor
descartes was known for their work as a  mathematician
napoleon was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
balzac was known for their work as a  novelist
shakespeare was known for their work as a  playwright
raphael was known for their work as a 
2024-08-01 06:17:34 root INFO     [order_1_approx] starting weight calculation for shakespeare was known for their work as a  playwright
descartes was known for their work as a  mathematician
napoleon was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
edison was known for their work as a  inventor
balzac was known for their work as a  novelist
raphael was known for their work as a  painter
darwin was known for their work as a 
2024-08-01 06:17:35 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:20:36 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([0.0697, 0.0557, 0.0065,  ..., 0.0639, 0.0611, 0.0199], device='cuda:0',
       dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9150, -5.4844,  2.1504,  ..., -5.5078, -0.5537, -2.0371],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0327,  0.0033,  0.0095,  ...,  0.0206,  0.0170, -0.0313],
        [ 0.0082,  0.0054,  0.0036,  ...,  0.0260,  0.0181, -0.0250],
        [ 0.0204,  0.0010,  0.0180,  ..., -0.0128, -0.0096,  0.0228],
        ...,
        [ 0.0027,  0.0013,  0.0138,  ...,  0.0156, -0.0036, -0.0123],
        [ 0.0065, -0.0062,  0.0055,  ..., -0.0035, -0.0060,  0.0157],
        [ 0.0189,  0.0041,  0.0119,  ...,  0.0258,  0.0046, -0.0175]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.8516, -5.3477,  2.1504,  ..., -5.1602, -0.3896, -1.9277]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:20:37 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for shakespeare was known for their work as a  playwright
descartes was known for their work as a  mathematician
napoleon was known for their work as a  emperor
michelangelo was known for their work as a  sculptor
edison was known for their work as a  inventor
balzac was known for their work as a  novelist
raphael was known for their work as a  painter
darwin was known for their work as a 
2024-08-01 06:20:37 root INFO     total operator prediction time: 1469.3342578411102 seconds
2024-08-01 06:20:37 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on country - capital
2024-08-01 06:20:37 root INFO     building operator country - capital
2024-08-01 06:20:37 root INFO     [order_1_approx] starting weight calculation for The country with athens as its capital is known as greece
The country with lisbon as its capital is known as portugal
The country with berlin as its capital is known as germany
The country with moscow as its capital is known as russia
The country with sofia as its capital is known as bulgaria
The country with warsaw as its capital is known as poland
The country with stockholm as its capital is known as sweden
The country with damascus as its capital is known as
2024-08-01 06:20:38 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:23:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0099, -0.0371, -0.1203,  ...,  0.0124, -0.0462, -0.0231],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.1387, -5.6562, -1.6709,  ..., -0.3237,  2.2617, -4.7344],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0231, -0.0626,  0.0011,  ..., -0.0288,  0.0823, -0.0226],
        [ 0.0031, -0.0006, -0.0072,  ...,  0.0060, -0.0034,  0.0054],
        [-0.0018,  0.0136,  0.0243,  ...,  0.0056, -0.0369, -0.0123],
        ...,
        [ 0.0117,  0.0341, -0.0203,  ...,  0.0071, -0.0285,  0.0074],
        [ 0.0025, -0.0206, -0.0023,  ...,  0.0192,  0.0117,  0.0062],
        [ 0.0163,  0.0089,  0.0022,  ...,  0.0313, -0.0330, -0.0010]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.7285, -5.8047, -1.7451,  ..., -0.4216,  2.2500, -5.0781]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:23:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with athens as its capital is known as greece
The country with lisbon as its capital is known as portugal
The country with berlin as its capital is known as germany
The country with moscow as its capital is known as russia
The country with sofia as its capital is known as bulgaria
The country with warsaw as its capital is known as poland
The country with stockholm as its capital is known as sweden
The country with damascus as its capital is known as
2024-08-01 06:23:43 root INFO     [order_1_approx] starting weight calculation for The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as portugal
The country with sofia as its capital is known as bulgaria
The country with damascus as its capital is known as syria
The country with athens as its capital is known as greece
The country with berlin as its capital is known as germany
The country with warsaw as its capital is known as poland
The country with moscow as its capital is known as
2024-08-01 06:23:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:26:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0343,  0.0008, -0.0902,  ...,  0.0726, -0.1003, -0.1426],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1965, -5.2773, -2.8828,  ..., -1.9541,  0.7773, -3.9062],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0138, -0.0256, -0.0212,  ..., -0.0012,  0.0081,  0.0087],
        [ 0.0063, -0.0008,  0.0015,  ..., -0.0069, -0.0108, -0.0123],
        [ 0.0054, -0.0204,  0.0021,  ..., -0.0070, -0.0081,  0.0021],
        ...,
        [ 0.0120,  0.0136, -0.0018,  ...,  0.0041, -0.0221, -0.0486],
        [ 0.0095, -0.0232, -0.0247,  ..., -0.0114,  0.0099,  0.0357],
        [-0.0112, -0.0147, -0.0029,  ...,  0.0175, -0.0275, -0.0174]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.2183, -5.3242, -2.8848,  ..., -1.9492,  0.9795, -3.7969]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:26:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as portugal
The country with sofia as its capital is known as bulgaria
The country with damascus as its capital is known as syria
The country with athens as its capital is known as greece
The country with berlin as its capital is known as germany
The country with warsaw as its capital is known as poland
The country with moscow as its capital is known as
2024-08-01 06:26:48 root INFO     [order_1_approx] starting weight calculation for The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with athens as its capital is known as greece
The country with moscow as its capital is known as russia
The country with damascus as its capital is known as syria
The country with lisbon as its capital is known as portugal
The country with stockholm as its capital is known as sweden
The country with berlin as its capital is known as
2024-08-01 06:26:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:29:52 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0874,  0.0797, -0.0776,  ...,  0.1938,  0.0652, -0.0781],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.1204, -5.5078, -0.9990,  ...,  0.3706,  0.9517, -4.3516],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0070,  0.0094, -0.0220,  ..., -0.0112,  0.0118, -0.0031],
        [ 0.0048,  0.0004,  0.0082,  ...,  0.0129, -0.0211, -0.0072],
        [ 0.0096, -0.0073,  0.0174,  ...,  0.0374,  0.0134,  0.0158],
        ...,
        [-0.0054,  0.0066, -0.0062,  ...,  0.0280, -0.0067, -0.0263],
        [ 0.0107, -0.0073, -0.0015,  ...,  0.0058,  0.0184, -0.0035],
        [ 0.0020, -0.0290, -0.0182,  ...,  0.0113, -0.0065, -0.0058]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.1487, -5.5938, -0.9702,  ...,  0.4197,  1.1338, -4.0312]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:29:53 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with warsaw as its capital is known as poland
The country with sofia as its capital is known as bulgaria
The country with athens as its capital is known as greece
The country with moscow as its capital is known as russia
The country with damascus as its capital is known as syria
The country with lisbon as its capital is known as portugal
The country with stockholm as its capital is known as sweden
The country with berlin as its capital is known as
2024-08-01 06:29:53 root INFO     [order_1_approx] starting weight calculation for The country with warsaw as its capital is known as poland
The country with moscow as its capital is known as russia
The country with damascus as its capital is known as syria
The country with sofia as its capital is known as bulgaria
The country with athens as its capital is known as greece
The country with berlin as its capital is known as germany
The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as
2024-08-01 06:29:53 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:32:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0275,  0.0734, -0.2010,  ...,  0.0914,  0.0802, -0.0368],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6055, -5.9375, -2.9395,  ...,  0.3933,  1.7344, -4.3477],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6312e-02, -2.2568e-02, -6.0654e-03,  ...,  2.4048e-02,
          7.5226e-03,  1.1108e-02],
        [ 1.4366e-02, -3.0609e-02,  3.7994e-03,  ..., -3.0960e-02,
         -3.5248e-03,  1.2611e-02],
        [-2.2221e-03,  1.2909e-02,  7.7972e-03,  ..., -2.4986e-04,
          1.2665e-02, -2.2751e-02],
        ...,
        [-9.8267e-03,  1.4267e-02, -6.2370e-04,  ...,  4.8065e-03,
         -1.9272e-02, -7.9041e-03],
        [ 9.9792e-03,  4.5776e-05, -1.5640e-02,  ...,  1.4095e-03,
          2.3926e-02,  4.8866e-03],
        [-2.0523e-03,  1.2314e-02, -1.2932e-02,  ..., -2.9053e-02,
         -2.7817e-02, -9.4910e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.7285, -5.7656, -3.0000,  ...,  0.4463,  1.5078, -4.5352]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:32:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with warsaw as its capital is known as poland
The country with moscow as its capital is known as russia
The country with damascus as its capital is known as syria
The country with sofia as its capital is known as bulgaria
The country with athens as its capital is known as greece
The country with berlin as its capital is known as germany
The country with stockholm as its capital is known as sweden
The country with lisbon as its capital is known as
2024-08-01 06:32:58 root INFO     [order_1_approx] starting weight calculation for The country with berlin as its capital is known as germany
The country with lisbon as its capital is known as portugal
The country with damascus as its capital is known as syria
The country with warsaw as its capital is known as poland
The country with stockholm as its capital is known as sweden
The country with moscow as its capital is known as russia
The country with athens as its capital is known as greece
The country with sofia as its capital is known as
2024-08-01 06:32:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:36:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1349, -0.0421, -0.2462,  ...,  0.2522, -0.0643,  0.0221],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.1475, -4.5938, -0.5146,  ...,  0.3364,  0.6553, -4.9805],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0073, -0.0032, -0.0172,  ...,  0.0043, -0.0057, -0.0079],
        [ 0.0642, -0.0449,  0.0221,  ...,  0.0039,  0.0025,  0.0070],
        [ 0.0073,  0.0197,  0.0307,  ..., -0.0147,  0.0075, -0.0075],
        ...,
        [ 0.0125,  0.0172,  0.0122,  ...,  0.0300, -0.0090, -0.0102],
        [ 0.0197, -0.0215, -0.0205,  ...,  0.0014,  0.0493,  0.0103],
        [ 0.0012, -0.0375,  0.0117,  ..., -0.0146,  0.0119,  0.0273]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0596, -4.6992, -0.5420,  ...,  0.4761,  0.6748, -5.1289]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:36:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with berlin as its capital is known as germany
The country with lisbon as its capital is known as portugal
The country with damascus as its capital is known as syria
The country with warsaw as its capital is known as poland
The country with stockholm as its capital is known as sweden
The country with moscow as its capital is known as russia
The country with athens as its capital is known as greece
The country with sofia as its capital is known as
2024-08-01 06:36:03 root INFO     [order_1_approx] starting weight calculation for The country with damascus as its capital is known as syria
The country with athens as its capital is known as greece
The country with sofia as its capital is known as bulgaria
The country with warsaw as its capital is known as poland
The country with moscow as its capital is known as russia
The country with lisbon as its capital is known as portugal
The country with berlin as its capital is known as germany
The country with stockholm as its capital is known as
2024-08-01 06:36:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:39:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1385,  0.1217, -0.1617,  ...,  0.2094,  0.1429,  0.1853],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8828, -6.2109, -1.8301,  ..., -1.1621, -1.5859, -3.3340],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0079, -0.0120,  0.0151,  ...,  0.0061,  0.0017,  0.0144],
        [ 0.0133,  0.0120, -0.0044,  ..., -0.0113, -0.0299, -0.0061],
        [-0.0142, -0.0103,  0.0121,  ..., -0.0030,  0.0144, -0.0003],
        ...,
        [ 0.0287,  0.0067,  0.0069,  ...,  0.0411, -0.0301, -0.0173],
        [-0.0110, -0.0201, -0.0210,  ...,  0.0103, -0.0031,  0.0097],
        [-0.0080, -0.0205, -0.0253,  ...,  0.0242, -0.0189, -0.0012]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6191, -6.1602, -2.0625,  ..., -0.9897, -1.3330, -3.3184]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:39:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with damascus as its capital is known as syria
The country with athens as its capital is known as greece
The country with sofia as its capital is known as bulgaria
The country with warsaw as its capital is known as poland
The country with moscow as its capital is known as russia
The country with lisbon as its capital is known as portugal
The country with berlin as its capital is known as germany
The country with stockholm as its capital is known as
2024-08-01 06:39:08 root INFO     [order_1_approx] starting weight calculation for The country with warsaw as its capital is known as poland
The country with stockholm as its capital is known as sweden
The country with sofia as its capital is known as bulgaria
The country with damascus as its capital is known as syria
The country with moscow as its capital is known as russia
The country with berlin as its capital is known as germany
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as
2024-08-01 06:39:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:42:11 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0254,  0.0544, -0.2944,  ...,  0.2598,  0.1326, -0.0953],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7031, -5.5508, -2.9102,  ..., -0.0491,  1.5176, -2.6562],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0335, -0.0118,  0.0121,  ...,  0.0039,  0.0174,  0.0054],
        [ 0.0099, -0.0130,  0.0104,  ..., -0.0016, -0.0303, -0.0175],
        [-0.0103, -0.0140,  0.0096,  ..., -0.0165, -0.0051, -0.0017],
        ...,
        [ 0.0081,  0.0188,  0.0023,  ...,  0.0258, -0.0415, -0.0181],
        [ 0.0118, -0.0182,  0.0184,  ...,  0.0120,  0.0405,  0.0124],
        [ 0.0119, -0.0079, -0.0075,  ...,  0.0056, -0.0048, -0.0406]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.5059, -5.6406, -2.8516,  ..., -0.1569,  1.6533, -2.6855]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:42:12 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with warsaw as its capital is known as poland
The country with stockholm as its capital is known as sweden
The country with sofia as its capital is known as bulgaria
The country with damascus as its capital is known as syria
The country with moscow as its capital is known as russia
The country with berlin as its capital is known as germany
The country with lisbon as its capital is known as portugal
The country with athens as its capital is known as
2024-08-01 06:42:13 root INFO     [order_1_approx] starting weight calculation for The country with lisbon as its capital is known as portugal
The country with stockholm as its capital is known as sweden
The country with sofia as its capital is known as bulgaria
The country with berlin as its capital is known as germany
The country with damascus as its capital is known as syria
The country with athens as its capital is known as greece
The country with moscow as its capital is known as russia
The country with warsaw as its capital is known as
2024-08-01 06:42:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:45:17 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0804,  0.0681,  0.1024,  ..., -0.0576,  0.0256, -0.1742],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7520, -6.6094, -1.5371,  ..., -0.6699,  1.6562, -4.2852],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0116, -0.0085, -0.0046,  ...,  0.0074,  0.0094, -0.0011],
        [ 0.0080, -0.0018,  0.0166,  ...,  0.0039, -0.0215,  0.0219],
        [-0.0025,  0.0093,  0.0223,  ..., -0.0108,  0.0088, -0.0066],
        ...,
        [-0.0087,  0.0143,  0.0201,  ...,  0.0452, -0.0420,  0.0219],
        [ 0.0038, -0.0151, -0.0101,  ...,  0.0171,  0.0118, -0.0079],
        [-0.0018, -0.0165, -0.0196,  ...,  0.0087, -0.0168, -0.0300]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8418, -6.7070, -1.7793,  ..., -0.6899,  1.9844, -4.1641]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:45:18 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The country with lisbon as its capital is known as portugal
The country with stockholm as its capital is known as sweden
The country with sofia as its capital is known as bulgaria
The country with berlin as its capital is known as germany
The country with damascus as its capital is known as syria
The country with athens as its capital is known as greece
The country with moscow as its capital is known as russia
The country with warsaw as its capital is known as
2024-08-01 06:45:18 root INFO     total operator prediction time: 1480.346078634262 seconds
2024-08-01 06:45:18 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on things - color
2024-08-01 06:45:18 root INFO     building operator things - color
2024-08-01 06:45:18 root INFO     [order_1_approx] starting weight calculation for The leaves is colored green
The sapphire is colored blue
The cherry is colored red
The tea is colored black
The sun is colored yellow
The raven is colored black
The sky is colored blue
The blood is colored
2024-08-01 06:45:18 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:48:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0906, -0.0464, -0.1085,  ...,  0.1736, -0.2151, -0.0501],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.4512, -9.7812, -2.2656,  ..., -2.2480,  2.8398, -1.3262],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.9272e-02,  6.4850e-03,  6.8893e-03,  ..., -1.8845e-02,
         -7.6218e-03,  8.6594e-03],
        [ 1.0368e-02,  2.3010e-02, -1.2741e-02,  ..., -1.5450e-03,
          1.2230e-02,  1.3985e-02],
        [ 2.2339e-02,  6.1035e-05,  4.3106e-03,  ..., -3.4618e-03,
         -1.4191e-03,  1.2856e-02],
        ...,
        [ 3.0556e-03, -8.8196e-03, -1.5320e-02,  ...,  2.3392e-02,
          5.8212e-03, -8.6288e-03],
        [-1.6113e-02,  3.5767e-02,  7.7820e-04,  ...,  3.4485e-03,
          1.5426e-04,  1.0063e-02],
        [-7.6866e-03,  1.0880e-02,  5.3406e-05,  ...,  1.4496e-02,
          1.2222e-02,  7.8440e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ -1.4482, -10.0469,  -2.1699,  ...,  -2.4551,   2.6660,  -1.5381]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:48:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The leaves is colored green
The sapphire is colored blue
The cherry is colored red
The tea is colored black
The sun is colored yellow
The raven is colored black
The sky is colored blue
The blood is colored
2024-08-01 06:48:13 root INFO     [order_1_approx] starting weight calculation for The sky is colored blue
The sapphire is colored blue
The cherry is colored red
The leaves is colored green
The sun is colored yellow
The raven is colored black
The blood is colored red
The tea is colored
2024-08-01 06:48:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:51:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1707, -0.0657, -0.1138,  ..., -0.0078,  0.0162,  0.1243],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.3516, -2.5527, -1.2686,  ..., -3.3086,  0.5439,  0.8730],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0126, -0.0003, -0.0051,  ..., -0.0367, -0.0283,  0.0416],
        [ 0.0105,  0.0378,  0.0166,  ..., -0.0169,  0.0095,  0.0313],
        [ 0.0064,  0.0221,  0.0009,  ...,  0.0226,  0.0186,  0.0063],
        ...,
        [ 0.0035, -0.0146, -0.0190,  ...,  0.0166,  0.0026, -0.0085],
        [ 0.0088, -0.0112, -0.0263,  ...,  0.0030,  0.0102, -0.0163],
        [-0.0007,  0.0411,  0.0165,  ...,  0.0170,  0.0447, -0.0143]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7798, -3.1875, -1.3711,  ..., -3.4473,  1.1621,  0.1880]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:51:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sky is colored blue
The sapphire is colored blue
The cherry is colored red
The leaves is colored green
The sun is colored yellow
The raven is colored black
The blood is colored red
The tea is colored
2024-08-01 06:51:14 root INFO     [order_1_approx] starting weight calculation for The sun is colored yellow
The tea is colored black
The raven is colored black
The blood is colored red
The leaves is colored green
The cherry is colored red
The sky is colored blue
The sapphire is colored
2024-08-01 06:51:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:54:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1401,  0.0546, -0.2888,  ...,  0.2465,  0.0974, -0.0685],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.8975, -3.6406, -1.5977,  ..., -2.0801,  0.9834,  0.5146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0151, -0.0042,  0.0161,  ..., -0.0153,  0.0166, -0.0016],
        [ 0.0125,  0.0005,  0.0112,  ...,  0.0031,  0.0070,  0.0062],
        [-0.0061,  0.0230, -0.0041,  ...,  0.0138, -0.0019, -0.0135],
        ...,
        [ 0.0170, -0.0035,  0.0150,  ...,  0.0247,  0.0033, -0.0201],
        [-0.0101, -0.0039, -0.0056,  ..., -0.0009,  0.0056, -0.0178],
        [ 0.0177, -0.0198,  0.0134,  ..., -0.0061,  0.0071,  0.0089]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.5869, -3.6973, -1.8457,  ..., -2.0273,  0.5620,  0.6084]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:54:13 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sun is colored yellow
The tea is colored black
The raven is colored black
The blood is colored red
The leaves is colored green
The cherry is colored red
The sky is colored blue
The sapphire is colored
2024-08-01 06:54:13 root INFO     [order_1_approx] starting weight calculation for The sapphire is colored blue
The cherry is colored red
The blood is colored red
The tea is colored black
The leaves is colored green
The sky is colored blue
The raven is colored black
The sun is colored
2024-08-01 06:54:13 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 06:57:14 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1930, -0.0773, -0.0324,  ..., -0.0125, -0.0004, -0.0969],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.4551, -7.5547, -0.0374,  ..., -2.0859, -2.0586, -0.8140],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0061, -0.0023,  0.0129,  ..., -0.0093, -0.0071, -0.0081],
        [ 0.0141,  0.0084, -0.0295,  ..., -0.0101,  0.0191,  0.0001],
        [-0.0158,  0.0085,  0.0128,  ...,  0.0124,  0.0266,  0.0037],
        ...,
        [ 0.0065, -0.0077, -0.0035,  ...,  0.0315,  0.0198, -0.0024],
        [ 0.0170, -0.0194,  0.0191,  ..., -0.0006,  0.0070, -0.0027],
        [-0.0220, -0.0114,  0.0092,  ..., -0.0041, -0.0020,  0.0103]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.3359, -7.6562,  0.1946,  ..., -2.2500, -1.7773, -0.7080]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 06:57:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sapphire is colored blue
The cherry is colored red
The blood is colored red
The tea is colored black
The leaves is colored green
The sky is colored blue
The raven is colored black
The sun is colored
2024-08-01 06:57:15 root INFO     [order_1_approx] starting weight calculation for The tea is colored black
The sun is colored yellow
The raven is colored black
The sky is colored blue
The leaves is colored green
The blood is colored red
The sapphire is colored blue
The cherry is colored
2024-08-01 06:57:15 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:00:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0842, -0.1317, -0.1877,  ...,  0.0275, -0.0695, -0.0515],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.6865, -6.7422, -2.1953,  ..., -1.9170,  1.1562, -1.8242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0176, -0.0271,  0.0033,  ..., -0.0326, -0.0089,  0.0004],
        [ 0.0137,  0.0013, -0.0080,  ...,  0.0042,  0.0024, -0.0077],
        [ 0.0121,  0.0148,  0.0165,  ..., -0.0075, -0.0198,  0.0039],
        ...,
        [ 0.0304, -0.0165, -0.0626,  ...,  0.0652,  0.0054, -0.0091],
        [-0.0046,  0.0079, -0.0087,  ...,  0.0035, -0.0079, -0.0052],
        [-0.0252,  0.0150,  0.0367,  ...,  0.0049, -0.0080, -0.0183]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7173, -6.6758, -2.2539,  ..., -2.0156,  1.1299, -1.9395]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:00:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The tea is colored black
The sun is colored yellow
The raven is colored black
The sky is colored blue
The leaves is colored green
The blood is colored red
The sapphire is colored blue
The cherry is colored
2024-08-01 07:00:09 root INFO     [order_1_approx] starting weight calculation for The cherry is colored red
The sapphire is colored blue
The sun is colored yellow
The blood is colored red
The raven is colored black
The leaves is colored green
The tea is colored black
The sky is colored
2024-08-01 07:00:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:03:10 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.2603,  0.0428, -0.0671,  ...,  0.0829,  0.0443, -0.1492],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.5371, -5.9766,  2.8535,  ..., -0.4131,  0.3230, -0.8745],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0039, -0.0059,  0.0047,  ...,  0.0096, -0.0208,  0.0160],
        [-0.0003, -0.0015,  0.0049,  ..., -0.0189, -0.0035, -0.0008],
        [ 0.0086,  0.0319,  0.0106,  ...,  0.0020,  0.0010,  0.0049],
        ...,
        [-0.0151, -0.0123, -0.0225,  ...,  0.0108, -0.0090, -0.0022],
        [ 0.0042, -0.0246, -0.0032,  ...,  0.0269,  0.0085, -0.0063],
        [-0.0045, -0.0159,  0.0035,  ...,  0.0088, -0.0011,  0.0054]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-2.2344, -5.8828,  2.6289,  ..., -0.3372,  0.8135, -1.0781]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:03:11 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The cherry is colored red
The sapphire is colored blue
The sun is colored yellow
The blood is colored red
The raven is colored black
The leaves is colored green
The tea is colored black
The sky is colored
2024-08-01 07:03:11 root INFO     [order_1_approx] starting weight calculation for The blood is colored red
The sky is colored blue
The cherry is colored red
The raven is colored black
The tea is colored black
The sapphire is colored blue
The sun is colored yellow
The leaves is colored
2024-08-01 07:03:11 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:06:08 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1329,  0.1334, -0.1653,  ..., -0.0502,  0.0903, -0.0878],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-2.0273, -7.5938,  0.3433,  ...,  0.9121, -0.0977, -2.8242],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0038,  0.0068, -0.0020,  ...,  0.0042, -0.0264, -0.0303],
        [-0.0101,  0.0360, -0.0116,  ...,  0.0060, -0.0138,  0.0094],
        [ 0.0094,  0.0048,  0.0172,  ...,  0.0013, -0.0028,  0.0108],
        ...,
        [-0.0228, -0.0182,  0.0067,  ...,  0.0368,  0.0141,  0.0005],
        [ 0.0427, -0.0389,  0.0197,  ...,  0.0190,  0.0220, -0.0281],
        [-0.0447, -0.0106,  0.0382,  ..., -0.0095,  0.0148, -0.0050]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.8301, -7.7852,  0.0413,  ...,  0.9385,  0.5269, -3.1797]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:06:09 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The blood is colored red
The sky is colored blue
The cherry is colored red
The raven is colored black
The tea is colored black
The sapphire is colored blue
The sun is colored yellow
The leaves is colored
2024-08-01 07:06:09 root INFO     [order_1_approx] starting weight calculation for The sapphire is colored blue
The blood is colored red
The tea is colored black
The leaves is colored green
The sky is colored blue
The sun is colored yellow
The cherry is colored red
The raven is colored
2024-08-01 07:06:09 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:09:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1541, -0.0031, -0.1129,  ...,  0.2520,  0.0536,  0.1924],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.5527, -4.5156,  2.2383,  ...,  0.8682,  3.0938, -2.0352],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 3.1662e-03,  2.1805e-02,  1.3756e-02,  ..., -1.9623e-02,
          2.0401e-02, -3.0655e-02],
        [-1.4557e-02,  7.1144e-03, -4.7684e-06,  ..., -1.6510e-02,
          4.2572e-02, -1.4519e-02],
        [ 5.2948e-03, -5.0583e-03,  2.8122e-02,  ..., -2.5726e-02,
          2.5291e-03,  2.5635e-03],
        ...,
        [ 2.7122e-03, -1.6785e-02,  2.7710e-02,  ...,  3.1929e-03,
          2.9678e-02, -3.1860e-02],
        [-6.5117e-03,  1.4626e-02,  3.7384e-03,  ...,  2.1362e-02,
          3.4088e-02,  7.9498e-03],
        [-1.2207e-02, -1.2527e-02, -8.7738e-03,  ..., -2.0523e-02,
         -5.3009e-02, -3.2410e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.4482, -4.7891,  1.7314,  ...,  1.0205,  2.1504, -1.0195]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:09:05 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sapphire is colored blue
The blood is colored red
The tea is colored black
The leaves is colored green
The sky is colored blue
The sun is colored yellow
The cherry is colored red
The raven is colored
2024-08-01 07:09:05 root INFO     total operator prediction time: 1427.9068512916565 seconds
2024-08-01 07:09:06 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - sound
2024-08-01 07:09:06 root INFO     building operator animal - sound
2024-08-01 07:09:06 root INFO     [order_1_approx] starting weight calculation for The sound that a crow makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a elephant makes is called a trumpet
The sound that a pig makes is called a oink
The sound that a moose makes is called a bellow
The sound that a whale makes is called a sing
The sound that a bee makes is called a buzz
The sound that a cat makes is called a
2024-08-01 07:09:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:12:06 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0701,  0.0245,  0.0891,  ...,  0.0282, -0.0114, -0.1235],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5244, -4.3516, -2.1758,  ..., -1.9248, -0.5625,  2.6992],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0136, -0.0052,  0.0071,  ..., -0.0254, -0.0105, -0.0135],
        [-0.0106,  0.0257,  0.0172,  ...,  0.0139,  0.0104,  0.0241],
        [-0.0093, -0.0248,  0.0249,  ..., -0.0128,  0.0045, -0.0164],
        ...,
        [ 0.0130,  0.0339,  0.0029,  ...,  0.0204,  0.0009,  0.0133],
        [ 0.0014, -0.0219, -0.0319,  ..., -0.0127, -0.0033,  0.0024],
        [ 0.0015, -0.0160,  0.0046,  ..., -0.0270, -0.0162, -0.0060]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.6411, -4.5703, -2.0332,  ..., -2.0039, -0.6299,  2.4805]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:12:07 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a crow makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a elephant makes is called a trumpet
The sound that a pig makes is called a oink
The sound that a moose makes is called a bellow
The sound that a whale makes is called a sing
The sound that a bee makes is called a buzz
The sound that a cat makes is called a
2024-08-01 07:12:07 root INFO     [order_1_approx] starting weight calculation for The sound that a cat makes is called a meow
The sound that a moose makes is called a bellow
The sound that a toad makes is called a ribbit
The sound that a pig makes is called a oink
The sound that a crow makes is called a caw
The sound that a whale makes is called a sing
The sound that a bee makes is called a buzz
The sound that a elephant makes is called a
2024-08-01 07:12:07 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:15:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0614,  0.0460,  0.0883,  ..., -0.0002, -0.2037, -0.1660],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3721, -3.4668,  1.4111,  ...,  1.0537, -1.5020,  0.5078],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0142,  0.0298, -0.0129,  ...,  0.0036, -0.0229, -0.0037],
        [-0.0162, -0.0090,  0.0076,  ...,  0.0032, -0.0045,  0.0106],
        [ 0.0036, -0.0064,  0.0098,  ..., -0.0022, -0.0011, -0.0119],
        ...,
        [-0.0047,  0.0196, -0.0164,  ..., -0.0035, -0.0016,  0.0203],
        [ 0.0022, -0.0038, -0.0011,  ..., -0.0025,  0.0068, -0.0017],
        [-0.0022, -0.0102,  0.0033,  ..., -0.0062,  0.0024, -0.0009]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9072, -3.1211,  1.3418,  ...,  0.9961, -1.5508,  0.6157]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:15:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a cat makes is called a meow
The sound that a moose makes is called a bellow
The sound that a toad makes is called a ribbit
The sound that a pig makes is called a oink
The sound that a crow makes is called a caw
The sound that a whale makes is called a sing
The sound that a bee makes is called a buzz
The sound that a elephant makes is called a
2024-08-01 07:15:06 root INFO     [order_1_approx] starting weight calculation for The sound that a moose makes is called a bellow
The sound that a cat makes is called a meow
The sound that a pig makes is called a oink
The sound that a crow makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a elephant makes is called a trumpet
The sound that a whale makes is called a sing
The sound that a bee makes is called a
2024-08-01 07:15:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:18:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0661,  0.0851,  0.1571,  ..., -0.0064,  0.0158, -0.1526],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.7930, -2.6055,  1.9082,  ..., -1.0625, -0.2246,  0.7510],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.6327e-02,  4.5967e-03,  1.3466e-02,  ...,  1.2314e-02,
         -7.3853e-03, -3.5992e-03],
        [-1.5114e-02, -3.0746e-02, -1.5137e-02,  ...,  4.8141e-03,
          4.1626e-02, -2.8419e-03],
        [ 1.8677e-02,  3.7689e-02,  7.1831e-03,  ...,  4.7836e-03,
         -3.2959e-02,  9.5901e-03],
        ...,
        [-3.3112e-03,  8.8654e-03,  9.5825e-03,  ...,  5.3772e-02,
         -7.2289e-04,  2.4338e-03],
        [-2.9526e-03,  1.7075e-02,  3.1738e-03,  ...,  1.1276e-02,
          1.1032e-02,  2.2888e-02],
        [ 7.3776e-03, -8.8959e-03,  9.3222e-05,  ..., -2.0599e-02,
         -1.8127e-02,  8.1635e-04]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6094, -2.5430,  1.6621,  ..., -1.2939, -0.4390,  0.8955]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:18:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a moose makes is called a bellow
The sound that a cat makes is called a meow
The sound that a pig makes is called a oink
The sound that a crow makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a elephant makes is called a trumpet
The sound that a whale makes is called a sing
The sound that a bee makes is called a
2024-08-01 07:18:06 root INFO     [order_1_approx] starting weight calculation for The sound that a whale makes is called a sing
The sound that a moose makes is called a bellow
The sound that a pig makes is called a oink
The sound that a crow makes is called a caw
The sound that a cat makes is called a meow
The sound that a bee makes is called a buzz
The sound that a elephant makes is called a trumpet
The sound that a toad makes is called a
2024-08-01 07:18:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:21:05 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0774,  0.2397,  0.2048,  ..., -0.2517,  0.0300,  0.1682],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.5996, -1.7529,  0.1924,  ...,  2.5762, -1.5547,  4.0000],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0489, -0.0403,  0.0352,  ..., -0.0034,  0.0051, -0.0214],
        [-0.0112, -0.0357, -0.0524,  ..., -0.0027,  0.0353, -0.0130],
        [-0.0131, -0.0139,  0.0442,  ..., -0.0426, -0.0364,  0.0150],
        ...,
        [-0.0087,  0.0265, -0.0345,  ...,  0.0034, -0.0021, -0.0105],
        [-0.0251, -0.0141, -0.0103,  ..., -0.0014,  0.0175, -0.0015],
        [ 0.0571,  0.0032, -0.0069,  ...,  0.0052,  0.0216,  0.0187]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7432, -2.0156,  0.2465,  ...,  2.4180, -2.0059,  4.1680]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:21:06 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a whale makes is called a sing
The sound that a moose makes is called a bellow
The sound that a pig makes is called a oink
The sound that a crow makes is called a caw
The sound that a cat makes is called a meow
The sound that a bee makes is called a buzz
The sound that a elephant makes is called a trumpet
The sound that a toad makes is called a
2024-08-01 07:21:06 root INFO     [order_1_approx] starting weight calculation for The sound that a toad makes is called a ribbit
The sound that a elephant makes is called a trumpet
The sound that a bee makes is called a buzz
The sound that a cat makes is called a meow
The sound that a whale makes is called a sing
The sound that a crow makes is called a caw
The sound that a pig makes is called a oink
The sound that a moose makes is called a
2024-08-01 07:21:06 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:24:04 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0421,  0.2544,  0.0369,  ..., -0.0586, -0.1017, -0.0874],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3076, -3.1758,  0.5918,  ...,  1.4678, -2.5996,  1.9941],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0217, -0.0502,  0.0338,  ..., -0.0564, -0.0072,  0.0199],
        [ 0.0308,  0.0405, -0.0466,  ...,  0.0567, -0.0637, -0.0555],
        [-0.0046,  0.0183,  0.0690,  ...,  0.0026, -0.0342, -0.0107],
        ...,
        [ 0.0091,  0.0494,  0.0012,  ...,  0.0668,  0.0323, -0.0497],
        [-0.0310,  0.0058, -0.0204,  ..., -0.0515, -0.0037,  0.0330],
        [ 0.0410, -0.0233,  0.0071,  ..., -0.0074, -0.0325, -0.0181]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.3638, -2.5742,  1.5449,  ...,  1.6738, -2.3496,  1.6953]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:24:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a toad makes is called a ribbit
The sound that a elephant makes is called a trumpet
The sound that a bee makes is called a buzz
The sound that a cat makes is called a meow
The sound that a whale makes is called a sing
The sound that a crow makes is called a caw
The sound that a pig makes is called a oink
The sound that a moose makes is called a
2024-08-01 07:24:05 root INFO     [order_1_approx] starting weight calculation for The sound that a pig makes is called a oink
The sound that a bee makes is called a buzz
The sound that a moose makes is called a bellow
The sound that a toad makes is called a ribbit
The sound that a whale makes is called a sing
The sound that a cat makes is called a meow
The sound that a elephant makes is called a trumpet
The sound that a crow makes is called a
2024-08-01 07:24:05 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:27:02 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1912,  0.0732,  0.0240,  ..., -0.0803, -0.0512,  0.0086],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.3740, -5.3281,  1.6260,  ..., -1.8047, -0.6665,  1.7666],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0545, -0.0094, -0.0223,  ..., -0.0408, -0.0293, -0.0259],
        [-0.0213,  0.0168,  0.0198,  ...,  0.0110,  0.0975,  0.0426],
        [-0.0142,  0.0133,  0.0572,  ..., -0.0138, -0.0613, -0.0598],
        ...,
        [ 0.0033,  0.0111,  0.0110,  ...,  0.0512,  0.0650,  0.0405],
        [-0.0620,  0.0030, -0.0748,  ...,  0.0293,  0.0532,  0.0664],
        [ 0.0476, -0.0131,  0.0250,  ..., -0.0362, -0.0168, -0.0046]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9834, -5.1914,  1.8818,  ..., -2.3164, -1.4375,  1.5801]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:27:03 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a pig makes is called a oink
The sound that a bee makes is called a buzz
The sound that a moose makes is called a bellow
The sound that a toad makes is called a ribbit
The sound that a whale makes is called a sing
The sound that a cat makes is called a meow
The sound that a elephant makes is called a trumpet
The sound that a crow makes is called a
2024-08-01 07:27:03 root INFO     [order_1_approx] starting weight calculation for The sound that a toad makes is called a ribbit
The sound that a elephant makes is called a trumpet
The sound that a whale makes is called a sing
The sound that a bee makes is called a buzz
The sound that a moose makes is called a bellow
The sound that a cat makes is called a meow
The sound that a crow makes is called a caw
The sound that a pig makes is called a
2024-08-01 07:27:03 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:30:01 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0044,  0.2255,  0.1306,  ...,  0.1511,  0.1191, -0.0533],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.8320, -2.0957,  3.2070,  ..., -2.6172,  0.6489,  1.3438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0018, -0.0360,  0.0189,  ..., -0.0195,  0.0024, -0.0037],
        [-0.0198, -0.0053,  0.0061,  ...,  0.0010,  0.0323,  0.0042],
        [-0.0088,  0.0244,  0.0006,  ..., -0.0282, -0.0507, -0.0165],
        ...,
        [ 0.0124, -0.0076,  0.0028,  ...,  0.0045,  0.0075,  0.0151],
        [ 0.0229, -0.0092,  0.0027,  ...,  0.0026,  0.0282,  0.0001],
        [ 0.0246, -0.0048,  0.0188,  ..., -0.0356, -0.0157, -0.0273]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.2168, -1.8682,  3.3848,  ..., -2.7969,  0.4341,  1.3887]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:30:02 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a toad makes is called a ribbit
The sound that a elephant makes is called a trumpet
The sound that a whale makes is called a sing
The sound that a bee makes is called a buzz
The sound that a moose makes is called a bellow
The sound that a cat makes is called a meow
The sound that a crow makes is called a caw
The sound that a pig makes is called a
2024-08-01 07:30:02 root INFO     [order_1_approx] starting weight calculation for The sound that a bee makes is called a buzz
The sound that a elephant makes is called a trumpet
The sound that a cat makes is called a meow
The sound that a pig makes is called a oink
The sound that a crow makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a moose makes is called a bellow
The sound that a whale makes is called a
2024-08-01 07:30:02 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:32:59 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0803,  0.0751,  0.1274,  ..., -0.1670, -0.0394, -0.1438],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.8906, -0.6689,  2.6758,  ...,  0.5830, -1.8643,  1.0967],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0056, -0.0004,  0.0056,  ..., -0.0060, -0.0201, -0.0072],
        [ 0.0171,  0.0717, -0.0525,  ..., -0.0073, -0.0003, -0.0160],
        [-0.0126,  0.0332,  0.0194,  ..., -0.0233, -0.0177, -0.0054],
        ...,
        [-0.0142,  0.0232, -0.0281,  ...,  0.0051, -0.0002, -0.0143],
        [-0.0470, -0.0156, -0.0106,  ..., -0.0179, -0.0057,  0.0063],
        [ 0.0280, -0.0444,  0.0006,  ...,  0.0004,  0.0069,  0.0020]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.8940, -0.8999,  2.5938,  ..., -0.0078, -1.9883,  1.4297]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:33:00 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The sound that a bee makes is called a buzz
The sound that a elephant makes is called a trumpet
The sound that a cat makes is called a meow
The sound that a pig makes is called a oink
The sound that a crow makes is called a caw
The sound that a toad makes is called a ribbit
The sound that a moose makes is called a bellow
The sound that a whale makes is called a
2024-08-01 07:33:00 root INFO     total operator prediction time: 1434.668447971344 seconds
2024-08-01 07:33:00 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on animal - youth
2024-08-01 07:33:00 root INFO     building operator animal - youth
2024-08-01 07:33:00 root INFO     [order_1_approx] starting weight calculation for The offspring of a ox is referred to as a calf
The offspring of a ferret is referred to as a kit
The offspring of a trout is referred to as a fingerling
The offspring of a skunk is referred to as a kit
The offspring of a salmon is referred to as a smolt
The offspring of a cat is referred to as a kitten
The offspring of a chimpanzee is referred to as a baby
The offspring of a cicada is referred to as a
2024-08-01 07:33:00 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:36:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0750,  0.0360, -0.1603,  ..., -0.2634,  0.0422,  0.0773],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.2417, -2.0859, -0.2222,  ..., -0.1685, -1.5742,  2.2383],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0153, -0.0412,  0.0268,  ..., -0.0202, -0.0364,  0.0038],
        [ 0.0145,  0.0280, -0.0178,  ...,  0.0050,  0.0146,  0.0287],
        [-0.0266,  0.0133,  0.0376,  ..., -0.0008, -0.0133,  0.0302],
        ...,
        [-0.0081, -0.0040, -0.0072,  ...,  0.0209,  0.0119,  0.0037],
        [-0.0007,  0.0433, -0.0117,  ...,  0.0119,  0.0447,  0.0328],
        [ 0.0175,  0.0086,  0.0210,  ...,  0.0173,  0.0009,  0.0492]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.7412, -2.3535, -0.9155,  ...,  0.4717, -2.0469,  2.2383]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:36:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a ox is referred to as a calf
The offspring of a ferret is referred to as a kit
The offspring of a trout is referred to as a fingerling
The offspring of a skunk is referred to as a kit
The offspring of a salmon is referred to as a smolt
The offspring of a cat is referred to as a kitten
The offspring of a chimpanzee is referred to as a baby
The offspring of a cicada is referred to as a
2024-08-01 07:36:04 root INFO     [order_1_approx] starting weight calculation for The offspring of a trout is referred to as a fingerling
The offspring of a ox is referred to as a calf
The offspring of a salmon is referred to as a smolt
The offspring of a ferret is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a cicada is referred to as a nymph
The offspring of a chimpanzee is referred to as a baby
The offspring of a cat is referred to as a
2024-08-01 07:36:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:39:07 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0548, -0.0377,  0.0851,  ...,  0.0041,  0.0330, -0.1080],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.9258, -3.6582, -2.2891,  ..., -0.3750, -0.7261,  0.3379],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0053, -0.0017, -0.0048,  ...,  0.0075, -0.0111,  0.0086],
        [ 0.0056,  0.0050, -0.0068,  ...,  0.0205,  0.0110,  0.0170],
        [ 0.0122, -0.0099,  0.0094,  ..., -0.0157, -0.0186, -0.0132],
        ...,
        [ 0.0094, -0.0118, -0.0222,  ...,  0.0049, -0.0011, -0.0027],
        [ 0.0015, -0.0040, -0.0114,  ...,  0.0167,  0.0385,  0.0238],
        [ 0.0054, -0.0198,  0.0163,  ..., -0.0101,  0.0028, -0.0125]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1680, -3.3965, -2.1387,  ..., -0.0195, -0.3860,  0.2725]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:39:08 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a trout is referred to as a fingerling
The offspring of a ox is referred to as a calf
The offspring of a salmon is referred to as a smolt
The offspring of a ferret is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a cicada is referred to as a nymph
The offspring of a chimpanzee is referred to as a baby
The offspring of a cat is referred to as a
2024-08-01 07:39:08 root INFO     [order_1_approx] starting weight calculation for The offspring of a chimpanzee is referred to as a baby
The offspring of a salmon is referred to as a smolt
The offspring of a skunk is referred to as a kit
The offspring of a cicada is referred to as a nymph
The offspring of a trout is referred to as a fingerling
The offspring of a cat is referred to as a kitten
The offspring of a ox is referred to as a calf
The offspring of a ferret is referred to as a
2024-08-01 07:39:08 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:42:12 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1009, -0.1228,  0.0876,  ...,  0.0010, -0.0007,  0.1350],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.6484, -0.8408, -1.6016,  ...,  1.1660, -2.3164,  0.6260],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0330, -0.0239,  0.0117,  ...,  0.0600, -0.0457,  0.0620],
        [ 0.0234,  0.0422, -0.0393,  ...,  0.0842,  0.0556,  0.0482],
        [ 0.0623,  0.0139, -0.0072,  ..., -0.0146, -0.0065,  0.0434],
        ...,
        [ 0.0339,  0.0174, -0.0757,  ...,  0.0492,  0.0381,  0.0186],
        [ 0.0596, -0.0126, -0.0278,  ...,  0.0186, -0.0011,  0.0011],
        [ 0.0254, -0.0236,  0.0085,  ..., -0.0066, -0.0095, -0.0156]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.1113, -0.7686, -1.6709,  ...,  1.6074, -2.3125,  0.6465]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:42:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a chimpanzee is referred to as a baby
The offspring of a salmon is referred to as a smolt
The offspring of a skunk is referred to as a kit
The offspring of a cicada is referred to as a nymph
The offspring of a trout is referred to as a fingerling
The offspring of a cat is referred to as a kitten
The offspring of a ox is referred to as a calf
The offspring of a ferret is referred to as a
2024-08-01 07:42:14 root INFO     [order_1_approx] starting weight calculation for The offspring of a cicada is referred to as a nymph
The offspring of a trout is referred to as a fingerling
The offspring of a cat is referred to as a kitten
The offspring of a ferret is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a ox is referred to as a calf
The offspring of a chimpanzee is referred to as a baby
The offspring of a salmon is referred to as a
2024-08-01 07:42:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:45:20 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1124, -0.0112, -0.1209,  ..., -0.1206, -0.0395,  0.1058],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.1169, -3.1562, -6.3047,  ...,  0.1035, -3.0781,  1.8281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0125, -0.0007,  0.0299,  ...,  0.0051, -0.0210, -0.0152],
        [-0.0037,  0.0506, -0.0170,  ...,  0.0026,  0.0276,  0.0078],
        [ 0.0440, -0.0141,  0.0227,  ...,  0.0289,  0.0056, -0.0076],
        ...,
        [ 0.0104,  0.0179, -0.0094,  ...,  0.0202,  0.0155,  0.0186],
        [ 0.0076,  0.0311, -0.0216,  ...,  0.0361,  0.0211, -0.0030],
        [ 0.0058,  0.0075,  0.0087,  ..., -0.0276, -0.0054,  0.0162]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.6680, -2.6680, -6.2852,  ...,  0.6245, -2.5820,  1.9170]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:45:21 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a cicada is referred to as a nymph
The offspring of a trout is referred to as a fingerling
The offspring of a cat is referred to as a kitten
The offspring of a ferret is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a ox is referred to as a calf
The offspring of a chimpanzee is referred to as a baby
The offspring of a salmon is referred to as a
2024-08-01 07:45:21 root INFO     [order_1_approx] starting weight calculation for The offspring of a salmon is referred to as a smolt
The offspring of a cicada is referred to as a nymph
The offspring of a cat is referred to as a kitten
The offspring of a ox is referred to as a calf
The offspring of a ferret is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a chimpanzee is referred to as a baby
The offspring of a trout is referred to as a
2024-08-01 07:45:21 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:48:28 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0582,  0.0178, -0.0602,  ..., -0.0884, -0.0195,  0.0287],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.4609, -2.9570, -6.0898,  ...,  1.6504, -2.8203,  0.0918],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0311,  0.0203,  0.0189,  ...,  0.0106,  0.0123,  0.0023],
        [ 0.0237,  0.0485, -0.0399,  ..., -0.0372, -0.0129,  0.0050],
        [ 0.0413, -0.0356,  0.0221,  ..., -0.0076,  0.0314, -0.0364],
        ...,
        [ 0.0370,  0.0212, -0.0240,  ...,  0.0656, -0.0295,  0.0168],
        [ 0.0492,  0.0370, -0.0301,  ...,  0.0430,  0.0007, -0.0217],
        [ 0.0021, -0.0385,  0.0244,  ..., -0.0379,  0.0178,  0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5400, -3.1250, -5.6484,  ...,  1.3906, -2.7031,  0.4519]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:48:28 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a salmon is referred to as a smolt
The offspring of a cicada is referred to as a nymph
The offspring of a cat is referred to as a kitten
The offspring of a ox is referred to as a calf
The offspring of a ferret is referred to as a kit
The offspring of a skunk is referred to as a kit
The offspring of a chimpanzee is referred to as a baby
The offspring of a trout is referred to as a
2024-08-01 07:48:29 root INFO     [order_1_approx] starting weight calculation for The offspring of a chimpanzee is referred to as a baby
The offspring of a trout is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a cat is referred to as a kitten
The offspring of a skunk is referred to as a kit
The offspring of a salmon is referred to as a smolt
The offspring of a ferret is referred to as a kit
The offspring of a ox is referred to as a
2024-08-01 07:48:29 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:51:35 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0204,  0.0584,  0.1075,  ..., -0.0794,  0.1416, -0.0474],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.5996, -2.9844, -1.8818,  ...,  1.5352, -0.9854,  0.5928],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0055, -0.0018,  0.0368,  ...,  0.0025, -0.0342, -0.0219],
        [ 0.0328,  0.0622, -0.0011,  ...,  0.0022, -0.0100,  0.0072],
        [-0.0037, -0.0010,  0.0057,  ..., -0.0442, -0.0160, -0.0279],
        ...,
        [ 0.0179,  0.0286, -0.0063,  ..., -0.0071,  0.0290, -0.0187],
        [-0.0068,  0.0483,  0.0192,  ...,  0.0019,  0.0433,  0.0207],
        [ 0.0446, -0.0101, -0.0156,  ...,  0.0151,  0.0472,  0.0257]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.5039, -2.1621, -2.5117,  ...,  1.5801, -0.5391,  0.9287]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:51:36 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a chimpanzee is referred to as a baby
The offspring of a trout is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a cat is referred to as a kitten
The offspring of a skunk is referred to as a kit
The offspring of a salmon is referred to as a smolt
The offspring of a ferret is referred to as a kit
The offspring of a ox is referred to as a
2024-08-01 07:51:36 root INFO     [order_1_approx] starting weight calculation for The offspring of a chimpanzee is referred to as a baby
The offspring of a ox is referred to as a calf
The offspring of a salmon is referred to as a smolt
The offspring of a cat is referred to as a kitten
The offspring of a ferret is referred to as a kit
The offspring of a trout is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a skunk is referred to as a
2024-08-01 07:51:37 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:54:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 4.4922e-02,  6.8420e-02, -9.1553e-05,  ..., -2.4768e-01,
        -7.4524e-02,  9.5215e-03], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4609, -2.6738, -1.6494,  ...,  0.3779, -2.8633,  1.6484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 9.5093e-02, -5.2246e-02,  1.2405e-02,  ...,  5.2856e-02,
          1.2398e-05, -2.5558e-03],
        [ 2.3163e-02,  2.1301e-02,  2.0676e-03,  ...,  3.6469e-02,
         -1.8219e-02,  6.2347e-02],
        [-4.2358e-02, -5.3711e-03,  1.6418e-02,  ...,  8.4991e-03,
          6.9160e-03,  2.2079e-02],
        ...,
        [-2.4445e-02,  3.1082e-02,  8.3923e-03,  ...,  4.2694e-02,
          2.2247e-02,  4.6570e-02],
        [-1.5778e-02, -8.4400e-04, -1.0345e-02,  ...,  5.4626e-03,
          5.7068e-02,  2.8488e-02],
        [ 1.0231e-02, -2.4765e-02,  3.8910e-02,  ..., -2.2598e-02,
          1.6083e-02,  2.9709e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.8281, -2.2734, -2.2266,  ...,  0.4641, -2.3652,  2.1348]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:54:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a chimpanzee is referred to as a baby
The offspring of a ox is referred to as a calf
The offspring of a salmon is referred to as a smolt
The offspring of a cat is referred to as a kitten
The offspring of a ferret is referred to as a kit
The offspring of a trout is referred to as a fingerling
The offspring of a cicada is referred to as a nymph
The offspring of a skunk is referred to as a
2024-08-01 07:54:44 root INFO     [order_1_approx] starting weight calculation for The offspring of a salmon is referred to as a smolt
The offspring of a ferret is referred to as a kit
The offspring of a cicada is referred to as a nymph
The offspring of a trout is referred to as a fingerling
The offspring of a skunk is referred to as a kit
The offspring of a ox is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a chimpanzee is referred to as a
2024-08-01 07:54:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 07:57:50 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1853, -0.0123,  0.0228,  ..., -0.0938, -0.3169, -0.0303],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.6621, -3.1875, -0.9766,  ...,  0.0596, -3.5742,  2.8281],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 6.9504e-03, -8.3923e-05, -1.9588e-03,  ...,  1.8463e-02,
         -4.6005e-03,  2.5749e-03],
        [ 1.9875e-03,  1.1597e-03,  3.7098e-03,  ...,  3.1700e-03,
          1.5535e-03, -8.0566e-03],
        [-9.9335e-03, -9.4070e-03, -4.8018e-04,  ..., -5.5218e-04,
          5.1193e-03, -3.2444e-03],
        ...,
        [ 7.0877e-03,  4.9744e-03,  3.2043e-04,  ..., -5.4073e-04,
         -7.8201e-04,  3.7231e-03],
        [-7.8430e-03, -8.3447e-04,  9.6436e-03,  ..., -6.5308e-03,
          1.4343e-02,  7.4081e-03],
        [ 3.7422e-03,  1.6308e-03, -3.9406e-03,  ...,  2.9202e-03,
          4.9305e-04, -1.6012e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.5371, -3.1289, -0.9927,  ...,  0.1296, -3.3477,  2.7812]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 07:57:51 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for The offspring of a salmon is referred to as a smolt
The offspring of a ferret is referred to as a kit
The offspring of a cicada is referred to as a nymph
The offspring of a trout is referred to as a fingerling
The offspring of a skunk is referred to as a kit
The offspring of a ox is referred to as a calf
The offspring of a cat is referred to as a kitten
The offspring of a chimpanzee is referred to as a
2024-08-01 07:57:51 root INFO     total operator prediction time: 1490.3398311138153 seconds
2024-08-01 07:57:51 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on UK_city - county
2024-08-01 07:57:51 root INFO     building operator UK_city - county
2024-08-01 07:57:51 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of carlisle is in the county of
2024-08-01 07:57:51 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:02:33 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0658, -0.0537, -0.1196,  ..., -0.1760, -0.1125,  0.2607],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.0303, -2.7422,  1.6270,  ..., -4.7422,  1.4414,  0.8486],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0082, -0.0226,  0.0060,  ...,  0.0147, -0.0046,  0.0029],
        [-0.0239,  0.0409, -0.0370,  ...,  0.0589,  0.0012, -0.0721],
        [-0.0263,  0.0036, -0.0038,  ...,  0.0415, -0.0109, -0.0117],
        ...,
        [ 0.0038,  0.0100, -0.0448,  ...,  0.0544, -0.0184, -0.0114],
        [ 0.0238, -0.0599,  0.0399,  ..., -0.0576,  0.0091,  0.0345],
        [ 0.0317, -0.0029, -0.0329,  ...,  0.0514, -0.0137, -0.0328]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.0717, -3.0391,  1.4727,  ..., -4.8633,  1.7188,  0.6182]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:02:34 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of carlisle is in the county of
2024-08-01 08:02:34 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of derby is in the county of
2024-08-01 08:02:34 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:07:18 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0663,  0.0599,  0.1238,  ...,  0.0998, -0.0137,  0.0204],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.2695e+00, -2.1758e+00,  2.3027e+00,  ..., -3.4141e+00,
        -2.9297e-03, -1.8857e+00], device='cuda:0', dtype=torch.float16,
       grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.0620e-02,  6.2466e-05,  1.1871e-02,  ...,  1.8799e-02,
          4.3678e-04,  1.6281e-02],
        [ 6.2561e-03, -1.6346e-03,  6.5552e-02,  ...,  2.9419e-02,
          8.3389e-03, -1.8829e-02],
        [-7.7591e-03, -1.0658e-02, -2.4673e-02,  ...,  2.6138e-02,
         -3.2593e-02, -2.4918e-02],
        ...,
        [ 4.2511e-02, -8.8654e-03, -1.9775e-02,  ...,  5.4565e-02,
         -4.0802e-02, -1.6464e-02],
        [-7.3090e-03,  4.0474e-03,  3.4485e-03,  ...,  5.4260e-02,
          3.1189e-02,  1.4290e-02],
        [ 3.2562e-02, -3.1189e-02, -2.3727e-02,  ...,  1.8967e-02,
         -2.2079e-02, -4.1924e-03]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.1836, -2.2051,  2.0762,  ..., -3.1328,  0.1600, -1.8389]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:07:19 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of derby is in the county of
2024-08-01 08:07:19 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of swansea is in the county of
2024-08-01 08:07:19 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:12:03 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0580,  0.0303, -0.1399,  ...,  0.1541,  0.1431, -0.0053],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.0352, -4.3672,  0.1045,  ..., -2.3828, -1.6367,  1.9102],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0080, -0.0047,  0.0172,  ..., -0.0167,  0.0117,  0.0167],
        [ 0.0141,  0.0116,  0.0146,  ..., -0.0174,  0.0044, -0.0031],
        [-0.0051, -0.0200, -0.0317,  ...,  0.0168, -0.0152,  0.0068],
        ...,
        [ 0.0013, -0.0086, -0.0047,  ...,  0.0240,  0.0053,  0.0038],
        [ 0.0042, -0.0182,  0.0205,  ..., -0.0164,  0.0255, -0.0087],
        [-0.0113, -0.0131, -0.0237,  ...,  0.0122, -0.0121,  0.0155]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1426, -4.3242,  0.2275,  ..., -2.2051, -1.5078,  1.7354]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:12:04 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of swansea is in the county of
2024-08-01 08:12:04 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of nottingham is in the county of
2024-08-01 08:12:04 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:16:46 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0280,  0.0752, -0.1776,  ...,  0.1494,  0.0554,  0.0230],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.0898, -3.0938, -1.4512,  ..., -4.8828, -0.8535, -1.1250],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0033,  0.0207,  0.0263,  ..., -0.0175,  0.0149,  0.0132],
        [-0.0016,  0.0025, -0.0052,  ...,  0.0011,  0.0029, -0.0162],
        [-0.0031,  0.0041,  0.0204,  ..., -0.0198, -0.0034, -0.0115],
        ...,
        [-0.0039, -0.0113,  0.0042,  ...,  0.0169, -0.0119, -0.0068],
        [-0.0046,  0.0016, -0.0045,  ...,  0.0214, -0.0081, -0.0127],
        [ 0.0080, -0.0211, -0.0403,  ...,  0.0060, -0.0126,  0.0221]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.8584, -3.0684, -1.3613,  ..., -4.5742, -0.6118, -1.2061]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:16:47 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of nottingham is in the county of
2024-08-01 08:16:47 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of stirling is in the county of
2024-08-01 08:16:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:21:30 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1064, -0.0151, -0.1232,  ...,  0.1665, -0.0243,  0.0934],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.0840, -3.4648,  0.1348,  ..., -2.9062, -1.9102, -1.4531],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0175, -0.0282, -0.0176,  ...,  0.0155,  0.0113, -0.0318],
        [-0.0015, -0.0175,  0.0535,  ...,  0.0390, -0.0122, -0.0486],
        [-0.0367, -0.0024,  0.0440,  ...,  0.0073, -0.0316,  0.0102],
        ...,
        [-0.0045, -0.0235, -0.0229,  ...,  0.0418, -0.0687,  0.0273],
        [ 0.0558, -0.0067, -0.0057,  ..., -0.0360,  0.0509,  0.0505],
        [ 0.0010, -0.0017, -0.0277,  ..., -0.0323, -0.0416,  0.0439]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2051, -3.7070,  0.0460,  ..., -2.6055, -1.3203, -1.2617]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:21:31 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of stirling is in the county of
2024-08-01 08:21:31 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of reading is in the county of
2024-08-01 08:21:32 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:26:13 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0156,  0.0250, -0.2112,  ...,  0.3049, -0.0210,  0.0336],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.3281, -5.0000,  1.9287,  ..., -2.4609,  3.0859, -2.3945],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0094, -0.0460, -0.0046,  ..., -0.0018,  0.0184, -0.0030],
        [ 0.0384, -0.0179,  0.0955,  ...,  0.0453,  0.0436, -0.0009],
        [-0.0162,  0.0235,  0.0085,  ..., -0.0085,  0.0414,  0.0087],
        ...,
        [ 0.0410,  0.0069, -0.0225,  ...,  0.0069, -0.0199,  0.0061],
        [-0.0039, -0.0079, -0.0293,  ..., -0.0090,  0.0073, -0.0101],
        [ 0.0100, -0.0202, -0.0118,  ...,  0.0103, -0.0147, -0.0071]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.3008, -4.5156,  1.8555,  ..., -2.4746,  3.0566, -2.3301]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:26:14 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of reading is in the county of
2024-08-01 08:26:14 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of worcester is in the county of
2024-08-01 08:26:14 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:30:57 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1124,  0.0248, -0.0457,  ...,  0.1117, -0.1141, -0.0238],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9600, -4.6172,  0.7412,  ..., -2.5703,  2.2461, -0.6367],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 1.5915e-02, -8.5571e-02,  3.5339e-02,  ...,  2.5177e-04,
          2.8946e-02, -2.3575e-02],
        [-2.1378e-02,  4.9103e-02, -2.4628e-02,  ...,  3.0746e-02,
         -1.6647e-02,  1.5976e-02],
        [-2.4414e-02,  2.7328e-02, -2.5635e-02,  ...,  2.8168e-02,
          2.7771e-03,  3.2928e-02],
        ...,
        [ 4.7302e-03,  4.2603e-02, -2.9964e-03,  ...,  1.8646e-02,
         -2.8549e-02,  7.6294e-03],
        [ 1.3077e-02, -4.5441e-02,  1.1787e-02,  ..., -4.5776e-05,
          2.5116e-02, -2.1088e-02],
        [-2.4796e-04, -1.3039e-02, -1.6388e-02,  ..., -1.6155e-03,
         -1.2619e-02,  2.2491e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2930, -4.7969,  0.6909,  ..., -2.7188,  2.4844, -0.6494]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:30:58 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of chichester is in the county of sussex
In the United Kingdom, the city of worcester is in the county of
2024-08-01 08:30:58 root INFO     [order_1_approx] starting weight calculation for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of chichester is in the county of
2024-08-01 08:30:58 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:35:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1176,  0.1133, -0.0446,  ...,  0.0170,  0.1368,  0.1245],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 4.4414, -1.9727,  0.8350,  ..., -1.6416,  1.1299,  0.4822],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0089, -0.0418, -0.0345,  ...,  0.0407, -0.0058, -0.0006],
        [ 0.0032,  0.0677, -0.0115,  ...,  0.0274, -0.0036, -0.0063],
        [-0.0077, -0.0280, -0.0567,  ...,  0.0219, -0.0136, -0.0103],
        ...,
        [ 0.0109, -0.0008, -0.0360,  ...,  0.0218,  0.0089, -0.0265],
        [-0.0079, -0.0576,  0.0497,  ...,  0.0181,  0.0395, -0.0008],
        [-0.0173,  0.0144, -0.0408,  ..., -0.0201,  0.0100,  0.0279]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 4.4336, -2.0781,  0.9048,  ..., -1.0918,  1.2354,  0.3992]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:35:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for In the United Kingdom, the city of carlisle is in the county of cumbria
In the United Kingdom, the city of reading is in the county of berkshire
In the United Kingdom, the city of stirling is in the county of stirlingshire
In the United Kingdom, the city of swansea is in the county of glamorgan
In the United Kingdom, the city of worcester is in the county of worcestershire
In the United Kingdom, the city of nottingham is in the county of nottinghamshire
In the United Kingdom, the city of derby is in the county of derbyshire
In the United Kingdom, the city of chichester is in the county of
2024-08-01 08:35:43 root INFO     total operator prediction time: 2272.2613723278046 seconds
2024-08-01 08:35:43 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on meronyms - part
2024-08-01 08:35:43 root INFO     building operator meronyms - part
2024-08-01 08:35:43 root INFO     [order_1_approx] starting weight calculation for A part of a gun is a trigger
A part of a shirt is a button
A part of a church is a altar
A part of a torso is a chest
A part of a movie is a scene
A part of a window is a pane
A part of a poem is a stanza
A part of a seafront is a
2024-08-01 08:35:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:38:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1267,  0.0205, -0.0024,  ...,  0.1030, -0.0958,  0.0232],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.6406, -5.0859, -3.0234,  ...,  5.9336, -1.6572, -1.2510],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0512, -0.0293,  0.0027,  ...,  0.0222, -0.0252, -0.0090],
        [ 0.0085,  0.0108, -0.0246,  ...,  0.0150,  0.0007, -0.0214],
        [ 0.0668, -0.0367,  0.0088,  ..., -0.0292,  0.0606,  0.0080],
        ...,
        [-0.0266,  0.0463, -0.0034,  ..., -0.0017, -0.0479,  0.0002],
        [ 0.0144, -0.0368, -0.0006,  ..., -0.0079,  0.0469, -0.0130],
        [-0.0059, -0.0078, -0.0170,  ...,  0.0206,  0.0043,  0.0278]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7017, -4.9531, -2.0430,  ...,  5.2266, -1.2695, -1.2002]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:38:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a gun is a trigger
A part of a shirt is a button
A part of a church is a altar
A part of a torso is a chest
A part of a movie is a scene
A part of a window is a pane
A part of a poem is a stanza
A part of a seafront is a
2024-08-01 08:38:42 root INFO     [order_1_approx] starting weight calculation for A part of a seafront is a harbor
A part of a movie is a scene
A part of a gun is a trigger
A part of a poem is a stanza
A part of a shirt is a button
A part of a window is a pane
A part of a torso is a chest
A part of a church is a
2024-08-01 08:38:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:41:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0170,  0.0164, -0.0417,  ...,  0.1216, -0.1923,  0.0146],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8154, -2.8125,  2.7344,  ...,  0.4102, -0.9146, -1.5459],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-5.6305e-03, -2.3376e-02,  1.4648e-02,  ..., -6.1035e-05,
          1.5602e-03, -3.2562e-02],
        [-3.1166e-03,  2.0771e-03, -5.9357e-03,  ..., -1.4725e-03,
          2.9266e-02, -3.2387e-03],
        [ 1.0826e-02, -1.2505e-02,  2.8610e-04,  ..., -1.5617e-02,
          9.1782e-03, -1.7334e-02],
        ...,
        [-1.7242e-02, -7.4234e-03, -9.0027e-04,  ...,  2.8900e-02,
          2.1027e-02, -1.8066e-02],
        [-1.6937e-02, -4.2648e-03, -4.8218e-03,  ..., -1.0689e-02,
          3.4546e-02,  8.9417e-03],
        [-8.3923e-03,  5.7297e-03,  1.4694e-02,  ...,  2.1774e-02,
         -1.9012e-02,  1.3359e-02]], device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7759, -2.1582,  2.5918,  ..., -0.0735, -1.1270, -0.7324]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:41:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a seafront is a harbor
A part of a movie is a scene
A part of a gun is a trigger
A part of a poem is a stanza
A part of a shirt is a button
A part of a window is a pane
A part of a torso is a chest
A part of a church is a
2024-08-01 08:41:43 root INFO     [order_1_approx] starting weight calculation for A part of a window is a pane
A part of a church is a altar
A part of a movie is a scene
A part of a torso is a chest
A part of a seafront is a harbor
A part of a gun is a trigger
A part of a shirt is a button
A part of a poem is a
2024-08-01 08:41:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:44:38 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0356,  0.2180, -0.0720,  ...,  0.0455, -0.1587,  0.0589],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 3.4863, -4.6797,  3.5996,  ...,  6.0391, -0.2998, -2.0410],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0200, -0.0046,  0.0178,  ...,  0.0078, -0.0006,  0.0383],
        [-0.0073, -0.0162,  0.0080,  ..., -0.0183,  0.0264, -0.0248],
        [-0.0089, -0.0005,  0.0401,  ..., -0.0327, -0.0038,  0.0014],
        ...,
        [-0.0064,  0.0041,  0.0254,  ...,  0.0071,  0.0018, -0.0277],
        [ 0.0021,  0.0207, -0.0169,  ..., -0.0057, -0.0031,  0.0311],
        [-0.0041, -0.0192,  0.0091,  ..., -0.0253,  0.0183,  0.0146]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1562, -3.5273,  4.1016,  ...,  6.0859, -1.0234, -1.0859]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:44:39 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a window is a pane
A part of a church is a altar
A part of a movie is a scene
A part of a torso is a chest
A part of a seafront is a harbor
A part of a gun is a trigger
A part of a shirt is a button
A part of a poem is a
2024-08-01 08:44:39 root INFO     [order_1_approx] starting weight calculation for A part of a church is a altar
A part of a torso is a chest
A part of a poem is a stanza
A part of a movie is a scene
A part of a shirt is a button
A part of a window is a pane
A part of a seafront is a harbor
A part of a gun is a
2024-08-01 08:44:39 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:47:40 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0739,  0.0145,  0.0615,  ..., -0.0409, -0.1403, -0.2100],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.9561, -2.7891,  2.0312,  ..., -0.0059,  0.6553, -2.7031],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0142, -0.0394,  0.0300,  ..., -0.0047, -0.0031, -0.0309],
        [-0.0177, -0.0088,  0.0108,  ...,  0.0159, -0.0015, -0.0173],
        [ 0.0205, -0.0282,  0.0414,  ..., -0.0173,  0.0115, -0.0141],
        ...,
        [-0.0069, -0.0065, -0.0326,  ...,  0.0353, -0.0238,  0.0223],
        [-0.0467,  0.0058, -0.0194,  ...,  0.0044,  0.0141,  0.0008],
        [ 0.0413, -0.0334, -0.0059,  ...,  0.0245,  0.0070, -0.0026]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.6465, -2.4922,  2.4844,  ..., -0.0264, -0.0317, -1.5732]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:47:40 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a church is a altar
A part of a torso is a chest
A part of a poem is a stanza
A part of a movie is a scene
A part of a shirt is a button
A part of a window is a pane
A part of a seafront is a harbor
A part of a gun is a
2024-08-01 08:47:41 root INFO     [order_1_approx] starting weight calculation for A part of a torso is a chest
A part of a seafront is a harbor
A part of a church is a altar
A part of a shirt is a button
A part of a gun is a trigger
A part of a poem is a stanza
A part of a window is a pane
A part of a movie is a
2024-08-01 08:47:41 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:50:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0582,  0.2881, -0.1304,  ...,  0.0372,  0.0392,  0.1022],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.7715, -0.7598,  4.1289,  ...,  0.2422,  0.1104, -1.6016],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0122, -0.0022,  0.0414,  ...,  0.0350, -0.0175,  0.0006],
        [-0.0106, -0.0077, -0.0285,  ..., -0.0031,  0.0116, -0.0147],
        [ 0.0079, -0.0252,  0.0155,  ..., -0.0361,  0.0179, -0.0199],
        ...,
        [-0.0118,  0.0126,  0.0082,  ...,  0.0204, -0.0057, -0.0056],
        [ 0.0490,  0.0189, -0.0113,  ..., -0.0087,  0.0254,  0.0320],
        [-0.0281, -0.0332, -0.0047,  ..., -0.0151, -0.0079, -0.0047]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.2046, -0.8701,  3.9766,  ...,  0.4878,  0.1724, -1.2246]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:50:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a torso is a chest
A part of a seafront is a harbor
A part of a church is a altar
A part of a shirt is a button
A part of a gun is a trigger
A part of a poem is a stanza
A part of a window is a pane
A part of a movie is a
2024-08-01 08:50:43 root INFO     [order_1_approx] starting weight calculation for A part of a torso is a chest
A part of a poem is a stanza
A part of a window is a pane
A part of a movie is a scene
A part of a seafront is a harbor
A part of a church is a altar
A part of a gun is a trigger
A part of a shirt is a
2024-08-01 08:50:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:53:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1849, -0.1322, -0.0778,  ...,  0.1361, -0.1763, -0.0133],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4316, -3.6641, -0.7822,  ...,  1.5527,  3.7871,  0.5039],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0117, -0.0171,  0.0044,  ...,  0.0025,  0.0328, -0.0273],
        [-0.0116, -0.0121,  0.0051,  ...,  0.0281, -0.0098, -0.0022],
        [ 0.0014,  0.0017,  0.0181,  ..., -0.0084, -0.0109,  0.0168],
        ...,
        [ 0.0091, -0.0231,  0.0026,  ...,  0.0025,  0.0271, -0.0254],
        [ 0.0097, -0.0021, -0.0306,  ..., -0.0331,  0.0488, -0.0065],
        [-0.0116, -0.0178, -0.0179,  ...,  0.0022, -0.0177, -0.0057]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.2227, -3.2910, -0.2749,  ...,  1.6592,  4.8281,  0.5938]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:53:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a torso is a chest
A part of a poem is a stanza
A part of a window is a pane
A part of a movie is a scene
A part of a seafront is a harbor
A part of a church is a altar
A part of a gun is a trigger
A part of a shirt is a
2024-08-01 08:53:42 root INFO     [order_1_approx] starting weight calculation for A part of a church is a altar
A part of a poem is a stanza
A part of a gun is a trigger
A part of a movie is a scene
A part of a seafront is a harbor
A part of a torso is a chest
A part of a shirt is a button
A part of a window is a
2024-08-01 08:53:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:56:43 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.1320, -0.0318, -0.0698,  ...,  0.2930, -0.0051, -0.0428],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 0.8560, -5.2734,  0.7520,  ..., -0.1855, -2.3047, -0.9673],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0451, -0.0156,  0.0114,  ..., -0.0069,  0.0066, -0.0252],
        [ 0.0121,  0.0273,  0.0107,  ..., -0.0291,  0.0191,  0.0056],
        [ 0.0004, -0.0168,  0.0157,  ...,  0.0062, -0.0261,  0.0004],
        ...,
        [ 0.0306,  0.0211, -0.0094,  ...,  0.0182, -0.0193, -0.0042],
        [ 0.0125, -0.0132, -0.0086,  ..., -0.0139,  0.0177, -0.0004],
        [ 0.0109, -0.0063, -0.0099,  ...,  0.0005, -0.0310,  0.0045]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 1.0361, -4.8516,  0.8560,  ..., -0.3022, -1.9912, -0.6348]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:56:44 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a church is a altar
A part of a poem is a stanza
A part of a gun is a trigger
A part of a movie is a scene
A part of a seafront is a harbor
A part of a torso is a chest
A part of a shirt is a button
A part of a window is a
2024-08-01 08:56:44 root INFO     [order_1_approx] starting weight calculation for A part of a shirt is a button
A part of a church is a altar
A part of a gun is a trigger
A part of a seafront is a harbor
A part of a poem is a stanza
A part of a window is a pane
A part of a movie is a scene
A part of a torso is a
2024-08-01 08:56:44 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 08:59:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0176,  0.0042, -0.0271,  ...,  0.1009,  0.0254, -0.0752],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.2051, -4.9844,  2.5703,  ...,  2.3359, -2.6113, -0.4121],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0381, -0.0729, -0.0161,  ...,  0.0490,  0.0654, -0.0543],
        [ 0.0510, -0.0339, -0.0131,  ...,  0.0122,  0.0968, -0.0568],
        [-0.0035,  0.0592, -0.0217,  ...,  0.0055, -0.0059, -0.0073],
        ...,
        [-0.0614,  0.0043,  0.0022,  ...,  0.0760,  0.0968, -0.0837],
        [-0.0014, -0.0401,  0.0115,  ...,  0.0140, -0.0300, -0.0035],
        [-0.0411, -0.0482, -0.0030,  ...,  0.0262,  0.0604, -0.0051]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.4883, -2.8594,  2.0859,  ...,  3.0332, -2.8340,  1.0410]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 08:59:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for A part of a shirt is a button
A part of a church is a altar
A part of a gun is a trigger
A part of a seafront is a harbor
A part of a poem is a stanza
A part of a window is a pane
A part of a movie is a scene
A part of a torso is a
2024-08-01 08:59:45 root INFO     total operator prediction time: 1442.2716574668884 seconds
2024-08-01 08:59:45 __main__ INFO     storing weights: <class 'lre.operators.JacobianIclMeanEstimator'> on synonyms - exact
2024-08-01 08:59:45 root INFO     building operator synonyms - exact
2024-08-01 08:59:45 root INFO     [order_1_approx] starting weight calculation for Another word for honest is sincere
Another word for mesh is gauze
Another word for portion is part
Another word for child is kid
Another word for lad is chap
Another word for phone is telephone
Another word for reasonable is sensible
Another word for organized is
2024-08-01 08:59:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 09:02:41 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0449,  0.2015, -0.0370,  ..., -0.0939, -0.0302, -0.0182],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-0.3325,  0.7383,  2.6406,  ...,  1.5195, -2.9004, -4.4141],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0440,  0.0004,  0.0331,  ..., -0.0005, -0.0171,  0.0134],
        [-0.0356, -0.0565,  0.0194,  ..., -0.0616, -0.0022, -0.0477],
        [ 0.0052, -0.0119,  0.0292,  ...,  0.0374,  0.0495,  0.0332],
        ...,
        [ 0.0135,  0.0391, -0.0166,  ..., -0.0027, -0.0405, -0.0244],
        [ 0.0229,  0.0341, -0.0073,  ...,  0.0593,  0.0632,  0.0476],
        [-0.0079, -0.0170,  0.0295,  ..., -0.0295, -0.0457, -0.0215]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-0.3008,  0.1948,  3.4414,  ...,  1.1504, -1.8438, -4.6875]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:02:42 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for honest is sincere
Another word for mesh is gauze
Another word for portion is part
Another word for child is kid
Another word for lad is chap
Another word for phone is telephone
Another word for reasonable is sensible
Another word for organized is
2024-08-01 09:02:42 root INFO     [order_1_approx] starting weight calculation for Another word for mesh is gauze
Another word for lad is chap
Another word for organized is arranged
Another word for phone is telephone
Another word for portion is part
Another word for honest is sincere
Another word for child is kid
Another word for reasonable is
2024-08-01 09:02:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 09:05:39 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1527,  0.1378, -0.1350,  ..., -0.0176, -0.1879,  0.0397],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.9004,  2.0742, -2.0469,  ..., -3.4844, -8.6562, -1.2148],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[-0.0052, -0.0431,  0.0272,  ...,  0.0089, -0.0341,  0.0261],
        [-0.0540,  0.0483, -0.0236,  ...,  0.0361,  0.0251,  0.0051],
        [ 0.0182, -0.0143,  0.0244,  ..., -0.0186,  0.0221, -0.0175],
        ...,
        [ 0.0574,  0.0076,  0.0338,  ..., -0.0355,  0.0267, -0.0321],
        [ 0.0024,  0.0262,  0.0346,  ..., -0.0438,  0.0647, -0.0033],
        [ 0.0171,  0.0086,  0.0290,  ...,  0.0074, -0.0205, -0.0052]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 3.1211,  2.7070, -1.8408,  ..., -3.3789, -8.5000, -1.2090]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:05:41 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for mesh is gauze
Another word for lad is chap
Another word for organized is arranged
Another word for phone is telephone
Another word for portion is part
Another word for honest is sincere
Another word for child is kid
Another word for reasonable is
2024-08-01 09:05:42 root INFO     [order_1_approx] starting weight calculation for Another word for reasonable is sensible
Another word for portion is part
Another word for lad is chap
Another word for honest is sincere
Another word for child is kid
Another word for mesh is gauze
Another word for organized is arranged
Another word for phone is
2024-08-01 09:05:42 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 09:08:42 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([-0.0241, -0.1536, -0.2057,  ..., -0.0204, -0.1304, -0.2988],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([-1.0850, -4.1602,  1.7383,  ...,  0.2291, -0.7314, -4.9844],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0509, -0.0412,  0.0553,  ...,  0.0169, -0.0306,  0.0834],
        [-0.0231, -0.0133,  0.0410,  ...,  0.0268,  0.0226, -0.0029],
        [ 0.0353, -0.0528,  0.0504,  ...,  0.0009, -0.0191,  0.0230],
        ...,
        [ 0.0677, -0.0061,  0.0102,  ..., -0.0468, -0.0480,  0.0114],
        [-0.0165, -0.0182,  0.0417,  ...,  0.0341,  0.0250,  0.0329],
        [-0.0338,  0.0072,  0.0003,  ..., -0.0052, -0.0254,  0.0216]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[-1.2227, -3.5371,  1.7080,  ...,  0.2976, -0.1553, -4.4414]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:08:43 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for reasonable is sensible
Another word for portion is part
Another word for lad is chap
Another word for honest is sincere
Another word for child is kid
Another word for mesh is gauze
Another word for organized is arranged
Another word for phone is
2024-08-01 09:08:43 root INFO     [order_1_approx] starting weight calculation for Another word for reasonable is sensible
Another word for honest is sincere
Another word for mesh is gauze
Another word for lad is chap
Another word for organized is arranged
Another word for phone is telephone
Another word for portion is part
Another word for child is
2024-08-01 09:08:43 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 09:11:44 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.0168, -0.1016, -0.1143,  ...,  0.0257, -0.2737, -0.0557],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 2.4180, -4.2227, -2.7480,  ...,  0.4775, -1.2910, -0.7451],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0437, -0.0071,  0.0149,  ...,  0.0184,  0.0068,  0.0188],
        [ 0.0229,  0.0240,  0.0126,  ...,  0.0300, -0.0287,  0.0269],
        [-0.0027, -0.0722,  0.0250,  ...,  0.0109, -0.0278, -0.0010],
        ...,
        [ 0.0071, -0.0005,  0.0015,  ...,  0.0036, -0.0059, -0.0034],
        [-0.0130,  0.0416, -0.0010,  ..., -0.0128,  0.0214, -0.0410],
        [-0.0019, -0.0107,  0.0039,  ...,  0.0115,  0.0029,  0.0293]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 2.0645, -4.1328, -1.9824,  ..., -0.2915, -0.5010, -1.4375]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:11:45 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for reasonable is sensible
Another word for honest is sincere
Another word for mesh is gauze
Another word for lad is chap
Another word for organized is arranged
Another word for phone is telephone
Another word for portion is part
Another word for child is
2024-08-01 09:11:45 root INFO     [order_1_approx] starting weight calculation for Another word for phone is telephone
Another word for child is kid
Another word for honest is sincere
Another word for organized is arranged
Another word for lad is chap
Another word for mesh is gauze
Another word for reasonable is sensible
Another word for portion is
2024-08-01 09:11:45 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 09:14:47 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.2671, -0.0594, -0.0815,  ..., -0.0370, -0.1180,  0.0713],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.2637, -3.9629,  0.0959,  ..., -2.4941, -1.1748, -2.1484],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0138, -0.0761,  0.0558,  ..., -0.0357,  0.0395,  0.0383],
        [-0.0065,  0.0035,  0.0273,  ..., -0.0591, -0.0253, -0.0144],
        [ 0.0361,  0.0582,  0.0451,  ..., -0.0025, -0.0751, -0.0574],
        ...,
        [-0.0021, -0.0445,  0.0107,  ..., -0.0198, -0.0142,  0.0114],
        [ 0.0064,  0.0207, -0.0182,  ...,  0.0669,  0.0632,  0.0356],
        [-0.0134, -0.0302, -0.0107,  ..., -0.0372,  0.0189,  0.0316]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.7437, -4.3984, -0.2800,  ..., -2.3301, -0.0332, -1.9268]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:14:48 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for phone is telephone
Another word for child is kid
Another word for honest is sincere
Another word for organized is arranged
Another word for lad is chap
Another word for mesh is gauze
Another word for reasonable is sensible
Another word for portion is
2024-08-01 09:14:48 root INFO     [order_1_approx] starting weight calculation for Another word for portion is part
Another word for lad is chap
Another word for phone is telephone
Another word for mesh is gauze
Another word for child is kid
Another word for reasonable is sensible
Another word for organized is arranged
Another word for honest is
2024-08-01 09:14:48 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
2024-08-01 09:17:48 root INFO     [order_1_approx] weight calculation finished 

                        s_j=tensor([ 0.1548,  0.1143, -0.0786,  ...,  0.1151, -0.1021,  0.1293],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        o_j1=tensor([ 1.8066, -3.0469, -0.9229,  ...,  0.5264, -9.0156,  2.5586],
       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>) 

                        s_o_weight: tensor([[ 0.0246, -0.0308,  0.0546,  ...,  0.0003, -0.0541,  0.0457],
        [ 0.0089,  0.0461,  0.0254,  ..., -0.0252,  0.0545, -0.0286],
        [ 0.0312,  0.0145,  0.0207,  ...,  0.0031, -0.0339, -0.0183],
        ...,
        [ 0.0082, -0.0278,  0.0417,  ...,  0.0667,  0.0602,  0.0150],
        [ 0.0158,  0.0082,  0.0389,  ...,  0.0297,  0.0708,  0.0281],
        [-0.0150, -0.0424,  0.0189,  ..., -0.0175, -0.0221,  0.0133]],
       device='cuda:0', dtype=torch.float16) 

                        s_o_bias=tensor([[ 0.9771, -3.5410, -1.3301,  ...,  2.6055, -8.0156,  2.9570]],
       device='cuda:0', dtype=torch.float16, grad_fn=<SubBackward0>) 

                    
2024-08-01 09:17:49 lre.operators INFO     sem1 [Jacobian] Finished order_1_approx for Another word for portion is part
Another word for lad is chap
Another word for phone is telephone
Another word for mesh is gauze
Another word for child is kid
Another word for reasonable is sensible
Another word for organized is arranged
Another word for honest is
2024-08-01 09:17:49 root INFO     [order_1_approx] starting weight calculation for Another word for portion is part
Another word for honest is sincere
Another word for lad is chap
Another word for phone is telephone
Another word for reasonable is sensible
Another word for child is kid
Another word for organized is arranged
Another word for mesh is
2024-08-01 09:17:49 lre.functional WARNING  [insert_s_j] layer model.layers.31 does not match model.layers.5
