{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4d83fb-81af-4c29-8b65-0f104333a540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exia/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from transformers import GPTJForCausalLM, AutoTokenizer\n",
    "import lre.models as models\n",
    "import lre.functional as functional\n",
    "import os\n",
    "\n",
    "import json\n",
    "import random\n",
    "from lre.data import Relation, RelationSample, Sequence\n",
    "import lre.metrics as metrics\n",
    "import lre.functional as functional\n",
    "\n",
    "device = 'cuda:0'\n",
    "weights = []\n",
    "biases = []\n",
    "subjects = []\n",
    "model = GPTJForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", revision=\"float16\", torch_dtype=torch.float16, low_cpu_mem_usage=True)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "mt = models.ModelAndTokenizer(model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c89eaaa6-e350-401a-80fb-bef421974cc1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#OBTAIN LRE WEIGHTS: Method 1\n",
    "#Load weights saved with new naming convention\n",
    "\n",
    "def mean_weight_or_bias(wdir, kind, samples):\n",
    "    weights = []\n",
    "    for sample in samples:\n",
    "        weight_path = f\"{wdir}/{sample}/{kind}.pt\"\n",
    "        #load s_s_weight and s_s_bias\n",
    "        weight = torch.load(weight_path).to(device)\n",
    "        #append to lists\n",
    "        weights.append(weight)\n",
    "    mean_weight = torch.stack(weights).mean(dim=0).to(device)\n",
    "    return mean_weight\n",
    "    \n",
    "samples = [\"ahead\", \"backward\", \"down\", \"inbound\", \"input\", \"mortal\", \"off\", \"top\"]\n",
    "lre_weight = mean_weight_or_bias('qapprox', 's_o_weight_5_27', samples)\n",
    "lre_bias = mean_weight_or_bias('qapprox', 's_o_bias_5_27', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebdca32-b2da-4046-a0ad-8b1d7ee6bd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meronyms - member_weight_3_140707.pt',\n",
       " 'meronyms - member_weight_5_140715.pt',\n",
       " 'meronyms - member_weight_7_140723.pt',\n",
       " 'meronyms - member_weight_6_140719.pt',\n",
       " 'meronyms - member_weight_1_140659.pt',\n",
       " 'meronyms - member_weight_2_140703.pt',\n",
       " 'meronyms - member_weight_0_140655.pt',\n",
       " 'meronyms - member_weight_4_140711.pt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OBTAIN LRE WEIGHTS: Method 2\n",
    "#Method 2: An LRE loading script for the older weights in 'approx' & 'wapprox'\n",
    "\n",
    "#verb + er\n",
    "\n",
    "weight_str = 'meronyms - member_weight'\n",
    "bias_str = 'meronyms - member_bias'\n",
    "wdir = \"approx/meronyms - member\"\n",
    "\n",
    "weight_paths = [f for f in os.listdir(wdir) if f.startswith(weight_str)]\n",
    "bias_paths = [f for f in os.listdir(wdir) if f.startswith(bias_str)]\n",
    "\n",
    "for weight_str, bias_str in zip(weight_paths, bias_paths):\n",
    "    weight = torch.load(wdir + \"/\" + weight_str).to(device)\n",
    "    bias = torch.load(wdir + \"/\" + bias_str).to(device)\n",
    "    weights.append(weight)\n",
    "    biases.append(bias)\n",
    "    \n",
    "lre_weight = torch.stack(weights).mean(dim=0).to(device)\n",
    "lre_bias = torch.stack(biases).mean(dim=0).to(device)\n",
    "weight_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d52b498-d9c0-4ac8-8dd7-ea46d3893f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import llra.build as build\n",
    "from importlib import reload\n",
    "reload(build)\n",
    "build.determine_device(mt)\n",
    "build.determine_params(mt)\n",
    "S_O_start = 21\n",
    "S_O_end = 26\n",
    "start, end = 7, 27\n",
    "beta = 2.75\n",
    "wdir = 'capprox/COMPLETE grads/0member-team'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0167f0c2-4b92-43ee-aacc-be24ef75f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=7 S_O_start=21 S_O_end=26 end=27\n",
      "calling mwb with 21\n",
      "constructed layer_dict for 21\n",
      "calling mwb with 22\n",
      "constructed layer_dict for 22\n",
      "calling mwb with 23\n",
      "constructed layer_dict for 23\n",
      "calling mwb with 24\n",
      "constructed layer_dict for 24\n",
      "calling mwb with 25\n",
      "constructed layer_dict for 25\n",
      "calling mwb with 7\n",
      "constructed layer_dict for 7\n",
      "calling mwb with 8\n",
      "constructed layer_dict for 8\n",
      "calling mwb with 9\n",
      "constructed layer_dict for 9\n",
      "calling mwb with 10\n",
      "constructed layer_dict for 10\n",
      "calling mwb with 11\n",
      "constructed layer_dict for 11\n",
      "calling mwb with 12\n",
      "constructed layer_dict for 12\n",
      "calling mwb with 13\n",
      "constructed layer_dict for 13\n",
      "calling mwb with 14\n",
      "constructed layer_dict for 14\n",
      "calling mwb with 15\n",
      "constructed layer_dict for 15\n",
      "calling mwb with 16\n",
      "constructed layer_dict for 16\n",
      "calling mwb with 17\n",
      "constructed layer_dict for 17\n",
      "calling mwb with 18\n",
      "constructed layer_dict for 18\n",
      "calling mwb with 19\n",
      "constructed layer_dict for 19\n",
      "calling mwb with 20\n",
      "constructed layer_dict for 20\n",
      "calling mwb with 21\n",
      "constructed layer_dict for 21\n",
      "calling mwb with 22\n",
      "constructed layer_dict for 22\n",
      "calling mwb with 23\n",
      "constructed layer_dict for 23\n",
      "calling mwb with 24\n",
      "constructed layer_dict for 24\n",
      "calling mwb with 25\n",
      "constructed layer_dict for 25\n",
      "calling mwb with 26\n",
      "constructed layer_dict for 26\n",
      "approx s_s\n",
      "approx_s_s layer_dict for 7 is {'i': 7, 'o_o_mean_weight': tensor([[ 8.6377e-01,  1.1292e-02, -9.4509e-04,  ..., -2.7695e-03,\n",
      "          6.9275e-03, -2.2545e-03],\n",
      "        [ 6.9571e-04,  8.5059e-01,  2.2602e-03,  ...,  3.2902e-03,\n",
      "         -7.4387e-03,  1.4572e-02],\n",
      "        [ 1.0956e-02, -4.9210e-04,  8.7305e-01,  ...,  8.8120e-04,\n",
      "         -7.9422e-03, -2.8286e-03],\n",
      "        ...,\n",
      "        [-1.4334e-03,  8.9493e-03, -2.4414e-03,  ...,  8.8965e-01,\n",
      "          1.0004e-03, -2.7752e-03],\n",
      "        [ 5.4073e-04, -2.7905e-03, -1.3256e-03,  ..., -5.1003e-03,\n",
      "          8.7500e-01,  3.8815e-03],\n",
      "        [-6.2447e-03,  6.8741e-03, -1.0773e-02,  ..., -8.0872e-03,\n",
      "          1.0063e-02,  8.6230e-01]], device='cuda:0', dtype=torch.float16), 'o_o_mean_bias': tensor([[ 0.3193, -0.2568,  0.2498,  ...,  0.0235,  0.1052, -0.1635]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<MeanBackward1>), 'o_o_sum_weight': tensor([[ 6.9102e+00,  9.0332e-02, -7.5607e-03,  ..., -2.2156e-02,\n",
      "          5.5420e-02, -1.8036e-02],\n",
      "        [ 5.5656e-03,  6.8047e+00,  1.8082e-02,  ...,  2.6321e-02,\n",
      "         -5.9509e-02,  1.1658e-01],\n",
      "        [ 8.7646e-02, -3.9368e-03,  6.9844e+00,  ...,  7.0496e-03,\n",
      "         -6.3538e-02, -2.2629e-02],\n",
      "        ...,\n",
      "        [-1.1467e-02,  7.1594e-02, -1.9531e-02,  ...,  7.1172e+00,\n",
      "          8.0032e-03, -2.2202e-02],\n",
      "        [ 4.3259e-03, -2.2324e-02, -1.0605e-02,  ..., -4.0802e-02,\n",
      "          7.0000e+00,  3.1052e-02],\n",
      "        [-4.9957e-02,  5.4993e-02, -8.6182e-02,  ..., -6.4697e-02,\n",
      "          8.0505e-02,  6.8984e+00]], device='cuda:0', dtype=torch.float16), 'o_o_sum_bias': tensor([[ 2.5547, -2.0547,  1.9980,  ...,  0.1880,  0.8413, -1.3076]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<SumBackward1>)}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'s_s_mean_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m hs \u001b[38;5;241m=\u001b[39m build\u001b[38;5;241m.\u001b[39mget_hidden_state(mt, prompt, sample\u001b[38;5;241m.\u001b[39msubject, start) \u001b[38;5;66;03m#layer 5\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#use the complete LRE\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m llra_object_hs \u001b[38;5;241m=\u001b[39m \u001b[43mllra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapprox_lm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_O_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS_O_end\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m llra_preds \u001b[38;5;241m=\u001b[39m build\u001b[38;5;241m.\u001b[39mget_object(mt, llra_object_hs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#use the simple LRE\u001b[39;00m\n",
      "File \u001b[0;32m~/my-lre/data/../llra/build.py:196\u001b[0m, in \u001b[0;36mLLRA.approx_lm\u001b[0;34m(self, hs, S_O, beta, beta_layer)\u001b[0m\n\u001b[1;32m    194\u001b[0m         hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapprox_s_s_layer(hs, i, beta)\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         hs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapprox_s_s_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(S_O_start, S_O_end):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapprox s_o\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/my-lre/data/../llra/build.py:145\u001b[0m, in \u001b[0;36mLLRA.approx_s_s_layer\u001b[0;34m(self, hs, i, beta)\u001b[0m\n\u001b[1;32m    143\u001b[0m layer_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_layer_dict(i)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapprox_s_s layer_dict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m layer_weight \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms_s_mean_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    146\u001b[0m layer_bias \u001b[38;5;241m=\u001b[39m layer_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms_s_mean_bias\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    147\u001b[0m ln_weight \u001b[38;5;241m=\u001b[39m lm_params[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer.h.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.ln_1.weight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 's_s_mean_weight'"
     ]
    }
   ],
   "source": [
    "# get relevant weights and biases from layers 0-27\n",
    "llra_samples = os.listdir(wdir)\n",
    "# clre_samples = [\"begin\", \"compose\", \"determine\", \"examine\", \"intrude\", \"recommend\", \"speak\", \"tell\"]\n",
    "# assert(len(clre_samples) == 8)\n",
    "\n",
    "json_path = 'json/lexsem/L05 [meronyms - member].json'\n",
    "DEFAULT_N_ICL = 8 \n",
    "N_TRIALS = 8\n",
    "VIEW_SAMPLES = 5\n",
    "\n",
    "file = open(json_path, 'r')\n",
    "data = json.load(file)\n",
    "file.close()\n",
    "\n",
    "beta = 1\n",
    "relation = Relation.from_dict(data)\n",
    "prompt_template = relation.prompt_templates[0]\n",
    "#ASSEMBLE PROMPTS AND OBJECT ANSWERS\n",
    "clozed_prompts = []\n",
    "clozed_answers = []\n",
    "\n",
    "for x in relation.samples:\n",
    "    samples = [x] + random.sample(relation.samples, DEFAULT_N_ICL - 1)\n",
    "    #print(f'{samples} samples)')\n",
    "    cloze_prompt = functional.make_prompt(\n",
    "        template = prompt_template, \n",
    "        target = x,\n",
    "        examples = samples\n",
    "        )\n",
    "    clozed_prompts.append(cloze_prompt)\n",
    "    clozed_answers.append(x.object)\n",
    "\n",
    "outputs_lm = functional.predict_next_token(mt=mt, prompt=clozed_prompts)\n",
    "preds_lm =  [[x.token for x in xs] for xs in outputs_lm]\n",
    "recall_lm = metrics.recall(preds_lm, clozed_answers)\n",
    "\n",
    "lre_correct = 0\n",
    "llra_correct = 0\n",
    "lm_correct = 0\n",
    "\n",
    "print(f'{start=} {S_O_start=} {S_O_end=} {end=}')\n",
    "layer_dicts = build.build_llra(wdir, llra_samples, start,S_O_start, S_O_end, end)\n",
    "#print(layer_dicts)\n",
    "llra = build.LLRA(layer_dicts=layer_dicts)\n",
    "\n",
    "for i, sample, objs, prompt, preds in \\\n",
    "zip(range(0,50), relation.samples, clozed_answers, clozed_prompts, preds_lm):\n",
    "    \n",
    "    if (metrics.any_is_nontrivial_prefix(predictions=preds, targets=objs)):\n",
    "        hs = build.get_hidden_state(mt, prompt, sample.subject, start) #layer 5\n",
    "        #use the complete LRE\n",
    "        llra_object_hs = llra.approx_lm(hs, (S_O_start, S_O_end))\n",
    "        llra_preds = build.get_object(mt, llra_object_hs)[0]\n",
    "        \n",
    "        #use the simple LRE\n",
    "        lre_object_hs = hs.mm(lre_weight.t()) * beta + lre_bias\n",
    "        lre_preds = build.get_object(mt, lre_object_hs)[0]\n",
    "        \n",
    "        if(metrics.any_is_nontrivial_prefix(predictions=llra_preds, targets=objs)):\n",
    "            llra_correct += 1\n",
    "\n",
    "        if(metrics.any_is_nontrivial_prefix(predictions=lre_preds, targets=objs)):\n",
    "            lre_correct += 1\n",
    "            \n",
    "        if(i < VIEW_SAMPLES):\n",
    "            print(f'{sample.subject} {preds[0]} {llra_preds}')\n",
    "            \n",
    "        lm_correct += 1\n",
    "print(f'S_O_START,{S_O_start},S_O_END,{S_O_end},beta,{beta},clre,{llra_correct},lre,{lre_correct},lm,{lm_correct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974add2-2c03-4b01-a71a-3762339fa440",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LRE BETA INSERTION POSITION\n",
    "json_path = 'qapprox/antonyms-binary.json'\n",
    "\n",
    "DEFAULT_N_ICL = 8 \n",
    "N_TRIALS = 8\n",
    "\n",
    "with open(json_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    relation = Relation.from_dict(data)\n",
    "    prompt = \"The opposite of {} is\"\n",
    "    prompt_template = relation.prompt_templates[0]\n",
    "    beta = 2.75\n",
    "    for beta_layer in range(5,27):\n",
    "        print(f'{beta_layer=}')\n",
    "        for _ in range(0,N_TRIALS):\n",
    "            clozed_prompts = []\n",
    "            clozed_answers = []\n",
    "            for x in relation.samples:\n",
    "                samples = [x] + random.sample(relation.samples, DEFAULT_N_ICL - 1)\n",
    "                cloze_prompt = functional.make_prompt(\n",
    "                    template = prompt_template, \n",
    "                    target = x,\n",
    "                    examples = samples\n",
    "                    )\n",
    "                clozed_prompts.append(cloze_prompt)\n",
    "                clozed_answers.append(x.object)\n",
    "            outputs_lm = functional.predict_next_token(mt=mt, prompt=clozed_prompts)\n",
    "            preds_lm =  [[x.token for x in xs] for xs in outputs_lm]\n",
    "            recall_lm = metrics.recall(preds_lm, clozed_answers)\n",
    "            lre_correct = 0\n",
    "            lm_correct = 0\n",
    "            \n",
    "            for _, sample, objs, prompt, preds in zip(range(50), relation.samples, clozed_answers, clozed_prompts, preds_lm):\n",
    "                if (metrics.any_is_nontrivial_prefix(\n",
    "                    predictions=preds, \n",
    "                    targets=objs)):\n",
    "                    hs = build.get_hidden_state(mt, prompt, sample.subject, 1) #layer 5\n",
    "                    object_hs = approx_lm(hs, beta, beta_layer)\n",
    "                    lre_preds = get_object(mt, object_hs)[0]\n",
    "                    if(metrics.any_is_nontrivial_prefix(predictions=lre_preds, targets=objs)):\n",
    "                        lre_correct += 1\n",
    "                    lm_correct += 1\n",
    "                    \n",
    "            print(f'{lre_correct} {lm_correct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2659a64-b5b5-43cd-b32c-cca6f82b397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for most relations.\n",
    "def is_nontrivial_prefix(prediction: str, target: str) -> bool:\n",
    "    target = target.lower().strip()\n",
    "    prediction = prediction.lower().strip()\n",
    "    # if len(prediction) > 0 and target.startswith(prediction):\n",
    "    #     print(f\"{prediction} matches {target}\")\n",
    "    return len(prediction) > 1 and target.startswith(prediction)\n",
    "\n",
    "def any_is_nontrivial_prefix(prediction, targets) -> bool:\n",
    "    return any(is_nontrivial_prefix(prediction, target) for target in targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec8e5733-9f9f-4ee1-88d9-aa76ecef4ee3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (subj, obj) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpairs\u001b[49m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m beta \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m         beta \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pairs' is not defined"
     ]
    }
   ],
   "source": [
    "for (subj, obj) in pairs:\n",
    "    for beta in range(10,50, 1):\n",
    "        beta /= 10\n",
    "        hs = get_hidden_state(mt, subj, 5) #layer 5\n",
    "        object_hs = approx_lm(hs, beta) #beta\n",
    "        pred = get_object(mt, object_hs)[0]\n",
    "        if (any_is_nontrivial_prefix(pred[0], obj)):\n",
    "            print(f\"{subj} matches {pred[0]}: {beta}\")\n",
    "            break\n",
    "    \n",
    "# for (subj, obj) in pairs:\n",
    "#     hs = get_hidden_state(mt, subj, 5)\n",
    "#     object_hs = approx_lm(hs, 2.4)\n",
    "#     print(f'{subj}: {get_object(mt, object_hs)[0]} {obj}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e63aa-35aa-4574-aeef-909288a286a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tokens in GPT-J\n",
    "#get the hidden state of them at the last layer (after the 28th layer, or s->o @ 27)\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_hidden_state(mt, subject, h_layer, h=None, k=5):\n",
    "    prompt = f\" {subject}\"\n",
    "    h_index, inputs = functional.find_subject_token_index(\n",
    "        mt = mt, prompt=prompt, subject=subject)\n",
    "    #print(f'h_index is {h_index}, inputs is {inputs}')\n",
    "    [[hs], _] = functional.compute_hidden_states(\n",
    "        mt = mt, layers = [h_layer], inputs = inputs)\n",
    "    #h is hs @ h_layer @ h_index\n",
    "    h = hs[:, h_index]\n",
    "    h = h.to(device)\n",
    "    return h\n",
    "    \n",
    "#Spaces are converted in a special character (the Ġ ) in the tokenizer prior to BPE splitting\n",
    "#mostly to avoid digesting spaces since the standard BPE algorithm used spaces in its process \n",
    "\n",
    "#all animal encodings are at [-0.4153   2.023   -2.23    ... -0.785    0.06323 -0.1819 ]\n",
    "\n",
    "text = \"our classic pre-baked blueberry pie filled with delicious plump and juicy wild blueberries\"\n",
    "encoded_input = mt.tokenizer(text, return_tensors=\"pt\")\n",
    "token_ids = range(0,50400)\n",
    "tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "tokens = [token.replace(\"Ġ\", \" \") for token in tokens]\n",
    "\n",
    "#this is too slow and not useful.\n",
    "dict27 = {}\n",
    "for i in tqdm(range(len(tokens))):\n",
    "    token = tokens[i]\n",
    "    dict27[token] = get_hidden_state(mt, token, 27)\n",
    "    \n",
    "with open('animal_youth_27.pkl', 'wb') as file:\n",
    "    pickle.dump(dict27, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c2b5d1c3-4f38-45ba-8664-9e535d0cd653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  (1): Linear(in_features=4096, out_features=50400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11195a8e-d798-4b60-8884-3c5ef6d7bc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' puppy', ' pup', ' p', ' dog', ' �']\n",
      "[' duck', ' dra', ' g', ' �', ' \"']\n",
      "[' fry', ' prog', ' F', ' �', ' lar']\n",
      "[' fo', ' col', ' horse', ' pony', ' �']\n",
      "[' kit', ' m', ' \"', ' �', ' p']\n",
      "[' seal', ' \"', ' �', ' pup', ' p']\n",
      "[' shark', ' \"', ' �', ' p', ' pup']\n",
      "[' fry', ' trout', ' \"', ' �', ' rainbow']\n"
     ]
    }
   ],
   "source": [
    "animals = [\"dog\", \"duck\", \"fish\", \"horse\", \"mink\", \"seal\", \"shark\", \"trout\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db937003-748c-465b-a853-4ec53556ec7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
