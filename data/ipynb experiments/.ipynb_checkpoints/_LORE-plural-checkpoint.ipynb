{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a889fad3-b5d9-4881-bcf8-1828c271bf8a",
   "metadata": {},
   "source": [
    "Linear Oriented Relational Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8b24b7-d135-4cd9-afa1-817a35d67114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from transformers import GPTJForCausalLM, AutoTokenizer\n",
    "import lre.models as models\n",
    "import lre.functional as functional\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "import torch\n",
    "from dataclasses_json import DataClassJsonMixin\n",
    "device = \"cuda:0\"\n",
    "\n",
    "model = GPTJForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\", revision=\"float16\", torch_dtype=torch.float16, low_cpu_mem_usage=True)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "mt = models.ModelAndTokenizer(model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68b72ef0-c79d-4042-939c-769e774fd142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "wdir = 'animal_youth'\n",
    "weight_str = 'weight_animal - youth_sem1'\n",
    "bias_str = 'bias_animal - youth_sem1'\n",
    "\n",
    "weight_paths = [f for f in os.listdir(wdir) if f.startswith(weight_str)]\n",
    "bias_paths = [f for f in os.listdir(wdir) if f.startswith(bias_str)]\n",
    "\n",
    "@dataclass(frozen=True, kw_only=True)\n",
    "class SubjectWeight(DataClassJsonMixin):\n",
    "    subject: str\n",
    "    weight: torch.Tensor\n",
    "    bias: torch.Tensor\n",
    "    hs: torch.Tensor\n",
    "\n",
    "weights = []\n",
    "biases = []\n",
    "subjects = []\n",
    "subject_weights = []\n",
    "h_layer = 1\n",
    "\n",
    "def no_context_hs(word):\n",
    "    h_index, inputs = functional.find_subject_token_index(\n",
    "    mt = mt, prompt=f'The offspring of a {word} is referred to as a ', subject=word)\n",
    "    [[hs], _] = functional.compute_hidden_states(\n",
    "        mt = mt, layers = [h_layer], inputs = inputs)\n",
    "    #h = hs @ h_layer @ h_index\n",
    "    h = hs[:, h_index]\n",
    "    return h\n",
    "\n",
    "for bias_path, weight_path in zip(bias_paths, weight_paths):\n",
    "    subject = weight_path.split(\"_\")[3]\n",
    "    weight = torch.load(f'{wdir}/' + weight_path)\n",
    "    bias = torch.load(f'{wdir}/' + bias_path)\n",
    "    hs = no_context_hs(subject).cpu()\n",
    "    sw = SubjectWeight(subject=subject,\n",
    "                       weight=weight,\n",
    "                       bias=bias,\n",
    "                       hs = hs\n",
    "                       )\n",
    "    subject_weights.append(sw)\n",
    "    \n",
    "weights = [s.weight for s in subject_weights]\n",
    "biases = [s.bias for s in subject_weights]\n",
    "\n",
    "weight = torch.stack(weights).mean(dim=0).to(device)\n",
    "bias = torch.stack(biases).mean(dim=0).to(device)\n",
    "#weigh similar subjects more than distant subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2571c28-5f55-49de-8d2f-e5d47db9b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#semantic method\n",
    "import numpy as np\n",
    "sim = torch.nn.CosineSimilarity(dim=1)\n",
    "#This doesn't work because more similar animals ~= similar youth.\n",
    "def lore_wb(word):\n",
    "    word_hs = no_context_hs(word).cpu()\n",
    "    sims = torch.stack([sim(word_hs, subject.hs) for subject in subject_weights])\n",
    "    sims = (sims - torch.mean(sims)) / torch.std(sims)\n",
    "    sims\n",
    "    similarities = sims.reshape((8,1,1)).to(device)\n",
    "    lore_weights = torch.mul(similarities,torch.stack(weights).to(device))\n",
    "    lore_biases = torch.mul(similarities,torch.stack(biases).to(device))\n",
    "    lore_weight = lore_weights.mean(dim=0).to(device)\n",
    "    lore_bias = lore_biases.mean(dim=0).to(device)\n",
    "    return (lore_weight, lore_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34c71942-2e65-4181-b957-c832a414f078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#testing data\n",
    "import json\n",
    "json_path = 'animal-youth.json'\n",
    "pairs = []\n",
    "with open(json_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "    for pair in data['samples']:\n",
    "        pairs.append((pair['subject'],pair['object'][0]))    \n",
    "        \n",
    "def is_nontrivial_prefix(prediction: str, target: str) -> bool:\n",
    "    target = target.lower().strip()\n",
    "    prediction = prediction.lower().strip()\n",
    "    # if len(prediction) > 0 and target.startswith(prediction):\n",
    "    #     print(f\"{prediction} matches {target}\")\n",
    "    return len(prediction) > 1 and target.startswith(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87f75b44-d870-4cb9-9abd-7acbd8ca7d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: 1.5 LORE: 28 LRE: 29\n",
      "beta: 1.6 LORE: 28 LRE: 29\n",
      "beta: 1.7 LORE: 29 LRE: 29\n",
      "beta: 1.8 LORE: 30 LRE: 29\n",
      "beta: 1.9 LORE: 29 LRE: 30\n"
     ]
    }
   ],
   "source": [
    "#mt = models.ModelAndTokenizer(model,tokenizer)\n",
    "\n",
    "LRE_H = 5\n",
    "def get_object(mt, subject, weight,bias, prompt, h_layer, beta, k=5):\n",
    "    h_index, inputs = functional.find_subject_token_index(\n",
    "        mt = mt, prompt=prompt, subject=subject)\n",
    "    #print(f'h_index is {h_index}, inputs is {inputs}')\n",
    "    [[hs], _] = functional.compute_hidden_states(\n",
    "        mt = mt, layers = [h_layer], inputs = inputs)\n",
    "    \n",
    "    #h is hs @ h_layer @ h_index\n",
    "    h = hs[:, h_index]\n",
    "    h = h.half().to(device)\n",
    "    z = h.mm(weight.t()) * beta + bias\n",
    "    logits = mt.lm_head(z)\n",
    "    dist = torch.softmax(logits.float(), dim=-1)\n",
    "    topk = dist.topk(dim=-1, k=k)\n",
    "    probs = topk.values.view(k).tolist()\n",
    "    token_ids = topk.indices.view(k).tolist()\n",
    "    words = [mt.tokenizer.decode(token_id) for token_id in token_ids]\n",
    "    return (words)\n",
    "\n",
    "for beta in range(0,5, 1):\n",
    "    beta = 1.5 + beta / 10\n",
    "    #print(\"LORE \\n\")\n",
    "    LORE_correct = 0\n",
    "    for pair in pairs:\n",
    "        subj, obj = pair\n",
    "        prompt = f'The offspring of a {subj} is referred to as a'\n",
    "        (lore_weight, lore_bias) = lore_wb(subj)\n",
    "        pred = get_object(mt,pair[0],lore_weight,lore_bias,prompt, LRE_H, beta)\n",
    "        #print(f'{pred[0]} {obj}')\n",
    "        if (is_nontrivial_prefix(pred[0], obj)):\n",
    "            LORE_correct += 1\n",
    "    \n",
    "    #LRE_correct = 0\n",
    "    LRE_correct = 0\n",
    "    for pair in pairs:\n",
    "        subj, obj = pair\n",
    "        prompt = f'The offspring of a {subj} is referred to as a'\n",
    "        pred = get_object(mt,pair[0],weight,bias,prompt, 5, beta)\n",
    "        #print(f'{pred[0]} {obj}')\n",
    "        if (is_nontrivial_prefix(pred[0], obj)):\n",
    "            LRE_correct += 1\n",
    "            \n",
    "    print(f'beta: {beta} LORE: {LORE_correct} LRE: {LRE_correct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dfb680-5825-45bb-ab7d-80c65d584e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
